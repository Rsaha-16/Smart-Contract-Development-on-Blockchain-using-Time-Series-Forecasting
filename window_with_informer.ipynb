{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import Informer\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom callback to save training losses at each epoch\n",
    "class SaveTrainingLossCallback(pl.Callback):\n",
    "    def __init__(self, log_file='epoch_loss_log_window_informer_model_one_year.txt'):\n",
    "        self.training_losses = []\n",
    "        self.log_file = log_file\n",
    "        self.window_number = 0\n",
    "        with open(self.log_file, 'w') as f:\n",
    "            f.write('Epoch,Train_Loss,Window\\n')\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # Save the training loss at the end of each epoch\n",
    "        train_loss = trainer.callback_metrics['train_loss'].item()\n",
    "        self.training_losses.append(train_loss)\n",
    "        print(f\"Epoch {trainer.current_epoch}: Train Loss = {train_loss}\")\n",
    "        \n",
    "        # Log the loss to the file\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write(f'{trainer.current_epoch},{train_loss},{self.window_number}\\n')\n",
    "\n",
    "    def set_window_number(self, window_number):\n",
    "        self.window_number = window_number\n",
    "\n",
    "# Initialize callbacks\n",
    "save_loss_callback = SaveTrainingLossCallback()\n",
    "pl_trainer_kwargs = {\"callbacks\": [save_loss_callback], \"accelerator\": \"cpu\", \"devices\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess the data\n",
    "csv_file_path = '/home/raj/Rajarshi/Term Project/rajarshi_code/rajarshi_code/data/SBIN.NS_day_2022.csv'\n",
    "sbi_data = pd.read_csv(csv_file_path, parse_dates=['Date'])\n",
    "sbi_data.dropna(inplace=True)\n",
    "sbi_data.set_index('Date', inplace=True)\n",
    "sbi_data = sbi_data.asfreq('B', method='pad')\n",
    "\n",
    "# Create scalers\n",
    "scaler_close = MinMaxScaler()\n",
    "sbi_data['Open_Close_Diff'] = sbi_data['Open'] - sbi_data['Close']\n",
    "sbi_data['Close'] = scaler_close.fit_transform(sbi_data[['Close']])\n",
    "\n",
    "# Initialize variables\n",
    "training_end_date = sbi_data.index.max() - pd.DateOffset(years=1)  # Train using last 1 year of data\n",
    "final_predictions = []\n",
    "\n",
    "# Define the window management and model training class\n",
    "class ModelTrainer:\n",
    "    def __init__(self, data, scaler_close, save_loss_callback, pl_trainer_kwargs):\n",
    "        self.data = data\n",
    "        self.scaler_close = scaler_close\n",
    "        self.save_loss_callback = save_loss_callback\n",
    "        self.pl_trainer_kwargs = pl_trainer_kwargs\n",
    "\n",
    "    def train_model(self, train_data, window_number):\n",
    "        # Set the window number for the callback\n",
    "        self.save_loss_callback.set_window_number(window_number)\n",
    "\n",
    "        # Prepare the training data\n",
    "        Y_train_df = train_data.reset_index().rename(columns={'Date': 'ds', 'Close': 'y'})\n",
    "        Y_train_df['unique_id'] = 'SBIN'\n",
    "\n",
    "        # Initialize and train the Informer model (without historical exogenous variables)\n",
    "        model = Informer(\n",
    "            h=7,  # Output horizon (prediction length)\n",
    "            input_size=60,  # Input window size\n",
    "            hidden_size=128,\n",
    "            conv_hidden_size=32,\n",
    "            n_head=4,\n",
    "            dropout=0.2,\n",
    "            encoder_layers=2,\n",
    "            decoder_layers=1,\n",
    "            factor=3,\n",
    "            distil=True,\n",
    "            loss=MAE(),\n",
    "            learning_rate=5e-4,\n",
    "            max_steps=250,  # Adjusted as per your code\n",
    "            **{'callbacks': [self.save_loss_callback]}  # Pass the callback directly here\n",
    "        )\n",
    "\n",
    "        # NeuralForecast object to handle model training\n",
    "        nf = NeuralForecast(models=[model], freq='B')\n",
    "        nf.fit(df=Y_train_df)\n",
    "\n",
    "        # Generate future dataframe automatically\n",
    "        futr_df = nf.make_future_dataframe()\n",
    "\n",
    "        # Generate predictions\n",
    "        forecasts = nf.predict(futr_df=futr_df)\n",
    "        \n",
    "        pred_values = self.scaler_close.inverse_transform(forecasts[['Informer']].values)\n",
    "        dates = futr_df['ds']\n",
    "\n",
    "        return dates, pred_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training window 1: from 1998-11-02 00:00:00 to 2021-12-30 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:04<00:00,  0.23it/s, v_num=115, train_loss_step=0.397]Epoch 0: Train Loss = 0.39650648832321167\n",
      "Epoch 1: 100%|██████████| 1/1 [00:04<00:00,  0.24it/s, v_num=115, train_loss_step=0.500, train_loss_epoch=0.397]Epoch 1: Train Loss = 0.49975866079330444\n",
      "Epoch 2: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.366, train_loss_epoch=0.500]Epoch 2: Train Loss = 0.36593756079673767\n",
      "Epoch 3: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.247, train_loss_epoch=0.366]Epoch 3: Train Loss = 0.24721702933311462\n",
      "Epoch 4: 100%|██████████| 1/1 [00:04<00:00,  0.24it/s, v_num=115, train_loss_step=0.310, train_loss_epoch=0.247]Epoch 4: Train Loss = 0.310354620218277\n",
      "Epoch 5: 100%|██████████| 1/1 [00:04<00:00,  0.24it/s, v_num=115, train_loss_step=0.304, train_loss_epoch=0.310]Epoch 5: Train Loss = 0.30386894941329956\n",
      "Epoch 6: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.248, train_loss_epoch=0.304]Epoch 6: Train Loss = 0.24759696424007416\n",
      "Epoch 7: 100%|██████████| 1/1 [00:04<00:00,  0.24it/s, v_num=115, train_loss_step=0.242, train_loss_epoch=0.248]Epoch 7: Train Loss = 0.24162913858890533\n",
      "Epoch 8: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.265, train_loss_epoch=0.242]Epoch 8: Train Loss = 0.2652994692325592\n",
      "Epoch 9: 100%|██████████| 1/1 [00:04<00:00,  0.23it/s, v_num=115, train_loss_step=0.254, train_loss_epoch=0.265]Epoch 9: Train Loss = 0.25427109003067017\n",
      "Epoch 10: 100%|██████████| 1/1 [00:04<00:00,  0.23it/s, v_num=115, train_loss_step=0.237, train_loss_epoch=0.254]Epoch 10: Train Loss = 0.23682349920272827\n",
      "Epoch 11: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.219, train_loss_epoch=0.237]Epoch 11: Train Loss = 0.2193099558353424\n",
      "Epoch 12: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.234, train_loss_epoch=0.219]Epoch 12: Train Loss = 0.2339942902326584\n",
      "Epoch 13: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.220, train_loss_epoch=0.234]Epoch 13: Train Loss = 0.21987497806549072\n",
      "Epoch 14: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.208, train_loss_epoch=0.220]Epoch 14: Train Loss = 0.20809543132781982\n",
      "Epoch 15: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.189, train_loss_epoch=0.208]Epoch 15: Train Loss = 0.18932922184467316\n",
      "Epoch 16: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.197, train_loss_epoch=0.189]Epoch 16: Train Loss = 0.19746552407741547\n",
      "Epoch 17: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.191, train_loss_epoch=0.197]Epoch 17: Train Loss = 0.19051770865917206\n",
      "Epoch 18: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.193, train_loss_epoch=0.191]Epoch 18: Train Loss = 0.1930505484342575\n",
      "Epoch 19: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.172, train_loss_epoch=0.193]Epoch 19: Train Loss = 0.17178307473659515\n",
      "Epoch 20: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.169, train_loss_epoch=0.172]Epoch 20: Train Loss = 0.16863632202148438\n",
      "Epoch 21: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.182, train_loss_epoch=0.169]Epoch 21: Train Loss = 0.18239928781986237\n",
      "Epoch 22: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.177, train_loss_epoch=0.182]Epoch 22: Train Loss = 0.17723187804222107\n",
      "Epoch 23: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.162, train_loss_epoch=0.177]Epoch 23: Train Loss = 0.16155506670475006\n",
      "Epoch 24: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.157, train_loss_epoch=0.162]Epoch 24: Train Loss = 0.15686538815498352\n",
      "Epoch 25: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.156, train_loss_epoch=0.157]Epoch 25: Train Loss = 0.1562296450138092\n",
      "Epoch 26: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.161, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.16127803921699524\n",
      "Epoch 27: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.150, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.1495710015296936\n",
      "Epoch 28: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.142, train_loss_epoch=0.150]Epoch 28: Train Loss = 0.1419907510280609\n",
      "Epoch 29: 100%|██████████| 1/1 [00:04<00:00,  0.22it/s, v_num=115, train_loss_step=0.149, train_loss_epoch=0.142]Epoch 29: Train Loss = 0.14939771592617035\n",
      "Epoch 30: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.143, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.14302989840507507\n",
      "Epoch 31: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.140, train_loss_epoch=0.143]Epoch 31: Train Loss = 0.14010123908519745\n",
      "Epoch 32: 100%|██████████| 1/1 [00:04<00:00,  0.22it/s, v_num=115, train_loss_step=0.137, train_loss_epoch=0.140]Epoch 32: Train Loss = 0.1366649866104126\n",
      "Epoch 33: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.133, train_loss_epoch=0.137]Epoch 33: Train Loss = 0.13277532160282135\n",
      "Epoch 34: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.134, train_loss_epoch=0.133]Epoch 34: Train Loss = 0.13370315730571747\n",
      "Epoch 35: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.130, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.13041973114013672\n",
      "Epoch 36: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.129, train_loss_epoch=0.130]Epoch 36: Train Loss = 0.12899164855480194\n",
      "Epoch 37: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.130, train_loss_epoch=0.129]Epoch 37: Train Loss = 0.129831001162529\n",
      "Epoch 38: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.123, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12284992635250092\n",
      "Epoch 39: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.117, train_loss_epoch=0.123]Epoch 39: Train Loss = 0.11669006943702698\n",
      "Epoch 40: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.116, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11589206755161285\n",
      "Epoch 41: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.118, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11822367459535599\n",
      "Epoch 42: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.113, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.1126527339220047\n",
      "Epoch 43: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.109, train_loss_epoch=0.113]Epoch 43: Train Loss = 0.10872813314199448\n",
      "Epoch 44: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.114, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11353884637355804\n",
      "Epoch 45: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.106, train_loss_epoch=0.114]Epoch 45: Train Loss = 0.10617482662200928\n",
      "Epoch 46: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.105, train_loss_epoch=0.106]Epoch 46: Train Loss = 0.10540948808193207\n",
      "Epoch 47: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.103, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10299297422170639\n",
      "Epoch 48: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0998, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.09976399689912796\n",
      "Epoch 49: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.103, train_loss_epoch=0.0998] Epoch 49: Train Loss = 0.10250020027160645\n",
      "Epoch 50: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.100, train_loss_epoch=0.103] Epoch 50: Train Loss = 0.10014031082391739\n",
      "Epoch 51: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.096, train_loss_epoch=0.100]Epoch 51: Train Loss = 0.09601695835590363\n",
      "Epoch 52: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0961, train_loss_epoch=0.096]Epoch 52: Train Loss = 0.0960703119635582\n",
      "Epoch 53: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0929, train_loss_epoch=0.0961]Epoch 53: Train Loss = 0.09292079508304596\n",
      "Epoch 54: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0913, train_loss_epoch=0.0929]Epoch 54: Train Loss = 0.09130781143903732\n",
      "Epoch 55: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0925, train_loss_epoch=0.0913]Epoch 55: Train Loss = 0.09247436374425888\n",
      "Epoch 56: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0891, train_loss_epoch=0.0925]Epoch 56: Train Loss = 0.0891195759177208\n",
      "Epoch 57: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0868, train_loss_epoch=0.0891]Epoch 57: Train Loss = 0.08678946644067764\n",
      "Epoch 58: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.088, train_loss_epoch=0.0868] Epoch 58: Train Loss = 0.0879838764667511\n",
      "Epoch 59: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.084, train_loss_epoch=0.088] Epoch 59: Train Loss = 0.08398657292127609\n",
      "Epoch 60: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0841, train_loss_epoch=0.084]Epoch 60: Train Loss = 0.08410754054784775\n",
      "Epoch 61: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0811, train_loss_epoch=0.0841]Epoch 61: Train Loss = 0.08105478435754776\n",
      "Epoch 62: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0802, train_loss_epoch=0.0811]Epoch 62: Train Loss = 0.08018509298563004\n",
      "Epoch 63: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0814, train_loss_epoch=0.0802]Epoch 63: Train Loss = 0.08140222728252411\n",
      "Epoch 64: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0776, train_loss_epoch=0.0814]Epoch 64: Train Loss = 0.07762263715267181\n",
      "Epoch 65: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0808, train_loss_epoch=0.0776]Epoch 65: Train Loss = 0.08076562732458115\n",
      "Epoch 66: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0766, train_loss_epoch=0.0808]Epoch 66: Train Loss = 0.07662973552942276\n",
      "Epoch 67: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0745, train_loss_epoch=0.0766]Epoch 67: Train Loss = 0.07453535497188568\n",
      "Epoch 68: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0742, train_loss_epoch=0.0745]Epoch 68: Train Loss = 0.07416283339262009\n",
      "Epoch 69: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.0719, train_loss_epoch=0.0742]Epoch 69: Train Loss = 0.07193212956190109\n",
      "Epoch 70: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.072, train_loss_epoch=0.0719] Epoch 70: Train Loss = 0.0720401480793953\n",
      "Epoch 71: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0686, train_loss_epoch=0.072]Epoch 71: Train Loss = 0.06856512278318405\n",
      "Epoch 72: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0686, train_loss_epoch=0.0686]Epoch 72: Train Loss = 0.06856433302164078\n",
      "Epoch 73: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0695, train_loss_epoch=0.0686]Epoch 73: Train Loss = 0.06948640197515488\n",
      "Epoch 74: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0689, train_loss_epoch=0.0695]Epoch 74: Train Loss = 0.06888958066701889\n",
      "Epoch 75: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0662, train_loss_epoch=0.0689]Epoch 75: Train Loss = 0.06618616729974747\n",
      "Epoch 76: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0651, train_loss_epoch=0.0662]Epoch 76: Train Loss = 0.06511283665895462\n",
      "Epoch 77: 100%|██████████| 1/1 [00:04<00:00,  0.25it/s, v_num=115, train_loss_step=0.067, train_loss_epoch=0.0651] Epoch 77: Train Loss = 0.06704403460025787\n",
      "Epoch 78: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0659, train_loss_epoch=0.067]Epoch 78: Train Loss = 0.06586001813411713\n",
      "Epoch 79: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0628, train_loss_epoch=0.0659]Epoch 79: Train Loss = 0.06279204785823822\n",
      "Epoch 80: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0633, train_loss_epoch=0.0628]Epoch 80: Train Loss = 0.06328005343675613\n",
      "Epoch 81: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0621, train_loss_epoch=0.0633]Epoch 81: Train Loss = 0.06211870163679123\n",
      "Epoch 82: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0621, train_loss_epoch=0.0621]Epoch 82: Train Loss = 0.062130775302648544\n",
      "Epoch 83: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0607, train_loss_epoch=0.0621]Epoch 83: Train Loss = 0.060685865581035614\n",
      "Epoch 84: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0607, train_loss_epoch=0.0607]Epoch 84: Train Loss = 0.060719672590494156\n",
      "Epoch 85: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0591, train_loss_epoch=0.0607]Epoch 85: Train Loss = 0.0591152124106884\n",
      "Epoch 86: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0591, train_loss_epoch=0.0591]Epoch 86: Train Loss = 0.059114351868629456\n",
      "Epoch 87: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0579, train_loss_epoch=0.0591]Epoch 87: Train Loss = 0.0578816719353199\n",
      "Epoch 88: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0591, train_loss_epoch=0.0579]Epoch 88: Train Loss = 0.059073567390441895\n",
      "Epoch 89: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.0578, train_loss_epoch=0.0591]Epoch 89: Train Loss = 0.05784677341580391\n",
      "Epoch 90: 100%|██████████| 1/1 [00:04<00:00,  0.25it/s, v_num=115, train_loss_step=0.0594, train_loss_epoch=0.0578]Epoch 90: Train Loss = 0.059364285320043564\n",
      "Epoch 91: 100%|██████████| 1/1 [00:04<00:00,  0.25it/s, v_num=115, train_loss_step=0.0561, train_loss_epoch=0.0594]Epoch 91: Train Loss = 0.05609362572431564\n",
      "Epoch 92: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0631, train_loss_epoch=0.0561]Epoch 92: Train Loss = 0.06314053386449814\n",
      "Epoch 93: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.053, train_loss_epoch=0.0631] Epoch 93: Train Loss = 0.05303957313299179\n",
      "Epoch 94: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0556, train_loss_epoch=0.053]Epoch 94: Train Loss = 0.05559245124459267\n",
      "Epoch 95: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0524, train_loss_epoch=0.0556]Epoch 95: Train Loss = 0.05243705213069916\n",
      "Epoch 96: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0537, train_loss_epoch=0.0524]Epoch 96: Train Loss = 0.05365833640098572\n",
      "Epoch 97: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0531, train_loss_epoch=0.0537]Epoch 97: Train Loss = 0.053125470876693726\n",
      "Epoch 98: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.0555, train_loss_epoch=0.0531]Epoch 98: Train Loss = 0.055526819080114365\n",
      "Epoch 99: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0513, train_loss_epoch=0.0555]Epoch 99: Train Loss = 0.051258571445941925\n",
      "Epoch 100: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0528, train_loss_epoch=0.0513]Epoch 100: Train Loss = 0.052791427820920944\n",
      "Epoch 101: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0509, train_loss_epoch=0.0528]Epoch 101: Train Loss = 0.05089793726801872\n",
      "Epoch 102: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0497, train_loss_epoch=0.0509]Epoch 102: Train Loss = 0.049710437655448914\n",
      "Epoch 103: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0484, train_loss_epoch=0.0497]Epoch 103: Train Loss = 0.04842055216431618\n",
      "Epoch 104: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0484, train_loss_epoch=0.0484]Epoch 104: Train Loss = 0.04836759716272354\n",
      "Epoch 105: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0486, train_loss_epoch=0.0484]Epoch 105: Train Loss = 0.048607222735881805\n",
      "Epoch 106: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0477, train_loss_epoch=0.0486]Epoch 106: Train Loss = 0.047721017152071\n",
      "Epoch 107: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0468, train_loss_epoch=0.0477]Epoch 107: Train Loss = 0.0467662587761879\n",
      "Epoch 108: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0478, train_loss_epoch=0.0468]Epoch 108: Train Loss = 0.04775381088256836\n",
      "Epoch 109: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0478, train_loss_epoch=0.0478]Epoch 109: Train Loss = 0.047752365469932556\n",
      "Epoch 110: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0462, train_loss_epoch=0.0478]Epoch 110: Train Loss = 0.046198520809412\n",
      "Epoch 111: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0505, train_loss_epoch=0.0462]Epoch 111: Train Loss = 0.050534773617982864\n",
      "Epoch 112: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0491, train_loss_epoch=0.0505]Epoch 112: Train Loss = 0.04912802577018738\n",
      "Epoch 113: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0464, train_loss_epoch=0.0491]Epoch 113: Train Loss = 0.04635397717356682\n",
      "Epoch 114: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0478, train_loss_epoch=0.0464]Epoch 114: Train Loss = 0.047794409096241\n",
      "Epoch 115: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0453, train_loss_epoch=0.0478]Epoch 115: Train Loss = 0.045336347073316574\n",
      "Epoch 116: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.049, train_loss_epoch=0.0453] Epoch 116: Train Loss = 0.04895321652293205\n",
      "Epoch 117: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0447, train_loss_epoch=0.049]Epoch 117: Train Loss = 0.04467533901333809\n",
      "Epoch 118: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0465, train_loss_epoch=0.0447]Epoch 118: Train Loss = 0.046472784131765366\n",
      "Epoch 119: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0442, train_loss_epoch=0.0465]Epoch 119: Train Loss = 0.044181060045957565\n",
      "Epoch 120: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0453, train_loss_epoch=0.0442]Epoch 120: Train Loss = 0.04533708468079567\n",
      "Epoch 121: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0441, train_loss_epoch=0.0453]Epoch 121: Train Loss = 0.044147249311208725\n",
      "Epoch 122: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0461, train_loss_epoch=0.0441]Epoch 122: Train Loss = 0.04611431807279587\n",
      "Epoch 123: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.044, train_loss_epoch=0.0461] Epoch 123: Train Loss = 0.0439608097076416\n",
      "Epoch 124: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0453, train_loss_epoch=0.044]Epoch 124: Train Loss = 0.04529436677694321\n",
      "Epoch 125: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=115, train_loss_step=0.0428, train_loss_epoch=0.0453]Epoch 125: Train Loss = 0.04275151342153549\n",
      "Epoch 126: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0419, train_loss_epoch=0.0428]Epoch 126: Train Loss = 0.041854459792375565\n",
      "Epoch 127: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0438, train_loss_epoch=0.0419]Epoch 127: Train Loss = 0.04381642863154411\n",
      "Epoch 128: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=115, train_loss_step=0.043, train_loss_epoch=0.0438] Epoch 128: Train Loss = 0.04303278028964996\n",
      "Epoch 129: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0433, train_loss_epoch=0.043]Epoch 129: Train Loss = 0.04325534403324127\n",
      "Epoch 130: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0407, train_loss_epoch=0.0433]Epoch 130: Train Loss = 0.04070227965712547\n",
      "Epoch 131: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0415, train_loss_epoch=0.0407]Epoch 131: Train Loss = 0.04151851311326027\n",
      "Epoch 132: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0408, train_loss_epoch=0.0415]Epoch 132: Train Loss = 0.04084239527583122\n",
      "Epoch 133: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0406, train_loss_epoch=0.0408]Epoch 133: Train Loss = 0.04060782119631767\n",
      "Epoch 134: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0412, train_loss_epoch=0.0406]Epoch 134: Train Loss = 0.041181016713380814\n",
      "Epoch 135: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0435, train_loss_epoch=0.0412]Epoch 135: Train Loss = 0.04348926991224289\n",
      "Epoch 136: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0405, train_loss_epoch=0.0435]Epoch 136: Train Loss = 0.04051479697227478\n",
      "Epoch 137: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0407, train_loss_epoch=0.0405]Epoch 137: Train Loss = 0.04070620983839035\n",
      "Epoch 138: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0395, train_loss_epoch=0.0407]Epoch 138: Train Loss = 0.03946903720498085\n",
      "Epoch 139: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.040, train_loss_epoch=0.0395] Epoch 139: Train Loss = 0.039996374398469925\n",
      "Epoch 140: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0387, train_loss_epoch=0.040]Epoch 140: Train Loss = 0.038650114089250565\n",
      "Epoch 141: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0387, train_loss_epoch=0.0387]Epoch 141: Train Loss = 0.03870972990989685\n",
      "Epoch 142: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0388, train_loss_epoch=0.0387]Epoch 142: Train Loss = 0.03877982869744301\n",
      "Epoch 143: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0401, train_loss_epoch=0.0388]Epoch 143: Train Loss = 0.04011989012360573\n",
      "Epoch 144: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0384, train_loss_epoch=0.0401]Epoch 144: Train Loss = 0.038419730961322784\n",
      "Epoch 145: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0384, train_loss_epoch=0.0384]Epoch 145: Train Loss = 0.038387637585401535\n",
      "Epoch 146: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0393, train_loss_epoch=0.0384]Epoch 146: Train Loss = 0.039289142936468124\n",
      "Epoch 147: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0387, train_loss_epoch=0.0393]Epoch 147: Train Loss = 0.03871152549982071\n",
      "Epoch 148: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0415, train_loss_epoch=0.0387]Epoch 148: Train Loss = 0.04150724783539772\n",
      "Epoch 149: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0376, train_loss_epoch=0.0415]Epoch 149: Train Loss = 0.03756839781999588\n",
      "Epoch 150: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0414, train_loss_epoch=0.0376]Epoch 150: Train Loss = 0.04140594229102135\n",
      "Epoch 151: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0378, train_loss_epoch=0.0414]Epoch 151: Train Loss = 0.037783026695251465\n",
      "Epoch 152: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.0415, train_loss_epoch=0.0378]Epoch 152: Train Loss = 0.041544556617736816\n",
      "Epoch 153: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0401, train_loss_epoch=0.0415]Epoch 153: Train Loss = 0.04008977860212326\n",
      "Epoch 154: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0433, train_loss_epoch=0.0401]Epoch 154: Train Loss = 0.04326691851019859\n",
      "Epoch 155: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0395, train_loss_epoch=0.0433]Epoch 155: Train Loss = 0.03952554613351822\n",
      "Epoch 156: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0374, train_loss_epoch=0.0395]Epoch 156: Train Loss = 0.03743695095181465\n",
      "Epoch 157: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0375, train_loss_epoch=0.0374]Epoch 157: Train Loss = 0.03748851269483566\n",
      "Epoch 158: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.036, train_loss_epoch=0.0375] Epoch 158: Train Loss = 0.03596261888742447\n",
      "Epoch 159: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0398, train_loss_epoch=0.036]Epoch 159: Train Loss = 0.039756882935762405\n",
      "Epoch 160: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0354, train_loss_epoch=0.0398]Epoch 160: Train Loss = 0.0353960357606411\n",
      "Epoch 161: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.039, train_loss_epoch=0.0354] Epoch 161: Train Loss = 0.038987599313259125\n",
      "Epoch 162: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.0353, train_loss_epoch=0.039]Epoch 162: Train Loss = 0.035270337015390396\n",
      "Epoch 163: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.038, train_loss_epoch=0.0353] Epoch 163: Train Loss = 0.037993814796209335\n",
      "Epoch 164: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.036, train_loss_epoch=0.038] Epoch 164: Train Loss = 0.03596974536776543\n",
      "Epoch 165: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0397, train_loss_epoch=0.036]Epoch 165: Train Loss = 0.039725158363580704\n",
      "Epoch 166: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0351, train_loss_epoch=0.0397]Epoch 166: Train Loss = 0.035083215683698654\n",
      "Epoch 167: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0353, train_loss_epoch=0.0351]Epoch 167: Train Loss = 0.035317983478307724\n",
      "Epoch 168: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0362, train_loss_epoch=0.0353]Epoch 168: Train Loss = 0.036159928888082504\n",
      "Epoch 169: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0349, train_loss_epoch=0.0362]Epoch 169: Train Loss = 0.03487741947174072\n",
      "Epoch 170: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0406, train_loss_epoch=0.0349]Epoch 170: Train Loss = 0.04061092808842659\n",
      "Epoch 171: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0345, train_loss_epoch=0.0406]Epoch 171: Train Loss = 0.03453441709280014\n",
      "Epoch 172: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0373, train_loss_epoch=0.0345]Epoch 172: Train Loss = 0.03732548654079437\n",
      "Epoch 173: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0368, train_loss_epoch=0.0373]Epoch 173: Train Loss = 0.036765679717063904\n",
      "Epoch 174: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0385, train_loss_epoch=0.0368]Epoch 174: Train Loss = 0.03847624361515045\n",
      "Epoch 175: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0386, train_loss_epoch=0.0385]Epoch 175: Train Loss = 0.03856872022151947\n",
      "Epoch 176: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0343, train_loss_epoch=0.0386]Epoch 176: Train Loss = 0.0343455970287323\n",
      "Epoch 177: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0363, train_loss_epoch=0.0343]Epoch 177: Train Loss = 0.03625032305717468\n",
      "Epoch 178: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0343, train_loss_epoch=0.0363]Epoch 178: Train Loss = 0.03427597135305405\n",
      "Epoch 179: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0347, train_loss_epoch=0.0343]Epoch 179: Train Loss = 0.03473423048853874\n",
      "Epoch 180: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0346, train_loss_epoch=0.0347]Epoch 180: Train Loss = 0.03464123606681824\n",
      "Epoch 181: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0351, train_loss_epoch=0.0346]Epoch 181: Train Loss = 0.035091299563646317\n",
      "Epoch 182: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.0339, train_loss_epoch=0.0351]Epoch 182: Train Loss = 0.03385210409760475\n",
      "Epoch 183: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0337, train_loss_epoch=0.0339]Epoch 183: Train Loss = 0.03366623446345329\n",
      "Epoch 184: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0336, train_loss_epoch=0.0337]Epoch 184: Train Loss = 0.033605415374040604\n",
      "Epoch 185: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0336, train_loss_epoch=0.0336]Epoch 185: Train Loss = 0.03361019119620323\n",
      "Epoch 186: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0332, train_loss_epoch=0.0336]Epoch 186: Train Loss = 0.03322242945432663\n",
      "Epoch 187: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0335, train_loss_epoch=0.0332]Epoch 187: Train Loss = 0.03353612497448921\n",
      "Epoch 188: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0329, train_loss_epoch=0.0335]Epoch 188: Train Loss = 0.032888319343328476\n",
      "Epoch 189: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0334, train_loss_epoch=0.0329]Epoch 189: Train Loss = 0.03336741030216217\n",
      "Epoch 190: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0348, train_loss_epoch=0.0334]Epoch 190: Train Loss = 0.03476020693778992\n",
      "Epoch 191: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0334, train_loss_epoch=0.0348]Epoch 191: Train Loss = 0.03340376541018486\n",
      "Epoch 192: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0327, train_loss_epoch=0.0334]Epoch 192: Train Loss = 0.03273274749517441\n",
      "Epoch 193: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0331, train_loss_epoch=0.0327]Epoch 193: Train Loss = 0.03314732760190964\n",
      "Epoch 194: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0335, train_loss_epoch=0.0331]Epoch 194: Train Loss = 0.03350644186139107\n",
      "Epoch 195: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.033, train_loss_epoch=0.0335] Epoch 195: Train Loss = 0.03299431875348091\n",
      "Epoch 196: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=115, train_loss_step=0.0331, train_loss_epoch=0.033]Epoch 196: Train Loss = 0.0330943688750267\n",
      "Epoch 197: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0322, train_loss_epoch=0.0331]Epoch 197: Train Loss = 0.03222023323178291\n",
      "Epoch 198: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0323, train_loss_epoch=0.0322]Epoch 198: Train Loss = 0.03233456239104271\n",
      "Epoch 199: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0319, train_loss_epoch=0.0323]Epoch 199: Train Loss = 0.031926535069942474\n",
      "Epoch 200: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0324, train_loss_epoch=0.0319]Epoch 200: Train Loss = 0.032398007810115814\n",
      "Epoch 201: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0314, train_loss_epoch=0.0324]Epoch 201: Train Loss = 0.0314435251057148\n",
      "Epoch 202: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0333, train_loss_epoch=0.0314]Epoch 202: Train Loss = 0.0332503467798233\n",
      "Epoch 203: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0333, train_loss_epoch=0.0333]Epoch 203: Train Loss = 0.033260270953178406\n",
      "Epoch 204: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0356, train_loss_epoch=0.0333]Epoch 204: Train Loss = 0.03563391789793968\n",
      "Epoch 205: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0319, train_loss_epoch=0.0356]Epoch 205: Train Loss = 0.031935516744852066\n",
      "Epoch 206: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0331, train_loss_epoch=0.0319]Epoch 206: Train Loss = 0.03311379253864288\n",
      "Epoch 207: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0331, train_loss_epoch=0.0331]Epoch 207: Train Loss = 0.033077701926231384\n",
      "Epoch 208: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0336, train_loss_epoch=0.0331]Epoch 208: Train Loss = 0.03355860337615013\n",
      "Epoch 209: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0346, train_loss_epoch=0.0336]Epoch 209: Train Loss = 0.03461434319615364\n",
      "Epoch 210: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0373, train_loss_epoch=0.0346]Epoch 210: Train Loss = 0.03734511137008667\n",
      "Epoch 211: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0348, train_loss_epoch=0.0373]Epoch 211: Train Loss = 0.034758761525154114\n",
      "Epoch 212: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0376, train_loss_epoch=0.0348]Epoch 212: Train Loss = 0.037557199597358704\n",
      "Epoch 213: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0348, train_loss_epoch=0.0376]Epoch 213: Train Loss = 0.03477479889988899\n",
      "Epoch 214: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0325, train_loss_epoch=0.0348]Epoch 214: Train Loss = 0.03245069831609726\n",
      "Epoch 215: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.040, train_loss_epoch=0.0325] Epoch 215: Train Loss = 0.03998534008860588\n",
      "Epoch 216: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0302, train_loss_epoch=0.040]Epoch 216: Train Loss = 0.03021061420440674\n",
      "Epoch 217: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0373, train_loss_epoch=0.0302]Epoch 217: Train Loss = 0.03725287318229675\n",
      "Epoch 218: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0315, train_loss_epoch=0.0373]Epoch 218: Train Loss = 0.03151502460241318\n",
      "Epoch 219: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0327, train_loss_epoch=0.0315]Epoch 219: Train Loss = 0.03267766907811165\n",
      "Epoch 220: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0342, train_loss_epoch=0.0327]Epoch 220: Train Loss = 0.034207895398139954\n",
      "Epoch 221: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0314, train_loss_epoch=0.0342]Epoch 221: Train Loss = 0.031396083533763885\n",
      "Epoch 222: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0357, train_loss_epoch=0.0314]Epoch 222: Train Loss = 0.035738762468099594\n",
      "Epoch 223: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=115, train_loss_step=0.0307, train_loss_epoch=0.0357]Epoch 223: Train Loss = 0.030704107135534286\n",
      "Epoch 224: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0351, train_loss_epoch=0.0307]Epoch 224: Train Loss = 0.035130780190229416\n",
      "Epoch 225: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0312, train_loss_epoch=0.0351]Epoch 225: Train Loss = 0.031201807782053947\n",
      "Epoch 226: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0319, train_loss_epoch=0.0312]Epoch 226: Train Loss = 0.03189143165946007\n",
      "Epoch 227: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0351, train_loss_epoch=0.0319]Epoch 227: Train Loss = 0.03509495407342911\n",
      "Epoch 228: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0325, train_loss_epoch=0.0351]Epoch 228: Train Loss = 0.03247438743710518\n",
      "Epoch 229: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0345, train_loss_epoch=0.0325]Epoch 229: Train Loss = 0.034457746893167496\n",
      "Epoch 230: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0307, train_loss_epoch=0.0345]Epoch 230: Train Loss = 0.030676189810037613\n",
      "Epoch 231: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0449, train_loss_epoch=0.0307]Epoch 231: Train Loss = 0.0448734387755394\n",
      "Epoch 232: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0316, train_loss_epoch=0.0449]Epoch 232: Train Loss = 0.031630177050828934\n",
      "Epoch 233: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0348, train_loss_epoch=0.0316]Epoch 233: Train Loss = 0.034771859645843506\n",
      "Epoch 234: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.0378, train_loss_epoch=0.0348]Epoch 234: Train Loss = 0.037753280252218246\n",
      "Epoch 235: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0335, train_loss_epoch=0.0378]Epoch 235: Train Loss = 0.03351600095629692\n",
      "Epoch 236: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0346, train_loss_epoch=0.0335]Epoch 236: Train Loss = 0.03461088612675667\n",
      "Epoch 237: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=115, train_loss_step=0.030, train_loss_epoch=0.0346] Epoch 237: Train Loss = 0.03001369722187519\n",
      "Epoch 238: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0322, train_loss_epoch=0.030]Epoch 238: Train Loss = 0.03219687566161156\n",
      "Epoch 239: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0297, train_loss_epoch=0.0322]Epoch 239: Train Loss = 0.029701892286539078\n",
      "Epoch 240: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0294, train_loss_epoch=0.0297]Epoch 240: Train Loss = 0.029433947056531906\n",
      "Epoch 241: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0302, train_loss_epoch=0.0294]Epoch 241: Train Loss = 0.03017592616379261\n",
      "Epoch 242: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0303, train_loss_epoch=0.0302]Epoch 242: Train Loss = 0.03029732219874859\n",
      "Epoch 243: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=115, train_loss_step=0.0316, train_loss_epoch=0.0303]Epoch 243: Train Loss = 0.03161805495619774\n",
      "Epoch 244: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0304, train_loss_epoch=0.0316]Epoch 244: Train Loss = 0.030442964285612106\n",
      "Epoch 245: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=115, train_loss_step=0.0295, train_loss_epoch=0.0304]Epoch 245: Train Loss = 0.029469083994627\n",
      "Epoch 246: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0313, train_loss_epoch=0.0295]Epoch 246: Train Loss = 0.03126899525523186\n",
      "Epoch 247: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0311, train_loss_epoch=0.0313]Epoch 247: Train Loss = 0.031107723712921143\n",
      "Epoch 248: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0333, train_loss_epoch=0.0311]Epoch 248: Train Loss = 0.03331679478287697\n",
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0298, train_loss_epoch=0.0333]Epoch 249: Train Loss = 0.02984078973531723\n",
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0298, train_loss_epoch=0.0298]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=115, train_loss_step=0.0298, train_loss_epoch=0.0298]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.70it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 2: from 1998-11-02 00:00:00 to 2022-01-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.396]Epoch 0: Train Loss = 0.3956851065158844\n",
      "Epoch 1: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.496, train_loss_epoch=0.396]Epoch 1: Train Loss = 0.4958781898021698\n",
      "Epoch 2: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.370, train_loss_epoch=0.496]Epoch 2: Train Loss = 0.37030354142189026\n",
      "Epoch 3: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.249, train_loss_epoch=0.370]Epoch 3: Train Loss = 0.24887946248054504\n",
      "Epoch 4: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.307, train_loss_epoch=0.249]Epoch 4: Train Loss = 0.30720949172973633\n",
      "Epoch 5: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.310, train_loss_epoch=0.307]Epoch 5: Train Loss = 0.31010866165161133\n",
      "Epoch 6: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.255, train_loss_epoch=0.310]Epoch 6: Train Loss = 0.25528016686439514\n",
      "Epoch 7: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.243, train_loss_epoch=0.255]Epoch 7: Train Loss = 0.2434173822402954\n",
      "Epoch 8: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.267, train_loss_epoch=0.243]Epoch 8: Train Loss = 0.2666409909725189\n",
      "Epoch 9: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.259, train_loss_epoch=0.267]Epoch 9: Train Loss = 0.25910085439682007\n",
      "Epoch 10: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=131, train_loss_step=0.238, train_loss_epoch=0.259]Epoch 10: Train Loss = 0.23789648711681366\n",
      "Epoch 11: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.220, train_loss_epoch=0.238]Epoch 11: Train Loss = 0.21965724229812622\n",
      "Epoch 12: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.237, train_loss_epoch=0.220]Epoch 12: Train Loss = 0.23706866800785065\n",
      "Epoch 13: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.221, train_loss_epoch=0.237]Epoch 13: Train Loss = 0.22087407112121582\n",
      "Epoch 14: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.209, train_loss_epoch=0.221]Epoch 14: Train Loss = 0.20907378196716309\n",
      "Epoch 15: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.187, train_loss_epoch=0.209]Epoch 15: Train Loss = 0.18716630339622498\n",
      "Epoch 16: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.199, train_loss_epoch=0.187]Epoch 16: Train Loss = 0.19873617589473724\n",
      "Epoch 17: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.189, train_loss_epoch=0.199]Epoch 17: Train Loss = 0.18949975073337555\n",
      "Epoch 18: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.196, train_loss_epoch=0.189]Epoch 18: Train Loss = 0.1960601806640625\n",
      "Epoch 19: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.173, train_loss_epoch=0.196]Epoch 19: Train Loss = 0.17254967987537384\n",
      "Epoch 20: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.168, train_loss_epoch=0.173]Epoch 20: Train Loss = 0.16764459013938904\n",
      "Epoch 21: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.183, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.1830124706029892\n",
      "Epoch 22: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.176, train_loss_epoch=0.183]Epoch 22: Train Loss = 0.17609284818172455\n",
      "Epoch 23: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.161, train_loss_epoch=0.176]Epoch 23: Train Loss = 0.16095001995563507\n",
      "Epoch 24: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.154, train_loss_epoch=0.161]Epoch 24: Train Loss = 0.15433776378631592\n",
      "Epoch 25: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.158, train_loss_epoch=0.154]Epoch 25: Train Loss = 0.1578383445739746\n",
      "Epoch 26: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.161, train_loss_epoch=0.158]Epoch 26: Train Loss = 0.16130775213241577\n",
      "Epoch 27: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.151, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.15118615329265594\n",
      "Epoch 28: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.143, train_loss_epoch=0.151]Epoch 28: Train Loss = 0.14255666732788086\n",
      "Epoch 29: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.148, train_loss_epoch=0.143]Epoch 29: Train Loss = 0.14825735986232758\n",
      "Epoch 30: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.140, train_loss_epoch=0.148]Epoch 30: Train Loss = 0.14039668440818787\n",
      "Epoch 31: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.140, train_loss_epoch=0.140]Epoch 31: Train Loss = 0.1397697478532791\n",
      "Epoch 32: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.139, train_loss_epoch=0.140]Epoch 32: Train Loss = 0.13879238069057465\n",
      "Epoch 33: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.133, train_loss_epoch=0.139]Epoch 33: Train Loss = 0.13321155309677124\n",
      "Epoch 34: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=131, train_loss_step=0.133, train_loss_epoch=0.133]Epoch 34: Train Loss = 0.13271309435367584\n",
      "Epoch 35: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.131, train_loss_epoch=0.133]Epoch 35: Train Loss = 0.13138820230960846\n",
      "Epoch 36: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.127, train_loss_epoch=0.131]Epoch 36: Train Loss = 0.1274505853652954\n",
      "Epoch 37: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.126, train_loss_epoch=0.127]Epoch 37: Train Loss = 0.12608090043067932\n",
      "Epoch 38: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.122, train_loss_epoch=0.126]Epoch 38: Train Loss = 0.12221240997314453\n",
      "Epoch 39: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=131, train_loss_step=0.118, train_loss_epoch=0.122]Epoch 39: Train Loss = 0.11833500862121582\n",
      "Epoch 40: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=131, train_loss_step=0.115, train_loss_epoch=0.118]Epoch 40: Train Loss = 0.11494871228933334\n",
      "Epoch 41: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=131, train_loss_step=0.118, train_loss_epoch=0.115]Epoch 41: Train Loss = 0.11784350126981735\n",
      "Epoch 42: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.113, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.11298179626464844\n",
      "Epoch 43: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.108, train_loss_epoch=0.113]Epoch 43: Train Loss = 0.10751017183065414\n",
      "Epoch 44: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.112, train_loss_epoch=0.108]Epoch 44: Train Loss = 0.11196166276931763\n",
      "Epoch 45: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=131, train_loss_step=0.107, train_loss_epoch=0.112]Epoch 45: Train Loss = 0.10681488364934921\n",
      "Epoch 46: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.105, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10533895343542099\n",
      "Epoch 47: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.102, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10161503404378891\n",
      "Epoch 48: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.103, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.10284852981567383\n",
      "Epoch 49: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.100, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.10037324577569962\n",
      "Epoch 50: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=131, train_loss_step=0.0981, train_loss_epoch=0.100]Epoch 50: Train Loss = 0.09811726957559586\n",
      "Epoch 51: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0975, train_loss_epoch=0.0981]Epoch 51: Train Loss = 0.09753552824258804\n",
      "Epoch 52: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0961, train_loss_epoch=0.0975]Epoch 52: Train Loss = 0.09605053812265396\n",
      "Epoch 53: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0938, train_loss_epoch=0.0961]Epoch 53: Train Loss = 0.09375905990600586\n",
      "Epoch 54: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0921, train_loss_epoch=0.0938]Epoch 54: Train Loss = 0.09212587028741837\n",
      "Epoch 55: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0916, train_loss_epoch=0.0921]Epoch 55: Train Loss = 0.09164564311504364\n",
      "Epoch 56: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0897, train_loss_epoch=0.0916]Epoch 56: Train Loss = 0.08965268731117249\n",
      "Epoch 57: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0854, train_loss_epoch=0.0897]Epoch 57: Train Loss = 0.08542928099632263\n",
      "Epoch 58: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.087, train_loss_epoch=0.0854] Epoch 58: Train Loss = 0.0870383158326149\n",
      "Epoch 59: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0836, train_loss_epoch=0.087]Epoch 59: Train Loss = 0.08362375199794769\n",
      "Epoch 60: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0839, train_loss_epoch=0.0836]Epoch 60: Train Loss = 0.08391641080379486\n",
      "Epoch 61: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0809, train_loss_epoch=0.0839]Epoch 61: Train Loss = 0.08094984292984009\n",
      "Epoch 62: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0792, train_loss_epoch=0.0809]Epoch 62: Train Loss = 0.07923755049705505\n",
      "Epoch 63: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0813, train_loss_epoch=0.0792]Epoch 63: Train Loss = 0.0812913030385971\n",
      "Epoch 64: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0771, train_loss_epoch=0.0813]Epoch 64: Train Loss = 0.0771477222442627\n",
      "Epoch 65: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0803, train_loss_epoch=0.0771]Epoch 65: Train Loss = 0.08034002780914307\n",
      "Epoch 66: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0769, train_loss_epoch=0.0803]Epoch 66: Train Loss = 0.07691797614097595\n",
      "Epoch 67: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0755, train_loss_epoch=0.0769]Epoch 67: Train Loss = 0.07547777146100998\n",
      "Epoch 68: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.074, train_loss_epoch=0.0755] Epoch 68: Train Loss = 0.0739593654870987\n",
      "Epoch 69: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.0725, train_loss_epoch=0.074]Epoch 69: Train Loss = 0.07248357683420181\n",
      "Epoch 70: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0713, train_loss_epoch=0.0725]Epoch 70: Train Loss = 0.07134052366018295\n",
      "Epoch 71: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0701, train_loss_epoch=0.0713]Epoch 71: Train Loss = 0.0700528547167778\n",
      "Epoch 72: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0689, train_loss_epoch=0.0701]Epoch 72: Train Loss = 0.06886766105890274\n",
      "Epoch 73: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0677, train_loss_epoch=0.0689]Epoch 73: Train Loss = 0.06771495938301086\n",
      "Epoch 74: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0688, train_loss_epoch=0.0677]Epoch 74: Train Loss = 0.06876572221517563\n",
      "Epoch 75: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0659, train_loss_epoch=0.0688]Epoch 75: Train Loss = 0.0659099891781807\n",
      "Epoch 76: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0664, train_loss_epoch=0.0659]Epoch 76: Train Loss = 0.06641320139169693\n",
      "Epoch 77: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0659, train_loss_epoch=0.0664]Epoch 77: Train Loss = 0.06589587032794952\n",
      "Epoch 78: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0653, train_loss_epoch=0.0659]Epoch 78: Train Loss = 0.06532453000545502\n",
      "Epoch 79: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0626, train_loss_epoch=0.0653]Epoch 79: Train Loss = 0.0626116618514061\n",
      "Epoch 80: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.064, train_loss_epoch=0.0626] Epoch 80: Train Loss = 0.06402749568223953\n",
      "Epoch 81: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0611, train_loss_epoch=0.064]Epoch 81: Train Loss = 0.06113129481673241\n",
      "Epoch 82: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0625, train_loss_epoch=0.0611]Epoch 82: Train Loss = 0.0624542310833931\n",
      "Epoch 83: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0603, train_loss_epoch=0.0625]Epoch 83: Train Loss = 0.060313913971185684\n",
      "Epoch 84: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0611, train_loss_epoch=0.0603]Epoch 84: Train Loss = 0.06107684597373009\n",
      "Epoch 85: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0589, train_loss_epoch=0.0611]Epoch 85: Train Loss = 0.05885753035545349\n",
      "Epoch 86: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0578, train_loss_epoch=0.0589]Epoch 86: Train Loss = 0.057814374566078186\n",
      "Epoch 87: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.062, train_loss_epoch=0.0578] Epoch 87: Train Loss = 0.061982519924640656\n",
      "Epoch 88: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0578, train_loss_epoch=0.062]Epoch 88: Train Loss = 0.057820986956357956\n",
      "Epoch 89: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0605, train_loss_epoch=0.0578]Epoch 89: Train Loss = 0.06046680361032486\n",
      "Epoch 90: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0576, train_loss_epoch=0.0605]Epoch 90: Train Loss = 0.05764957517385483\n",
      "Epoch 91: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0598, train_loss_epoch=0.0576]Epoch 91: Train Loss = 0.05976315960288048\n",
      "Epoch 92: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0582, train_loss_epoch=0.0598]Epoch 92: Train Loss = 0.058229316025972366\n",
      "Epoch 93: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0537, train_loss_epoch=0.0582]Epoch 93: Train Loss = 0.05365365371108055\n",
      "Epoch 94: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.054, train_loss_epoch=0.0537] Epoch 94: Train Loss = 0.05404047295451164\n",
      "Epoch 95: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0535, train_loss_epoch=0.054]Epoch 95: Train Loss = 0.05353614315390587\n",
      "Epoch 96: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0534, train_loss_epoch=0.0535]Epoch 96: Train Loss = 0.05342255160212517\n",
      "Epoch 97: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0572, train_loss_epoch=0.0534]Epoch 97: Train Loss = 0.05724659189581871\n",
      "Epoch 98: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0527, train_loss_epoch=0.0572]Epoch 98: Train Loss = 0.05271881818771362\n",
      "Epoch 99: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0604, train_loss_epoch=0.0527]Epoch 99: Train Loss = 0.0603664331138134\n",
      "Epoch 100: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0501, train_loss_epoch=0.0604]Epoch 100: Train Loss = 0.05014318600296974\n",
      "Epoch 101: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0579, train_loss_epoch=0.0501]Epoch 101: Train Loss = 0.057858265936374664\n",
      "Epoch 102: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0497, train_loss_epoch=0.0579]Epoch 102: Train Loss = 0.04970453679561615\n",
      "Epoch 103: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0517, train_loss_epoch=0.0497]Epoch 103: Train Loss = 0.051699455827474594\n",
      "Epoch 104: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.051, train_loss_epoch=0.0517] Epoch 104: Train Loss = 0.05096771568059921\n",
      "Epoch 105: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.050, train_loss_epoch=0.051] Epoch 105: Train Loss = 0.04997584968805313\n",
      "Epoch 106: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0513, train_loss_epoch=0.050]Epoch 106: Train Loss = 0.05126666650176048\n",
      "Epoch 107: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0482, train_loss_epoch=0.0513]Epoch 107: Train Loss = 0.04822178930044174\n",
      "Epoch 108: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.054, train_loss_epoch=0.0482] Epoch 108: Train Loss = 0.05402644723653793\n",
      "Epoch 109: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.049, train_loss_epoch=0.054] Epoch 109: Train Loss = 0.04904480651021004\n",
      "Epoch 110: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0533, train_loss_epoch=0.049]Epoch 110: Train Loss = 0.0532502681016922\n",
      "Epoch 111: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0507, train_loss_epoch=0.0533]Epoch 111: Train Loss = 0.05065414309501648\n",
      "Epoch 112: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0504, train_loss_epoch=0.0507]Epoch 112: Train Loss = 0.05035506933927536\n",
      "Epoch 113: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0515, train_loss_epoch=0.0504]Epoch 113: Train Loss = 0.05149540677666664\n",
      "Epoch 114: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0467, train_loss_epoch=0.0515]Epoch 114: Train Loss = 0.04668156057596207\n",
      "Epoch 115: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0545, train_loss_epoch=0.0467]Epoch 115: Train Loss = 0.05449511483311653\n",
      "Epoch 116: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0461, train_loss_epoch=0.0545]Epoch 116: Train Loss = 0.04609847813844681\n",
      "Epoch 117: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0478, train_loss_epoch=0.0461]Epoch 117: Train Loss = 0.04780469834804535\n",
      "Epoch 118: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0443, train_loss_epoch=0.0478]Epoch 118: Train Loss = 0.044273752719163895\n",
      "Epoch 119: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0454, train_loss_epoch=0.0443]Epoch 119: Train Loss = 0.045393262058496475\n",
      "Epoch 120: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0445, train_loss_epoch=0.0454]Epoch 120: Train Loss = 0.044529110193252563\n",
      "Epoch 121: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0454, train_loss_epoch=0.0445]Epoch 121: Train Loss = 0.04544747620820999\n",
      "Epoch 122: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0452, train_loss_epoch=0.0454]Epoch 122: Train Loss = 0.04516255483031273\n",
      "Epoch 123: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0438, train_loss_epoch=0.0452]Epoch 123: Train Loss = 0.043806761503219604\n",
      "Epoch 124: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0441, train_loss_epoch=0.0438]Epoch 124: Train Loss = 0.04411301761865616\n",
      "Epoch 125: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0434, train_loss_epoch=0.0441]Epoch 125: Train Loss = 0.04337873309850693\n",
      "Epoch 126: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0435, train_loss_epoch=0.0434]Epoch 126: Train Loss = 0.043501537293195724\n",
      "Epoch 127: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0448, train_loss_epoch=0.0435]Epoch 127: Train Loss = 0.044763218611478806\n",
      "Epoch 128: 100%|██████████| 1/1 [00:03<00:00,  0.32it/s, v_num=131, train_loss_step=0.0431, train_loss_epoch=0.0448]Epoch 128: Train Loss = 0.043080251663923264\n",
      "Epoch 129: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0428, train_loss_epoch=0.0431]Epoch 129: Train Loss = 0.042791612446308136\n",
      "Epoch 130: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0416, train_loss_epoch=0.0428]Epoch 130: Train Loss = 0.04156222566962242\n",
      "Epoch 131: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0412, train_loss_epoch=0.0416]Epoch 131: Train Loss = 0.04116479679942131\n",
      "Epoch 132: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0438, train_loss_epoch=0.0412]Epoch 132: Train Loss = 0.04383086413145065\n",
      "Epoch 133: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0409, train_loss_epoch=0.0438]Epoch 133: Train Loss = 0.04092429205775261\n",
      "Epoch 134: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0462, train_loss_epoch=0.0409]Epoch 134: Train Loss = 0.046206697821617126\n",
      "Epoch 135: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0409, train_loss_epoch=0.0462]Epoch 135: Train Loss = 0.04090539366006851\n",
      "Epoch 136: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0406, train_loss_epoch=0.0409]Epoch 136: Train Loss = 0.04063272848725319\n",
      "Epoch 137: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0452, train_loss_epoch=0.0406]Epoch 137: Train Loss = 0.04515570029616356\n",
      "Epoch 138: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0403, train_loss_epoch=0.0452]Epoch 138: Train Loss = 0.04025670513510704\n",
      "Epoch 139: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0424, train_loss_epoch=0.0403]Epoch 139: Train Loss = 0.042418092489242554\n",
      "Epoch 140: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0406, train_loss_epoch=0.0424]Epoch 140: Train Loss = 0.04062977805733681\n",
      "Epoch 141: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.0394, train_loss_epoch=0.0406]Epoch 141: Train Loss = 0.03940987214446068\n",
      "Epoch 142: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0413, train_loss_epoch=0.0394]Epoch 142: Train Loss = 0.04126168042421341\n",
      "Epoch 143: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0396, train_loss_epoch=0.0413]Epoch 143: Train Loss = 0.03957107663154602\n",
      "Epoch 144: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0397, train_loss_epoch=0.0396]Epoch 144: Train Loss = 0.039655059576034546\n",
      "Epoch 145: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0399, train_loss_epoch=0.0397]Epoch 145: Train Loss = 0.03985859081149101\n",
      "Epoch 146: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0407, train_loss_epoch=0.0399]Epoch 146: Train Loss = 0.040670644491910934\n",
      "Epoch 147: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0382, train_loss_epoch=0.0407]Epoch 147: Train Loss = 0.0382167287170887\n",
      "Epoch 148: 100%|██████████| 1/1 [00:03<00:00,  0.32it/s, v_num=131, train_loss_step=0.0392, train_loss_epoch=0.0382]Epoch 148: Train Loss = 0.03923456743359566\n",
      "Epoch 149: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0387, train_loss_epoch=0.0392]Epoch 149: Train Loss = 0.038661208003759384\n",
      "Epoch 150: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0378, train_loss_epoch=0.0387]Epoch 150: Train Loss = 0.037757501006126404\n",
      "Epoch 151: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0383, train_loss_epoch=0.0378]Epoch 151: Train Loss = 0.03832791745662689\n",
      "Epoch 152: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0371, train_loss_epoch=0.0383]Epoch 152: Train Loss = 0.0371367409825325\n",
      "Epoch 153: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0382, train_loss_epoch=0.0371]Epoch 153: Train Loss = 0.03824692219495773\n",
      "Epoch 154: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0419, train_loss_epoch=0.0382]Epoch 154: Train Loss = 0.04190022498369217\n",
      "Epoch 155: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0383, train_loss_epoch=0.0419]Epoch 155: Train Loss = 0.03829294815659523\n",
      "Epoch 156: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.041, train_loss_epoch=0.0383] Epoch 156: Train Loss = 0.04097685590386391\n",
      "Epoch 157: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0383, train_loss_epoch=0.041]Epoch 157: Train Loss = 0.038276977837085724\n",
      "Epoch 158: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0392, train_loss_epoch=0.0383]Epoch 158: Train Loss = 0.039165183901786804\n",
      "Epoch 159: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0373, train_loss_epoch=0.0392]Epoch 159: Train Loss = 0.03728342801332474\n",
      "Epoch 160: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0367, train_loss_epoch=0.0373]Epoch 160: Train Loss = 0.03669564798474312\n",
      "Epoch 161: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0364, train_loss_epoch=0.0367]Epoch 161: Train Loss = 0.03641302138566971\n",
      "Epoch 162: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0362, train_loss_epoch=0.0364]Epoch 162: Train Loss = 0.03615816682577133\n",
      "Epoch 163: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.037, train_loss_epoch=0.0362] Epoch 163: Train Loss = 0.03700883314013481\n",
      "Epoch 164: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0361, train_loss_epoch=0.037]Epoch 164: Train Loss = 0.036146216094493866\n",
      "Epoch 165: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0362, train_loss_epoch=0.0361]Epoch 165: Train Loss = 0.03616892173886299\n",
      "Epoch 166: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0351, train_loss_epoch=0.0362]Epoch 166: Train Loss = 0.0350913442671299\n",
      "Epoch 167: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0348, train_loss_epoch=0.0351]Epoch 167: Train Loss = 0.03475400060415268\n",
      "Epoch 168: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0356, train_loss_epoch=0.0348]Epoch 168: Train Loss = 0.03556222841143608\n",
      "Epoch 169: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0357, train_loss_epoch=0.0356]Epoch 169: Train Loss = 0.03567902743816376\n",
      "Epoch 170: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0351, train_loss_epoch=0.0357]Epoch 170: Train Loss = 0.035097505897283554\n",
      "Epoch 171: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0357, train_loss_epoch=0.0351]Epoch 171: Train Loss = 0.03569293022155762\n",
      "Epoch 172: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.0345, train_loss_epoch=0.0357]Epoch 172: Train Loss = 0.03452949598431587\n",
      "Epoch 173: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0349, train_loss_epoch=0.0345]Epoch 173: Train Loss = 0.034871432930231094\n",
      "Epoch 174: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0342, train_loss_epoch=0.0349]Epoch 174: Train Loss = 0.034205224364995956\n",
      "Epoch 175: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0366, train_loss_epoch=0.0342]Epoch 175: Train Loss = 0.036555975675582886\n",
      "Epoch 176: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0347, train_loss_epoch=0.0366]Epoch 176: Train Loss = 0.03471096605062485\n",
      "Epoch 177: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0345, train_loss_epoch=0.0347]Epoch 177: Train Loss = 0.03454718366265297\n",
      "Epoch 178: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=131, train_loss_step=0.0345, train_loss_epoch=0.0345]Epoch 178: Train Loss = 0.03448239341378212\n",
      "Epoch 179: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0401, train_loss_epoch=0.0345]Epoch 179: Train Loss = 0.04011489450931549\n",
      "Epoch 180: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0364, train_loss_epoch=0.0401]Epoch 180: Train Loss = 0.03637785091996193\n",
      "Epoch 181: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0359, train_loss_epoch=0.0364]Epoch 181: Train Loss = 0.03587298467755318\n",
      "Epoch 182: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0341, train_loss_epoch=0.0359]Epoch 182: Train Loss = 0.034120213240385056\n",
      "Epoch 183: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0405, train_loss_epoch=0.0341]Epoch 183: Train Loss = 0.04048344865441322\n",
      "Epoch 184: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0337, train_loss_epoch=0.0405]Epoch 184: Train Loss = 0.03369599208235741\n",
      "Epoch 185: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0348, train_loss_epoch=0.0337]Epoch 185: Train Loss = 0.03484939783811569\n",
      "Epoch 186: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0341, train_loss_epoch=0.0348]Epoch 186: Train Loss = 0.034077249467372894\n",
      "Epoch 187: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0356, train_loss_epoch=0.0341]Epoch 187: Train Loss = 0.035609833896160126\n",
      "Epoch 188: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0328, train_loss_epoch=0.0356]Epoch 188: Train Loss = 0.03275415673851967\n",
      "Epoch 189: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.035, train_loss_epoch=0.0328] Epoch 189: Train Loss = 0.0349942147731781\n",
      "Epoch 190: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.034, train_loss_epoch=0.035] Epoch 190: Train Loss = 0.03401244059205055\n",
      "Epoch 191: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0417, train_loss_epoch=0.034]Epoch 191: Train Loss = 0.041732046753168106\n",
      "Epoch 192: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0345, train_loss_epoch=0.0417]Epoch 192: Train Loss = 0.034515008330345154\n",
      "Epoch 193: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0415, train_loss_epoch=0.0345]Epoch 193: Train Loss = 0.04147475212812424\n",
      "Epoch 194: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0379, train_loss_epoch=0.0415]Epoch 194: Train Loss = 0.03787696361541748\n",
      "Epoch 195: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0363, train_loss_epoch=0.0379]Epoch 195: Train Loss = 0.03630226477980614\n",
      "Epoch 196: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0451, train_loss_epoch=0.0363]Epoch 196: Train Loss = 0.04512043669819832\n",
      "Epoch 197: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0332, train_loss_epoch=0.0451]Epoch 197: Train Loss = 0.03315208852291107\n",
      "Epoch 198: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0384, train_loss_epoch=0.0332]Epoch 198: Train Loss = 0.03838111087679863\n",
      "Epoch 199: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0328, train_loss_epoch=0.0384]Epoch 199: Train Loss = 0.03278649225831032\n",
      "Epoch 200: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0361, train_loss_epoch=0.0328]Epoch 200: Train Loss = 0.036109864711761475\n",
      "Epoch 201: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0339, train_loss_epoch=0.0361]Epoch 201: Train Loss = 0.03394488990306854\n",
      "Epoch 202: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0363, train_loss_epoch=0.0339]Epoch 202: Train Loss = 0.036254316568374634\n",
      "Epoch 203: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0372, train_loss_epoch=0.0363]Epoch 203: Train Loss = 0.037177834659814835\n",
      "Epoch 204: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0348, train_loss_epoch=0.0372]Epoch 204: Train Loss = 0.03480716422200203\n",
      "Epoch 205: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0353, train_loss_epoch=0.0348]Epoch 205: Train Loss = 0.035306282341480255\n",
      "Epoch 206: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0315, train_loss_epoch=0.0353]Epoch 206: Train Loss = 0.03147117793560028\n",
      "Epoch 207: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0331, train_loss_epoch=0.0315]Epoch 207: Train Loss = 0.03305922448635101\n",
      "Epoch 208: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0355, train_loss_epoch=0.0331]Epoch 208: Train Loss = 0.035469911992549896\n",
      "Epoch 209: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0347, train_loss_epoch=0.0355]Epoch 209: Train Loss = 0.034704580903053284\n",
      "Epoch 210: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0321, train_loss_epoch=0.0347]Epoch 210: Train Loss = 0.03205475956201553\n",
      "Epoch 211: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0314, train_loss_epoch=0.0321]Epoch 211: Train Loss = 0.03136724233627319\n",
      "Epoch 212: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0319, train_loss_epoch=0.0314]Epoch 212: Train Loss = 0.03191497176885605\n",
      "Epoch 213: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0311, train_loss_epoch=0.0319]Epoch 213: Train Loss = 0.0310919638723135\n",
      "Epoch 214: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0318, train_loss_epoch=0.0311]Epoch 214: Train Loss = 0.03175092488527298\n",
      "Epoch 215: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0329, train_loss_epoch=0.0318]Epoch 215: Train Loss = 0.03290151059627533\n",
      "Epoch 216: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0313, train_loss_epoch=0.0329]Epoch 216: Train Loss = 0.03132380545139313\n",
      "Epoch 217: 100%|██████████| 1/1 [00:03<00:00,  0.32it/s, v_num=131, train_loss_step=0.0314, train_loss_epoch=0.0313]Epoch 217: Train Loss = 0.03135879337787628\n",
      "Epoch 218: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0321, train_loss_epoch=0.0314]Epoch 218: Train Loss = 0.03206866607069969\n",
      "Epoch 219: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.031, train_loss_epoch=0.0321] Epoch 219: Train Loss = 0.03097100928425789\n",
      "Epoch 220: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0316, train_loss_epoch=0.031]Epoch 220: Train Loss = 0.03161688148975372\n",
      "Epoch 221: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.031, train_loss_epoch=0.0316] Epoch 221: Train Loss = 0.030986754223704338\n",
      "Epoch 222: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0309, train_loss_epoch=0.031]Epoch 222: Train Loss = 0.03087332472205162\n",
      "Epoch 223: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0324, train_loss_epoch=0.0309]Epoch 223: Train Loss = 0.032405316829681396\n",
      "Epoch 224: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0312, train_loss_epoch=0.0324]Epoch 224: Train Loss = 0.031157759949564934\n",
      "Epoch 225: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0313, train_loss_epoch=0.0312]Epoch 225: Train Loss = 0.03129110485315323\n",
      "Epoch 226: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0303, train_loss_epoch=0.0313]Epoch 226: Train Loss = 0.030289778485894203\n",
      "Epoch 227: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0306, train_loss_epoch=0.0303]Epoch 227: Train Loss = 0.030645225197076797\n",
      "Epoch 228: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0317, train_loss_epoch=0.0306]Epoch 228: Train Loss = 0.03170587867498398\n",
      "Epoch 229: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.031, train_loss_epoch=0.0317] Epoch 229: Train Loss = 0.03096085600554943\n",
      "Epoch 230: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0298, train_loss_epoch=0.031]Epoch 230: Train Loss = 0.02976478822529316\n",
      "Epoch 231: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0326, train_loss_epoch=0.0298]Epoch 231: Train Loss = 0.03262520208954811\n",
      "Epoch 232: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0312, train_loss_epoch=0.0326]Epoch 232: Train Loss = 0.03121863305568695\n",
      "Epoch 233: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0336, train_loss_epoch=0.0312]Epoch 233: Train Loss = 0.03357008099555969\n",
      "Epoch 234: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0317, train_loss_epoch=0.0336]Epoch 234: Train Loss = 0.031651806086301804\n",
      "Epoch 235: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0315, train_loss_epoch=0.0317]Epoch 235: Train Loss = 0.03153690695762634\n",
      "Epoch 236: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0329, train_loss_epoch=0.0315]Epoch 236: Train Loss = 0.03292318433523178\n",
      "Epoch 237: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0298, train_loss_epoch=0.0329]Epoch 237: Train Loss = 0.029824621975421906\n",
      "Epoch 238: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0327, train_loss_epoch=0.0298]Epoch 238: Train Loss = 0.03266775980591774\n",
      "Epoch 239: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0307, train_loss_epoch=0.0327]Epoch 239: Train Loss = 0.03069966472685337\n",
      "Epoch 240: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0324, train_loss_epoch=0.0307]Epoch 240: Train Loss = 0.0323869064450264\n",
      "Epoch 241: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0333, train_loss_epoch=0.0324]Epoch 241: Train Loss = 0.0332677997648716\n",
      "Epoch 242: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=131, train_loss_step=0.0349, train_loss_epoch=0.0333]Epoch 242: Train Loss = 0.03487898036837578\n",
      "Epoch 243: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0334, train_loss_epoch=0.0349]Epoch 243: Train Loss = 0.033395279198884964\n",
      "Epoch 244: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.032, train_loss_epoch=0.0334] Epoch 244: Train Loss = 0.03201359882950783\n",
      "Epoch 245: 100%|██████████| 1/1 [00:03<00:00,  0.32it/s, v_num=131, train_loss_step=0.0355, train_loss_epoch=0.032]Epoch 245: Train Loss = 0.03554359823465347\n",
      "Epoch 246: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0302, train_loss_epoch=0.0355]Epoch 246: Train Loss = 0.030191943049430847\n",
      "Epoch 247: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=131, train_loss_step=0.0327, train_loss_epoch=0.0302]Epoch 247: Train Loss = 0.03274979069828987\n",
      "Epoch 248: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=131, train_loss_step=0.0301, train_loss_epoch=0.0327]Epoch 248: Train Loss = 0.030055809766054153\n",
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0351, train_loss_epoch=0.0301]Epoch 249: Train Loss = 0.03514731675386429\n",
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0351, train_loss_epoch=0.0351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=131, train_loss_step=0.0351, train_loss_epoch=0.0351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 3: from 1998-11-02 00:00:00 to 2022-01-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.394]Epoch 0: Train Loss = 0.3944900333881378\n",
      "Epoch 1: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.501, train_loss_epoch=0.394]Epoch 1: Train Loss = 0.501404345035553\n",
      "Epoch 2: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.369, train_loss_epoch=0.501]Epoch 2: Train Loss = 0.3692372441291809\n",
      "Epoch 3: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.247, train_loss_epoch=0.369]Epoch 3: Train Loss = 0.24663662910461426\n",
      "Epoch 4: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.311, train_loss_epoch=0.247]Epoch 4: Train Loss = 0.3106629252433777\n",
      "Epoch 5: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.305, train_loss_epoch=0.311]Epoch 5: Train Loss = 0.3050011992454529\n",
      "Epoch 6: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.251, train_loss_epoch=0.305]Epoch 6: Train Loss = 0.2509640157222748\n",
      "Epoch 7: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.241, train_loss_epoch=0.251]Epoch 7: Train Loss = 0.24051283299922943\n",
      "Epoch 8: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.265, train_loss_epoch=0.241]Epoch 8: Train Loss = 0.26513880491256714\n",
      "Epoch 9: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.260, train_loss_epoch=0.265]Epoch 9: Train Loss = 0.26034238934516907\n",
      "Epoch 10: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.240, train_loss_epoch=0.260]Epoch 10: Train Loss = 0.23988032341003418\n",
      "Epoch 11: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.223, train_loss_epoch=0.240]Epoch 11: Train Loss = 0.2229003608226776\n",
      "Epoch 12: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.232, train_loss_epoch=0.223]Epoch 12: Train Loss = 0.23247882723808289\n",
      "Epoch 13: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.216, train_loss_epoch=0.232]Epoch 13: Train Loss = 0.21619971096515656\n",
      "Epoch 14: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.211, train_loss_epoch=0.216]Epoch 14: Train Loss = 0.21066567301750183\n",
      "Epoch 15: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.189, train_loss_epoch=0.211]Epoch 15: Train Loss = 0.1887197196483612\n",
      "Epoch 16: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.198, train_loss_epoch=0.189]Epoch 16: Train Loss = 0.1976073831319809\n",
      "Epoch 17: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.189, train_loss_epoch=0.198]Epoch 17: Train Loss = 0.18932783603668213\n",
      "Epoch 18: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.194, train_loss_epoch=0.189]Epoch 18: Train Loss = 0.19437702000141144\n",
      "Epoch 19: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.172, train_loss_epoch=0.194]Epoch 19: Train Loss = 0.1723661720752716\n",
      "Epoch 20: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.168, train_loss_epoch=0.172]Epoch 20: Train Loss = 0.16792722046375275\n",
      "Epoch 21: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.182, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.18180152773857117\n",
      "Epoch 22: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.180, train_loss_epoch=0.182]Epoch 22: Train Loss = 0.18008111417293549\n",
      "Epoch 23: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.161, train_loss_epoch=0.180]Epoch 23: Train Loss = 0.16090825200080872\n",
      "Epoch 24: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.157, train_loss_epoch=0.161]Epoch 24: Train Loss = 0.1573735922574997\n",
      "Epoch 25: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.156, train_loss_epoch=0.157]Epoch 25: Train Loss = 0.15629248321056366\n",
      "Epoch 26: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.161, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.16105778515338898\n",
      "Epoch 27: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.150, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.14993548393249512\n",
      "Epoch 28: 100%|██████████| 1/1 [00:03<00:00,  0.32it/s, v_num=149, train_loss_step=0.142, train_loss_epoch=0.150]Epoch 28: Train Loss = 0.1423821896314621\n",
      "Epoch 29: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.149, train_loss_epoch=0.142]Epoch 29: Train Loss = 0.14856889843940735\n",
      "Epoch 30: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.145, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.14491945505142212\n",
      "Epoch 31: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.142, train_loss_epoch=0.145]Epoch 31: Train Loss = 0.14167095720767975\n",
      "Epoch 32: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.137, train_loss_epoch=0.142]Epoch 32: Train Loss = 0.13709010183811188\n",
      "Epoch 33: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.133, train_loss_epoch=0.137]Epoch 33: Train Loss = 0.13272981345653534\n",
      "Epoch 34: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.135, train_loss_epoch=0.133]Epoch 34: Train Loss = 0.13485458493232727\n",
      "Epoch 35: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.130, train_loss_epoch=0.135]Epoch 35: Train Loss = 0.13043075799942017\n",
      "Epoch 36: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.128, train_loss_epoch=0.130]Epoch 36: Train Loss = 0.12774980068206787\n",
      "Epoch 37: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.130, train_loss_epoch=0.128]Epoch 37: Train Loss = 0.12960191071033478\n",
      "Epoch 38: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.123, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12301849573850632\n",
      "Epoch 39: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.116, train_loss_epoch=0.123]Epoch 39: Train Loss = 0.11645359545946121\n",
      "Epoch 40: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.116, train_loss_epoch=0.116]Epoch 40: Train Loss = 0.11593496799468994\n",
      "Epoch 41: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.117, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11734824627637863\n",
      "Epoch 42: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.115, train_loss_epoch=0.117]Epoch 42: Train Loss = 0.11489009857177734\n",
      "Epoch 43: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.109, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.10863710194826126\n",
      "Epoch 44: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.114, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11396194249391556\n",
      "Epoch 45: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.106, train_loss_epoch=0.114]Epoch 45: Train Loss = 0.10590337961912155\n",
      "Epoch 46: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.105, train_loss_epoch=0.106]Epoch 46: Train Loss = 0.10517266392707825\n",
      "Epoch 47: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.103, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10333161801099777\n",
      "Epoch 48: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.103, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10251358151435852\n",
      "Epoch 49: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.103, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.10304959863424301\n",
      "Epoch 50: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.100, train_loss_epoch=0.103]Epoch 50: Train Loss = 0.10002650320529938\n",
      "Epoch 51: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0969, train_loss_epoch=0.100]Epoch 51: Train Loss = 0.09693150967359543\n",
      "Epoch 52: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0957, train_loss_epoch=0.0969]Epoch 52: Train Loss = 0.0957229882478714\n",
      "Epoch 53: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.094, train_loss_epoch=0.0957] Epoch 53: Train Loss = 0.09396138787269592\n",
      "Epoch 54: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=149, train_loss_step=0.0921, train_loss_epoch=0.094]Epoch 54: Train Loss = 0.0920909121632576\n",
      "Epoch 55: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0929, train_loss_epoch=0.0921]Epoch 55: Train Loss = 0.09288294613361359\n",
      "Epoch 56: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0907, train_loss_epoch=0.0929]Epoch 56: Train Loss = 0.09071265906095505\n",
      "Epoch 57: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0862, train_loss_epoch=0.0907]Epoch 57: Train Loss = 0.08620727062225342\n",
      "Epoch 58: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0874, train_loss_epoch=0.0862]Epoch 58: Train Loss = 0.08737745136022568\n",
      "Epoch 59: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0853, train_loss_epoch=0.0874]Epoch 59: Train Loss = 0.08529891818761826\n",
      "Epoch 60: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0848, train_loss_epoch=0.0853]Epoch 60: Train Loss = 0.0848231241106987\n",
      "Epoch 61: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0816, train_loss_epoch=0.0848]Epoch 61: Train Loss = 0.0816485658288002\n",
      "Epoch 62: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0808, train_loss_epoch=0.0816]Epoch 62: Train Loss = 0.0807589739561081\n",
      "Epoch 63: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0857, train_loss_epoch=0.0808]Epoch 63: Train Loss = 0.08570928126573563\n",
      "Epoch 64: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0767, train_loss_epoch=0.0857]Epoch 64: Train Loss = 0.07672831416130066\n",
      "Epoch 65: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0802, train_loss_epoch=0.0767]Epoch 65: Train Loss = 0.08015155047178268\n",
      "Epoch 66: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0767, train_loss_epoch=0.0802]Epoch 66: Train Loss = 0.07674848288297653\n",
      "Epoch 67: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0771, train_loss_epoch=0.0767]Epoch 67: Train Loss = 0.07707513123750687\n",
      "Epoch 68: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0742, train_loss_epoch=0.0771]Epoch 68: Train Loss = 0.07416494935750961\n",
      "Epoch 69: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0729, train_loss_epoch=0.0742]Epoch 69: Train Loss = 0.07291115075349808\n",
      "Epoch 70: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0724, train_loss_epoch=0.0729]Epoch 70: Train Loss = 0.07235848158597946\n",
      "Epoch 71: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0696, train_loss_epoch=0.0724]Epoch 71: Train Loss = 0.0695895329117775\n",
      "Epoch 72: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0703, train_loss_epoch=0.0696]Epoch 72: Train Loss = 0.07031722366809845\n",
      "Epoch 73: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0695, train_loss_epoch=0.0703]Epoch 73: Train Loss = 0.06953837722539902\n",
      "Epoch 74: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0695, train_loss_epoch=0.0695]Epoch 74: Train Loss = 0.0694744884967804\n",
      "Epoch 75: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0668, train_loss_epoch=0.0695]Epoch 75: Train Loss = 0.06677781790494919\n",
      "Epoch 76: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0663, train_loss_epoch=0.0668]Epoch 76: Train Loss = 0.06631781905889511\n",
      "Epoch 77: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0665, train_loss_epoch=0.0663]Epoch 77: Train Loss = 0.06647513061761856\n",
      "Epoch 78: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.066, train_loss_epoch=0.0665] Epoch 78: Train Loss = 0.06595294177532196\n",
      "Epoch 79: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0647, train_loss_epoch=0.066]Epoch 79: Train Loss = 0.06466859579086304\n",
      "Epoch 80: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=149, train_loss_step=0.0624, train_loss_epoch=0.0647]Epoch 80: Train Loss = 0.06241529434919357\n",
      "Epoch 81: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0627, train_loss_epoch=0.0624]Epoch 81: Train Loss = 0.06269394606351852\n",
      "Epoch 82: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0641, train_loss_epoch=0.0627]Epoch 82: Train Loss = 0.06408392637968063\n",
      "Epoch 83: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0623, train_loss_epoch=0.0641]Epoch 83: Train Loss = 0.062258582562208176\n",
      "Epoch 84: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0621, train_loss_epoch=0.0623]Epoch 84: Train Loss = 0.062102582305669785\n",
      "Epoch 85: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0622, train_loss_epoch=0.0621]Epoch 85: Train Loss = 0.06224973872303963\n",
      "Epoch 86: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.059, train_loss_epoch=0.0622] Epoch 86: Train Loss = 0.05895056948065758\n",
      "Epoch 87: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0607, train_loss_epoch=0.059]Epoch 87: Train Loss = 0.06071825698018074\n",
      "Epoch 88: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0567, train_loss_epoch=0.0607]Epoch 88: Train Loss = 0.056689146906137466\n",
      "Epoch 89: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.058, train_loss_epoch=0.0567] Epoch 89: Train Loss = 0.058038536459207535\n",
      "Epoch 90: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0579, train_loss_epoch=0.058]Epoch 90: Train Loss = 0.05785417929291725\n",
      "Epoch 91: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0562, train_loss_epoch=0.0579]Epoch 91: Train Loss = 0.05616813898086548\n",
      "Epoch 92: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0558, train_loss_epoch=0.0562]Epoch 92: Train Loss = 0.05582296848297119\n",
      "Epoch 93: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0556, train_loss_epoch=0.0558]Epoch 93: Train Loss = 0.05555877089500427\n",
      "Epoch 94: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0537, train_loss_epoch=0.0556]Epoch 94: Train Loss = 0.05374813452363014\n",
      "Epoch 95: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.053, train_loss_epoch=0.0537] Epoch 95: Train Loss = 0.05298293009400368\n",
      "Epoch 96: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0539, train_loss_epoch=0.053]Epoch 96: Train Loss = 0.053932446986436844\n",
      "Epoch 97: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0537, train_loss_epoch=0.0539]Epoch 97: Train Loss = 0.053700294345617294\n",
      "Epoch 98: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0544, train_loss_epoch=0.0537]Epoch 98: Train Loss = 0.054386261850595474\n",
      "Epoch 99: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0518, train_loss_epoch=0.0544]Epoch 99: Train Loss = 0.051831167191267014\n",
      "Epoch 100: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0523, train_loss_epoch=0.0518]Epoch 100: Train Loss = 0.05226793512701988\n",
      "Epoch 101: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0508, train_loss_epoch=0.0523]Epoch 101: Train Loss = 0.05079370737075806\n",
      "Epoch 102: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0505, train_loss_epoch=0.0508]Epoch 102: Train Loss = 0.05047563090920448\n",
      "Epoch 103: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0504, train_loss_epoch=0.0505]Epoch 103: Train Loss = 0.050433676689863205\n",
      "Epoch 104: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0491, train_loss_epoch=0.0504]Epoch 104: Train Loss = 0.04913032054901123\n",
      "Epoch 105: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0499, train_loss_epoch=0.0491]Epoch 105: Train Loss = 0.049932826310396194\n",
      "Epoch 106: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0487, train_loss_epoch=0.0499]Epoch 106: Train Loss = 0.0487193800508976\n",
      "Epoch 107: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0496, train_loss_epoch=0.0487]Epoch 107: Train Loss = 0.0496111623942852\n",
      "Epoch 108: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0485, train_loss_epoch=0.0496]Epoch 108: Train Loss = 0.048482950776815414\n",
      "Epoch 109: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0502, train_loss_epoch=0.0485]Epoch 109: Train Loss = 0.05020276829600334\n",
      "Epoch 110: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0472, train_loss_epoch=0.0502]Epoch 110: Train Loss = 0.047193389385938644\n",
      "Epoch 111: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0554, train_loss_epoch=0.0472]Epoch 111: Train Loss = 0.05539800599217415\n",
      "Epoch 112: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0458, train_loss_epoch=0.0554]Epoch 112: Train Loss = 0.04581557959318161\n",
      "Epoch 113: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0543, train_loss_epoch=0.0458]Epoch 113: Train Loss = 0.05430992692708969\n",
      "Epoch 114: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.046, train_loss_epoch=0.0543] Epoch 114: Train Loss = 0.04600822180509567\n",
      "Epoch 115: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0484, train_loss_epoch=0.046]Epoch 115: Train Loss = 0.048361148685216904\n",
      "Epoch 116: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0459, train_loss_epoch=0.0484]Epoch 116: Train Loss = 0.04590504989027977\n",
      "Epoch 117: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.050, train_loss_epoch=0.0459] Epoch 117: Train Loss = 0.05004945397377014\n",
      "Epoch 118: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0457, train_loss_epoch=0.050]Epoch 118: Train Loss = 0.0456664152443409\n",
      "Epoch 119: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0489, train_loss_epoch=0.0457]Epoch 119: Train Loss = 0.048860784620046616\n",
      "Epoch 120: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0444, train_loss_epoch=0.0489]Epoch 120: Train Loss = 0.04438105970621109\n",
      "Epoch 121: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0494, train_loss_epoch=0.0444]Epoch 121: Train Loss = 0.04941779375076294\n",
      "Epoch 122: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0439, train_loss_epoch=0.0494]Epoch 122: Train Loss = 0.04390477389097214\n",
      "Epoch 123: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0435, train_loss_epoch=0.0439]Epoch 123: Train Loss = 0.043546684086322784\n",
      "Epoch 124: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0435, train_loss_epoch=0.0435]Epoch 124: Train Loss = 0.04352329671382904\n",
      "Epoch 125: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0432, train_loss_epoch=0.0435]Epoch 125: Train Loss = 0.04316466674208641\n",
      "Epoch 126: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0423, train_loss_epoch=0.0432]Epoch 126: Train Loss = 0.042344432324171066\n",
      "Epoch 127: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0437, train_loss_epoch=0.0423]Epoch 127: Train Loss = 0.043694209307432175\n",
      "Epoch 128: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0419, train_loss_epoch=0.0437]Epoch 128: Train Loss = 0.04187481850385666\n",
      "Epoch 129: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0428, train_loss_epoch=0.0419]Epoch 129: Train Loss = 0.04281839728355408\n",
      "Epoch 130: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0419, train_loss_epoch=0.0428]Epoch 130: Train Loss = 0.041936613619327545\n",
      "Epoch 131: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0411, train_loss_epoch=0.0419]Epoch 131: Train Loss = 0.04113320633769035\n",
      "Epoch 132: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0417, train_loss_epoch=0.0411]Epoch 132: Train Loss = 0.04166453331708908\n",
      "Epoch 133: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0427, train_loss_epoch=0.0417]Epoch 133: Train Loss = 0.04270358383655548\n",
      "Epoch 134: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0407, train_loss_epoch=0.0427]Epoch 134: Train Loss = 0.040686774998903275\n",
      "Epoch 135: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0439, train_loss_epoch=0.0407]Epoch 135: Train Loss = 0.04385492205619812\n",
      "Epoch 136: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.041, train_loss_epoch=0.0439] Epoch 136: Train Loss = 0.04100256785750389\n",
      "Epoch 137: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0399, train_loss_epoch=0.041]Epoch 137: Train Loss = 0.03985027223825455\n",
      "Epoch 138: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0403, train_loss_epoch=0.0399]Epoch 138: Train Loss = 0.04027315601706505\n",
      "Epoch 139: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0404, train_loss_epoch=0.0403]Epoch 139: Train Loss = 0.04040541872382164\n",
      "Epoch 140: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0389, train_loss_epoch=0.0404]Epoch 140: Train Loss = 0.03885556757450104\n",
      "Epoch 141: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0401, train_loss_epoch=0.0389]Epoch 141: Train Loss = 0.040086064487695694\n",
      "Epoch 142: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0413, train_loss_epoch=0.0401]Epoch 142: Train Loss = 0.04128742218017578\n",
      "Epoch 143: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0419, train_loss_epoch=0.0413]Epoch 143: Train Loss = 0.04191569238901138\n",
      "Epoch 144: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0389, train_loss_epoch=0.0419]Epoch 144: Train Loss = 0.03888494148850441\n",
      "Epoch 145: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0383, train_loss_epoch=0.0389]Epoch 145: Train Loss = 0.03829849883913994\n",
      "Epoch 146: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0394, train_loss_epoch=0.0383]Epoch 146: Train Loss = 0.03937830775976181\n",
      "Epoch 147: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0381, train_loss_epoch=0.0394]Epoch 147: Train Loss = 0.03806509077548981\n",
      "Epoch 148: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0384, train_loss_epoch=0.0381]Epoch 148: Train Loss = 0.03844943270087242\n",
      "Epoch 149: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0379, train_loss_epoch=0.0384]Epoch 149: Train Loss = 0.03794243186712265\n",
      "Epoch 150: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0371, train_loss_epoch=0.0379]Epoch 150: Train Loss = 0.037054624408483505\n",
      "Epoch 151: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0369, train_loss_epoch=0.0371]Epoch 151: Train Loss = 0.036899518221616745\n",
      "Epoch 152: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0374, train_loss_epoch=0.0369]Epoch 152: Train Loss = 0.03736278787255287\n",
      "Epoch 153: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.037, train_loss_epoch=0.0374] Epoch 153: Train Loss = 0.03700530529022217\n",
      "Epoch 154: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0371, train_loss_epoch=0.037]Epoch 154: Train Loss = 0.03710357844829559\n",
      "Epoch 155: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0384, train_loss_epoch=0.0371]Epoch 155: Train Loss = 0.03844704478979111\n",
      "Epoch 156: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0369, train_loss_epoch=0.0384]Epoch 156: Train Loss = 0.03685471788048744\n",
      "Epoch 157: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0438, train_loss_epoch=0.0369]Epoch 157: Train Loss = 0.04376984015107155\n",
      "Epoch 158: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0359, train_loss_epoch=0.0438]Epoch 158: Train Loss = 0.03587127849459648\n",
      "Epoch 159: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0449, train_loss_epoch=0.0359]Epoch 159: Train Loss = 0.04490865021944046\n",
      "Epoch 160: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0363, train_loss_epoch=0.0449]Epoch 160: Train Loss = 0.03630160912871361\n",
      "Epoch 161: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0436, train_loss_epoch=0.0363]Epoch 161: Train Loss = 0.04360540583729744\n",
      "Epoch 162: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0359, train_loss_epoch=0.0436]Epoch 162: Train Loss = 0.035928692668676376\n",
      "Epoch 163: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0456, train_loss_epoch=0.0359]Epoch 163: Train Loss = 0.04557108134031296\n",
      "Epoch 164: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.036, train_loss_epoch=0.0456] Epoch 164: Train Loss = 0.036028530448675156\n",
      "Epoch 165: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0372, train_loss_epoch=0.036]Epoch 165: Train Loss = 0.037198495119810104\n",
      "Epoch 166: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0373, train_loss_epoch=0.0372]Epoch 166: Train Loss = 0.0373050682246685\n",
      "Epoch 167: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.036, train_loss_epoch=0.0373] Epoch 167: Train Loss = 0.03597332164645195\n",
      "Epoch 168: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0378, train_loss_epoch=0.036]Epoch 168: Train Loss = 0.03778352588415146\n",
      "Epoch 169: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0374, train_loss_epoch=0.0378]Epoch 169: Train Loss = 0.03735068812966347\n",
      "Epoch 170: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0373, train_loss_epoch=0.0374]Epoch 170: Train Loss = 0.03733191266655922\n",
      "Epoch 171: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0359, train_loss_epoch=0.0373]Epoch 171: Train Loss = 0.03588709980249405\n",
      "Epoch 172: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0392, train_loss_epoch=0.0359]Epoch 172: Train Loss = 0.039168812334537506\n",
      "Epoch 173: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0347, train_loss_epoch=0.0392]Epoch 173: Train Loss = 0.034714944660663605\n",
      "Epoch 174: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.039, train_loss_epoch=0.0347] Epoch 174: Train Loss = 0.03903481736779213\n",
      "Epoch 175: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0351, train_loss_epoch=0.039]Epoch 175: Train Loss = 0.03506430611014366\n",
      "Epoch 176: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0346, train_loss_epoch=0.0351]Epoch 176: Train Loss = 0.034605395048856735\n",
      "Epoch 177: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0351, train_loss_epoch=0.0346]Epoch 177: Train Loss = 0.03508584201335907\n",
      "Epoch 178: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0353, train_loss_epoch=0.0351]Epoch 178: Train Loss = 0.03530867025256157\n",
      "Epoch 179: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0346, train_loss_epoch=0.0353]Epoch 179: Train Loss = 0.034562088549137115\n",
      "Epoch 180: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0344, train_loss_epoch=0.0346]Epoch 180: Train Loss = 0.03442330285906792\n",
      "Epoch 181: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0344, train_loss_epoch=0.0344]Epoch 181: Train Loss = 0.03442532196640968\n",
      "Epoch 182: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0342, train_loss_epoch=0.0344]Epoch 182: Train Loss = 0.03417722135782242\n",
      "Epoch 183: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0341, train_loss_epoch=0.0342]Epoch 183: Train Loss = 0.03408318758010864\n",
      "Epoch 184: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0334, train_loss_epoch=0.0341]Epoch 184: Train Loss = 0.03341098129749298\n",
      "Epoch 185: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=149, train_loss_step=0.0335, train_loss_epoch=0.0334]Epoch 185: Train Loss = 0.033530812710523605\n",
      "Epoch 186: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0334, train_loss_epoch=0.0335]Epoch 186: Train Loss = 0.03340571001172066\n",
      "Epoch 187: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=149, train_loss_step=0.0329, train_loss_epoch=0.0334]Epoch 187: Train Loss = 0.03294950723648071\n",
      "Epoch 188: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0327, train_loss_epoch=0.0329]Epoch 188: Train Loss = 0.03265421837568283\n",
      "Epoch 189: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0337, train_loss_epoch=0.0327]Epoch 189: Train Loss = 0.03368491306900978\n",
      "Epoch 190: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0324, train_loss_epoch=0.0337]Epoch 190: Train Loss = 0.03236465901136398\n",
      "Epoch 191: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0329, train_loss_epoch=0.0324]Epoch 191: Train Loss = 0.032893333584070206\n",
      "Epoch 192: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0337, train_loss_epoch=0.0329]Epoch 192: Train Loss = 0.03372442349791527\n",
      "Epoch 193: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0342, train_loss_epoch=0.0337]Epoch 193: Train Loss = 0.034189023077487946\n",
      "Epoch 194: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.033, train_loss_epoch=0.0342] Epoch 194: Train Loss = 0.032984547317028046\n",
      "Epoch 195: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.033, train_loss_epoch=0.033] Epoch 195: Train Loss = 0.03298024833202362\n",
      "Epoch 196: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0342, train_loss_epoch=0.033]Epoch 196: Train Loss = 0.03421131148934364\n",
      "Epoch 197: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0328, train_loss_epoch=0.0342]Epoch 197: Train Loss = 0.032814327627420425\n",
      "Epoch 198: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0327, train_loss_epoch=0.0328]Epoch 198: Train Loss = 0.03268113359808922\n",
      "Epoch 199: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0342, train_loss_epoch=0.0327]Epoch 199: Train Loss = 0.034210119396448135\n",
      "Epoch 200: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0339, train_loss_epoch=0.0342]Epoch 200: Train Loss = 0.03392857685685158\n",
      "Epoch 201: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0323, train_loss_epoch=0.0339]Epoch 201: Train Loss = 0.0322558768093586\n",
      "Epoch 202: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0328, train_loss_epoch=0.0323]Epoch 202: Train Loss = 0.032833535224199295\n",
      "Epoch 203: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0326, train_loss_epoch=0.0328]Epoch 203: Train Loss = 0.03264833241701126\n",
      "Epoch 204: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0311, train_loss_epoch=0.0326]Epoch 204: Train Loss = 0.031137831509113312\n",
      "Epoch 205: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0334, train_loss_epoch=0.0311]Epoch 205: Train Loss = 0.03340306133031845\n",
      "Epoch 206: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0311, train_loss_epoch=0.0334]Epoch 206: Train Loss = 0.03109891712665558\n",
      "Epoch 207: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0317, train_loss_epoch=0.0311]Epoch 207: Train Loss = 0.03171628341078758\n",
      "Epoch 208: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0324, train_loss_epoch=0.0317]Epoch 208: Train Loss = 0.03241882845759392\n",
      "Epoch 209: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0316, train_loss_epoch=0.0324]Epoch 209: Train Loss = 0.03157513961195946\n",
      "Epoch 210: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0315, train_loss_epoch=0.0316]Epoch 210: Train Loss = 0.03154481202363968\n",
      "Epoch 211: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0319, train_loss_epoch=0.0315]Epoch 211: Train Loss = 0.031913261860609055\n",
      "Epoch 212: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0337, train_loss_epoch=0.0319]Epoch 212: Train Loss = 0.03374231979250908\n",
      "Epoch 213: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0313, train_loss_epoch=0.0337]Epoch 213: Train Loss = 0.031342826783657074\n",
      "Epoch 214: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=149, train_loss_step=0.0316, train_loss_epoch=0.0313]Epoch 214: Train Loss = 0.031598981469869614\n",
      "Epoch 215: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.031, train_loss_epoch=0.0316] Epoch 215: Train Loss = 0.03096732497215271\n",
      "Epoch 216: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0306, train_loss_epoch=0.031]Epoch 216: Train Loss = 0.030573461204767227\n",
      "Epoch 217: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0305, train_loss_epoch=0.0306]Epoch 217: Train Loss = 0.030516119673848152\n",
      "Epoch 218: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.032, train_loss_epoch=0.0305] Epoch 218: Train Loss = 0.03199409320950508\n",
      "Epoch 219: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0326, train_loss_epoch=0.032]Epoch 219: Train Loss = 0.03264511376619339\n",
      "Epoch 220: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0306, train_loss_epoch=0.0326]Epoch 220: Train Loss = 0.030586272478103638\n",
      "Epoch 221: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=149, train_loss_step=0.0328, train_loss_epoch=0.0306]Epoch 221: Train Loss = 0.03282859921455383\n",
      "Epoch 222: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0307, train_loss_epoch=0.0328]Epoch 222: Train Loss = 0.030710985884070396\n",
      "Epoch 223: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0315, train_loss_epoch=0.0307]Epoch 223: Train Loss = 0.03145923838019371\n",
      "Epoch 224: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0318, train_loss_epoch=0.0315]Epoch 224: Train Loss = 0.0318232960999012\n",
      "Epoch 225: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.031, train_loss_epoch=0.0318] Epoch 225: Train Loss = 0.030975548550486565\n",
      "Epoch 226: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0318, train_loss_epoch=0.031]Epoch 226: Train Loss = 0.03180357813835144\n",
      "Epoch 227: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0308, train_loss_epoch=0.0318]Epoch 227: Train Loss = 0.03083573281764984\n",
      "Epoch 228: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0301, train_loss_epoch=0.0308]Epoch 228: Train Loss = 0.030136166140437126\n",
      "Epoch 229: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0336, train_loss_epoch=0.0301]Epoch 229: Train Loss = 0.033635541796684265\n",
      "Epoch 230: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0364, train_loss_epoch=0.0336]Epoch 230: Train Loss = 0.03638516366481781\n",
      "Epoch 231: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0299, train_loss_epoch=0.0364]Epoch 231: Train Loss = 0.029923293739557266\n",
      "Epoch 232: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=149, train_loss_step=0.0315, train_loss_epoch=0.0299]Epoch 232: Train Loss = 0.03146802634000778\n",
      "Epoch 233: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0303, train_loss_epoch=0.0315]Epoch 233: Train Loss = 0.03027956746518612\n",
      "Epoch 234: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0307, train_loss_epoch=0.0303]Epoch 234: Train Loss = 0.030694952234625816\n",
      "Epoch 235: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.038, train_loss_epoch=0.0307] Epoch 235: Train Loss = 0.03796728327870369\n",
      "Epoch 236: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0302, train_loss_epoch=0.038]Epoch 236: Train Loss = 0.030202141031622887\n",
      "Epoch 237: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=149, train_loss_step=0.0374, train_loss_epoch=0.0302]Epoch 237: Train Loss = 0.03744974359869957\n",
      "Epoch 238: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0295, train_loss_epoch=0.0374]Epoch 238: Train Loss = 0.029519658535718918\n",
      "Epoch 239: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0325, train_loss_epoch=0.0295]Epoch 239: Train Loss = 0.03250632807612419\n",
      "Epoch 240: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0314, train_loss_epoch=0.0325]Epoch 240: Train Loss = 0.03139172121882439\n",
      "Epoch 241: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0355, train_loss_epoch=0.0314]Epoch 241: Train Loss = 0.03549547493457794\n",
      "Epoch 242: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0331, train_loss_epoch=0.0355]Epoch 242: Train Loss = 0.03312588855624199\n",
      "Epoch 243: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0364, train_loss_epoch=0.0331]Epoch 243: Train Loss = 0.03640962392091751\n",
      "Epoch 244: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0323, train_loss_epoch=0.0364]Epoch 244: Train Loss = 0.03234327957034111\n",
      "Epoch 245: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.032, train_loss_epoch=0.0323] Epoch 245: Train Loss = 0.03195517137646675\n",
      "Epoch 246: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0313, train_loss_epoch=0.032]Epoch 246: Train Loss = 0.03133491426706314\n",
      "Epoch 247: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0302, train_loss_epoch=0.0313]Epoch 247: Train Loss = 0.03023402765393257\n",
      "Epoch 248: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=149, train_loss_step=0.0294, train_loss_epoch=0.0302]Epoch 248: Train Loss = 0.029388438910245895\n",
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0299, train_loss_epoch=0.0294]Epoch 249: Train Loss = 0.029926424846053123\n",
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0299, train_loss_epoch=0.0299]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=149, train_loss_step=0.0299, train_loss_epoch=0.0299]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 34.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 4: from 1998-11-02 00:00:00 to 2022-01-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.400]Epoch 0: Train Loss = 0.3995901942253113\n",
      "Epoch 1: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.499, train_loss_epoch=0.400]Epoch 1: Train Loss = 0.4994108974933624\n",
      "Epoch 2: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.370, train_loss_epoch=0.499]Epoch 2: Train Loss = 0.37032151222229004\n",
      "Epoch 3: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.245, train_loss_epoch=0.370]Epoch 3: Train Loss = 0.24500589072704315\n",
      "Epoch 4: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.313, train_loss_epoch=0.245]Epoch 4: Train Loss = 0.3128345310688019\n",
      "Epoch 5: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.309, train_loss_epoch=0.313]Epoch 5: Train Loss = 0.30902600288391113\n",
      "Epoch 6: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.249, train_loss_epoch=0.309]Epoch 6: Train Loss = 0.24857038259506226\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.35it/s, v_num=165, train_loss_step=0.244, train_loss_epoch=0.249]Epoch 7: Train Loss = 0.24359706044197083\n",
      "Epoch 8: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.267, train_loss_epoch=0.244]Epoch 8: Train Loss = 0.2670626938343048\n",
      "Epoch 9: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.256, train_loss_epoch=0.267]Epoch 9: Train Loss = 0.25609156489372253\n",
      "Epoch 10: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.237, train_loss_epoch=0.256]Epoch 10: Train Loss = 0.2370540201663971\n",
      "Epoch 11: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.220, train_loss_epoch=0.237]Epoch 11: Train Loss = 0.21972301602363586\n",
      "Epoch 12: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.239, train_loss_epoch=0.220]Epoch 12: Train Loss = 0.23854340612888336\n",
      "Epoch 13: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.222, train_loss_epoch=0.239]Epoch 13: Train Loss = 0.2215229719877243\n",
      "Epoch 14: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.211, train_loss_epoch=0.222]Epoch 14: Train Loss = 0.2110736221075058\n",
      "Epoch 15: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.190, train_loss_epoch=0.211]Epoch 15: Train Loss = 0.1902230978012085\n",
      "Epoch 16: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.198, train_loss_epoch=0.190]Epoch 16: Train Loss = 0.19784066081047058\n",
      "Epoch 17: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.192, train_loss_epoch=0.198]Epoch 17: Train Loss = 0.19187712669372559\n",
      "Epoch 18: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.198, train_loss_epoch=0.192]Epoch 18: Train Loss = 0.19833704829216003\n",
      "Epoch 19: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=165, train_loss_step=0.173, train_loss_epoch=0.198]Epoch 19: Train Loss = 0.17319618165493011\n",
      "Epoch 20: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.168, train_loss_epoch=0.173]Epoch 20: Train Loss = 0.16812105476856232\n",
      "Epoch 21: 100%|██████████| 1/1 [00:04<00:00,  0.25it/s, v_num=165, train_loss_step=0.180, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.18024161458015442\n",
      "Epoch 22: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=165, train_loss_step=0.178, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.1783619374036789\n",
      "Epoch 23: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.162, train_loss_epoch=0.178]Epoch 23: Train Loss = 0.16231508553028107\n",
      "Epoch 24: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.159, train_loss_epoch=0.162]Epoch 24: Train Loss = 0.1593300998210907\n",
      "Epoch 25: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.154, train_loss_epoch=0.159]Epoch 25: Train Loss = 0.15386684238910675\n",
      "Epoch 26: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.161, train_loss_epoch=0.154]Epoch 26: Train Loss = 0.16106700897216797\n",
      "Epoch 27: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.151, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.1508350521326065\n",
      "Epoch 28: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.145, train_loss_epoch=0.151]Epoch 28: Train Loss = 0.14546115696430206\n",
      "Epoch 29: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.150, train_loss_epoch=0.145]Epoch 29: Train Loss = 0.14996184408664703\n",
      "Epoch 30: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.141, train_loss_epoch=0.150]Epoch 30: Train Loss = 0.14097192883491516\n",
      "Epoch 31: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.142, train_loss_epoch=0.141]Epoch 31: Train Loss = 0.14156095683574677\n",
      "Epoch 32: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.139, train_loss_epoch=0.142]Epoch 32: Train Loss = 0.1385817974805832\n",
      "Epoch 33: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.134, train_loss_epoch=0.139]Epoch 33: Train Loss = 0.1336897909641266\n",
      "Epoch 34: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.135, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.13513466715812683\n",
      "Epoch 35: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.131, train_loss_epoch=0.135]Epoch 35: Train Loss = 0.13080677390098572\n",
      "Epoch 36: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.129, train_loss_epoch=0.131]Epoch 36: Train Loss = 0.12918280065059662\n",
      "Epoch 37: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.127, train_loss_epoch=0.129]Epoch 37: Train Loss = 0.12723885476589203\n",
      "Epoch 38: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.124, train_loss_epoch=0.127]Epoch 38: Train Loss = 0.12358738481998444\n",
      "Epoch 39: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.118, train_loss_epoch=0.124]Epoch 39: Train Loss = 0.11839504539966583\n",
      "Epoch 40: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.117, train_loss_epoch=0.118]Epoch 40: Train Loss = 0.11659523099660873\n",
      "Epoch 41: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.118, train_loss_epoch=0.117]Epoch 41: Train Loss = 0.11788852512836456\n",
      "Epoch 42: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.115, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.11502035707235336\n",
      "Epoch 43: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.109, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.10868707299232483\n",
      "Epoch 44: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.113, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11318953335285187\n",
      "Epoch 45: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.109, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10883989185094833\n",
      "Epoch 46: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.105, train_loss_epoch=0.109]Epoch 46: Train Loss = 0.10525522381067276\n",
      "Epoch 47: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.102, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10242825746536255\n",
      "Epoch 48: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.104, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.10378988087177277\n",
      "Epoch 49: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.104, train_loss_epoch=0.104]Epoch 49: Train Loss = 0.10375215858221054\n",
      "Epoch 50: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.101, train_loss_epoch=0.104]Epoch 50: Train Loss = 0.10144498944282532\n",
      "Epoch 51: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0979, train_loss_epoch=0.101]Epoch 51: Train Loss = 0.09793788194656372\n",
      "Epoch 52: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0983, train_loss_epoch=0.0979]Epoch 52: Train Loss = 0.09831276535987854\n",
      "Epoch 53: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0954, train_loss_epoch=0.0983]Epoch 53: Train Loss = 0.0953911766409874\n",
      "Epoch 54: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0916, train_loss_epoch=0.0954]Epoch 54: Train Loss = 0.09163558483123779\n",
      "Epoch 55: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.093, train_loss_epoch=0.0916] Epoch 55: Train Loss = 0.09298323839902878\n",
      "Epoch 56: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.092, train_loss_epoch=0.093] Epoch 56: Train Loss = 0.09199947863817215\n",
      "Epoch 57: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0879, train_loss_epoch=0.092]Epoch 57: Train Loss = 0.08792710304260254\n",
      "Epoch 58: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0872, train_loss_epoch=0.0879]Epoch 58: Train Loss = 0.08716099709272385\n",
      "Epoch 59: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0861, train_loss_epoch=0.0872]Epoch 59: Train Loss = 0.08606123924255371\n",
      "Epoch 60: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0848, train_loss_epoch=0.0861]Epoch 60: Train Loss = 0.08481396734714508\n",
      "Epoch 61: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0811, train_loss_epoch=0.0848]Epoch 61: Train Loss = 0.08112005889415741\n",
      "Epoch 62: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0821, train_loss_epoch=0.0811]Epoch 62: Train Loss = 0.08214308321475983\n",
      "Epoch 63: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.0806, train_loss_epoch=0.0821]Epoch 63: Train Loss = 0.08060640841722488\n",
      "Epoch 64: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0783, train_loss_epoch=0.0806]Epoch 64: Train Loss = 0.07828018069267273\n",
      "Epoch 65: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0779, train_loss_epoch=0.0783]Epoch 65: Train Loss = 0.07791722565889359\n",
      "Epoch 66: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0771, train_loss_epoch=0.0779]Epoch 66: Train Loss = 0.07710527628660202\n",
      "Epoch 67: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0769, train_loss_epoch=0.0771]Epoch 67: Train Loss = 0.07693945616483688\n",
      "Epoch 68: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0746, train_loss_epoch=0.0769]Epoch 68: Train Loss = 0.0745777040719986\n",
      "Epoch 69: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0715, train_loss_epoch=0.0746]Epoch 69: Train Loss = 0.07153910398483276\n",
      "Epoch 70: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0721, train_loss_epoch=0.0715]Epoch 70: Train Loss = 0.0721137523651123\n",
      "Epoch 71: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.070, train_loss_epoch=0.0721] Epoch 71: Train Loss = 0.07004480808973312\n",
      "Epoch 72: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0694, train_loss_epoch=0.070]Epoch 72: Train Loss = 0.0693870484828949\n",
      "Epoch 73: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0694, train_loss_epoch=0.0694]Epoch 73: Train Loss = 0.06935571134090424\n",
      "Epoch 74: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0686, train_loss_epoch=0.0694]Epoch 74: Train Loss = 0.06862662732601166\n",
      "Epoch 75: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0664, train_loss_epoch=0.0686]Epoch 75: Train Loss = 0.06639458239078522\n",
      "Epoch 76: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0656, train_loss_epoch=0.0664]Epoch 76: Train Loss = 0.06564643979072571\n",
      "Epoch 77: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.067, train_loss_epoch=0.0656] Epoch 77: Train Loss = 0.06695423275232315\n",
      "Epoch 78: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0667, train_loss_epoch=0.067]Epoch 78: Train Loss = 0.06668888032436371\n",
      "Epoch 79: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0625, train_loss_epoch=0.0667]Epoch 79: Train Loss = 0.062463995069265366\n",
      "Epoch 80: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0626, train_loss_epoch=0.0625]Epoch 80: Train Loss = 0.06263764202594757\n",
      "Epoch 81: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0617, train_loss_epoch=0.0626]Epoch 81: Train Loss = 0.06171224266290665\n",
      "Epoch 82: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.062, train_loss_epoch=0.0617] Epoch 82: Train Loss = 0.06196309253573418\n",
      "Epoch 83: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0607, train_loss_epoch=0.062]Epoch 83: Train Loss = 0.06069573014974594\n",
      "Epoch 84: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.061, train_loss_epoch=0.0607] Epoch 84: Train Loss = 0.06098667159676552\n",
      "Epoch 85: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0601, train_loss_epoch=0.061]Epoch 85: Train Loss = 0.060113128274679184\n",
      "Epoch 86: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0597, train_loss_epoch=0.0601]Epoch 86: Train Loss = 0.059744399040937424\n",
      "Epoch 87: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0597, train_loss_epoch=0.0597]Epoch 87: Train Loss = 0.059689026325941086\n",
      "Epoch 88: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0608, train_loss_epoch=0.0597]Epoch 88: Train Loss = 0.060805320739746094\n",
      "Epoch 89: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0575, train_loss_epoch=0.0608]Epoch 89: Train Loss = 0.05752747878432274\n",
      "Epoch 90: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0575, train_loss_epoch=0.0575]Epoch 90: Train Loss = 0.057452913373708725\n",
      "Epoch 91: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0545, train_loss_epoch=0.0575]Epoch 91: Train Loss = 0.0545114129781723\n",
      "Epoch 92: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.0551, train_loss_epoch=0.0545]Epoch 92: Train Loss = 0.055050771683454514\n",
      "Epoch 93: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0574, train_loss_epoch=0.0551]Epoch 93: Train Loss = 0.05735564976930618\n",
      "Epoch 94: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0532, train_loss_epoch=0.0574]Epoch 94: Train Loss = 0.05319424346089363\n",
      "Epoch 95: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0578, train_loss_epoch=0.0532]Epoch 95: Train Loss = 0.05777531489729881\n",
      "Epoch 96: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0517, train_loss_epoch=0.0578]Epoch 96: Train Loss = 0.05173210799694061\n",
      "Epoch 97: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0567, train_loss_epoch=0.0517]Epoch 97: Train Loss = 0.056749388575553894\n",
      "Epoch 98: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0525, train_loss_epoch=0.0567]Epoch 98: Train Loss = 0.05248262733221054\n",
      "Epoch 99: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0558, train_loss_epoch=0.0525]Epoch 99: Train Loss = 0.05583292618393898\n",
      "Epoch 100: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0505, train_loss_epoch=0.0558]Epoch 100: Train Loss = 0.05051606893539429\n",
      "Epoch 101: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0552, train_loss_epoch=0.0505]Epoch 101: Train Loss = 0.055233124643564224\n",
      "Epoch 102: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0496, train_loss_epoch=0.0552]Epoch 102: Train Loss = 0.04957304149866104\n",
      "Epoch 103: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0527, train_loss_epoch=0.0496]Epoch 103: Train Loss = 0.05268179997801781\n",
      "Epoch 104: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0489, train_loss_epoch=0.0527]Epoch 104: Train Loss = 0.048875924199819565\n",
      "Epoch 105: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0519, train_loss_epoch=0.0489]Epoch 105: Train Loss = 0.05186668410897255\n",
      "Epoch 106: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0484, train_loss_epoch=0.0519]Epoch 106: Train Loss = 0.048416320234537125\n",
      "Epoch 107: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0496, train_loss_epoch=0.0484]Epoch 107: Train Loss = 0.049613554030656815\n",
      "Epoch 108: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.048, train_loss_epoch=0.0496] Epoch 108: Train Loss = 0.04800081625580788\n",
      "Epoch 109: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0469, train_loss_epoch=0.048]Epoch 109: Train Loss = 0.04689845070242882\n",
      "Epoch 110: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.047, train_loss_epoch=0.0469] Epoch 110: Train Loss = 0.04700354114174843\n",
      "Epoch 111: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0474, train_loss_epoch=0.047]Epoch 111: Train Loss = 0.0474223792552948\n",
      "Epoch 112: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0467, train_loss_epoch=0.0474]Epoch 112: Train Loss = 0.04674319177865982\n",
      "Epoch 113: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0497, train_loss_epoch=0.0467]Epoch 113: Train Loss = 0.04973248392343521\n",
      "Epoch 114: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0481, train_loss_epoch=0.0497]Epoch 114: Train Loss = 0.04807986319065094\n",
      "Epoch 115: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0516, train_loss_epoch=0.0481]Epoch 115: Train Loss = 0.05161556974053383\n",
      "Epoch 116: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0472, train_loss_epoch=0.0516]Epoch 116: Train Loss = 0.04722171649336815\n",
      "Epoch 117: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0476, train_loss_epoch=0.0472]Epoch 117: Train Loss = 0.047633714973926544\n",
      "Epoch 118: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0477, train_loss_epoch=0.0476]Epoch 118: Train Loss = 0.047657277435064316\n",
      "Epoch 119: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0465, train_loss_epoch=0.0477]Epoch 119: Train Loss = 0.046466242522001266\n",
      "Epoch 120: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.0482, train_loss_epoch=0.0465]Epoch 120: Train Loss = 0.04819817095994949\n",
      "Epoch 121: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0442, train_loss_epoch=0.0482]Epoch 121: Train Loss = 0.04422738403081894\n",
      "Epoch 122: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0496, train_loss_epoch=0.0442]Epoch 122: Train Loss = 0.049588870257139206\n",
      "Epoch 123: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.044, train_loss_epoch=0.0496] Epoch 123: Train Loss = 0.04395609349012375\n",
      "Epoch 124: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0439, train_loss_epoch=0.044]Epoch 124: Train Loss = 0.04391217976808548\n",
      "Epoch 125: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0439, train_loss_epoch=0.0439]Epoch 125: Train Loss = 0.04392075538635254\n",
      "Epoch 126: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0423, train_loss_epoch=0.0439]Epoch 126: Train Loss = 0.04230846092104912\n",
      "Epoch 127: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.0453, train_loss_epoch=0.0423]Epoch 127: Train Loss = 0.04527615010738373\n",
      "Epoch 128: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0438, train_loss_epoch=0.0453]Epoch 128: Train Loss = 0.043792545795440674\n",
      "Epoch 129: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0421, train_loss_epoch=0.0438]Epoch 129: Train Loss = 0.042080771178007126\n",
      "Epoch 130: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0415, train_loss_epoch=0.0421]Epoch 130: Train Loss = 0.04146572947502136\n",
      "Epoch 131: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0426, train_loss_epoch=0.0415]Epoch 131: Train Loss = 0.04258302226662636\n",
      "Epoch 132: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0411, train_loss_epoch=0.0426]Epoch 132: Train Loss = 0.041057612746953964\n",
      "Epoch 133: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0428, train_loss_epoch=0.0411]Epoch 133: Train Loss = 0.042777933180332184\n",
      "Epoch 134: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0404, train_loss_epoch=0.0428]Epoch 134: Train Loss = 0.04044944792985916\n",
      "Epoch 135: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0422, train_loss_epoch=0.0404]Epoch 135: Train Loss = 0.042186666280031204\n",
      "Epoch 136: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0407, train_loss_epoch=0.0422]Epoch 136: Train Loss = 0.04067612811923027\n",
      "Epoch 137: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0417, train_loss_epoch=0.0407]Epoch 137: Train Loss = 0.04165515676140785\n",
      "Epoch 138: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0397, train_loss_epoch=0.0417]Epoch 138: Train Loss = 0.03974713757634163\n",
      "Epoch 139: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0406, train_loss_epoch=0.0397]Epoch 139: Train Loss = 0.040625836700201035\n",
      "Epoch 140: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0406, train_loss_epoch=0.0406]Epoch 140: Train Loss = 0.04061400145292282\n",
      "Epoch 141: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0412, train_loss_epoch=0.0406]Epoch 141: Train Loss = 0.041208118200302124\n",
      "Epoch 142: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0402, train_loss_epoch=0.0412]Epoch 142: Train Loss = 0.0401545949280262\n",
      "Epoch 143: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0411, train_loss_epoch=0.0402]Epoch 143: Train Loss = 0.04111053794622421\n",
      "Epoch 144: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0387, train_loss_epoch=0.0411]Epoch 144: Train Loss = 0.03873410448431969\n",
      "Epoch 145: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0382, train_loss_epoch=0.0387]Epoch 145: Train Loss = 0.0382378064095974\n",
      "Epoch 146: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.039, train_loss_epoch=0.0382] Epoch 146: Train Loss = 0.038976892828941345\n",
      "Epoch 147: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0386, train_loss_epoch=0.039]Epoch 147: Train Loss = 0.03863215446472168\n",
      "Epoch 148: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0377, train_loss_epoch=0.0386]Epoch 148: Train Loss = 0.03766978904604912\n",
      "Epoch 149: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0377, train_loss_epoch=0.0377]Epoch 149: Train Loss = 0.037730276584625244\n",
      "Epoch 150: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0375, train_loss_epoch=0.0377]Epoch 150: Train Loss = 0.0375310517847538\n",
      "Epoch 151: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0375, train_loss_epoch=0.0375]Epoch 151: Train Loss = 0.03753703087568283\n",
      "Epoch 152: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0392, train_loss_epoch=0.0375]Epoch 152: Train Loss = 0.03919265419244766\n",
      "Epoch 153: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0377, train_loss_epoch=0.0392]Epoch 153: Train Loss = 0.037667352706193924\n",
      "Epoch 154: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.038, train_loss_epoch=0.0377] Epoch 154: Train Loss = 0.03796307370066643\n",
      "Epoch 155: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.0374, train_loss_epoch=0.038]Epoch 155: Train Loss = 0.03739955276250839\n",
      "Epoch 156: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0376, train_loss_epoch=0.0374]Epoch 156: Train Loss = 0.03760512173175812\n",
      "Epoch 157: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0389, train_loss_epoch=0.0376]Epoch 157: Train Loss = 0.03888382762670517\n",
      "Epoch 158: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0377, train_loss_epoch=0.0389]Epoch 158: Train Loss = 0.037671156227588654\n",
      "Epoch 159: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0376, train_loss_epoch=0.0377]Epoch 159: Train Loss = 0.03755219653248787\n",
      "Epoch 160: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0382, train_loss_epoch=0.0376]Epoch 160: Train Loss = 0.038156069815158844\n",
      "Epoch 161: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0399, train_loss_epoch=0.0382]Epoch 161: Train Loss = 0.03988320380449295\n",
      "Epoch 162: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0359, train_loss_epoch=0.0399]Epoch 162: Train Loss = 0.03593584522604942\n",
      "Epoch 163: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0362, train_loss_epoch=0.0359]Epoch 163: Train Loss = 0.036221809685230255\n",
      "Epoch 164: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0382, train_loss_epoch=0.0362]Epoch 164: Train Loss = 0.038224343210458755\n",
      "Epoch 165: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0368, train_loss_epoch=0.0382]Epoch 165: Train Loss = 0.03684966266155243\n",
      "Epoch 166: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0368, train_loss_epoch=0.0368]Epoch 166: Train Loss = 0.036847278475761414\n",
      "Epoch 167: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0349, train_loss_epoch=0.0368]Epoch 167: Train Loss = 0.03490529581904411\n",
      "Epoch 168: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0384, train_loss_epoch=0.0349]Epoch 168: Train Loss = 0.03836063668131828\n",
      "Epoch 169: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.036, train_loss_epoch=0.0384] Epoch 169: Train Loss = 0.03599204495549202\n",
      "Epoch 170: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0389, train_loss_epoch=0.036]Epoch 170: Train Loss = 0.03888611122965813\n",
      "Epoch 171: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0355, train_loss_epoch=0.0389]Epoch 171: Train Loss = 0.03549778833985329\n",
      "Epoch 172: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0341, train_loss_epoch=0.0355]Epoch 172: Train Loss = 0.03407460078597069\n",
      "Epoch 173: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0378, train_loss_epoch=0.0341]Epoch 173: Train Loss = 0.03777003288269043\n",
      "Epoch 174: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0334, train_loss_epoch=0.0378]Epoch 174: Train Loss = 0.03337058424949646\n",
      "Epoch 175: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0377, train_loss_epoch=0.0334]Epoch 175: Train Loss = 0.037664733827114105\n",
      "Epoch 176: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0346, train_loss_epoch=0.0377]Epoch 176: Train Loss = 0.0346175879240036\n",
      "Epoch 177: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0347, train_loss_epoch=0.0346]Epoch 177: Train Loss = 0.03471483662724495\n",
      "Epoch 178: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0345, train_loss_epoch=0.0347]Epoch 178: Train Loss = 0.03452383354306221\n",
      "Epoch 179: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.0337, train_loss_epoch=0.0345]Epoch 179: Train Loss = 0.033690597862005234\n",
      "Epoch 180: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.0353, train_loss_epoch=0.0337]Epoch 180: Train Loss = 0.03530384972691536\n",
      "Epoch 181: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.036, train_loss_epoch=0.0353] Epoch 181: Train Loss = 0.035954780876636505\n",
      "Epoch 182: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0341, train_loss_epoch=0.036]Epoch 182: Train Loss = 0.03413026034832001\n",
      "Epoch 183: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0349, train_loss_epoch=0.0341]Epoch 183: Train Loss = 0.03485912084579468\n",
      "Epoch 184: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0346, train_loss_epoch=0.0349]Epoch 184: Train Loss = 0.03456300124526024\n",
      "Epoch 185: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0337, train_loss_epoch=0.0346]Epoch 185: Train Loss = 0.0336664542555809\n",
      "Epoch 186: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0335, train_loss_epoch=0.0337]Epoch 186: Train Loss = 0.03350204601883888\n",
      "Epoch 187: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.034, train_loss_epoch=0.0335] Epoch 187: Train Loss = 0.0339820496737957\n",
      "Epoch 188: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0327, train_loss_epoch=0.034]Epoch 188: Train Loss = 0.03271883353590965\n",
      "Epoch 189: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0327, train_loss_epoch=0.0327]Epoch 189: Train Loss = 0.03266632929444313\n",
      "Epoch 190: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0343, train_loss_epoch=0.0327]Epoch 190: Train Loss = 0.03430831432342529\n",
      "Epoch 191: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0334, train_loss_epoch=0.0343]Epoch 191: Train Loss = 0.033365990966558456\n",
      "Epoch 192: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0329, train_loss_epoch=0.0334]Epoch 192: Train Loss = 0.03294723853468895\n",
      "Epoch 193: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0342, train_loss_epoch=0.0329]Epoch 193: Train Loss = 0.03420061245560646\n",
      "Epoch 194: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.034, train_loss_epoch=0.0342] Epoch 194: Train Loss = 0.034047652035951614\n",
      "Epoch 195: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0326, train_loss_epoch=0.034]Epoch 195: Train Loss = 0.032564882189035416\n",
      "Epoch 196: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0357, train_loss_epoch=0.0326]Epoch 196: Train Loss = 0.03568868339061737\n",
      "Epoch 197: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0337, train_loss_epoch=0.0357]Epoch 197: Train Loss = 0.03366754204034805\n",
      "Epoch 198: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0331, train_loss_epoch=0.0337]Epoch 198: Train Loss = 0.033087871968746185\n",
      "Epoch 199: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0321, train_loss_epoch=0.0331]Epoch 199: Train Loss = 0.03206801414489746\n",
      "Epoch 200: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0352, train_loss_epoch=0.0321]Epoch 200: Train Loss = 0.03519685938954353\n",
      "Epoch 201: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0328, train_loss_epoch=0.0352]Epoch 201: Train Loss = 0.03282201662659645\n",
      "Epoch 202: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0341, train_loss_epoch=0.0328]Epoch 202: Train Loss = 0.034078240394592285\n",
      "Epoch 203: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0321, train_loss_epoch=0.0341]Epoch 203: Train Loss = 0.03207112476229668\n",
      "Epoch 204: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0336, train_loss_epoch=0.0321]Epoch 204: Train Loss = 0.033585499972105026\n",
      "Epoch 205: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0337, train_loss_epoch=0.0336]Epoch 205: Train Loss = 0.03372557461261749\n",
      "Epoch 206: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0407, train_loss_epoch=0.0337]Epoch 206: Train Loss = 0.04067514091730118\n",
      "Epoch 207: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0313, train_loss_epoch=0.0407]Epoch 207: Train Loss = 0.031284939497709274\n",
      "Epoch 208: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0347, train_loss_epoch=0.0313]Epoch 208: Train Loss = 0.034662358462810516\n",
      "Epoch 209: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.033, train_loss_epoch=0.0347] Epoch 209: Train Loss = 0.03302149847149849\n",
      "Epoch 210: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0381, train_loss_epoch=0.033]Epoch 210: Train Loss = 0.038139425218105316\n",
      "Epoch 211: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.032, train_loss_epoch=0.0381] Epoch 211: Train Loss = 0.03201907500624657\n",
      "Epoch 212: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0354, train_loss_epoch=0.032]Epoch 212: Train Loss = 0.03540822118520737\n",
      "Epoch 213: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0337, train_loss_epoch=0.0354]Epoch 213: Train Loss = 0.0336572602391243\n",
      "Epoch 214: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0346, train_loss_epoch=0.0337]Epoch 214: Train Loss = 0.03459761664271355\n",
      "Epoch 215: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0361, train_loss_epoch=0.0346]Epoch 215: Train Loss = 0.03613222390413284\n",
      "Epoch 216: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0344, train_loss_epoch=0.0361]Epoch 216: Train Loss = 0.03438330814242363\n",
      "Epoch 217: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0326, train_loss_epoch=0.0344]Epoch 217: Train Loss = 0.032646212726831436\n",
      "Epoch 218: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0312, train_loss_epoch=0.0326]Epoch 218: Train Loss = 0.03117944858968258\n",
      "Epoch 219: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0383, train_loss_epoch=0.0312]Epoch 219: Train Loss = 0.038261402398347855\n",
      "Epoch 220: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0307, train_loss_epoch=0.0383]Epoch 220: Train Loss = 0.030736075714230537\n",
      "Epoch 221: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0363, train_loss_epoch=0.0307]Epoch 221: Train Loss = 0.036304887384176254\n",
      "Epoch 222: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0316, train_loss_epoch=0.0363]Epoch 222: Train Loss = 0.031614817678928375\n",
      "Epoch 223: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0359, train_loss_epoch=0.0316]Epoch 223: Train Loss = 0.03589339181780815\n",
      "Epoch 224: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0332, train_loss_epoch=0.0359]Epoch 224: Train Loss = 0.03323590010404587\n",
      "Epoch 225: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0415, train_loss_epoch=0.0332]Epoch 225: Train Loss = 0.04154110327363014\n",
      "Epoch 226: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0322, train_loss_epoch=0.0415]Epoch 226: Train Loss = 0.032245878130197525\n",
      "Epoch 227: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0359, train_loss_epoch=0.0322]Epoch 227: Train Loss = 0.03591528162360191\n",
      "Epoch 228: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=165, train_loss_step=0.0325, train_loss_epoch=0.0359]Epoch 228: Train Loss = 0.03250063955783844\n",
      "Epoch 229: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0312, train_loss_epoch=0.0325]Epoch 229: Train Loss = 0.031207283958792686\n",
      "Epoch 230: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0303, train_loss_epoch=0.0312]Epoch 230: Train Loss = 0.030291598290205002\n",
      "Epoch 231: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0341, train_loss_epoch=0.0303]Epoch 231: Train Loss = 0.03406171873211861\n",
      "Epoch 232: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0325, train_loss_epoch=0.0341]Epoch 232: Train Loss = 0.032543156296014786\n",
      "Epoch 233: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0354, train_loss_epoch=0.0325]Epoch 233: Train Loss = 0.035386938601732254\n",
      "Epoch 234: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0312, train_loss_epoch=0.0354]Epoch 234: Train Loss = 0.03118261881172657\n",
      "Epoch 235: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0314, train_loss_epoch=0.0312]Epoch 235: Train Loss = 0.031424250453710556\n",
      "Epoch 236: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0318, train_loss_epoch=0.0314]Epoch 236: Train Loss = 0.03179012984037399\n",
      "Epoch 237: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.0315, train_loss_epoch=0.0318]Epoch 237: Train Loss = 0.03145555779337883\n",
      "Epoch 238: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0357, train_loss_epoch=0.0315]Epoch 238: Train Loss = 0.03568200767040253\n",
      "Epoch 239: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=165, train_loss_step=0.032, train_loss_epoch=0.0357] Epoch 239: Train Loss = 0.03201168775558472\n",
      "Epoch 240: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.032, train_loss_epoch=0.032] Epoch 240: Train Loss = 0.03202897310256958\n",
      "Epoch 241: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.030, train_loss_epoch=0.032]Epoch 241: Train Loss = 0.030030716210603714\n",
      "Epoch 242: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0316, train_loss_epoch=0.030]Epoch 242: Train Loss = 0.03160720691084862\n",
      "Epoch 243: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0302, train_loss_epoch=0.0316]Epoch 243: Train Loss = 0.03024749830365181\n",
      "Epoch 244: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0299, train_loss_epoch=0.0302]Epoch 244: Train Loss = 0.029907124117016792\n",
      "Epoch 245: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.031, train_loss_epoch=0.0299] Epoch 245: Train Loss = 0.03098706528544426\n",
      "Epoch 246: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0294, train_loss_epoch=0.031]Epoch 246: Train Loss = 0.029445085674524307\n",
      "Epoch 247: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=165, train_loss_step=0.0316, train_loss_epoch=0.0294]Epoch 247: Train Loss = 0.03164936229586601\n",
      "Epoch 248: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=165, train_loss_step=0.030, train_loss_epoch=0.0316] Epoch 248: Train Loss = 0.030033772811293602\n",
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0308, train_loss_epoch=0.030]Epoch 249: Train Loss = 0.030775653198361397\n",
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0308, train_loss_epoch=0.0308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=165, train_loss_step=0.0308, train_loss_epoch=0.0308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 5: from 1998-11-02 00:00:00 to 2022-02-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.399]Epoch 0: Train Loss = 0.398878276348114\n",
      "Epoch 1: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.498, train_loss_epoch=0.399]Epoch 1: Train Loss = 0.49849191308021545\n",
      "Epoch 2: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.373, train_loss_epoch=0.498]Epoch 2: Train Loss = 0.3730452358722687\n",
      "Epoch 3: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.251, train_loss_epoch=0.373]Epoch 3: Train Loss = 0.25081124901771545\n",
      "Epoch 4: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.309, train_loss_epoch=0.251]Epoch 4: Train Loss = 0.3086529076099396\n",
      "Epoch 5: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.303, train_loss_epoch=0.309]Epoch 5: Train Loss = 0.3029225468635559\n",
      "Epoch 6: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.251, train_loss_epoch=0.303]Epoch 6: Train Loss = 0.2506124675273895\n",
      "Epoch 7: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.247, train_loss_epoch=0.251]Epoch 7: Train Loss = 0.2470174878835678\n",
      "Epoch 8: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.266, train_loss_epoch=0.247]Epoch 8: Train Loss = 0.2659001052379608\n",
      "Epoch 9: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.258, train_loss_epoch=0.266]Epoch 9: Train Loss = 0.2577272355556488\n",
      "Epoch 10: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.236, train_loss_epoch=0.258]Epoch 10: Train Loss = 0.23604416847229004\n",
      "Epoch 11: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.223, train_loss_epoch=0.236]Epoch 11: Train Loss = 0.22323663532733917\n",
      "Epoch 12: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.237, train_loss_epoch=0.223]Epoch 12: Train Loss = 0.2367250770330429\n",
      "Epoch 13: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=185, train_loss_step=0.219, train_loss_epoch=0.237]Epoch 13: Train Loss = 0.21891894936561584\n",
      "Epoch 14: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.212, train_loss_epoch=0.219]Epoch 14: Train Loss = 0.21192653477191925\n",
      "Epoch 15: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.189, train_loss_epoch=0.212]Epoch 15: Train Loss = 0.18948712944984436\n",
      "Epoch 16: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.198, train_loss_epoch=0.189]Epoch 16: Train Loss = 0.19799543917179108\n",
      "Epoch 17: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.188, train_loss_epoch=0.198]Epoch 17: Train Loss = 0.18849970400333405\n",
      "Epoch 18: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.195, train_loss_epoch=0.188]Epoch 18: Train Loss = 0.1949225515127182\n",
      "Epoch 19: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.172, train_loss_epoch=0.195]Epoch 19: Train Loss = 0.17235122621059418\n",
      "Epoch 20: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.168, train_loss_epoch=0.172]Epoch 20: Train Loss = 0.1677117794752121\n",
      "Epoch 21: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.182, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.18199388682842255\n",
      "Epoch 22: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.175, train_loss_epoch=0.182]Epoch 22: Train Loss = 0.1750696301460266\n",
      "Epoch 23: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.165, train_loss_epoch=0.175]Epoch 23: Train Loss = 0.16542905569076538\n",
      "Epoch 24: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.156, train_loss_epoch=0.165]Epoch 24: Train Loss = 0.15616735816001892\n",
      "Epoch 25: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.155, train_loss_epoch=0.156]Epoch 25: Train Loss = 0.1546173393726349\n",
      "Epoch 26: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.161, train_loss_epoch=0.155]Epoch 26: Train Loss = 0.16102607548236847\n",
      "Epoch 27: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.151, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.15070447325706482\n",
      "Epoch 28: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.146, train_loss_epoch=0.151]Epoch 28: Train Loss = 0.14556661248207092\n",
      "Epoch 29: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.149, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.14935074746608734\n",
      "Epoch 30: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.141, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.14101633429527283\n",
      "Epoch 31: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.140, train_loss_epoch=0.141]Epoch 31: Train Loss = 0.13976822793483734\n",
      "Epoch 32: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.138, train_loss_epoch=0.140]Epoch 32: Train Loss = 0.13788318634033203\n",
      "Epoch 33: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.133, train_loss_epoch=0.138]Epoch 33: Train Loss = 0.1330268681049347\n",
      "Epoch 34: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.131, train_loss_epoch=0.133]Epoch 34: Train Loss = 0.13058283925056458\n",
      "Epoch 35: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.130, train_loss_epoch=0.131]Epoch 35: Train Loss = 0.1300998330116272\n",
      "Epoch 36: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.128, train_loss_epoch=0.130]Epoch 36: Train Loss = 0.12808716297149658\n",
      "Epoch 37: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.130, train_loss_epoch=0.128]Epoch 37: Train Loss = 0.12969784438610077\n",
      "Epoch 38: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=185, train_loss_step=0.121, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12106593698263168\n",
      "Epoch 39: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.117, train_loss_epoch=0.121]Epoch 39: Train Loss = 0.11659640073776245\n",
      "Epoch 40: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.115, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11542682349681854\n",
      "Epoch 41: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.118, train_loss_epoch=0.115]Epoch 41: Train Loss = 0.11756512522697449\n",
      "Epoch 42: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.113, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.11299069225788116\n",
      "Epoch 43: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=185, train_loss_step=0.109, train_loss_epoch=0.113]Epoch 43: Train Loss = 0.10868530720472336\n",
      "Epoch 44: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.113, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.1128741130232811\n",
      "Epoch 45: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.105, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10529033839702606\n",
      "Epoch 46: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.105, train_loss_epoch=0.105]Epoch 46: Train Loss = 0.10466258972883224\n",
      "Epoch 47: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.102, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10179964452981949\n",
      "Epoch 48: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.101, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.10119322687387466\n",
      "Epoch 49: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=185, train_loss_step=0.102, train_loss_epoch=0.101]Epoch 49: Train Loss = 0.10174037516117096\n",
      "Epoch 50: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0991, train_loss_epoch=0.102]Epoch 50: Train Loss = 0.0990975871682167\n",
      "Epoch 51: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.096, train_loss_epoch=0.0991] Epoch 51: Train Loss = 0.09603536874055862\n",
      "Epoch 52: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.096, train_loss_epoch=0.096] Epoch 52: Train Loss = 0.09602788835763931\n",
      "Epoch 53: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0926, train_loss_epoch=0.096]Epoch 53: Train Loss = 0.09264267235994339\n",
      "Epoch 54: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0922, train_loss_epoch=0.0926]Epoch 54: Train Loss = 0.09221168607473373\n",
      "Epoch 55: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=185, train_loss_step=0.0916, train_loss_epoch=0.0922]Epoch 55: Train Loss = 0.09162352979183197\n",
      "Epoch 56: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0909, train_loss_epoch=0.0916]Epoch 56: Train Loss = 0.09090597182512283\n",
      "Epoch 57: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0849, train_loss_epoch=0.0909]Epoch 57: Train Loss = 0.0848531648516655\n",
      "Epoch 58: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0885, train_loss_epoch=0.0849]Epoch 58: Train Loss = 0.08848880976438522\n",
      "Epoch 59: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0841, train_loss_epoch=0.0885]Epoch 59: Train Loss = 0.084140345454216\n",
      "Epoch 60: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0841, train_loss_epoch=0.0841]Epoch 60: Train Loss = 0.08407968282699585\n",
      "Epoch 61: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0814, train_loss_epoch=0.0841]Epoch 61: Train Loss = 0.08144836127758026\n",
      "Epoch 62: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0796, train_loss_epoch=0.0814]Epoch 62: Train Loss = 0.0796007513999939\n",
      "Epoch 63: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0815, train_loss_epoch=0.0796]Epoch 63: Train Loss = 0.08150742202997208\n",
      "Epoch 64: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0772, train_loss_epoch=0.0815]Epoch 64: Train Loss = 0.07718148827552795\n",
      "Epoch 65: 100%|██████████| 1/1 [00:04<00:00,  0.25it/s, v_num=185, train_loss_step=0.0775, train_loss_epoch=0.0772]Epoch 65: Train Loss = 0.07750611752271652\n",
      "Epoch 66: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0757, train_loss_epoch=0.0775]Epoch 66: Train Loss = 0.07565809041261673\n",
      "Epoch 67: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0756, train_loss_epoch=0.0757]Epoch 67: Train Loss = 0.07560359686613083\n",
      "Epoch 68: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0737, train_loss_epoch=0.0756]Epoch 68: Train Loss = 0.0736827626824379\n",
      "Epoch 69: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0701, train_loss_epoch=0.0737]Epoch 69: Train Loss = 0.07013591378927231\n",
      "Epoch 70: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0717, train_loss_epoch=0.0701]Epoch 70: Train Loss = 0.07170382142066956\n",
      "Epoch 71: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0688, train_loss_epoch=0.0717]Epoch 71: Train Loss = 0.06882729381322861\n",
      "Epoch 72: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0692, train_loss_epoch=0.0688]Epoch 72: Train Loss = 0.06923794001340866\n",
      "Epoch 73: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0688, train_loss_epoch=0.0692]Epoch 73: Train Loss = 0.06882284581661224\n",
      "Epoch 74: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0691, train_loss_epoch=0.0688]Epoch 74: Train Loss = 0.06914485991001129\n",
      "Epoch 75: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0647, train_loss_epoch=0.0691]Epoch 75: Train Loss = 0.06467000395059586\n",
      "Epoch 76: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0685, train_loss_epoch=0.0647]Epoch 76: Train Loss = 0.06847736239433289\n",
      "Epoch 77: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0654, train_loss_epoch=0.0685]Epoch 77: Train Loss = 0.06541703641414642\n",
      "Epoch 78: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0645, train_loss_epoch=0.0654]Epoch 78: Train Loss = 0.06447777897119522\n",
      "Epoch 79: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0633, train_loss_epoch=0.0645]Epoch 79: Train Loss = 0.06333138048648834\n",
      "Epoch 80: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0641, train_loss_epoch=0.0633]Epoch 80: Train Loss = 0.06408241391181946\n",
      "Epoch 81: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0616, train_loss_epoch=0.0641]Epoch 81: Train Loss = 0.061593521386384964\n",
      "Epoch 82: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.065, train_loss_epoch=0.0616] Epoch 82: Train Loss = 0.06499649584293365\n",
      "Epoch 83: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.060, train_loss_epoch=0.065] Epoch 83: Train Loss = 0.060000840574502945\n",
      "Epoch 84: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0613, train_loss_epoch=0.060]Epoch 84: Train Loss = 0.061295993626117706\n",
      "Epoch 85: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0583, train_loss_epoch=0.0613]Epoch 85: Train Loss = 0.058256279677152634\n",
      "Epoch 86: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0581, train_loss_epoch=0.0583]Epoch 86: Train Loss = 0.058054205030202866\n",
      "Epoch 87: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0586, train_loss_epoch=0.0581]Epoch 87: Train Loss = 0.058647271245718\n",
      "Epoch 88: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0583, train_loss_epoch=0.0586]Epoch 88: Train Loss = 0.05826183781027794\n",
      "Epoch 89: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0564, train_loss_epoch=0.0583]Epoch 89: Train Loss = 0.05635810270905495\n",
      "Epoch 90: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0561, train_loss_epoch=0.0564]Epoch 90: Train Loss = 0.056115858256816864\n",
      "Epoch 91: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0551, train_loss_epoch=0.0561]Epoch 91: Train Loss = 0.05513159558176994\n",
      "Epoch 92: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.056, train_loss_epoch=0.0551] Epoch 92: Train Loss = 0.05603193864226341\n",
      "Epoch 93: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0533, train_loss_epoch=0.056]Epoch 93: Train Loss = 0.05331742390990257\n",
      "Epoch 94: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0532, train_loss_epoch=0.0533]Epoch 94: Train Loss = 0.0531560555100441\n",
      "Epoch 95: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0515, train_loss_epoch=0.0532]Epoch 95: Train Loss = 0.05153822526335716\n",
      "Epoch 96: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.055, train_loss_epoch=0.0515] Epoch 96: Train Loss = 0.05500015988945961\n",
      "Epoch 97: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0518, train_loss_epoch=0.055]Epoch 97: Train Loss = 0.051836371421813965\n",
      "Epoch 98: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.055, train_loss_epoch=0.0518] Epoch 98: Train Loss = 0.0549975223839283\n",
      "Epoch 99: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0509, train_loss_epoch=0.055]Epoch 99: Train Loss = 0.050925303250551224\n",
      "Epoch 100: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0562, train_loss_epoch=0.0509]Epoch 100: Train Loss = 0.056155119091272354\n",
      "Epoch 101: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0498, train_loss_epoch=0.0562]Epoch 101: Train Loss = 0.04976753145456314\n",
      "Epoch 102: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0548, train_loss_epoch=0.0498]Epoch 102: Train Loss = 0.05480125546455383\n",
      "Epoch 103: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0493, train_loss_epoch=0.0548]Epoch 103: Train Loss = 0.04932593181729317\n",
      "Epoch 104: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0533, train_loss_epoch=0.0493]Epoch 104: Train Loss = 0.05326027050614357\n",
      "Epoch 105: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0499, train_loss_epoch=0.0533]Epoch 105: Train Loss = 0.04988976940512657\n",
      "Epoch 106: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0501, train_loss_epoch=0.0499]Epoch 106: Train Loss = 0.05009693652391434\n",
      "Epoch 107: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0475, train_loss_epoch=0.0501]Epoch 107: Train Loss = 0.04753676429390907\n",
      "Epoch 108: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0537, train_loss_epoch=0.0475]Epoch 108: Train Loss = 0.05369291082024574\n",
      "Epoch 109: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0469, train_loss_epoch=0.0537]Epoch 109: Train Loss = 0.04692651331424713\n",
      "Epoch 110: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=185, train_loss_step=0.050, train_loss_epoch=0.0469] Epoch 110: Train Loss = 0.04998352751135826\n",
      "Epoch 111: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0459, train_loss_epoch=0.050]Epoch 111: Train Loss = 0.04592205211520195\n",
      "Epoch 112: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0466, train_loss_epoch=0.0459]Epoch 112: Train Loss = 0.046580906957387924\n",
      "Epoch 113: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0476, train_loss_epoch=0.0466]Epoch 113: Train Loss = 0.04763861745595932\n",
      "Epoch 114: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0458, train_loss_epoch=0.0476]Epoch 114: Train Loss = 0.04584240913391113\n",
      "Epoch 115: 100%|██████████| 1/1 [00:03<00:00,  0.30it/s, v_num=185, train_loss_step=0.0457, train_loss_epoch=0.0458]Epoch 115: Train Loss = 0.045666661113500595\n",
      "Epoch 116: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0446, train_loss_epoch=0.0457]Epoch 116: Train Loss = 0.04460771754384041\n",
      "Epoch 117: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0446, train_loss_epoch=0.0446]Epoch 117: Train Loss = 0.04456264525651932\n",
      "Epoch 118: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.044, train_loss_epoch=0.0446] Epoch 118: Train Loss = 0.043979108333587646\n",
      "Epoch 119: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0447, train_loss_epoch=0.044]Epoch 119: Train Loss = 0.04471953585743904\n",
      "Epoch 120: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0432, train_loss_epoch=0.0447]Epoch 120: Train Loss = 0.04317173361778259\n",
      "Epoch 121: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0466, train_loss_epoch=0.0432]Epoch 121: Train Loss = 0.04658851400017738\n",
      "Epoch 122: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0437, train_loss_epoch=0.0466]Epoch 122: Train Loss = 0.04370860382914543\n",
      "Epoch 123: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0451, train_loss_epoch=0.0437]Epoch 123: Train Loss = 0.04506002739071846\n",
      "Epoch 124: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0451, train_loss_epoch=0.0451]Epoch 124: Train Loss = 0.04505414515733719\n",
      "Epoch 125: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.044, train_loss_epoch=0.0451] Epoch 125: Train Loss = 0.04398417845368385\n",
      "Epoch 126: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0446, train_loss_epoch=0.044]Epoch 126: Train Loss = 0.04462861269712448\n",
      "Epoch 127: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0434, train_loss_epoch=0.0446]Epoch 127: Train Loss = 0.04339060187339783\n",
      "Epoch 128: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0444, train_loss_epoch=0.0434]Epoch 128: Train Loss = 0.04436106234788895\n",
      "Epoch 129: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.042, train_loss_epoch=0.0444] Epoch 129: Train Loss = 0.04202936589717865\n",
      "Epoch 130: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0425, train_loss_epoch=0.042]Epoch 130: Train Loss = 0.042493563145399094\n",
      "Epoch 131: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0416, train_loss_epoch=0.0425]Epoch 131: Train Loss = 0.0415840819478035\n",
      "Epoch 132: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0421, train_loss_epoch=0.0416]Epoch 132: Train Loss = 0.042051877826452255\n",
      "Epoch 133: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0403, train_loss_epoch=0.0421]Epoch 133: Train Loss = 0.0403115339577198\n",
      "Epoch 134: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0412, train_loss_epoch=0.0403]Epoch 134: Train Loss = 0.041151564568281174\n",
      "Epoch 135: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0398, train_loss_epoch=0.0412]Epoch 135: Train Loss = 0.03978821262717247\n",
      "Epoch 136: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0425, train_loss_epoch=0.0398]Epoch 136: Train Loss = 0.042479146271944046\n",
      "Epoch 137: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0396, train_loss_epoch=0.0425]Epoch 137: Train Loss = 0.03957879915833473\n",
      "Epoch 138: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0407, train_loss_epoch=0.0396]Epoch 138: Train Loss = 0.04069206491112709\n",
      "Epoch 139: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0397, train_loss_epoch=0.0407]Epoch 139: Train Loss = 0.039697159081697464\n",
      "Epoch 140: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0409, train_loss_epoch=0.0397]Epoch 140: Train Loss = 0.04085738956928253\n",
      "Epoch 141: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0402, train_loss_epoch=0.0409]Epoch 141: Train Loss = 0.040156107395887375\n",
      "Epoch 142: 100%|██████████| 1/1 [00:03<00:00,  0.29it/s, v_num=185, train_loss_step=0.0466, train_loss_epoch=0.0402]Epoch 142: Train Loss = 0.04656665027141571\n",
      "Epoch 143: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0411, train_loss_epoch=0.0466]Epoch 143: Train Loss = 0.04114684835076332\n",
      "Epoch 144: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0438, train_loss_epoch=0.0411]Epoch 144: Train Loss = 0.0438266284763813\n",
      "Epoch 145: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0401, train_loss_epoch=0.0438]Epoch 145: Train Loss = 0.040111493319272995\n",
      "Epoch 146: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0416, train_loss_epoch=0.0401]Epoch 146: Train Loss = 0.041556745767593384\n",
      "Epoch 147: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0382, train_loss_epoch=0.0416]Epoch 147: Train Loss = 0.038188159465789795\n",
      "Epoch 148: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0384, train_loss_epoch=0.0382]Epoch 148: Train Loss = 0.03842411935329437\n",
      "Epoch 149: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0376, train_loss_epoch=0.0384]Epoch 149: Train Loss = 0.03759729489684105\n",
      "Epoch 150: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0382, train_loss_epoch=0.0376]Epoch 150: Train Loss = 0.038219742476940155\n",
      "Epoch 151: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0375, train_loss_epoch=0.0382]Epoch 151: Train Loss = 0.037509262561798096\n",
      "Epoch 152: 100%|██████████| 1/1 [00:03<00:00,  0.28it/s, v_num=185, train_loss_step=0.0401, train_loss_epoch=0.0375]Epoch 152: Train Loss = 0.040075648576021194\n",
      "Epoch 153: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0366, train_loss_epoch=0.0401]Epoch 153: Train Loss = 0.03656554967164993\n",
      "Epoch 154: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0381, train_loss_epoch=0.0366]Epoch 154: Train Loss = 0.03810998052358627\n",
      "Epoch 155: 100%|██████████| 1/1 [00:03<00:00,  0.26it/s, v_num=185, train_loss_step=0.0365, train_loss_epoch=0.0381]Epoch 155: Train Loss = 0.03648556396365166\n",
      "Epoch 156: 100%|██████████| 1/1 [00:03<00:00,  0.27it/s, v_num=185, train_loss_step=0.0365, train_loss_epoch=0.0365]Epoch 156: Train Loss = 0.036491136997938156\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.36it/s, v_num=185, train_loss_step=0.0368, train_loss_epoch=0.0365]Epoch 157: Train Loss = 0.036796316504478455\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=185, train_loss_step=0.0381, train_loss_epoch=0.0368]Epoch 158: Train Loss = 0.03812597692012787\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0373, train_loss_epoch=0.0381]Epoch 159: Train Loss = 0.03729581832885742\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0374, train_loss_epoch=0.0373]Epoch 160: Train Loss = 0.037437476217746735\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0366, train_loss_epoch=0.0374]Epoch 161: Train Loss = 0.03662927821278572\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.0363, train_loss_epoch=0.0366]Epoch 162: Train Loss = 0.03630254045128822\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0365, train_loss_epoch=0.0363]Epoch 163: Train Loss = 0.03652414306998253\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0354, train_loss_epoch=0.0365]Epoch 164: Train Loss = 0.035369668155908585\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0358, train_loss_epoch=0.0354]Epoch 165: Train Loss = 0.035833608359098434\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0384, train_loss_epoch=0.0358]Epoch 166: Train Loss = 0.03840288519859314\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0369, train_loss_epoch=0.0384]Epoch 167: Train Loss = 0.03688610717654228\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0353, train_loss_epoch=0.0369]Epoch 168: Train Loss = 0.035290900617837906\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0355, train_loss_epoch=0.0353]Epoch 169: Train Loss = 0.03546500578522682\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.035, train_loss_epoch=0.0355] Epoch 170: Train Loss = 0.0349646732211113\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0358, train_loss_epoch=0.035]Epoch 171: Train Loss = 0.03580371290445328\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.0337, train_loss_epoch=0.0358]Epoch 172: Train Loss = 0.03371022641658783\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0396, train_loss_epoch=0.0337]Epoch 173: Train Loss = 0.0395965538918972\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0343, train_loss_epoch=0.0396]Epoch 174: Train Loss = 0.03429083153605461\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0388, train_loss_epoch=0.0343]Epoch 175: Train Loss = 0.038819313049316406\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0354, train_loss_epoch=0.0388]Epoch 176: Train Loss = 0.03541328012943268\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0348, train_loss_epoch=0.0354]Epoch 177: Train Loss = 0.0348227322101593\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=185, train_loss_step=0.0356, train_loss_epoch=0.0348]Epoch 178: Train Loss = 0.035554543137550354\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=185, train_loss_step=0.0348, train_loss_epoch=0.0356]Epoch 179: Train Loss = 0.034799836575984955\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=185, train_loss_step=0.0335, train_loss_epoch=0.0348]Epoch 180: Train Loss = 0.03350808471441269\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0347, train_loss_epoch=0.0335]Epoch 181: Train Loss = 0.034717027097940445\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0351, train_loss_epoch=0.0347]Epoch 182: Train Loss = 0.035132795572280884\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=185, train_loss_step=0.0358, train_loss_epoch=0.0351]Epoch 183: Train Loss = 0.03584451600909233\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0369, train_loss_epoch=0.0358]Epoch 184: Train Loss = 0.036944735795259476\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=185, train_loss_step=0.0342, train_loss_epoch=0.0369]Epoch 185: Train Loss = 0.034208256751298904\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0365, train_loss_epoch=0.0342]Epoch 186: Train Loss = 0.03653740510344505\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.034, train_loss_epoch=0.0365] Epoch 187: Train Loss = 0.03402000293135643\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0354, train_loss_epoch=0.034]Epoch 188: Train Loss = 0.03540947288274765\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0331, train_loss_epoch=0.0354]Epoch 189: Train Loss = 0.03311432525515556\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0342, train_loss_epoch=0.0331]Epoch 190: Train Loss = 0.034239064902067184\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0327, train_loss_epoch=0.0342]Epoch 191: Train Loss = 0.032712314277887344\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=185, train_loss_step=0.0344, train_loss_epoch=0.0327]Epoch 192: Train Loss = 0.034373436123132706\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0341, train_loss_epoch=0.0344]Epoch 193: Train Loss = 0.03411787003278732\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0336, train_loss_epoch=0.0341]Epoch 194: Train Loss = 0.033554743975400925\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=185, train_loss_step=0.0331, train_loss_epoch=0.0336]Epoch 195: Train Loss = 0.03311298415064812\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0336, train_loss_epoch=0.0331]Epoch 196: Train Loss = 0.03363925591111183\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=185, train_loss_step=0.0328, train_loss_epoch=0.0336]Epoch 197: Train Loss = 0.03283141180872917\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.0339, train_loss_epoch=0.0328]Epoch 198: Train Loss = 0.033943161368370056\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0326, train_loss_epoch=0.0339]Epoch 199: Train Loss = 0.032595615833997726\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0333, train_loss_epoch=0.0326]Epoch 200: Train Loss = 0.03333818539977074\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0325, train_loss_epoch=0.0333]Epoch 201: Train Loss = 0.03246711567044258\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0362, train_loss_epoch=0.0325]Epoch 202: Train Loss = 0.03624949976801872\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0328, train_loss_epoch=0.0362]Epoch 203: Train Loss = 0.032802511006593704\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.0354, train_loss_epoch=0.0328]Epoch 204: Train Loss = 0.035399358719587326\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0324, train_loss_epoch=0.0354]Epoch 205: Train Loss = 0.032433394342660904\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0374, train_loss_epoch=0.0324]Epoch 206: Train Loss = 0.03737267106771469\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0323, train_loss_epoch=0.0374]Epoch 207: Train Loss = 0.03229182958602905\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0391, train_loss_epoch=0.0323]Epoch 208: Train Loss = 0.03910708799958229\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0322, train_loss_epoch=0.0391]Epoch 209: Train Loss = 0.032210081815719604\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.0444, train_loss_epoch=0.0322]Epoch 210: Train Loss = 0.04436538740992546\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0335, train_loss_epoch=0.0444]Epoch 211: Train Loss = 0.0335470512509346\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0357, train_loss_epoch=0.0335]Epoch 212: Train Loss = 0.035738468170166016\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0388, train_loss_epoch=0.0357]Epoch 213: Train Loss = 0.038773633539676666\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0309, train_loss_epoch=0.0388]Epoch 214: Train Loss = 0.030888911336660385\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0436, train_loss_epoch=0.0309]Epoch 215: Train Loss = 0.04358315095305443\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0332, train_loss_epoch=0.0436]Epoch 216: Train Loss = 0.03323504701256752\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.0402, train_loss_epoch=0.0332]Epoch 217: Train Loss = 0.04016828164458275\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0356, train_loss_epoch=0.0402]Epoch 218: Train Loss = 0.035619813948869705\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0329, train_loss_epoch=0.0356]Epoch 219: Train Loss = 0.03286626935005188\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0368, train_loss_epoch=0.0329]Epoch 220: Train Loss = 0.036835793405771255\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0304, train_loss_epoch=0.0368]Epoch 221: Train Loss = 0.030358146876096725\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0316, train_loss_epoch=0.0304]Epoch 222: Train Loss = 0.03160317614674568\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.035, train_loss_epoch=0.0316] Epoch 223: Train Loss = 0.0350339338183403\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0311, train_loss_epoch=0.035]Epoch 224: Train Loss = 0.031090015545487404\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.038, train_loss_epoch=0.0311] Epoch 225: Train Loss = 0.03802955895662308\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0297, train_loss_epoch=0.038]Epoch 226: Train Loss = 0.029653403908014297\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0313, train_loss_epoch=0.0297]Epoch 227: Train Loss = 0.03130447492003441\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0312, train_loss_epoch=0.0313]Epoch 228: Train Loss = 0.031233979389071465\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0327, train_loss_epoch=0.0312]Epoch 229: Train Loss = 0.0327276736497879\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0301, train_loss_epoch=0.0327]Epoch 230: Train Loss = 0.030071921646595\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0307, train_loss_epoch=0.0301]Epoch 231: Train Loss = 0.030747583135962486\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0307, train_loss_epoch=0.0307]Epoch 232: Train Loss = 0.030700867995619774\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=185, train_loss_step=0.0317, train_loss_epoch=0.0307]Epoch 233: Train Loss = 0.0316988006234169\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0305, train_loss_epoch=0.0317]Epoch 234: Train Loss = 0.030462058261036873\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0317, train_loss_epoch=0.0305]Epoch 235: Train Loss = 0.031693898141384125\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.0307, train_loss_epoch=0.0317]Epoch 236: Train Loss = 0.03072318248450756\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0326, train_loss_epoch=0.0307]Epoch 237: Train Loss = 0.032624006271362305\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0307, train_loss_epoch=0.0326]Epoch 238: Train Loss = 0.030710555613040924\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0325, train_loss_epoch=0.0307]Epoch 239: Train Loss = 0.03252866864204407\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0298, train_loss_epoch=0.0325]Epoch 240: Train Loss = 0.02981877699494362\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0308, train_loss_epoch=0.0298]Epoch 241: Train Loss = 0.030833544209599495\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0301, train_loss_epoch=0.0308]Epoch 242: Train Loss = 0.030119113624095917\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.0304, train_loss_epoch=0.0301]Epoch 243: Train Loss = 0.03043719194829464\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0359, train_loss_epoch=0.0304]Epoch 244: Train Loss = 0.03593054041266441\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0291, train_loss_epoch=0.0359]Epoch 245: Train Loss = 0.029118038713932037\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0405, train_loss_epoch=0.0291]Epoch 246: Train Loss = 0.04046294093132019\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0303, train_loss_epoch=0.0405]Epoch 247: Train Loss = 0.030255800113081932\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0312, train_loss_epoch=0.0303]Epoch 248: Train Loss = 0.031239047646522522\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=185, train_loss_step=0.0339, train_loss_epoch=0.0312]Epoch 249: Train Loss = 0.03393282741308212\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.0339, train_loss_epoch=0.0339]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=185, train_loss_step=0.0339, train_loss_epoch=0.0339]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 6: from 1998-11-02 00:00:00 to 2022-02-17 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.397]Epoch 0: Train Loss = 0.3973892033100128\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.498, train_loss_epoch=0.397]Epoch 1: Train Loss = 0.49816733598709106\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.374, train_loss_epoch=0.498]Epoch 2: Train Loss = 0.3741784989833832\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.250, train_loss_epoch=0.374]Epoch 3: Train Loss = 0.2502664029598236\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.308, train_loss_epoch=0.250]Epoch 4: Train Loss = 0.30805206298828125\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.306, train_loss_epoch=0.308]Epoch 5: Train Loss = 0.30587729811668396\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.253, train_loss_epoch=0.306]Epoch 6: Train Loss = 0.2533963620662689\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.236, train_loss_epoch=0.253]Epoch 7: Train Loss = 0.23575541377067566\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.263, train_loss_epoch=0.236]Epoch 8: Train Loss = 0.262970894575119\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.257, train_loss_epoch=0.263]Epoch 9: Train Loss = 0.25697940587997437\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.239, train_loss_epoch=0.257]Epoch 10: Train Loss = 0.23937389254570007\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.215, train_loss_epoch=0.239]Epoch 11: Train Loss = 0.21530061960220337\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.232, train_loss_epoch=0.215]Epoch 12: Train Loss = 0.23169371485710144\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.221, train_loss_epoch=0.232]Epoch 13: Train Loss = 0.22119355201721191\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.212, train_loss_epoch=0.221]Epoch 14: Train Loss = 0.21160651743412018\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.188, train_loss_epoch=0.212]Epoch 15: Train Loss = 0.18823914229869843\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.197, train_loss_epoch=0.188]Epoch 16: Train Loss = 0.1973440796136856\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.188, train_loss_epoch=0.197]Epoch 17: Train Loss = 0.188100203871727\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.192, train_loss_epoch=0.188]Epoch 18: Train Loss = 0.1922420710325241\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.171, train_loss_epoch=0.192]Epoch 19: Train Loss = 0.17085343599319458\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.166, train_loss_epoch=0.171]Epoch 20: Train Loss = 0.16608667373657227\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.180, train_loss_epoch=0.166]Epoch 21: Train Loss = 0.18000006675720215\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.177, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.17690879106521606\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.164, train_loss_epoch=0.177]Epoch 23: Train Loss = 0.1640484482049942\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.157, train_loss_epoch=0.164]Epoch 24: Train Loss = 0.1572495549917221\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.153, train_loss_epoch=0.157]Epoch 25: Train Loss = 0.1533922553062439\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.161, train_loss_epoch=0.153]Epoch 26: Train Loss = 0.16084790229797363\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.152, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.15247754752635956\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.146, train_loss_epoch=0.152]Epoch 28: Train Loss = 0.1455240696668625\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.152, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.15163066983222961\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.140, train_loss_epoch=0.152]Epoch 30: Train Loss = 0.13988611102104187\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.139, train_loss_epoch=0.140]Epoch 31: Train Loss = 0.13903525471687317\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.137, train_loss_epoch=0.139]Epoch 32: Train Loss = 0.13681137561798096\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.133, train_loss_epoch=0.137]Epoch 33: Train Loss = 0.13264527916908264\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.132, train_loss_epoch=0.133]Epoch 34: Train Loss = 0.1317921280860901\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.133, train_loss_epoch=0.132]Epoch 35: Train Loss = 0.13278137147426605\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.127, train_loss_epoch=0.133]Epoch 36: Train Loss = 0.12717056274414062\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.129, train_loss_epoch=0.127]Epoch 37: Train Loss = 0.12867535650730133\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.122, train_loss_epoch=0.129]Epoch 38: Train Loss = 0.12234007567167282\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.119, train_loss_epoch=0.122]Epoch 39: Train Loss = 0.11853285878896713\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.116, train_loss_epoch=0.119]Epoch 40: Train Loss = 0.11625038087368011\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.119, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11946820467710495\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.118, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.1175505667924881\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.107, train_loss_epoch=0.118]Epoch 43: Train Loss = 0.10653190314769745\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.113, train_loss_epoch=0.107]Epoch 44: Train Loss = 0.11289039254188538\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.107, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10720488429069519\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.105, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10516227036714554\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.101, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10104566812515259\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.103, train_loss_epoch=0.101]Epoch 48: Train Loss = 0.10321522504091263\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.102, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.10199768096208572\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0993, train_loss_epoch=0.102]Epoch 50: Train Loss = 0.0993049144744873\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0958, train_loss_epoch=0.0993]Epoch 51: Train Loss = 0.0958029255270958\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0961, train_loss_epoch=0.0958]Epoch 52: Train Loss = 0.09609710425138474\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0934, train_loss_epoch=0.0961]Epoch 53: Train Loss = 0.0933976024389267\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.094, train_loss_epoch=0.0934] Epoch 54: Train Loss = 0.09396854788064957\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0913, train_loss_epoch=0.094]Epoch 55: Train Loss = 0.09129995852708817\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0914, train_loss_epoch=0.0913]Epoch 56: Train Loss = 0.0914229080080986\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0877, train_loss_epoch=0.0914]Epoch 57: Train Loss = 0.08765863627195358\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.087, train_loss_epoch=0.0877] Epoch 58: Train Loss = 0.0869901031255722\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0864, train_loss_epoch=0.087]Epoch 59: Train Loss = 0.08641158044338226\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0841, train_loss_epoch=0.0864]Epoch 60: Train Loss = 0.08410029858350754\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0805, train_loss_epoch=0.0841]Epoch 61: Train Loss = 0.08046897500753403\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.080, train_loss_epoch=0.0805] Epoch 62: Train Loss = 0.07998013496398926\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0796, train_loss_epoch=0.080]Epoch 63: Train Loss = 0.07960652559995651\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0769, train_loss_epoch=0.0796]Epoch 64: Train Loss = 0.07692606747150421\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0781, train_loss_epoch=0.0769]Epoch 65: Train Loss = 0.07814301550388336\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0757, train_loss_epoch=0.0781]Epoch 66: Train Loss = 0.07570488005876541\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0777, train_loss_epoch=0.0757]Epoch 67: Train Loss = 0.07766284793615341\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0741, train_loss_epoch=0.0777]Epoch 68: Train Loss = 0.07414077967405319\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0716, train_loss_epoch=0.0741]Epoch 69: Train Loss = 0.07159587740898132\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0727, train_loss_epoch=0.0716]Epoch 70: Train Loss = 0.07270057499408722\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0689, train_loss_epoch=0.0727]Epoch 71: Train Loss = 0.06889277696609497\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.069, train_loss_epoch=0.0689] Epoch 72: Train Loss = 0.06897337734699249\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0679, train_loss_epoch=0.069]Epoch 73: Train Loss = 0.06793835014104843\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0692, train_loss_epoch=0.0679]Epoch 74: Train Loss = 0.0692068412899971\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0656, train_loss_epoch=0.0692]Epoch 75: Train Loss = 0.06561429053544998\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0658, train_loss_epoch=0.0656]Epoch 76: Train Loss = 0.06576491892337799\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0656, train_loss_epoch=0.0658]Epoch 77: Train Loss = 0.0655871331691742\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0654, train_loss_epoch=0.0656]Epoch 78: Train Loss = 0.06536869704723358\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0618, train_loss_epoch=0.0654]Epoch 79: Train Loss = 0.061817388981580734\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0635, train_loss_epoch=0.0618]Epoch 80: Train Loss = 0.06349358707666397\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0621, train_loss_epoch=0.0635]Epoch 81: Train Loss = 0.06213495135307312\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0622, train_loss_epoch=0.0621]Epoch 82: Train Loss = 0.06222132220864296\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0607, train_loss_epoch=0.0622]Epoch 83: Train Loss = 0.06073892116546631\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0612, train_loss_epoch=0.0607]Epoch 84: Train Loss = 0.061204295605421066\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0587, train_loss_epoch=0.0612]Epoch 85: Train Loss = 0.05872002989053726\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0609, train_loss_epoch=0.0587]Epoch 86: Train Loss = 0.06087259575724602\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0601, train_loss_epoch=0.0609]Epoch 87: Train Loss = 0.06011456996202469\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0562, train_loss_epoch=0.0601]Epoch 88: Train Loss = 0.05616176128387451\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0557, train_loss_epoch=0.0562]Epoch 89: Train Loss = 0.055718306452035904\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0562, train_loss_epoch=0.0557]Epoch 90: Train Loss = 0.056203629821538925\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.054, train_loss_epoch=0.0562] Epoch 91: Train Loss = 0.05402994900941849\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0548, train_loss_epoch=0.054]Epoch 92: Train Loss = 0.05483366176486015\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0532, train_loss_epoch=0.0548]Epoch 93: Train Loss = 0.05323055759072304\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0533, train_loss_epoch=0.0532]Epoch 94: Train Loss = 0.05329541489481926\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0511, train_loss_epoch=0.0533]Epoch 95: Train Loss = 0.05108806863427162\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0525, train_loss_epoch=0.0511]Epoch 96: Train Loss = 0.052461374551057816\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0519, train_loss_epoch=0.0525]Epoch 97: Train Loss = 0.051897455006837845\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0516, train_loss_epoch=0.0519]Epoch 98: Train Loss = 0.051606617867946625\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0504, train_loss_epoch=0.0516]Epoch 99: Train Loss = 0.050362855195999146\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0506, train_loss_epoch=0.0504]Epoch 100: Train Loss = 0.050639353692531586\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0494, train_loss_epoch=0.0506]Epoch 101: Train Loss = 0.04935082793235779\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0494, train_loss_epoch=0.0494]Epoch 102: Train Loss = 0.0494452640414238\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0467, train_loss_epoch=0.0494]Epoch 103: Train Loss = 0.04670168086886406\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0485, train_loss_epoch=0.0467]Epoch 104: Train Loss = 0.04850241541862488\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0479, train_loss_epoch=0.0485]Epoch 105: Train Loss = 0.04787791520357132\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0515, train_loss_epoch=0.0479]Epoch 106: Train Loss = 0.05147085338830948\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0489, train_loss_epoch=0.0515]Epoch 107: Train Loss = 0.04893980175256729\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0516, train_loss_epoch=0.0489]Epoch 108: Train Loss = 0.05160849541425705\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0553, train_loss_epoch=0.0516]Epoch 109: Train Loss = 0.0553225502371788\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0505, train_loss_epoch=0.0553]Epoch 110: Train Loss = 0.05050038546323776\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0569, train_loss_epoch=0.0505]Epoch 111: Train Loss = 0.05689636990427971\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.049, train_loss_epoch=0.0569] Epoch 112: Train Loss = 0.04895470291376114\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0505, train_loss_epoch=0.049]Epoch 113: Train Loss = 0.050514087080955505\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0522, train_loss_epoch=0.0505]Epoch 114: Train Loss = 0.05220964550971985\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0461, train_loss_epoch=0.0522]Epoch 115: Train Loss = 0.04609635844826698\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0564, train_loss_epoch=0.0461]Epoch 116: Train Loss = 0.05644826218485832\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0451, train_loss_epoch=0.0564]Epoch 117: Train Loss = 0.045134007930755615\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0528, train_loss_epoch=0.0451]Epoch 118: Train Loss = 0.05277064070105553\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0437, train_loss_epoch=0.0528]Epoch 119: Train Loss = 0.04370203986763954\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0485, train_loss_epoch=0.0437]Epoch 120: Train Loss = 0.04853365570306778\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0482, train_loss_epoch=0.0485]Epoch 121: Train Loss = 0.04821985587477684\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0456, train_loss_epoch=0.0482]Epoch 122: Train Loss = 0.0456012487411499\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0496, train_loss_epoch=0.0456]Epoch 123: Train Loss = 0.04962814971804619\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0434, train_loss_epoch=0.0496]Epoch 124: Train Loss = 0.04337157681584358\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0494, train_loss_epoch=0.0434]Epoch 125: Train Loss = 0.04942676052451134\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0419, train_loss_epoch=0.0494]Epoch 126: Train Loss = 0.04192934185266495\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0463, train_loss_epoch=0.0419]Epoch 127: Train Loss = 0.046300120651721954\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0435, train_loss_epoch=0.0463]Epoch 128: Train Loss = 0.043492771685123444\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0444, train_loss_epoch=0.0435]Epoch 129: Train Loss = 0.04438287019729614\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0436, train_loss_epoch=0.0444]Epoch 130: Train Loss = 0.04363536834716797\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0429, train_loss_epoch=0.0436]Epoch 131: Train Loss = 0.04286101087927818\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0445, train_loss_epoch=0.0429]Epoch 132: Train Loss = 0.0444544181227684\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0403, train_loss_epoch=0.0445]Epoch 133: Train Loss = 0.04032515361905098\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0484, train_loss_epoch=0.0403]Epoch 134: Train Loss = 0.04841034486889839\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0408, train_loss_epoch=0.0484]Epoch 135: Train Loss = 0.040826987475156784\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.046, train_loss_epoch=0.0408] Epoch 136: Train Loss = 0.04600828140974045\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0398, train_loss_epoch=0.046]Epoch 137: Train Loss = 0.03984975442290306\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0416, train_loss_epoch=0.0398]Epoch 138: Train Loss = 0.04161819815635681\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0407, train_loss_epoch=0.0416]Epoch 139: Train Loss = 0.040743015706539154\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0401, train_loss_epoch=0.0407]Epoch 140: Train Loss = 0.04011230170726776\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0424, train_loss_epoch=0.0401]Epoch 141: Train Loss = 0.042360223829746246\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0413, train_loss_epoch=0.0424]Epoch 142: Train Loss = 0.0413021519780159\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0407, train_loss_epoch=0.0413]Epoch 143: Train Loss = 0.040741898119449615\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0415, train_loss_epoch=0.0407]Epoch 144: Train Loss = 0.041468728333711624\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0401, train_loss_epoch=0.0415]Epoch 145: Train Loss = 0.04006415233016014\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.039, train_loss_epoch=0.0401] Epoch 146: Train Loss = 0.03897560015320778\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0381, train_loss_epoch=0.039]Epoch 147: Train Loss = 0.038077302277088165\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0384, train_loss_epoch=0.0381]Epoch 148: Train Loss = 0.03839089348912239\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0398, train_loss_epoch=0.0384]Epoch 149: Train Loss = 0.0398206003010273\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0395, train_loss_epoch=0.0398]Epoch 150: Train Loss = 0.03949678689241409\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0396, train_loss_epoch=0.0395]Epoch 151: Train Loss = 0.039603184908628464\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0381, train_loss_epoch=0.0396]Epoch 152: Train Loss = 0.03813382238149643\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0374, train_loss_epoch=0.0381]Epoch 153: Train Loss = 0.03735567256808281\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0373, train_loss_epoch=0.0374]Epoch 154: Train Loss = 0.03725401312112808\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0389, train_loss_epoch=0.0373]Epoch 155: Train Loss = 0.03892902657389641\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0397, train_loss_epoch=0.0389]Epoch 156: Train Loss = 0.039663687348365784\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0416, train_loss_epoch=0.0397]Epoch 157: Train Loss = 0.041573114693164825\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0408, train_loss_epoch=0.0416]Epoch 158: Train Loss = 0.04078797623515129\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0387, train_loss_epoch=0.0408]Epoch 159: Train Loss = 0.03872539848089218\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0367, train_loss_epoch=0.0387]Epoch 160: Train Loss = 0.036703772842884064\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0399, train_loss_epoch=0.0367]Epoch 161: Train Loss = 0.03994584456086159\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0373, train_loss_epoch=0.0399]Epoch 162: Train Loss = 0.0372806042432785\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.037, train_loss_epoch=0.0373] Epoch 163: Train Loss = 0.03700907155871391\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0402, train_loss_epoch=0.037]Epoch 164: Train Loss = 0.04022204875946045\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0358, train_loss_epoch=0.0402]Epoch 165: Train Loss = 0.03576837107539177\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0379, train_loss_epoch=0.0358]Epoch 166: Train Loss = 0.037902601063251495\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0353, train_loss_epoch=0.0379]Epoch 167: Train Loss = 0.035295404493808746\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0368, train_loss_epoch=0.0353]Epoch 168: Train Loss = 0.036771856248378754\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0367, train_loss_epoch=0.0368]Epoch 169: Train Loss = 0.03672792762517929\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0354, train_loss_epoch=0.0367]Epoch 170: Train Loss = 0.035424429923295975\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0373, train_loss_epoch=0.0354]Epoch 171: Train Loss = 0.037305042147636414\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0358, train_loss_epoch=0.0373]Epoch 172: Train Loss = 0.03575654700398445\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0389, train_loss_epoch=0.0358]Epoch 173: Train Loss = 0.03891386836767197\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0361, train_loss_epoch=0.0389]Epoch 174: Train Loss = 0.03610599413514137\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0359, train_loss_epoch=0.0361]Epoch 175: Train Loss = 0.0359366238117218\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0354, train_loss_epoch=0.0359]Epoch 176: Train Loss = 0.03543941676616669\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0362, train_loss_epoch=0.0354]Epoch 177: Train Loss = 0.03623301908373833\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0355, train_loss_epoch=0.0362]Epoch 178: Train Loss = 0.03554077446460724\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0377, train_loss_epoch=0.0355]Epoch 179: Train Loss = 0.03773641586303711\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0351, train_loss_epoch=0.0377]Epoch 180: Train Loss = 0.03513471409678459\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0412, train_loss_epoch=0.0351]Epoch 181: Train Loss = 0.041180405765771866\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0366, train_loss_epoch=0.0412]Epoch 182: Train Loss = 0.03655363619327545\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0401, train_loss_epoch=0.0366]Epoch 183: Train Loss = 0.04011840745806694\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.034, train_loss_epoch=0.0401] Epoch 184: Train Loss = 0.03402632474899292\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.034, train_loss_epoch=0.034] Epoch 185: Train Loss = 0.033955276012420654\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0333, train_loss_epoch=0.034]Epoch 186: Train Loss = 0.03325119987130165\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0333, train_loss_epoch=0.0333]Epoch 187: Train Loss = 0.033332496881484985\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0336, train_loss_epoch=0.0333]Epoch 188: Train Loss = 0.03356534615159035\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0339, train_loss_epoch=0.0336]Epoch 189: Train Loss = 0.033892903476953506\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0335, train_loss_epoch=0.0339]Epoch 190: Train Loss = 0.03346037119626999\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0331, train_loss_epoch=0.0335]Epoch 191: Train Loss = 0.03313165530562401\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0341, train_loss_epoch=0.0331]Epoch 192: Train Loss = 0.034058552235364914\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.034, train_loss_epoch=0.0341] Epoch 193: Train Loss = 0.03398905321955681\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0343, train_loss_epoch=0.034]Epoch 194: Train Loss = 0.03432846441864967\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0325, train_loss_epoch=0.0343]Epoch 195: Train Loss = 0.032504696398973465\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0334, train_loss_epoch=0.0325]Epoch 196: Train Loss = 0.03335952013731003\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0339, train_loss_epoch=0.0334]Epoch 197: Train Loss = 0.03385188803076744\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0326, train_loss_epoch=0.0339]Epoch 198: Train Loss = 0.03257450461387634\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0366, train_loss_epoch=0.0326]Epoch 199: Train Loss = 0.03661157935857773\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0333, train_loss_epoch=0.0366]Epoch 200: Train Loss = 0.03325158730149269\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0364, train_loss_epoch=0.0333]Epoch 201: Train Loss = 0.036430906504392624\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0381, train_loss_epoch=0.0364]Epoch 202: Train Loss = 0.03809884935617447\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0337, train_loss_epoch=0.0381]Epoch 203: Train Loss = 0.03369160369038582\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0406, train_loss_epoch=0.0337]Epoch 204: Train Loss = 0.04057799279689789\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0324, train_loss_epoch=0.0406]Epoch 205: Train Loss = 0.03243107348680496\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0346, train_loss_epoch=0.0324]Epoch 206: Train Loss = 0.034557048231363297\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0338, train_loss_epoch=0.0346]Epoch 207: Train Loss = 0.03383497893810272\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0333, train_loss_epoch=0.0338]Epoch 208: Train Loss = 0.033283572643995285\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0365, train_loss_epoch=0.0333]Epoch 209: Train Loss = 0.036459144204854965\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0343, train_loss_epoch=0.0365]Epoch 210: Train Loss = 0.034253355115652084\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0341, train_loss_epoch=0.0343]Epoch 211: Train Loss = 0.03405462205410004\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0316, train_loss_epoch=0.0341]Epoch 212: Train Loss = 0.03157014399766922\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0348, train_loss_epoch=0.0316]Epoch 213: Train Loss = 0.03484530746936798\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0335, train_loss_epoch=0.0348]Epoch 214: Train Loss = 0.03345436230301857\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0363, train_loss_epoch=0.0335]Epoch 215: Train Loss = 0.03627714514732361\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0329, train_loss_epoch=0.0363]Epoch 216: Train Loss = 0.03293090686202049\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.032, train_loss_epoch=0.0329] Epoch 217: Train Loss = 0.03199071064591408\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0369, train_loss_epoch=0.032]Epoch 218: Train Loss = 0.03694428503513336\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.034, train_loss_epoch=0.0369] Epoch 219: Train Loss = 0.03399180993437767\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0388, train_loss_epoch=0.034]Epoch 220: Train Loss = 0.03884740546345711\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0323, train_loss_epoch=0.0388]Epoch 221: Train Loss = 0.032254431396722794\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0326, train_loss_epoch=0.0323]Epoch 222: Train Loss = 0.032599810510873795\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0347, train_loss_epoch=0.0326]Epoch 223: Train Loss = 0.034678954631090164\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0312, train_loss_epoch=0.0347]Epoch 224: Train Loss = 0.031181905418634415\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0388, train_loss_epoch=0.0312]Epoch 225: Train Loss = 0.03882596269249916\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0315, train_loss_epoch=0.0388]Epoch 226: Train Loss = 0.03152044862508774\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0332, train_loss_epoch=0.0315]Epoch 227: Train Loss = 0.03322846442461014\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.033, train_loss_epoch=0.0332] Epoch 228: Train Loss = 0.033006876707077026\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0317, train_loss_epoch=0.033]Epoch 229: Train Loss = 0.03174525871872902\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0322, train_loss_epoch=0.0317]Epoch 230: Train Loss = 0.032151591032743454\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0315, train_loss_epoch=0.0322]Epoch 231: Train Loss = 0.031497057527303696\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0314, train_loss_epoch=0.0315]Epoch 232: Train Loss = 0.0313662551343441\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0306, train_loss_epoch=0.0314]Epoch 233: Train Loss = 0.030590740963816643\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0308, train_loss_epoch=0.0306]Epoch 234: Train Loss = 0.030795210972428322\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.031, train_loss_epoch=0.0308] Epoch 235: Train Loss = 0.031017517670989037\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0306, train_loss_epoch=0.031]Epoch 236: Train Loss = 0.030558396130800247\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0306, train_loss_epoch=0.0306]Epoch 237: Train Loss = 0.030624596402049065\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.0314, train_loss_epoch=0.0306]Epoch 238: Train Loss = 0.03136215731501579\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0307, train_loss_epoch=0.0314]Epoch 239: Train Loss = 0.03069303184747696\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0313, train_loss_epoch=0.0307]Epoch 240: Train Loss = 0.031262751668691635\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=198, train_loss_step=0.0299, train_loss_epoch=0.0313]Epoch 241: Train Loss = 0.029926065355539322\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0301, train_loss_epoch=0.0299]Epoch 242: Train Loss = 0.030115697532892227\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0297, train_loss_epoch=0.0301]Epoch 243: Train Loss = 0.02965099923312664\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0298, train_loss_epoch=0.0297]Epoch 244: Train Loss = 0.02980373427271843\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0306, train_loss_epoch=0.0298]Epoch 245: Train Loss = 0.030554844066500664\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0299, train_loss_epoch=0.0306]Epoch 246: Train Loss = 0.029940517619252205\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0302, train_loss_epoch=0.0299]Epoch 247: Train Loss = 0.030186086893081665\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=198, train_loss_step=0.0303, train_loss_epoch=0.0302]Epoch 248: Train Loss = 0.030263790860772133\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.030, train_loss_epoch=0.0303] Epoch 249: Train Loss = 0.029963718727231026\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.030, train_loss_epoch=0.030] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=198, train_loss_step=0.030, train_loss_epoch=0.030]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 7: from 1998-11-02 00:00:00 to 2022-02-28 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.394]Epoch 0: Train Loss = 0.3942623734474182\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.498, train_loss_epoch=0.394]Epoch 1: Train Loss = 0.4980601668357849\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.364, train_loss_epoch=0.498]Epoch 2: Train Loss = 0.36423856019973755\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.250, train_loss_epoch=0.364]Epoch 3: Train Loss = 0.24995549023151398\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.312, train_loss_epoch=0.250]Epoch 4: Train Loss = 0.31204754114151\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.307, train_loss_epoch=0.312]Epoch 5: Train Loss = 0.307308167219162\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.249, train_loss_epoch=0.307]Epoch 6: Train Loss = 0.24864794313907623\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.241, train_loss_epoch=0.249]Epoch 7: Train Loss = 0.24115054309368134\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.268, train_loss_epoch=0.241]Epoch 8: Train Loss = 0.26807892322540283\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.259, train_loss_epoch=0.268]Epoch 9: Train Loss = 0.2590203285217285\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.237, train_loss_epoch=0.259]Epoch 10: Train Loss = 0.2374648004770279\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.219, train_loss_epoch=0.237]Epoch 11: Train Loss = 0.21946272253990173\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.234, train_loss_epoch=0.219]Epoch 12: Train Loss = 0.23412545025348663\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.218, train_loss_epoch=0.234]Epoch 13: Train Loss = 0.21833457052707672\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.211, train_loss_epoch=0.218]Epoch 14: Train Loss = 0.21088826656341553\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.190, train_loss_epoch=0.211]Epoch 15: Train Loss = 0.18965131044387817\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.202, train_loss_epoch=0.190]Epoch 16: Train Loss = 0.20201468467712402\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.187, train_loss_epoch=0.202]Epoch 17: Train Loss = 0.1871393322944641\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.195, train_loss_epoch=0.187]Epoch 18: Train Loss = 0.19486777484416962\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.170, train_loss_epoch=0.195]Epoch 19: Train Loss = 0.16984514892101288\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.164, train_loss_epoch=0.170]Epoch 20: Train Loss = 0.16442501544952393\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.178, train_loss_epoch=0.164]Epoch 21: Train Loss = 0.17808181047439575\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.178, train_loss_epoch=0.178]Epoch 22: Train Loss = 0.17836585640907288\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.162, train_loss_epoch=0.178]Epoch 23: Train Loss = 0.16175588965415955\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.158, train_loss_epoch=0.162]Epoch 24: Train Loss = 0.15805889666080475\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.156, train_loss_epoch=0.158]Epoch 25: Train Loss = 0.15615925192832947\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.161, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.1605900079011917\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.149, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.1491727977991104\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.143, train_loss_epoch=0.149]Epoch 28: Train Loss = 0.14345525205135345\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.149, train_loss_epoch=0.143]Epoch 29: Train Loss = 0.14937053620815277\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.141, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.14053653180599213\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.141, train_loss_epoch=0.141]Epoch 31: Train Loss = 0.14069810509681702\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.134, train_loss_epoch=0.141]Epoch 32: Train Loss = 0.13425613939762115\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.132, train_loss_epoch=0.134]Epoch 33: Train Loss = 0.1323733776807785\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.133, train_loss_epoch=0.132]Epoch 34: Train Loss = 0.1325370818376541\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.130, train_loss_epoch=0.133]Epoch 35: Train Loss = 0.12999077141284943\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.128, train_loss_epoch=0.130]Epoch 36: Train Loss = 0.1284203678369522\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.128, train_loss_epoch=0.128]Epoch 37: Train Loss = 0.12770527601242065\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.120, train_loss_epoch=0.128]Epoch 38: Train Loss = 0.12009928375482559\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.117, train_loss_epoch=0.120]Epoch 39: Train Loss = 0.1170150637626648\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.115, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11477344483137131\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.117, train_loss_epoch=0.115]Epoch 41: Train Loss = 0.11699635535478592\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.113, train_loss_epoch=0.117]Epoch 42: Train Loss = 0.1130383238196373\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.107, train_loss_epoch=0.113]Epoch 43: Train Loss = 0.10679290443658829\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.112, train_loss_epoch=0.107]Epoch 44: Train Loss = 0.11185785382986069\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.105, train_loss_epoch=0.112]Epoch 45: Train Loss = 0.10460546612739563\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.104, train_loss_epoch=0.105]Epoch 46: Train Loss = 0.10413482785224915\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.101, train_loss_epoch=0.104]Epoch 47: Train Loss = 0.10064017027616501\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0995, train_loss_epoch=0.101]Epoch 48: Train Loss = 0.09949169307947159\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.101, train_loss_epoch=0.0995] Epoch 49: Train Loss = 0.10136643797159195\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0968, train_loss_epoch=0.101]Epoch 50: Train Loss = 0.09676923602819443\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0945, train_loss_epoch=0.0968]Epoch 51: Train Loss = 0.09448592364788055\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0945, train_loss_epoch=0.0945]Epoch 52: Train Loss = 0.09446529299020767\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0913, train_loss_epoch=0.0945]Epoch 53: Train Loss = 0.09130365401506424\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0901, train_loss_epoch=0.0913]Epoch 54: Train Loss = 0.09011130779981613\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0897, train_loss_epoch=0.0901]Epoch 55: Train Loss = 0.08967617899179459\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0877, train_loss_epoch=0.0897]Epoch 56: Train Loss = 0.08771617710590363\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.085, train_loss_epoch=0.0877] Epoch 57: Train Loss = 0.0850117951631546\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.086, train_loss_epoch=0.085] Epoch 58: Train Loss = 0.08604038506746292\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0834, train_loss_epoch=0.086]Epoch 59: Train Loss = 0.08343683928251266\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0836, train_loss_epoch=0.0834]Epoch 60: Train Loss = 0.08356762677431107\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0788, train_loss_epoch=0.0836]Epoch 61: Train Loss = 0.07883251458406448\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0787, train_loss_epoch=0.0788]Epoch 62: Train Loss = 0.07869130373001099\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0772, train_loss_epoch=0.0787]Epoch 63: Train Loss = 0.07722951471805573\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0785, train_loss_epoch=0.0772]Epoch 64: Train Loss = 0.07851792871952057\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0754, train_loss_epoch=0.0785]Epoch 65: Train Loss = 0.07540138065814972\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.079, train_loss_epoch=0.0754] Epoch 66: Train Loss = 0.07896897941827774\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0741, train_loss_epoch=0.079]Epoch 67: Train Loss = 0.07407473027706146\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0729, train_loss_epoch=0.0741]Epoch 68: Train Loss = 0.07292766869068146\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0688, train_loss_epoch=0.0729]Epoch 69: Train Loss = 0.0687926635146141\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0713, train_loss_epoch=0.0688]Epoch 70: Train Loss = 0.07130041718482971\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0682, train_loss_epoch=0.0713]Epoch 71: Train Loss = 0.06818562746047974\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.069, train_loss_epoch=0.0682] Epoch 72: Train Loss = 0.06900602579116821\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0696, train_loss_epoch=0.069]Epoch 73: Train Loss = 0.06964477151632309\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0695, train_loss_epoch=0.0696]Epoch 74: Train Loss = 0.06946831941604614\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0644, train_loss_epoch=0.0695]Epoch 75: Train Loss = 0.06444653868675232\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0642, train_loss_epoch=0.0644]Epoch 76: Train Loss = 0.0641641691327095\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.065, train_loss_epoch=0.0642] Epoch 77: Train Loss = 0.06499382108449936\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0642, train_loss_epoch=0.065]Epoch 78: Train Loss = 0.06421972811222076\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0616, train_loss_epoch=0.0642]Epoch 79: Train Loss = 0.061630699783563614\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0625, train_loss_epoch=0.0616]Epoch 80: Train Loss = 0.06251300871372223\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0603, train_loss_epoch=0.0625]Epoch 81: Train Loss = 0.060312774032354355\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0617, train_loss_epoch=0.0603]Epoch 82: Train Loss = 0.061742834746837616\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0607, train_loss_epoch=0.0617]Epoch 83: Train Loss = 0.06067861616611481\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0599, train_loss_epoch=0.0607]Epoch 84: Train Loss = 0.05993444845080376\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0569, train_loss_epoch=0.0599]Epoch 85: Train Loss = 0.056887440383434296\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0574, train_loss_epoch=0.0569]Epoch 86: Train Loss = 0.05738966539502144\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.057, train_loss_epoch=0.0574] Epoch 87: Train Loss = 0.056981511414051056\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0556, train_loss_epoch=0.057]Epoch 88: Train Loss = 0.05556225776672363\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0562, train_loss_epoch=0.0556]Epoch 89: Train Loss = 0.05623805895447731\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0555, train_loss_epoch=0.0562]Epoch 90: Train Loss = 0.055469807237386703\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0557, train_loss_epoch=0.0555]Epoch 91: Train Loss = 0.05565543845295906\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0533, train_loss_epoch=0.0557]Epoch 92: Train Loss = 0.05328774079680443\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0523, train_loss_epoch=0.0533]Epoch 93: Train Loss = 0.05234157666563988\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0527, train_loss_epoch=0.0523]Epoch 94: Train Loss = 0.05272508040070534\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0524, train_loss_epoch=0.0527]Epoch 95: Train Loss = 0.05235482007265091\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0517, train_loss_epoch=0.0524]Epoch 96: Train Loss = 0.051652416586875916\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0518, train_loss_epoch=0.0517]Epoch 97: Train Loss = 0.051794081926345825\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0515, train_loss_epoch=0.0518]Epoch 98: Train Loss = 0.05148566514253616\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0506, train_loss_epoch=0.0515]Epoch 99: Train Loss = 0.05056578665971756\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0496, train_loss_epoch=0.0506]Epoch 100: Train Loss = 0.049561552703380585\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0492, train_loss_epoch=0.0496]Epoch 101: Train Loss = 0.04915448650717735\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0485, train_loss_epoch=0.0492]Epoch 102: Train Loss = 0.048508353531360626\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0484, train_loss_epoch=0.0485]Epoch 103: Train Loss = 0.04844538867473602\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0479, train_loss_epoch=0.0484]Epoch 104: Train Loss = 0.04791698232293129\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0466, train_loss_epoch=0.0479]Epoch 105: Train Loss = 0.04662628099322319\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0484, train_loss_epoch=0.0466]Epoch 106: Train Loss = 0.04844682291150093\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0463, train_loss_epoch=0.0484]Epoch 107: Train Loss = 0.04628675431013107\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0535, train_loss_epoch=0.0463]Epoch 108: Train Loss = 0.05353192612528801\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0497, train_loss_epoch=0.0535]Epoch 109: Train Loss = 0.04967084899544716\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0527, train_loss_epoch=0.0497]Epoch 110: Train Loss = 0.052681080996990204\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0502, train_loss_epoch=0.0527]Epoch 111: Train Loss = 0.0501910075545311\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0472, train_loss_epoch=0.0502]Epoch 112: Train Loss = 0.04722581431269646\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0466, train_loss_epoch=0.0472]Epoch 113: Train Loss = 0.04655726999044418\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0467, train_loss_epoch=0.0466]Epoch 114: Train Loss = 0.04674982279539108\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0449, train_loss_epoch=0.0467]Epoch 115: Train Loss = 0.04489053413271904\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0482, train_loss_epoch=0.0449]Epoch 116: Train Loss = 0.048216596245765686\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0446, train_loss_epoch=0.0482]Epoch 117: Train Loss = 0.04455186054110527\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0465, train_loss_epoch=0.0446]Epoch 118: Train Loss = 0.04652423411607742\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.044, train_loss_epoch=0.0465] Epoch 119: Train Loss = 0.043994348496198654\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0429, train_loss_epoch=0.044]Epoch 120: Train Loss = 0.04290788993239403\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0437, train_loss_epoch=0.0429]Epoch 121: Train Loss = 0.04367097094655037\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0437, train_loss_epoch=0.0437]Epoch 122: Train Loss = 0.04370167478919029\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0428, train_loss_epoch=0.0437]Epoch 123: Train Loss = 0.0428498350083828\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0444, train_loss_epoch=0.0428]Epoch 124: Train Loss = 0.044410981237888336\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0448, train_loss_epoch=0.0444]Epoch 125: Train Loss = 0.044786304235458374\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0412, train_loss_epoch=0.0448]Epoch 126: Train Loss = 0.04118843004107475\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0429, train_loss_epoch=0.0412]Epoch 127: Train Loss = 0.04287198558449745\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0422, train_loss_epoch=0.0429]Epoch 128: Train Loss = 0.042152851819992065\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0464, train_loss_epoch=0.0422]Epoch 129: Train Loss = 0.046365682035684586\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0404, train_loss_epoch=0.0464]Epoch 130: Train Loss = 0.0404047891497612\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0465, train_loss_epoch=0.0404]Epoch 131: Train Loss = 0.046539317816495895\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0422, train_loss_epoch=0.0465]Epoch 132: Train Loss = 0.04222017526626587\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.044, train_loss_epoch=0.0422] Epoch 133: Train Loss = 0.043963465839624405\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0432, train_loss_epoch=0.044]Epoch 134: Train Loss = 0.04319504648447037\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.044, train_loss_epoch=0.0432] Epoch 135: Train Loss = 0.044049713760614395\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0414, train_loss_epoch=0.044]Epoch 136: Train Loss = 0.041442256420850754\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0401, train_loss_epoch=0.0414]Epoch 137: Train Loss = 0.040086884051561356\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0399, train_loss_epoch=0.0401]Epoch 138: Train Loss = 0.039887089282274246\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0406, train_loss_epoch=0.0399]Epoch 139: Train Loss = 0.0405966155230999\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0422, train_loss_epoch=0.0406]Epoch 140: Train Loss = 0.04224282130599022\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0398, train_loss_epoch=0.0422]Epoch 141: Train Loss = 0.03982969745993614\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0405, train_loss_epoch=0.0398]Epoch 142: Train Loss = 0.04052598774433136\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0385, train_loss_epoch=0.0405]Epoch 143: Train Loss = 0.03850739821791649\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0372, train_loss_epoch=0.0385]Epoch 144: Train Loss = 0.03722219169139862\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0391, train_loss_epoch=0.0372]Epoch 145: Train Loss = 0.039052486419677734\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0388, train_loss_epoch=0.0391]Epoch 146: Train Loss = 0.0387723445892334\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0405, train_loss_epoch=0.0388]Epoch 147: Train Loss = 0.04045596346259117\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0371, train_loss_epoch=0.0405]Epoch 148: Train Loss = 0.03705628588795662\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0397, train_loss_epoch=0.0371]Epoch 149: Train Loss = 0.039741095155477524\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0374, train_loss_epoch=0.0397]Epoch 150: Train Loss = 0.037432070821523666\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0371, train_loss_epoch=0.0374]Epoch 151: Train Loss = 0.037149250507354736\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0409, train_loss_epoch=0.0371]Epoch 152: Train Loss = 0.04091845452785492\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0441, train_loss_epoch=0.0409]Epoch 153: Train Loss = 0.044095367193222046\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0395, train_loss_epoch=0.0441]Epoch 154: Train Loss = 0.03949052095413208\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0446, train_loss_epoch=0.0395]Epoch 155: Train Loss = 0.044616732746362686\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0381, train_loss_epoch=0.0446]Epoch 156: Train Loss = 0.03806273639202118\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0442, train_loss_epoch=0.0381]Epoch 157: Train Loss = 0.044203393161296844\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0373, train_loss_epoch=0.0442]Epoch 158: Train Loss = 0.03731067106127739\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0417, train_loss_epoch=0.0373]Epoch 159: Train Loss = 0.041743502020835876\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0375, train_loss_epoch=0.0417]Epoch 160: Train Loss = 0.03752058371901512\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0378, train_loss_epoch=0.0375]Epoch 161: Train Loss = 0.037828680127859116\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.041, train_loss_epoch=0.0378] Epoch 162: Train Loss = 0.04100504517555237\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0359, train_loss_epoch=0.041]Epoch 163: Train Loss = 0.035863157361745834\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0412, train_loss_epoch=0.0359]Epoch 164: Train Loss = 0.04121068865060806\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0356, train_loss_epoch=0.0412]Epoch 165: Train Loss = 0.03559691458940506\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0402, train_loss_epoch=0.0356]Epoch 166: Train Loss = 0.04015801101922989\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0342, train_loss_epoch=0.0402]Epoch 167: Train Loss = 0.03420843556523323\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0349, train_loss_epoch=0.0342]Epoch 168: Train Loss = 0.03490189462900162\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0368, train_loss_epoch=0.0349]Epoch 169: Train Loss = 0.036764878779649734\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0342, train_loss_epoch=0.0368]Epoch 170: Train Loss = 0.03421911969780922\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0384, train_loss_epoch=0.0342]Epoch 171: Train Loss = 0.03835068270564079\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0373, train_loss_epoch=0.0384]Epoch 172: Train Loss = 0.037307582795619965\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0417, train_loss_epoch=0.0373]Epoch 173: Train Loss = 0.04168808087706566\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0406, train_loss_epoch=0.0417]Epoch 174: Train Loss = 0.040576864033937454\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0382, train_loss_epoch=0.0406]Epoch 175: Train Loss = 0.038248397409915924\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0368, train_loss_epoch=0.0382]Epoch 176: Train Loss = 0.03679341450333595\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0338, train_loss_epoch=0.0368]Epoch 177: Train Loss = 0.033777374774217606\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0349, train_loss_epoch=0.0338]Epoch 178: Train Loss = 0.03489292785525322\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0369, train_loss_epoch=0.0349]Epoch 179: Train Loss = 0.036943644285202026\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0336, train_loss_epoch=0.0369]Epoch 180: Train Loss = 0.033642660826444626\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0352, train_loss_epoch=0.0336]Epoch 181: Train Loss = 0.03522457927465439\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0348, train_loss_epoch=0.0352]Epoch 182: Train Loss = 0.034762173891067505\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0355, train_loss_epoch=0.0348]Epoch 183: Train Loss = 0.035472508519887924\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0337, train_loss_epoch=0.0355]Epoch 184: Train Loss = 0.033681754022836685\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0331, train_loss_epoch=0.0337]Epoch 185: Train Loss = 0.0331227071583271\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0337, train_loss_epoch=0.0331]Epoch 186: Train Loss = 0.03374945744872093\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.033, train_loss_epoch=0.0337] Epoch 187: Train Loss = 0.033003561198711395\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0329, train_loss_epoch=0.033]Epoch 188: Train Loss = 0.03289895877242088\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0335, train_loss_epoch=0.0329]Epoch 189: Train Loss = 0.033452071249485016\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0327, train_loss_epoch=0.0335]Epoch 190: Train Loss = 0.032748375087976456\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0324, train_loss_epoch=0.0327]Epoch 191: Train Loss = 0.03236909210681915\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0326, train_loss_epoch=0.0324]Epoch 192: Train Loss = 0.03259538114070892\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0331, train_loss_epoch=0.0326]Epoch 193: Train Loss = 0.0331241749227047\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0336, train_loss_epoch=0.0331]Epoch 194: Train Loss = 0.03362559899687767\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0332, train_loss_epoch=0.0336]Epoch 195: Train Loss = 0.033243682235479355\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0365, train_loss_epoch=0.0332]Epoch 196: Train Loss = 0.03649742156267166\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0342, train_loss_epoch=0.0365]Epoch 197: Train Loss = 0.034199900925159454\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0331, train_loss_epoch=0.0342]Epoch 198: Train Loss = 0.033089879900217056\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0338, train_loss_epoch=0.0331]Epoch 199: Train Loss = 0.033755943179130554\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0326, train_loss_epoch=0.0338]Epoch 200: Train Loss = 0.032615091651678085\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0324, train_loss_epoch=0.0326]Epoch 201: Train Loss = 0.032442860305309296\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0326, train_loss_epoch=0.0324]Epoch 202: Train Loss = 0.03261406719684601\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0322, train_loss_epoch=0.0326]Epoch 203: Train Loss = 0.0321839302778244\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0316, train_loss_epoch=0.0322]Epoch 204: Train Loss = 0.0315505675971508\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0323, train_loss_epoch=0.0316]Epoch 205: Train Loss = 0.03233521431684494\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0321, train_loss_epoch=0.0323]Epoch 206: Train Loss = 0.03207411617040634\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0331, train_loss_epoch=0.0321]Epoch 207: Train Loss = 0.03313545137643814\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0322, train_loss_epoch=0.0331]Epoch 208: Train Loss = 0.03218213468790054\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0326, train_loss_epoch=0.0322]Epoch 209: Train Loss = 0.03255802392959595\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0329, train_loss_epoch=0.0326]Epoch 210: Train Loss = 0.03287295252084732\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0317, train_loss_epoch=0.0329]Epoch 211: Train Loss = 0.031713660806417465\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0336, train_loss_epoch=0.0317]Epoch 212: Train Loss = 0.0336126834154129\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0321, train_loss_epoch=0.0336]Epoch 213: Train Loss = 0.03207298368215561\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0342, train_loss_epoch=0.0321]Epoch 214: Train Loss = 0.034205853939056396\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0344, train_loss_epoch=0.0342]Epoch 215: Train Loss = 0.03439173847436905\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0361, train_loss_epoch=0.0344]Epoch 216: Train Loss = 0.036083150655031204\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0334, train_loss_epoch=0.0361]Epoch 217: Train Loss = 0.03336025029420853\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0327, train_loss_epoch=0.0334]Epoch 218: Train Loss = 0.03265443816781044\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0347, train_loss_epoch=0.0327]Epoch 219: Train Loss = 0.03467525541782379\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.031, train_loss_epoch=0.0347] Epoch 220: Train Loss = 0.030970565974712372\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0371, train_loss_epoch=0.031]Epoch 221: Train Loss = 0.037089984863996506\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0339, train_loss_epoch=0.0371]Epoch 222: Train Loss = 0.033902958035469055\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0326, train_loss_epoch=0.0339]Epoch 223: Train Loss = 0.03257470205426216\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0347, train_loss_epoch=0.0326]Epoch 224: Train Loss = 0.034696534276008606\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.031, train_loss_epoch=0.0347] Epoch 225: Train Loss = 0.031011147424578667\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.035, train_loss_epoch=0.031] Epoch 226: Train Loss = 0.03495610132813454\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0345, train_loss_epoch=0.035]Epoch 227: Train Loss = 0.03446715697646141\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0335, train_loss_epoch=0.0345]Epoch 228: Train Loss = 0.03354155272245407\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0328, train_loss_epoch=0.0335]Epoch 229: Train Loss = 0.03275992348790169\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.030, train_loss_epoch=0.0328] Epoch 230: Train Loss = 0.030031045898795128\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0305, train_loss_epoch=0.030]Epoch 231: Train Loss = 0.03048638440668583\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0331, train_loss_epoch=0.0305]Epoch 232: Train Loss = 0.03305564075708389\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0331, train_loss_epoch=0.0331]Epoch 233: Train Loss = 0.03314237669110298\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0304, train_loss_epoch=0.0331]Epoch 234: Train Loss = 0.03039616160094738\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0302, train_loss_epoch=0.0304]Epoch 235: Train Loss = 0.03024732880294323\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0307, train_loss_epoch=0.0302]Epoch 236: Train Loss = 0.03069133870303631\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.031, train_loss_epoch=0.0307] Epoch 237: Train Loss = 0.030981969088315964\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.030, train_loss_epoch=0.031] Epoch 238: Train Loss = 0.030027689412236214\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=200, train_loss_step=0.0309, train_loss_epoch=0.030]Epoch 239: Train Loss = 0.030888613313436508\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=200, train_loss_step=0.0291, train_loss_epoch=0.0309]Epoch 240: Train Loss = 0.02914419397711754\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0303, train_loss_epoch=0.0291]Epoch 241: Train Loss = 0.030296441167593002\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0296, train_loss_epoch=0.0303]Epoch 242: Train Loss = 0.029574431478977203\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0295, train_loss_epoch=0.0296]Epoch 243: Train Loss = 0.02952762134373188\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0301, train_loss_epoch=0.0295]Epoch 244: Train Loss = 0.03007153421640396\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0314, train_loss_epoch=0.0301]Epoch 245: Train Loss = 0.031433314085006714\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=200, train_loss_step=0.0303, train_loss_epoch=0.0314]Epoch 246: Train Loss = 0.030333174392580986\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0326, train_loss_epoch=0.0303]Epoch 247: Train Loss = 0.03255347162485123\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0314, train_loss_epoch=0.0326]Epoch 248: Train Loss = 0.03139586001634598\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0318, train_loss_epoch=0.0314]Epoch 249: Train Loss = 0.031809501349925995\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0318, train_loss_epoch=0.0318]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=200, train_loss_step=0.0318, train_loss_epoch=0.0318]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 8: from 1998-11-02 00:00:00 to 2022-03-09 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.393]Epoch 0: Train Loss = 0.3932155966758728\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.498, train_loss_epoch=0.393]Epoch 1: Train Loss = 0.49810969829559326\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.368, train_loss_epoch=0.498]Epoch 2: Train Loss = 0.3675841689109802\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.247, train_loss_epoch=0.368]Epoch 3: Train Loss = 0.2471049576997757\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.317, train_loss_epoch=0.247]Epoch 4: Train Loss = 0.31701135635375977\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.310, train_loss_epoch=0.317]Epoch 5: Train Loss = 0.3100331425666809\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.249, train_loss_epoch=0.310]Epoch 6: Train Loss = 0.24895043671131134\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.239, train_loss_epoch=0.249]Epoch 7: Train Loss = 0.23946930468082428\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.267, train_loss_epoch=0.239]Epoch 8: Train Loss = 0.266950398683548\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.261, train_loss_epoch=0.267]Epoch 9: Train Loss = 0.26052120327949524\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.238, train_loss_epoch=0.261]Epoch 10: Train Loss = 0.2375987023115158\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.221, train_loss_epoch=0.238]Epoch 11: Train Loss = 0.2207028567790985\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.233, train_loss_epoch=0.221]Epoch 12: Train Loss = 0.233411505818367\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.221, train_loss_epoch=0.233]Epoch 13: Train Loss = 0.22129416465759277\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.209, train_loss_epoch=0.221]Epoch 14: Train Loss = 0.20941747725009918\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.192, train_loss_epoch=0.209]Epoch 15: Train Loss = 0.1922522485256195\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.197, train_loss_epoch=0.192]Epoch 16: Train Loss = 0.1969870626926422\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.191, train_loss_epoch=0.197]Epoch 17: Train Loss = 0.19065488874912262\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.194, train_loss_epoch=0.191]Epoch 18: Train Loss = 0.19407053291797638\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.173, train_loss_epoch=0.194]Epoch 19: Train Loss = 0.17263881862163544\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.164, train_loss_epoch=0.173]Epoch 20: Train Loss = 0.1644737422466278\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.182, train_loss_epoch=0.164]Epoch 21: Train Loss = 0.1819213479757309\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.182, train_loss_epoch=0.182]Epoch 22: Train Loss = 0.18224695324897766\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.164, train_loss_epoch=0.182]Epoch 23: Train Loss = 0.16400264203548431\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.156, train_loss_epoch=0.164]Epoch 24: Train Loss = 0.15612316131591797\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.156, train_loss_epoch=0.156]Epoch 25: Train Loss = 0.1555429846048355\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.161, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.16094990074634552\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.152, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.15167583525180817\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.146, train_loss_epoch=0.152]Epoch 28: Train Loss = 0.14639024436473846\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.151, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.1509014517068863\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.140, train_loss_epoch=0.151]Epoch 30: Train Loss = 0.13971975445747375\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.141, train_loss_epoch=0.140]Epoch 31: Train Loss = 0.14141277968883514\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.138, train_loss_epoch=0.141]Epoch 32: Train Loss = 0.13795191049575806\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.135, train_loss_epoch=0.138]Epoch 33: Train Loss = 0.1347610205411911\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.134, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13355587422847748\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.134, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.13362263143062592\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.130, train_loss_epoch=0.134]Epoch 36: Train Loss = 0.12994904816150665\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.130, train_loss_epoch=0.130]Epoch 37: Train Loss = 0.12966811656951904\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.123, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12327565252780914\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.116, train_loss_epoch=0.123]Epoch 39: Train Loss = 0.11649931967258453\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.114, train_loss_epoch=0.116]Epoch 40: Train Loss = 0.1144312173128128\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.117, train_loss_epoch=0.114]Epoch 41: Train Loss = 0.11674565076828003\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.115, train_loss_epoch=0.117]Epoch 42: Train Loss = 0.11498575657606125\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.109, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.10890704393386841\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.112, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11189451068639755\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.104, train_loss_epoch=0.112]Epoch 45: Train Loss = 0.10434547066688538\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.105, train_loss_epoch=0.104]Epoch 46: Train Loss = 0.10462120920419693\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.101, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10100965946912766\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.100, train_loss_epoch=0.101]Epoch 48: Train Loss = 0.10014639049768448\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.101, train_loss_epoch=0.100]Epoch 49: Train Loss = 0.10142911970615387\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0987, train_loss_epoch=0.101]Epoch 50: Train Loss = 0.09873056411743164\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0963, train_loss_epoch=0.0987]Epoch 51: Train Loss = 0.09631910920143127\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0951, train_loss_epoch=0.0963]Epoch 52: Train Loss = 0.09511465579271317\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0929, train_loss_epoch=0.0951]Epoch 53: Train Loss = 0.09292217344045639\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0912, train_loss_epoch=0.0929]Epoch 54: Train Loss = 0.09122183918952942\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0907, train_loss_epoch=0.0912]Epoch 55: Train Loss = 0.0907323956489563\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0882, train_loss_epoch=0.0907]Epoch 56: Train Loss = 0.08824998140335083\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0875, train_loss_epoch=0.0882]Epoch 57: Train Loss = 0.08745893090963364\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0864, train_loss_epoch=0.0875]Epoch 58: Train Loss = 0.08636178821325302\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0834, train_loss_epoch=0.0864]Epoch 59: Train Loss = 0.08340643346309662\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0829, train_loss_epoch=0.0834]Epoch 60: Train Loss = 0.08293412625789642\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0794, train_loss_epoch=0.0829]Epoch 61: Train Loss = 0.07936306297779083\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0804, train_loss_epoch=0.0794]Epoch 62: Train Loss = 0.0803595781326294\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.079, train_loss_epoch=0.0804] Epoch 63: Train Loss = 0.0789698138833046\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0783, train_loss_epoch=0.079]Epoch 64: Train Loss = 0.07826389372348785\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0758, train_loss_epoch=0.0783]Epoch 65: Train Loss = 0.07579303532838821\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0792, train_loss_epoch=0.0758]Epoch 66: Train Loss = 0.07919813692569733\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0744, train_loss_epoch=0.0792]Epoch 67: Train Loss = 0.07444224506616592\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0735, train_loss_epoch=0.0744]Epoch 68: Train Loss = 0.07345199584960938\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0697, train_loss_epoch=0.0735]Epoch 69: Train Loss = 0.06966900825500488\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0709, train_loss_epoch=0.0697]Epoch 70: Train Loss = 0.07091367989778519\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0677, train_loss_epoch=0.0709]Epoch 71: Train Loss = 0.0677332878112793\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0682, train_loss_epoch=0.0677]Epoch 72: Train Loss = 0.06817873567342758\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.068, train_loss_epoch=0.0682] Epoch 73: Train Loss = 0.0679730698466301\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0677, train_loss_epoch=0.068]Epoch 74: Train Loss = 0.06768758594989777\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0661, train_loss_epoch=0.0677]Epoch 75: Train Loss = 0.06607387959957123\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0642, train_loss_epoch=0.0661]Epoch 76: Train Loss = 0.06419037282466888\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0637, train_loss_epoch=0.0642]Epoch 77: Train Loss = 0.06371598690748215\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0645, train_loss_epoch=0.0637]Epoch 78: Train Loss = 0.06445782631635666\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0621, train_loss_epoch=0.0645]Epoch 79: Train Loss = 0.062084320932626724\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0637, train_loss_epoch=0.0621]Epoch 80: Train Loss = 0.06368755549192429\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0629, train_loss_epoch=0.0637]Epoch 81: Train Loss = 0.06289143860340118\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0616, train_loss_epoch=0.0629]Epoch 82: Train Loss = 0.06164291128516197\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0603, train_loss_epoch=0.0616]Epoch 83: Train Loss = 0.060277871787548065\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0598, train_loss_epoch=0.0603]Epoch 84: Train Loss = 0.05975855886936188\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0603, train_loss_epoch=0.0598]Epoch 85: Train Loss = 0.06034359708428383\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0584, train_loss_epoch=0.0603]Epoch 86: Train Loss = 0.058409206569194794\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0592, train_loss_epoch=0.0584]Epoch 87: Train Loss = 0.05917239934206009\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0549, train_loss_epoch=0.0592]Epoch 88: Train Loss = 0.054876916110515594\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.056, train_loss_epoch=0.0549] Epoch 89: Train Loss = 0.05598820373415947\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0571, train_loss_epoch=0.056]Epoch 90: Train Loss = 0.05714107304811478\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0538, train_loss_epoch=0.0571]Epoch 91: Train Loss = 0.05375395342707634\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0553, train_loss_epoch=0.0538]Epoch 92: Train Loss = 0.0552605465054512\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0537, train_loss_epoch=0.0553]Epoch 93: Train Loss = 0.05366557091474533\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0533, train_loss_epoch=0.0537]Epoch 94: Train Loss = 0.05329331383109093\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0516, train_loss_epoch=0.0533]Epoch 95: Train Loss = 0.05161864683032036\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0533, train_loss_epoch=0.0516]Epoch 96: Train Loss = 0.053321048617362976\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0539, train_loss_epoch=0.0533]Epoch 97: Train Loss = 0.05385139212012291\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0508, train_loss_epoch=0.0539]Epoch 98: Train Loss = 0.05084183067083359\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0526, train_loss_epoch=0.0508]Epoch 99: Train Loss = 0.052634093910455704\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0504, train_loss_epoch=0.0526]Epoch 100: Train Loss = 0.050413403660058975\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0514, train_loss_epoch=0.0504]Epoch 101: Train Loss = 0.051442719995975494\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0489, train_loss_epoch=0.0514]Epoch 102: Train Loss = 0.04887092486023903\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0492, train_loss_epoch=0.0489]Epoch 103: Train Loss = 0.04923228546977043\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0473, train_loss_epoch=0.0492]Epoch 104: Train Loss = 0.04727435111999512\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0544, train_loss_epoch=0.0473]Epoch 105: Train Loss = 0.05439639836549759\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0506, train_loss_epoch=0.0544]Epoch 106: Train Loss = 0.05057656764984131\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0508, train_loss_epoch=0.0506]Epoch 107: Train Loss = 0.05076459422707558\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0496, train_loss_epoch=0.0508]Epoch 108: Train Loss = 0.049644313752651215\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0524, train_loss_epoch=0.0496]Epoch 109: Train Loss = 0.05236787721514702\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0528, train_loss_epoch=0.0524]Epoch 110: Train Loss = 0.052802301943302155\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0499, train_loss_epoch=0.0528]Epoch 111: Train Loss = 0.049917593598365784\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0492, train_loss_epoch=0.0499]Epoch 112: Train Loss = 0.04918844997882843\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0547, train_loss_epoch=0.0492]Epoch 113: Train Loss = 0.05466059222817421\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0496, train_loss_epoch=0.0547]Epoch 114: Train Loss = 0.049648795276880264\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0561, train_loss_epoch=0.0496]Epoch 115: Train Loss = 0.0560537613928318\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0444, train_loss_epoch=0.0561]Epoch 116: Train Loss = 0.044389162212610245\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0626, train_loss_epoch=0.0444]Epoch 117: Train Loss = 0.06255801767110825\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0449, train_loss_epoch=0.0626]Epoch 118: Train Loss = 0.04485547915101051\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0564, train_loss_epoch=0.0449]Epoch 119: Train Loss = 0.056421909481287\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0543, train_loss_epoch=0.0564]Epoch 120: Train Loss = 0.05432252958416939\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0471, train_loss_epoch=0.0543]Epoch 121: Train Loss = 0.047090619802474976\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0496, train_loss_epoch=0.0471]Epoch 122: Train Loss = 0.049620892852544785\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0441, train_loss_epoch=0.0496]Epoch 123: Train Loss = 0.04408857226371765\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0444, train_loss_epoch=0.0441]Epoch 124: Train Loss = 0.04444192722439766\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0447, train_loss_epoch=0.0444]Epoch 125: Train Loss = 0.04468357935547829\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0427, train_loss_epoch=0.0447]Epoch 126: Train Loss = 0.04268218204379082\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0463, train_loss_epoch=0.0427]Epoch 127: Train Loss = 0.04631372168660164\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0446, train_loss_epoch=0.0463]Epoch 128: Train Loss = 0.044614460319280624\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0422, train_loss_epoch=0.0446]Epoch 129: Train Loss = 0.04219852015376091\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0427, train_loss_epoch=0.0422]Epoch 130: Train Loss = 0.04268324375152588\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0428, train_loss_epoch=0.0427]Epoch 131: Train Loss = 0.04281098023056984\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0424, train_loss_epoch=0.0428]Epoch 132: Train Loss = 0.042404480278491974\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0439, train_loss_epoch=0.0424]Epoch 133: Train Loss = 0.04393192380666733\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0399, train_loss_epoch=0.0439]Epoch 134: Train Loss = 0.03988030180335045\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.042, train_loss_epoch=0.0399] Epoch 135: Train Loss = 0.041980624198913574\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0435, train_loss_epoch=0.042]Epoch 136: Train Loss = 0.04354305565357208\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.043, train_loss_epoch=0.0435] Epoch 137: Train Loss = 0.042982254177331924\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0443, train_loss_epoch=0.043]Epoch 138: Train Loss = 0.04425070807337761\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0423, train_loss_epoch=0.0443]Epoch 139: Train Loss = 0.04230523481965065\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0412, train_loss_epoch=0.0423]Epoch 140: Train Loss = 0.04122656211256981\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0389, train_loss_epoch=0.0412]Epoch 141: Train Loss = 0.038940440863370895\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0407, train_loss_epoch=0.0389]Epoch 142: Train Loss = 0.0406566858291626\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0406, train_loss_epoch=0.0407]Epoch 143: Train Loss = 0.040647950023412704\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0394, train_loss_epoch=0.0406]Epoch 144: Train Loss = 0.03936377540230751\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0398, train_loss_epoch=0.0394]Epoch 145: Train Loss = 0.03980128467082977\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0392, train_loss_epoch=0.0398]Epoch 146: Train Loss = 0.0391676239669323\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.039, train_loss_epoch=0.0392] Epoch 147: Train Loss = 0.038999706506729126\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0386, train_loss_epoch=0.039]Epoch 148: Train Loss = 0.038558512926101685\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0389, train_loss_epoch=0.0386]Epoch 149: Train Loss = 0.03887138143181801\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0385, train_loss_epoch=0.0389]Epoch 150: Train Loss = 0.038470469415187836\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0385, train_loss_epoch=0.0385]Epoch 151: Train Loss = 0.038549572229385376\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0379, train_loss_epoch=0.0385]Epoch 152: Train Loss = 0.03789198026061058\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0382, train_loss_epoch=0.0379]Epoch 153: Train Loss = 0.03821203112602234\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.039, train_loss_epoch=0.0382] Epoch 154: Train Loss = 0.038982491940259933\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0379, train_loss_epoch=0.039]Epoch 155: Train Loss = 0.037922587245702744\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0384, train_loss_epoch=0.0379]Epoch 156: Train Loss = 0.038408972322940826\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.038, train_loss_epoch=0.0384] Epoch 157: Train Loss = 0.03804052248597145\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0374, train_loss_epoch=0.038]Epoch 158: Train Loss = 0.0373590923845768\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.038, train_loss_epoch=0.0374] Epoch 159: Train Loss = 0.037987153977155685\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0376, train_loss_epoch=0.038]Epoch 160: Train Loss = 0.03757273405790329\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0379, train_loss_epoch=0.0376]Epoch 161: Train Loss = 0.03794245794415474\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0366, train_loss_epoch=0.0379]Epoch 162: Train Loss = 0.036593396216630936\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0363, train_loss_epoch=0.0366]Epoch 163: Train Loss = 0.03628833591938019\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.036, train_loss_epoch=0.0363] Epoch 164: Train Loss = 0.036003388464450836\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0358, train_loss_epoch=0.036]Epoch 165: Train Loss = 0.03575713187456131\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0349, train_loss_epoch=0.0358]Epoch 166: Train Loss = 0.034948017448186874\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.036, train_loss_epoch=0.0349] Epoch 167: Train Loss = 0.035989146679639816\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0359, train_loss_epoch=0.036]Epoch 168: Train Loss = 0.03589330241084099\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0351, train_loss_epoch=0.0359]Epoch 169: Train Loss = 0.03512788936495781\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0358, train_loss_epoch=0.0351]Epoch 170: Train Loss = 0.035789210349321365\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0356, train_loss_epoch=0.0358]Epoch 171: Train Loss = 0.035577431321144104\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0355, train_loss_epoch=0.0356]Epoch 172: Train Loss = 0.03551975637674332\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0356, train_loss_epoch=0.0355]Epoch 173: Train Loss = 0.03560082986950874\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0351, train_loss_epoch=0.0356]Epoch 174: Train Loss = 0.035059064626693726\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0355, train_loss_epoch=0.0351]Epoch 175: Train Loss = 0.03553461655974388\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0343, train_loss_epoch=0.0355]Epoch 176: Train Loss = 0.034313395619392395\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0346, train_loss_epoch=0.0343]Epoch 177: Train Loss = 0.034631844609975815\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0348, train_loss_epoch=0.0346]Epoch 178: Train Loss = 0.0348229818046093\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.036, train_loss_epoch=0.0348] Epoch 179: Train Loss = 0.03604833409190178\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0343, train_loss_epoch=0.036]Epoch 180: Train Loss = 0.03434493765234947\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0354, train_loss_epoch=0.0343]Epoch 181: Train Loss = 0.03535681217908859\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0354, train_loss_epoch=0.0354]Epoch 182: Train Loss = 0.03535391017794609\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0349, train_loss_epoch=0.0354]Epoch 183: Train Loss = 0.034921277314424515\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0338, train_loss_epoch=0.0349]Epoch 184: Train Loss = 0.03381078690290451\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0344, train_loss_epoch=0.0338]Epoch 185: Train Loss = 0.03436009958386421\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0342, train_loss_epoch=0.0344]Epoch 186: Train Loss = 0.03423672914505005\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0354, train_loss_epoch=0.0342]Epoch 187: Train Loss = 0.035444337874650955\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0332, train_loss_epoch=0.0354]Epoch 188: Train Loss = 0.033182293176651\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0353, train_loss_epoch=0.0332]Epoch 189: Train Loss = 0.03527195006608963\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0364, train_loss_epoch=0.0353]Epoch 190: Train Loss = 0.036409735679626465\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0344, train_loss_epoch=0.0364]Epoch 191: Train Loss = 0.034416213631629944\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0362, train_loss_epoch=0.0344]Epoch 192: Train Loss = 0.03621065616607666\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0373, train_loss_epoch=0.0362]Epoch 193: Train Loss = 0.03731410205364227\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0357, train_loss_epoch=0.0373]Epoch 194: Train Loss = 0.03568592295050621\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0402, train_loss_epoch=0.0357]Epoch 195: Train Loss = 0.040181729942560196\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0352, train_loss_epoch=0.0402]Epoch 196: Train Loss = 0.03517482802271843\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0417, train_loss_epoch=0.0352]Epoch 197: Train Loss = 0.04170063138008118\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.033, train_loss_epoch=0.0417] Epoch 198: Train Loss = 0.03302304819226265\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0425, train_loss_epoch=0.033]Epoch 199: Train Loss = 0.04252495616674423\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0327, train_loss_epoch=0.0425]Epoch 200: Train Loss = 0.03268713504076004\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0407, train_loss_epoch=0.0327]Epoch 201: Train Loss = 0.04071743041276932\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.037, train_loss_epoch=0.0407] Epoch 202: Train Loss = 0.03697258606553078\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0362, train_loss_epoch=0.037]Epoch 203: Train Loss = 0.03615489974617958\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0373, train_loss_epoch=0.0362]Epoch 204: Train Loss = 0.03728404641151428\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.033, train_loss_epoch=0.0373] Epoch 205: Train Loss = 0.03303101286292076\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0361, train_loss_epoch=0.033]Epoch 206: Train Loss = 0.03611835837364197\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0344, train_loss_epoch=0.0361]Epoch 207: Train Loss = 0.03444892540574074\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0355, train_loss_epoch=0.0344]Epoch 208: Train Loss = 0.03545444831252098\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0341, train_loss_epoch=0.0355]Epoch 209: Train Loss = 0.03414011374115944\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.032, train_loss_epoch=0.0341] Epoch 210: Train Loss = 0.03201832249760628\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0346, train_loss_epoch=0.032]Epoch 211: Train Loss = 0.034632906317710876\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0316, train_loss_epoch=0.0346]Epoch 212: Train Loss = 0.03159220144152641\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0327, train_loss_epoch=0.0316]Epoch 213: Train Loss = 0.03267957270145416\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0334, train_loss_epoch=0.0327]Epoch 214: Train Loss = 0.03342266380786896\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0327, train_loss_epoch=0.0334]Epoch 215: Train Loss = 0.03268910199403763\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0359, train_loss_epoch=0.0327]Epoch 216: Train Loss = 0.03590884059667587\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.032, train_loss_epoch=0.0359] Epoch 217: Train Loss = 0.03201049938797951\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0322, train_loss_epoch=0.032]Epoch 218: Train Loss = 0.03216296434402466\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0324, train_loss_epoch=0.0322]Epoch 219: Train Loss = 0.03244902566075325\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0314, train_loss_epoch=0.0324]Epoch 220: Train Loss = 0.03142940625548363\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0325, train_loss_epoch=0.0314]Epoch 221: Train Loss = 0.032510172575712204\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0318, train_loss_epoch=0.0325]Epoch 222: Train Loss = 0.03180485591292381\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0327, train_loss_epoch=0.0318]Epoch 223: Train Loss = 0.03268439322710037\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0338, train_loss_epoch=0.0327]Epoch 224: Train Loss = 0.03379104286432266\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0314, train_loss_epoch=0.0338]Epoch 225: Train Loss = 0.031414326280355453\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.032, train_loss_epoch=0.0314] Epoch 226: Train Loss = 0.03200875595211983\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0318, train_loss_epoch=0.032]Epoch 227: Train Loss = 0.031818121671676636\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0345, train_loss_epoch=0.0318]Epoch 228: Train Loss = 0.034539349377155304\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0346, train_loss_epoch=0.0345]Epoch 229: Train Loss = 0.03464379161596298\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.031, train_loss_epoch=0.0346] Epoch 230: Train Loss = 0.03099607490003109\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0343, train_loss_epoch=0.031]Epoch 231: Train Loss = 0.0343356616795063\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0363, train_loss_epoch=0.0343]Epoch 232: Train Loss = 0.036317747086286545\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0352, train_loss_epoch=0.0363]Epoch 233: Train Loss = 0.0352129191160202\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0372, train_loss_epoch=0.0352]Epoch 234: Train Loss = 0.03716729208827019\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0302, train_loss_epoch=0.0372]Epoch 235: Train Loss = 0.03021068684756756\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0328, train_loss_epoch=0.0302]Epoch 236: Train Loss = 0.03282260522246361\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0335, train_loss_epoch=0.0328]Epoch 237: Train Loss = 0.033466193825006485\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0315, train_loss_epoch=0.0335]Epoch 238: Train Loss = 0.031542517244815826\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0318, train_loss_epoch=0.0315]Epoch 239: Train Loss = 0.031824782490730286\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0299, train_loss_epoch=0.0318]Epoch 240: Train Loss = 0.02993036061525345\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0311, train_loss_epoch=0.0299]Epoch 241: Train Loss = 0.031130284070968628\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0308, train_loss_epoch=0.0311]Epoch 242: Train Loss = 0.03076246567070484\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0326, train_loss_epoch=0.0308]Epoch 243: Train Loss = 0.03258071094751358\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0311, train_loss_epoch=0.0326]Epoch 244: Train Loss = 0.03108328953385353\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0302, train_loss_epoch=0.0311]Epoch 245: Train Loss = 0.030247589573264122\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.0323, train_loss_epoch=0.0302]Epoch 246: Train Loss = 0.032292380928993225\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=202, train_loss_step=0.0319, train_loss_epoch=0.0323]Epoch 247: Train Loss = 0.03186263516545296\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=202, train_loss_step=0.0298, train_loss_epoch=0.0319]Epoch 248: Train Loss = 0.029832055792212486\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.034, train_loss_epoch=0.0298] Epoch 249: Train Loss = 0.03402520716190338\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.034, train_loss_epoch=0.034] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=202, train_loss_step=0.034, train_loss_epoch=0.034]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 9: from 1998-11-02 00:00:00 to 2022-03-18 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.397]Epoch 0: Train Loss = 0.39742520451545715\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.503, train_loss_epoch=0.397]Epoch 1: Train Loss = 0.502911388874054\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.367, train_loss_epoch=0.503]Epoch 2: Train Loss = 0.36735838651657104\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.248, train_loss_epoch=0.367]Epoch 3: Train Loss = 0.2481757402420044\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.313, train_loss_epoch=0.248]Epoch 4: Train Loss = 0.31315359473228455\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.304, train_loss_epoch=0.313]Epoch 5: Train Loss = 0.30426907539367676\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.251, train_loss_epoch=0.304]Epoch 6: Train Loss = 0.25052061676979065\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.242, train_loss_epoch=0.251]Epoch 7: Train Loss = 0.24237492680549622\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.269, train_loss_epoch=0.242]Epoch 8: Train Loss = 0.26920294761657715\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.259, train_loss_epoch=0.269]Epoch 9: Train Loss = 0.2587485909461975\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.239, train_loss_epoch=0.259]Epoch 10: Train Loss = 0.23887112736701965\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.219, train_loss_epoch=0.239]Epoch 11: Train Loss = 0.2192099243402481\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.234, train_loss_epoch=0.219]Epoch 12: Train Loss = 0.2341853231191635\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.218, train_loss_epoch=0.234]Epoch 13: Train Loss = 0.21822252869606018\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.211, train_loss_epoch=0.218]Epoch 14: Train Loss = 0.21133354306221008\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.193, train_loss_epoch=0.211]Epoch 15: Train Loss = 0.19265960156917572\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.200, train_loss_epoch=0.193]Epoch 16: Train Loss = 0.20025597512722015\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.190, train_loss_epoch=0.200]Epoch 17: Train Loss = 0.19001886248588562\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.195, train_loss_epoch=0.190]Epoch 18: Train Loss = 0.19487591087818146\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.170, train_loss_epoch=0.195]Epoch 19: Train Loss = 0.17025861144065857\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.167, train_loss_epoch=0.170]Epoch 20: Train Loss = 0.16723854839801788\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.182, train_loss_epoch=0.167]Epoch 21: Train Loss = 0.1824013739824295\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.180, train_loss_epoch=0.182]Epoch 22: Train Loss = 0.1795988380908966\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.163, train_loss_epoch=0.180]Epoch 23: Train Loss = 0.16311661899089813\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.158, train_loss_epoch=0.163]Epoch 24: Train Loss = 0.15832708775997162\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.155, train_loss_epoch=0.158]Epoch 25: Train Loss = 0.15539082884788513\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.159, train_loss_epoch=0.155]Epoch 26: Train Loss = 0.15878131985664368\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.150, train_loss_epoch=0.159]Epoch 27: Train Loss = 0.15013381838798523\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.149, train_loss_epoch=0.150]Epoch 28: Train Loss = 0.14877434074878693\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.151, train_loss_epoch=0.149]Epoch 29: Train Loss = 0.1513480693101883\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.139, train_loss_epoch=0.151]Epoch 30: Train Loss = 0.13926191627979279\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.141, train_loss_epoch=0.139]Epoch 31: Train Loss = 0.1410275548696518\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.139, train_loss_epoch=0.141]Epoch 32: Train Loss = 0.13865533471107483\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.134, train_loss_epoch=0.139]Epoch 33: Train Loss = 0.1341174840927124\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.134, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.13438093662261963\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.132, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.13158902525901794\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.128, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.12752960622310638\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.128, train_loss_epoch=0.128]Epoch 37: Train Loss = 0.12809322774410248\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.122, train_loss_epoch=0.128]Epoch 38: Train Loss = 0.12203984707593918\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.117, train_loss_epoch=0.122]Epoch 39: Train Loss = 0.11733357608318329\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.116, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11624763906002045\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.119, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11860541999340057\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.115, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.11503761261701584\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.109, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.1085691973567009\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.113, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11288324743509293\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.107, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10724907368421555\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.105, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.1053013801574707\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.103, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10318558663129807\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.101, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10111736506223679\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.102, train_loss_epoch=0.101]Epoch 49: Train Loss = 0.1019839495420456\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0998, train_loss_epoch=0.102]Epoch 50: Train Loss = 0.099847212433815\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0969, train_loss_epoch=0.0998]Epoch 51: Train Loss = 0.09692532569169998\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0956, train_loss_epoch=0.0969]Epoch 52: Train Loss = 0.09564859420061111\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0918, train_loss_epoch=0.0956]Epoch 53: Train Loss = 0.09180398285388947\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.091, train_loss_epoch=0.0918] Epoch 54: Train Loss = 0.09100216627120972\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0907, train_loss_epoch=0.091]Epoch 55: Train Loss = 0.0906742513179779\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0896, train_loss_epoch=0.0907]Epoch 56: Train Loss = 0.08957595378160477\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0861, train_loss_epoch=0.0896]Epoch 57: Train Loss = 0.08614852279424667\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0867, train_loss_epoch=0.0861]Epoch 58: Train Loss = 0.08665086328983307\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0831, train_loss_epoch=0.0867]Epoch 59: Train Loss = 0.08310671895742416\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0846, train_loss_epoch=0.0831]Epoch 60: Train Loss = 0.08455812931060791\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=204, train_loss_step=0.0808, train_loss_epoch=0.0846]Epoch 61: Train Loss = 0.08084331452846527\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0795, train_loss_epoch=0.0808]Epoch 62: Train Loss = 0.07947630435228348\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0806, train_loss_epoch=0.0795]Epoch 63: Train Loss = 0.08060655742883682\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0756, train_loss_epoch=0.0806]Epoch 64: Train Loss = 0.07555897533893585\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.076, train_loss_epoch=0.0756] Epoch 65: Train Loss = 0.07601459324359894\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.078, train_loss_epoch=0.076] Epoch 66: Train Loss = 0.07800032198429108\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0755, train_loss_epoch=0.078]Epoch 67: Train Loss = 0.07551547139883041\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0756, train_loss_epoch=0.0755]Epoch 68: Train Loss = 0.07560727745294571\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0713, train_loss_epoch=0.0756]Epoch 69: Train Loss = 0.07127604633569717\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0762, train_loss_epoch=0.0713]Epoch 70: Train Loss = 0.07619272917509079\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.069, train_loss_epoch=0.0762] Epoch 71: Train Loss = 0.06903897970914841\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0736, train_loss_epoch=0.069]Epoch 72: Train Loss = 0.07361406832933426\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0691, train_loss_epoch=0.0736]Epoch 73: Train Loss = 0.06905929744243622\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0731, train_loss_epoch=0.0691]Epoch 74: Train Loss = 0.073069728910923\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0673, train_loss_epoch=0.0731]Epoch 75: Train Loss = 0.06727299094200134\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0663, train_loss_epoch=0.0673]Epoch 76: Train Loss = 0.0663226917386055\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0709, train_loss_epoch=0.0663]Epoch 77: Train Loss = 0.07093286514282227\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0665, train_loss_epoch=0.0709]Epoch 78: Train Loss = 0.06645966321229935\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.071, train_loss_epoch=0.0665] Epoch 79: Train Loss = 0.07099154591560364\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0651, train_loss_epoch=0.071]Epoch 80: Train Loss = 0.06507041305303574\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.066, train_loss_epoch=0.0651] Epoch 81: Train Loss = 0.06600788980722427\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0701, train_loss_epoch=0.066]Epoch 82: Train Loss = 0.07006271183490753\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0614, train_loss_epoch=0.0701]Epoch 83: Train Loss = 0.06135169416666031\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.072, train_loss_epoch=0.0614] Epoch 84: Train Loss = 0.07197201251983643\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0626, train_loss_epoch=0.072]Epoch 85: Train Loss = 0.06261149793863297\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.063, train_loss_epoch=0.0626] Epoch 86: Train Loss = 0.06297770142555237\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0697, train_loss_epoch=0.063]Epoch 87: Train Loss = 0.06971044093370438\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0582, train_loss_epoch=0.0697]Epoch 88: Train Loss = 0.05818381533026695\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0716, train_loss_epoch=0.0582]Epoch 89: Train Loss = 0.07160226255655289\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0646, train_loss_epoch=0.0716]Epoch 90: Train Loss = 0.06456741690635681\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0623, train_loss_epoch=0.0646]Epoch 91: Train Loss = 0.06233356520533562\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0692, train_loss_epoch=0.0623]Epoch 92: Train Loss = 0.06917112320661545\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0548, train_loss_epoch=0.0692]Epoch 93: Train Loss = 0.054826050996780396\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0611, train_loss_epoch=0.0548]Epoch 94: Train Loss = 0.06114404648542404\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0578, train_loss_epoch=0.0611]Epoch 95: Train Loss = 0.057835932821035385\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.054, train_loss_epoch=0.0578] Epoch 96: Train Loss = 0.0540187731385231\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0614, train_loss_epoch=0.054]Epoch 97: Train Loss = 0.06136589124798775\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0563, train_loss_epoch=0.0614]Epoch 98: Train Loss = 0.0562523789703846\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0544, train_loss_epoch=0.0563]Epoch 99: Train Loss = 0.054368507117033005\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0552, train_loss_epoch=0.0544]Epoch 100: Train Loss = 0.055230673402547836\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0534, train_loss_epoch=0.0552]Epoch 101: Train Loss = 0.053439877927303314\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0534, train_loss_epoch=0.0534]Epoch 102: Train Loss = 0.05344761162996292\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0544, train_loss_epoch=0.0534]Epoch 103: Train Loss = 0.05438930168747902\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0508, train_loss_epoch=0.0544]Epoch 104: Train Loss = 0.05078452080488205\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0538, train_loss_epoch=0.0508]Epoch 105: Train Loss = 0.053793828934431076\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0544, train_loss_epoch=0.0538]Epoch 106: Train Loss = 0.05444134771823883\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0505, train_loss_epoch=0.0544]Epoch 107: Train Loss = 0.05047047138214111\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0551, train_loss_epoch=0.0505]Epoch 108: Train Loss = 0.055123504251241684\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.051, train_loss_epoch=0.0551] Epoch 109: Train Loss = 0.051037225872278214\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0501, train_loss_epoch=0.051]Epoch 110: Train Loss = 0.050074074417352676\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0533, train_loss_epoch=0.0501]Epoch 111: Train Loss = 0.05325763300061226\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0477, train_loss_epoch=0.0533]Epoch 112: Train Loss = 0.0477360375225544\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0498, train_loss_epoch=0.0477]Epoch 113: Train Loss = 0.049783751368522644\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0508, train_loss_epoch=0.0498]Epoch 114: Train Loss = 0.05079130083322525\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.048, train_loss_epoch=0.0508] Epoch 115: Train Loss = 0.04802373796701431\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0497, train_loss_epoch=0.048]Epoch 116: Train Loss = 0.04974405840039253\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0479, train_loss_epoch=0.0497]Epoch 117: Train Loss = 0.04794652760028839\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0496, train_loss_epoch=0.0479]Epoch 118: Train Loss = 0.0496465340256691\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0473, train_loss_epoch=0.0496]Epoch 119: Train Loss = 0.047290269285440445\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0491, train_loss_epoch=0.0473]Epoch 120: Train Loss = 0.049088042229413986\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0482, train_loss_epoch=0.0491]Epoch 121: Train Loss = 0.048232171684503555\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0495, train_loss_epoch=0.0482]Epoch 122: Train Loss = 0.04949326813220978\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0492, train_loss_epoch=0.0495]Epoch 123: Train Loss = 0.049218907952308655\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0469, train_loss_epoch=0.0492]Epoch 124: Train Loss = 0.04688439145684242\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0492, train_loss_epoch=0.0469]Epoch 125: Train Loss = 0.0492052286863327\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.045, train_loss_epoch=0.0492] Epoch 126: Train Loss = 0.04495828226208687\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0474, train_loss_epoch=0.045]Epoch 127: Train Loss = 0.04736987128853798\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0443, train_loss_epoch=0.0474]Epoch 128: Train Loss = 0.044313766062259674\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0459, train_loss_epoch=0.0443]Epoch 129: Train Loss = 0.04588300734758377\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0445, train_loss_epoch=0.0459]Epoch 130: Train Loss = 0.044487401843070984\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0457, train_loss_epoch=0.0445]Epoch 131: Train Loss = 0.04571245610713959\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0458, train_loss_epoch=0.0457]Epoch 132: Train Loss = 0.04576858878135681\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0427, train_loss_epoch=0.0458]Epoch 133: Train Loss = 0.042709700763225555\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0457, train_loss_epoch=0.0427]Epoch 134: Train Loss = 0.04568350687623024\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0463, train_loss_epoch=0.0457]Epoch 135: Train Loss = 0.04630450904369354\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0456, train_loss_epoch=0.0463]Epoch 136: Train Loss = 0.04563320428133011\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0452, train_loss_epoch=0.0456]Epoch 137: Train Loss = 0.045180801302194595\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0421, train_loss_epoch=0.0452]Epoch 138: Train Loss = 0.042100656777620316\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0446, train_loss_epoch=0.0421]Epoch 139: Train Loss = 0.044648658484220505\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0429, train_loss_epoch=0.0446]Epoch 140: Train Loss = 0.04288331791758537\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.041, train_loss_epoch=0.0429] Epoch 141: Train Loss = 0.040974896401166916\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0467, train_loss_epoch=0.041]Epoch 142: Train Loss = 0.04671448469161987\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0408, train_loss_epoch=0.0467]Epoch 143: Train Loss = 0.040802158415317535\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.041, train_loss_epoch=0.0408] Epoch 144: Train Loss = 0.04099215939640999\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.041, train_loss_epoch=0.041] Epoch 145: Train Loss = 0.0410425178706646\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0411, train_loss_epoch=0.041]Epoch 146: Train Loss = 0.04105429723858833\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0392, train_loss_epoch=0.0411]Epoch 147: Train Loss = 0.03922565281391144\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0394, train_loss_epoch=0.0392]Epoch 148: Train Loss = 0.03942600265145302\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0408, train_loss_epoch=0.0394]Epoch 149: Train Loss = 0.04082957282662392\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0405, train_loss_epoch=0.0408]Epoch 150: Train Loss = 0.040501318871974945\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0391, train_loss_epoch=0.0405]Epoch 151: Train Loss = 0.03910373896360397\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0417, train_loss_epoch=0.0391]Epoch 152: Train Loss = 0.041744545102119446\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0397, train_loss_epoch=0.0417]Epoch 153: Train Loss = 0.03974005952477455\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0416, train_loss_epoch=0.0397]Epoch 154: Train Loss = 0.041629087179899216\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0432, train_loss_epoch=0.0416]Epoch 155: Train Loss = 0.04322188347578049\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0399, train_loss_epoch=0.0432]Epoch 156: Train Loss = 0.039874374866485596\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0455, train_loss_epoch=0.0399]Epoch 157: Train Loss = 0.04554673284292221\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0378, train_loss_epoch=0.0455]Epoch 158: Train Loss = 0.03783826157450676\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.047, train_loss_epoch=0.0378] Epoch 159: Train Loss = 0.047011714428663254\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0381, train_loss_epoch=0.047]Epoch 160: Train Loss = 0.03809865191578865\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0403, train_loss_epoch=0.0381]Epoch 161: Train Loss = 0.04034087806940079\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0428, train_loss_epoch=0.0403]Epoch 162: Train Loss = 0.04280804842710495\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0385, train_loss_epoch=0.0428]Epoch 163: Train Loss = 0.03848131373524666\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0452, train_loss_epoch=0.0385]Epoch 164: Train Loss = 0.04515788331627846\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.039, train_loss_epoch=0.0452] Epoch 165: Train Loss = 0.0389927439391613\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0379, train_loss_epoch=0.039]Epoch 166: Train Loss = 0.037922024726867676\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0396, train_loss_epoch=0.0379]Epoch 167: Train Loss = 0.03959328681230545\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0362, train_loss_epoch=0.0396]Epoch 168: Train Loss = 0.03624320030212402\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0394, train_loss_epoch=0.0362]Epoch 169: Train Loss = 0.03941971808671951\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0385, train_loss_epoch=0.0394]Epoch 170: Train Loss = 0.03848094493150711\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.037, train_loss_epoch=0.0385] Epoch 171: Train Loss = 0.03699297085404396\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0414, train_loss_epoch=0.037]Epoch 172: Train Loss = 0.04143207520246506\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0367, train_loss_epoch=0.0414]Epoch 173: Train Loss = 0.03665832057595253\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0418, train_loss_epoch=0.0367]Epoch 174: Train Loss = 0.0417541079223156\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0367, train_loss_epoch=0.0418]Epoch 175: Train Loss = 0.03667423129081726\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0361, train_loss_epoch=0.0367]Epoch 176: Train Loss = 0.03613495081663132\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0411, train_loss_epoch=0.0361]Epoch 177: Train Loss = 0.04112560302019119\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0363, train_loss_epoch=0.0411]Epoch 178: Train Loss = 0.036301251500844955\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0375, train_loss_epoch=0.0363]Epoch 179: Train Loss = 0.037462808191776276\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0364, train_loss_epoch=0.0375]Epoch 180: Train Loss = 0.03635682538151741\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0362, train_loss_epoch=0.0364]Epoch 181: Train Loss = 0.036219920963048935\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0364, train_loss_epoch=0.0362]Epoch 182: Train Loss = 0.03642185032367706\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0367, train_loss_epoch=0.0364]Epoch 183: Train Loss = 0.036670245230197906\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0364, train_loss_epoch=0.0367]Epoch 184: Train Loss = 0.0363788828253746\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0362, train_loss_epoch=0.0364]Epoch 185: Train Loss = 0.03618047013878822\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0358, train_loss_epoch=0.0362]Epoch 186: Train Loss = 0.03577348589897156\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.037, train_loss_epoch=0.0358] Epoch 187: Train Loss = 0.03700851649045944\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0348, train_loss_epoch=0.037]Epoch 188: Train Loss = 0.034835658967494965\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.040, train_loss_epoch=0.0348] Epoch 189: Train Loss = 0.039986979216337204\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.036, train_loss_epoch=0.040] Epoch 190: Train Loss = 0.035971228033304214\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.037, train_loss_epoch=0.036]Epoch 191: Train Loss = 0.036978792399168015\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.041, train_loss_epoch=0.037]Epoch 192: Train Loss = 0.04097571223974228\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0361, train_loss_epoch=0.041]Epoch 193: Train Loss = 0.0361236035823822\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0385, train_loss_epoch=0.0361]Epoch 194: Train Loss = 0.03851926326751709\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0344, train_loss_epoch=0.0385]Epoch 195: Train Loss = 0.03443517908453941\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0342, train_loss_epoch=0.0344]Epoch 196: Train Loss = 0.03421897068619728\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0338, train_loss_epoch=0.0342]Epoch 197: Train Loss = 0.033756062388420105\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.034, train_loss_epoch=0.0338] Epoch 198: Train Loss = 0.03403733670711517\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0341, train_loss_epoch=0.034]Epoch 199: Train Loss = 0.03413718566298485\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0342, train_loss_epoch=0.0341]Epoch 200: Train Loss = 0.034195251762866974\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0366, train_loss_epoch=0.0342]Epoch 201: Train Loss = 0.036633990705013275\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0341, train_loss_epoch=0.0366]Epoch 202: Train Loss = 0.03414366394281387\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.034, train_loss_epoch=0.0341] Epoch 203: Train Loss = 0.033991292119026184\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0347, train_loss_epoch=0.034]Epoch 204: Train Loss = 0.03466331958770752\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0341, train_loss_epoch=0.0347]Epoch 205: Train Loss = 0.034131474792957306\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.035, train_loss_epoch=0.0341] Epoch 206: Train Loss = 0.035013165324926376\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0345, train_loss_epoch=0.035]Epoch 207: Train Loss = 0.03445131331682205\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0336, train_loss_epoch=0.0345]Epoch 208: Train Loss = 0.03362726792693138\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0339, train_loss_epoch=0.0336]Epoch 209: Train Loss = 0.033898476511240005\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0343, train_loss_epoch=0.0339]Epoch 210: Train Loss = 0.03431577607989311\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0327, train_loss_epoch=0.0343]Epoch 211: Train Loss = 0.03270909562706947\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0329, train_loss_epoch=0.0327]Epoch 212: Train Loss = 0.03285819664597511\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=204, train_loss_step=0.0332, train_loss_epoch=0.0329]Epoch 213: Train Loss = 0.03315066546201706\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0332, train_loss_epoch=0.0332]Epoch 214: Train Loss = 0.03315921127796173\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0337, train_loss_epoch=0.0332]Epoch 215: Train Loss = 0.033650923520326614\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0323, train_loss_epoch=0.0337]Epoch 216: Train Loss = 0.03228849917650223\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0337, train_loss_epoch=0.0323]Epoch 217: Train Loss = 0.03370262682437897\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0329, train_loss_epoch=0.0337]Epoch 218: Train Loss = 0.032886527478694916\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0329, train_loss_epoch=0.0329]Epoch 219: Train Loss = 0.0328667052090168\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0328, train_loss_epoch=0.0329]Epoch 220: Train Loss = 0.032757699489593506\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0328, train_loss_epoch=0.0328]Epoch 221: Train Loss = 0.03279025852680206\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0325, train_loss_epoch=0.0328]Epoch 222: Train Loss = 0.03252338618040085\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0348, train_loss_epoch=0.0325]Epoch 223: Train Loss = 0.0348067432641983\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0368, train_loss_epoch=0.0348]Epoch 224: Train Loss = 0.03679969534277916\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0324, train_loss_epoch=0.0368]Epoch 225: Train Loss = 0.0324128121137619\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0321, train_loss_epoch=0.0324]Epoch 226: Train Loss = 0.03211897611618042\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0326, train_loss_epoch=0.0321]Epoch 227: Train Loss = 0.03257546201348305\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0346, train_loss_epoch=0.0326]Epoch 228: Train Loss = 0.03463410958647728\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0342, train_loss_epoch=0.0346]Epoch 229: Train Loss = 0.03416632488369942\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0318, train_loss_epoch=0.0342]Epoch 230: Train Loss = 0.031818997114896774\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0325, train_loss_epoch=0.0318]Epoch 231: Train Loss = 0.03245236724615097\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0316, train_loss_epoch=0.0325]Epoch 232: Train Loss = 0.03157936781644821\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0327, train_loss_epoch=0.0316]Epoch 233: Train Loss = 0.032728906720876694\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.032, train_loss_epoch=0.0327] Epoch 234: Train Loss = 0.03203486278653145\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0321, train_loss_epoch=0.032]Epoch 235: Train Loss = 0.032110970467329025\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0312, train_loss_epoch=0.0321]Epoch 236: Train Loss = 0.03124990686774254\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0319, train_loss_epoch=0.0312]Epoch 237: Train Loss = 0.03190753236413002\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0309, train_loss_epoch=0.0319]Epoch 238: Train Loss = 0.030945437029004097\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0328, train_loss_epoch=0.0309]Epoch 239: Train Loss = 0.03276616334915161\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0309, train_loss_epoch=0.0328]Epoch 240: Train Loss = 0.030855242162942886\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0322, train_loss_epoch=0.0309]Epoch 241: Train Loss = 0.03222983703017235\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0311, train_loss_epoch=0.0322]Epoch 242: Train Loss = 0.031076187267899513\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.032, train_loss_epoch=0.0311] Epoch 243: Train Loss = 0.032001469284296036\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.030, train_loss_epoch=0.032] Epoch 244: Train Loss = 0.03003312274813652\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0311, train_loss_epoch=0.030]Epoch 245: Train Loss = 0.031146366149187088\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0306, train_loss_epoch=0.0311]Epoch 246: Train Loss = 0.03060850128531456\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0305, train_loss_epoch=0.0306]Epoch 247: Train Loss = 0.03051593340933323\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=204, train_loss_step=0.0312, train_loss_epoch=0.0305]Epoch 248: Train Loss = 0.031204426661133766\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0311, train_loss_epoch=0.0312]Epoch 249: Train Loss = 0.03114718571305275\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=204, train_loss_step=0.0311, train_loss_epoch=0.0311]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=204, train_loss_step=0.0311, train_loss_epoch=0.0311]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 10: from 1998-11-02 00:00:00 to 2022-03-29 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.397]Epoch 0: Train Loss = 0.39665839076042175\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.506, train_loss_epoch=0.397]Epoch 1: Train Loss = 0.506071150302887\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.372, train_loss_epoch=0.506]Epoch 2: Train Loss = 0.3720664381980896\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.252, train_loss_epoch=0.372]Epoch 3: Train Loss = 0.25228971242904663\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.317, train_loss_epoch=0.252]Epoch 4: Train Loss = 0.3171665072441101\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.310, train_loss_epoch=0.317]Epoch 5: Train Loss = 0.31011006236076355\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.255, train_loss_epoch=0.310]Epoch 6: Train Loss = 0.25458812713623047\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.239, train_loss_epoch=0.255]Epoch 7: Train Loss = 0.2389133721590042\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.268, train_loss_epoch=0.239]Epoch 8: Train Loss = 0.26799318194389343\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.268, train_loss_epoch=0.268]Epoch 9: Train Loss = 0.2675253450870514\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.246, train_loss_epoch=0.268]Epoch 10: Train Loss = 0.2462463676929474\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.221, train_loss_epoch=0.246]Epoch 11: Train Loss = 0.22081191837787628\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.235, train_loss_epoch=0.221]Epoch 12: Train Loss = 0.2348155677318573\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.223, train_loss_epoch=0.235]Epoch 13: Train Loss = 0.2229953110218048\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.218, train_loss_epoch=0.223]Epoch 14: Train Loss = 0.21839775145053864\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.194, train_loss_epoch=0.218]Epoch 15: Train Loss = 0.19353212416172028\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.200, train_loss_epoch=0.194]Epoch 16: Train Loss = 0.19982968270778656\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.191, train_loss_epoch=0.200]Epoch 17: Train Loss = 0.19085896015167236\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.202, train_loss_epoch=0.191]Epoch 18: Train Loss = 0.20181946456432343\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.179, train_loss_epoch=0.202]Epoch 19: Train Loss = 0.17922987043857574\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.167, train_loss_epoch=0.179]Epoch 20: Train Loss = 0.16675259172916412\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.176, train_loss_epoch=0.167]Epoch 21: Train Loss = 0.17622898519039154\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.180, train_loss_epoch=0.176]Epoch 22: Train Loss = 0.1804967224597931\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.166, train_loss_epoch=0.180]Epoch 23: Train Loss = 0.16632892191410065\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.159, train_loss_epoch=0.166]Epoch 24: Train Loss = 0.15944664180278778\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.155, train_loss_epoch=0.159]Epoch 25: Train Loss = 0.15505370497703552\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.159, train_loss_epoch=0.155]Epoch 26: Train Loss = 0.1593925952911377\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.154, train_loss_epoch=0.159]Epoch 27: Train Loss = 0.15380015969276428\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.147, train_loss_epoch=0.154]Epoch 28: Train Loss = 0.1471075713634491\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.149, train_loss_epoch=0.147]Epoch 29: Train Loss = 0.1494649201631546\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.140, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.14015083014965057\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.144, train_loss_epoch=0.140]Epoch 31: Train Loss = 0.14354604482650757\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.141, train_loss_epoch=0.144]Epoch 32: Train Loss = 0.14074763655662537\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.134, train_loss_epoch=0.141]Epoch 33: Train Loss = 0.13407032191753387\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.133, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.13346751034259796\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.132, train_loss_epoch=0.133]Epoch 35: Train Loss = 0.13247112929821014\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.131, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.13055486977100372\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.129, train_loss_epoch=0.131]Epoch 37: Train Loss = 0.12937508523464203\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.123, train_loss_epoch=0.129]Epoch 38: Train Loss = 0.1234312504529953\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.120, train_loss_epoch=0.123]Epoch 39: Train Loss = 0.11954621970653534\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.116, train_loss_epoch=0.120]Epoch 40: Train Loss = 0.11607683449983597\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.117, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11749063432216644\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.115, train_loss_epoch=0.117]Epoch 42: Train Loss = 0.11494933813810349\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.109, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.10900221019983292\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.114, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11359024047851562\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.107, train_loss_epoch=0.114]Epoch 45: Train Loss = 0.10659972578287125\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.106, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10565311461687088\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.102, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.10210762917995453\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.102, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.10213043540716171\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.104, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.10370619595050812\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.100, train_loss_epoch=0.104]Epoch 50: Train Loss = 0.09999695420265198\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0979, train_loss_epoch=0.100]Epoch 51: Train Loss = 0.09793151915073395\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.097, train_loss_epoch=0.0979] Epoch 52: Train Loss = 0.09703870117664337\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0937, train_loss_epoch=0.097]Epoch 53: Train Loss = 0.09371426701545715\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0928, train_loss_epoch=0.0937]Epoch 54: Train Loss = 0.09276159107685089\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0925, train_loss_epoch=0.0928]Epoch 55: Train Loss = 0.09254097193479538\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0907, train_loss_epoch=0.0925]Epoch 56: Train Loss = 0.0907285213470459\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0878, train_loss_epoch=0.0907]Epoch 57: Train Loss = 0.0878322422504425\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0888, train_loss_epoch=0.0878]Epoch 58: Train Loss = 0.08878277242183685\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0846, train_loss_epoch=0.0888]Epoch 59: Train Loss = 0.08461464196443558\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.083, train_loss_epoch=0.0846] Epoch 60: Train Loss = 0.08299066871404648\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0802, train_loss_epoch=0.083]Epoch 61: Train Loss = 0.08022672683000565\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0811, train_loss_epoch=0.0802]Epoch 62: Train Loss = 0.08109536021947861\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.080, train_loss_epoch=0.0811] Epoch 63: Train Loss = 0.07999427616596222\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.077, train_loss_epoch=0.080] Epoch 64: Train Loss = 0.07701416313648224\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0779, train_loss_epoch=0.077]Epoch 65: Train Loss = 0.07786335051059723\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0782, train_loss_epoch=0.0779]Epoch 66: Train Loss = 0.07817474752664566\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0769, train_loss_epoch=0.0782]Epoch 67: Train Loss = 0.07685226202011108\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.078, train_loss_epoch=0.0769] Epoch 68: Train Loss = 0.0779503881931305\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0731, train_loss_epoch=0.078]Epoch 69: Train Loss = 0.07310272753238678\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.075, train_loss_epoch=0.0731] Epoch 70: Train Loss = 0.0750286653637886\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0699, train_loss_epoch=0.075]Epoch 71: Train Loss = 0.06989634037017822\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0764, train_loss_epoch=0.0699]Epoch 72: Train Loss = 0.07642565667629242\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0694, train_loss_epoch=0.0764]Epoch 73: Train Loss = 0.06937102973461151\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0743, train_loss_epoch=0.0694]Epoch 74: Train Loss = 0.07428422570228577\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0665, train_loss_epoch=0.0743]Epoch 75: Train Loss = 0.06653104722499847\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0685, train_loss_epoch=0.0665]Epoch 76: Train Loss = 0.06849848479032516\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0664, train_loss_epoch=0.0685]Epoch 77: Train Loss = 0.06636545062065125\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0665, train_loss_epoch=0.0664]Epoch 78: Train Loss = 0.06649503111839294\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0661, train_loss_epoch=0.0665]Epoch 79: Train Loss = 0.06611320376396179\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0633, train_loss_epoch=0.0661]Epoch 80: Train Loss = 0.06328429281711578\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0632, train_loss_epoch=0.0633]Epoch 81: Train Loss = 0.06318255513906479\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0627, train_loss_epoch=0.0632]Epoch 82: Train Loss = 0.0626983717083931\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0619, train_loss_epoch=0.0627]Epoch 83: Train Loss = 0.061859551817178726\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0631, train_loss_epoch=0.0619]Epoch 84: Train Loss = 0.06310176849365234\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0596, train_loss_epoch=0.0631]Epoch 85: Train Loss = 0.05960192531347275\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0611, train_loss_epoch=0.0596]Epoch 86: Train Loss = 0.06114780157804489\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0593, train_loss_epoch=0.0611]Epoch 87: Train Loss = 0.05930547043681145\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0582, train_loss_epoch=0.0593]Epoch 88: Train Loss = 0.05819353088736534\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0581, train_loss_epoch=0.0582]Epoch 89: Train Loss = 0.05809822678565979\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0583, train_loss_epoch=0.0581]Epoch 90: Train Loss = 0.05833427980542183\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0554, train_loss_epoch=0.0583]Epoch 91: Train Loss = 0.05540164187550545\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0569, train_loss_epoch=0.0554]Epoch 92: Train Loss = 0.0569184236228466\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0594, train_loss_epoch=0.0569]Epoch 93: Train Loss = 0.0594305656850338\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0599, train_loss_epoch=0.0594]Epoch 94: Train Loss = 0.05992459878325462\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0591, train_loss_epoch=0.0599]Epoch 95: Train Loss = 0.059070147573947906\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0592, train_loss_epoch=0.0591]Epoch 96: Train Loss = 0.05922120064496994\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0604, train_loss_epoch=0.0592]Epoch 97: Train Loss = 0.06036653742194176\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0547, train_loss_epoch=0.0604]Epoch 98: Train Loss = 0.05469288304448128\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0601, train_loss_epoch=0.0547]Epoch 99: Train Loss = 0.06010488048195839\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0534, train_loss_epoch=0.0601]Epoch 100: Train Loss = 0.053414490073919296\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0642, train_loss_epoch=0.0534]Epoch 101: Train Loss = 0.0641787201166153\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0535, train_loss_epoch=0.0642]Epoch 102: Train Loss = 0.05346609279513359\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0552, train_loss_epoch=0.0535]Epoch 103: Train Loss = 0.05516866222023964\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0581, train_loss_epoch=0.0552]Epoch 104: Train Loss = 0.05810518562793732\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.050, train_loss_epoch=0.0581] Epoch 105: Train Loss = 0.04996249079704285\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0578, train_loss_epoch=0.050]Epoch 106: Train Loss = 0.0578201487660408\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0509, train_loss_epoch=0.0578]Epoch 107: Train Loss = 0.05087362229824066\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.051, train_loss_epoch=0.0509] Epoch 108: Train Loss = 0.05102889984846115\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0529, train_loss_epoch=0.051]Epoch 109: Train Loss = 0.05287986993789673\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0491, train_loss_epoch=0.0529]Epoch 110: Train Loss = 0.04911983013153076\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0538, train_loss_epoch=0.0491]Epoch 111: Train Loss = 0.05379249528050423\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0489, train_loss_epoch=0.0538]Epoch 112: Train Loss = 0.048898711800575256\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0528, train_loss_epoch=0.0489]Epoch 113: Train Loss = 0.052797455340623856\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0485, train_loss_epoch=0.0528]Epoch 114: Train Loss = 0.04853665456175804\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0471, train_loss_epoch=0.0485]Epoch 115: Train Loss = 0.04707350209355354\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0507, train_loss_epoch=0.0471]Epoch 116: Train Loss = 0.05073223263025284\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0477, train_loss_epoch=0.0507]Epoch 117: Train Loss = 0.04767270386219025\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.050, train_loss_epoch=0.0477] Epoch 118: Train Loss = 0.05000060051679611\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0479, train_loss_epoch=0.050]Epoch 119: Train Loss = 0.04789528250694275\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0485, train_loss_epoch=0.0479]Epoch 120: Train Loss = 0.04848158732056618\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0467, train_loss_epoch=0.0485]Epoch 121: Train Loss = 0.04672367870807648\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0459, train_loss_epoch=0.0467]Epoch 122: Train Loss = 0.04592578485608101\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0461, train_loss_epoch=0.0459]Epoch 123: Train Loss = 0.04606948792934418\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0452, train_loss_epoch=0.0461]Epoch 124: Train Loss = 0.045245639979839325\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0443, train_loss_epoch=0.0452]Epoch 125: Train Loss = 0.044302232563495636\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0463, train_loss_epoch=0.0443]Epoch 126: Train Loss = 0.04625615477561951\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0445, train_loss_epoch=0.0463]Epoch 127: Train Loss = 0.04452952370047569\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0456, train_loss_epoch=0.0445]Epoch 128: Train Loss = 0.04561825841665268\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0438, train_loss_epoch=0.0456]Epoch 129: Train Loss = 0.0438496433198452\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.043, train_loss_epoch=0.0438] Epoch 130: Train Loss = 0.043048322200775146\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0434, train_loss_epoch=0.043]Epoch 131: Train Loss = 0.043381113559007645\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0427, train_loss_epoch=0.0434]Epoch 132: Train Loss = 0.04266597703099251\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0432, train_loss_epoch=0.0427]Epoch 133: Train Loss = 0.0431673489511013\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0429, train_loss_epoch=0.0432]Epoch 134: Train Loss = 0.04287904128432274\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.042, train_loss_epoch=0.0429] Epoch 135: Train Loss = 0.04201912507414818\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0435, train_loss_epoch=0.042]Epoch 136: Train Loss = 0.04346718639135361\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0416, train_loss_epoch=0.0435]Epoch 137: Train Loss = 0.041563939303159714\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0422, train_loss_epoch=0.0416]Epoch 138: Train Loss = 0.04218495264649391\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0419, train_loss_epoch=0.0422]Epoch 139: Train Loss = 0.041939713060855865\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0413, train_loss_epoch=0.0419]Epoch 140: Train Loss = 0.04130275920033455\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0435, train_loss_epoch=0.0413]Epoch 141: Train Loss = 0.04347282648086548\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0418, train_loss_epoch=0.0435]Epoch 142: Train Loss = 0.04180138185620308\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0463, train_loss_epoch=0.0418]Epoch 143: Train Loss = 0.04633322358131409\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0395, train_loss_epoch=0.0463]Epoch 144: Train Loss = 0.0395171158015728\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0441, train_loss_epoch=0.0395]Epoch 145: Train Loss = 0.04412483796477318\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0397, train_loss_epoch=0.0441]Epoch 146: Train Loss = 0.03971695899963379\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0414, train_loss_epoch=0.0397]Epoch 147: Train Loss = 0.041380446404218674\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0384, train_loss_epoch=0.0414]Epoch 148: Train Loss = 0.0384083017706871\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=206, train_loss_step=0.0414, train_loss_epoch=0.0384]Epoch 149: Train Loss = 0.04142261669039726\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0389, train_loss_epoch=0.0414]Epoch 150: Train Loss = 0.03888630494475365\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0403, train_loss_epoch=0.0389]Epoch 151: Train Loss = 0.04026687890291214\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0399, train_loss_epoch=0.0403]Epoch 152: Train Loss = 0.03987574204802513\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0385, train_loss_epoch=0.0399]Epoch 153: Train Loss = 0.03847862407565117\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0437, train_loss_epoch=0.0385]Epoch 154: Train Loss = 0.04369561746716499\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0391, train_loss_epoch=0.0437]Epoch 155: Train Loss = 0.03905584290623665\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0405, train_loss_epoch=0.0391]Epoch 156: Train Loss = 0.04046250134706497\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0405, train_loss_epoch=0.0405]Epoch 157: Train Loss = 0.040474217385053635\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0378, train_loss_epoch=0.0405]Epoch 158: Train Loss = 0.037846289575099945\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0416, train_loss_epoch=0.0378]Epoch 159: Train Loss = 0.04164161905646324\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0376, train_loss_epoch=0.0416]Epoch 160: Train Loss = 0.037626590579748154\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0394, train_loss_epoch=0.0376]Epoch 161: Train Loss = 0.03935994580388069\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0387, train_loss_epoch=0.0394]Epoch 162: Train Loss = 0.038714904338121414\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0375, train_loss_epoch=0.0387]Epoch 163: Train Loss = 0.037513814866542816\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0382, train_loss_epoch=0.0375]Epoch 164: Train Loss = 0.038190215826034546\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0378, train_loss_epoch=0.0382]Epoch 165: Train Loss = 0.03776972368359566\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0414, train_loss_epoch=0.0378]Epoch 166: Train Loss = 0.041418060660362244\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0365, train_loss_epoch=0.0414]Epoch 167: Train Loss = 0.03645281121134758\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.039, train_loss_epoch=0.0365] Epoch 168: Train Loss = 0.038978755474090576\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0396, train_loss_epoch=0.039]Epoch 169: Train Loss = 0.039620138704776764\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0389, train_loss_epoch=0.0396]Epoch 170: Train Loss = 0.038929715752601624\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0465, train_loss_epoch=0.0389]Epoch 171: Train Loss = 0.046533871442079544\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0378, train_loss_epoch=0.0465]Epoch 172: Train Loss = 0.037814561277627945\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0435, train_loss_epoch=0.0378]Epoch 173: Train Loss = 0.04350971803069115\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0356, train_loss_epoch=0.0435]Epoch 174: Train Loss = 0.03561379015445709\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0395, train_loss_epoch=0.0356]Epoch 175: Train Loss = 0.03950361907482147\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0441, train_loss_epoch=0.0395]Epoch 176: Train Loss = 0.0440785251557827\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0364, train_loss_epoch=0.0441]Epoch 177: Train Loss = 0.03639328479766846\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0418, train_loss_epoch=0.0364]Epoch 178: Train Loss = 0.0418015755712986\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0376, train_loss_epoch=0.0418]Epoch 179: Train Loss = 0.037608176469802856\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0359, train_loss_epoch=0.0376]Epoch 180: Train Loss = 0.03587326034903526\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0426, train_loss_epoch=0.0359]Epoch 181: Train Loss = 0.04259489104151726\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0356, train_loss_epoch=0.0426]Epoch 182: Train Loss = 0.03555678576231003\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0389, train_loss_epoch=0.0356]Epoch 183: Train Loss = 0.038930442184209824\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0369, train_loss_epoch=0.0389]Epoch 184: Train Loss = 0.036872442811727524\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0349, train_loss_epoch=0.0369]Epoch 185: Train Loss = 0.03485257178544998\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0377, train_loss_epoch=0.0349]Epoch 186: Train Loss = 0.03765163943171501\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0353, train_loss_epoch=0.0377]Epoch 187: Train Loss = 0.03533522039651871\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.034, train_loss_epoch=0.0353] Epoch 188: Train Loss = 0.03401009365916252\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0348, train_loss_epoch=0.034]Epoch 189: Train Loss = 0.03478978946805\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0345, train_loss_epoch=0.0348]Epoch 190: Train Loss = 0.034544169902801514\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0335, train_loss_epoch=0.0345]Epoch 191: Train Loss = 0.03351058438420296\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0343, train_loss_epoch=0.0335]Epoch 192: Train Loss = 0.034321337938308716\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.035, train_loss_epoch=0.0343] Epoch 193: Train Loss = 0.03502164036035538\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0334, train_loss_epoch=0.035]Epoch 194: Train Loss = 0.03335998207330704\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0344, train_loss_epoch=0.0334]Epoch 195: Train Loss = 0.03437845781445503\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0344, train_loss_epoch=0.0344]Epoch 196: Train Loss = 0.034381140023469925\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0336, train_loss_epoch=0.0344]Epoch 197: Train Loss = 0.03361258655786514\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0341, train_loss_epoch=0.0336]Epoch 198: Train Loss = 0.03407896310091019\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0346, train_loss_epoch=0.0341]Epoch 199: Train Loss = 0.034609775990247726\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0338, train_loss_epoch=0.0346]Epoch 200: Train Loss = 0.03379589691758156\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0331, train_loss_epoch=0.0338]Epoch 201: Train Loss = 0.033075716346502304\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0336, train_loss_epoch=0.0331]Epoch 202: Train Loss = 0.0335615836083889\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0346, train_loss_epoch=0.0336]Epoch 203: Train Loss = 0.034575339406728745\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0343, train_loss_epoch=0.0346]Epoch 204: Train Loss = 0.03425086662173271\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0358, train_loss_epoch=0.0343]Epoch 205: Train Loss = 0.03582432493567467\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0338, train_loss_epoch=0.0358]Epoch 206: Train Loss = 0.033781278878450394\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0357, train_loss_epoch=0.0338]Epoch 207: Train Loss = 0.035665009170770645\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0339, train_loss_epoch=0.0357]Epoch 208: Train Loss = 0.03385305404663086\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0396, train_loss_epoch=0.0339]Epoch 209: Train Loss = 0.039620108902454376\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0336, train_loss_epoch=0.0396]Epoch 210: Train Loss = 0.03360980004072189\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0328, train_loss_epoch=0.0336]Epoch 211: Train Loss = 0.03277289494872093\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0356, train_loss_epoch=0.0328]Epoch 212: Train Loss = 0.03557920083403587\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0327, train_loss_epoch=0.0356]Epoch 213: Train Loss = 0.03269260749220848\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0393, train_loss_epoch=0.0327]Epoch 214: Train Loss = 0.0392504557967186\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0352, train_loss_epoch=0.0393]Epoch 215: Train Loss = 0.03521355241537094\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0365, train_loss_epoch=0.0352]Epoch 216: Train Loss = 0.03645263612270355\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0374, train_loss_epoch=0.0365]Epoch 217: Train Loss = 0.03735277056694031\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0339, train_loss_epoch=0.0374]Epoch 218: Train Loss = 0.033920109272003174\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.040, train_loss_epoch=0.0339] Epoch 219: Train Loss = 0.04000287503004074\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0315, train_loss_epoch=0.040]Epoch 220: Train Loss = 0.031504660844802856\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0391, train_loss_epoch=0.0315]Epoch 221: Train Loss = 0.03912923112511635\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.033, train_loss_epoch=0.0391] Epoch 222: Train Loss = 0.03302231803536415\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0333, train_loss_epoch=0.033]Epoch 223: Train Loss = 0.033283818513154984\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0367, train_loss_epoch=0.0333]Epoch 224: Train Loss = 0.03670719638466835\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0321, train_loss_epoch=0.0367]Epoch 225: Train Loss = 0.0321325808763504\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0342, train_loss_epoch=0.0321]Epoch 226: Train Loss = 0.034210026264190674\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.035, train_loss_epoch=0.0342] Epoch 227: Train Loss = 0.03498029336333275\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.032, train_loss_epoch=0.035] Epoch 228: Train Loss = 0.032013364136219025\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0383, train_loss_epoch=0.032]Epoch 229: Train Loss = 0.03830296918749809\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0328, train_loss_epoch=0.0383]Epoch 230: Train Loss = 0.03279842808842659\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.036, train_loss_epoch=0.0328] Epoch 231: Train Loss = 0.0360318124294281\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0377, train_loss_epoch=0.036]Epoch 232: Train Loss = 0.037712886929512024\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0315, train_loss_epoch=0.0377]Epoch 233: Train Loss = 0.03148703649640083\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.038, train_loss_epoch=0.0315] Epoch 234: Train Loss = 0.03799689933657646\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0355, train_loss_epoch=0.038]Epoch 235: Train Loss = 0.03550730645656586\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0343, train_loss_epoch=0.0355]Epoch 236: Train Loss = 0.03427087888121605\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0406, train_loss_epoch=0.0343]Epoch 237: Train Loss = 0.04061053320765495\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=206, train_loss_step=0.0309, train_loss_epoch=0.0406]Epoch 238: Train Loss = 0.03086121566593647\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.035, train_loss_epoch=0.0309] Epoch 239: Train Loss = 0.03495311737060547\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0311, train_loss_epoch=0.035]Epoch 240: Train Loss = 0.031139986589550972\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0311, train_loss_epoch=0.0311]Epoch 241: Train Loss = 0.031122969463467598\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.033, train_loss_epoch=0.0311] Epoch 242: Train Loss = 0.03296010568737984\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0326, train_loss_epoch=0.033]Epoch 243: Train Loss = 0.0326329842209816\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0308, train_loss_epoch=0.0326]Epoch 244: Train Loss = 0.030783789232373238\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0326, train_loss_epoch=0.0308]Epoch 245: Train Loss = 0.03264917433261871\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=206, train_loss_step=0.0302, train_loss_epoch=0.0326]Epoch 246: Train Loss = 0.030210431665182114\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0308, train_loss_epoch=0.0302]Epoch 247: Train Loss = 0.030827399343252182\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0322, train_loss_epoch=0.0308]Epoch 248: Train Loss = 0.03217872604727745\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0307, train_loss_epoch=0.0322]Epoch 249: Train Loss = 0.030716342851519585\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0307, train_loss_epoch=0.0307]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=206, train_loss_step=0.0307, train_loss_epoch=0.0307]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 11: from 1998-11-02 00:00:00 to 2022-04-07 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.400]Epoch 0: Train Loss = 0.3999269902706146\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.500, train_loss_epoch=0.400]Epoch 1: Train Loss = 0.5003246068954468\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.371, train_loss_epoch=0.500]Epoch 2: Train Loss = 0.3711710274219513\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.253, train_loss_epoch=0.371]Epoch 3: Train Loss = 0.2525138556957245\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.310, train_loss_epoch=0.253]Epoch 4: Train Loss = 0.31027206778526306\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.308, train_loss_epoch=0.310]Epoch 5: Train Loss = 0.30811092257499695\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.256, train_loss_epoch=0.308]Epoch 6: Train Loss = 0.2555854022502899\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.239, train_loss_epoch=0.256]Epoch 7: Train Loss = 0.2393570989370346\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.266, train_loss_epoch=0.239]Epoch 8: Train Loss = 0.26586174964904785\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.261, train_loss_epoch=0.266]Epoch 9: Train Loss = 0.2605530619621277\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.238, train_loss_epoch=0.261]Epoch 10: Train Loss = 0.2384248822927475\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.220, train_loss_epoch=0.238]Epoch 11: Train Loss = 0.2196633666753769\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.233, train_loss_epoch=0.220]Epoch 12: Train Loss = 0.23275230824947357\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.219, train_loss_epoch=0.233]Epoch 13: Train Loss = 0.21909166872501373\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.206, train_loss_epoch=0.219]Epoch 14: Train Loss = 0.20557603240013123\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.187, train_loss_epoch=0.206]Epoch 15: Train Loss = 0.18733732402324677\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.201, train_loss_epoch=0.187]Epoch 16: Train Loss = 0.20091529190540314\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.188, train_loss_epoch=0.201]Epoch 17: Train Loss = 0.18778957426548004\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.192, train_loss_epoch=0.188]Epoch 18: Train Loss = 0.19192549586296082\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.171, train_loss_epoch=0.192]Epoch 19: Train Loss = 0.17077989876270294\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.166, train_loss_epoch=0.171]Epoch 20: Train Loss = 0.16607153415679932\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.183, train_loss_epoch=0.166]Epoch 21: Train Loss = 0.18265560269355774\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.176, train_loss_epoch=0.183]Epoch 22: Train Loss = 0.17589817941188812\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.162, train_loss_epoch=0.176]Epoch 23: Train Loss = 0.1622951477766037\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.157, train_loss_epoch=0.162]Epoch 24: Train Loss = 0.15720152854919434\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.157, train_loss_epoch=0.157]Epoch 25: Train Loss = 0.15700790286064148\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.160, train_loss_epoch=0.157]Epoch 26: Train Loss = 0.16020998358726501\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.148, train_loss_epoch=0.160]Epoch 27: Train Loss = 0.14818307757377625\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.144, train_loss_epoch=0.148]Epoch 28: Train Loss = 0.14428949356079102\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.151, train_loss_epoch=0.144]Epoch 29: Train Loss = 0.15115420520305634\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.140, train_loss_epoch=0.151]Epoch 30: Train Loss = 0.13959330320358276\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.141, train_loss_epoch=0.140]Epoch 31: Train Loss = 0.14071932435035706\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.138, train_loss_epoch=0.141]Epoch 32: Train Loss = 0.13786688446998596\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.135, train_loss_epoch=0.138]Epoch 33: Train Loss = 0.13507069647312164\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.134, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13413897156715393\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.131, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.13097092509269714\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.129, train_loss_epoch=0.131]Epoch 36: Train Loss = 0.12862113118171692\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.131, train_loss_epoch=0.129]Epoch 37: Train Loss = 0.13082754611968994\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.123, train_loss_epoch=0.131]Epoch 38: Train Loss = 0.12323891371488571\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.118, train_loss_epoch=0.123]Epoch 39: Train Loss = 0.11762051284313202\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.116, train_loss_epoch=0.118]Epoch 40: Train Loss = 0.11554072797298431\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.118, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11752527952194214\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.115, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.11452040076255798\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.109, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.10908211767673492\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.113, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11275049299001694\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.106, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.1063116267323494\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.105, train_loss_epoch=0.106]Epoch 46: Train Loss = 0.10453146696090698\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.102, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10242191702127457\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.101, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.10073413699865341\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.101, train_loss_epoch=0.101]Epoch 49: Train Loss = 0.10085923969745636\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0986, train_loss_epoch=0.101]Epoch 50: Train Loss = 0.09857798367738724\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.095, train_loss_epoch=0.0986] Epoch 51: Train Loss = 0.0949975997209549\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.095, train_loss_epoch=0.095] Epoch 52: Train Loss = 0.09499473869800568\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0931, train_loss_epoch=0.095]Epoch 53: Train Loss = 0.09312461316585541\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.091, train_loss_epoch=0.0931] Epoch 54: Train Loss = 0.09095247089862823\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0918, train_loss_epoch=0.091]Epoch 55: Train Loss = 0.0917513445019722\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0885, train_loss_epoch=0.0918]Epoch 56: Train Loss = 0.08853081613779068\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.087, train_loss_epoch=0.0885] Epoch 57: Train Loss = 0.08695168048143387\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0869, train_loss_epoch=0.087]Epoch 58: Train Loss = 0.08692330867052078\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0839, train_loss_epoch=0.0869]Epoch 59: Train Loss = 0.0838523730635643\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0835, train_loss_epoch=0.0839]Epoch 60: Train Loss = 0.08348056674003601\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0801, train_loss_epoch=0.0835]Epoch 61: Train Loss = 0.08009205758571625\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0792, train_loss_epoch=0.0801]Epoch 62: Train Loss = 0.0791545882821083\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0784, train_loss_epoch=0.0792]Epoch 63: Train Loss = 0.07842766493558884\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0763, train_loss_epoch=0.0784]Epoch 64: Train Loss = 0.07634612917900085\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0758, train_loss_epoch=0.0763]Epoch 65: Train Loss = 0.07579682022333145\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0793, train_loss_epoch=0.0758]Epoch 66: Train Loss = 0.07925577461719513\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0741, train_loss_epoch=0.0793]Epoch 67: Train Loss = 0.07406564801931381\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.077, train_loss_epoch=0.0741] Epoch 68: Train Loss = 0.07695730775594711\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0723, train_loss_epoch=0.077]Epoch 69: Train Loss = 0.07230457663536072\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.076, train_loss_epoch=0.0723] Epoch 70: Train Loss = 0.07604257762432098\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0684, train_loss_epoch=0.076]Epoch 71: Train Loss = 0.06835247576236725\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0759, train_loss_epoch=0.0684]Epoch 72: Train Loss = 0.07588667422533035\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0686, train_loss_epoch=0.0759]Epoch 73: Train Loss = 0.06861438602209091\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.070, train_loss_epoch=0.0686] Epoch 74: Train Loss = 0.07004473358392715\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0664, train_loss_epoch=0.070]Epoch 75: Train Loss = 0.06635638326406479\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.064, train_loss_epoch=0.0664] Epoch 76: Train Loss = 0.06399371474981308\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.069, train_loss_epoch=0.064] Epoch 77: Train Loss = 0.06904057413339615\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0653, train_loss_epoch=0.069]Epoch 78: Train Loss = 0.06530256569385529\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0637, train_loss_epoch=0.0653]Epoch 79: Train Loss = 0.063730888068676\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0642, train_loss_epoch=0.0637]Epoch 80: Train Loss = 0.06418359279632568\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0621, train_loss_epoch=0.0642]Epoch 81: Train Loss = 0.06213698536157608\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0618, train_loss_epoch=0.0621]Epoch 82: Train Loss = 0.061756618320941925\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0613, train_loss_epoch=0.0618]Epoch 83: Train Loss = 0.06126721203327179\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0606, train_loss_epoch=0.0613]Epoch 84: Train Loss = 0.06061084195971489\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0597, train_loss_epoch=0.0606]Epoch 85: Train Loss = 0.05972781404852867\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0594, train_loss_epoch=0.0597]Epoch 86: Train Loss = 0.05941973254084587\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0579, train_loss_epoch=0.0594]Epoch 87: Train Loss = 0.05793992429971695\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0567, train_loss_epoch=0.0579]Epoch 88: Train Loss = 0.05671202391386032\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0577, train_loss_epoch=0.0567]Epoch 89: Train Loss = 0.057712066918611526\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0574, train_loss_epoch=0.0577]Epoch 90: Train Loss = 0.05743546411395073\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0553, train_loss_epoch=0.0574]Epoch 91: Train Loss = 0.05525827780365944\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0556, train_loss_epoch=0.0553]Epoch 92: Train Loss = 0.05558031424880028\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0538, train_loss_epoch=0.0556]Epoch 93: Train Loss = 0.05376662313938141\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0545, train_loss_epoch=0.0538]Epoch 94: Train Loss = 0.05451374500989914\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0527, train_loss_epoch=0.0545]Epoch 95: Train Loss = 0.05273227021098137\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0556, train_loss_epoch=0.0527]Epoch 96: Train Loss = 0.055632334202528\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0528, train_loss_epoch=0.0556]Epoch 97: Train Loss = 0.052773069590330124\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0567, train_loss_epoch=0.0528]Epoch 98: Train Loss = 0.05666400492191315\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0527, train_loss_epoch=0.0567]Epoch 99: Train Loss = 0.052723053842782974\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0515, train_loss_epoch=0.0527]Epoch 100: Train Loss = 0.051505036652088165\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0502, train_loss_epoch=0.0515]Epoch 101: Train Loss = 0.05021883547306061\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0491, train_loss_epoch=0.0502]Epoch 102: Train Loss = 0.049091096967458725\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0484, train_loss_epoch=0.0491]Epoch 103: Train Loss = 0.04842125624418259\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0489, train_loss_epoch=0.0484]Epoch 104: Train Loss = 0.0489351823925972\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0477, train_loss_epoch=0.0489]Epoch 105: Train Loss = 0.04771515354514122\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0486, train_loss_epoch=0.0477]Epoch 106: Train Loss = 0.04855344071984291\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0485, train_loss_epoch=0.0486]Epoch 107: Train Loss = 0.048456523567438126\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0481, train_loss_epoch=0.0485]Epoch 108: Train Loss = 0.04814688116312027\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0475, train_loss_epoch=0.0481]Epoch 109: Train Loss = 0.04754670336842537\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0486, train_loss_epoch=0.0475]Epoch 110: Train Loss = 0.048626858741045\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0472, train_loss_epoch=0.0486]Epoch 111: Train Loss = 0.04719160869717598\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0483, train_loss_epoch=0.0472]Epoch 112: Train Loss = 0.048329293727874756\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.051, train_loss_epoch=0.0483] Epoch 113: Train Loss = 0.051003348082304\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0449, train_loss_epoch=0.051]Epoch 114: Train Loss = 0.044927921146154404\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0464, train_loss_epoch=0.0449]Epoch 115: Train Loss = 0.046384088695049286\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0452, train_loss_epoch=0.0464]Epoch 116: Train Loss = 0.04515642672777176\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0455, train_loss_epoch=0.0452]Epoch 117: Train Loss = 0.04548234865069389\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0447, train_loss_epoch=0.0455]Epoch 118: Train Loss = 0.04473210126161575\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0451, train_loss_epoch=0.0447]Epoch 119: Train Loss = 0.04509465768933296\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0426, train_loss_epoch=0.0451]Epoch 120: Train Loss = 0.04256561025977135\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0454, train_loss_epoch=0.0426]Epoch 121: Train Loss = 0.04537195712327957\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0432, train_loss_epoch=0.0454]Epoch 122: Train Loss = 0.04322972521185875\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0449, train_loss_epoch=0.0432]Epoch 123: Train Loss = 0.0449044369161129\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0427, train_loss_epoch=0.0449]Epoch 124: Train Loss = 0.042727041989564896\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0443, train_loss_epoch=0.0427]Epoch 125: Train Loss = 0.044311992824077606\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0411, train_loss_epoch=0.0443]Epoch 126: Train Loss = 0.041055768728256226\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0429, train_loss_epoch=0.0411]Epoch 127: Train Loss = 0.04290857911109924\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0413, train_loss_epoch=0.0429]Epoch 128: Train Loss = 0.04127949848771095\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0438, train_loss_epoch=0.0413]Epoch 129: Train Loss = 0.04382607713341713\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0402, train_loss_epoch=0.0438]Epoch 130: Train Loss = 0.040212348103523254\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0424, train_loss_epoch=0.0402]Epoch 131: Train Loss = 0.04235983267426491\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0415, train_loss_epoch=0.0424]Epoch 132: Train Loss = 0.04154404625296593\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0414, train_loss_epoch=0.0415]Epoch 133: Train Loss = 0.04135502129793167\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0401, train_loss_epoch=0.0414]Epoch 134: Train Loss = 0.04013257846236229\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0471, train_loss_epoch=0.0401]Epoch 135: Train Loss = 0.04708819091320038\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0406, train_loss_epoch=0.0471]Epoch 136: Train Loss = 0.04058050364255905\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.044, train_loss_epoch=0.0406] Epoch 137: Train Loss = 0.044002991169691086\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0404, train_loss_epoch=0.044]Epoch 138: Train Loss = 0.040404632687568665\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.045, train_loss_epoch=0.0404] Epoch 139: Train Loss = 0.045004114508628845\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.044, train_loss_epoch=0.045] Epoch 140: Train Loss = 0.044009897857904434\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.040, train_loss_epoch=0.044]Epoch 141: Train Loss = 0.03998861834406853\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0408, train_loss_epoch=0.040]Epoch 142: Train Loss = 0.04081283137202263\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0405, train_loss_epoch=0.0408]Epoch 143: Train Loss = 0.040451791137456894\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.041, train_loss_epoch=0.0405] Epoch 144: Train Loss = 0.04095325246453285\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.038, train_loss_epoch=0.041] Epoch 145: Train Loss = 0.03800961747765541\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0384, train_loss_epoch=0.038]Epoch 146: Train Loss = 0.03835076093673706\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0387, train_loss_epoch=0.0384]Epoch 147: Train Loss = 0.03865428268909454\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0395, train_loss_epoch=0.0387]Epoch 148: Train Loss = 0.039452824741601944\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0377, train_loss_epoch=0.0395]Epoch 149: Train Loss = 0.03765666484832764\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0375, train_loss_epoch=0.0377]Epoch 150: Train Loss = 0.037457555532455444\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0392, train_loss_epoch=0.0375]Epoch 151: Train Loss = 0.039214469492435455\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0388, train_loss_epoch=0.0392]Epoch 152: Train Loss = 0.038842182606458664\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0377, train_loss_epoch=0.0388]Epoch 153: Train Loss = 0.03766355663537979\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0377, train_loss_epoch=0.0377]Epoch 154: Train Loss = 0.03769811615347862\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0391, train_loss_epoch=0.0377]Epoch 155: Train Loss = 0.039148785173892975\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0372, train_loss_epoch=0.0391]Epoch 156: Train Loss = 0.037215135991573334\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.043, train_loss_epoch=0.0372] Epoch 157: Train Loss = 0.04303815960884094\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0374, train_loss_epoch=0.043]Epoch 158: Train Loss = 0.037411466240882874\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0414, train_loss_epoch=0.0374]Epoch 159: Train Loss = 0.04142330214381218\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0386, train_loss_epoch=0.0414]Epoch 160: Train Loss = 0.03861767798662186\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0396, train_loss_epoch=0.0386]Epoch 161: Train Loss = 0.03956940025091171\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0367, train_loss_epoch=0.0396]Epoch 162: Train Loss = 0.03670240193605423\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0367, train_loss_epoch=0.0367]Epoch 163: Train Loss = 0.03668679669499397\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0353, train_loss_epoch=0.0367]Epoch 164: Train Loss = 0.03531178459525108\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0379, train_loss_epoch=0.0353]Epoch 165: Train Loss = 0.037865154445171356\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0353, train_loss_epoch=0.0379]Epoch 166: Train Loss = 0.0352955088019371\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0369, train_loss_epoch=0.0353]Epoch 167: Train Loss = 0.03692523390054703\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0345, train_loss_epoch=0.0369]Epoch 168: Train Loss = 0.03448343649506569\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0386, train_loss_epoch=0.0345]Epoch 169: Train Loss = 0.038583751767873764\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0348, train_loss_epoch=0.0386]Epoch 170: Train Loss = 0.03479449823498726\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0417, train_loss_epoch=0.0348]Epoch 171: Train Loss = 0.04173363000154495\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0349, train_loss_epoch=0.0417]Epoch 172: Train Loss = 0.03491772338747978\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.041, train_loss_epoch=0.0349] Epoch 173: Train Loss = 0.041038740426301956\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0343, train_loss_epoch=0.041]Epoch 174: Train Loss = 0.034296996891498566\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.037, train_loss_epoch=0.0343] Epoch 175: Train Loss = 0.03697112575173378\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0348, train_loss_epoch=0.037]Epoch 176: Train Loss = 0.034839484840631485\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0344, train_loss_epoch=0.0348]Epoch 177: Train Loss = 0.034443940967321396\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.036, train_loss_epoch=0.0344] Epoch 178: Train Loss = 0.03600248321890831\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.035, train_loss_epoch=0.036] Epoch 179: Train Loss = 0.03501379117369652\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0358, train_loss_epoch=0.035]Epoch 180: Train Loss = 0.03577844053506851\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0369, train_loss_epoch=0.0358]Epoch 181: Train Loss = 0.03688642010092735\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0341, train_loss_epoch=0.0369]Epoch 182: Train Loss = 0.034078214317560196\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0379, train_loss_epoch=0.0341]Epoch 183: Train Loss = 0.03785101696848869\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.034, train_loss_epoch=0.0379] Epoch 184: Train Loss = 0.03404385596513748\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.038, train_loss_epoch=0.034] Epoch 185: Train Loss = 0.03804827108979225\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0346, train_loss_epoch=0.038]Epoch 186: Train Loss = 0.03464612737298012\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.037, train_loss_epoch=0.0346] Epoch 187: Train Loss = 0.03701150044798851\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0336, train_loss_epoch=0.037]Epoch 188: Train Loss = 0.03363776579499245\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0341, train_loss_epoch=0.0336]Epoch 189: Train Loss = 0.03413747623562813\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0337, train_loss_epoch=0.0341]Epoch 190: Train Loss = 0.033701904118061066\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0332, train_loss_epoch=0.0337]Epoch 191: Train Loss = 0.033189866691827774\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0338, train_loss_epoch=0.0332]Epoch 192: Train Loss = 0.03384404256939888\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0335, train_loss_epoch=0.0338]Epoch 193: Train Loss = 0.03354852274060249\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0342, train_loss_epoch=0.0335]Epoch 194: Train Loss = 0.03417382761836052\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0333, train_loss_epoch=0.0342]Epoch 195: Train Loss = 0.03325878083705902\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0372, train_loss_epoch=0.0333]Epoch 196: Train Loss = 0.03723645210266113\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0329, train_loss_epoch=0.0372]Epoch 197: Train Loss = 0.03294612094759941\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0359, train_loss_epoch=0.0329]Epoch 198: Train Loss = 0.03592993691563606\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0319, train_loss_epoch=0.0359]Epoch 199: Train Loss = 0.031940482556819916\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0355, train_loss_epoch=0.0319]Epoch 200: Train Loss = 0.035468894988298416\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0327, train_loss_epoch=0.0355]Epoch 201: Train Loss = 0.032686587423086166\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0342, train_loss_epoch=0.0327]Epoch 202: Train Loss = 0.034245576709508896\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.033, train_loss_epoch=0.0342] Epoch 203: Train Loss = 0.03295913711190224\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0333, train_loss_epoch=0.033]Epoch 204: Train Loss = 0.033332303166389465\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0374, train_loss_epoch=0.0333]Epoch 205: Train Loss = 0.037411224097013474\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0366, train_loss_epoch=0.0374]Epoch 206: Train Loss = 0.03659233823418617\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0329, train_loss_epoch=0.0366]Epoch 207: Train Loss = 0.032939258962869644\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0318, train_loss_epoch=0.0329]Epoch 208: Train Loss = 0.03181380033493042\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0314, train_loss_epoch=0.0318]Epoch 209: Train Loss = 0.03139228746294975\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0362, train_loss_epoch=0.0314]Epoch 210: Train Loss = 0.03622247278690338\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0311, train_loss_epoch=0.0362]Epoch 211: Train Loss = 0.031141508370637894\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0394, train_loss_epoch=0.0311]Epoch 212: Train Loss = 0.039369769394397736\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0337, train_loss_epoch=0.0394]Epoch 213: Train Loss = 0.03372010216116905\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0315, train_loss_epoch=0.0337]Epoch 214: Train Loss = 0.03152012079954147\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0314, train_loss_epoch=0.0315]Epoch 215: Train Loss = 0.03136662021279335\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0307, train_loss_epoch=0.0314]Epoch 216: Train Loss = 0.03065488301217556\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0338, train_loss_epoch=0.0307]Epoch 217: Train Loss = 0.0337759368121624\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0325, train_loss_epoch=0.0338]Epoch 218: Train Loss = 0.03245997801423073\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0317, train_loss_epoch=0.0325]Epoch 219: Train Loss = 0.03168480843305588\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0314, train_loss_epoch=0.0317]Epoch 220: Train Loss = 0.031444989144802094\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0335, train_loss_epoch=0.0314]Epoch 221: Train Loss = 0.03352133184671402\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0313, train_loss_epoch=0.0335]Epoch 222: Train Loss = 0.031333062797784805\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=208, train_loss_step=0.0327, train_loss_epoch=0.0313]Epoch 223: Train Loss = 0.032697711139917374\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0368, train_loss_epoch=0.0327]Epoch 224: Train Loss = 0.036798376590013504\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0319, train_loss_epoch=0.0368]Epoch 225: Train Loss = 0.03193940222263336\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0372, train_loss_epoch=0.0319]Epoch 226: Train Loss = 0.03717903792858124\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0304, train_loss_epoch=0.0372]Epoch 227: Train Loss = 0.030391743406653404\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0428, train_loss_epoch=0.0304]Epoch 228: Train Loss = 0.04284626618027687\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.035, train_loss_epoch=0.0428] Epoch 229: Train Loss = 0.034998100250959396\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0368, train_loss_epoch=0.035]Epoch 230: Train Loss = 0.036818645894527435\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0434, train_loss_epoch=0.0368]Epoch 231: Train Loss = 0.04344302415847778\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0304, train_loss_epoch=0.0434]Epoch 232: Train Loss = 0.030415238812565804\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.041, train_loss_epoch=0.0304] Epoch 233: Train Loss = 0.04096512123942375\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0328, train_loss_epoch=0.041]Epoch 234: Train Loss = 0.032839562743902206\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0308, train_loss_epoch=0.0328]Epoch 235: Train Loss = 0.030799787491559982\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0387, train_loss_epoch=0.0308]Epoch 236: Train Loss = 0.03867310658097267\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.031, train_loss_epoch=0.0387] Epoch 237: Train Loss = 0.030962659046053886\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0309, train_loss_epoch=0.031]Epoch 238: Train Loss = 0.030868295580148697\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0359, train_loss_epoch=0.0309]Epoch 239: Train Loss = 0.03590105101466179\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0298, train_loss_epoch=0.0359]Epoch 240: Train Loss = 0.02976655773818493\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.033, train_loss_epoch=0.0298] Epoch 241: Train Loss = 0.03296665474772453\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0333, train_loss_epoch=0.033]Epoch 242: Train Loss = 0.03330561891198158\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0305, train_loss_epoch=0.0333]Epoch 243: Train Loss = 0.03054002858698368\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0313, train_loss_epoch=0.0305]Epoch 244: Train Loss = 0.03125036507844925\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0303, train_loss_epoch=0.0313]Epoch 245: Train Loss = 0.03034270741045475\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0299, train_loss_epoch=0.0303]Epoch 246: Train Loss = 0.029919754713773727\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0296, train_loss_epoch=0.0299]Epoch 247: Train Loss = 0.02961764670908451\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=208, train_loss_step=0.0307, train_loss_epoch=0.0296]Epoch 248: Train Loss = 0.030730383470654488\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0292, train_loss_epoch=0.0307]Epoch 249: Train Loss = 0.029173526912927628\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0292, train_loss_epoch=0.0292]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=208, train_loss_step=0.0292, train_loss_epoch=0.0292]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 12: from 1998-11-02 00:00:00 to 2022-04-18 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.399]Epoch 0: Train Loss = 0.39943596720695496\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.495, train_loss_epoch=0.399]Epoch 1: Train Loss = 0.49503374099731445\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.371, train_loss_epoch=0.495]Epoch 2: Train Loss = 0.37091922760009766\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.250, train_loss_epoch=0.371]Epoch 3: Train Loss = 0.24966739118099213\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.315, train_loss_epoch=0.250]Epoch 4: Train Loss = 0.3149304687976837\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.313, train_loss_epoch=0.315]Epoch 5: Train Loss = 0.31263256072998047\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.258, train_loss_epoch=0.313]Epoch 6: Train Loss = 0.2575385272502899\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.244, train_loss_epoch=0.258]Epoch 7: Train Loss = 0.24383525550365448\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.269, train_loss_epoch=0.244]Epoch 8: Train Loss = 0.2685076594352722\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.261, train_loss_epoch=0.269]Epoch 9: Train Loss = 0.26103976368904114\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.241, train_loss_epoch=0.261]Epoch 10: Train Loss = 0.24118845164775848\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.224, train_loss_epoch=0.241]Epoch 11: Train Loss = 0.22441646456718445\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.237, train_loss_epoch=0.224]Epoch 12: Train Loss = 0.2366286963224411\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.219, train_loss_epoch=0.237]Epoch 13: Train Loss = 0.2186681479215622\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.211, train_loss_epoch=0.219]Epoch 14: Train Loss = 0.21068201959133148\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.189, train_loss_epoch=0.211]Epoch 15: Train Loss = 0.18883129954338074\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.196, train_loss_epoch=0.189]Epoch 16: Train Loss = 0.19623568654060364\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.192, train_loss_epoch=0.196]Epoch 17: Train Loss = 0.19167254865169525\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.197, train_loss_epoch=0.192]Epoch 18: Train Loss = 0.19671198725700378\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.177, train_loss_epoch=0.197]Epoch 19: Train Loss = 0.1770118921995163\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.169, train_loss_epoch=0.177]Epoch 20: Train Loss = 0.1691645085811615\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.179, train_loss_epoch=0.169]Epoch 21: Train Loss = 0.17907635867595673\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.177, train_loss_epoch=0.179]Epoch 22: Train Loss = 0.17717956006526947\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.166, train_loss_epoch=0.177]Epoch 23: Train Loss = 0.16575531661510468\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.158, train_loss_epoch=0.166]Epoch 24: Train Loss = 0.1582687497138977\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.157, train_loss_epoch=0.158]Epoch 25: Train Loss = 0.1568375676870346\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.160, train_loss_epoch=0.157]Epoch 26: Train Loss = 0.16023792326450348\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.152, train_loss_epoch=0.160]Epoch 27: Train Loss = 0.1522156447172165\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.145, train_loss_epoch=0.152]Epoch 28: Train Loss = 0.14493675529956818\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.148, train_loss_epoch=0.145]Epoch 29: Train Loss = 0.14799469709396362\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.140, train_loss_epoch=0.148]Epoch 30: Train Loss = 0.13958927989006042\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.144, train_loss_epoch=0.140]Epoch 31: Train Loss = 0.1438675820827484\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.139, train_loss_epoch=0.144]Epoch 32: Train Loss = 0.13932567834854126\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.134, train_loss_epoch=0.139]Epoch 33: Train Loss = 0.13433849811553955\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.134, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.13444292545318604\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.132, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.1324271261692047\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.127, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.12703633308410645\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.129, train_loss_epoch=0.127]Epoch 37: Train Loss = 0.12930922210216522\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.122, train_loss_epoch=0.129]Epoch 38: Train Loss = 0.12222141027450562\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.118, train_loss_epoch=0.122]Epoch 39: Train Loss = 0.11809633672237396\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.116, train_loss_epoch=0.118]Epoch 40: Train Loss = 0.1160283163189888\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.118, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11774545907974243\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.114, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.11377410590648651\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.108, train_loss_epoch=0.114]Epoch 43: Train Loss = 0.1075395718216896\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.113, train_loss_epoch=0.108]Epoch 44: Train Loss = 0.11322861909866333\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.108, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10750933736562729\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.106, train_loss_epoch=0.108]Epoch 46: Train Loss = 0.10590837150812149\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.105, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.1047939583659172\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.102, train_loss_epoch=0.105]Epoch 48: Train Loss = 0.10215093195438385\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.101, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.10120327025651932\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.101, train_loss_epoch=0.101]Epoch 50: Train Loss = 0.10093484818935394\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0968, train_loss_epoch=0.101]Epoch 51: Train Loss = 0.09677091985940933\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0964, train_loss_epoch=0.0968]Epoch 52: Train Loss = 0.09636655449867249\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0933, train_loss_epoch=0.0964]Epoch 53: Train Loss = 0.09332984685897827\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0926, train_loss_epoch=0.0933]Epoch 54: Train Loss = 0.09255106002092361\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0925, train_loss_epoch=0.0926]Epoch 55: Train Loss = 0.09245753288269043\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0913, train_loss_epoch=0.0925]Epoch 56: Train Loss = 0.09133501350879669\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0866, train_loss_epoch=0.0913]Epoch 57: Train Loss = 0.08657795190811157\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0891, train_loss_epoch=0.0866]Epoch 58: Train Loss = 0.08911353349685669\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0849, train_loss_epoch=0.0891]Epoch 59: Train Loss = 0.08489286154508591\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0872, train_loss_epoch=0.0849]Epoch 60: Train Loss = 0.08724786341190338\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0802, train_loss_epoch=0.0872]Epoch 61: Train Loss = 0.08023142069578171\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0813, train_loss_epoch=0.0802]Epoch 62: Train Loss = 0.08132359385490417\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0794, train_loss_epoch=0.0813]Epoch 63: Train Loss = 0.07942225784063339\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0773, train_loss_epoch=0.0794]Epoch 64: Train Loss = 0.07733220607042313\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0781, train_loss_epoch=0.0773]Epoch 65: Train Loss = 0.0780535563826561\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0761, train_loss_epoch=0.0781]Epoch 66: Train Loss = 0.07607866823673248\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0762, train_loss_epoch=0.0761]Epoch 67: Train Loss = 0.07618794590234756\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0739, train_loss_epoch=0.0762]Epoch 68: Train Loss = 0.07385483384132385\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0725, train_loss_epoch=0.0739]Epoch 69: Train Loss = 0.07248781621456146\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0718, train_loss_epoch=0.0725]Epoch 70: Train Loss = 0.07176407426595688\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0709, train_loss_epoch=0.0718]Epoch 71: Train Loss = 0.07089138776063919\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0704, train_loss_epoch=0.0709]Epoch 72: Train Loss = 0.07043252140283585\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0694, train_loss_epoch=0.0704]Epoch 73: Train Loss = 0.06937531381845474\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0688, train_loss_epoch=0.0694]Epoch 74: Train Loss = 0.0688318982720375\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0673, train_loss_epoch=0.0688]Epoch 75: Train Loss = 0.06728440523147583\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0659, train_loss_epoch=0.0673]Epoch 76: Train Loss = 0.06589065492153168\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0677, train_loss_epoch=0.0659]Epoch 77: Train Loss = 0.06773310899734497\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0644, train_loss_epoch=0.0677]Epoch 78: Train Loss = 0.06438078731298447\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0638, train_loss_epoch=0.0644]Epoch 79: Train Loss = 0.06383916735649109\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0635, train_loss_epoch=0.0638]Epoch 80: Train Loss = 0.06351698189973831\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0619, train_loss_epoch=0.0635]Epoch 81: Train Loss = 0.06185465678572655\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0627, train_loss_epoch=0.0619]Epoch 82: Train Loss = 0.06273870915174484\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0603, train_loss_epoch=0.0627]Epoch 83: Train Loss = 0.060346875339746475\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0614, train_loss_epoch=0.0603]Epoch 84: Train Loss = 0.061362333595752716\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0594, train_loss_epoch=0.0614]Epoch 85: Train Loss = 0.05935734882950783\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.058, train_loss_epoch=0.0594] Epoch 86: Train Loss = 0.057956404983997345\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0582, train_loss_epoch=0.058]Epoch 87: Train Loss = 0.058190155774354935\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0572, train_loss_epoch=0.0582]Epoch 88: Train Loss = 0.05717916414141655\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0574, train_loss_epoch=0.0572]Epoch 89: Train Loss = 0.05737078934907913\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0573, train_loss_epoch=0.0574]Epoch 90: Train Loss = 0.05730530247092247\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0549, train_loss_epoch=0.0573]Epoch 91: Train Loss = 0.054865043610334396\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0544, train_loss_epoch=0.0549]Epoch 92: Train Loss = 0.05436840280890465\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0543, train_loss_epoch=0.0544]Epoch 93: Train Loss = 0.054310914129018784\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0548, train_loss_epoch=0.0543]Epoch 94: Train Loss = 0.05476554110646248\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0529, train_loss_epoch=0.0548]Epoch 95: Train Loss = 0.05293725058436394\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0562, train_loss_epoch=0.0529]Epoch 96: Train Loss = 0.056186649948358536\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0525, train_loss_epoch=0.0562]Epoch 97: Train Loss = 0.05245281383395195\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0578, train_loss_epoch=0.0525]Epoch 98: Train Loss = 0.05778735876083374\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0521, train_loss_epoch=0.0578]Epoch 99: Train Loss = 0.052144285291433334\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.052, train_loss_epoch=0.0521] Epoch 100: Train Loss = 0.05196702107787132\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0507, train_loss_epoch=0.052]Epoch 101: Train Loss = 0.0506775863468647\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0506, train_loss_epoch=0.0507]Epoch 102: Train Loss = 0.050597093999385834\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.050, train_loss_epoch=0.0506] Epoch 103: Train Loss = 0.05001034960150719\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0484, train_loss_epoch=0.050]Epoch 104: Train Loss = 0.048420555889606476\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0499, train_loss_epoch=0.0484]Epoch 105: Train Loss = 0.049931593239307404\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0492, train_loss_epoch=0.0499]Epoch 106: Train Loss = 0.049186188727617264\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0488, train_loss_epoch=0.0492]Epoch 107: Train Loss = 0.04875553399324417\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0481, train_loss_epoch=0.0488]Epoch 108: Train Loss = 0.04808264598250389\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0499, train_loss_epoch=0.0481]Epoch 109: Train Loss = 0.04986383765935898\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0468, train_loss_epoch=0.0499]Epoch 110: Train Loss = 0.04678703472018242\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0493, train_loss_epoch=0.0468]Epoch 111: Train Loss = 0.04925429821014404\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0467, train_loss_epoch=0.0493]Epoch 112: Train Loss = 0.04673212394118309\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0487, train_loss_epoch=0.0467]Epoch 113: Train Loss = 0.04869012534618378\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.050, train_loss_epoch=0.0487] Epoch 114: Train Loss = 0.05004788562655449\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0456, train_loss_epoch=0.050]Epoch 115: Train Loss = 0.0456065908074379\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0464, train_loss_epoch=0.0456]Epoch 116: Train Loss = 0.046393632888793945\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0452, train_loss_epoch=0.0464]Epoch 117: Train Loss = 0.04522189125418663\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0446, train_loss_epoch=0.0452]Epoch 118: Train Loss = 0.0445961058139801\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0459, train_loss_epoch=0.0446]Epoch 119: Train Loss = 0.04585198685526848\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0439, train_loss_epoch=0.0459]Epoch 120: Train Loss = 0.04386366531252861\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0455, train_loss_epoch=0.0439]Epoch 121: Train Loss = 0.04547574371099472\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0438, train_loss_epoch=0.0455]Epoch 122: Train Loss = 0.043765898793935776\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0443, train_loss_epoch=0.0438]Epoch 123: Train Loss = 0.04428824409842491\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0425, train_loss_epoch=0.0443]Epoch 124: Train Loss = 0.042535535991191864\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0428, train_loss_epoch=0.0425]Epoch 125: Train Loss = 0.04275241866707802\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0419, train_loss_epoch=0.0428]Epoch 126: Train Loss = 0.04185924306511879\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0455, train_loss_epoch=0.0419]Epoch 127: Train Loss = 0.045548196882009506\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.041, train_loss_epoch=0.0455] Epoch 128: Train Loss = 0.040976956486701965\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0428, train_loss_epoch=0.041]Epoch 129: Train Loss = 0.04281225800514221\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0407, train_loss_epoch=0.0428]Epoch 130: Train Loss = 0.04068595916032791\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0413, train_loss_epoch=0.0407]Epoch 131: Train Loss = 0.041339997202157974\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0407, train_loss_epoch=0.0413]Epoch 132: Train Loss = 0.04071781039237976\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0409, train_loss_epoch=0.0407]Epoch 133: Train Loss = 0.04089010879397392\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0406, train_loss_epoch=0.0409]Epoch 134: Train Loss = 0.04061966389417648\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0413, train_loss_epoch=0.0406]Epoch 135: Train Loss = 0.041261907666921616\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0407, train_loss_epoch=0.0413]Epoch 136: Train Loss = 0.04070562869310379\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0404, train_loss_epoch=0.0407]Epoch 137: Train Loss = 0.04039948433637619\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0397, train_loss_epoch=0.0404]Epoch 138: Train Loss = 0.03971538320183754\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0393, train_loss_epoch=0.0397]Epoch 139: Train Loss = 0.039324820041656494\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0427, train_loss_epoch=0.0393]Epoch 140: Train Loss = 0.042737074196338654\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0419, train_loss_epoch=0.0427]Epoch 141: Train Loss = 0.041872020810842514\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0391, train_loss_epoch=0.0419]Epoch 142: Train Loss = 0.03906158730387688\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0438, train_loss_epoch=0.0391]Epoch 143: Train Loss = 0.043844833970069885\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.038, train_loss_epoch=0.0438] Epoch 144: Train Loss = 0.0380157008767128\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0431, train_loss_epoch=0.038]Epoch 145: Train Loss = 0.04310085251927376\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.039, train_loss_epoch=0.0431] Epoch 146: Train Loss = 0.038976699113845825\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0387, train_loss_epoch=0.039]Epoch 147: Train Loss = 0.03874535858631134\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0377, train_loss_epoch=0.0387]Epoch 148: Train Loss = 0.03769904747605324\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0387, train_loss_epoch=0.0377]Epoch 149: Train Loss = 0.03866352513432503\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0384, train_loss_epoch=0.0387]Epoch 150: Train Loss = 0.038389600813388824\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0429, train_loss_epoch=0.0384]Epoch 151: Train Loss = 0.042922280728816986\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0379, train_loss_epoch=0.0429]Epoch 152: Train Loss = 0.03794652968645096\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0447, train_loss_epoch=0.0379]Epoch 153: Train Loss = 0.04472967982292175\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0371, train_loss_epoch=0.0447]Epoch 154: Train Loss = 0.03712046146392822\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0383, train_loss_epoch=0.0371]Epoch 155: Train Loss = 0.038257062435150146\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0379, train_loss_epoch=0.0383]Epoch 156: Train Loss = 0.037927404046058655\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0369, train_loss_epoch=0.0379]Epoch 157: Train Loss = 0.03686612844467163\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0392, train_loss_epoch=0.0369]Epoch 158: Train Loss = 0.03924011066555977\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0364, train_loss_epoch=0.0392]Epoch 159: Train Loss = 0.03637590631842613\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0443, train_loss_epoch=0.0364]Epoch 160: Train Loss = 0.04428864270448685\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0371, train_loss_epoch=0.0443]Epoch 161: Train Loss = 0.037083592265844345\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0442, train_loss_epoch=0.0371]Epoch 162: Train Loss = 0.04417416825890541\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0359, train_loss_epoch=0.0442]Epoch 163: Train Loss = 0.035908058285713196\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0397, train_loss_epoch=0.0359]Epoch 164: Train Loss = 0.03968537226319313\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0384, train_loss_epoch=0.0397]Epoch 165: Train Loss = 0.03839073330163956\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0377, train_loss_epoch=0.0384]Epoch 166: Train Loss = 0.03771362453699112\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.038, train_loss_epoch=0.0377] Epoch 167: Train Loss = 0.03804904222488403\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0359, train_loss_epoch=0.038]Epoch 168: Train Loss = 0.035928208380937576\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0411, train_loss_epoch=0.0359]Epoch 169: Train Loss = 0.041126541793346405\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0366, train_loss_epoch=0.0411]Epoch 170: Train Loss = 0.03655167669057846\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0417, train_loss_epoch=0.0366]Epoch 171: Train Loss = 0.04172245413064957\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0354, train_loss_epoch=0.0417]Epoch 172: Train Loss = 0.035441022366285324\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0406, train_loss_epoch=0.0354]Epoch 173: Train Loss = 0.040628377348184586\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0342, train_loss_epoch=0.0406]Epoch 174: Train Loss = 0.03419477492570877\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0368, train_loss_epoch=0.0342]Epoch 175: Train Loss = 0.03680591285228729\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0345, train_loss_epoch=0.0368]Epoch 176: Train Loss = 0.034497812390327454\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0347, train_loss_epoch=0.0345]Epoch 177: Train Loss = 0.03467736765742302\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0349, train_loss_epoch=0.0347]Epoch 178: Train Loss = 0.0348992757499218\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0344, train_loss_epoch=0.0349]Epoch 179: Train Loss = 0.03436949849128723\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0339, train_loss_epoch=0.0344]Epoch 180: Train Loss = 0.03388199582695961\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0378, train_loss_epoch=0.0339]Epoch 181: Train Loss = 0.03778728097677231\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0338, train_loss_epoch=0.0378]Epoch 182: Train Loss = 0.03378532826900482\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0356, train_loss_epoch=0.0338]Epoch 183: Train Loss = 0.03562852740287781\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0359, train_loss_epoch=0.0356]Epoch 184: Train Loss = 0.03585369884967804\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0355, train_loss_epoch=0.0359]Epoch 185: Train Loss = 0.03546179458498955\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0343, train_loss_epoch=0.0355]Epoch 186: Train Loss = 0.034317146986722946\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.033, train_loss_epoch=0.0343] Epoch 187: Train Loss = 0.03298512101173401\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0323, train_loss_epoch=0.033]Epoch 188: Train Loss = 0.03232547268271446\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0374, train_loss_epoch=0.0323]Epoch 189: Train Loss = 0.03740685060620308\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0368, train_loss_epoch=0.0374]Epoch 190: Train Loss = 0.036773111671209335\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0336, train_loss_epoch=0.0368]Epoch 191: Train Loss = 0.0335911326110363\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0332, train_loss_epoch=0.0336]Epoch 192: Train Loss = 0.033223602920770645\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0338, train_loss_epoch=0.0332]Epoch 193: Train Loss = 0.033774569630622864\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0339, train_loss_epoch=0.0338]Epoch 194: Train Loss = 0.03387955203652382\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0336, train_loss_epoch=0.0339]Epoch 195: Train Loss = 0.0335746668279171\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0334, train_loss_epoch=0.0336]Epoch 196: Train Loss = 0.03335900232195854\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0326, train_loss_epoch=0.0334]Epoch 197: Train Loss = 0.03262729570269585\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0336, train_loss_epoch=0.0326]Epoch 198: Train Loss = 0.03356657177209854\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0329, train_loss_epoch=0.0336]Epoch 199: Train Loss = 0.03288530558347702\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0337, train_loss_epoch=0.0329]Epoch 200: Train Loss = 0.03373080864548683\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0367, train_loss_epoch=0.0337]Epoch 201: Train Loss = 0.036697156727313995\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0336, train_loss_epoch=0.0367]Epoch 202: Train Loss = 0.03358301892876625\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0402, train_loss_epoch=0.0336]Epoch 203: Train Loss = 0.04020366072654724\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0326, train_loss_epoch=0.0402]Epoch 204: Train Loss = 0.03263015300035477\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0391, train_loss_epoch=0.0326]Epoch 205: Train Loss = 0.039128318428993225\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.034, train_loss_epoch=0.0391] Epoch 206: Train Loss = 0.033957310020923615\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.041, train_loss_epoch=0.034] Epoch 207: Train Loss = 0.04102081432938576\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0349, train_loss_epoch=0.041]Epoch 208: Train Loss = 0.034888856112957\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.034, train_loss_epoch=0.0349] Epoch 209: Train Loss = 0.03399283438920975\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0383, train_loss_epoch=0.034]Epoch 210: Train Loss = 0.03834059089422226\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0325, train_loss_epoch=0.0383]Epoch 211: Train Loss = 0.03253866732120514\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0345, train_loss_epoch=0.0325]Epoch 212: Train Loss = 0.034455690532922745\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0321, train_loss_epoch=0.0345]Epoch 213: Train Loss = 0.03209295496344566\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.034, train_loss_epoch=0.0321] Epoch 214: Train Loss = 0.0340246818959713\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0316, train_loss_epoch=0.034]Epoch 215: Train Loss = 0.03157363459467888\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0327, train_loss_epoch=0.0316]Epoch 216: Train Loss = 0.03267078846693039\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0309, train_loss_epoch=0.0327]Epoch 217: Train Loss = 0.03093094751238823\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0319, train_loss_epoch=0.0309]Epoch 218: Train Loss = 0.03187065199017525\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0315, train_loss_epoch=0.0319]Epoch 219: Train Loss = 0.0315094031393528\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0316, train_loss_epoch=0.0315]Epoch 220: Train Loss = 0.03159788250923157\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0314, train_loss_epoch=0.0316]Epoch 221: Train Loss = 0.03142643719911575\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0313, train_loss_epoch=0.0314]Epoch 222: Train Loss = 0.03133464604616165\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0363, train_loss_epoch=0.0313]Epoch 223: Train Loss = 0.03633178770542145\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0324, train_loss_epoch=0.0363]Epoch 224: Train Loss = 0.03242407739162445\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0354, train_loss_epoch=0.0324]Epoch 225: Train Loss = 0.035357970744371414\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.030, train_loss_epoch=0.0354] Epoch 226: Train Loss = 0.029963403940200806\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0354, train_loss_epoch=0.030]Epoch 227: Train Loss = 0.035371411591768265\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0314, train_loss_epoch=0.0354]Epoch 228: Train Loss = 0.031417619436979294\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0325, train_loss_epoch=0.0314]Epoch 229: Train Loss = 0.032532937824726105\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0354, train_loss_epoch=0.0325]Epoch 230: Train Loss = 0.035396527498960495\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0322, train_loss_epoch=0.0354]Epoch 231: Train Loss = 0.03224383667111397\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0372, train_loss_epoch=0.0322]Epoch 232: Train Loss = 0.03717609494924545\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0314, train_loss_epoch=0.0372]Epoch 233: Train Loss = 0.031419966369867325\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0347, train_loss_epoch=0.0314]Epoch 234: Train Loss = 0.034652359783649445\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0303, train_loss_epoch=0.0347]Epoch 235: Train Loss = 0.030311118811368942\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0332, train_loss_epoch=0.0303]Epoch 236: Train Loss = 0.03319094702601433\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0322, train_loss_epoch=0.0332]Epoch 237: Train Loss = 0.0322161465883255\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0368, train_loss_epoch=0.0322]Epoch 238: Train Loss = 0.036807019263505936\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0303, train_loss_epoch=0.0368]Epoch 239: Train Loss = 0.030299624428153038\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0334, train_loss_epoch=0.0303]Epoch 240: Train Loss = 0.03338601067662239\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.0293, train_loss_epoch=0.0334]Epoch 241: Train Loss = 0.029256487265229225\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.031, train_loss_epoch=0.0293] Epoch 242: Train Loss = 0.03097354806959629\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.031, train_loss_epoch=0.031] Epoch 243: Train Loss = 0.030995521694421768\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0298, train_loss_epoch=0.031]Epoch 244: Train Loss = 0.029763292521238327\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0305, train_loss_epoch=0.0298]Epoch 245: Train Loss = 0.030462950468063354\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=210, train_loss_step=0.0314, train_loss_epoch=0.0305]Epoch 246: Train Loss = 0.0314147025346756\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=210, train_loss_step=0.030, train_loss_epoch=0.0314] Epoch 247: Train Loss = 0.030045567080378532\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0302, train_loss_epoch=0.030]Epoch 248: Train Loss = 0.030170924961566925\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0311, train_loss_epoch=0.0302]Epoch 249: Train Loss = 0.031133880838751793\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0311, train_loss_epoch=0.0311]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=210, train_loss_step=0.0311, train_loss_epoch=0.0311]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 13: from 1998-11-02 00:00:00 to 2022-04-27 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.394]Epoch 0: Train Loss = 0.3942417502403259\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.502, train_loss_epoch=0.394]Epoch 1: Train Loss = 0.5024809241294861\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.366, train_loss_epoch=0.502]Epoch 2: Train Loss = 0.3661916255950928\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.251, train_loss_epoch=0.366]Epoch 3: Train Loss = 0.2509876489639282\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.317, train_loss_epoch=0.251]Epoch 4: Train Loss = 0.3169606626033783\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.307, train_loss_epoch=0.317]Epoch 5: Train Loss = 0.3070460259914398\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.252, train_loss_epoch=0.307]Epoch 6: Train Loss = 0.25185683369636536\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.239, train_loss_epoch=0.252]Epoch 7: Train Loss = 0.23919637501239777\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.270, train_loss_epoch=0.239]Epoch 8: Train Loss = 0.2703583240509033\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.267, train_loss_epoch=0.270]Epoch 9: Train Loss = 0.26712048053741455\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.241, train_loss_epoch=0.267]Epoch 10: Train Loss = 0.24119365215301514\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.217, train_loss_epoch=0.241]Epoch 11: Train Loss = 0.21732258796691895\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.233, train_loss_epoch=0.217]Epoch 12: Train Loss = 0.2325306385755539\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.221, train_loss_epoch=0.233]Epoch 13: Train Loss = 0.22147823870182037\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.214, train_loss_epoch=0.221]Epoch 14: Train Loss = 0.21393243968486786\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.195, train_loss_epoch=0.214]Epoch 15: Train Loss = 0.19465766847133636\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.199, train_loss_epoch=0.195]Epoch 16: Train Loss = 0.19938501715660095\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.189, train_loss_epoch=0.199]Epoch 17: Train Loss = 0.18922966718673706\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.197, train_loss_epoch=0.189]Epoch 18: Train Loss = 0.19697469472885132\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.175, train_loss_epoch=0.197]Epoch 19: Train Loss = 0.17533640563488007\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.166, train_loss_epoch=0.175]Epoch 20: Train Loss = 0.16554328799247742\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.179, train_loss_epoch=0.166]Epoch 21: Train Loss = 0.17902792990207672\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.177, train_loss_epoch=0.179]Epoch 22: Train Loss = 0.17693133652210236\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.167, train_loss_epoch=0.177]Epoch 23: Train Loss = 0.16663435101509094\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.159, train_loss_epoch=0.167]Epoch 24: Train Loss = 0.1588488072156906\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.153, train_loss_epoch=0.159]Epoch 25: Train Loss = 0.1525828093290329\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.159, train_loss_epoch=0.153]Epoch 26: Train Loss = 0.15922914445400238\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.154, train_loss_epoch=0.159]Epoch 27: Train Loss = 0.1543094664812088\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.148, train_loss_epoch=0.154]Epoch 28: Train Loss = 0.14776720106601715\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.149, train_loss_epoch=0.148]Epoch 29: Train Loss = 0.14891481399536133\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.142, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.1417059302330017\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.144, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.14390113949775696\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.139, train_loss_epoch=0.144]Epoch 32: Train Loss = 0.1388053596019745\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.133, train_loss_epoch=0.139]Epoch 33: Train Loss = 0.1334221363067627\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.136, train_loss_epoch=0.133]Epoch 34: Train Loss = 0.13570547103881836\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.132, train_loss_epoch=0.136]Epoch 35: Train Loss = 0.13162006437778473\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.130, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.12986266613006592\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.129, train_loss_epoch=0.130]Epoch 37: Train Loss = 0.12941768765449524\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.122, train_loss_epoch=0.129]Epoch 38: Train Loss = 0.12230204790830612\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.120, train_loss_epoch=0.122]Epoch 39: Train Loss = 0.11950507014989853\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.116, train_loss_epoch=0.120]Epoch 40: Train Loss = 0.1162785142660141\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.118, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11800343543291092\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.117, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.1166117936372757\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.110, train_loss_epoch=0.117]Epoch 43: Train Loss = 0.10980289429426193\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.114, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11396007239818573\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.107, train_loss_epoch=0.114]Epoch 45: Train Loss = 0.10671126842498779\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.108, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10760585963726044\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.104, train_loss_epoch=0.108]Epoch 47: Train Loss = 0.10363338887691498\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.103, train_loss_epoch=0.104]Epoch 48: Train Loss = 0.1025829017162323\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.103, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.10286897420883179\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0991, train_loss_epoch=0.103]Epoch 50: Train Loss = 0.0990801453590393\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0977, train_loss_epoch=0.0991]Epoch 51: Train Loss = 0.09774402529001236\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0958, train_loss_epoch=0.0977]Epoch 52: Train Loss = 0.09580951929092407\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0944, train_loss_epoch=0.0958]Epoch 53: Train Loss = 0.09440223127603531\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0927, train_loss_epoch=0.0944]Epoch 54: Train Loss = 0.09273023158311844\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0917, train_loss_epoch=0.0927]Epoch 55: Train Loss = 0.09170884639024734\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0909, train_loss_epoch=0.0917]Epoch 56: Train Loss = 0.09092088043689728\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.090, train_loss_epoch=0.0909] Epoch 57: Train Loss = 0.09000188112258911\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0871, train_loss_epoch=0.090]Epoch 58: Train Loss = 0.08707765489816666\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0866, train_loss_epoch=0.0871]Epoch 59: Train Loss = 0.08658120781183243\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.088, train_loss_epoch=0.0866] Epoch 60: Train Loss = 0.0880141481757164\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0818, train_loss_epoch=0.088]Epoch 61: Train Loss = 0.0817931741476059\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0896, train_loss_epoch=0.0818]Epoch 62: Train Loss = 0.08960501849651337\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0804, train_loss_epoch=0.0896]Epoch 63: Train Loss = 0.08044277131557465\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0833, train_loss_epoch=0.0804]Epoch 64: Train Loss = 0.08327474445104599\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0791, train_loss_epoch=0.0833]Epoch 65: Train Loss = 0.07906474173069\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0792, train_loss_epoch=0.0791]Epoch 66: Train Loss = 0.079245425760746\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0798, train_loss_epoch=0.0792]Epoch 67: Train Loss = 0.07983753085136414\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0753, train_loss_epoch=0.0798]Epoch 68: Train Loss = 0.0752723217010498\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0748, train_loss_epoch=0.0753]Epoch 69: Train Loss = 0.07477952539920807\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0751, train_loss_epoch=0.0748]Epoch 70: Train Loss = 0.07512404769659042\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.073, train_loss_epoch=0.0751] Epoch 71: Train Loss = 0.07302524894475937\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0769, train_loss_epoch=0.073]Epoch 72: Train Loss = 0.0768507570028305\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0698, train_loss_epoch=0.0769]Epoch 73: Train Loss = 0.06982892006635666\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0745, train_loss_epoch=0.0698]Epoch 74: Train Loss = 0.07451348751783371\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.068, train_loss_epoch=0.0745] Epoch 75: Train Loss = 0.0680215060710907\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0691, train_loss_epoch=0.068]Epoch 76: Train Loss = 0.06905244290828705\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0698, train_loss_epoch=0.0691]Epoch 77: Train Loss = 0.06980714201927185\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0681, train_loss_epoch=0.0698]Epoch 78: Train Loss = 0.06811412423849106\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0667, train_loss_epoch=0.0681]Epoch 79: Train Loss = 0.06672737747430801\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.064, train_loss_epoch=0.0667] Epoch 80: Train Loss = 0.06401155143976212\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0666, train_loss_epoch=0.064]Epoch 81: Train Loss = 0.06661625951528549\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0641, train_loss_epoch=0.0666]Epoch 82: Train Loss = 0.06414292752742767\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0673, train_loss_epoch=0.0641]Epoch 83: Train Loss = 0.0672932118177414\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0632, train_loss_epoch=0.0673]Epoch 84: Train Loss = 0.06317319720983505\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0628, train_loss_epoch=0.0632]Epoch 85: Train Loss = 0.06277252733707428\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0615, train_loss_epoch=0.0628]Epoch 86: Train Loss = 0.06147453933954239\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.061, train_loss_epoch=0.0615] Epoch 87: Train Loss = 0.06096549704670906\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.061, train_loss_epoch=0.061] Epoch 88: Train Loss = 0.06103929877281189\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0595, train_loss_epoch=0.061]Epoch 89: Train Loss = 0.05954646319150925\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0598, train_loss_epoch=0.0595]Epoch 90: Train Loss = 0.059816211462020874\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0563, train_loss_epoch=0.0598]Epoch 91: Train Loss = 0.05631323158740997\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0616, train_loss_epoch=0.0563]Epoch 92: Train Loss = 0.0616065077483654\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0554, train_loss_epoch=0.0616]Epoch 93: Train Loss = 0.055388063192367554\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0596, train_loss_epoch=0.0554]Epoch 94: Train Loss = 0.05957334116101265\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0552, train_loss_epoch=0.0596]Epoch 95: Train Loss = 0.0552230104804039\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0601, train_loss_epoch=0.0552]Epoch 96: Train Loss = 0.06005881354212761\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.056, train_loss_epoch=0.0601] Epoch 97: Train Loss = 0.056028638035058975\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0559, train_loss_epoch=0.056]Epoch 98: Train Loss = 0.055920153856277466\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0569, train_loss_epoch=0.0559]Epoch 99: Train Loss = 0.05687181279063225\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0516, train_loss_epoch=0.0569]Epoch 100: Train Loss = 0.05158320069313049\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0572, train_loss_epoch=0.0516]Epoch 101: Train Loss = 0.05722775682806969\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0519, train_loss_epoch=0.0572]Epoch 102: Train Loss = 0.0518859401345253\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0528, train_loss_epoch=0.0519]Epoch 103: Train Loss = 0.052803654223680496\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0518, train_loss_epoch=0.0528]Epoch 104: Train Loss = 0.051816441118717194\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0513, train_loss_epoch=0.0518]Epoch 105: Train Loss = 0.05130646750330925\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0535, train_loss_epoch=0.0513]Epoch 106: Train Loss = 0.0534745417535305\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0507, train_loss_epoch=0.0535]Epoch 107: Train Loss = 0.05071442201733589\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0588, train_loss_epoch=0.0507]Epoch 108: Train Loss = 0.058798450976610184\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0522, train_loss_epoch=0.0588]Epoch 109: Train Loss = 0.052212174981832504\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0529, train_loss_epoch=0.0522]Epoch 110: Train Loss = 0.052939802408218384\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0547, train_loss_epoch=0.0529]Epoch 111: Train Loss = 0.05470891669392586\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0501, train_loss_epoch=0.0547]Epoch 112: Train Loss = 0.05010863393545151\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0555, train_loss_epoch=0.0501]Epoch 113: Train Loss = 0.05554438382387161\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0485, train_loss_epoch=0.0555]Epoch 114: Train Loss = 0.048515018075704575\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.054, train_loss_epoch=0.0485] Epoch 115: Train Loss = 0.05399242788553238\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0504, train_loss_epoch=0.054]Epoch 116: Train Loss = 0.05037374049425125\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0475, train_loss_epoch=0.0504]Epoch 117: Train Loss = 0.04753716662526131\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.052, train_loss_epoch=0.0475] Epoch 118: Train Loss = 0.05197054147720337\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0468, train_loss_epoch=0.052]Epoch 119: Train Loss = 0.04679781198501587\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.050, train_loss_epoch=0.0468] Epoch 120: Train Loss = 0.050033461302518845\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0476, train_loss_epoch=0.050]Epoch 121: Train Loss = 0.047615282237529755\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0484, train_loss_epoch=0.0476]Epoch 122: Train Loss = 0.048382241278886795\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0467, train_loss_epoch=0.0484]Epoch 123: Train Loss = 0.046704087406396866\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0452, train_loss_epoch=0.0467]Epoch 124: Train Loss = 0.04516404867172241\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0463, train_loss_epoch=0.0452]Epoch 125: Train Loss = 0.04629111662507057\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0442, train_loss_epoch=0.0463]Epoch 126: Train Loss = 0.04420429468154907\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0447, train_loss_epoch=0.0442]Epoch 127: Train Loss = 0.04474376514554024\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0443, train_loss_epoch=0.0447]Epoch 128: Train Loss = 0.04430750384926796\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0436, train_loss_epoch=0.0443]Epoch 129: Train Loss = 0.043554745614528656\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0424, train_loss_epoch=0.0436]Epoch 130: Train Loss = 0.04237121716141701\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0441, train_loss_epoch=0.0424]Epoch 131: Train Loss = 0.04408197104930878\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0436, train_loss_epoch=0.0441]Epoch 132: Train Loss = 0.04359310120344162\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0424, train_loss_epoch=0.0436]Epoch 133: Train Loss = 0.04243473336100578\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0444, train_loss_epoch=0.0424]Epoch 134: Train Loss = 0.044383637607097626\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0426, train_loss_epoch=0.0444]Epoch 135: Train Loss = 0.042584095150232315\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0458, train_loss_epoch=0.0426]Epoch 136: Train Loss = 0.04576369747519493\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0422, train_loss_epoch=0.0458]Epoch 137: Train Loss = 0.04216824844479561\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0486, train_loss_epoch=0.0422]Epoch 138: Train Loss = 0.04864836856722832\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.044, train_loss_epoch=0.0486] Epoch 139: Train Loss = 0.0439697690308094\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0449, train_loss_epoch=0.044]Epoch 140: Train Loss = 0.04494033381342888\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0459, train_loss_epoch=0.0449]Epoch 141: Train Loss = 0.045925166457891464\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.042, train_loss_epoch=0.0459] Epoch 142: Train Loss = 0.041951585561037064\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0467, train_loss_epoch=0.042]Epoch 143: Train Loss = 0.04671134427189827\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0428, train_loss_epoch=0.0467]Epoch 144: Train Loss = 0.04275362566113472\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0476, train_loss_epoch=0.0428]Epoch 145: Train Loss = 0.04756632447242737\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0449, train_loss_epoch=0.0476]Epoch 146: Train Loss = 0.04486573487520218\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0404, train_loss_epoch=0.0449]Epoch 147: Train Loss = 0.04035165533423424\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0435, train_loss_epoch=0.0404]Epoch 148: Train Loss = 0.04354787990450859\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0389, train_loss_epoch=0.0435]Epoch 149: Train Loss = 0.038884248584508896\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0411, train_loss_epoch=0.0389]Epoch 150: Train Loss = 0.04111836105585098\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0402, train_loss_epoch=0.0411]Epoch 151: Train Loss = 0.04020160436630249\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0392, train_loss_epoch=0.0402]Epoch 152: Train Loss = 0.03916424885392189\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0413, train_loss_epoch=0.0392]Epoch 153: Train Loss = 0.041278425604104996\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0387, train_loss_epoch=0.0413]Epoch 154: Train Loss = 0.038679949939250946\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0401, train_loss_epoch=0.0387]Epoch 155: Train Loss = 0.04013004153966904\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0392, train_loss_epoch=0.0401]Epoch 156: Train Loss = 0.039183344691991806\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0396, train_loss_epoch=0.0392]Epoch 157: Train Loss = 0.03962286561727524\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0404, train_loss_epoch=0.0396]Epoch 158: Train Loss = 0.04040367901325226\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0409, train_loss_epoch=0.0404]Epoch 159: Train Loss = 0.040878862142562866\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0384, train_loss_epoch=0.0409]Epoch 160: Train Loss = 0.03838694468140602\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0386, train_loss_epoch=0.0384]Epoch 161: Train Loss = 0.03859848901629448\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0376, train_loss_epoch=0.0386]Epoch 162: Train Loss = 0.037562403827905655\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0382, train_loss_epoch=0.0376]Epoch 163: Train Loss = 0.038178812712430954\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0374, train_loss_epoch=0.0382]Epoch 164: Train Loss = 0.037371229380369186\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0383, train_loss_epoch=0.0374]Epoch 165: Train Loss = 0.03831907734274864\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0385, train_loss_epoch=0.0383]Epoch 166: Train Loss = 0.03846028074622154\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0386, train_loss_epoch=0.0385]Epoch 167: Train Loss = 0.03864055126905441\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0374, train_loss_epoch=0.0386]Epoch 168: Train Loss = 0.03743603080511093\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0383, train_loss_epoch=0.0374]Epoch 169: Train Loss = 0.038349345326423645\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0363, train_loss_epoch=0.0383]Epoch 170: Train Loss = 0.03626381605863571\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0372, train_loss_epoch=0.0363]Epoch 171: Train Loss = 0.03724927082657814\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.036, train_loss_epoch=0.0372] Epoch 172: Train Loss = 0.035997986793518066\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0367, train_loss_epoch=0.036]Epoch 173: Train Loss = 0.03665070980787277\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0358, train_loss_epoch=0.0367]Epoch 174: Train Loss = 0.035841260105371475\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0371, train_loss_epoch=0.0358]Epoch 175: Train Loss = 0.03707123547792435\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0367, train_loss_epoch=0.0371]Epoch 176: Train Loss = 0.03668544441461563\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0368, train_loss_epoch=0.0367]Epoch 177: Train Loss = 0.03681008145213127\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0358, train_loss_epoch=0.0368]Epoch 178: Train Loss = 0.03580191731452942\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0352, train_loss_epoch=0.0358]Epoch 179: Train Loss = 0.035171765834093094\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0364, train_loss_epoch=0.0352]Epoch 180: Train Loss = 0.036354053765535355\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0358, train_loss_epoch=0.0364]Epoch 181: Train Loss = 0.03577393293380737\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0379, train_loss_epoch=0.0358]Epoch 182: Train Loss = 0.037901632487773895\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0363, train_loss_epoch=0.0379]Epoch 183: Train Loss = 0.03633173555135727\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0349, train_loss_epoch=0.0363]Epoch 184: Train Loss = 0.034931134432554245\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0345, train_loss_epoch=0.0349]Epoch 185: Train Loss = 0.03451691195368767\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0344, train_loss_epoch=0.0345]Epoch 186: Train Loss = 0.034425895661115646\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0353, train_loss_epoch=0.0344]Epoch 187: Train Loss = 0.03525004908442497\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0342, train_loss_epoch=0.0353]Epoch 188: Train Loss = 0.03420445695519447\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0358, train_loss_epoch=0.0342]Epoch 189: Train Loss = 0.03576463460922241\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0372, train_loss_epoch=0.0358]Epoch 190: Train Loss = 0.03717200085520744\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0347, train_loss_epoch=0.0372]Epoch 191: Train Loss = 0.03471483290195465\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0336, train_loss_epoch=0.0347]Epoch 192: Train Loss = 0.03357706218957901\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0347, train_loss_epoch=0.0336]Epoch 193: Train Loss = 0.03467181697487831\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0349, train_loss_epoch=0.0347]Epoch 194: Train Loss = 0.034907180815935135\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0345, train_loss_epoch=0.0349]Epoch 195: Train Loss = 0.03451107442378998\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0352, train_loss_epoch=0.0345]Epoch 196: Train Loss = 0.03518304228782654\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0333, train_loss_epoch=0.0352]Epoch 197: Train Loss = 0.03327612578868866\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0436, train_loss_epoch=0.0333]Epoch 198: Train Loss = 0.04360298067331314\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0348, train_loss_epoch=0.0436]Epoch 199: Train Loss = 0.03475409001111984\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0373, train_loss_epoch=0.0348]Epoch 200: Train Loss = 0.037289947271347046\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0331, train_loss_epoch=0.0373]Epoch 201: Train Loss = 0.03314226120710373\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0363, train_loss_epoch=0.0331]Epoch 202: Train Loss = 0.036282360553741455\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0354, train_loss_epoch=0.0363]Epoch 203: Train Loss = 0.0354277528822422\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0373, train_loss_epoch=0.0354]Epoch 204: Train Loss = 0.037346791476011276\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0346, train_loss_epoch=0.0373]Epoch 205: Train Loss = 0.0346343033015728\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0335, train_loss_epoch=0.0346]Epoch 206: Train Loss = 0.03352861478924751\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0329, train_loss_epoch=0.0335]Epoch 207: Train Loss = 0.032879460602998734\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0357, train_loss_epoch=0.0329]Epoch 208: Train Loss = 0.0357009582221508\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.033, train_loss_epoch=0.0357] Epoch 209: Train Loss = 0.03304900601506233\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0344, train_loss_epoch=0.033]Epoch 210: Train Loss = 0.03444782271981239\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0321, train_loss_epoch=0.0344]Epoch 211: Train Loss = 0.032077085226774216\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0342, train_loss_epoch=0.0321]Epoch 212: Train Loss = 0.0342438668012619\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0335, train_loss_epoch=0.0342]Epoch 213: Train Loss = 0.03352613374590874\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0325, train_loss_epoch=0.0335]Epoch 214: Train Loss = 0.03254856541752815\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0363, train_loss_epoch=0.0325]Epoch 215: Train Loss = 0.036273203790187836\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.033, train_loss_epoch=0.0363] Epoch 216: Train Loss = 0.03304360434412956\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.035, train_loss_epoch=0.033] Epoch 217: Train Loss = 0.03503834456205368\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0332, train_loss_epoch=0.035]Epoch 218: Train Loss = 0.03323475271463394\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0337, train_loss_epoch=0.0332]Epoch 219: Train Loss = 0.033704791218042374\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0335, train_loss_epoch=0.0337]Epoch 220: Train Loss = 0.03345559164881706\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.034, train_loss_epoch=0.0335] Epoch 221: Train Loss = 0.034036315977573395\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0334, train_loss_epoch=0.034]Epoch 222: Train Loss = 0.0334201343357563\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.0327, train_loss_epoch=0.0334]Epoch 223: Train Loss = 0.032701101154088974\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0396, train_loss_epoch=0.0327]Epoch 224: Train Loss = 0.03959362581372261\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0324, train_loss_epoch=0.0396]Epoch 225: Train Loss = 0.03240112215280533\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0349, train_loss_epoch=0.0324]Epoch 226: Train Loss = 0.03488047793507576\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0363, train_loss_epoch=0.0349]Epoch 227: Train Loss = 0.03627483919262886\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.040, train_loss_epoch=0.0363] Epoch 228: Train Loss = 0.04002537578344345\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0381, train_loss_epoch=0.040]Epoch 229: Train Loss = 0.03809669613838196\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=212, train_loss_step=0.033, train_loss_epoch=0.0381] Epoch 230: Train Loss = 0.0330045111477375\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0413, train_loss_epoch=0.033]Epoch 231: Train Loss = 0.04131406545639038\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0313, train_loss_epoch=0.0413]Epoch 232: Train Loss = 0.03129182755947113\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.036, train_loss_epoch=0.0313] Epoch 233: Train Loss = 0.036046646535396576\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0322, train_loss_epoch=0.036]Epoch 234: Train Loss = 0.032213207334280014\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0371, train_loss_epoch=0.0322]Epoch 235: Train Loss = 0.037097930908203125\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0314, train_loss_epoch=0.0371]Epoch 236: Train Loss = 0.031398992985486984\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0316, train_loss_epoch=0.0314]Epoch 237: Train Loss = 0.03160685673356056\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0334, train_loss_epoch=0.0316]Epoch 238: Train Loss = 0.03336081653833389\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0333, train_loss_epoch=0.0334]Epoch 239: Train Loss = 0.03334318846464157\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0389, train_loss_epoch=0.0333]Epoch 240: Train Loss = 0.03887033835053444\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.033, train_loss_epoch=0.0389] Epoch 241: Train Loss = 0.03296695277094841\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0321, train_loss_epoch=0.033]Epoch 242: Train Loss = 0.032106902450323105\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0391, train_loss_epoch=0.0321]Epoch 243: Train Loss = 0.039101917296648026\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0306, train_loss_epoch=0.0391]Epoch 244: Train Loss = 0.030627403408288956\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0398, train_loss_epoch=0.0306]Epoch 245: Train Loss = 0.03976479917764664\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0339, train_loss_epoch=0.0398]Epoch 246: Train Loss = 0.033901505172252655\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0347, train_loss_epoch=0.0339]Epoch 247: Train Loss = 0.03471016511321068\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0428, train_loss_epoch=0.0347]Epoch 248: Train Loss = 0.04281862452626228\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0306, train_loss_epoch=0.0428]Epoch 249: Train Loss = 0.030646277591586113\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=212, train_loss_step=0.0306, train_loss_epoch=0.0306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=212, train_loss_step=0.0306, train_loss_epoch=0.0306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 14: from 1998-11-02 00:00:00 to 2022-05-06 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.404]Epoch 0: Train Loss = 0.403655469417572\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.497, train_loss_epoch=0.404]Epoch 1: Train Loss = 0.49721837043762207\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.368, train_loss_epoch=0.497]Epoch 2: Train Loss = 0.3683761954307556\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.249, train_loss_epoch=0.368]Epoch 3: Train Loss = 0.2486961930990219\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.309, train_loss_epoch=0.249]Epoch 4: Train Loss = 0.308770090341568\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.310, train_loss_epoch=0.309]Epoch 5: Train Loss = 0.3100396692752838\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.257, train_loss_epoch=0.310]Epoch 6: Train Loss = 0.2573832869529724\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.241, train_loss_epoch=0.257]Epoch 7: Train Loss = 0.2406616061925888\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.271, train_loss_epoch=0.241]Epoch 8: Train Loss = 0.2709108591079712\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.260, train_loss_epoch=0.271]Epoch 9: Train Loss = 0.2603800594806671\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.240, train_loss_epoch=0.260]Epoch 10: Train Loss = 0.23980291187763214\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.224, train_loss_epoch=0.240]Epoch 11: Train Loss = 0.22376957535743713\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.238, train_loss_epoch=0.224]Epoch 12: Train Loss = 0.23839569091796875\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.220, train_loss_epoch=0.238]Epoch 13: Train Loss = 0.21976004540920258\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.213, train_loss_epoch=0.220]Epoch 14: Train Loss = 0.212712362408638\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.190, train_loss_epoch=0.213]Epoch 15: Train Loss = 0.19014832377433777\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.196, train_loss_epoch=0.190]Epoch 16: Train Loss = 0.19617637991905212\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.191, train_loss_epoch=0.196]Epoch 17: Train Loss = 0.19132843613624573\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.199, train_loss_epoch=0.191]Epoch 18: Train Loss = 0.19900692999362946\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.175, train_loss_epoch=0.199]Epoch 19: Train Loss = 0.17478379607200623\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.167, train_loss_epoch=0.175]Epoch 20: Train Loss = 0.16694270074367523\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.180, train_loss_epoch=0.167]Epoch 21: Train Loss = 0.17974010109901428\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.178, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.17826731503009796\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.165, train_loss_epoch=0.178]Epoch 23: Train Loss = 0.16544002294540405\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.159, train_loss_epoch=0.165]Epoch 24: Train Loss = 0.159016951918602\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.156, train_loss_epoch=0.159]Epoch 25: Train Loss = 0.1561179757118225\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.162, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.1620868444442749\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.151, train_loss_epoch=0.162]Epoch 27: Train Loss = 0.15098623931407928\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.146, train_loss_epoch=0.151]Epoch 28: Train Loss = 0.1462399661540985\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.150, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.1497119814157486\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.141, train_loss_epoch=0.150]Epoch 30: Train Loss = 0.14144892990589142\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.144, train_loss_epoch=0.141]Epoch 31: Train Loss = 0.1438649445772171\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.140, train_loss_epoch=0.144]Epoch 32: Train Loss = 0.140243262052536\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.134, train_loss_epoch=0.140]Epoch 33: Train Loss = 0.13423094153404236\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.134, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.13387754559516907\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.134, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.13381777703762054\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.130, train_loss_epoch=0.134]Epoch 36: Train Loss = 0.1296636462211609\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.130, train_loss_epoch=0.130]Epoch 37: Train Loss = 0.1297035664319992\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.122, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12249458581209183\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.118, train_loss_epoch=0.122]Epoch 39: Train Loss = 0.11817905306816101\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.116, train_loss_epoch=0.118]Epoch 40: Train Loss = 0.11616532504558563\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.119, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.118648000061512\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.115, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.11475474387407303\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.110, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.10974683612585068\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.114, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.1135558933019638\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.108, train_loss_epoch=0.114]Epoch 45: Train Loss = 0.10772999376058578\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.107, train_loss_epoch=0.108]Epoch 46: Train Loss = 0.10659226030111313\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.102, train_loss_epoch=0.107]Epoch 47: Train Loss = 0.10157710313796997\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.103, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.10333694517612457\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.103, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.10267578810453415\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0983, train_loss_epoch=0.103]Epoch 50: Train Loss = 0.09830912947654724\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0994, train_loss_epoch=0.0983]Epoch 51: Train Loss = 0.09940303862094879\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0959, train_loss_epoch=0.0994]Epoch 52: Train Loss = 0.09586385637521744\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0932, train_loss_epoch=0.0959]Epoch 53: Train Loss = 0.09315633028745651\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0918, train_loss_epoch=0.0932]Epoch 54: Train Loss = 0.0917552262544632\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0913, train_loss_epoch=0.0918]Epoch 55: Train Loss = 0.09132085740566254\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0898, train_loss_epoch=0.0913]Epoch 56: Train Loss = 0.0897907018661499\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0877, train_loss_epoch=0.0898]Epoch 57: Train Loss = 0.08767686039209366\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0866, train_loss_epoch=0.0877]Epoch 58: Train Loss = 0.08664581924676895\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0846, train_loss_epoch=0.0866]Epoch 59: Train Loss = 0.08458743244409561\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0852, train_loss_epoch=0.0846]Epoch 60: Train Loss = 0.08520710468292236\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.081, train_loss_epoch=0.0852] Epoch 61: Train Loss = 0.08101662248373032\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0858, train_loss_epoch=0.081]Epoch 62: Train Loss = 0.08579717576503754\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0801, train_loss_epoch=0.0858]Epoch 63: Train Loss = 0.08014406263828278\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0807, train_loss_epoch=0.0801]Epoch 64: Train Loss = 0.08072225004434586\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0776, train_loss_epoch=0.0807]Epoch 65: Train Loss = 0.07755998522043228\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0801, train_loss_epoch=0.0776]Epoch 66: Train Loss = 0.0800660029053688\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0795, train_loss_epoch=0.0801]Epoch 67: Train Loss = 0.07953570783138275\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0748, train_loss_epoch=0.0795]Epoch 68: Train Loss = 0.07477306574583054\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.076, train_loss_epoch=0.0748] Epoch 69: Train Loss = 0.07596534490585327\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.072, train_loss_epoch=0.076] Epoch 70: Train Loss = 0.07201672345399857\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0715, train_loss_epoch=0.072]Epoch 71: Train Loss = 0.07145316898822784\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0708, train_loss_epoch=0.0715]Epoch 72: Train Loss = 0.07080130279064178\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0701, train_loss_epoch=0.0708]Epoch 73: Train Loss = 0.07012483477592468\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0714, train_loss_epoch=0.0701]Epoch 74: Train Loss = 0.07142853736877441\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0681, train_loss_epoch=0.0714]Epoch 75: Train Loss = 0.06807883828878403\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0692, train_loss_epoch=0.0681]Epoch 76: Train Loss = 0.06919269263744354\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0661, train_loss_epoch=0.0692]Epoch 77: Train Loss = 0.06613820791244507\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.068, train_loss_epoch=0.0661] Epoch 78: Train Loss = 0.0679599866271019\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0632, train_loss_epoch=0.068]Epoch 79: Train Loss = 0.0631977990269661\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0639, train_loss_epoch=0.0632]Epoch 80: Train Loss = 0.06393236666917801\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0626, train_loss_epoch=0.0639]Epoch 81: Train Loss = 0.06261924654245377\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0628, train_loss_epoch=0.0626]Epoch 82: Train Loss = 0.06278087198734283\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0632, train_loss_epoch=0.0628]Epoch 83: Train Loss = 0.06322727352380753\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0628, train_loss_epoch=0.0632]Epoch 84: Train Loss = 0.06283392757177353\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0602, train_loss_epoch=0.0628]Epoch 85: Train Loss = 0.06023731827735901\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0597, train_loss_epoch=0.0602]Epoch 86: Train Loss = 0.05968000367283821\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0594, train_loss_epoch=0.0597]Epoch 87: Train Loss = 0.05942683666944504\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0577, train_loss_epoch=0.0594]Epoch 88: Train Loss = 0.057725775986909866\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0588, train_loss_epoch=0.0577]Epoch 89: Train Loss = 0.05881276726722717\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0578, train_loss_epoch=0.0588]Epoch 90: Train Loss = 0.05781375616788864\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0572, train_loss_epoch=0.0578]Epoch 91: Train Loss = 0.05719919502735138\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0564, train_loss_epoch=0.0572]Epoch 92: Train Loss = 0.056397441774606705\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0546, train_loss_epoch=0.0564]Epoch 93: Train Loss = 0.05459323897957802\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0554, train_loss_epoch=0.0546]Epoch 94: Train Loss = 0.05537530034780502\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.054, train_loss_epoch=0.0554] Epoch 95: Train Loss = 0.05400192737579346\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0548, train_loss_epoch=0.054]Epoch 96: Train Loss = 0.0547950379550457\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0556, train_loss_epoch=0.0548]Epoch 97: Train Loss = 0.055569104850292206\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0531, train_loss_epoch=0.0556]Epoch 98: Train Loss = 0.05313308909535408\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.053, train_loss_epoch=0.0531] Epoch 99: Train Loss = 0.052956368774175644\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0532, train_loss_epoch=0.053]Epoch 100: Train Loss = 0.053180892020463943\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0524, train_loss_epoch=0.0532]Epoch 101: Train Loss = 0.05239114537835121\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0506, train_loss_epoch=0.0524]Epoch 102: Train Loss = 0.05056174471974373\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0511, train_loss_epoch=0.0506]Epoch 103: Train Loss = 0.051094334572553635\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0489, train_loss_epoch=0.0511]Epoch 104: Train Loss = 0.0488784983754158\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0484, train_loss_epoch=0.0489]Epoch 105: Train Loss = 0.0483655221760273\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0486, train_loss_epoch=0.0484]Epoch 106: Train Loss = 0.04857165366411209\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0493, train_loss_epoch=0.0486]Epoch 107: Train Loss = 0.04931848123669624\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0492, train_loss_epoch=0.0493]Epoch 108: Train Loss = 0.04922444000840187\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.049, train_loss_epoch=0.0492] Epoch 109: Train Loss = 0.04897056147456169\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0486, train_loss_epoch=0.049]Epoch 110: Train Loss = 0.04857208579778671\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0487, train_loss_epoch=0.0486]Epoch 111: Train Loss = 0.04867302253842354\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0504, train_loss_epoch=0.0487]Epoch 112: Train Loss = 0.050358280539512634\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0484, train_loss_epoch=0.0504]Epoch 113: Train Loss = 0.04840436950325966\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0497, train_loss_epoch=0.0484]Epoch 114: Train Loss = 0.04974884167313576\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0483, train_loss_epoch=0.0497]Epoch 115: Train Loss = 0.04834906384348869\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0461, train_loss_epoch=0.0483]Epoch 116: Train Loss = 0.046083319932222366\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0466, train_loss_epoch=0.0461]Epoch 117: Train Loss = 0.046567585319280624\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0451, train_loss_epoch=0.0466]Epoch 118: Train Loss = 0.04509482532739639\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0461, train_loss_epoch=0.0451]Epoch 119: Train Loss = 0.04607446491718292\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=214, train_loss_step=0.0455, train_loss_epoch=0.0461]Epoch 120: Train Loss = 0.045475754886865616\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0451, train_loss_epoch=0.0455]Epoch 121: Train Loss = 0.04512564465403557\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0448, train_loss_epoch=0.0451]Epoch 122: Train Loss = 0.04478642717003822\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0455, train_loss_epoch=0.0448]Epoch 123: Train Loss = 0.04551069065928459\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0431, train_loss_epoch=0.0455]Epoch 124: Train Loss = 0.04312976449728012\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.043, train_loss_epoch=0.0431] Epoch 125: Train Loss = 0.04303751513361931\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0437, train_loss_epoch=0.043]Epoch 126: Train Loss = 0.043690264225006104\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0445, train_loss_epoch=0.0437]Epoch 127: Train Loss = 0.044475946575403214\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0429, train_loss_epoch=0.0445]Epoch 128: Train Loss = 0.042923204600811005\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0421, train_loss_epoch=0.0429]Epoch 129: Train Loss = 0.042058639228343964\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0427, train_loss_epoch=0.0421]Epoch 130: Train Loss = 0.04265086352825165\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0423, train_loss_epoch=0.0427]Epoch 131: Train Loss = 0.04231882467865944\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0439, train_loss_epoch=0.0423]Epoch 132: Train Loss = 0.043863844126462936\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0407, train_loss_epoch=0.0439]Epoch 133: Train Loss = 0.04070962220430374\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0438, train_loss_epoch=0.0407]Epoch 134: Train Loss = 0.0438418872654438\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0408, train_loss_epoch=0.0438]Epoch 135: Train Loss = 0.04077468812465668\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0434, train_loss_epoch=0.0408]Epoch 136: Train Loss = 0.043414823710918427\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0408, train_loss_epoch=0.0434]Epoch 137: Train Loss = 0.040805332362651825\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.045, train_loss_epoch=0.0408] Epoch 138: Train Loss = 0.04495294764637947\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0406, train_loss_epoch=0.045]Epoch 139: Train Loss = 0.04058665782213211\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0425, train_loss_epoch=0.0406]Epoch 140: Train Loss = 0.042502980679273605\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0404, train_loss_epoch=0.0425]Epoch 141: Train Loss = 0.04038551449775696\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0405, train_loss_epoch=0.0404]Epoch 142: Train Loss = 0.04045919328927994\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0397, train_loss_epoch=0.0405]Epoch 143: Train Loss = 0.03974052891135216\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0391, train_loss_epoch=0.0397]Epoch 144: Train Loss = 0.039111245423555374\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0422, train_loss_epoch=0.0391]Epoch 145: Train Loss = 0.04221545532345772\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0432, train_loss_epoch=0.0422]Epoch 146: Train Loss = 0.0431845560669899\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0399, train_loss_epoch=0.0432]Epoch 147: Train Loss = 0.03992260992527008\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0409, train_loss_epoch=0.0399]Epoch 148: Train Loss = 0.04090191051363945\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0392, train_loss_epoch=0.0409]Epoch 149: Train Loss = 0.03916027396917343\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0437, train_loss_epoch=0.0392]Epoch 150: Train Loss = 0.04367560148239136\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0381, train_loss_epoch=0.0437]Epoch 151: Train Loss = 0.03805607184767723\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0405, train_loss_epoch=0.0381]Epoch 152: Train Loss = 0.04050032049417496\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.037, train_loss_epoch=0.0405] Epoch 153: Train Loss = 0.037002816796302795\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0396, train_loss_epoch=0.037]Epoch 154: Train Loss = 0.03962979465723038\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.037, train_loss_epoch=0.0396] Epoch 155: Train Loss = 0.03701158985495567\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0377, train_loss_epoch=0.037]Epoch 156: Train Loss = 0.037691276520490646\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0374, train_loss_epoch=0.0377]Epoch 157: Train Loss = 0.03735978528857231\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.039, train_loss_epoch=0.0374] Epoch 158: Train Loss = 0.03899474814534187\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0392, train_loss_epoch=0.039]Epoch 159: Train Loss = 0.03923068195581436\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0379, train_loss_epoch=0.0392]Epoch 160: Train Loss = 0.03788166865706444\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0378, train_loss_epoch=0.0379]Epoch 161: Train Loss = 0.03776191920042038\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0384, train_loss_epoch=0.0378]Epoch 162: Train Loss = 0.03844418004155159\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0368, train_loss_epoch=0.0384]Epoch 163: Train Loss = 0.03676812723278999\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0391, train_loss_epoch=0.0368]Epoch 164: Train Loss = 0.03911926969885826\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0369, train_loss_epoch=0.0391]Epoch 165: Train Loss = 0.03690013289451599\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0374, train_loss_epoch=0.0369]Epoch 166: Train Loss = 0.037417855113744736\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0352, train_loss_epoch=0.0374]Epoch 167: Train Loss = 0.0352313369512558\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0378, train_loss_epoch=0.0352]Epoch 168: Train Loss = 0.0377843901515007\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0369, train_loss_epoch=0.0378]Epoch 169: Train Loss = 0.03685611113905907\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.036, train_loss_epoch=0.0369] Epoch 170: Train Loss = 0.03603694215416908\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0387, train_loss_epoch=0.036]Epoch 171: Train Loss = 0.03874439746141434\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0349, train_loss_epoch=0.0387]Epoch 172: Train Loss = 0.03493541479110718\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0399, train_loss_epoch=0.0349]Epoch 173: Train Loss = 0.0398985929787159\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0353, train_loss_epoch=0.0399]Epoch 174: Train Loss = 0.03530253469944\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0356, train_loss_epoch=0.0353]Epoch 175: Train Loss = 0.03564193844795227\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0355, train_loss_epoch=0.0356]Epoch 176: Train Loss = 0.03553472459316254\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0356, train_loss_epoch=0.0355]Epoch 177: Train Loss = 0.03555227443575859\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0371, train_loss_epoch=0.0356]Epoch 178: Train Loss = 0.03713900223374367\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0355, train_loss_epoch=0.0371]Epoch 179: Train Loss = 0.03551890701055527\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0366, train_loss_epoch=0.0355]Epoch 180: Train Loss = 0.03661978617310524\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0359, train_loss_epoch=0.0366]Epoch 181: Train Loss = 0.035901520401239395\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0348, train_loss_epoch=0.0359]Epoch 182: Train Loss = 0.03484482690691948\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.036, train_loss_epoch=0.0348] Epoch 183: Train Loss = 0.03600010648369789\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0343, train_loss_epoch=0.036]Epoch 184: Train Loss = 0.03427911177277565\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0341, train_loss_epoch=0.0343]Epoch 185: Train Loss = 0.03406421095132828\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0333, train_loss_epoch=0.0341]Epoch 186: Train Loss = 0.03328517824411392\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0364, train_loss_epoch=0.0333]Epoch 187: Train Loss = 0.03635189309716225\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0345, train_loss_epoch=0.0364]Epoch 188: Train Loss = 0.034489065408706665\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0335, train_loss_epoch=0.0345]Epoch 189: Train Loss = 0.03353150561451912\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0352, train_loss_epoch=0.0335]Epoch 190: Train Loss = 0.03517088294029236\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0352, train_loss_epoch=0.0352]Epoch 191: Train Loss = 0.03520830348134041\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0391, train_loss_epoch=0.0352]Epoch 192: Train Loss = 0.03912917897105217\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0364, train_loss_epoch=0.0391]Epoch 193: Train Loss = 0.03635178133845329\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0447, train_loss_epoch=0.0364]Epoch 194: Train Loss = 0.04470811411738396\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0361, train_loss_epoch=0.0447]Epoch 195: Train Loss = 0.03605668991804123\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0378, train_loss_epoch=0.0361]Epoch 196: Train Loss = 0.037768881767988205\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0441, train_loss_epoch=0.0378]Epoch 197: Train Loss = 0.04411162808537483\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0351, train_loss_epoch=0.0441]Epoch 198: Train Loss = 0.03505853936076164\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0385, train_loss_epoch=0.0351]Epoch 199: Train Loss = 0.03849361836910248\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0332, train_loss_epoch=0.0385]Epoch 200: Train Loss = 0.033245231956243515\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0408, train_loss_epoch=0.0332]Epoch 201: Train Loss = 0.04075025022029877\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0358, train_loss_epoch=0.0408]Epoch 202: Train Loss = 0.035840827971696854\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0374, train_loss_epoch=0.0358]Epoch 203: Train Loss = 0.03742906078696251\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0341, train_loss_epoch=0.0374]Epoch 204: Train Loss = 0.03409237042069435\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0328, train_loss_epoch=0.0341]Epoch 205: Train Loss = 0.03281864523887634\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0397, train_loss_epoch=0.0328]Epoch 206: Train Loss = 0.039681803435087204\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0322, train_loss_epoch=0.0397]Epoch 207: Train Loss = 0.032153308391571045\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0385, train_loss_epoch=0.0322]Epoch 208: Train Loss = 0.0384531132876873\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0403, train_loss_epoch=0.0385]Epoch 209: Train Loss = 0.04034385457634926\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0382, train_loss_epoch=0.0403]Epoch 210: Train Loss = 0.03821758180856705\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0447, train_loss_epoch=0.0382]Epoch 211: Train Loss = 0.044714607298374176\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0321, train_loss_epoch=0.0447]Epoch 212: Train Loss = 0.03210890293121338\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0431, train_loss_epoch=0.0321]Epoch 213: Train Loss = 0.04312247782945633\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0316, train_loss_epoch=0.0431]Epoch 214: Train Loss = 0.03156592324376106\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0356, train_loss_epoch=0.0316]Epoch 215: Train Loss = 0.035634562373161316\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0385, train_loss_epoch=0.0356]Epoch 216: Train Loss = 0.03852245956659317\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0313, train_loss_epoch=0.0385]Epoch 217: Train Loss = 0.0312756672501564\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0413, train_loss_epoch=0.0313]Epoch 218: Train Loss = 0.041328877210617065\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0321, train_loss_epoch=0.0413]Epoch 219: Train Loss = 0.03211638331413269\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.034, train_loss_epoch=0.0321] Epoch 220: Train Loss = 0.03395311161875725\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0338, train_loss_epoch=0.034]Epoch 221: Train Loss = 0.03379295393824577\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0319, train_loss_epoch=0.0338]Epoch 222: Train Loss = 0.0318879559636116\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0442, train_loss_epoch=0.0319]Epoch 223: Train Loss = 0.044190775603055954\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0317, train_loss_epoch=0.0442]Epoch 224: Train Loss = 0.03172362223267555\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0338, train_loss_epoch=0.0317]Epoch 225: Train Loss = 0.03375294432044029\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0339, train_loss_epoch=0.0338]Epoch 226: Train Loss = 0.03392383083701134\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0315, train_loss_epoch=0.0339]Epoch 227: Train Loss = 0.031533028930425644\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0381, train_loss_epoch=0.0315]Epoch 228: Train Loss = 0.038107626140117645\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0345, train_loss_epoch=0.0381]Epoch 229: Train Loss = 0.03447088599205017\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0357, train_loss_epoch=0.0345]Epoch 230: Train Loss = 0.03574899211525917\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0328, train_loss_epoch=0.0357]Epoch 231: Train Loss = 0.03276872634887695\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0309, train_loss_epoch=0.0328]Epoch 232: Train Loss = 0.030922474339604378\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.033, train_loss_epoch=0.0309] Epoch 233: Train Loss = 0.03298518434166908\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0306, train_loss_epoch=0.033]Epoch 234: Train Loss = 0.030594831332564354\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0308, train_loss_epoch=0.0306]Epoch 235: Train Loss = 0.030799955129623413\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0316, train_loss_epoch=0.0308]Epoch 236: Train Loss = 0.031610410660505295\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0314, train_loss_epoch=0.0316]Epoch 237: Train Loss = 0.0313950777053833\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0309, train_loss_epoch=0.0314]Epoch 238: Train Loss = 0.030880840495228767\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.032, train_loss_epoch=0.0309] Epoch 239: Train Loss = 0.03201322630047798\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0303, train_loss_epoch=0.032]Epoch 240: Train Loss = 0.03025263175368309\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0306, train_loss_epoch=0.0303]Epoch 241: Train Loss = 0.030612768605351448\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0311, train_loss_epoch=0.0306]Epoch 242: Train Loss = 0.0311119481921196\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0312, train_loss_epoch=0.0311]Epoch 243: Train Loss = 0.031214861199259758\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0302, train_loss_epoch=0.0312]Epoch 244: Train Loss = 0.030213281512260437\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.0304, train_loss_epoch=0.0302]Epoch 245: Train Loss = 0.030359843745827675\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0314, train_loss_epoch=0.0304]Epoch 246: Train Loss = 0.03139669820666313\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=214, train_loss_step=0.030, train_loss_epoch=0.0314] Epoch 247: Train Loss = 0.029981039464473724\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=214, train_loss_step=0.0316, train_loss_epoch=0.030]Epoch 248: Train Loss = 0.03159826621413231\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0305, train_loss_epoch=0.0316]Epoch 249: Train Loss = 0.03054889105260372\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0305, train_loss_epoch=0.0305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=214, train_loss_step=0.0305, train_loss_epoch=0.0305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 15: from 1998-11-02 00:00:00 to 2022-05-17 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.403]Epoch 0: Train Loss = 0.4026525020599365\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.496, train_loss_epoch=0.403]Epoch 1: Train Loss = 0.4961818754673004\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.377, train_loss_epoch=0.496]Epoch 2: Train Loss = 0.3766598701477051\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.252, train_loss_epoch=0.377]Epoch 3: Train Loss = 0.252448171377182\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.305, train_loss_epoch=0.252]Epoch 4: Train Loss = 0.30481642484664917\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.315, train_loss_epoch=0.305]Epoch 5: Train Loss = 0.3147278428077698\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.253, train_loss_epoch=0.315]Epoch 6: Train Loss = 0.2533615529537201\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.237, train_loss_epoch=0.253]Epoch 7: Train Loss = 0.237390398979187\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.269, train_loss_epoch=0.237]Epoch 8: Train Loss = 0.268780916929245\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.263, train_loss_epoch=0.269]Epoch 9: Train Loss = 0.26319563388824463\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.241, train_loss_epoch=0.263]Epoch 10: Train Loss = 0.24104316532611847\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.219, train_loss_epoch=0.241]Epoch 11: Train Loss = 0.2192249447107315\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.235, train_loss_epoch=0.219]Epoch 12: Train Loss = 0.23518748581409454\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.225, train_loss_epoch=0.235]Epoch 13: Train Loss = 0.22493910789489746\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.215, train_loss_epoch=0.225]Epoch 14: Train Loss = 0.21466754376888275\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.191, train_loss_epoch=0.215]Epoch 15: Train Loss = 0.19053815305233002\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.195, train_loss_epoch=0.191]Epoch 16: Train Loss = 0.19544851779937744\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.191, train_loss_epoch=0.195]Epoch 17: Train Loss = 0.19068501889705658\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.197, train_loss_epoch=0.191]Epoch 18: Train Loss = 0.19725336134433746\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.176, train_loss_epoch=0.197]Epoch 19: Train Loss = 0.17642369866371155\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.168, train_loss_epoch=0.176]Epoch 20: Train Loss = 0.16781191527843475\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.177, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.1774282604455948\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.177, train_loss_epoch=0.177]Epoch 22: Train Loss = 0.17709018290042877\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.165, train_loss_epoch=0.177]Epoch 23: Train Loss = 0.16526933014392853\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.158, train_loss_epoch=0.165]Epoch 24: Train Loss = 0.15769176185131073\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.156, train_loss_epoch=0.158]Epoch 25: Train Loss = 0.15645121037960052\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.163, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.1632850021123886\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.152, train_loss_epoch=0.163]Epoch 27: Train Loss = 0.1516551822423935\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.145, train_loss_epoch=0.152]Epoch 28: Train Loss = 0.14533795416355133\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.148, train_loss_epoch=0.145]Epoch 29: Train Loss = 0.14847499132156372\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.141, train_loss_epoch=0.148]Epoch 30: Train Loss = 0.14071443676948547\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.145, train_loss_epoch=0.141]Epoch 31: Train Loss = 0.14453251659870148\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.140, train_loss_epoch=0.145]Epoch 32: Train Loss = 0.14047960937023163\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.135, train_loss_epoch=0.140]Epoch 33: Train Loss = 0.13518670201301575\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.134, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13429175317287445\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.133, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.13294897973537445\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.130, train_loss_epoch=0.133]Epoch 36: Train Loss = 0.12970469892024994\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.130, train_loss_epoch=0.130]Epoch 37: Train Loss = 0.13015718758106232\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.124, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12366191297769547\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.120, train_loss_epoch=0.124]Epoch 39: Train Loss = 0.11988848447799683\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.117, train_loss_epoch=0.120]Epoch 40: Train Loss = 0.11676717549562454\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.119, train_loss_epoch=0.117]Epoch 41: Train Loss = 0.11873935163021088\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.118, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.11770030111074448\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.110, train_loss_epoch=0.118]Epoch 43: Train Loss = 0.11027715355157852\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.114, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11351008713245392\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.109, train_loss_epoch=0.114]Epoch 45: Train Loss = 0.10883784294128418\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.106, train_loss_epoch=0.109]Epoch 46: Train Loss = 0.10634271800518036\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.103, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.10263057053089142\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.103, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10257906466722488\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.102, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.10224384814500809\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.100, train_loss_epoch=0.102]Epoch 50: Train Loss = 0.10045213252305984\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0976, train_loss_epoch=0.100]Epoch 51: Train Loss = 0.0976351946592331\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0971, train_loss_epoch=0.0976]Epoch 52: Train Loss = 0.09706896543502808\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0949, train_loss_epoch=0.0971]Epoch 53: Train Loss = 0.09485769271850586\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0932, train_loss_epoch=0.0949]Epoch 54: Train Loss = 0.09316180646419525\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0931, train_loss_epoch=0.0932]Epoch 55: Train Loss = 0.09305580705404282\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.092, train_loss_epoch=0.0931] Epoch 56: Train Loss = 0.09198346734046936\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0884, train_loss_epoch=0.092]Epoch 57: Train Loss = 0.08838088810443878\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0878, train_loss_epoch=0.0884]Epoch 58: Train Loss = 0.08777377754449844\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0852, train_loss_epoch=0.0878]Epoch 59: Train Loss = 0.08521128445863724\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0845, train_loss_epoch=0.0852]Epoch 60: Train Loss = 0.08445831388235092\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0813, train_loss_epoch=0.0845]Epoch 61: Train Loss = 0.08129974454641342\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.085, train_loss_epoch=0.0813] Epoch 62: Train Loss = 0.08499187976121902\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0791, train_loss_epoch=0.085]Epoch 63: Train Loss = 0.07912485301494598\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0794, train_loss_epoch=0.0791]Epoch 64: Train Loss = 0.07938716560602188\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=216, train_loss_step=0.0798, train_loss_epoch=0.0794]Epoch 65: Train Loss = 0.0797717422246933\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=216, train_loss_step=0.0793, train_loss_epoch=0.0798]Epoch 66: Train Loss = 0.07932265102863312\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0802, train_loss_epoch=0.0793]Epoch 67: Train Loss = 0.08021090179681778\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=216, train_loss_step=0.0758, train_loss_epoch=0.0802]Epoch 68: Train Loss = 0.0758102610707283\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0769, train_loss_epoch=0.0758]Epoch 69: Train Loss = 0.07690013200044632\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=216, train_loss_step=0.0719, train_loss_epoch=0.0769]Epoch 70: Train Loss = 0.07188405841588974\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0732, train_loss_epoch=0.0719]Epoch 71: Train Loss = 0.07321560382843018\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=216, train_loss_step=0.0698, train_loss_epoch=0.0732]Epoch 72: Train Loss = 0.06983254849910736\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.070, train_loss_epoch=0.0698] Epoch 73: Train Loss = 0.06998326629400253\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=216, train_loss_step=0.0705, train_loss_epoch=0.070]Epoch 74: Train Loss = 0.0704689621925354\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0676, train_loss_epoch=0.0705]Epoch 75: Train Loss = 0.06760713458061218\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0682, train_loss_epoch=0.0676]Epoch 76: Train Loss = 0.06815074384212494\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=216, train_loss_step=0.0669, train_loss_epoch=0.0682]Epoch 77: Train Loss = 0.06689208745956421\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0711, train_loss_epoch=0.0669]Epoch 78: Train Loss = 0.07112547755241394\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0636, train_loss_epoch=0.0711]Epoch 79: Train Loss = 0.06357832252979279\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=216, train_loss_step=0.0655, train_loss_epoch=0.0636]Epoch 80: Train Loss = 0.0654771700501442\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0618, train_loss_epoch=0.0655]Epoch 81: Train Loss = 0.06180413439869881\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0639, train_loss_epoch=0.0618]Epoch 82: Train Loss = 0.06392983347177505\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=216, train_loss_step=0.0622, train_loss_epoch=0.0639]Epoch 83: Train Loss = 0.06220484524965286\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=216, train_loss_step=0.0637, train_loss_epoch=0.0622]Epoch 84: Train Loss = 0.06366996467113495\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0605, train_loss_epoch=0.0637]Epoch 85: Train Loss = 0.060469381511211395\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0624, train_loss_epoch=0.0605]Epoch 86: Train Loss = 0.062360167503356934\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0615, train_loss_epoch=0.0624]Epoch 87: Train Loss = 0.06146236136555672\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0601, train_loss_epoch=0.0615]Epoch 88: Train Loss = 0.060128357261419296\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0604, train_loss_epoch=0.0601]Epoch 89: Train Loss = 0.06035736948251724\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0581, train_loss_epoch=0.0604]Epoch 90: Train Loss = 0.058093391358852386\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0579, train_loss_epoch=0.0581]Epoch 91: Train Loss = 0.057866234332323074\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0572, train_loss_epoch=0.0579]Epoch 92: Train Loss = 0.05717736855149269\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0583, train_loss_epoch=0.0572]Epoch 93: Train Loss = 0.05834733694791794\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0563, train_loss_epoch=0.0583]Epoch 94: Train Loss = 0.056342337280511856\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0562, train_loss_epoch=0.0563]Epoch 95: Train Loss = 0.056230928748846054\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0551, train_loss_epoch=0.0562]Epoch 96: Train Loss = 0.05512714758515358\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0544, train_loss_epoch=0.0551]Epoch 97: Train Loss = 0.05440811440348625\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0574, train_loss_epoch=0.0544]Epoch 98: Train Loss = 0.05742737650871277\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0532, train_loss_epoch=0.0574]Epoch 99: Train Loss = 0.0531763918697834\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0586, train_loss_epoch=0.0532]Epoch 100: Train Loss = 0.05862988904118538\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0534, train_loss_epoch=0.0586]Epoch 101: Train Loss = 0.05339178815484047\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0587, train_loss_epoch=0.0534]Epoch 102: Train Loss = 0.05871710553765297\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0512, train_loss_epoch=0.0587]Epoch 103: Train Loss = 0.05117226392030716\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0521, train_loss_epoch=0.0512]Epoch 104: Train Loss = 0.052072662860155106\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0537, train_loss_epoch=0.0521]Epoch 105: Train Loss = 0.053656309843063354\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0502, train_loss_epoch=0.0537]Epoch 106: Train Loss = 0.05019688233733177\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0529, train_loss_epoch=0.0502]Epoch 107: Train Loss = 0.05285384878516197\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0505, train_loss_epoch=0.0529]Epoch 108: Train Loss = 0.05054854974150658\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0559, train_loss_epoch=0.0505]Epoch 109: Train Loss = 0.055933497846126556\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0498, train_loss_epoch=0.0559]Epoch 110: Train Loss = 0.04980958625674248\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0516, train_loss_epoch=0.0498]Epoch 111: Train Loss = 0.051563799381256104\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.056, train_loss_epoch=0.0516] Epoch 112: Train Loss = 0.055979371070861816\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.050, train_loss_epoch=0.056] Epoch 113: Train Loss = 0.050027016550302505\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.054, train_loss_epoch=0.050]Epoch 114: Train Loss = 0.054032716900110245\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0466, train_loss_epoch=0.054]Epoch 115: Train Loss = 0.04661107063293457\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0546, train_loss_epoch=0.0466]Epoch 116: Train Loss = 0.05458880588412285\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0488, train_loss_epoch=0.0546]Epoch 117: Train Loss = 0.04878290370106697\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0527, train_loss_epoch=0.0488]Epoch 118: Train Loss = 0.05265045911073685\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0529, train_loss_epoch=0.0527]Epoch 119: Train Loss = 0.05289365351200104\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0487, train_loss_epoch=0.0529]Epoch 120: Train Loss = 0.04871825873851776\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.051, train_loss_epoch=0.0487] Epoch 121: Train Loss = 0.05102761462330818\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0456, train_loss_epoch=0.051]Epoch 122: Train Loss = 0.04557862877845764\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0502, train_loss_epoch=0.0456]Epoch 123: Train Loss = 0.05016544088721275\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0481, train_loss_epoch=0.0502]Epoch 124: Train Loss = 0.04810159280896187\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0471, train_loss_epoch=0.0481]Epoch 125: Train Loss = 0.04707248508930206\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0453, train_loss_epoch=0.0471]Epoch 126: Train Loss = 0.04531298205256462\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0448, train_loss_epoch=0.0453]Epoch 127: Train Loss = 0.044815316796302795\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0434, train_loss_epoch=0.0448]Epoch 128: Train Loss = 0.04339702054858208\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0432, train_loss_epoch=0.0434]Epoch 129: Train Loss = 0.04317057877779007\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0422, train_loss_epoch=0.0432]Epoch 130: Train Loss = 0.042205970734357834\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0432, train_loss_epoch=0.0422]Epoch 131: Train Loss = 0.04322865232825279\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0426, train_loss_epoch=0.0432]Epoch 132: Train Loss = 0.04258256033062935\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0429, train_loss_epoch=0.0426]Epoch 133: Train Loss = 0.04289790987968445\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0427, train_loss_epoch=0.0429]Epoch 134: Train Loss = 0.04272901266813278\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0427, train_loss_epoch=0.0427]Epoch 135: Train Loss = 0.0426558293402195\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0441, train_loss_epoch=0.0427]Epoch 136: Train Loss = 0.044139690697193146\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.043, train_loss_epoch=0.0441] Epoch 137: Train Loss = 0.04296001046895981\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0412, train_loss_epoch=0.043]Epoch 138: Train Loss = 0.04116928577423096\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0421, train_loss_epoch=0.0412]Epoch 139: Train Loss = 0.04208935797214508\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.042, train_loss_epoch=0.0421] Epoch 140: Train Loss = 0.04198777675628662\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0418, train_loss_epoch=0.042]Epoch 141: Train Loss = 0.041788458824157715\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.041, train_loss_epoch=0.0418] Epoch 142: Train Loss = 0.04096822813153267\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0435, train_loss_epoch=0.041]Epoch 143: Train Loss = 0.043540775775909424\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0397, train_loss_epoch=0.0435]Epoch 144: Train Loss = 0.039735011756420135\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0462, train_loss_epoch=0.0397]Epoch 145: Train Loss = 0.04615802317857742\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0422, train_loss_epoch=0.0462]Epoch 146: Train Loss = 0.04220743477344513\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0431, train_loss_epoch=0.0422]Epoch 147: Train Loss = 0.04311423376202583\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0397, train_loss_epoch=0.0431]Epoch 148: Train Loss = 0.03969787061214447\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.045, train_loss_epoch=0.0397] Epoch 149: Train Loss = 0.04496562480926514\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.040, train_loss_epoch=0.045] Epoch 150: Train Loss = 0.04001249372959137\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0409, train_loss_epoch=0.040]Epoch 151: Train Loss = 0.04092191532254219\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0396, train_loss_epoch=0.0409]Epoch 152: Train Loss = 0.03964425250887871\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0402, train_loss_epoch=0.0396]Epoch 153: Train Loss = 0.04018792882561684\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0401, train_loss_epoch=0.0402]Epoch 154: Train Loss = 0.04014626517891884\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0385, train_loss_epoch=0.0401]Epoch 155: Train Loss = 0.038519930094480515\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0407, train_loss_epoch=0.0385]Epoch 156: Train Loss = 0.04065864905714989\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.040, train_loss_epoch=0.0407] Epoch 157: Train Loss = 0.03999738022685051\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0406, train_loss_epoch=0.040]Epoch 158: Train Loss = 0.0406443290412426\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0405, train_loss_epoch=0.0406]Epoch 159: Train Loss = 0.04046406224370003\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0393, train_loss_epoch=0.0405]Epoch 160: Train Loss = 0.03929222747683525\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0406, train_loss_epoch=0.0393]Epoch 161: Train Loss = 0.040644075721502304\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0373, train_loss_epoch=0.0406]Epoch 162: Train Loss = 0.037292927503585815\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0439, train_loss_epoch=0.0373]Epoch 163: Train Loss = 0.043886613100767136\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0373, train_loss_epoch=0.0439]Epoch 164: Train Loss = 0.037335872650146484\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0397, train_loss_epoch=0.0373]Epoch 165: Train Loss = 0.03968837112188339\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0374, train_loss_epoch=0.0397]Epoch 166: Train Loss = 0.03738013654947281\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0377, train_loss_epoch=0.0374]Epoch 167: Train Loss = 0.037686385214328766\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.037, train_loss_epoch=0.0377] Epoch 168: Train Loss = 0.036953896284103394\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0382, train_loss_epoch=0.037]Epoch 169: Train Loss = 0.03823167458176613\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0363, train_loss_epoch=0.0382]Epoch 170: Train Loss = 0.036324091255664825\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0372, train_loss_epoch=0.0363]Epoch 171: Train Loss = 0.037155721336603165\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0379, train_loss_epoch=0.0372]Epoch 172: Train Loss = 0.03787251561880112\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.037, train_loss_epoch=0.0379] Epoch 173: Train Loss = 0.036958251148462296\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0361, train_loss_epoch=0.037]Epoch 174: Train Loss = 0.03607882186770439\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0397, train_loss_epoch=0.0361]Epoch 175: Train Loss = 0.03970577195286751\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0363, train_loss_epoch=0.0397]Epoch 176: Train Loss = 0.036287885159254074\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0389, train_loss_epoch=0.0363]Epoch 177: Train Loss = 0.03893526270985603\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0353, train_loss_epoch=0.0389]Epoch 178: Train Loss = 0.03534137085080147\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0402, train_loss_epoch=0.0353]Epoch 179: Train Loss = 0.040162257850170135\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0382, train_loss_epoch=0.0402]Epoch 180: Train Loss = 0.03818335384130478\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0398, train_loss_epoch=0.0382]Epoch 181: Train Loss = 0.03980470821261406\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0394, train_loss_epoch=0.0398]Epoch 182: Train Loss = 0.03939124941825867\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0356, train_loss_epoch=0.0394]Epoch 183: Train Loss = 0.03564072027802467\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0453, train_loss_epoch=0.0356]Epoch 184: Train Loss = 0.04530387371778488\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0362, train_loss_epoch=0.0453]Epoch 185: Train Loss = 0.03617498651146889\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0442, train_loss_epoch=0.0362]Epoch 186: Train Loss = 0.04420820623636246\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0357, train_loss_epoch=0.0442]Epoch 187: Train Loss = 0.03568083792924881\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.035, train_loss_epoch=0.0357] Epoch 188: Train Loss = 0.03499690070748329\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0362, train_loss_epoch=0.035]Epoch 189: Train Loss = 0.03616206347942352\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0349, train_loss_epoch=0.0362]Epoch 190: Train Loss = 0.03486225754022598\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0355, train_loss_epoch=0.0349]Epoch 191: Train Loss = 0.035466451197862625\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.035, train_loss_epoch=0.0355] Epoch 192: Train Loss = 0.03500085324048996\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.035, train_loss_epoch=0.035] Epoch 193: Train Loss = 0.03498464077711105\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0393, train_loss_epoch=0.035]Epoch 194: Train Loss = 0.03931982070207596\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0356, train_loss_epoch=0.0393]Epoch 195: Train Loss = 0.0355616956949234\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0372, train_loss_epoch=0.0356]Epoch 196: Train Loss = 0.03717849776148796\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0376, train_loss_epoch=0.0372]Epoch 197: Train Loss = 0.037617798894643784\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0346, train_loss_epoch=0.0376]Epoch 198: Train Loss = 0.03458843752741814\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0366, train_loss_epoch=0.0346]Epoch 199: Train Loss = 0.036585114896297455\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0365, train_loss_epoch=0.0366]Epoch 200: Train Loss = 0.03645532578229904\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0372, train_loss_epoch=0.0365]Epoch 201: Train Loss = 0.037161555141210556\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0356, train_loss_epoch=0.0372]Epoch 202: Train Loss = 0.03563297539949417\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0335, train_loss_epoch=0.0356]Epoch 203: Train Loss = 0.03351419046521187\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0397, train_loss_epoch=0.0335]Epoch 204: Train Loss = 0.03966393321752548\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0355, train_loss_epoch=0.0397]Epoch 205: Train Loss = 0.03547169640660286\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0352, train_loss_epoch=0.0355]Epoch 206: Train Loss = 0.03515467420220375\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0398, train_loss_epoch=0.0352]Epoch 207: Train Loss = 0.03977089375257492\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0327, train_loss_epoch=0.0398]Epoch 208: Train Loss = 0.03269896283745766\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0419, train_loss_epoch=0.0327]Epoch 209: Train Loss = 0.04194943979382515\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0408, train_loss_epoch=0.0419]Epoch 210: Train Loss = 0.04075749218463898\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0395, train_loss_epoch=0.0408]Epoch 211: Train Loss = 0.03953414037823677\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0413, train_loss_epoch=0.0395]Epoch 212: Train Loss = 0.041348811239004135\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0329, train_loss_epoch=0.0413]Epoch 213: Train Loss = 0.032912880182266235\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0352, train_loss_epoch=0.0329]Epoch 214: Train Loss = 0.035194750875234604\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0373, train_loss_epoch=0.0352]Epoch 215: Train Loss = 0.03728261962532997\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0338, train_loss_epoch=0.0373]Epoch 216: Train Loss = 0.033765289932489395\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0373, train_loss_epoch=0.0338]Epoch 217: Train Loss = 0.03731575235724449\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0331, train_loss_epoch=0.0373]Epoch 218: Train Loss = 0.033144500106573105\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.034, train_loss_epoch=0.0331] Epoch 219: Train Loss = 0.03403341397643089\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0323, train_loss_epoch=0.034]Epoch 220: Train Loss = 0.0323091596364975\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0332, train_loss_epoch=0.0323]Epoch 221: Train Loss = 0.03319280222058296\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0331, train_loss_epoch=0.0332]Epoch 222: Train Loss = 0.03311055898666382\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0328, train_loss_epoch=0.0331]Epoch 223: Train Loss = 0.03276265785098076\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0337, train_loss_epoch=0.0328]Epoch 224: Train Loss = 0.03370704874396324\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0321, train_loss_epoch=0.0337]Epoch 225: Train Loss = 0.0320579819381237\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0328, train_loss_epoch=0.0321]Epoch 226: Train Loss = 0.03284774348139763\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0339, train_loss_epoch=0.0328]Epoch 227: Train Loss = 0.03390408307313919\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0325, train_loss_epoch=0.0339]Epoch 228: Train Loss = 0.03248952329158783\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0322, train_loss_epoch=0.0325]Epoch 229: Train Loss = 0.03220532462000847\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0326, train_loss_epoch=0.0322]Epoch 230: Train Loss = 0.032607533037662506\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0321, train_loss_epoch=0.0326]Epoch 231: Train Loss = 0.03210798278450966\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0346, train_loss_epoch=0.0321]Epoch 232: Train Loss = 0.03460681065917015\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.032, train_loss_epoch=0.0346] Epoch 233: Train Loss = 0.0319809727370739\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0364, train_loss_epoch=0.032]Epoch 234: Train Loss = 0.03643697872757912\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0314, train_loss_epoch=0.0364]Epoch 235: Train Loss = 0.0314030647277832\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0331, train_loss_epoch=0.0314]Epoch 236: Train Loss = 0.03306886553764343\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0323, train_loss_epoch=0.0331]Epoch 237: Train Loss = 0.03230079635977745\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0314, train_loss_epoch=0.0323]Epoch 238: Train Loss = 0.03143930807709694\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.032, train_loss_epoch=0.0314] Epoch 239: Train Loss = 0.03202139958739281\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0323, train_loss_epoch=0.032]Epoch 240: Train Loss = 0.032330676913261414\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=216, train_loss_step=0.0317, train_loss_epoch=0.0323]Epoch 241: Train Loss = 0.031728263944387436\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0333, train_loss_epoch=0.0317]Epoch 242: Train Loss = 0.033255476504564285\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.031, train_loss_epoch=0.0333] Epoch 243: Train Loss = 0.031038900837302208\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0322, train_loss_epoch=0.031]Epoch 244: Train Loss = 0.03218473866581917\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0351, train_loss_epoch=0.0322]Epoch 245: Train Loss = 0.03510867431759834\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.032, train_loss_epoch=0.0351] Epoch 246: Train Loss = 0.03195708990097046\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.0405, train_loss_epoch=0.032]Epoch 247: Train Loss = 0.04051411524415016\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=216, train_loss_step=0.0299, train_loss_epoch=0.0405]Epoch 248: Train Loss = 0.029852908104658127\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.036, train_loss_epoch=0.0299] Epoch 249: Train Loss = 0.03604576736688614\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.036, train_loss_epoch=0.036] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=216, train_loss_step=0.036, train_loss_epoch=0.036]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 16: from 1998-11-02 00:00:00 to 2022-05-26 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.397]Epoch 0: Train Loss = 0.3967117369174957\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.497, train_loss_epoch=0.397]Epoch 1: Train Loss = 0.4974454939365387\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.371, train_loss_epoch=0.497]Epoch 2: Train Loss = 0.37061792612075806\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.250, train_loss_epoch=0.371]Epoch 3: Train Loss = 0.24986368417739868\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.311, train_loss_epoch=0.250]Epoch 4: Train Loss = 0.3110913932323456\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.310, train_loss_epoch=0.311]Epoch 5: Train Loss = 0.3103250563144684\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.258, train_loss_epoch=0.310]Epoch 6: Train Loss = 0.25801533460617065\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.243, train_loss_epoch=0.258]Epoch 7: Train Loss = 0.24346038699150085\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.271, train_loss_epoch=0.243]Epoch 8: Train Loss = 0.2708909213542938\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.263, train_loss_epoch=0.271]Epoch 9: Train Loss = 0.26294535398483276\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.245, train_loss_epoch=0.263]Epoch 10: Train Loss = 0.24540190398693085\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.220, train_loss_epoch=0.245]Epoch 11: Train Loss = 0.21974216401576996\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.238, train_loss_epoch=0.220]Epoch 12: Train Loss = 0.23780353367328644\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.223, train_loss_epoch=0.238]Epoch 13: Train Loss = 0.22263368964195251\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.211, train_loss_epoch=0.223]Epoch 14: Train Loss = 0.21095158159732819\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.191, train_loss_epoch=0.211]Epoch 15: Train Loss = 0.19077123701572418\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.200, train_loss_epoch=0.191]Epoch 16: Train Loss = 0.1998547464609146\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.192, train_loss_epoch=0.200]Epoch 17: Train Loss = 0.19235025346279144\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.199, train_loss_epoch=0.192]Epoch 18: Train Loss = 0.19861182570457458\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.176, train_loss_epoch=0.199]Epoch 19: Train Loss = 0.1757296472787857\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.168, train_loss_epoch=0.176]Epoch 20: Train Loss = 0.1680569350719452\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.181, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.18061266839504242\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.178, train_loss_epoch=0.181]Epoch 22: Train Loss = 0.17780032753944397\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.163, train_loss_epoch=0.178]Epoch 23: Train Loss = 0.16297529637813568\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.161, train_loss_epoch=0.163]Epoch 24: Train Loss = 0.16059716045856476\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.159, train_loss_epoch=0.161]Epoch 25: Train Loss = 0.15943394601345062\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.161, train_loss_epoch=0.159]Epoch 26: Train Loss = 0.16116705536842346\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.153, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.15283051133155823\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.146, train_loss_epoch=0.153]Epoch 28: Train Loss = 0.1458561271429062\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.150, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.1496117264032364\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.140, train_loss_epoch=0.150]Epoch 30: Train Loss = 0.1398376077413559\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.146, train_loss_epoch=0.140]Epoch 31: Train Loss = 0.1459842324256897\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.140, train_loss_epoch=0.146]Epoch 32: Train Loss = 0.14033295214176178\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.135, train_loss_epoch=0.140]Epoch 33: Train Loss = 0.13471350073814392\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.134, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.1341942995786667\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.133, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.13320593535900116\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.128, train_loss_epoch=0.133]Epoch 36: Train Loss = 0.12756510078907013\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.128, train_loss_epoch=0.128]Epoch 37: Train Loss = 0.1275831013917923\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.125, train_loss_epoch=0.128]Epoch 38: Train Loss = 0.12473504990339279\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.117, train_loss_epoch=0.125]Epoch 39: Train Loss = 0.1174631267786026\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.117, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11676784604787827\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.119, train_loss_epoch=0.117]Epoch 41: Train Loss = 0.11884444952011108\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.115, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.1152692660689354\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.109, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.10947270691394806\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.113, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11312814801931381\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.107, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10686834156513214\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.108, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10811171680688858\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.104, train_loss_epoch=0.108]Epoch 47: Train Loss = 0.10393286496400833\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.102, train_loss_epoch=0.104]Epoch 48: Train Loss = 0.1016773208975792\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.104, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.10389441251754761\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0984, train_loss_epoch=0.104]Epoch 50: Train Loss = 0.09840026497840881\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0976, train_loss_epoch=0.0984]Epoch 51: Train Loss = 0.09755627065896988\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0985, train_loss_epoch=0.0976]Epoch 52: Train Loss = 0.09845743328332901\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0948, train_loss_epoch=0.0985]Epoch 53: Train Loss = 0.09478931128978729\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0938, train_loss_epoch=0.0948]Epoch 54: Train Loss = 0.0938194990158081\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0918, train_loss_epoch=0.0938]Epoch 55: Train Loss = 0.09178932011127472\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0898, train_loss_epoch=0.0918]Epoch 56: Train Loss = 0.0897713229060173\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0878, train_loss_epoch=0.0898]Epoch 57: Train Loss = 0.08775626868009567\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0882, train_loss_epoch=0.0878]Epoch 58: Train Loss = 0.08822713047266006\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0867, train_loss_epoch=0.0882]Epoch 59: Train Loss = 0.08667262643575668\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0843, train_loss_epoch=0.0867]Epoch 60: Train Loss = 0.08429788798093796\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.080, train_loss_epoch=0.0843] Epoch 61: Train Loss = 0.08004450052976608\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0814, train_loss_epoch=0.080]Epoch 62: Train Loss = 0.0814429447054863\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0808, train_loss_epoch=0.0814]Epoch 63: Train Loss = 0.08078537881374359\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0785, train_loss_epoch=0.0808]Epoch 64: Train Loss = 0.07848747819662094\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0773, train_loss_epoch=0.0785]Epoch 65: Train Loss = 0.07732883840799332\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0766, train_loss_epoch=0.0773]Epoch 66: Train Loss = 0.07658564299345016\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0765, train_loss_epoch=0.0766]Epoch 67: Train Loss = 0.07647484540939331\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0742, train_loss_epoch=0.0765]Epoch 68: Train Loss = 0.07422541081905365\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0722, train_loss_epoch=0.0742]Epoch 69: Train Loss = 0.07215778529644012\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.072, train_loss_epoch=0.0722] Epoch 70: Train Loss = 0.071965791285038\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0706, train_loss_epoch=0.072]Epoch 71: Train Loss = 0.07062606513500214\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0697, train_loss_epoch=0.0706]Epoch 72: Train Loss = 0.06970451772212982\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0702, train_loss_epoch=0.0697]Epoch 73: Train Loss = 0.07016588002443314\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0693, train_loss_epoch=0.0702]Epoch 74: Train Loss = 0.06929484009742737\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0681, train_loss_epoch=0.0693]Epoch 75: Train Loss = 0.06807757914066315\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0661, train_loss_epoch=0.0681]Epoch 76: Train Loss = 0.06611279398202896\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0658, train_loss_epoch=0.0661]Epoch 77: Train Loss = 0.06583084911108017\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0673, train_loss_epoch=0.0658]Epoch 78: Train Loss = 0.06726216524839401\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0622, train_loss_epoch=0.0673]Epoch 79: Train Loss = 0.06223557889461517\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0629, train_loss_epoch=0.0622]Epoch 80: Train Loss = 0.06285310536623001\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0625, train_loss_epoch=0.0629]Epoch 81: Train Loss = 0.06252703070640564\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0621, train_loss_epoch=0.0625]Epoch 82: Train Loss = 0.062071237713098526\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0606, train_loss_epoch=0.0621]Epoch 83: Train Loss = 0.06058555468916893\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0601, train_loss_epoch=0.0606]Epoch 84: Train Loss = 0.06010482832789421\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0595, train_loss_epoch=0.0601]Epoch 85: Train Loss = 0.05947703868150711\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0594, train_loss_epoch=0.0595]Epoch 86: Train Loss = 0.059435393661260605\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0588, train_loss_epoch=0.0594]Epoch 87: Train Loss = 0.05877523496747017\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0573, train_loss_epoch=0.0588]Epoch 88: Train Loss = 0.057324524968862534\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.056, train_loss_epoch=0.0573] Epoch 89: Train Loss = 0.05599640682339668\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0565, train_loss_epoch=0.056]Epoch 90: Train Loss = 0.056471824645996094\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0555, train_loss_epoch=0.0565]Epoch 91: Train Loss = 0.05554142966866493\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0547, train_loss_epoch=0.0555]Epoch 92: Train Loss = 0.05472243204712868\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0523, train_loss_epoch=0.0547]Epoch 93: Train Loss = 0.05227279290556908\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0539, train_loss_epoch=0.0523]Epoch 94: Train Loss = 0.05385848507285118\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0526, train_loss_epoch=0.0539]Epoch 95: Train Loss = 0.05263520032167435\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0536, train_loss_epoch=0.0526]Epoch 96: Train Loss = 0.05356038734316826\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0524, train_loss_epoch=0.0536]Epoch 97: Train Loss = 0.05239672586321831\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0525, train_loss_epoch=0.0524]Epoch 98: Train Loss = 0.05251941829919815\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0503, train_loss_epoch=0.0525]Epoch 99: Train Loss = 0.05030765384435654\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0514, train_loss_epoch=0.0503]Epoch 100: Train Loss = 0.05136232078075409\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0499, train_loss_epoch=0.0514]Epoch 101: Train Loss = 0.04987954720854759\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0498, train_loss_epoch=0.0499]Epoch 102: Train Loss = 0.04981445521116257\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.049, train_loss_epoch=0.0498] Epoch 103: Train Loss = 0.04900592193007469\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0483, train_loss_epoch=0.049]Epoch 104: Train Loss = 0.04830009117722511\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0495, train_loss_epoch=0.0483]Epoch 105: Train Loss = 0.049467381089925766\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.048, train_loss_epoch=0.0495] Epoch 106: Train Loss = 0.04797837510704994\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0484, train_loss_epoch=0.048]Epoch 107: Train Loss = 0.04836585745215416\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0478, train_loss_epoch=0.0484]Epoch 108: Train Loss = 0.04781831055879593\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0482, train_loss_epoch=0.0478]Epoch 109: Train Loss = 0.04820292070508003\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0477, train_loss_epoch=0.0482]Epoch 110: Train Loss = 0.04774436727166176\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.046, train_loss_epoch=0.0477] Epoch 111: Train Loss = 0.04598086327314377\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0456, train_loss_epoch=0.046]Epoch 112: Train Loss = 0.04562574252486229\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0463, train_loss_epoch=0.0456]Epoch 113: Train Loss = 0.04625927284359932\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0467, train_loss_epoch=0.0463]Epoch 114: Train Loss = 0.046698831021785736\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0448, train_loss_epoch=0.0467]Epoch 115: Train Loss = 0.044766902923583984\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0451, train_loss_epoch=0.0448]Epoch 116: Train Loss = 0.04507503658533096\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0439, train_loss_epoch=0.0451]Epoch 117: Train Loss = 0.04394655302166939\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0431, train_loss_epoch=0.0439]Epoch 118: Train Loss = 0.04313668608665466\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0451, train_loss_epoch=0.0431]Epoch 119: Train Loss = 0.04514557123184204\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0423, train_loss_epoch=0.0451]Epoch 120: Train Loss = 0.04227033257484436\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0437, train_loss_epoch=0.0423]Epoch 121: Train Loss = 0.04367677494883537\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0442, train_loss_epoch=0.0437]Epoch 122: Train Loss = 0.04418537765741348\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0474, train_loss_epoch=0.0442]Epoch 123: Train Loss = 0.04742201045155525\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0425, train_loss_epoch=0.0474]Epoch 124: Train Loss = 0.04253483563661575\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0464, train_loss_epoch=0.0425]Epoch 125: Train Loss = 0.04636044427752495\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0427, train_loss_epoch=0.0464]Epoch 126: Train Loss = 0.042718056589365005\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0519, train_loss_epoch=0.0427]Epoch 127: Train Loss = 0.05186723545193672\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0421, train_loss_epoch=0.0519]Epoch 128: Train Loss = 0.04209885373711586\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0472, train_loss_epoch=0.0421]Epoch 129: Train Loss = 0.04720234125852585\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0469, train_loss_epoch=0.0472]Epoch 130: Train Loss = 0.0469103641808033\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0489, train_loss_epoch=0.0469]Epoch 131: Train Loss = 0.04893163591623306\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.048, train_loss_epoch=0.0489] Epoch 132: Train Loss = 0.047953665256500244\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0454, train_loss_epoch=0.048]Epoch 133: Train Loss = 0.04543212056159973\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0414, train_loss_epoch=0.0454]Epoch 134: Train Loss = 0.04138842970132828\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0398, train_loss_epoch=0.0414]Epoch 135: Train Loss = 0.039835624396800995\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0433, train_loss_epoch=0.0398]Epoch 136: Train Loss = 0.04328212887048721\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0394, train_loss_epoch=0.0433]Epoch 137: Train Loss = 0.03940737992525101\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0427, train_loss_epoch=0.0394]Epoch 138: Train Loss = 0.042719654738903046\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.040, train_loss_epoch=0.0427] Epoch 139: Train Loss = 0.03995637968182564\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0404, train_loss_epoch=0.040]Epoch 140: Train Loss = 0.04043551906943321\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0396, train_loss_epoch=0.0404]Epoch 141: Train Loss = 0.03963892534375191\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0394, train_loss_epoch=0.0396]Epoch 142: Train Loss = 0.039429862052202225\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0405, train_loss_epoch=0.0394]Epoch 143: Train Loss = 0.04047195985913277\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.039, train_loss_epoch=0.0405] Epoch 144: Train Loss = 0.03895387798547745\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0383, train_loss_epoch=0.039]Epoch 145: Train Loss = 0.038296930491924286\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0389, train_loss_epoch=0.0383]Epoch 146: Train Loss = 0.0389176644384861\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0373, train_loss_epoch=0.0389]Epoch 147: Train Loss = 0.037316352128982544\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0412, train_loss_epoch=0.0373]Epoch 148: Train Loss = 0.041174959391355515\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0379, train_loss_epoch=0.0412]Epoch 149: Train Loss = 0.03790990635752678\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0388, train_loss_epoch=0.0379]Epoch 150: Train Loss = 0.038839008659124374\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0372, train_loss_epoch=0.0388]Epoch 151: Train Loss = 0.037199437618255615\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0377, train_loss_epoch=0.0372]Epoch 152: Train Loss = 0.03773394599556923\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0375, train_loss_epoch=0.0377]Epoch 153: Train Loss = 0.03748353570699692\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0372, train_loss_epoch=0.0375]Epoch 154: Train Loss = 0.03718462213873863\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0368, train_loss_epoch=0.0372]Epoch 155: Train Loss = 0.03683796897530556\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0372, train_loss_epoch=0.0368]Epoch 156: Train Loss = 0.03716867417097092\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0378, train_loss_epoch=0.0372]Epoch 157: Train Loss = 0.03781498596072197\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0365, train_loss_epoch=0.0378]Epoch 158: Train Loss = 0.03653044253587723\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.037, train_loss_epoch=0.0365] Epoch 159: Train Loss = 0.0369703508913517\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0383, train_loss_epoch=0.037]Epoch 160: Train Loss = 0.03832247480750084\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.039, train_loss_epoch=0.0383] Epoch 161: Train Loss = 0.039014190435409546\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0361, train_loss_epoch=0.039]Epoch 162: Train Loss = 0.03613504767417908\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0363, train_loss_epoch=0.0361]Epoch 163: Train Loss = 0.03627530485391617\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0375, train_loss_epoch=0.0363]Epoch 164: Train Loss = 0.03751043975353241\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0395, train_loss_epoch=0.0375]Epoch 165: Train Loss = 0.03952683508396149\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0344, train_loss_epoch=0.0395]Epoch 166: Train Loss = 0.03437607362866402\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.037, train_loss_epoch=0.0344] Epoch 167: Train Loss = 0.03700277954339981\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0372, train_loss_epoch=0.037]Epoch 168: Train Loss = 0.03722724691033363\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0399, train_loss_epoch=0.0372]Epoch 169: Train Loss = 0.039896462112665176\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0417, train_loss_epoch=0.0399]Epoch 170: Train Loss = 0.041719816625118256\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0475, train_loss_epoch=0.0417]Epoch 171: Train Loss = 0.04749707877635956\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0416, train_loss_epoch=0.0475]Epoch 172: Train Loss = 0.041575584560632706\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0413, train_loss_epoch=0.0416]Epoch 173: Train Loss = 0.04130170866847038\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0389, train_loss_epoch=0.0413]Epoch 174: Train Loss = 0.03891512379050255\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0345, train_loss_epoch=0.0389]Epoch 175: Train Loss = 0.034513454884290695\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0404, train_loss_epoch=0.0345]Epoch 176: Train Loss = 0.04043759033083916\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0353, train_loss_epoch=0.0404]Epoch 177: Train Loss = 0.035310663282871246\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0351, train_loss_epoch=0.0353]Epoch 178: Train Loss = 0.03514348715543747\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0377, train_loss_epoch=0.0351]Epoch 179: Train Loss = 0.0376909039914608\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0339, train_loss_epoch=0.0377]Epoch 180: Train Loss = 0.03393244743347168\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0403, train_loss_epoch=0.0339]Epoch 181: Train Loss = 0.040257856249809265\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0346, train_loss_epoch=0.0403]Epoch 182: Train Loss = 0.0345536544919014\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0357, train_loss_epoch=0.0346]Epoch 183: Train Loss = 0.035710226744413376\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0343, train_loss_epoch=0.0357]Epoch 184: Train Loss = 0.03434900566935539\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0347, train_loss_epoch=0.0343]Epoch 185: Train Loss = 0.03467821329832077\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0343, train_loss_epoch=0.0347]Epoch 186: Train Loss = 0.03432120755314827\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0348, train_loss_epoch=0.0343]Epoch 187: Train Loss = 0.03475344181060791\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0334, train_loss_epoch=0.0348]Epoch 188: Train Loss = 0.033401794731616974\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0332, train_loss_epoch=0.0334]Epoch 189: Train Loss = 0.03317662328481674\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0335, train_loss_epoch=0.0332]Epoch 190: Train Loss = 0.03349165990948677\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0335, train_loss_epoch=0.0335]Epoch 191: Train Loss = 0.033455539494752884\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0326, train_loss_epoch=0.0335]Epoch 192: Train Loss = 0.0325796902179718\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0337, train_loss_epoch=0.0326]Epoch 193: Train Loss = 0.03366449102759361\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0332, train_loss_epoch=0.0337]Epoch 194: Train Loss = 0.033220354467630386\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0331, train_loss_epoch=0.0332]Epoch 195: Train Loss = 0.033064939081668854\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0327, train_loss_epoch=0.0331]Epoch 196: Train Loss = 0.03266983479261398\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0339, train_loss_epoch=0.0327]Epoch 197: Train Loss = 0.03386029228568077\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0333, train_loss_epoch=0.0339]Epoch 198: Train Loss = 0.03334088623523712\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0329, train_loss_epoch=0.0333]Epoch 199: Train Loss = 0.03285698965191841\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0365, train_loss_epoch=0.0329]Epoch 200: Train Loss = 0.03645704314112663\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0336, train_loss_epoch=0.0365]Epoch 201: Train Loss = 0.0336136594414711\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0376, train_loss_epoch=0.0336]Epoch 202: Train Loss = 0.037555623799562454\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0323, train_loss_epoch=0.0376]Epoch 203: Train Loss = 0.032261550426483154\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0365, train_loss_epoch=0.0323]Epoch 204: Train Loss = 0.03652717173099518\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0339, train_loss_epoch=0.0365]Epoch 205: Train Loss = 0.033889878541231155\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.037, train_loss_epoch=0.0339] Epoch 206: Train Loss = 0.03696057200431824\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0353, train_loss_epoch=0.037]Epoch 207: Train Loss = 0.03534754738211632\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0351, train_loss_epoch=0.0353]Epoch 208: Train Loss = 0.035114873200654984\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0352, train_loss_epoch=0.0351]Epoch 209: Train Loss = 0.03524952009320259\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0317, train_loss_epoch=0.0352]Epoch 210: Train Loss = 0.03174502030014992\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0346, train_loss_epoch=0.0317]Epoch 211: Train Loss = 0.03462895005941391\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.033, train_loss_epoch=0.0346] Epoch 212: Train Loss = 0.03299032524228096\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0364, train_loss_epoch=0.033]Epoch 213: Train Loss = 0.03640148416161537\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0337, train_loss_epoch=0.0364]Epoch 214: Train Loss = 0.03370552882552147\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.035, train_loss_epoch=0.0337] Epoch 215: Train Loss = 0.035014089196920395\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.035, train_loss_epoch=0.035] Epoch 216: Train Loss = 0.03496801108121872\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0315, train_loss_epoch=0.035]Epoch 217: Train Loss = 0.03147958219051361\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0367, train_loss_epoch=0.0315]Epoch 218: Train Loss = 0.03666192293167114\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0327, train_loss_epoch=0.0367]Epoch 219: Train Loss = 0.03270412236452103\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0359, train_loss_epoch=0.0327]Epoch 220: Train Loss = 0.035895977169275284\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0335, train_loss_epoch=0.0359]Epoch 221: Train Loss = 0.033530402928590775\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0318, train_loss_epoch=0.0335]Epoch 222: Train Loss = 0.03176981583237648\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.034, train_loss_epoch=0.0318] Epoch 223: Train Loss = 0.03402986004948616\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.031, train_loss_epoch=0.034] Epoch 224: Train Loss = 0.03104669228196144\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0355, train_loss_epoch=0.031]Epoch 225: Train Loss = 0.03550407290458679\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.031, train_loss_epoch=0.0355] Epoch 226: Train Loss = 0.030960315838456154\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0361, train_loss_epoch=0.031]Epoch 227: Train Loss = 0.03605025261640549\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=218, train_loss_step=0.0312, train_loss_epoch=0.0361]Epoch 228: Train Loss = 0.031245794147253036\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0363, train_loss_epoch=0.0312]Epoch 229: Train Loss = 0.03630942851305008\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0302, train_loss_epoch=0.0363]Epoch 230: Train Loss = 0.030178898945450783\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0319, train_loss_epoch=0.0302]Epoch 231: Train Loss = 0.031944725662469864\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0324, train_loss_epoch=0.0319]Epoch 232: Train Loss = 0.032360903918743134\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0324, train_loss_epoch=0.0324]Epoch 233: Train Loss = 0.03240500018000603\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0336, train_loss_epoch=0.0324]Epoch 234: Train Loss = 0.03362179920077324\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0303, train_loss_epoch=0.0336]Epoch 235: Train Loss = 0.030315188691020012\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0344, train_loss_epoch=0.0303]Epoch 236: Train Loss = 0.03439408913254738\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.032, train_loss_epoch=0.0344] Epoch 237: Train Loss = 0.03198622167110443\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0325, train_loss_epoch=0.032]Epoch 238: Train Loss = 0.03248610347509384\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0333, train_loss_epoch=0.0325]Epoch 239: Train Loss = 0.0332864448428154\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0304, train_loss_epoch=0.0333]Epoch 240: Train Loss = 0.03037649765610695\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0331, train_loss_epoch=0.0304]Epoch 241: Train Loss = 0.033098578453063965\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0297, train_loss_epoch=0.0331]Epoch 242: Train Loss = 0.029656078666448593\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0324, train_loss_epoch=0.0297]Epoch 243: Train Loss = 0.032361164689064026\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0303, train_loss_epoch=0.0324]Epoch 244: Train Loss = 0.03030906245112419\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=218, train_loss_step=0.0304, train_loss_epoch=0.0303]Epoch 245: Train Loss = 0.03040614351630211\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0333, train_loss_epoch=0.0304]Epoch 246: Train Loss = 0.0333164744079113\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0301, train_loss_epoch=0.0333]Epoch 247: Train Loss = 0.030138496309518814\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=218, train_loss_step=0.0313, train_loss_epoch=0.0301]Epoch 248: Train Loss = 0.03125397115945816\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0322, train_loss_epoch=0.0313]Epoch 249: Train Loss = 0.03221249580383301\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0322, train_loss_epoch=0.0322]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=218, train_loss_step=0.0322, train_loss_epoch=0.0322]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 17: from 1998-11-02 00:00:00 to 2022-06-06 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.398]Epoch 0: Train Loss = 0.3981464207172394\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.500, train_loss_epoch=0.398]Epoch 1: Train Loss = 0.4997313320636749\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.376, train_loss_epoch=0.500]Epoch 2: Train Loss = 0.3756049871444702\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.248, train_loss_epoch=0.376]Epoch 3: Train Loss = 0.24793671071529388\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.310, train_loss_epoch=0.248]Epoch 4: Train Loss = 0.3104998469352722\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.317, train_loss_epoch=0.310]Epoch 5: Train Loss = 0.31748929619789124\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.257, train_loss_epoch=0.317]Epoch 6: Train Loss = 0.2571790814399719\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.237, train_loss_epoch=0.257]Epoch 7: Train Loss = 0.23713888227939606\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.269, train_loss_epoch=0.237]Epoch 8: Train Loss = 0.268707811832428\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.263, train_loss_epoch=0.269]Epoch 9: Train Loss = 0.26260605454444885\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.242, train_loss_epoch=0.263]Epoch 10: Train Loss = 0.2419927567243576\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.217, train_loss_epoch=0.242]Epoch 11: Train Loss = 0.21664966642856598\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.233, train_loss_epoch=0.217]Epoch 12: Train Loss = 0.23334142565727234\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.224, train_loss_epoch=0.233]Epoch 13: Train Loss = 0.22378693521022797\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.210, train_loss_epoch=0.224]Epoch 14: Train Loss = 0.21022871136665344\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.191, train_loss_epoch=0.210]Epoch 15: Train Loss = 0.1907608062028885\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.198, train_loss_epoch=0.191]Epoch 16: Train Loss = 0.1975010633468628\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.192, train_loss_epoch=0.198]Epoch 17: Train Loss = 0.19175797700881958\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.198, train_loss_epoch=0.192]Epoch 18: Train Loss = 0.19781173765659332\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.175, train_loss_epoch=0.198]Epoch 19: Train Loss = 0.17506030201911926\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.167, train_loss_epoch=0.175]Epoch 20: Train Loss = 0.16733510792255402\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.180, train_loss_epoch=0.167]Epoch 21: Train Loss = 0.1804078221321106\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.178, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.17834365367889404\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.163, train_loss_epoch=0.178]Epoch 23: Train Loss = 0.16269740462303162\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.156, train_loss_epoch=0.163]Epoch 24: Train Loss = 0.15644130110740662\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.155, train_loss_epoch=0.156]Epoch 25: Train Loss = 0.155463308095932\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.159, train_loss_epoch=0.155]Epoch 26: Train Loss = 0.1586303561925888\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.153, train_loss_epoch=0.159]Epoch 27: Train Loss = 0.15347805619239807\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.145, train_loss_epoch=0.153]Epoch 28: Train Loss = 0.1454819142818451\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.151, train_loss_epoch=0.145]Epoch 29: Train Loss = 0.15061548352241516\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.142, train_loss_epoch=0.151]Epoch 30: Train Loss = 0.1422043740749359\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.145, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.14465561509132385\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.140, train_loss_epoch=0.145]Epoch 32: Train Loss = 0.13993678987026215\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.134, train_loss_epoch=0.140]Epoch 33: Train Loss = 0.13443203270435333\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.136, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.13557589054107666\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.132, train_loss_epoch=0.136]Epoch 35: Train Loss = 0.13238948583602905\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.129, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.12909117341041565\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.131, train_loss_epoch=0.129]Epoch 37: Train Loss = 0.13098475337028503\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.122, train_loss_epoch=0.131]Epoch 38: Train Loss = 0.12213215976953506\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.119, train_loss_epoch=0.122]Epoch 39: Train Loss = 0.11855094134807587\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.116, train_loss_epoch=0.119]Epoch 40: Train Loss = 0.115716353058815\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.120, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.12028830498456955\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.118, train_loss_epoch=0.120]Epoch 42: Train Loss = 0.11767459660768509\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.110, train_loss_epoch=0.118]Epoch 43: Train Loss = 0.11022751778364182\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.113, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.1131264716386795\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.105, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10543781518936157\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.107, train_loss_epoch=0.105]Epoch 46: Train Loss = 0.10724323987960815\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.104, train_loss_epoch=0.107]Epoch 47: Train Loss = 0.1037466749548912\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.102, train_loss_epoch=0.104]Epoch 48: Train Loss = 0.10206595063209534\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.103, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.102508544921875\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0979, train_loss_epoch=0.103]Epoch 50: Train Loss = 0.09793366491794586\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.098, train_loss_epoch=0.0979] Epoch 51: Train Loss = 0.09804628789424896\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0973, train_loss_epoch=0.098]Epoch 52: Train Loss = 0.09732826799154282\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0946, train_loss_epoch=0.0973]Epoch 53: Train Loss = 0.09457169473171234\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.094, train_loss_epoch=0.0946] Epoch 54: Train Loss = 0.09403534978628159\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0928, train_loss_epoch=0.094]Epoch 55: Train Loss = 0.09278418868780136\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0912, train_loss_epoch=0.0928]Epoch 56: Train Loss = 0.09117846190929413\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0885, train_loss_epoch=0.0912]Epoch 57: Train Loss = 0.08849353343248367\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0878, train_loss_epoch=0.0885]Epoch 58: Train Loss = 0.08782059699296951\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0877, train_loss_epoch=0.0878]Epoch 59: Train Loss = 0.08773475885391235\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0845, train_loss_epoch=0.0877]Epoch 60: Train Loss = 0.08450236171483994\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.083, train_loss_epoch=0.0845] Epoch 61: Train Loss = 0.08300020545721054\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0804, train_loss_epoch=0.083]Epoch 62: Train Loss = 0.08040862530469894\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0796, train_loss_epoch=0.0804]Epoch 63: Train Loss = 0.07962722331285477\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0781, train_loss_epoch=0.0796]Epoch 64: Train Loss = 0.07813317328691483\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0776, train_loss_epoch=0.0781]Epoch 65: Train Loss = 0.07755103707313538\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0779, train_loss_epoch=0.0776]Epoch 66: Train Loss = 0.07788113504648209\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0754, train_loss_epoch=0.0779]Epoch 67: Train Loss = 0.07535640150308609\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0744, train_loss_epoch=0.0754]Epoch 68: Train Loss = 0.07444018125534058\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0718, train_loss_epoch=0.0744]Epoch 69: Train Loss = 0.07183383405208588\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0743, train_loss_epoch=0.0718]Epoch 70: Train Loss = 0.0742703303694725\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0698, train_loss_epoch=0.0743]Epoch 71: Train Loss = 0.06977446377277374\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0699, train_loss_epoch=0.0698]Epoch 72: Train Loss = 0.06990435719490051\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0683, train_loss_epoch=0.0699]Epoch 73: Train Loss = 0.06826446205377579\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0689, train_loss_epoch=0.0683]Epoch 74: Train Loss = 0.06892707943916321\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0659, train_loss_epoch=0.0689]Epoch 75: Train Loss = 0.06588573008775711\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0664, train_loss_epoch=0.0659]Epoch 76: Train Loss = 0.06639622896909714\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0669, train_loss_epoch=0.0664]Epoch 77: Train Loss = 0.06691984832286835\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0652, train_loss_epoch=0.0669]Epoch 78: Train Loss = 0.06515495479106903\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0626, train_loss_epoch=0.0652]Epoch 79: Train Loss = 0.06263529509305954\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0643, train_loss_epoch=0.0626]Epoch 80: Train Loss = 0.06425684690475464\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0625, train_loss_epoch=0.0643]Epoch 81: Train Loss = 0.0624917596578598\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0626, train_loss_epoch=0.0625]Epoch 82: Train Loss = 0.06260839104652405\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0618, train_loss_epoch=0.0626]Epoch 83: Train Loss = 0.061766739934682846\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0638, train_loss_epoch=0.0618]Epoch 84: Train Loss = 0.06375207006931305\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0592, train_loss_epoch=0.0638]Epoch 85: Train Loss = 0.05917634442448616\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0599, train_loss_epoch=0.0592]Epoch 86: Train Loss = 0.059947844594717026\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0581, train_loss_epoch=0.0599]Epoch 87: Train Loss = 0.058113157749176025\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0576, train_loss_epoch=0.0581]Epoch 88: Train Loss = 0.0576351135969162\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0571, train_loss_epoch=0.0576]Epoch 89: Train Loss = 0.05706962198019028\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0566, train_loss_epoch=0.0571]Epoch 90: Train Loss = 0.05655382573604584\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0556, train_loss_epoch=0.0566]Epoch 91: Train Loss = 0.055593088269233704\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0568, train_loss_epoch=0.0556]Epoch 92: Train Loss = 0.05682401731610298\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0537, train_loss_epoch=0.0568]Epoch 93: Train Loss = 0.05367520824074745\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.056, train_loss_epoch=0.0537] Epoch 94: Train Loss = 0.055951181799173355\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0529, train_loss_epoch=0.056]Epoch 95: Train Loss = 0.05291133373975754\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0553, train_loss_epoch=0.0529]Epoch 96: Train Loss = 0.055273134261369705\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0525, train_loss_epoch=0.0553]Epoch 97: Train Loss = 0.05250724032521248\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.056, train_loss_epoch=0.0525] Epoch 98: Train Loss = 0.05599283054471016\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0507, train_loss_epoch=0.056]Epoch 99: Train Loss = 0.050680678337812424\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0547, train_loss_epoch=0.0507]Epoch 100: Train Loss = 0.05473986268043518\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.050, train_loss_epoch=0.0547] Epoch 101: Train Loss = 0.049962084740400314\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0514, train_loss_epoch=0.050]Epoch 102: Train Loss = 0.051420725882053375\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0476, train_loss_epoch=0.0514]Epoch 103: Train Loss = 0.04756739363074303\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0556, train_loss_epoch=0.0476]Epoch 104: Train Loss = 0.05560814589262009\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0478, train_loss_epoch=0.0556]Epoch 105: Train Loss = 0.047812189906835556\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0598, train_loss_epoch=0.0478]Epoch 106: Train Loss = 0.059829775243997574\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0481, train_loss_epoch=0.0598]Epoch 107: Train Loss = 0.04808058589696884\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0616, train_loss_epoch=0.0481]Epoch 108: Train Loss = 0.06162836030125618\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0471, train_loss_epoch=0.0616]Epoch 109: Train Loss = 0.04711941257119179\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0561, train_loss_epoch=0.0471]Epoch 110: Train Loss = 0.05605059489607811\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0493, train_loss_epoch=0.0561]Epoch 111: Train Loss = 0.04927821084856987\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0542, train_loss_epoch=0.0493]Epoch 112: Train Loss = 0.054246533662080765\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0545, train_loss_epoch=0.0542]Epoch 113: Train Loss = 0.054510872811079025\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0518, train_loss_epoch=0.0545]Epoch 114: Train Loss = 0.05180034413933754\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0546, train_loss_epoch=0.0518]Epoch 115: Train Loss = 0.05461057648062706\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0478, train_loss_epoch=0.0546]Epoch 116: Train Loss = 0.04782216623425484\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0493, train_loss_epoch=0.0478]Epoch 117: Train Loss = 0.049268998205661774\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0444, train_loss_epoch=0.0493]Epoch 118: Train Loss = 0.044367413967847824\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0455, train_loss_epoch=0.0444]Epoch 119: Train Loss = 0.04550590366125107\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0443, train_loss_epoch=0.0455]Epoch 120: Train Loss = 0.044310312718153\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0447, train_loss_epoch=0.0443]Epoch 121: Train Loss = 0.04473971575498581\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0448, train_loss_epoch=0.0447]Epoch 122: Train Loss = 0.044790465384721756\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0478, train_loss_epoch=0.0448]Epoch 123: Train Loss = 0.04781289026141167\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0433, train_loss_epoch=0.0478]Epoch 124: Train Loss = 0.04331102967262268\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0505, train_loss_epoch=0.0433]Epoch 125: Train Loss = 0.050481829792261124\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0422, train_loss_epoch=0.0505]Epoch 126: Train Loss = 0.042157962918281555\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.044, train_loss_epoch=0.0422] Epoch 127: Train Loss = 0.04402485862374306\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0451, train_loss_epoch=0.044]Epoch 128: Train Loss = 0.04506895691156387\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0426, train_loss_epoch=0.0451]Epoch 129: Train Loss = 0.042555034160614014\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0454, train_loss_epoch=0.0426]Epoch 130: Train Loss = 0.04540131613612175\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0435, train_loss_epoch=0.0454]Epoch 131: Train Loss = 0.04350718483328819\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.046, train_loss_epoch=0.0435] Epoch 132: Train Loss = 0.04597751051187515\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0431, train_loss_epoch=0.046]Epoch 133: Train Loss = 0.043077439069747925\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0405, train_loss_epoch=0.0431]Epoch 134: Train Loss = 0.040470190346241\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0454, train_loss_epoch=0.0405]Epoch 135: Train Loss = 0.04538073390722275\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0428, train_loss_epoch=0.0454]Epoch 136: Train Loss = 0.04282683506608009\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.046, train_loss_epoch=0.0428] Epoch 137: Train Loss = 0.046002041548490524\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0417, train_loss_epoch=0.046]Epoch 138: Train Loss = 0.041659239679574966\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.043, train_loss_epoch=0.0417] Epoch 139: Train Loss = 0.04303037375211716\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0404, train_loss_epoch=0.043]Epoch 140: Train Loss = 0.040402207523584366\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0404, train_loss_epoch=0.0404]Epoch 141: Train Loss = 0.04035364091396332\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0415, train_loss_epoch=0.0404]Epoch 142: Train Loss = 0.04152859002351761\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0403, train_loss_epoch=0.0415]Epoch 143: Train Loss = 0.04027029499411583\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0394, train_loss_epoch=0.0403]Epoch 144: Train Loss = 0.03938048705458641\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0401, train_loss_epoch=0.0394]Epoch 145: Train Loss = 0.040098365396261215\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0397, train_loss_epoch=0.0401]Epoch 146: Train Loss = 0.03974608704447746\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0394, train_loss_epoch=0.0397]Epoch 147: Train Loss = 0.03938841074705124\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0392, train_loss_epoch=0.0394]Epoch 148: Train Loss = 0.0391598679125309\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0386, train_loss_epoch=0.0392]Epoch 149: Train Loss = 0.03858285769820213\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0383, train_loss_epoch=0.0386]Epoch 150: Train Loss = 0.038273341953754425\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0386, train_loss_epoch=0.0383]Epoch 151: Train Loss = 0.03859495744109154\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0386, train_loss_epoch=0.0386]Epoch 152: Train Loss = 0.038627296686172485\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0371, train_loss_epoch=0.0386]Epoch 153: Train Loss = 0.0371028371155262\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0394, train_loss_epoch=0.0371]Epoch 154: Train Loss = 0.03943565860390663\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0381, train_loss_epoch=0.0394]Epoch 155: Train Loss = 0.03811631724238396\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0406, train_loss_epoch=0.0381]Epoch 156: Train Loss = 0.0406402088701725\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0387, train_loss_epoch=0.0406]Epoch 157: Train Loss = 0.03874487057328224\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0421, train_loss_epoch=0.0387]Epoch 158: Train Loss = 0.04205256700515747\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0391, train_loss_epoch=0.0421]Epoch 159: Train Loss = 0.03905732184648514\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0383, train_loss_epoch=0.0391]Epoch 160: Train Loss = 0.038266267627477646\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0384, train_loss_epoch=0.0383]Epoch 161: Train Loss = 0.038386933505535126\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0375, train_loss_epoch=0.0384]Epoch 162: Train Loss = 0.0374532975256443\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0365, train_loss_epoch=0.0375]Epoch 163: Train Loss = 0.03650595620274544\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0374, train_loss_epoch=0.0365]Epoch 164: Train Loss = 0.03735493868589401\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0382, train_loss_epoch=0.0374]Epoch 165: Train Loss = 0.038162071257829666\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0379, train_loss_epoch=0.0382]Epoch 166: Train Loss = 0.037875182926654816\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0376, train_loss_epoch=0.0379]Epoch 167: Train Loss = 0.037569329142570496\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0417, train_loss_epoch=0.0376]Epoch 168: Train Loss = 0.04165394604206085\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.036, train_loss_epoch=0.0417] Epoch 169: Train Loss = 0.036012083292007446\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0389, train_loss_epoch=0.036]Epoch 170: Train Loss = 0.03888656571507454\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0355, train_loss_epoch=0.0389]Epoch 171: Train Loss = 0.0354507714509964\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0362, train_loss_epoch=0.0355]Epoch 172: Train Loss = 0.03617236390709877\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0392, train_loss_epoch=0.0362]Epoch 173: Train Loss = 0.03918754309415817\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0354, train_loss_epoch=0.0392]Epoch 174: Train Loss = 0.03541365638375282\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0381, train_loss_epoch=0.0354]Epoch 175: Train Loss = 0.038145020604133606\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.035, train_loss_epoch=0.0381] Epoch 176: Train Loss = 0.03497777134180069\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0363, train_loss_epoch=0.035]Epoch 177: Train Loss = 0.036329153925180435\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0355, train_loss_epoch=0.0363]Epoch 178: Train Loss = 0.035488955676555634\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0357, train_loss_epoch=0.0355]Epoch 179: Train Loss = 0.03570624068379402\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.035, train_loss_epoch=0.0357] Epoch 180: Train Loss = 0.03499177098274231\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0359, train_loss_epoch=0.035]Epoch 181: Train Loss = 0.03587496280670166\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0349, train_loss_epoch=0.0359]Epoch 182: Train Loss = 0.03489099070429802\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0354, train_loss_epoch=0.0349]Epoch 183: Train Loss = 0.03543245792388916\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0346, train_loss_epoch=0.0354]Epoch 184: Train Loss = 0.034632544964551926\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0337, train_loss_epoch=0.0346]Epoch 185: Train Loss = 0.03374724090099335\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0348, train_loss_epoch=0.0337]Epoch 186: Train Loss = 0.034849219024181366\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0346, train_loss_epoch=0.0348]Epoch 187: Train Loss = 0.03461755812168121\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0365, train_loss_epoch=0.0346]Epoch 188: Train Loss = 0.036529261618852615\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0341, train_loss_epoch=0.0365]Epoch 189: Train Loss = 0.03408363461494446\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0368, train_loss_epoch=0.0341]Epoch 190: Train Loss = 0.03675897419452667\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0366, train_loss_epoch=0.0368]Epoch 191: Train Loss = 0.03656398877501488\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0351, train_loss_epoch=0.0366]Epoch 192: Train Loss = 0.035054463893175125\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0367, train_loss_epoch=0.0351]Epoch 193: Train Loss = 0.036733098328113556\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0344, train_loss_epoch=0.0367]Epoch 194: Train Loss = 0.03442522883415222\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0344, train_loss_epoch=0.0344]Epoch 195: Train Loss = 0.03442250192165375\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0344, train_loss_epoch=0.0344]Epoch 196: Train Loss = 0.0344238206744194\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0371, train_loss_epoch=0.0344]Epoch 197: Train Loss = 0.03706023469567299\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0329, train_loss_epoch=0.0371]Epoch 198: Train Loss = 0.032932981848716736\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0352, train_loss_epoch=0.0329]Epoch 199: Train Loss = 0.03522631525993347\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0334, train_loss_epoch=0.0352]Epoch 200: Train Loss = 0.03336837887763977\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0369, train_loss_epoch=0.0334]Epoch 201: Train Loss = 0.0369361974298954\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0358, train_loss_epoch=0.0369]Epoch 202: Train Loss = 0.035818446427583694\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.034, train_loss_epoch=0.0358] Epoch 203: Train Loss = 0.03397236764431\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0345, train_loss_epoch=0.034]Epoch 204: Train Loss = 0.034506868571043015\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0326, train_loss_epoch=0.0345]Epoch 205: Train Loss = 0.032563451677560806\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0357, train_loss_epoch=0.0326]Epoch 206: Train Loss = 0.035749804228544235\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0335, train_loss_epoch=0.0357]Epoch 207: Train Loss = 0.03354538604617119\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0373, train_loss_epoch=0.0335]Epoch 208: Train Loss = 0.03729003295302391\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.033, train_loss_epoch=0.0373] Epoch 209: Train Loss = 0.03304538503289223\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.034, train_loss_epoch=0.033] Epoch 210: Train Loss = 0.03404751047492027\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.0327, train_loss_epoch=0.034]Epoch 211: Train Loss = 0.03274811804294586\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0323, train_loss_epoch=0.0327]Epoch 212: Train Loss = 0.0322590097784996\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=220, train_loss_step=0.032, train_loss_epoch=0.0323] Epoch 213: Train Loss = 0.032007426023483276\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0331, train_loss_epoch=0.032]Epoch 214: Train Loss = 0.033055976033210754\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0369, train_loss_epoch=0.0331]Epoch 215: Train Loss = 0.0369463749229908\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0328, train_loss_epoch=0.0369]Epoch 216: Train Loss = 0.0328342467546463\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0318, train_loss_epoch=0.0328]Epoch 217: Train Loss = 0.031828440725803375\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0326, train_loss_epoch=0.0318]Epoch 218: Train Loss = 0.03259630873799324\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.032, train_loss_epoch=0.0326] Epoch 219: Train Loss = 0.03196798264980316\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.033, train_loss_epoch=0.032] Epoch 220: Train Loss = 0.032969988882541656\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0319, train_loss_epoch=0.033]Epoch 221: Train Loss = 0.031868401914834976\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0324, train_loss_epoch=0.0319]Epoch 222: Train Loss = 0.03241107612848282\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0346, train_loss_epoch=0.0324]Epoch 223: Train Loss = 0.03462885692715645\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0323, train_loss_epoch=0.0346]Epoch 224: Train Loss = 0.03232693672180176\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0336, train_loss_epoch=0.0323]Epoch 225: Train Loss = 0.03363080695271492\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0313, train_loss_epoch=0.0336]Epoch 226: Train Loss = 0.03128635510802269\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0342, train_loss_epoch=0.0313]Epoch 227: Train Loss = 0.03423410281538963\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0347, train_loss_epoch=0.0342]Epoch 228: Train Loss = 0.034716974943876266\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0322, train_loss_epoch=0.0347]Epoch 229: Train Loss = 0.032228946685791016\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0315, train_loss_epoch=0.0322]Epoch 230: Train Loss = 0.03153254836797714\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0334, train_loss_epoch=0.0315]Epoch 231: Train Loss = 0.03340800479054451\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0329, train_loss_epoch=0.0334]Epoch 232: Train Loss = 0.03289908170700073\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0326, train_loss_epoch=0.0329]Epoch 233: Train Loss = 0.03257662057876587\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0317, train_loss_epoch=0.0326]Epoch 234: Train Loss = 0.03171791881322861\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0331, train_loss_epoch=0.0317]Epoch 235: Train Loss = 0.033102259039878845\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0316, train_loss_epoch=0.0331]Epoch 236: Train Loss = 0.03164134547114372\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0326, train_loss_epoch=0.0316]Epoch 237: Train Loss = 0.032593682408332825\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0309, train_loss_epoch=0.0326]Epoch 238: Train Loss = 0.030934946611523628\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0362, train_loss_epoch=0.0309]Epoch 239: Train Loss = 0.036168914288282394\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0308, train_loss_epoch=0.0362]Epoch 240: Train Loss = 0.03078899160027504\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0324, train_loss_epoch=0.0308]Epoch 241: Train Loss = 0.03237910196185112\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0357, train_loss_epoch=0.0324]Epoch 242: Train Loss = 0.0357435941696167\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0372, train_loss_epoch=0.0357]Epoch 243: Train Loss = 0.03721122071146965\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0338, train_loss_epoch=0.0372]Epoch 244: Train Loss = 0.0337979830801487\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0307, train_loss_epoch=0.0338]Epoch 245: Train Loss = 0.03074212558567524\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0338, train_loss_epoch=0.0307]Epoch 246: Train Loss = 0.03382918983697891\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.031, train_loss_epoch=0.0338] Epoch 247: Train Loss = 0.03096690960228443\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=220, train_loss_step=0.0311, train_loss_epoch=0.031]Epoch 248: Train Loss = 0.03110417164862156\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0329, train_loss_epoch=0.0311]Epoch 249: Train Loss = 0.032945118844509125\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0329, train_loss_epoch=0.0329]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=220, train_loss_step=0.0329, train_loss_epoch=0.0329]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 18: from 1998-11-02 00:00:00 to 2022-06-15 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.403]Epoch 0: Train Loss = 0.40305814146995544\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.495, train_loss_epoch=0.403]Epoch 1: Train Loss = 0.49519023299217224\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.371, train_loss_epoch=0.495]Epoch 2: Train Loss = 0.3713236451148987\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.249, train_loss_epoch=0.371]Epoch 3: Train Loss = 0.24945983290672302\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.306, train_loss_epoch=0.249]Epoch 4: Train Loss = 0.3063555359840393\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.315, train_loss_epoch=0.306]Epoch 5: Train Loss = 0.31516513228416443\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.259, train_loss_epoch=0.315]Epoch 6: Train Loss = 0.2588602900505066\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.243, train_loss_epoch=0.259]Epoch 7: Train Loss = 0.24328456819057465\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.268, train_loss_epoch=0.243]Epoch 8: Train Loss = 0.2682570219039917\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.258, train_loss_epoch=0.268]Epoch 9: Train Loss = 0.2576890289783478\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.240, train_loss_epoch=0.258]Epoch 10: Train Loss = 0.23979118466377258\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.223, train_loss_epoch=0.240]Epoch 11: Train Loss = 0.22266295552253723\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.235, train_loss_epoch=0.223]Epoch 12: Train Loss = 0.2353302240371704\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.221, train_loss_epoch=0.235]Epoch 13: Train Loss = 0.22124840319156647\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.211, train_loss_epoch=0.221]Epoch 14: Train Loss = 0.21144016087055206\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.190, train_loss_epoch=0.211]Epoch 15: Train Loss = 0.1903546005487442\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.200, train_loss_epoch=0.190]Epoch 16: Train Loss = 0.1998680830001831\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.191, train_loss_epoch=0.200]Epoch 17: Train Loss = 0.19067102670669556\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.198, train_loss_epoch=0.191]Epoch 18: Train Loss = 0.1983584761619568\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.174, train_loss_epoch=0.198]Epoch 19: Train Loss = 0.17365510761737823\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.170, train_loss_epoch=0.174]Epoch 20: Train Loss = 0.16962096095085144\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.182, train_loss_epoch=0.170]Epoch 21: Train Loss = 0.18169894814491272\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.180, train_loss_epoch=0.182]Epoch 22: Train Loss = 0.17976811528205872\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.162, train_loss_epoch=0.180]Epoch 23: Train Loss = 0.16235515475273132\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.161, train_loss_epoch=0.162]Epoch 24: Train Loss = 0.1612509936094284\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.157, train_loss_epoch=0.161]Epoch 25: Train Loss = 0.1573135107755661\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.161, train_loss_epoch=0.157]Epoch 26: Train Loss = 0.16086700558662415\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.153, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.15259557962417603\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.145, train_loss_epoch=0.153]Epoch 28: Train Loss = 0.14494146406650543\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.150, train_loss_epoch=0.145]Epoch 29: Train Loss = 0.14991497993469238\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.144, train_loss_epoch=0.150]Epoch 30: Train Loss = 0.14405570924282074\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.144, train_loss_epoch=0.144]Epoch 31: Train Loss = 0.14401064813137054\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.139, train_loss_epoch=0.144]Epoch 32: Train Loss = 0.13927218317985535\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.135, train_loss_epoch=0.139]Epoch 33: Train Loss = 0.13493917882442474\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.135, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13484813272953033\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.132, train_loss_epoch=0.135]Epoch 35: Train Loss = 0.1319313645362854\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.128, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.12833039462566376\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.130, train_loss_epoch=0.128]Epoch 37: Train Loss = 0.13031317293643951\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.122, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12234240770339966\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.118, train_loss_epoch=0.122]Epoch 39: Train Loss = 0.11811404675245285\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.115, train_loss_epoch=0.118]Epoch 40: Train Loss = 0.11480488628149033\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.117, train_loss_epoch=0.115]Epoch 41: Train Loss = 0.1168222427368164\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.115, train_loss_epoch=0.117]Epoch 42: Train Loss = 0.11488592624664307\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.110, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.1098344698548317\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.113, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11289581656455994\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.106, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10582021623849869\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.106, train_loss_epoch=0.106]Epoch 46: Train Loss = 0.10570356994867325\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.103, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.10328056663274765\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.102, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10177571326494217\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.102, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.10213729739189148\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0979, train_loss_epoch=0.102]Epoch 50: Train Loss = 0.0978991836309433\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0974, train_loss_epoch=0.0979]Epoch 51: Train Loss = 0.09739598631858826\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0964, train_loss_epoch=0.0974]Epoch 52: Train Loss = 0.09639427065849304\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0921, train_loss_epoch=0.0964]Epoch 53: Train Loss = 0.09206549823284149\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0922, train_loss_epoch=0.0921]Epoch 54: Train Loss = 0.09219148010015488\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0919, train_loss_epoch=0.0922]Epoch 55: Train Loss = 0.09188026934862137\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0908, train_loss_epoch=0.0919]Epoch 56: Train Loss = 0.09081582725048065\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0874, train_loss_epoch=0.0908]Epoch 57: Train Loss = 0.087374247610569\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0877, train_loss_epoch=0.0874]Epoch 58: Train Loss = 0.08768798410892487\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0839, train_loss_epoch=0.0877]Epoch 59: Train Loss = 0.08389964699745178\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0864, train_loss_epoch=0.0839]Epoch 60: Train Loss = 0.0863828957080841\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0792, train_loss_epoch=0.0864]Epoch 61: Train Loss = 0.07915925234556198\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0856, train_loss_epoch=0.0792]Epoch 62: Train Loss = 0.08556437492370605\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0782, train_loss_epoch=0.0856]Epoch 63: Train Loss = 0.0782344713807106\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0817, train_loss_epoch=0.0782]Epoch 64: Train Loss = 0.08166209608316422\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0775, train_loss_epoch=0.0817]Epoch 65: Train Loss = 0.07746538519859314\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0802, train_loss_epoch=0.0775]Epoch 66: Train Loss = 0.08016792684793472\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0786, train_loss_epoch=0.0802]Epoch 67: Train Loss = 0.07856746762990952\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0766, train_loss_epoch=0.0786]Epoch 68: Train Loss = 0.0765681117773056\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0741, train_loss_epoch=0.0766]Epoch 69: Train Loss = 0.07414978742599487\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0728, train_loss_epoch=0.0741]Epoch 70: Train Loss = 0.07281237840652466\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0732, train_loss_epoch=0.0728]Epoch 71: Train Loss = 0.07315640896558762\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0693, train_loss_epoch=0.0732]Epoch 72: Train Loss = 0.06929632276296616\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0716, train_loss_epoch=0.0693]Epoch 73: Train Loss = 0.07161463052034378\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0723, train_loss_epoch=0.0716]Epoch 74: Train Loss = 0.07227964699268341\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.067, train_loss_epoch=0.0723] Epoch 75: Train Loss = 0.06701292097568512\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0712, train_loss_epoch=0.067]Epoch 76: Train Loss = 0.07118469476699829\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0659, train_loss_epoch=0.0712]Epoch 77: Train Loss = 0.06594500690698624\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0702, train_loss_epoch=0.0659]Epoch 78: Train Loss = 0.07019125670194626\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0639, train_loss_epoch=0.0702]Epoch 79: Train Loss = 0.06393764913082123\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0642, train_loss_epoch=0.0639]Epoch 80: Train Loss = 0.06416253000497818\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0646, train_loss_epoch=0.0642]Epoch 81: Train Loss = 0.06456080824136734\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0632, train_loss_epoch=0.0646]Epoch 82: Train Loss = 0.06320150941610336\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0657, train_loss_epoch=0.0632]Epoch 83: Train Loss = 0.06572957336902618\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0624, train_loss_epoch=0.0657]Epoch 84: Train Loss = 0.06238669529557228\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.064, train_loss_epoch=0.0624] Epoch 85: Train Loss = 0.06402420252561569\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0615, train_loss_epoch=0.064]Epoch 86: Train Loss = 0.06147840619087219\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0604, train_loss_epoch=0.0615]Epoch 87: Train Loss = 0.060373060405254364\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0637, train_loss_epoch=0.0604]Epoch 88: Train Loss = 0.06371551007032394\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.058, train_loss_epoch=0.0637] Epoch 89: Train Loss = 0.05795016139745712\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0644, train_loss_epoch=0.058]Epoch 90: Train Loss = 0.06444483250379562\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0563, train_loss_epoch=0.0644]Epoch 91: Train Loss = 0.05629657581448555\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0565, train_loss_epoch=0.0563]Epoch 92: Train Loss = 0.05652974173426628\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0598, train_loss_epoch=0.0565]Epoch 93: Train Loss = 0.05978751927614212\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.056, train_loss_epoch=0.0598] Epoch 94: Train Loss = 0.056008949875831604\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0609, train_loss_epoch=0.056]Epoch 95: Train Loss = 0.060912124812603\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0544, train_loss_epoch=0.0609]Epoch 96: Train Loss = 0.05437437444925308\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0568, train_loss_epoch=0.0544]Epoch 97: Train Loss = 0.05683312192559242\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0586, train_loss_epoch=0.0568]Epoch 98: Train Loss = 0.058597955852746964\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0549, train_loss_epoch=0.0586]Epoch 99: Train Loss = 0.05489196255803108\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0562, train_loss_epoch=0.0549]Epoch 100: Train Loss = 0.05622154474258423\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0526, train_loss_epoch=0.0562]Epoch 101: Train Loss = 0.052588675171136856\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0576, train_loss_epoch=0.0526]Epoch 102: Train Loss = 0.05759856849908829\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0518, train_loss_epoch=0.0576]Epoch 103: Train Loss = 0.05178798362612724\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0574, train_loss_epoch=0.0518]Epoch 104: Train Loss = 0.05742403864860535\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0511, train_loss_epoch=0.0574]Epoch 105: Train Loss = 0.0511496365070343\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.053, train_loss_epoch=0.0511] Epoch 106: Train Loss = 0.05300381779670715\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0547, train_loss_epoch=0.053]Epoch 107: Train Loss = 0.05468253418803215\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0511, train_loss_epoch=0.0547]Epoch 108: Train Loss = 0.05106290057301521\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0529, train_loss_epoch=0.0511]Epoch 109: Train Loss = 0.0528692863881588\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0492, train_loss_epoch=0.0529]Epoch 110: Train Loss = 0.04919085279107094\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0535, train_loss_epoch=0.0492]Epoch 111: Train Loss = 0.05351286754012108\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0512, train_loss_epoch=0.0535]Epoch 112: Train Loss = 0.05116897076368332\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.051, train_loss_epoch=0.0512] Epoch 113: Train Loss = 0.0510370247066021\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0526, train_loss_epoch=0.051]Epoch 114: Train Loss = 0.05260073021054268\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0473, train_loss_epoch=0.0526]Epoch 115: Train Loss = 0.04726182669401169\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0497, train_loss_epoch=0.0473]Epoch 116: Train Loss = 0.04966231435537338\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0481, train_loss_epoch=0.0497]Epoch 117: Train Loss = 0.04813491553068161\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0466, train_loss_epoch=0.0481]Epoch 118: Train Loss = 0.04659494385123253\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.057, train_loss_epoch=0.0466] Epoch 119: Train Loss = 0.057027991861104965\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0448, train_loss_epoch=0.057]Epoch 120: Train Loss = 0.0448489785194397\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0635, train_loss_epoch=0.0448]Epoch 121: Train Loss = 0.06354088336229324\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0533, train_loss_epoch=0.0635]Epoch 122: Train Loss = 0.053261999040842056\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0513, train_loss_epoch=0.0533]Epoch 123: Train Loss = 0.051322925835847855\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0565, train_loss_epoch=0.0513]Epoch 124: Train Loss = 0.05647580325603485\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0447, train_loss_epoch=0.0565]Epoch 125: Train Loss = 0.044749896973371506\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0553, train_loss_epoch=0.0447]Epoch 126: Train Loss = 0.05526380240917206\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0509, train_loss_epoch=0.0553]Epoch 127: Train Loss = 0.05087948590517044\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.046, train_loss_epoch=0.0509] Epoch 128: Train Loss = 0.04603144899010658\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0526, train_loss_epoch=0.046]Epoch 129: Train Loss = 0.05259597301483154\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0443, train_loss_epoch=0.0526]Epoch 130: Train Loss = 0.044335607439279556\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0477, train_loss_epoch=0.0443]Epoch 131: Train Loss = 0.04766625165939331\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0478, train_loss_epoch=0.0477]Epoch 132: Train Loss = 0.0478239543735981\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0436, train_loss_epoch=0.0478]Epoch 133: Train Loss = 0.04356277361512184\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.047, train_loss_epoch=0.0436] Epoch 134: Train Loss = 0.04703286662697792\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0444, train_loss_epoch=0.047]Epoch 135: Train Loss = 0.04444517195224762\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0442, train_loss_epoch=0.0444]Epoch 136: Train Loss = 0.04423930495977402\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0443, train_loss_epoch=0.0442]Epoch 137: Train Loss = 0.04426708072423935\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0421, train_loss_epoch=0.0443]Epoch 138: Train Loss = 0.04212851822376251\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0442, train_loss_epoch=0.0421]Epoch 139: Train Loss = 0.044151268899440765\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.043, train_loss_epoch=0.0442] Epoch 140: Train Loss = 0.042956430464982986\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0407, train_loss_epoch=0.043]Epoch 141: Train Loss = 0.04074510186910629\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0449, train_loss_epoch=0.0407]Epoch 142: Train Loss = 0.044870082288980484\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0423, train_loss_epoch=0.0449]Epoch 143: Train Loss = 0.04229346662759781\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0443, train_loss_epoch=0.0423]Epoch 144: Train Loss = 0.044324807822704315\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.042, train_loss_epoch=0.0443] Epoch 145: Train Loss = 0.04196891561150551\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0411, train_loss_epoch=0.042]Epoch 146: Train Loss = 0.0411389134824276\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0446, train_loss_epoch=0.0411]Epoch 147: Train Loss = 0.04457269608974457\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0429, train_loss_epoch=0.0446]Epoch 148: Train Loss = 0.042862024158239365\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0477, train_loss_epoch=0.0429]Epoch 149: Train Loss = 0.04770854860544205\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0444, train_loss_epoch=0.0477]Epoch 150: Train Loss = 0.044418539851903915\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.040, train_loss_epoch=0.0444] Epoch 151: Train Loss = 0.03996283933520317\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0451, train_loss_epoch=0.040]Epoch 152: Train Loss = 0.0450645387172699\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0453, train_loss_epoch=0.0451]Epoch 153: Train Loss = 0.0453418530523777\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0436, train_loss_epoch=0.0453]Epoch 154: Train Loss = 0.04361334443092346\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0528, train_loss_epoch=0.0436]Epoch 155: Train Loss = 0.05281083658337593\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.039, train_loss_epoch=0.0528] Epoch 156: Train Loss = 0.03896842151880264\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0438, train_loss_epoch=0.039]Epoch 157: Train Loss = 0.04382963851094246\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0408, train_loss_epoch=0.0438]Epoch 158: Train Loss = 0.040774740278720856\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0395, train_loss_epoch=0.0408]Epoch 159: Train Loss = 0.039479706436395645\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0424, train_loss_epoch=0.0395]Epoch 160: Train Loss = 0.04238227754831314\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0409, train_loss_epoch=0.0424]Epoch 161: Train Loss = 0.040880050510168076\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0387, train_loss_epoch=0.0409]Epoch 162: Train Loss = 0.0387481190264225\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0408, train_loss_epoch=0.0387]Epoch 163: Train Loss = 0.04084502160549164\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0376, train_loss_epoch=0.0408]Epoch 164: Train Loss = 0.037641461938619614\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0386, train_loss_epoch=0.0376]Epoch 165: Train Loss = 0.0385965034365654\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0411, train_loss_epoch=0.0386]Epoch 166: Train Loss = 0.04107449948787689\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0376, train_loss_epoch=0.0411]Epoch 167: Train Loss = 0.0375785268843174\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0392, train_loss_epoch=0.0376]Epoch 168: Train Loss = 0.039159804582595825\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0381, train_loss_epoch=0.0392]Epoch 169: Train Loss = 0.03810080513358116\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0381, train_loss_epoch=0.0381]Epoch 170: Train Loss = 0.03808319568634033\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0389, train_loss_epoch=0.0381]Epoch 171: Train Loss = 0.03892768546938896\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.037, train_loss_epoch=0.0389] Epoch 172: Train Loss = 0.037017203867435455\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0408, train_loss_epoch=0.037]Epoch 173: Train Loss = 0.04078991338610649\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0368, train_loss_epoch=0.0408]Epoch 174: Train Loss = 0.03684939071536064\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0381, train_loss_epoch=0.0368]Epoch 175: Train Loss = 0.038118310272693634\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0369, train_loss_epoch=0.0381]Epoch 176: Train Loss = 0.03689735755324364\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0371, train_loss_epoch=0.0369]Epoch 177: Train Loss = 0.0370807871222496\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0374, train_loss_epoch=0.0371]Epoch 178: Train Loss = 0.03735576197504997\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0372, train_loss_epoch=0.0374]Epoch 179: Train Loss = 0.03717561811208725\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0364, train_loss_epoch=0.0372]Epoch 180: Train Loss = 0.03635740280151367\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.037, train_loss_epoch=0.0364] Epoch 181: Train Loss = 0.037044648081064224\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0362, train_loss_epoch=0.037]Epoch 182: Train Loss = 0.03622356057167053\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0367, train_loss_epoch=0.0362]Epoch 183: Train Loss = 0.036690518260002136\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0352, train_loss_epoch=0.0367]Epoch 184: Train Loss = 0.03518575802445412\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0355, train_loss_epoch=0.0352]Epoch 185: Train Loss = 0.035457544028759\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0356, train_loss_epoch=0.0355]Epoch 186: Train Loss = 0.03558538481593132\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0352, train_loss_epoch=0.0356]Epoch 187: Train Loss = 0.035208068788051605\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0363, train_loss_epoch=0.0352]Epoch 188: Train Loss = 0.036318324506282806\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.035, train_loss_epoch=0.0363] Epoch 189: Train Loss = 0.0349939800798893\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0353, train_loss_epoch=0.035]Epoch 190: Train Loss = 0.03532197326421738\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0352, train_loss_epoch=0.0353]Epoch 191: Train Loss = 0.035204388201236725\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0358, train_loss_epoch=0.0352]Epoch 192: Train Loss = 0.03584342822432518\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0355, train_loss_epoch=0.0358]Epoch 193: Train Loss = 0.035460833460092545\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0351, train_loss_epoch=0.0355]Epoch 194: Train Loss = 0.03514178842306137\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0371, train_loss_epoch=0.0351]Epoch 195: Train Loss = 0.03709573298692703\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.035, train_loss_epoch=0.0371] Epoch 196: Train Loss = 0.034954775124788284\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0346, train_loss_epoch=0.035]Epoch 197: Train Loss = 0.03462681546807289\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0365, train_loss_epoch=0.0346]Epoch 198: Train Loss = 0.03652886673808098\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0366, train_loss_epoch=0.0365]Epoch 199: Train Loss = 0.03661471605300903\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0356, train_loss_epoch=0.0366]Epoch 200: Train Loss = 0.035629577934741974\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0389, train_loss_epoch=0.0356]Epoch 201: Train Loss = 0.038930438458919525\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.034, train_loss_epoch=0.0389] Epoch 202: Train Loss = 0.03397636488080025\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0361, train_loss_epoch=0.034]Epoch 203: Train Loss = 0.036076705902814865\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.037, train_loss_epoch=0.0361] Epoch 204: Train Loss = 0.036986544728279114\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.037, train_loss_epoch=0.037] Epoch 205: Train Loss = 0.036979470402002335\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0359, train_loss_epoch=0.037]Epoch 206: Train Loss = 0.03587500751018524\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0335, train_loss_epoch=0.0359]Epoch 207: Train Loss = 0.03348229080438614\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0403, train_loss_epoch=0.0335]Epoch 208: Train Loss = 0.040254268795251846\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0339, train_loss_epoch=0.0403]Epoch 209: Train Loss = 0.03394792228937149\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0376, train_loss_epoch=0.0339]Epoch 210: Train Loss = 0.03759514167904854\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0355, train_loss_epoch=0.0376]Epoch 211: Train Loss = 0.03551967442035675\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0335, train_loss_epoch=0.0355]Epoch 212: Train Loss = 0.0335499532520771\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0376, train_loss_epoch=0.0335]Epoch 213: Train Loss = 0.037560928612947464\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0332, train_loss_epoch=0.0376]Epoch 214: Train Loss = 0.03320762515068054\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0336, train_loss_epoch=0.0332]Epoch 215: Train Loss = 0.03360139951109886\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0343, train_loss_epoch=0.0336]Epoch 216: Train Loss = 0.0343320295214653\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0336, train_loss_epoch=0.0343]Epoch 217: Train Loss = 0.03360355272889137\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0339, train_loss_epoch=0.0336]Epoch 218: Train Loss = 0.033879514783620834\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0354, train_loss_epoch=0.0339]Epoch 219: Train Loss = 0.035352542996406555\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0323, train_loss_epoch=0.0354]Epoch 220: Train Loss = 0.032312676310539246\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0347, train_loss_epoch=0.0323]Epoch 221: Train Loss = 0.034692246466875076\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0325, train_loss_epoch=0.0347]Epoch 222: Train Loss = 0.03249337524175644\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0326, train_loss_epoch=0.0325]Epoch 223: Train Loss = 0.03263826295733452\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0349, train_loss_epoch=0.0326]Epoch 224: Train Loss = 0.034928012639284134\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0337, train_loss_epoch=0.0349]Epoch 225: Train Loss = 0.033662036061286926\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0329, train_loss_epoch=0.0337]Epoch 226: Train Loss = 0.03292308747768402\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0367, train_loss_epoch=0.0329]Epoch 227: Train Loss = 0.036693181842565536\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0324, train_loss_epoch=0.0367]Epoch 228: Train Loss = 0.03239466995000839\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.035, train_loss_epoch=0.0324] Epoch 229: Train Loss = 0.03503333032131195\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0401, train_loss_epoch=0.035]Epoch 230: Train Loss = 0.04007060080766678\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0337, train_loss_epoch=0.0401]Epoch 231: Train Loss = 0.03369419649243355\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0413, train_loss_epoch=0.0337]Epoch 232: Train Loss = 0.04126451537013054\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0328, train_loss_epoch=0.0413]Epoch 233: Train Loss = 0.03282207250595093\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0352, train_loss_epoch=0.0328]Epoch 234: Train Loss = 0.03521527349948883\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0326, train_loss_epoch=0.0352]Epoch 235: Train Loss = 0.032550353556871414\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.032, train_loss_epoch=0.0326] Epoch 236: Train Loss = 0.03200996294617653\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0336, train_loss_epoch=0.032]Epoch 237: Train Loss = 0.033590737730264664\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=222, train_loss_step=0.0316, train_loss_epoch=0.0336]Epoch 238: Train Loss = 0.03157416731119156\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0326, train_loss_epoch=0.0316]Epoch 239: Train Loss = 0.032557811588048935\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0336, train_loss_epoch=0.0326]Epoch 240: Train Loss = 0.03355003520846367\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0317, train_loss_epoch=0.0336]Epoch 241: Train Loss = 0.03166409209370613\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0405, train_loss_epoch=0.0317]Epoch 242: Train Loss = 0.04050084203481674\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0338, train_loss_epoch=0.0405]Epoch 243: Train Loss = 0.03376612067222595\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0358, train_loss_epoch=0.0338]Epoch 244: Train Loss = 0.035786379128694534\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0429, train_loss_epoch=0.0358]Epoch 245: Train Loss = 0.04288919270038605\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.0327, train_loss_epoch=0.0429]Epoch 246: Train Loss = 0.03272831812500954\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0393, train_loss_epoch=0.0327]Epoch 247: Train Loss = 0.03934571146965027\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=222, train_loss_step=0.031, train_loss_epoch=0.0393] Epoch 248: Train Loss = 0.030987845733761787\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0331, train_loss_epoch=0.031]Epoch 249: Train Loss = 0.03309649974107742\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0331, train_loss_epoch=0.0331]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=222, train_loss_step=0.0331, train_loss_epoch=0.0331]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 19: from 1998-11-02 00:00:00 to 2022-06-24 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.400]Epoch 0: Train Loss = 0.4000101387500763\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.500, train_loss_epoch=0.400]Epoch 1: Train Loss = 0.49965277314186096\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.370, train_loss_epoch=0.500]Epoch 2: Train Loss = 0.36998245120048523\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.251, train_loss_epoch=0.370]Epoch 3: Train Loss = 0.25069907307624817\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.301, train_loss_epoch=0.251]Epoch 4: Train Loss = 0.3012503385543823\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.303, train_loss_epoch=0.301]Epoch 5: Train Loss = 0.3028479218482971\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.250, train_loss_epoch=0.303]Epoch 6: Train Loss = 0.250171035528183\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.244, train_loss_epoch=0.250]Epoch 7: Train Loss = 0.24421270191669464\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.267, train_loss_epoch=0.244]Epoch 8: Train Loss = 0.266613632440567\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.254, train_loss_epoch=0.267]Epoch 9: Train Loss = 0.25443440675735474\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.240, train_loss_epoch=0.254]Epoch 10: Train Loss = 0.24026130139827728\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.221, train_loss_epoch=0.240]Epoch 11: Train Loss = 0.2206202894449234\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.237, train_loss_epoch=0.221]Epoch 12: Train Loss = 0.23696064949035645\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.217, train_loss_epoch=0.237]Epoch 13: Train Loss = 0.21741701662540436\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.206, train_loss_epoch=0.217]Epoch 14: Train Loss = 0.20635373890399933\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.188, train_loss_epoch=0.206]Epoch 15: Train Loss = 0.18846775591373444\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.199, train_loss_epoch=0.188]Epoch 16: Train Loss = 0.19874003529548645\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.189, train_loss_epoch=0.199]Epoch 17: Train Loss = 0.18852804601192474\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.190, train_loss_epoch=0.189]Epoch 18: Train Loss = 0.1904919445514679\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.170, train_loss_epoch=0.190]Epoch 19: Train Loss = 0.1704578697681427\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.167, train_loss_epoch=0.170]Epoch 20: Train Loss = 0.1670757383108139\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.179, train_loss_epoch=0.167]Epoch 21: Train Loss = 0.17904172837734222\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.172, train_loss_epoch=0.179]Epoch 22: Train Loss = 0.1723117232322693\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.160, train_loss_epoch=0.172]Epoch 23: Train Loss = 0.160161092877388\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.159, train_loss_epoch=0.160]Epoch 24: Train Loss = 0.15909729897975922\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.160, train_loss_epoch=0.159]Epoch 25: Train Loss = 0.1598864644765854\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.159, train_loss_epoch=0.160]Epoch 26: Train Loss = 0.1585659235715866\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.147, train_loss_epoch=0.159]Epoch 27: Train Loss = 0.14734525978565216\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.143, train_loss_epoch=0.147]Epoch 28: Train Loss = 0.14301732182502747\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.149, train_loss_epoch=0.143]Epoch 29: Train Loss = 0.14928174018859863\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.141, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.1413930207490921\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.139, train_loss_epoch=0.141]Epoch 31: Train Loss = 0.1386902630329132\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.137, train_loss_epoch=0.139]Epoch 32: Train Loss = 0.1366192251443863\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.134, train_loss_epoch=0.137]Epoch 33: Train Loss = 0.1342797577381134\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.132, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.1323678344488144\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.127, train_loss_epoch=0.132]Epoch 35: Train Loss = 0.1267063319683075\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.128, train_loss_epoch=0.127]Epoch 36: Train Loss = 0.12816403806209564\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.127, train_loss_epoch=0.128]Epoch 37: Train Loss = 0.12670107185840607\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.121, train_loss_epoch=0.127]Epoch 38: Train Loss = 0.1209956482052803\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.117, train_loss_epoch=0.121]Epoch 39: Train Loss = 0.1165347620844841\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.115, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11524679511785507\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.116, train_loss_epoch=0.115]Epoch 41: Train Loss = 0.11632116138935089\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.111, train_loss_epoch=0.116]Epoch 42: Train Loss = 0.11084349453449249\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.106, train_loss_epoch=0.111]Epoch 43: Train Loss = 0.10600198060274124\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.112, train_loss_epoch=0.106]Epoch 44: Train Loss = 0.11201172322034836\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.105, train_loss_epoch=0.112]Epoch 45: Train Loss = 0.10538289695978165\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.104, train_loss_epoch=0.105]Epoch 46: Train Loss = 0.104214608669281\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.100, train_loss_epoch=0.104]Epoch 47: Train Loss = 0.1002860963344574\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0994, train_loss_epoch=0.100]Epoch 48: Train Loss = 0.0993584543466568\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0989, train_loss_epoch=0.0994]Epoch 49: Train Loss = 0.09885720163583755\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0967, train_loss_epoch=0.0989]Epoch 50: Train Loss = 0.0967358648777008\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.095, train_loss_epoch=0.0967] Epoch 51: Train Loss = 0.09504766762256622\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0943, train_loss_epoch=0.095]Epoch 52: Train Loss = 0.09432124346494675\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0906, train_loss_epoch=0.0943]Epoch 53: Train Loss = 0.09056578576564789\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0909, train_loss_epoch=0.0906]Epoch 54: Train Loss = 0.09094872325658798\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0898, train_loss_epoch=0.0909]Epoch 55: Train Loss = 0.0898372232913971\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0875, train_loss_epoch=0.0898]Epoch 56: Train Loss = 0.08752884715795517\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0863, train_loss_epoch=0.0875]Epoch 57: Train Loss = 0.0862857848405838\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0848, train_loss_epoch=0.0863]Epoch 58: Train Loss = 0.08479935675859451\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0841, train_loss_epoch=0.0848]Epoch 59: Train Loss = 0.0841212272644043\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0822, train_loss_epoch=0.0841]Epoch 60: Train Loss = 0.08221054077148438\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.080, train_loss_epoch=0.0822] Epoch 61: Train Loss = 0.07996150851249695\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0817, train_loss_epoch=0.080]Epoch 62: Train Loss = 0.08174411952495575\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0772, train_loss_epoch=0.0817]Epoch 63: Train Loss = 0.07720781862735748\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0764, train_loss_epoch=0.0772]Epoch 64: Train Loss = 0.07643119245767593\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0758, train_loss_epoch=0.0764]Epoch 65: Train Loss = 0.07581266760826111\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0762, train_loss_epoch=0.0758]Epoch 66: Train Loss = 0.07624205946922302\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0749, train_loss_epoch=0.0762]Epoch 67: Train Loss = 0.07493219524621964\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0756, train_loss_epoch=0.0749]Epoch 68: Train Loss = 0.07560571283102036\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.070, train_loss_epoch=0.0756] Epoch 69: Train Loss = 0.06995033472776413\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0714, train_loss_epoch=0.070]Epoch 70: Train Loss = 0.07141042500734329\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0681, train_loss_epoch=0.0714]Epoch 71: Train Loss = 0.06810811907052994\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0674, train_loss_epoch=0.0681]Epoch 72: Train Loss = 0.06738058477640152\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0673, train_loss_epoch=0.0674]Epoch 73: Train Loss = 0.0673312321305275\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0676, train_loss_epoch=0.0673]Epoch 74: Train Loss = 0.06762293726205826\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0663, train_loss_epoch=0.0676]Epoch 75: Train Loss = 0.06629226356744766\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0646, train_loss_epoch=0.0663]Epoch 76: Train Loss = 0.06462138891220093\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0645, train_loss_epoch=0.0646]Epoch 77: Train Loss = 0.06445272266864777\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0638, train_loss_epoch=0.0645]Epoch 78: Train Loss = 0.06377686560153961\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0627, train_loss_epoch=0.0638]Epoch 79: Train Loss = 0.06269747763872147\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0629, train_loss_epoch=0.0627]Epoch 80: Train Loss = 0.06289152055978775\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0635, train_loss_epoch=0.0629]Epoch 81: Train Loss = 0.06354089081287384\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0618, train_loss_epoch=0.0635]Epoch 82: Train Loss = 0.061778273433446884\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0601, train_loss_epoch=0.0618]Epoch 83: Train Loss = 0.06009182706475258\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0598, train_loss_epoch=0.0601]Epoch 84: Train Loss = 0.05976119264960289\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0604, train_loss_epoch=0.0598]Epoch 85: Train Loss = 0.060441505163908005\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0578, train_loss_epoch=0.0604]Epoch 86: Train Loss = 0.057809825986623764\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0596, train_loss_epoch=0.0578]Epoch 87: Train Loss = 0.05956243723630905\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0572, train_loss_epoch=0.0596]Epoch 88: Train Loss = 0.057189371436834335\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0576, train_loss_epoch=0.0572]Epoch 89: Train Loss = 0.05761077255010605\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0571, train_loss_epoch=0.0576]Epoch 90: Train Loss = 0.057069942355155945\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0551, train_loss_epoch=0.0571]Epoch 91: Train Loss = 0.055104468017816544\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0559, train_loss_epoch=0.0551]Epoch 92: Train Loss = 0.05589919537305832\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0568, train_loss_epoch=0.0559]Epoch 93: Train Loss = 0.05678500980138779\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0536, train_loss_epoch=0.0568]Epoch 94: Train Loss = 0.05360741913318634\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0591, train_loss_epoch=0.0536]Epoch 95: Train Loss = 0.05908617377281189\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0534, train_loss_epoch=0.0591]Epoch 96: Train Loss = 0.053422123193740845\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0591, train_loss_epoch=0.0534]Epoch 97: Train Loss = 0.059130147099494934\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0515, train_loss_epoch=0.0591]Epoch 98: Train Loss = 0.05152403935790062\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0531, train_loss_epoch=0.0515]Epoch 99: Train Loss = 0.05305806174874306\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0505, train_loss_epoch=0.0531]Epoch 100: Train Loss = 0.050542332231998444\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0541, train_loss_epoch=0.0505]Epoch 101: Train Loss = 0.05408427491784096\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0487, train_loss_epoch=0.0541]Epoch 102: Train Loss = 0.04868892952799797\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0514, train_loss_epoch=0.0487]Epoch 103: Train Loss = 0.05142762139439583\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0505, train_loss_epoch=0.0514]Epoch 104: Train Loss = 0.05045020207762718\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0518, train_loss_epoch=0.0505]Epoch 105: Train Loss = 0.05177465081214905\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0493, train_loss_epoch=0.0518]Epoch 106: Train Loss = 0.04927082732319832\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0487, train_loss_epoch=0.0493]Epoch 107: Train Loss = 0.04870135337114334\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0494, train_loss_epoch=0.0487]Epoch 108: Train Loss = 0.04936137795448303\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0525, train_loss_epoch=0.0494]Epoch 109: Train Loss = 0.05252420902252197\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0467, train_loss_epoch=0.0525]Epoch 110: Train Loss = 0.04665859043598175\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0491, train_loss_epoch=0.0467]Epoch 111: Train Loss = 0.04905698448419571\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0471, train_loss_epoch=0.0491]Epoch 112: Train Loss = 0.04711895436048508\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0458, train_loss_epoch=0.0471]Epoch 113: Train Loss = 0.04577069729566574\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0524, train_loss_epoch=0.0458]Epoch 114: Train Loss = 0.05243057757616043\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0466, train_loss_epoch=0.0524]Epoch 115: Train Loss = 0.04656621813774109\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0505, train_loss_epoch=0.0466]Epoch 116: Train Loss = 0.05052490159869194\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0455, train_loss_epoch=0.0505]Epoch 117: Train Loss = 0.04549521952867508\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.049, train_loss_epoch=0.0455] Epoch 118: Train Loss = 0.04903059080243111\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.045, train_loss_epoch=0.049] Epoch 119: Train Loss = 0.04495774582028389\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0466, train_loss_epoch=0.045]Epoch 120: Train Loss = 0.04660338908433914\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0457, train_loss_epoch=0.0466]Epoch 121: Train Loss = 0.045748911798000336\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0461, train_loss_epoch=0.0457]Epoch 122: Train Loss = 0.0460633747279644\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0457, train_loss_epoch=0.0461]Epoch 123: Train Loss = 0.0457305833697319\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0447, train_loss_epoch=0.0457]Epoch 124: Train Loss = 0.04468485340476036\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.045, train_loss_epoch=0.0447] Epoch 125: Train Loss = 0.04499829187989235\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0441, train_loss_epoch=0.045]Epoch 126: Train Loss = 0.044087667018175125\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0444, train_loss_epoch=0.0441]Epoch 127: Train Loss = 0.044353365898132324\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0424, train_loss_epoch=0.0444]Epoch 128: Train Loss = 0.04244087263941765\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0447, train_loss_epoch=0.0424]Epoch 129: Train Loss = 0.04471373185515404\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0407, train_loss_epoch=0.0447]Epoch 130: Train Loss = 0.04069412127137184\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0446, train_loss_epoch=0.0407]Epoch 131: Train Loss = 0.044580429792404175\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0417, train_loss_epoch=0.0446]Epoch 132: Train Loss = 0.04172639176249504\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0426, train_loss_epoch=0.0417]Epoch 133: Train Loss = 0.042601339519023895\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0408, train_loss_epoch=0.0426]Epoch 134: Train Loss = 0.040772370994091034\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0418, train_loss_epoch=0.0408]Epoch 135: Train Loss = 0.04176422581076622\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0403, train_loss_epoch=0.0418]Epoch 136: Train Loss = 0.040266770869493484\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.040, train_loss_epoch=0.0403] Epoch 137: Train Loss = 0.0399634912610054\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0408, train_loss_epoch=0.040]Epoch 138: Train Loss = 0.040758613497018814\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0413, train_loss_epoch=0.0408]Epoch 139: Train Loss = 0.04130275547504425\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0429, train_loss_epoch=0.0413]Epoch 140: Train Loss = 0.04290056601166725\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0391, train_loss_epoch=0.0429]Epoch 141: Train Loss = 0.03913191333413124\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0419, train_loss_epoch=0.0391]Epoch 142: Train Loss = 0.04193354398012161\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0409, train_loss_epoch=0.0419]Epoch 143: Train Loss = 0.040875013917684555\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0401, train_loss_epoch=0.0409]Epoch 144: Train Loss = 0.0401388555765152\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0399, train_loss_epoch=0.0401]Epoch 145: Train Loss = 0.039906442165374756\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0397, train_loss_epoch=0.0399]Epoch 146: Train Loss = 0.039666127413511276\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0405, train_loss_epoch=0.0397]Epoch 147: Train Loss = 0.040538083761930466\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0378, train_loss_epoch=0.0405]Epoch 148: Train Loss = 0.03780122846364975\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0406, train_loss_epoch=0.0378]Epoch 149: Train Loss = 0.04061880707740784\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0416, train_loss_epoch=0.0406]Epoch 150: Train Loss = 0.0415944866836071\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0382, train_loss_epoch=0.0416]Epoch 151: Train Loss = 0.03815404698252678\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0379, train_loss_epoch=0.0382]Epoch 152: Train Loss = 0.03787962347269058\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0374, train_loss_epoch=0.0379]Epoch 153: Train Loss = 0.03743389993906021\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0374, train_loss_epoch=0.0374]Epoch 154: Train Loss = 0.03743545338511467\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0377, train_loss_epoch=0.0374]Epoch 155: Train Loss = 0.03770679235458374\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0385, train_loss_epoch=0.0377]Epoch 156: Train Loss = 0.03845179080963135\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0385, train_loss_epoch=0.0385]Epoch 157: Train Loss = 0.038470588624477386\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0381, train_loss_epoch=0.0385]Epoch 158: Train Loss = 0.038054466247558594\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0371, train_loss_epoch=0.0381]Epoch 159: Train Loss = 0.0371209979057312\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0376, train_loss_epoch=0.0371]Epoch 160: Train Loss = 0.03756782412528992\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0378, train_loss_epoch=0.0376]Epoch 161: Train Loss = 0.03778921440243721\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0364, train_loss_epoch=0.0378]Epoch 162: Train Loss = 0.03639135882258415\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0364, train_loss_epoch=0.0364]Epoch 163: Train Loss = 0.036389224231243134\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0361, train_loss_epoch=0.0364]Epoch 164: Train Loss = 0.036134399473667145\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0363, train_loss_epoch=0.0361]Epoch 165: Train Loss = 0.036271754652261734\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0351, train_loss_epoch=0.0363]Epoch 166: Train Loss = 0.03509658947587013\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0354, train_loss_epoch=0.0351]Epoch 167: Train Loss = 0.03541883826255798\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0358, train_loss_epoch=0.0354]Epoch 168: Train Loss = 0.03576722368597984\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0358, train_loss_epoch=0.0358]Epoch 169: Train Loss = 0.03576713055372238\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.036, train_loss_epoch=0.0358] Epoch 170: Train Loss = 0.036017291247844696\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0352, train_loss_epoch=0.036]Epoch 171: Train Loss = 0.035244815051555634\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0348, train_loss_epoch=0.0352]Epoch 172: Train Loss = 0.034836895763874054\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.035, train_loss_epoch=0.0348] Epoch 173: Train Loss = 0.035023536533117294\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0364, train_loss_epoch=0.035]Epoch 174: Train Loss = 0.03640807420015335\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0365, train_loss_epoch=0.0364]Epoch 175: Train Loss = 0.03649824857711792\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0371, train_loss_epoch=0.0365]Epoch 176: Train Loss = 0.037055712193250656\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0345, train_loss_epoch=0.0371]Epoch 177: Train Loss = 0.03452198952436447\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0348, train_loss_epoch=0.0345]Epoch 178: Train Loss = 0.034849073737859726\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0384, train_loss_epoch=0.0348]Epoch 179: Train Loss = 0.03838583081960678\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0343, train_loss_epoch=0.0384]Epoch 180: Train Loss = 0.03431875258684158\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0442, train_loss_epoch=0.0343]Epoch 181: Train Loss = 0.044153161346912384\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0347, train_loss_epoch=0.0442]Epoch 182: Train Loss = 0.03471516817808151\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0424, train_loss_epoch=0.0347]Epoch 183: Train Loss = 0.042434174567461014\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0343, train_loss_epoch=0.0424]Epoch 184: Train Loss = 0.03426208347082138\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0368, train_loss_epoch=0.0343]Epoch 185: Train Loss = 0.036820802837610245\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0342, train_loss_epoch=0.0368]Epoch 186: Train Loss = 0.03419336676597595\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0356, train_loss_epoch=0.0342]Epoch 187: Train Loss = 0.03556966036558151\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.034, train_loss_epoch=0.0356] Epoch 188: Train Loss = 0.033995818346738815\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0352, train_loss_epoch=0.034]Epoch 189: Train Loss = 0.03515639528632164\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0355, train_loss_epoch=0.0352]Epoch 190: Train Loss = 0.035502899438142776\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.037, train_loss_epoch=0.0355] Epoch 191: Train Loss = 0.03699208050966263\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0416, train_loss_epoch=0.037]Epoch 192: Train Loss = 0.041619762778282166\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0416, train_loss_epoch=0.0416]Epoch 193: Train Loss = 0.041618313640356064\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0399, train_loss_epoch=0.0416]Epoch 194: Train Loss = 0.03985919430851936\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0344, train_loss_epoch=0.0399]Epoch 195: Train Loss = 0.03436020389199257\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0468, train_loss_epoch=0.0344]Epoch 196: Train Loss = 0.04676342383027077\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0331, train_loss_epoch=0.0468]Epoch 197: Train Loss = 0.033110640943050385\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0461, train_loss_epoch=0.0331]Epoch 198: Train Loss = 0.046057771891355515\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.041, train_loss_epoch=0.0461] Epoch 199: Train Loss = 0.041023943573236465\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0488, train_loss_epoch=0.041]Epoch 200: Train Loss = 0.04876708984375\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0415, train_loss_epoch=0.0488]Epoch 201: Train Loss = 0.041487060487270355\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0346, train_loss_epoch=0.0415]Epoch 202: Train Loss = 0.03460655361413956\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0432, train_loss_epoch=0.0346]Epoch 203: Train Loss = 0.04324125498533249\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0347, train_loss_epoch=0.0432]Epoch 204: Train Loss = 0.03469132259488106\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0439, train_loss_epoch=0.0347]Epoch 205: Train Loss = 0.04394438862800598\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.038, train_loss_epoch=0.0439] Epoch 206: Train Loss = 0.03804020211100578\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0343, train_loss_epoch=0.038]Epoch 207: Train Loss = 0.034327514469623566\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0381, train_loss_epoch=0.0343]Epoch 208: Train Loss = 0.038083259016275406\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0321, train_loss_epoch=0.0381]Epoch 209: Train Loss = 0.032052766531705856\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0365, train_loss_epoch=0.0321]Epoch 210: Train Loss = 0.036483075469732285\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0357, train_loss_epoch=0.0365]Epoch 211: Train Loss = 0.035695139318704605\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0323, train_loss_epoch=0.0357]Epoch 212: Train Loss = 0.032301876693964005\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0355, train_loss_epoch=0.0323]Epoch 213: Train Loss = 0.03546278178691864\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0336, train_loss_epoch=0.0355]Epoch 214: Train Loss = 0.0336424857378006\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.0345, train_loss_epoch=0.0336]Epoch 215: Train Loss = 0.03452490642666817\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0429, train_loss_epoch=0.0345]Epoch 216: Train Loss = 0.04286270588636398\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0322, train_loss_epoch=0.0429]Epoch 217: Train Loss = 0.0322280116379261\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0375, train_loss_epoch=0.0322]Epoch 218: Train Loss = 0.03749959170818329\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.034, train_loss_epoch=0.0375] Epoch 219: Train Loss = 0.03399711102247238\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0339, train_loss_epoch=0.034]Epoch 220: Train Loss = 0.033937256783246994\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0359, train_loss_epoch=0.0339]Epoch 221: Train Loss = 0.03586813807487488\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0324, train_loss_epoch=0.0359]Epoch 222: Train Loss = 0.032437391579151154\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0342, train_loss_epoch=0.0324]Epoch 223: Train Loss = 0.03419305384159088\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0339, train_loss_epoch=0.0342]Epoch 224: Train Loss = 0.03388500586152077\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.034, train_loss_epoch=0.0339] Epoch 225: Train Loss = 0.03402899578213692\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0358, train_loss_epoch=0.034]Epoch 226: Train Loss = 0.035804521292448044\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0315, train_loss_epoch=0.0358]Epoch 227: Train Loss = 0.03151961416006088\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0335, train_loss_epoch=0.0315]Epoch 228: Train Loss = 0.03354715183377266\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0321, train_loss_epoch=0.0335]Epoch 229: Train Loss = 0.032115403562784195\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0316, train_loss_epoch=0.0321]Epoch 230: Train Loss = 0.03157257288694382\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0314, train_loss_epoch=0.0316]Epoch 231: Train Loss = 0.03140968084335327\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.031, train_loss_epoch=0.0314] Epoch 232: Train Loss = 0.030974315479397774\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=224, train_loss_step=0.037, train_loss_epoch=0.031] Epoch 233: Train Loss = 0.037003304809331894\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0315, train_loss_epoch=0.037]Epoch 234: Train Loss = 0.031537603586912155\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0338, train_loss_epoch=0.0315]Epoch 235: Train Loss = 0.03384493663907051\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0327, train_loss_epoch=0.0338]Epoch 236: Train Loss = 0.03273081034421921\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0303, train_loss_epoch=0.0327]Epoch 237: Train Loss = 0.03031242825090885\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0326, train_loss_epoch=0.0303]Epoch 238: Train Loss = 0.03262362256646156\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0302, train_loss_epoch=0.0326]Epoch 239: Train Loss = 0.030202437192201614\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0311, train_loss_epoch=0.0302]Epoch 240: Train Loss = 0.031101176515221596\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0313, train_loss_epoch=0.0311]Epoch 241: Train Loss = 0.03126412257552147\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0299, train_loss_epoch=0.0313]Epoch 242: Train Loss = 0.02986326813697815\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0303, train_loss_epoch=0.0299]Epoch 243: Train Loss = 0.03031991794705391\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0366, train_loss_epoch=0.0303]Epoch 244: Train Loss = 0.03659174218773842\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.0318, train_loss_epoch=0.0366]Epoch 245: Train Loss = 0.03176211565732956\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0391, train_loss_epoch=0.0318]Epoch 246: Train Loss = 0.03909790515899658\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0348, train_loss_epoch=0.0391]Epoch 247: Train Loss = 0.03478815406560898\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=224, train_loss_step=0.0302, train_loss_epoch=0.0348]Epoch 248: Train Loss = 0.03024926409125328\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.044, train_loss_epoch=0.0302] Epoch 249: Train Loss = 0.04396628588438034\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.044, train_loss_epoch=0.044] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=224, train_loss_step=0.044, train_loss_epoch=0.044]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 20: from 1998-11-02 00:00:00 to 2022-07-05 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.402]Epoch 0: Train Loss = 0.40219831466674805\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.497, train_loss_epoch=0.402]Epoch 1: Train Loss = 0.4969358444213867\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.372, train_loss_epoch=0.497]Epoch 2: Train Loss = 0.37224724888801575\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.250, train_loss_epoch=0.372]Epoch 3: Train Loss = 0.2501959502696991\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.310, train_loss_epoch=0.250]Epoch 4: Train Loss = 0.3104080557823181\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.312, train_loss_epoch=0.310]Epoch 5: Train Loss = 0.31194868683815\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.257, train_loss_epoch=0.312]Epoch 6: Train Loss = 0.2573414742946625\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.242, train_loss_epoch=0.257]Epoch 7: Train Loss = 0.2416577935218811\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.272, train_loss_epoch=0.242]Epoch 8: Train Loss = 0.2717646658420563\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.264, train_loss_epoch=0.272]Epoch 9: Train Loss = 0.264461487531662\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.245, train_loss_epoch=0.264]Epoch 10: Train Loss = 0.2450093924999237\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.220, train_loss_epoch=0.245]Epoch 11: Train Loss = 0.2198382467031479\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.236, train_loss_epoch=0.220]Epoch 12: Train Loss = 0.2363685518503189\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.223, train_loss_epoch=0.236]Epoch 13: Train Loss = 0.22311362624168396\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.214, train_loss_epoch=0.223]Epoch 14: Train Loss = 0.21355299651622772\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.190, train_loss_epoch=0.214]Epoch 15: Train Loss = 0.19040295481681824\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.201, train_loss_epoch=0.190]Epoch 16: Train Loss = 0.20109757781028748\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.190, train_loss_epoch=0.201]Epoch 17: Train Loss = 0.19018076360225677\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.196, train_loss_epoch=0.190]Epoch 18: Train Loss = 0.19564692676067352\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.175, train_loss_epoch=0.196]Epoch 19: Train Loss = 0.17466433346271515\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.165, train_loss_epoch=0.175]Epoch 20: Train Loss = 0.16536279022693634\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.179, train_loss_epoch=0.165]Epoch 21: Train Loss = 0.1793145388364792\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.178, train_loss_epoch=0.179]Epoch 22: Train Loss = 0.17818216979503632\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.166, train_loss_epoch=0.178]Epoch 23: Train Loss = 0.1657683104276657\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.158, train_loss_epoch=0.166]Epoch 24: Train Loss = 0.1576528251171112\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.156, train_loss_epoch=0.158]Epoch 25: Train Loss = 0.15600843727588654\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.162, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.16211876273155212\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.153, train_loss_epoch=0.162]Epoch 27: Train Loss = 0.15317389369010925\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.146, train_loss_epoch=0.153]Epoch 28: Train Loss = 0.14574642479419708\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.150, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.15002597868442535\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.143, train_loss_epoch=0.150]Epoch 30: Train Loss = 0.14316511154174805\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.143, train_loss_epoch=0.143]Epoch 31: Train Loss = 0.14345650374889374\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.141, train_loss_epoch=0.143]Epoch 32: Train Loss = 0.14051710069179535\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.135, train_loss_epoch=0.141]Epoch 33: Train Loss = 0.1350567787885666\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.135, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13482454419136047\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.132, train_loss_epoch=0.135]Epoch 35: Train Loss = 0.13206617534160614\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.129, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.12942403554916382\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.128, train_loss_epoch=0.129]Epoch 37: Train Loss = 0.12813159823417664\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.123, train_loss_epoch=0.128]Epoch 38: Train Loss = 0.12310239672660828\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.119, train_loss_epoch=0.123]Epoch 39: Train Loss = 0.11888417601585388\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.116, train_loss_epoch=0.119]Epoch 40: Train Loss = 0.11612503975629807\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.119, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11936943233013153\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.115, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.1151910126209259\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.110, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.11038654297590256\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.113, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11322076618671417\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.107, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10721307247877121\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.105, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10513900220394135\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.102, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10248057544231415\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.102, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.10248102247714996\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.102, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.1020263284444809\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.100, train_loss_epoch=0.102]Epoch 50: Train Loss = 0.10047417134046555\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0969, train_loss_epoch=0.100]Epoch 51: Train Loss = 0.09686668962240219\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0967, train_loss_epoch=0.0969]Epoch 52: Train Loss = 0.09669121354818344\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0934, train_loss_epoch=0.0967]Epoch 53: Train Loss = 0.09339098632335663\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0929, train_loss_epoch=0.0934]Epoch 54: Train Loss = 0.09290345013141632\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0925, train_loss_epoch=0.0929]Epoch 55: Train Loss = 0.09254252165555954\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0891, train_loss_epoch=0.0925]Epoch 56: Train Loss = 0.0890912190079689\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0874, train_loss_epoch=0.0891]Epoch 57: Train Loss = 0.08743463456630707\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0879, train_loss_epoch=0.0874]Epoch 58: Train Loss = 0.08794053643941879\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0849, train_loss_epoch=0.0879]Epoch 59: Train Loss = 0.08493626117706299\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0855, train_loss_epoch=0.0849]Epoch 60: Train Loss = 0.08551152795553207\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.081, train_loss_epoch=0.0855] Epoch 61: Train Loss = 0.08095645904541016\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=226, train_loss_step=0.080, train_loss_epoch=0.081] Epoch 62: Train Loss = 0.07995323836803436\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0791, train_loss_epoch=0.080]Epoch 63: Train Loss = 0.07910551875829697\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0772, train_loss_epoch=0.0791]Epoch 64: Train Loss = 0.07719278335571289\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0782, train_loss_epoch=0.0772]Epoch 65: Train Loss = 0.07818874716758728\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0762, train_loss_epoch=0.0782]Epoch 66: Train Loss = 0.07615192234516144\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0771, train_loss_epoch=0.0762]Epoch 67: Train Loss = 0.07705269753932953\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0727, train_loss_epoch=0.0771]Epoch 68: Train Loss = 0.0726516917347908\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0715, train_loss_epoch=0.0727]Epoch 69: Train Loss = 0.07146663218736649\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.073, train_loss_epoch=0.0715] Epoch 70: Train Loss = 0.07299637794494629\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0705, train_loss_epoch=0.073]Epoch 71: Train Loss = 0.07052932679653168\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0702, train_loss_epoch=0.0705]Epoch 72: Train Loss = 0.07022412866353989\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0682, train_loss_epoch=0.0702]Epoch 73: Train Loss = 0.06819625198841095\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.072, train_loss_epoch=0.0682] Epoch 74: Train Loss = 0.07199423760175705\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0666, train_loss_epoch=0.072]Epoch 75: Train Loss = 0.06659216433763504\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0693, train_loss_epoch=0.0666]Epoch 76: Train Loss = 0.06929226964712143\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0655, train_loss_epoch=0.0693]Epoch 77: Train Loss = 0.06550724059343338\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0701, train_loss_epoch=0.0655]Epoch 78: Train Loss = 0.07010743767023087\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0617, train_loss_epoch=0.0701]Epoch 79: Train Loss = 0.06173766404390335\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0696, train_loss_epoch=0.0617]Epoch 80: Train Loss = 0.06959544867277145\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0622, train_loss_epoch=0.0696]Epoch 81: Train Loss = 0.06219640001654625\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0629, train_loss_epoch=0.0622]Epoch 82: Train Loss = 0.06291121989488602\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=226, train_loss_step=0.0624, train_loss_epoch=0.0629]Epoch 83: Train Loss = 0.0624217689037323\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0624, train_loss_epoch=0.0624]Epoch 84: Train Loss = 0.062415044754743576\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0623, train_loss_epoch=0.0624]Epoch 85: Train Loss = 0.062305014580488205\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0638, train_loss_epoch=0.0623]Epoch 86: Train Loss = 0.0637773871421814\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0614, train_loss_epoch=0.0638]Epoch 87: Train Loss = 0.061447981745004654\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0605, train_loss_epoch=0.0614]Epoch 88: Train Loss = 0.060541171580553055\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0602, train_loss_epoch=0.0605]Epoch 89: Train Loss = 0.06015092879533768\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0579, train_loss_epoch=0.0602]Epoch 90: Train Loss = 0.0578734464943409\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.059, train_loss_epoch=0.0579] Epoch 91: Train Loss = 0.0589987076818943\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.057, train_loss_epoch=0.059] Epoch 92: Train Loss = 0.05699678510427475\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0563, train_loss_epoch=0.057]Epoch 93: Train Loss = 0.056300509721040726\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0555, train_loss_epoch=0.0563]Epoch 94: Train Loss = 0.0555058978497982\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.054, train_loss_epoch=0.0555] Epoch 95: Train Loss = 0.05395885556936264\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.055, train_loss_epoch=0.054] Epoch 96: Train Loss = 0.0549996979534626\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0545, train_loss_epoch=0.055]Epoch 97: Train Loss = 0.05450846254825592\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0543, train_loss_epoch=0.0545]Epoch 98: Train Loss = 0.05425390228629112\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0542, train_loss_epoch=0.0543]Epoch 99: Train Loss = 0.05420192703604698\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0531, train_loss_epoch=0.0542]Epoch 100: Train Loss = 0.053131166845560074\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0522, train_loss_epoch=0.0531]Epoch 101: Train Loss = 0.052233289927244186\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=226, train_loss_step=0.0507, train_loss_epoch=0.0522]Epoch 102: Train Loss = 0.05073966458439827\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.049, train_loss_epoch=0.0507] Epoch 103: Train Loss = 0.04898108169436455\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=226, train_loss_step=0.0493, train_loss_epoch=0.049]Epoch 104: Train Loss = 0.049330949783325195\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0501, train_loss_epoch=0.0493]Epoch 105: Train Loss = 0.05008196830749512\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0493, train_loss_epoch=0.0501]Epoch 106: Train Loss = 0.04930686950683594\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0496, train_loss_epoch=0.0493]Epoch 107: Train Loss = 0.04962702468037605\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0513, train_loss_epoch=0.0496]Epoch 108: Train Loss = 0.051259446889162064\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0488, train_loss_epoch=0.0513]Epoch 109: Train Loss = 0.048813190311193466\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0525, train_loss_epoch=0.0488]Epoch 110: Train Loss = 0.0524793416261673\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0487, train_loss_epoch=0.0525]Epoch 111: Train Loss = 0.04870399832725525\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0475, train_loss_epoch=0.0487]Epoch 112: Train Loss = 0.04749380052089691\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0484, train_loss_epoch=0.0475]Epoch 113: Train Loss = 0.04840933158993721\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0506, train_loss_epoch=0.0484]Epoch 114: Train Loss = 0.0506497286260128\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0471, train_loss_epoch=0.0506]Epoch 115: Train Loss = 0.04713552072644234\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0481, train_loss_epoch=0.0471]Epoch 116: Train Loss = 0.04808466508984566\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0467, train_loss_epoch=0.0481]Epoch 117: Train Loss = 0.0467405691742897\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0491, train_loss_epoch=0.0467]Epoch 118: Train Loss = 0.049129292368888855\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0455, train_loss_epoch=0.0491]Epoch 119: Train Loss = 0.045485615730285645\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0468, train_loss_epoch=0.0455]Epoch 120: Train Loss = 0.04680614173412323\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0455, train_loss_epoch=0.0468]Epoch 121: Train Loss = 0.04551747068762779\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=226, train_loss_step=0.0509, train_loss_epoch=0.0455]Epoch 122: Train Loss = 0.050905000418424606\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0449, train_loss_epoch=0.0509]Epoch 123: Train Loss = 0.04485433176159859\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0453, train_loss_epoch=0.0449]Epoch 124: Train Loss = 0.04530445113778114\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0437, train_loss_epoch=0.0453]Epoch 125: Train Loss = 0.043740611523389816\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0468, train_loss_epoch=0.0437]Epoch 126: Train Loss = 0.04678153991699219\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0438, train_loss_epoch=0.0468]Epoch 127: Train Loss = 0.04384513571858406\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0478, train_loss_epoch=0.0438]Epoch 128: Train Loss = 0.04775001481175423\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0429, train_loss_epoch=0.0478]Epoch 129: Train Loss = 0.04287251457571983\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0447, train_loss_epoch=0.0429]Epoch 130: Train Loss = 0.04474402964115143\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0423, train_loss_epoch=0.0447]Epoch 131: Train Loss = 0.042345475405454636\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.042, train_loss_epoch=0.0423] Epoch 132: Train Loss = 0.04202217608690262\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0432, train_loss_epoch=0.042]Epoch 133: Train Loss = 0.04322464019060135\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0421, train_loss_epoch=0.0432]Epoch 134: Train Loss = 0.042100731283426285\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.043, train_loss_epoch=0.0421] Epoch 135: Train Loss = 0.04298079386353493\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0421, train_loss_epoch=0.043]Epoch 136: Train Loss = 0.042069319635629654\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0417, train_loss_epoch=0.0421]Epoch 137: Train Loss = 0.041708867996931076\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0419, train_loss_epoch=0.0417]Epoch 138: Train Loss = 0.04194452986121178\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0414, train_loss_epoch=0.0419]Epoch 139: Train Loss = 0.04141651839017868\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0404, train_loss_epoch=0.0414]Epoch 140: Train Loss = 0.04041149094700813\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0405, train_loss_epoch=0.0404]Epoch 141: Train Loss = 0.04052145034074783\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0406, train_loss_epoch=0.0405]Epoch 142: Train Loss = 0.04061669111251831\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0417, train_loss_epoch=0.0406]Epoch 143: Train Loss = 0.0416756235063076\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0399, train_loss_epoch=0.0417]Epoch 144: Train Loss = 0.0399174764752388\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0407, train_loss_epoch=0.0399]Epoch 145: Train Loss = 0.04068217799067497\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0402, train_loss_epoch=0.0407]Epoch 146: Train Loss = 0.04020683094859123\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0392, train_loss_epoch=0.0402]Epoch 147: Train Loss = 0.039248302578926086\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0393, train_loss_epoch=0.0392]Epoch 148: Train Loss = 0.03932749480009079\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0375, train_loss_epoch=0.0393]Epoch 149: Train Loss = 0.037546444684267044\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0385, train_loss_epoch=0.0375]Epoch 150: Train Loss = 0.03846894949674606\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0389, train_loss_epoch=0.0385]Epoch 151: Train Loss = 0.03888973221182823\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0391, train_loss_epoch=0.0389]Epoch 152: Train Loss = 0.03906692564487457\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0397, train_loss_epoch=0.0391]Epoch 153: Train Loss = 0.03965499624609947\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.039, train_loss_epoch=0.0397] Epoch 154: Train Loss = 0.03898501768708229\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0412, train_loss_epoch=0.039]Epoch 155: Train Loss = 0.04121333360671997\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0391, train_loss_epoch=0.0412]Epoch 156: Train Loss = 0.03908615931868553\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.046, train_loss_epoch=0.0391] Epoch 157: Train Loss = 0.045954931527376175\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0369, train_loss_epoch=0.046]Epoch 158: Train Loss = 0.03690255805850029\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0405, train_loss_epoch=0.0369]Epoch 159: Train Loss = 0.04046096280217171\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0372, train_loss_epoch=0.0405]Epoch 160: Train Loss = 0.0372174046933651\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.040, train_loss_epoch=0.0372] Epoch 161: Train Loss = 0.040008578449487686\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0373, train_loss_epoch=0.040]Epoch 162: Train Loss = 0.037301868200302124\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0388, train_loss_epoch=0.0373]Epoch 163: Train Loss = 0.03878249600529671\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0401, train_loss_epoch=0.0388]Epoch 164: Train Loss = 0.04005271568894386\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0399, train_loss_epoch=0.0401]Epoch 165: Train Loss = 0.0399300642311573\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0356, train_loss_epoch=0.0399]Epoch 166: Train Loss = 0.03557916730642319\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0365, train_loss_epoch=0.0356]Epoch 167: Train Loss = 0.036514762789011\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0375, train_loss_epoch=0.0365]Epoch 168: Train Loss = 0.037477947771549225\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0376, train_loss_epoch=0.0375]Epoch 169: Train Loss = 0.03756556659936905\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.038, train_loss_epoch=0.0376] Epoch 170: Train Loss = 0.03796816244721413\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0372, train_loss_epoch=0.038]Epoch 171: Train Loss = 0.03716517239809036\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0363, train_loss_epoch=0.0372]Epoch 172: Train Loss = 0.036272548139095306\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0358, train_loss_epoch=0.0363]Epoch 173: Train Loss = 0.03576122969388962\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0364, train_loss_epoch=0.0358]Epoch 174: Train Loss = 0.036355774849653244\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0358, train_loss_epoch=0.0364]Epoch 175: Train Loss = 0.035796307027339935\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0362, train_loss_epoch=0.0358]Epoch 176: Train Loss = 0.03621058911085129\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0345, train_loss_epoch=0.0362]Epoch 177: Train Loss = 0.03452679514884949\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0357, train_loss_epoch=0.0345]Epoch 178: Train Loss = 0.03570619598031044\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0361, train_loss_epoch=0.0357]Epoch 179: Train Loss = 0.036103103309869766\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0364, train_loss_epoch=0.0361]Epoch 180: Train Loss = 0.03642510622739792\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0346, train_loss_epoch=0.0364]Epoch 181: Train Loss = 0.034625373780727386\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=226, train_loss_step=0.036, train_loss_epoch=0.0346] Epoch 182: Train Loss = 0.03604770451784134\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0349, train_loss_epoch=0.036]Epoch 183: Train Loss = 0.034887801855802536\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=226, train_loss_step=0.0363, train_loss_epoch=0.0349]Epoch 184: Train Loss = 0.03630102053284645\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0343, train_loss_epoch=0.0363]Epoch 185: Train Loss = 0.034306544810533524\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0366, train_loss_epoch=0.0343]Epoch 186: Train Loss = 0.03661717474460602\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0339, train_loss_epoch=0.0366]Epoch 187: Train Loss = 0.03388353809714317\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0388, train_loss_epoch=0.0339]Epoch 188: Train Loss = 0.03881422057747841\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0335, train_loss_epoch=0.0388]Epoch 189: Train Loss = 0.03349853679537773\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0375, train_loss_epoch=0.0335]Epoch 190: Train Loss = 0.03752894327044487\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0337, train_loss_epoch=0.0375]Epoch 191: Train Loss = 0.03366834297776222\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0342, train_loss_epoch=0.0337]Epoch 192: Train Loss = 0.034211862832307816\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0369, train_loss_epoch=0.0342]Epoch 193: Train Loss = 0.03694307804107666\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0384, train_loss_epoch=0.0369]Epoch 194: Train Loss = 0.03836313262581825\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0346, train_loss_epoch=0.0384]Epoch 195: Train Loss = 0.03461264446377754\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.039, train_loss_epoch=0.0346] Epoch 196: Train Loss = 0.039011042565107346\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0357, train_loss_epoch=0.039]Epoch 197: Train Loss = 0.03570186719298363\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0418, train_loss_epoch=0.0357]Epoch 198: Train Loss = 0.04180147498846054\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.038, train_loss_epoch=0.0418] Epoch 199: Train Loss = 0.0379842109978199\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0377, train_loss_epoch=0.038]Epoch 200: Train Loss = 0.037653010338544846\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0364, train_loss_epoch=0.0377]Epoch 201: Train Loss = 0.03641747683286667\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0333, train_loss_epoch=0.0364]Epoch 202: Train Loss = 0.03331763297319412\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0373, train_loss_epoch=0.0333]Epoch 203: Train Loss = 0.037264660000801086\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0333, train_loss_epoch=0.0373]Epoch 204: Train Loss = 0.03329062834382057\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0338, train_loss_epoch=0.0333]Epoch 205: Train Loss = 0.03383970633149147\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0332, train_loss_epoch=0.0338]Epoch 206: Train Loss = 0.03321424871683121\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0362, train_loss_epoch=0.0332]Epoch 207: Train Loss = 0.036239296197891235\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0319, train_loss_epoch=0.0362]Epoch 208: Train Loss = 0.03187202289700508\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0337, train_loss_epoch=0.0319]Epoch 209: Train Loss = 0.033693552017211914\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0369, train_loss_epoch=0.0337]Epoch 210: Train Loss = 0.03687470778822899\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0337, train_loss_epoch=0.0369]Epoch 211: Train Loss = 0.03371915966272354\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0324, train_loss_epoch=0.0337]Epoch 212: Train Loss = 0.032437607645988464\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0321, train_loss_epoch=0.0324]Epoch 213: Train Loss = 0.03209150582551956\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0323, train_loss_epoch=0.0321]Epoch 214: Train Loss = 0.03233636915683746\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0328, train_loss_epoch=0.0323]Epoch 215: Train Loss = 0.0327833816409111\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0313, train_loss_epoch=0.0328]Epoch 216: Train Loss = 0.03130332753062248\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0322, train_loss_epoch=0.0313]Epoch 217: Train Loss = 0.032151103019714355\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0325, train_loss_epoch=0.0322]Epoch 218: Train Loss = 0.032466255128383636\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0329, train_loss_epoch=0.0325]Epoch 219: Train Loss = 0.03291739523410797\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0329, train_loss_epoch=0.0329]Epoch 220: Train Loss = 0.03288361057639122\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0331, train_loss_epoch=0.0329]Epoch 221: Train Loss = 0.03310921788215637\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0323, train_loss_epoch=0.0331]Epoch 222: Train Loss = 0.03231320530176163\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0325, train_loss_epoch=0.0323]Epoch 223: Train Loss = 0.032487209886312485\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0329, train_loss_epoch=0.0325]Epoch 224: Train Loss = 0.03289003670215607\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0315, train_loss_epoch=0.0329]Epoch 225: Train Loss = 0.03146045282483101\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0308, train_loss_epoch=0.0315]Epoch 226: Train Loss = 0.03075544908642769\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0332, train_loss_epoch=0.0308]Epoch 227: Train Loss = 0.03316441550850868\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.032, train_loss_epoch=0.0332] Epoch 228: Train Loss = 0.03204091265797615\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.032, train_loss_epoch=0.032] Epoch 229: Train Loss = 0.03200695663690567\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=226, train_loss_step=0.0316, train_loss_epoch=0.032]Epoch 230: Train Loss = 0.031615130603313446\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0328, train_loss_epoch=0.0316]Epoch 231: Train Loss = 0.032783716917037964\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0319, train_loss_epoch=0.0328]Epoch 232: Train Loss = 0.03192627429962158\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0348, train_loss_epoch=0.0319]Epoch 233: Train Loss = 0.03483464568853378\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0314, train_loss_epoch=0.0348]Epoch 234: Train Loss = 0.031391628086566925\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0331, train_loss_epoch=0.0314]Epoch 235: Train Loss = 0.03306550160050392\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0305, train_loss_epoch=0.0331]Epoch 236: Train Loss = 0.030474327504634857\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0334, train_loss_epoch=0.0305]Epoch 237: Train Loss = 0.033446453511714935\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0299, train_loss_epoch=0.0334]Epoch 238: Train Loss = 0.029909050092101097\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0314, train_loss_epoch=0.0299]Epoch 239: Train Loss = 0.031383104622364044\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0299, train_loss_epoch=0.0314]Epoch 240: Train Loss = 0.0299103744328022\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0309, train_loss_epoch=0.0299]Epoch 241: Train Loss = 0.030893415212631226\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0303, train_loss_epoch=0.0309]Epoch 242: Train Loss = 0.030258359387516975\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0314, train_loss_epoch=0.0303]Epoch 243: Train Loss = 0.03139897808432579\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=226, train_loss_step=0.0298, train_loss_epoch=0.0314]Epoch 244: Train Loss = 0.029803074896335602\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=226, train_loss_step=0.0351, train_loss_epoch=0.0298]Epoch 245: Train Loss = 0.035086262971162796\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0319, train_loss_epoch=0.0351]Epoch 246: Train Loss = 0.03187562897801399\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0314, train_loss_epoch=0.0319]Epoch 247: Train Loss = 0.03139722719788551\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0313, train_loss_epoch=0.0314]Epoch 248: Train Loss = 0.031336430460214615\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0309, train_loss_epoch=0.0313]Epoch 249: Train Loss = 0.03085292875766754\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0309, train_loss_epoch=0.0309]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=226, train_loss_step=0.0309, train_loss_epoch=0.0309]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 21: from 1998-11-02 00:00:00 to 2022-07-14 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.401]Epoch 0: Train Loss = 0.40128692984580994\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.494, train_loss_epoch=0.401]Epoch 1: Train Loss = 0.4939517676830292\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.379, train_loss_epoch=0.494]Epoch 2: Train Loss = 0.3791930377483368\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.253, train_loss_epoch=0.379]Epoch 3: Train Loss = 0.25292205810546875\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.302, train_loss_epoch=0.253]Epoch 4: Train Loss = 0.30210837721824646\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.309, train_loss_epoch=0.302]Epoch 5: Train Loss = 0.3091669976711273\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.260, train_loss_epoch=0.309]Epoch 6: Train Loss = 0.2599673867225647\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.242, train_loss_epoch=0.260]Epoch 7: Train Loss = 0.24222049117088318\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.264, train_loss_epoch=0.242]Epoch 8: Train Loss = 0.26385360956192017\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.257, train_loss_epoch=0.264]Epoch 9: Train Loss = 0.2574160695075989\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.241, train_loss_epoch=0.257]Epoch 10: Train Loss = 0.24068060517311096\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.222, train_loss_epoch=0.241]Epoch 11: Train Loss = 0.22218634188175201\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.234, train_loss_epoch=0.222]Epoch 12: Train Loss = 0.23412983119487762\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.222, train_loss_epoch=0.234]Epoch 13: Train Loss = 0.2220298945903778\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.209, train_loss_epoch=0.222]Epoch 14: Train Loss = 0.2089100033044815\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.188, train_loss_epoch=0.209]Epoch 15: Train Loss = 0.18775515258312225\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.199, train_loss_epoch=0.188]Epoch 16: Train Loss = 0.19892120361328125\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.191, train_loss_epoch=0.199]Epoch 17: Train Loss = 0.1908540427684784\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.197, train_loss_epoch=0.191]Epoch 18: Train Loss = 0.19681160151958466\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.174, train_loss_epoch=0.197]Epoch 19: Train Loss = 0.17394158244132996\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.166, train_loss_epoch=0.174]Epoch 20: Train Loss = 0.16576935350894928\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.180, train_loss_epoch=0.166]Epoch 21: Train Loss = 0.17952804267406464\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.175, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.1746394783258438\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.165, train_loss_epoch=0.175]Epoch 23: Train Loss = 0.16474130749702454\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.159, train_loss_epoch=0.165]Epoch 24: Train Loss = 0.1585911363363266\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.158, train_loss_epoch=0.159]Epoch 25: Train Loss = 0.15803323686122894\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.163, train_loss_epoch=0.158]Epoch 26: Train Loss = 0.1626283973455429\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.153, train_loss_epoch=0.163]Epoch 27: Train Loss = 0.15254531800746918\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.144, train_loss_epoch=0.153]Epoch 28: Train Loss = 0.14446090161800385\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.148, train_loss_epoch=0.144]Epoch 29: Train Loss = 0.14779077470302582\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=228, train_loss_step=0.143, train_loss_epoch=0.148]Epoch 30: Train Loss = 0.14286722242832184\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.144, train_loss_epoch=0.143]Epoch 31: Train Loss = 0.14411020278930664\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.139, train_loss_epoch=0.144]Epoch 32: Train Loss = 0.1392289698123932\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.135, train_loss_epoch=0.139]Epoch 33: Train Loss = 0.1349918395280838\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.134, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13422301411628723\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.130, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.12955531477928162\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.128, train_loss_epoch=0.130]Epoch 36: Train Loss = 0.12827196717262268\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.129, train_loss_epoch=0.128]Epoch 37: Train Loss = 0.1287059187889099\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.124, train_loss_epoch=0.129]Epoch 38: Train Loss = 0.12380778044462204\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.117, train_loss_epoch=0.124]Epoch 39: Train Loss = 0.11674556136131287\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.116, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11643524467945099\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.118, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11764572560787201\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.114, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.11407800018787384\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.109, train_loss_epoch=0.114]Epoch 43: Train Loss = 0.10926689207553864\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.114, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.113974429666996\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.107, train_loss_epoch=0.114]Epoch 45: Train Loss = 0.10708734393119812\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.106, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.1059943288564682\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.102, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.10172436386346817\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0999, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.09992765635251999\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=228, train_loss_step=0.103, train_loss_epoch=0.0999] Epoch 49: Train Loss = 0.10274338722229004\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0992, train_loss_epoch=0.103]Epoch 50: Train Loss = 0.09920970350503922\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.098, train_loss_epoch=0.0992] Epoch 51: Train Loss = 0.09795688837766647\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0975, train_loss_epoch=0.098]Epoch 52: Train Loss = 0.09750902652740479\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0935, train_loss_epoch=0.0975]Epoch 53: Train Loss = 0.09350702166557312\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0936, train_loss_epoch=0.0935]Epoch 54: Train Loss = 0.09360535442829132\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0922, train_loss_epoch=0.0936]Epoch 55: Train Loss = 0.09217137098312378\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0897, train_loss_epoch=0.0922]Epoch 56: Train Loss = 0.08968935906887054\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0882, train_loss_epoch=0.0897]Epoch 57: Train Loss = 0.08818037062883377\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0873, train_loss_epoch=0.0882]Epoch 58: Train Loss = 0.08731424063444138\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0849, train_loss_epoch=0.0873]Epoch 59: Train Loss = 0.08492695540189743\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0849, train_loss_epoch=0.0849]Epoch 60: Train Loss = 0.08486094325780869\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0806, train_loss_epoch=0.0849]Epoch 61: Train Loss = 0.08056318759918213\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0815, train_loss_epoch=0.0806]Epoch 62: Train Loss = 0.08152636885643005\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.080, train_loss_epoch=0.0815] Epoch 63: Train Loss = 0.08002080023288727\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0789, train_loss_epoch=0.080]Epoch 64: Train Loss = 0.07889234274625778\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0771, train_loss_epoch=0.0789]Epoch 65: Train Loss = 0.07707483321428299\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0776, train_loss_epoch=0.0771]Epoch 66: Train Loss = 0.07760918140411377\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.076, train_loss_epoch=0.0776] Epoch 67: Train Loss = 0.07604837417602539\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.074, train_loss_epoch=0.076] Epoch 68: Train Loss = 0.07400638610124588\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0729, train_loss_epoch=0.074]Epoch 69: Train Loss = 0.07288315892219543\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0714, train_loss_epoch=0.0729]Epoch 70: Train Loss = 0.0714380145072937\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0698, train_loss_epoch=0.0714]Epoch 71: Train Loss = 0.06977944821119308\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0718, train_loss_epoch=0.0698]Epoch 72: Train Loss = 0.07183589041233063\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0681, train_loss_epoch=0.0718]Epoch 73: Train Loss = 0.06807124614715576\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0725, train_loss_epoch=0.0681]Epoch 74: Train Loss = 0.07247500121593475\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.066, train_loss_epoch=0.0725] Epoch 75: Train Loss = 0.06602958589792252\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0705, train_loss_epoch=0.066]Epoch 76: Train Loss = 0.0705423355102539\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0671, train_loss_epoch=0.0705]Epoch 77: Train Loss = 0.06709896773099899\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0706, train_loss_epoch=0.0671]Epoch 78: Train Loss = 0.0706387460231781\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=228, train_loss_step=0.0634, train_loss_epoch=0.0706]Epoch 79: Train Loss = 0.06335044652223587\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0674, train_loss_epoch=0.0634]Epoch 80: Train Loss = 0.06735524535179138\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0624, train_loss_epoch=0.0674]Epoch 81: Train Loss = 0.06239650771021843\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0655, train_loss_epoch=0.0624]Epoch 82: Train Loss = 0.06550927460193634\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0622, train_loss_epoch=0.0655]Epoch 83: Train Loss = 0.06223054975271225\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0622, train_loss_epoch=0.0622]Epoch 84: Train Loss = 0.06216055154800415\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0612, train_loss_epoch=0.0622]Epoch 85: Train Loss = 0.061209503561258316\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0605, train_loss_epoch=0.0612]Epoch 86: Train Loss = 0.06047258526086807\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0597, train_loss_epoch=0.0605]Epoch 87: Train Loss = 0.059722900390625\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0574, train_loss_epoch=0.0597]Epoch 88: Train Loss = 0.057420600205659866\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0582, train_loss_epoch=0.0574]Epoch 89: Train Loss = 0.05822768434882164\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0576, train_loss_epoch=0.0582]Epoch 90: Train Loss = 0.05759873986244202\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0573, train_loss_epoch=0.0576]Epoch 91: Train Loss = 0.05728079378604889\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0556, train_loss_epoch=0.0573]Epoch 92: Train Loss = 0.05564490705728531\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0551, train_loss_epoch=0.0556]Epoch 93: Train Loss = 0.05510200932621956\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0563, train_loss_epoch=0.0551]Epoch 94: Train Loss = 0.05629346892237663\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0527, train_loss_epoch=0.0563]Epoch 95: Train Loss = 0.052667442709207535\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0536, train_loss_epoch=0.0527]Epoch 96: Train Loss = 0.053634826093912125\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0537, train_loss_epoch=0.0536]Epoch 97: Train Loss = 0.0536922961473465\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0531, train_loss_epoch=0.0537]Epoch 98: Train Loss = 0.053113386034965515\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0518, train_loss_epoch=0.0531]Epoch 99: Train Loss = 0.05175367742776871\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0505, train_loss_epoch=0.0518]Epoch 100: Train Loss = 0.050505220890045166\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0507, train_loss_epoch=0.0505]Epoch 101: Train Loss = 0.050710923969745636\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0494, train_loss_epoch=0.0507]Epoch 102: Train Loss = 0.04940680041909218\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0498, train_loss_epoch=0.0494]Epoch 103: Train Loss = 0.04982560873031616\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0494, train_loss_epoch=0.0498]Epoch 104: Train Loss = 0.04941382631659508\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0491, train_loss_epoch=0.0494]Epoch 105: Train Loss = 0.04906703159213066\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0504, train_loss_epoch=0.0491]Epoch 106: Train Loss = 0.050426729023456573\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0481, train_loss_epoch=0.0504]Epoch 107: Train Loss = 0.048118893057107925\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0541, train_loss_epoch=0.0481]Epoch 108: Train Loss = 0.054107666015625\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0493, train_loss_epoch=0.0541]Epoch 109: Train Loss = 0.04925907403230667\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0511, train_loss_epoch=0.0493]Epoch 110: Train Loss = 0.05105685442686081\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0487, train_loss_epoch=0.0511]Epoch 111: Train Loss = 0.048725031316280365\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0477, train_loss_epoch=0.0487]Epoch 112: Train Loss = 0.0477009192109108\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0481, train_loss_epoch=0.0477]Epoch 113: Train Loss = 0.04812043532729149\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0483, train_loss_epoch=0.0481]Epoch 114: Train Loss = 0.04826587438583374\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0468, train_loss_epoch=0.0483]Epoch 115: Train Loss = 0.04675261303782463\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.049, train_loss_epoch=0.0468] Epoch 116: Train Loss = 0.04899611324071884\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0472, train_loss_epoch=0.049]Epoch 117: Train Loss = 0.04720497503876686\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0494, train_loss_epoch=0.0472]Epoch 118: Train Loss = 0.04943741858005524\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0523, train_loss_epoch=0.0494]Epoch 119: Train Loss = 0.052314139902591705\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0462, train_loss_epoch=0.0523]Epoch 120: Train Loss = 0.04624025896191597\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.046, train_loss_epoch=0.0462] Epoch 121: Train Loss = 0.046002574265003204\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0513, train_loss_epoch=0.046]Epoch 122: Train Loss = 0.05126969888806343\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.046, train_loss_epoch=0.0513] Epoch 123: Train Loss = 0.04596123844385147\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.050, train_loss_epoch=0.046] Epoch 124: Train Loss = 0.05000598728656769\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0437, train_loss_epoch=0.050]Epoch 125: Train Loss = 0.04371929168701172\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0484, train_loss_epoch=0.0437]Epoch 126: Train Loss = 0.04837258160114288\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=228, train_loss_step=0.0424, train_loss_epoch=0.0484]Epoch 127: Train Loss = 0.04240036383271217\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=228, train_loss_step=0.0457, train_loss_epoch=0.0424]Epoch 128: Train Loss = 0.0457155704498291\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0427, train_loss_epoch=0.0457]Epoch 129: Train Loss = 0.042719241231679916\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=228, train_loss_step=0.0411, train_loss_epoch=0.0427]Epoch 130: Train Loss = 0.041119374334812164\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=228, train_loss_step=0.0426, train_loss_epoch=0.0411]Epoch 131: Train Loss = 0.04262729361653328\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0421, train_loss_epoch=0.0426]Epoch 132: Train Loss = 0.04210749641060829\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0422, train_loss_epoch=0.0421]Epoch 133: Train Loss = 0.04222201183438301\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0411, train_loss_epoch=0.0422]Epoch 134: Train Loss = 0.04109334200620651\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0418, train_loss_epoch=0.0411]Epoch 135: Train Loss = 0.04181483015418053\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0415, train_loss_epoch=0.0418]Epoch 136: Train Loss = 0.041488781571388245\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0404, train_loss_epoch=0.0415]Epoch 137: Train Loss = 0.040354788303375244\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0408, train_loss_epoch=0.0404]Epoch 138: Train Loss = 0.04080687090754509\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0406, train_loss_epoch=0.0408]Epoch 139: Train Loss = 0.04062781110405922\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.040, train_loss_epoch=0.0406] Epoch 140: Train Loss = 0.04003892093896866\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0397, train_loss_epoch=0.040]Epoch 141: Train Loss = 0.03974608704447746\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.040, train_loss_epoch=0.0397] Epoch 142: Train Loss = 0.03996828570961952\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0395, train_loss_epoch=0.040]Epoch 143: Train Loss = 0.039523158222436905\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0392, train_loss_epoch=0.0395]Epoch 144: Train Loss = 0.039205580949783325\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0395, train_loss_epoch=0.0392]Epoch 145: Train Loss = 0.03945824131369591\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0396, train_loss_epoch=0.0395]Epoch 146: Train Loss = 0.039635561406612396\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0394, train_loss_epoch=0.0396]Epoch 147: Train Loss = 0.03944258764386177\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0378, train_loss_epoch=0.0394]Epoch 148: Train Loss = 0.03779898211359978\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0426, train_loss_epoch=0.0378]Epoch 149: Train Loss = 0.04259469732642174\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0384, train_loss_epoch=0.0426]Epoch 150: Train Loss = 0.038365624845027924\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0411, train_loss_epoch=0.0384]Epoch 151: Train Loss = 0.041093502193689346\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0389, train_loss_epoch=0.0411]Epoch 152: Train Loss = 0.038909826427698135\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0419, train_loss_epoch=0.0389]Epoch 153: Train Loss = 0.04193710535764694\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0372, train_loss_epoch=0.0419]Epoch 154: Train Loss = 0.037227194756269455\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0389, train_loss_epoch=0.0372]Epoch 155: Train Loss = 0.038887232542037964\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0385, train_loss_epoch=0.0389]Epoch 156: Train Loss = 0.038548994809389114\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0385, train_loss_epoch=0.0385]Epoch 157: Train Loss = 0.038536425679922104\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0376, train_loss_epoch=0.0385]Epoch 158: Train Loss = 0.03763015568256378\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.038, train_loss_epoch=0.0376] Epoch 159: Train Loss = 0.037962399423122406\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0371, train_loss_epoch=0.038]Epoch 160: Train Loss = 0.037095848470926285\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0374, train_loss_epoch=0.0371]Epoch 161: Train Loss = 0.03744645044207573\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0365, train_loss_epoch=0.0374]Epoch 162: Train Loss = 0.036525189876556396\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0368, train_loss_epoch=0.0365]Epoch 163: Train Loss = 0.03680507466197014\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0366, train_loss_epoch=0.0368]Epoch 164: Train Loss = 0.03660217300057411\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0363, train_loss_epoch=0.0366]Epoch 165: Train Loss = 0.036282263696193695\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0366, train_loss_epoch=0.0363]Epoch 166: Train Loss = 0.036587249487638474\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0361, train_loss_epoch=0.0366]Epoch 167: Train Loss = 0.03610783815383911\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.037, train_loss_epoch=0.0361] Epoch 168: Train Loss = 0.03703144192695618\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0357, train_loss_epoch=0.037]Epoch 169: Train Loss = 0.035690005868673325\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0412, train_loss_epoch=0.0357]Epoch 170: Train Loss = 0.04123573377728462\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0357, train_loss_epoch=0.0412]Epoch 171: Train Loss = 0.035653065890073776\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0443, train_loss_epoch=0.0357]Epoch 172: Train Loss = 0.04433789104223251\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0359, train_loss_epoch=0.0443]Epoch 173: Train Loss = 0.03588302806019783\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=228, train_loss_step=0.0377, train_loss_epoch=0.0359]Epoch 174: Train Loss = 0.0376911424100399\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0371, train_loss_epoch=0.0377]Epoch 175: Train Loss = 0.03707321360707283\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0398, train_loss_epoch=0.0371]Epoch 176: Train Loss = 0.03976265713572502\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0355, train_loss_epoch=0.0398]Epoch 177: Train Loss = 0.035477619618177414\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.037, train_loss_epoch=0.0355] Epoch 178: Train Loss = 0.03699469938874245\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.034, train_loss_epoch=0.037] Epoch 179: Train Loss = 0.03399312496185303\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0346, train_loss_epoch=0.034]Epoch 180: Train Loss = 0.034647103399038315\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0359, train_loss_epoch=0.0346]Epoch 181: Train Loss = 0.035898540169000626\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0352, train_loss_epoch=0.0359]Epoch 182: Train Loss = 0.03520737960934639\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0345, train_loss_epoch=0.0352]Epoch 183: Train Loss = 0.03448093309998512\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0345, train_loss_epoch=0.0345]Epoch 184: Train Loss = 0.03445857763290405\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0338, train_loss_epoch=0.0345]Epoch 185: Train Loss = 0.033814139664173126\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0344, train_loss_epoch=0.0338]Epoch 186: Train Loss = 0.034402064979076385\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0341, train_loss_epoch=0.0344]Epoch 187: Train Loss = 0.03411489352583885\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0341, train_loss_epoch=0.0341]Epoch 188: Train Loss = 0.03413458541035652\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=228, train_loss_step=0.0337, train_loss_epoch=0.0341]Epoch 189: Train Loss = 0.03368458151817322\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0347, train_loss_epoch=0.0337]Epoch 190: Train Loss = 0.03471996635198593\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0345, train_loss_epoch=0.0347]Epoch 191: Train Loss = 0.034472327679395676\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0353, train_loss_epoch=0.0345]Epoch 192: Train Loss = 0.03528493642807007\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0347, train_loss_epoch=0.0353]Epoch 193: Train Loss = 0.034671682864427567\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0336, train_loss_epoch=0.0347]Epoch 194: Train Loss = 0.03362104669213295\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0335, train_loss_epoch=0.0336]Epoch 195: Train Loss = 0.03354594111442566\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0343, train_loss_epoch=0.0335]Epoch 196: Train Loss = 0.03426554054021835\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0335, train_loss_epoch=0.0343]Epoch 197: Train Loss = 0.033508725464344025\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0332, train_loss_epoch=0.0335]Epoch 198: Train Loss = 0.033224113285541534\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0339, train_loss_epoch=0.0332]Epoch 199: Train Loss = 0.03385430946946144\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.035, train_loss_epoch=0.0339] Epoch 200: Train Loss = 0.03502112254500389\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0331, train_loss_epoch=0.035]Epoch 201: Train Loss = 0.03309546038508415\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0334, train_loss_epoch=0.0331]Epoch 202: Train Loss = 0.03344964608550072\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.033, train_loss_epoch=0.0334] Epoch 203: Train Loss = 0.03300017490983009\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0326, train_loss_epoch=0.033]Epoch 204: Train Loss = 0.03261540085077286\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0339, train_loss_epoch=0.0326]Epoch 205: Train Loss = 0.033869821578264236\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0353, train_loss_epoch=0.0339]Epoch 206: Train Loss = 0.03528163954615593\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=228, train_loss_step=0.0378, train_loss_epoch=0.0353]Epoch 207: Train Loss = 0.03784182295203209\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0348, train_loss_epoch=0.0378]Epoch 208: Train Loss = 0.034843768924474716\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0346, train_loss_epoch=0.0348]Epoch 209: Train Loss = 0.03464638441801071\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0354, train_loss_epoch=0.0346]Epoch 210: Train Loss = 0.035427894443273544\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0336, train_loss_epoch=0.0354]Epoch 211: Train Loss = 0.03362226113677025\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0326, train_loss_epoch=0.0336]Epoch 212: Train Loss = 0.03258644416928291\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0325, train_loss_epoch=0.0326]Epoch 213: Train Loss = 0.03251093998551369\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0432, train_loss_epoch=0.0325]Epoch 214: Train Loss = 0.043222576379776\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0334, train_loss_epoch=0.0432]Epoch 215: Train Loss = 0.03338693082332611\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0344, train_loss_epoch=0.0334]Epoch 216: Train Loss = 0.03436371311545372\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0318, train_loss_epoch=0.0344]Epoch 217: Train Loss = 0.031773220747709274\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0348, train_loss_epoch=0.0318]Epoch 218: Train Loss = 0.034758396446704865\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0315, train_loss_epoch=0.0348]Epoch 219: Train Loss = 0.031467240303754807\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=228, train_loss_step=0.0356, train_loss_epoch=0.0315]Epoch 220: Train Loss = 0.03563380986452103\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0319, train_loss_epoch=0.0356]Epoch 221: Train Loss = 0.031904518604278564\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0319, train_loss_epoch=0.0319]Epoch 222: Train Loss = 0.03193189203739166\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0318, train_loss_epoch=0.0319]Epoch 223: Train Loss = 0.03175494819879532\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0323, train_loss_epoch=0.0318]Epoch 224: Train Loss = 0.0322876051068306\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0319, train_loss_epoch=0.0323]Epoch 225: Train Loss = 0.03193790838122368\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.031, train_loss_epoch=0.0319] Epoch 226: Train Loss = 0.031023042276501656\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0345, train_loss_epoch=0.031]Epoch 227: Train Loss = 0.03450042009353638\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.032, train_loss_epoch=0.0345] Epoch 228: Train Loss = 0.03197450935840607\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0311, train_loss_epoch=0.032]Epoch 229: Train Loss = 0.031071672216057777\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0319, train_loss_epoch=0.0311]Epoch 230: Train Loss = 0.031899772584438324\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0324, train_loss_epoch=0.0319]Epoch 231: Train Loss = 0.032368555665016174\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.032, train_loss_epoch=0.0324] Epoch 232: Train Loss = 0.03201794996857643\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0323, train_loss_epoch=0.032]Epoch 233: Train Loss = 0.03226318955421448\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0339, train_loss_epoch=0.0323]Epoch 234: Train Loss = 0.03392891213297844\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0311, train_loss_epoch=0.0339]Epoch 235: Train Loss = 0.031094107776880264\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=228, train_loss_step=0.0352, train_loss_epoch=0.0311]Epoch 236: Train Loss = 0.03519679605960846\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0305, train_loss_epoch=0.0352]Epoch 237: Train Loss = 0.030530575662851334\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0367, train_loss_epoch=0.0305]Epoch 238: Train Loss = 0.03668951615691185\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0311, train_loss_epoch=0.0367]Epoch 239: Train Loss = 0.03110305219888687\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0327, train_loss_epoch=0.0311]Epoch 240: Train Loss = 0.032732050865888596\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0302, train_loss_epoch=0.0327]Epoch 241: Train Loss = 0.030195588245987892\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=228, train_loss_step=0.0324, train_loss_epoch=0.0302]Epoch 242: Train Loss = 0.03243069723248482\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0305, train_loss_epoch=0.0324]Epoch 243: Train Loss = 0.03047008253633976\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.031, train_loss_epoch=0.0305] Epoch 244: Train Loss = 0.030968638136982918\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0302, train_loss_epoch=0.031]Epoch 245: Train Loss = 0.03018464893102646\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=228, train_loss_step=0.0317, train_loss_epoch=0.0302]Epoch 246: Train Loss = 0.03165297955274582\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=228, train_loss_step=0.0307, train_loss_epoch=0.0317]Epoch 247: Train Loss = 0.030658472329378128\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=228, train_loss_step=0.0303, train_loss_epoch=0.0307]Epoch 248: Train Loss = 0.030330272391438484\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=228, train_loss_step=0.0304, train_loss_epoch=0.0303]Epoch 249: Train Loss = 0.03037256933748722\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=228, train_loss_step=0.0304, train_loss_epoch=0.0304]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=228, train_loss_step=0.0304, train_loss_epoch=0.0304]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 22: from 1998-11-02 00:00:00 to 2022-07-25 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.400]Epoch 0: Train Loss = 0.4001089632511139\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.491, train_loss_epoch=0.400]Epoch 1: Train Loss = 0.49098333716392517\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.373, train_loss_epoch=0.491]Epoch 2: Train Loss = 0.3733431100845337\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.249, train_loss_epoch=0.373]Epoch 3: Train Loss = 0.24907882511615753\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.308, train_loss_epoch=0.249]Epoch 4: Train Loss = 0.3082006573677063\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.319, train_loss_epoch=0.308]Epoch 5: Train Loss = 0.31946972012519836\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.257, train_loss_epoch=0.319]Epoch 6: Train Loss = 0.25746333599090576\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.239, train_loss_epoch=0.257]Epoch 7: Train Loss = 0.23932161927223206\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.266, train_loss_epoch=0.239]Epoch 8: Train Loss = 0.2655896842479706\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.264, train_loss_epoch=0.266]Epoch 9: Train Loss = 0.26424771547317505\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.243, train_loss_epoch=0.264]Epoch 10: Train Loss = 0.24310202896595\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.219, train_loss_epoch=0.243]Epoch 11: Train Loss = 0.21876072883605957\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.234, train_loss_epoch=0.219]Epoch 12: Train Loss = 0.23441411554813385\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.223, train_loss_epoch=0.234]Epoch 13: Train Loss = 0.22323334217071533\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.212, train_loss_epoch=0.223]Epoch 14: Train Loss = 0.2119293361902237\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.191, train_loss_epoch=0.212]Epoch 15: Train Loss = 0.1912248730659485\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.199, train_loss_epoch=0.191]Epoch 16: Train Loss = 0.19879713654518127\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.192, train_loss_epoch=0.199]Epoch 17: Train Loss = 0.19212126731872559\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.197, train_loss_epoch=0.192]Epoch 18: Train Loss = 0.19695255160331726\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.173, train_loss_epoch=0.197]Epoch 19: Train Loss = 0.17301104962825775\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.166, train_loss_epoch=0.173]Epoch 20: Train Loss = 0.16612538695335388\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.179, train_loss_epoch=0.166]Epoch 21: Train Loss = 0.17948570847511292\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.177, train_loss_epoch=0.179]Epoch 22: Train Loss = 0.17700275778770447\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.164, train_loss_epoch=0.177]Epoch 23: Train Loss = 0.16395214200019836\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.160, train_loss_epoch=0.164]Epoch 24: Train Loss = 0.1597360223531723\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.156, train_loss_epoch=0.160]Epoch 25: Train Loss = 0.1556679904460907\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.158, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.15790222585201263\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.152, train_loss_epoch=0.158]Epoch 27: Train Loss = 0.15157277882099152\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.147, train_loss_epoch=0.152]Epoch 28: Train Loss = 0.14665652811527252\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.149, train_loss_epoch=0.147]Epoch 29: Train Loss = 0.14899064600467682\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.142, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.14248372614383698\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.141, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.14147184789180756\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.138, train_loss_epoch=0.141]Epoch 32: Train Loss = 0.13840769231319427\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.135, train_loss_epoch=0.138]Epoch 33: Train Loss = 0.13468731939792633\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.133, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13272711634635925\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.132, train_loss_epoch=0.133]Epoch 35: Train Loss = 0.13160601258277893\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.129, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.1289213001728058\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.129, train_loss_epoch=0.129]Epoch 37: Train Loss = 0.12868034839630127\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.123, train_loss_epoch=0.129]Epoch 38: Train Loss = 0.1227579191327095\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.118, train_loss_epoch=0.123]Epoch 39: Train Loss = 0.11788095533847809\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.116, train_loss_epoch=0.118]Epoch 40: Train Loss = 0.1157815009355545\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.118, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11765079200267792\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.116, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.11582367867231369\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.108, train_loss_epoch=0.116]Epoch 43: Train Loss = 0.10820984840393066\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.114, train_loss_epoch=0.108]Epoch 44: Train Loss = 0.1136343702673912\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.108, train_loss_epoch=0.114]Epoch 45: Train Loss = 0.10760306566953659\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.105, train_loss_epoch=0.108]Epoch 46: Train Loss = 0.10503070801496506\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.103, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10268908739089966\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.102, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10229300707578659\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.101, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.1008044108748436\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.101, train_loss_epoch=0.101]Epoch 50: Train Loss = 0.10134477913379669\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0967, train_loss_epoch=0.101]Epoch 51: Train Loss = 0.09665931016206741\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0958, train_loss_epoch=0.0967]Epoch 52: Train Loss = 0.0957878902554512\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0955, train_loss_epoch=0.0958]Epoch 53: Train Loss = 0.09545248001813889\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0922, train_loss_epoch=0.0955]Epoch 54: Train Loss = 0.09217146784067154\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0934, train_loss_epoch=0.0922]Epoch 55: Train Loss = 0.09343823045492172\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0894, train_loss_epoch=0.0934]Epoch 56: Train Loss = 0.08941650390625\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0864, train_loss_epoch=0.0894]Epoch 57: Train Loss = 0.08641622215509415\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0892, train_loss_epoch=0.0864]Epoch 58: Train Loss = 0.0892016813158989\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0843, train_loss_epoch=0.0892]Epoch 59: Train Loss = 0.08428771048784256\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=230, train_loss_step=0.0861, train_loss_epoch=0.0843]Epoch 60: Train Loss = 0.08612320572137833\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0821, train_loss_epoch=0.0861]Epoch 61: Train Loss = 0.08212880045175552\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0802, train_loss_epoch=0.0821]Epoch 62: Train Loss = 0.08019614219665527\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=230, train_loss_step=0.080, train_loss_epoch=0.0802] Epoch 63: Train Loss = 0.07998598366975784\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0766, train_loss_epoch=0.080]Epoch 64: Train Loss = 0.07664617151021957\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0785, train_loss_epoch=0.0766]Epoch 65: Train Loss = 0.07846897095441818\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0756, train_loss_epoch=0.0785]Epoch 66: Train Loss = 0.07564063370227814\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0751, train_loss_epoch=0.0756]Epoch 67: Train Loss = 0.0751439556479454\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0744, train_loss_epoch=0.0751]Epoch 68: Train Loss = 0.07443508505821228\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0709, train_loss_epoch=0.0744]Epoch 69: Train Loss = 0.07093090564012527\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0717, train_loss_epoch=0.0709]Epoch 70: Train Loss = 0.07173473387956619\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0697, train_loss_epoch=0.0717]Epoch 71: Train Loss = 0.06973934173583984\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0685, train_loss_epoch=0.0697]Epoch 72: Train Loss = 0.06845712661743164\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.070, train_loss_epoch=0.0685] Epoch 73: Train Loss = 0.0699860081076622\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0692, train_loss_epoch=0.070]Epoch 74: Train Loss = 0.06919074803590775\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0673, train_loss_epoch=0.0692]Epoch 75: Train Loss = 0.06730519980192184\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0666, train_loss_epoch=0.0673]Epoch 76: Train Loss = 0.06660983711481094\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=230, train_loss_step=0.068, train_loss_epoch=0.0666] Epoch 77: Train Loss = 0.06795928627252579\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0649, train_loss_epoch=0.068]Epoch 78: Train Loss = 0.06491772085428238\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0673, train_loss_epoch=0.0649]Epoch 79: Train Loss = 0.06734950095415115\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0625, train_loss_epoch=0.0673]Epoch 80: Train Loss = 0.0624808669090271\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0651, train_loss_epoch=0.0625]Epoch 81: Train Loss = 0.0650739073753357\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0628, train_loss_epoch=0.0651]Epoch 82: Train Loss = 0.06279148161411285\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0656, train_loss_epoch=0.0628]Epoch 83: Train Loss = 0.0655914768576622\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.062, train_loss_epoch=0.0656] Epoch 84: Train Loss = 0.061950985342264175\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0632, train_loss_epoch=0.062]Epoch 85: Train Loss = 0.0631757453083992\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0593, train_loss_epoch=0.0632]Epoch 86: Train Loss = 0.05932983383536339\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0613, train_loss_epoch=0.0593]Epoch 87: Train Loss = 0.061340268701314926\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0578, train_loss_epoch=0.0613]Epoch 88: Train Loss = 0.05775478482246399\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0576, train_loss_epoch=0.0578]Epoch 89: Train Loss = 0.05763517692685127\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0569, train_loss_epoch=0.0576]Epoch 90: Train Loss = 0.05685345083475113\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0556, train_loss_epoch=0.0569]Epoch 91: Train Loss = 0.05561913177371025\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0554, train_loss_epoch=0.0556]Epoch 92: Train Loss = 0.05541270598769188\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0557, train_loss_epoch=0.0554]Epoch 93: Train Loss = 0.055666692554950714\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0537, train_loss_epoch=0.0557]Epoch 94: Train Loss = 0.05368209257721901\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0535, train_loss_epoch=0.0537]Epoch 95: Train Loss = 0.05351166054606438\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0533, train_loss_epoch=0.0535]Epoch 96: Train Loss = 0.05333061143755913\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0549, train_loss_epoch=0.0533]Epoch 97: Train Loss = 0.0548546202480793\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0532, train_loss_epoch=0.0549]Epoch 98: Train Loss = 0.05321831628680229\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0548, train_loss_epoch=0.0532]Epoch 99: Train Loss = 0.054764315485954285\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=230, train_loss_step=0.0537, train_loss_epoch=0.0548]Epoch 100: Train Loss = 0.05369526147842407\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0498, train_loss_epoch=0.0537]Epoch 101: Train Loss = 0.049754057079553604\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=230, train_loss_step=0.0506, train_loss_epoch=0.0498]Epoch 102: Train Loss = 0.050558481365442276\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0518, train_loss_epoch=0.0506]Epoch 103: Train Loss = 0.05178176611661911\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0492, train_loss_epoch=0.0518]Epoch 104: Train Loss = 0.04917746037244797\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0525, train_loss_epoch=0.0492]Epoch 105: Train Loss = 0.05252989009022713\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0495, train_loss_epoch=0.0525]Epoch 106: Train Loss = 0.0495230108499527\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0576, train_loss_epoch=0.0495]Epoch 107: Train Loss = 0.05758221819996834\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.048, train_loss_epoch=0.0576] Epoch 108: Train Loss = 0.048006705939769745\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.055, train_loss_epoch=0.048] Epoch 109: Train Loss = 0.05496291443705559\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0465, train_loss_epoch=0.055]Epoch 110: Train Loss = 0.04650089517235756\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0491, train_loss_epoch=0.0465]Epoch 111: Train Loss = 0.04914843663573265\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0466, train_loss_epoch=0.0491]Epoch 112: Train Loss = 0.04656859487295151\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0466, train_loss_epoch=0.0466]Epoch 113: Train Loss = 0.04656970500946045\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0471, train_loss_epoch=0.0466]Epoch 114: Train Loss = 0.04712803289294243\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0466, train_loss_epoch=0.0471]Epoch 115: Train Loss = 0.04657121002674103\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0463, train_loss_epoch=0.0466]Epoch 116: Train Loss = 0.04627096652984619\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0466, train_loss_epoch=0.0463]Epoch 117: Train Loss = 0.046649713069200516\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0454, train_loss_epoch=0.0466]Epoch 118: Train Loss = 0.04536723345518112\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0469, train_loss_epoch=0.0454]Epoch 119: Train Loss = 0.046859316527843475\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0446, train_loss_epoch=0.0469]Epoch 120: Train Loss = 0.04457726702094078\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0455, train_loss_epoch=0.0446]Epoch 121: Train Loss = 0.04546286165714264\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0466, train_loss_epoch=0.0455]Epoch 122: Train Loss = 0.04655568301677704\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0462, train_loss_epoch=0.0466]Epoch 123: Train Loss = 0.04615243896842003\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0458, train_loss_epoch=0.0462]Epoch 124: Train Loss = 0.04577949270606041\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0454, train_loss_epoch=0.0458]Epoch 125: Train Loss = 0.04544845223426819\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0451, train_loss_epoch=0.0454]Epoch 126: Train Loss = 0.04510451480746269\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0455, train_loss_epoch=0.0451]Epoch 127: Train Loss = 0.045508138835430145\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0434, train_loss_epoch=0.0455]Epoch 128: Train Loss = 0.043384525924921036\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0442, train_loss_epoch=0.0434]Epoch 129: Train Loss = 0.04416352137923241\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.042, train_loss_epoch=0.0442] Epoch 130: Train Loss = 0.04202659800648689\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0444, train_loss_epoch=0.042]Epoch 131: Train Loss = 0.044432491064071655\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0411, train_loss_epoch=0.0444]Epoch 132: Train Loss = 0.04107717052102089\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0406, train_loss_epoch=0.0411]Epoch 133: Train Loss = 0.04057150334119797\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0443, train_loss_epoch=0.0406]Epoch 134: Train Loss = 0.04425965994596481\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.042, train_loss_epoch=0.0443] Epoch 135: Train Loss = 0.042005281895399094\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0436, train_loss_epoch=0.042]Epoch 136: Train Loss = 0.043563585728406906\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0418, train_loss_epoch=0.0436]Epoch 137: Train Loss = 0.041790518909692764\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0437, train_loss_epoch=0.0418]Epoch 138: Train Loss = 0.04367023706436157\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0415, train_loss_epoch=0.0437]Epoch 139: Train Loss = 0.04146574065089226\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0459, train_loss_epoch=0.0415]Epoch 140: Train Loss = 0.0459137037396431\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0398, train_loss_epoch=0.0459]Epoch 141: Train Loss = 0.03983594477176666\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0529, train_loss_epoch=0.0398]Epoch 142: Train Loss = 0.0528566874563694\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0422, train_loss_epoch=0.0529]Epoch 143: Train Loss = 0.04221034795045853\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0487, train_loss_epoch=0.0422]Epoch 144: Train Loss = 0.048701755702495575\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0411, train_loss_epoch=0.0487]Epoch 145: Train Loss = 0.04106782004237175\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0429, train_loss_epoch=0.0411]Epoch 146: Train Loss = 0.04294048622250557\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0381, train_loss_epoch=0.0429]Epoch 147: Train Loss = 0.038083817809820175\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0416, train_loss_epoch=0.0381]Epoch 148: Train Loss = 0.041562844067811966\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0389, train_loss_epoch=0.0416]Epoch 149: Train Loss = 0.038922715932130814\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0402, train_loss_epoch=0.0389]Epoch 150: Train Loss = 0.04016653820872307\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0426, train_loss_epoch=0.0402]Epoch 151: Train Loss = 0.04262737184762955\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=230, train_loss_step=0.0416, train_loss_epoch=0.0426]Epoch 152: Train Loss = 0.041580818593502045\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0414, train_loss_epoch=0.0416]Epoch 153: Train Loss = 0.0413585789501667\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0393, train_loss_epoch=0.0414]Epoch 154: Train Loss = 0.03925153613090515\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0439, train_loss_epoch=0.0393]Epoch 155: Train Loss = 0.04389218986034393\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0385, train_loss_epoch=0.0439]Epoch 156: Train Loss = 0.03850989416241646\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0418, train_loss_epoch=0.0385]Epoch 157: Train Loss = 0.0418412983417511\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0368, train_loss_epoch=0.0418]Epoch 158: Train Loss = 0.036750610917806625\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0408, train_loss_epoch=0.0368]Epoch 159: Train Loss = 0.040779344737529755\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0419, train_loss_epoch=0.0408]Epoch 160: Train Loss = 0.0418672077357769\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0422, train_loss_epoch=0.0419]Epoch 161: Train Loss = 0.04218880832195282\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.046, train_loss_epoch=0.0422] Epoch 162: Train Loss = 0.04596218839287758\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0373, train_loss_epoch=0.046]Epoch 163: Train Loss = 0.03727166727185249\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.045, train_loss_epoch=0.0373] Epoch 164: Train Loss = 0.044951219111680984\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0378, train_loss_epoch=0.045]Epoch 165: Train Loss = 0.03776438534259796\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0399, train_loss_epoch=0.0378]Epoch 166: Train Loss = 0.03987843170762062\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0373, train_loss_epoch=0.0399]Epoch 167: Train Loss = 0.03728319704532623\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0358, train_loss_epoch=0.0373]Epoch 168: Train Loss = 0.0358491912484169\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0371, train_loss_epoch=0.0358]Epoch 169: Train Loss = 0.0370844267308712\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0369, train_loss_epoch=0.0371]Epoch 170: Train Loss = 0.03690481185913086\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0369, train_loss_epoch=0.0369]Epoch 171: Train Loss = 0.036902107298374176\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0387, train_loss_epoch=0.0369]Epoch 172: Train Loss = 0.038740821182727814\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0366, train_loss_epoch=0.0387]Epoch 173: Train Loss = 0.03658995404839516\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0352, train_loss_epoch=0.0366]Epoch 174: Train Loss = 0.03520721197128296\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0361, train_loss_epoch=0.0352]Epoch 175: Train Loss = 0.03607374429702759\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0356, train_loss_epoch=0.0361]Epoch 176: Train Loss = 0.03557834401726723\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0355, train_loss_epoch=0.0356]Epoch 177: Train Loss = 0.035497575998306274\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0362, train_loss_epoch=0.0355]Epoch 178: Train Loss = 0.03619951382279396\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0359, train_loss_epoch=0.0362]Epoch 179: Train Loss = 0.03586132451891899\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0354, train_loss_epoch=0.0359]Epoch 180: Train Loss = 0.035401519387960434\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0384, train_loss_epoch=0.0354]Epoch 181: Train Loss = 0.038391828536987305\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0341, train_loss_epoch=0.0384]Epoch 182: Train Loss = 0.03414515033364296\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0393, train_loss_epoch=0.0341]Epoch 183: Train Loss = 0.03930550441145897\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0354, train_loss_epoch=0.0393]Epoch 184: Train Loss = 0.03540245071053505\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0372, train_loss_epoch=0.0354]Epoch 185: Train Loss = 0.037236619740724564\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.036, train_loss_epoch=0.0372] Epoch 186: Train Loss = 0.03602428734302521\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0376, train_loss_epoch=0.036]Epoch 187: Train Loss = 0.03762664645910263\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=230, train_loss_step=0.0351, train_loss_epoch=0.0376]Epoch 188: Train Loss = 0.03514336049556732\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0346, train_loss_epoch=0.0351]Epoch 189: Train Loss = 0.03464808315038681\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0373, train_loss_epoch=0.0346]Epoch 190: Train Loss = 0.03734564036130905\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0333, train_loss_epoch=0.0373]Epoch 191: Train Loss = 0.033347759395837784\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.038, train_loss_epoch=0.0333] Epoch 192: Train Loss = 0.03795060142874718\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0363, train_loss_epoch=0.038]Epoch 193: Train Loss = 0.036308784037828445\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0381, train_loss_epoch=0.0363]Epoch 194: Train Loss = 0.03809565305709839\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0354, train_loss_epoch=0.0381]Epoch 195: Train Loss = 0.03539658710360527\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0345, train_loss_epoch=0.0354]Epoch 196: Train Loss = 0.03453174978494644\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=230, train_loss_step=0.0347, train_loss_epoch=0.0345]Epoch 197: Train Loss = 0.03465469554066658\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0331, train_loss_epoch=0.0347]Epoch 198: Train Loss = 0.033112794160842896\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.037, train_loss_epoch=0.0331] Epoch 199: Train Loss = 0.03695984557271004\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0335, train_loss_epoch=0.037]Epoch 200: Train Loss = 0.033539820462465286\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0352, train_loss_epoch=0.0335]Epoch 201: Train Loss = 0.035163670778274536\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0333, train_loss_epoch=0.0352]Epoch 202: Train Loss = 0.03329934552311897\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0333, train_loss_epoch=0.0333]Epoch 203: Train Loss = 0.03329158574342728\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0355, train_loss_epoch=0.0333]Epoch 204: Train Loss = 0.03548981994390488\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=230, train_loss_step=0.0326, train_loss_epoch=0.0355]Epoch 205: Train Loss = 0.032634247094392776\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0337, train_loss_epoch=0.0326]Epoch 206: Train Loss = 0.03369743376970291\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0327, train_loss_epoch=0.0337]Epoch 207: Train Loss = 0.032652873545885086\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.034, train_loss_epoch=0.0327] Epoch 208: Train Loss = 0.0339542031288147\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.033, train_loss_epoch=0.034] Epoch 209: Train Loss = 0.032963965088129044\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0349, train_loss_epoch=0.033]Epoch 210: Train Loss = 0.034852247685194016\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0335, train_loss_epoch=0.0349]Epoch 211: Train Loss = 0.033519111573696136\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0385, train_loss_epoch=0.0335]Epoch 212: Train Loss = 0.03846502676606178\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0331, train_loss_epoch=0.0385]Epoch 213: Train Loss = 0.033070050179958344\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0327, train_loss_epoch=0.0331]Epoch 214: Train Loss = 0.032652877271175385\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0395, train_loss_epoch=0.0327]Epoch 215: Train Loss = 0.03952395170927048\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0327, train_loss_epoch=0.0395]Epoch 216: Train Loss = 0.03267122805118561\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0337, train_loss_epoch=0.0327]Epoch 217: Train Loss = 0.03366377204656601\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0339, train_loss_epoch=0.0337]Epoch 218: Train Loss = 0.033868275582790375\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.033, train_loss_epoch=0.0339] Epoch 219: Train Loss = 0.03295464441180229\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0348, train_loss_epoch=0.033]Epoch 220: Train Loss = 0.03481561318039894\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0321, train_loss_epoch=0.0348]Epoch 221: Train Loss = 0.03214140236377716\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0346, train_loss_epoch=0.0321]Epoch 222: Train Loss = 0.03459378331899643\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0326, train_loss_epoch=0.0346]Epoch 223: Train Loss = 0.03263755515217781\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0349, train_loss_epoch=0.0326]Epoch 224: Train Loss = 0.034883879125118256\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0317, train_loss_epoch=0.0349]Epoch 225: Train Loss = 0.0316716693341732\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0312, train_loss_epoch=0.0317]Epoch 226: Train Loss = 0.031180160120129585\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0339, train_loss_epoch=0.0312]Epoch 227: Train Loss = 0.03392574191093445\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0316, train_loss_epoch=0.0339]Epoch 228: Train Loss = 0.03161090984940529\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.033, train_loss_epoch=0.0316] Epoch 229: Train Loss = 0.033020030707120895\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0325, train_loss_epoch=0.033]Epoch 230: Train Loss = 0.03249402716755867\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0347, train_loss_epoch=0.0325]Epoch 231: Train Loss = 0.034736379981040955\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0311, train_loss_epoch=0.0347]Epoch 232: Train Loss = 0.03112858161330223\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.032, train_loss_epoch=0.0311] Epoch 233: Train Loss = 0.03195623308420181\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0333, train_loss_epoch=0.032]Epoch 234: Train Loss = 0.03331340476870537\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0312, train_loss_epoch=0.0333]Epoch 235: Train Loss = 0.031154604628682137\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0327, train_loss_epoch=0.0312]Epoch 236: Train Loss = 0.0327419675886631\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0313, train_loss_epoch=0.0327]Epoch 237: Train Loss = 0.03127714991569519\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0315, train_loss_epoch=0.0313]Epoch 238: Train Loss = 0.03147539868950844\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0318, train_loss_epoch=0.0315]Epoch 239: Train Loss = 0.03178412467241287\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0311, train_loss_epoch=0.0318]Epoch 240: Train Loss = 0.031061047688126564\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0304, train_loss_epoch=0.0311]Epoch 241: Train Loss = 0.030379021540284157\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.031, train_loss_epoch=0.0304] Epoch 242: Train Loss = 0.03098517842590809\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.030, train_loss_epoch=0.031] Epoch 243: Train Loss = 0.03003843128681183\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0301, train_loss_epoch=0.030]Epoch 244: Train Loss = 0.030073033645749092\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0313, train_loss_epoch=0.0301]Epoch 245: Train Loss = 0.03132735937833786\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.0315, train_loss_epoch=0.0313]Epoch 246: Train Loss = 0.03146719932556152\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.031, train_loss_epoch=0.0315] Epoch 247: Train Loss = 0.03101537749171257\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=230, train_loss_step=0.0314, train_loss_epoch=0.031]Epoch 248: Train Loss = 0.03138282150030136\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.031, train_loss_epoch=0.0314] Epoch 249: Train Loss = 0.031037267297506332\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.031, train_loss_epoch=0.031] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=230, train_loss_step=0.031, train_loss_epoch=0.031]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 23: from 1998-11-02 00:00:00 to 2022-08-03 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.402]Epoch 0: Train Loss = 0.40151485800743103\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.494, train_loss_epoch=0.402]Epoch 1: Train Loss = 0.4942091405391693\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.377, train_loss_epoch=0.494]Epoch 2: Train Loss = 0.37662848830223083\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.250, train_loss_epoch=0.377]Epoch 3: Train Loss = 0.25037527084350586\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.306, train_loss_epoch=0.250]Epoch 4: Train Loss = 0.3063138723373413\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.311, train_loss_epoch=0.306]Epoch 5: Train Loss = 0.3112502098083496\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.257, train_loss_epoch=0.311]Epoch 6: Train Loss = 0.2568435072898865\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.239, train_loss_epoch=0.257]Epoch 7: Train Loss = 0.23896346986293793\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.263, train_loss_epoch=0.239]Epoch 8: Train Loss = 0.26293209195137024\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.260, train_loss_epoch=0.263]Epoch 9: Train Loss = 0.25981876254081726\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.244, train_loss_epoch=0.260]Epoch 10: Train Loss = 0.24360673129558563\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.221, train_loss_epoch=0.244]Epoch 11: Train Loss = 0.22149959206581116\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.234, train_loss_epoch=0.221]Epoch 12: Train Loss = 0.23365269601345062\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.220, train_loss_epoch=0.234]Epoch 13: Train Loss = 0.21967948973178864\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.211, train_loss_epoch=0.220]Epoch 14: Train Loss = 0.21149638295173645\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.193, train_loss_epoch=0.211]Epoch 15: Train Loss = 0.19348670542240143\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.200, train_loss_epoch=0.193]Epoch 16: Train Loss = 0.20046216249465942\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.191, train_loss_epoch=0.200]Epoch 17: Train Loss = 0.19123557209968567\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.200, train_loss_epoch=0.191]Epoch 18: Train Loss = 0.20010216534137726\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.176, train_loss_epoch=0.200]Epoch 19: Train Loss = 0.1757061928510666\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.168, train_loss_epoch=0.176]Epoch 20: Train Loss = 0.1680186241865158\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.178, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.17847667634487152\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.181, train_loss_epoch=0.178]Epoch 22: Train Loss = 0.1814558357000351\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.167, train_loss_epoch=0.181]Epoch 23: Train Loss = 0.16660746932029724\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.160, train_loss_epoch=0.167]Epoch 24: Train Loss = 0.16037671267986298\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.156, train_loss_epoch=0.160]Epoch 25: Train Loss = 0.15550272166728973\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.160, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.16023756563663483\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.153, train_loss_epoch=0.160]Epoch 27: Train Loss = 0.15331028401851654\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.147, train_loss_epoch=0.153]Epoch 28: Train Loss = 0.14676854014396667\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.147, train_loss_epoch=0.147]Epoch 29: Train Loss = 0.14679068326950073\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.140, train_loss_epoch=0.147]Epoch 30: Train Loss = 0.13991589844226837\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.143, train_loss_epoch=0.140]Epoch 31: Train Loss = 0.1426897943019867\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.140, train_loss_epoch=0.143]Epoch 32: Train Loss = 0.1399356871843338\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.132, train_loss_epoch=0.140]Epoch 33: Train Loss = 0.1323186457157135\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.134, train_loss_epoch=0.132]Epoch 34: Train Loss = 0.13446302711963654\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.132, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.1317499876022339\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.127, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.12737804651260376\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.129, train_loss_epoch=0.127]Epoch 37: Train Loss = 0.12896668910980225\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.123, train_loss_epoch=0.129]Epoch 38: Train Loss = 0.1230447068810463\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.117, train_loss_epoch=0.123]Epoch 39: Train Loss = 0.11715980619192123\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.116, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.1157180517911911\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.118, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11814335733652115\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.114, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.11425720900297165\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.110, train_loss_epoch=0.114]Epoch 43: Train Loss = 0.10993511974811554\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=232, train_loss_step=0.113, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11303531378507614\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.108, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10820075869560242\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.106, train_loss_epoch=0.108]Epoch 46: Train Loss = 0.10575991868972778\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.103, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.10250244289636612\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.102, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10191654413938522\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.104, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.10360351949930191\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0996, train_loss_epoch=0.104]Epoch 50: Train Loss = 0.09964507818222046\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0976, train_loss_epoch=0.0996]Epoch 51: Train Loss = 0.09760230034589767\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0957, train_loss_epoch=0.0976]Epoch 52: Train Loss = 0.095674529671669\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0935, train_loss_epoch=0.0957]Epoch 53: Train Loss = 0.09347202628850937\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0922, train_loss_epoch=0.0935]Epoch 54: Train Loss = 0.09219243377447128\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0919, train_loss_epoch=0.0922]Epoch 55: Train Loss = 0.091927669942379\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0901, train_loss_epoch=0.0919]Epoch 56: Train Loss = 0.09008622914552689\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0864, train_loss_epoch=0.0901]Epoch 57: Train Loss = 0.08638858795166016\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0878, train_loss_epoch=0.0864]Epoch 58: Train Loss = 0.08779565989971161\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0857, train_loss_epoch=0.0878]Epoch 59: Train Loss = 0.0857490673661232\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0837, train_loss_epoch=0.0857]Epoch 60: Train Loss = 0.0836583822965622\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.081, train_loss_epoch=0.0837] Epoch 61: Train Loss = 0.08101636916399002\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0805, train_loss_epoch=0.081]Epoch 62: Train Loss = 0.0804566815495491\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0799, train_loss_epoch=0.0805]Epoch 63: Train Loss = 0.0798983946442604\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0768, train_loss_epoch=0.0799]Epoch 64: Train Loss = 0.07675456255674362\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0771, train_loss_epoch=0.0768]Epoch 65: Train Loss = 0.07708058506250381\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0758, train_loss_epoch=0.0771]Epoch 66: Train Loss = 0.07578162103891373\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0764, train_loss_epoch=0.0758]Epoch 67: Train Loss = 0.07636930048465729\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0729, train_loss_epoch=0.0764]Epoch 68: Train Loss = 0.07291512191295624\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0716, train_loss_epoch=0.0729]Epoch 69: Train Loss = 0.07155093550682068\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0713, train_loss_epoch=0.0716]Epoch 70: Train Loss = 0.0713108628988266\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0729, train_loss_epoch=0.0713]Epoch 71: Train Loss = 0.07285726070404053\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0696, train_loss_epoch=0.0729]Epoch 72: Train Loss = 0.06958328187465668\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0758, train_loss_epoch=0.0696]Epoch 73: Train Loss = 0.07583437114953995\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0677, train_loss_epoch=0.0758]Epoch 74: Train Loss = 0.06768865883350372\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0699, train_loss_epoch=0.0677]Epoch 75: Train Loss = 0.06986302882432938\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0653, train_loss_epoch=0.0699]Epoch 76: Train Loss = 0.06529143452644348\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0661, train_loss_epoch=0.0653]Epoch 77: Train Loss = 0.06609256565570831\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0656, train_loss_epoch=0.0661]Epoch 78: Train Loss = 0.06558533012866974\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0646, train_loss_epoch=0.0656]Epoch 79: Train Loss = 0.06457550078630447\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0629, train_loss_epoch=0.0646]Epoch 80: Train Loss = 0.06287653744220734\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0637, train_loss_epoch=0.0629]Epoch 81: Train Loss = 0.06366114318370819\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.063, train_loss_epoch=0.0637] Epoch 82: Train Loss = 0.06303751468658447\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0641, train_loss_epoch=0.063]Epoch 83: Train Loss = 0.06409918516874313\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0602, train_loss_epoch=0.0641]Epoch 84: Train Loss = 0.06015670672059059\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0609, train_loss_epoch=0.0602]Epoch 85: Train Loss = 0.060851551592350006\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.059, train_loss_epoch=0.0609] Epoch 86: Train Loss = 0.05903787165880203\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0616, train_loss_epoch=0.059]Epoch 87: Train Loss = 0.06161383539438248\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.057, train_loss_epoch=0.0616] Epoch 88: Train Loss = 0.056998200714588165\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0576, train_loss_epoch=0.057]Epoch 89: Train Loss = 0.05755138397216797\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0601, train_loss_epoch=0.0576]Epoch 90: Train Loss = 0.06012069806456566\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0561, train_loss_epoch=0.0601]Epoch 91: Train Loss = 0.056127678602933884\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0546, train_loss_epoch=0.0561]Epoch 92: Train Loss = 0.05457345396280289\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0537, train_loss_epoch=0.0546]Epoch 93: Train Loss = 0.053663622587919235\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0539, train_loss_epoch=0.0537]Epoch 94: Train Loss = 0.05387480929493904\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0546, train_loss_epoch=0.0539]Epoch 95: Train Loss = 0.05463321879506111\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0541, train_loss_epoch=0.0546]Epoch 96: Train Loss = 0.05413328483700752\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0566, train_loss_epoch=0.0541]Epoch 97: Train Loss = 0.056556276977062225\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0535, train_loss_epoch=0.0566]Epoch 98: Train Loss = 0.05352306365966797\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0572, train_loss_epoch=0.0535]Epoch 99: Train Loss = 0.057233065366744995\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0521, train_loss_epoch=0.0572]Epoch 100: Train Loss = 0.052078936249017715\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0525, train_loss_epoch=0.0521]Epoch 101: Train Loss = 0.052499812096357346\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0504, train_loss_epoch=0.0525]Epoch 102: Train Loss = 0.050449930131435394\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0549, train_loss_epoch=0.0504]Epoch 103: Train Loss = 0.05493638291954994\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0496, train_loss_epoch=0.0549]Epoch 104: Train Loss = 0.049647413194179535\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0529, train_loss_epoch=0.0496]Epoch 105: Train Loss = 0.052909981459379196\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0513, train_loss_epoch=0.0529]Epoch 106: Train Loss = 0.051265276968479156\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0518, train_loss_epoch=0.0513]Epoch 107: Train Loss = 0.051814403384923935\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0522, train_loss_epoch=0.0518]Epoch 108: Train Loss = 0.05217459797859192\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0513, train_loss_epoch=0.0522]Epoch 109: Train Loss = 0.05131471902132034\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0497, train_loss_epoch=0.0513]Epoch 110: Train Loss = 0.04966406524181366\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0483, train_loss_epoch=0.0497]Epoch 111: Train Loss = 0.0482557937502861\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0489, train_loss_epoch=0.0483]Epoch 112: Train Loss = 0.048893146216869354\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.047, train_loss_epoch=0.0489] Epoch 113: Train Loss = 0.04696105793118477\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0482, train_loss_epoch=0.047]Epoch 114: Train Loss = 0.048181381076574326\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0467, train_loss_epoch=0.0482]Epoch 115: Train Loss = 0.04665236547589302\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.050, train_loss_epoch=0.0467] Epoch 116: Train Loss = 0.05002472922205925\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0463, train_loss_epoch=0.050]Epoch 117: Train Loss = 0.04627400264143944\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.048, train_loss_epoch=0.0463] Epoch 118: Train Loss = 0.047977931797504425\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0461, train_loss_epoch=0.048]Epoch 119: Train Loss = 0.04609110206365585\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0458, train_loss_epoch=0.0461]Epoch 120: Train Loss = 0.045826707035303116\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0449, train_loss_epoch=0.0458]Epoch 121: Train Loss = 0.044947125017642975\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0444, train_loss_epoch=0.0449]Epoch 122: Train Loss = 0.04443104565143585\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.044, train_loss_epoch=0.0444] Epoch 123: Train Loss = 0.04396441951394081\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0438, train_loss_epoch=0.044]Epoch 124: Train Loss = 0.04383666440844536\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0435, train_loss_epoch=0.0438]Epoch 125: Train Loss = 0.04346970096230507\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0439, train_loss_epoch=0.0435]Epoch 126: Train Loss = 0.04388820007443428\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0434, train_loss_epoch=0.0439]Epoch 127: Train Loss = 0.0434497632086277\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=232, train_loss_step=0.0427, train_loss_epoch=0.0434]Epoch 128: Train Loss = 0.04270115867257118\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0424, train_loss_epoch=0.0427]Epoch 129: Train Loss = 0.042406585067510605\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0416, train_loss_epoch=0.0424]Epoch 130: Train Loss = 0.04159068316221237\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.042, train_loss_epoch=0.0416] Epoch 131: Train Loss = 0.042030513286590576\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0431, train_loss_epoch=0.042]Epoch 132: Train Loss = 0.043144579976797104\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0413, train_loss_epoch=0.0431]Epoch 133: Train Loss = 0.04125320911407471\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0422, train_loss_epoch=0.0413]Epoch 134: Train Loss = 0.04220370575785637\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0418, train_loss_epoch=0.0422]Epoch 135: Train Loss = 0.041842952370643616\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0424, train_loss_epoch=0.0418]Epoch 136: Train Loss = 0.04241323471069336\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0403, train_loss_epoch=0.0424]Epoch 137: Train Loss = 0.040288787335157394\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0414, train_loss_epoch=0.0403]Epoch 138: Train Loss = 0.0414428785443306\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0403, train_loss_epoch=0.0414]Epoch 139: Train Loss = 0.04033806174993515\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0407, train_loss_epoch=0.0403]Epoch 140: Train Loss = 0.04065649211406708\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0401, train_loss_epoch=0.0407]Epoch 141: Train Loss = 0.04013288766145706\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0432, train_loss_epoch=0.0401]Epoch 142: Train Loss = 0.04324087128043175\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0397, train_loss_epoch=0.0432]Epoch 143: Train Loss = 0.03974071890115738\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0405, train_loss_epoch=0.0397]Epoch 144: Train Loss = 0.040458329021930695\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0398, train_loss_epoch=0.0405]Epoch 145: Train Loss = 0.039780087769031525\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0438, train_loss_epoch=0.0398]Epoch 146: Train Loss = 0.04379685968160629\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0386, train_loss_epoch=0.0438]Epoch 147: Train Loss = 0.03861217945814133\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0452, train_loss_epoch=0.0386]Epoch 148: Train Loss = 0.04522545263171196\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0378, train_loss_epoch=0.0452]Epoch 149: Train Loss = 0.03782052919268608\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0451, train_loss_epoch=0.0378]Epoch 150: Train Loss = 0.04508306458592415\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0378, train_loss_epoch=0.0451]Epoch 151: Train Loss = 0.03780439868569374\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.042, train_loss_epoch=0.0378] Epoch 152: Train Loss = 0.04195332154631615\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0392, train_loss_epoch=0.042]Epoch 153: Train Loss = 0.03921797126531601\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0439, train_loss_epoch=0.0392]Epoch 154: Train Loss = 0.04393434524536133\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0411, train_loss_epoch=0.0439]Epoch 155: Train Loss = 0.041113801300525665\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0413, train_loss_epoch=0.0411]Epoch 156: Train Loss = 0.04126961529254913\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0414, train_loss_epoch=0.0413]Epoch 157: Train Loss = 0.04137422889471054\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0378, train_loss_epoch=0.0414]Epoch 158: Train Loss = 0.03778696805238724\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0395, train_loss_epoch=0.0378]Epoch 159: Train Loss = 0.03951343148946762\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0367, train_loss_epoch=0.0395]Epoch 160: Train Loss = 0.03670908138155937\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0387, train_loss_epoch=0.0367]Epoch 161: Train Loss = 0.03866972401738167\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0366, train_loss_epoch=0.0387]Epoch 162: Train Loss = 0.03663627430796623\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0399, train_loss_epoch=0.0366]Epoch 163: Train Loss = 0.039857976138591766\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.036, train_loss_epoch=0.0399] Epoch 164: Train Loss = 0.036017514765262604\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0366, train_loss_epoch=0.036]Epoch 165: Train Loss = 0.036638643592596054\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0364, train_loss_epoch=0.0366]Epoch 166: Train Loss = 0.03640842065215111\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.036, train_loss_epoch=0.0364] Epoch 167: Train Loss = 0.03603098541498184\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0355, train_loss_epoch=0.036]Epoch 168: Train Loss = 0.035503700375556946\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0357, train_loss_epoch=0.0355]Epoch 169: Train Loss = 0.03569645434617996\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0371, train_loss_epoch=0.0357]Epoch 170: Train Loss = 0.03709758073091507\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0376, train_loss_epoch=0.0371]Epoch 171: Train Loss = 0.03755796700716019\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0419, train_loss_epoch=0.0376]Epoch 172: Train Loss = 0.04193292558193207\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0353, train_loss_epoch=0.0419]Epoch 173: Train Loss = 0.035318534821271896\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0356, train_loss_epoch=0.0353]Epoch 174: Train Loss = 0.035611484199762344\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0349, train_loss_epoch=0.0356]Epoch 175: Train Loss = 0.03489083796739578\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0352, train_loss_epoch=0.0349]Epoch 176: Train Loss = 0.035200539976358414\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0362, train_loss_epoch=0.0352]Epoch 177: Train Loss = 0.03623868152499199\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0361, train_loss_epoch=0.0362]Epoch 178: Train Loss = 0.0360582210123539\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0374, train_loss_epoch=0.0361]Epoch 179: Train Loss = 0.037416018545627594\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0353, train_loss_epoch=0.0374]Epoch 180: Train Loss = 0.03531946241855621\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0377, train_loss_epoch=0.0353]Epoch 181: Train Loss = 0.03773163631558418\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0348, train_loss_epoch=0.0377]Epoch 182: Train Loss = 0.03484911471605301\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0392, train_loss_epoch=0.0348]Epoch 183: Train Loss = 0.039169248193502426\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0379, train_loss_epoch=0.0392]Epoch 184: Train Loss = 0.03785044699907303\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0395, train_loss_epoch=0.0379]Epoch 185: Train Loss = 0.0395486056804657\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0407, train_loss_epoch=0.0395]Epoch 186: Train Loss = 0.04065462946891785\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0405, train_loss_epoch=0.0407]Epoch 187: Train Loss = 0.040453191846609116\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0406, train_loss_epoch=0.0405]Epoch 188: Train Loss = 0.04062207043170929\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0369, train_loss_epoch=0.0406]Epoch 189: Train Loss = 0.036927200853824615\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0405, train_loss_epoch=0.0369]Epoch 190: Train Loss = 0.04051796346902847\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0335, train_loss_epoch=0.0405]Epoch 191: Train Loss = 0.03352304548025131\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0444, train_loss_epoch=0.0335]Epoch 192: Train Loss = 0.044357430189847946\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0352, train_loss_epoch=0.0444]Epoch 193: Train Loss = 0.035208508372306824\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0353, train_loss_epoch=0.0352]Epoch 194: Train Loss = 0.0353073887526989\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0401, train_loss_epoch=0.0353]Epoch 195: Train Loss = 0.04007624834775925\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.034, train_loss_epoch=0.0401] Epoch 196: Train Loss = 0.03403562307357788\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0374, train_loss_epoch=0.034]Epoch 197: Train Loss = 0.03735363110899925\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0348, train_loss_epoch=0.0374]Epoch 198: Train Loss = 0.03479522839188576\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0369, train_loss_epoch=0.0348]Epoch 199: Train Loss = 0.03688553720712662\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0391, train_loss_epoch=0.0369]Epoch 200: Train Loss = 0.0390583761036396\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.037, train_loss_epoch=0.0391] Epoch 201: Train Loss = 0.03702868893742561\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0343, train_loss_epoch=0.037]Epoch 202: Train Loss = 0.03432435914874077\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0346, train_loss_epoch=0.0343]Epoch 203: Train Loss = 0.03455785661935806\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0417, train_loss_epoch=0.0346]Epoch 204: Train Loss = 0.041739895939826965\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.036, train_loss_epoch=0.0417] Epoch 205: Train Loss = 0.03603183850646019\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.040, train_loss_epoch=0.036] Epoch 206: Train Loss = 0.040043268352746964\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0377, train_loss_epoch=0.040]Epoch 207: Train Loss = 0.037666480988264084\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=232, train_loss_step=0.0331, train_loss_epoch=0.0377]Epoch 208: Train Loss = 0.03308568149805069\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0389, train_loss_epoch=0.0331]Epoch 209: Train Loss = 0.038939572870731354\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0339, train_loss_epoch=0.0389]Epoch 210: Train Loss = 0.03387731686234474\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0353, train_loss_epoch=0.0339]Epoch 211: Train Loss = 0.03532787412405014\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0342, train_loss_epoch=0.0353]Epoch 212: Train Loss = 0.03415677323937416\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0329, train_loss_epoch=0.0342]Epoch 213: Train Loss = 0.03288102149963379\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0347, train_loss_epoch=0.0329]Epoch 214: Train Loss = 0.03468348830938339\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0324, train_loss_epoch=0.0347]Epoch 215: Train Loss = 0.03235943987965584\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0327, train_loss_epoch=0.0324]Epoch 216: Train Loss = 0.03271732106804848\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0324, train_loss_epoch=0.0327]Epoch 217: Train Loss = 0.03244467452168465\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0318, train_loss_epoch=0.0324]Epoch 218: Train Loss = 0.0317535437643528\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0324, train_loss_epoch=0.0318]Epoch 219: Train Loss = 0.032376728951931\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0311, train_loss_epoch=0.0324]Epoch 220: Train Loss = 0.031068990007042885\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0344, train_loss_epoch=0.0311]Epoch 221: Train Loss = 0.0344175361096859\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0334, train_loss_epoch=0.0344]Epoch 222: Train Loss = 0.03337881341576576\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0334, train_loss_epoch=0.0334]Epoch 223: Train Loss = 0.03343338146805763\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0325, train_loss_epoch=0.0334]Epoch 224: Train Loss = 0.03252173215150833\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0324, train_loss_epoch=0.0325]Epoch 225: Train Loss = 0.03243178501725197\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0306, train_loss_epoch=0.0324]Epoch 226: Train Loss = 0.030554035678505898\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0313, train_loss_epoch=0.0306]Epoch 227: Train Loss = 0.031250108033418655\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0334, train_loss_epoch=0.0313]Epoch 228: Train Loss = 0.03338383510708809\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0327, train_loss_epoch=0.0334]Epoch 229: Train Loss = 0.03268556669354439\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.032, train_loss_epoch=0.0327] Epoch 230: Train Loss = 0.03195401653647423\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.031, train_loss_epoch=0.032] Epoch 231: Train Loss = 0.030986234545707703\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0309, train_loss_epoch=0.031]Epoch 232: Train Loss = 0.030919848009943962\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0322, train_loss_epoch=0.0309]Epoch 233: Train Loss = 0.03216264769434929\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0306, train_loss_epoch=0.0322]Epoch 234: Train Loss = 0.0305537898093462\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=232, train_loss_step=0.0324, train_loss_epoch=0.0306]Epoch 235: Train Loss = 0.032351624220609665\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0309, train_loss_epoch=0.0324]Epoch 236: Train Loss = 0.030910393223166466\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.033, train_loss_epoch=0.0309] Epoch 237: Train Loss = 0.03300371766090393\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0313, train_loss_epoch=0.033]Epoch 238: Train Loss = 0.031283557415008545\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=232, train_loss_step=0.031, train_loss_epoch=0.0313] Epoch 239: Train Loss = 0.031048400327563286\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0295, train_loss_epoch=0.031]Epoch 240: Train Loss = 0.029537126421928406\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0315, train_loss_epoch=0.0295]Epoch 241: Train Loss = 0.031504616141319275\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0314, train_loss_epoch=0.0315]Epoch 242: Train Loss = 0.031436774879693985\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0391, train_loss_epoch=0.0314]Epoch 243: Train Loss = 0.03912043571472168\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0301, train_loss_epoch=0.0391]Epoch 244: Train Loss = 0.030111096799373627\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0343, train_loss_epoch=0.0301]Epoch 245: Train Loss = 0.0343472845852375\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0328, train_loss_epoch=0.0343]Epoch 246: Train Loss = 0.032791104167699814\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0324, train_loss_epoch=0.0328]Epoch 247: Train Loss = 0.0324229970574379\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=232, train_loss_step=0.0368, train_loss_epoch=0.0324]Epoch 248: Train Loss = 0.03678275644779205\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0302, train_loss_epoch=0.0368]Epoch 249: Train Loss = 0.03018099069595337\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0302, train_loss_epoch=0.0302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=232, train_loss_step=0.0302, train_loss_epoch=0.0302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 24: from 1998-11-02 00:00:00 to 2022-08-12 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.400]Epoch 0: Train Loss = 0.39999550580978394\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.493, train_loss_epoch=0.400]Epoch 1: Train Loss = 0.49272868037223816\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.372, train_loss_epoch=0.493]Epoch 2: Train Loss = 0.37166628241539\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.251, train_loss_epoch=0.372]Epoch 3: Train Loss = 0.25121524930000305\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.307, train_loss_epoch=0.251]Epoch 4: Train Loss = 0.3067518174648285\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.317, train_loss_epoch=0.307]Epoch 5: Train Loss = 0.3166085183620453\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.257, train_loss_epoch=0.317]Epoch 6: Train Loss = 0.2573123574256897\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.242, train_loss_epoch=0.257]Epoch 7: Train Loss = 0.24224594235420227\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.272, train_loss_epoch=0.242]Epoch 8: Train Loss = 0.2718398869037628\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.263, train_loss_epoch=0.272]Epoch 9: Train Loss = 0.263460248708725\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.242, train_loss_epoch=0.263]Epoch 10: Train Loss = 0.2418435662984848\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.220, train_loss_epoch=0.242]Epoch 11: Train Loss = 0.21997614204883575\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.236, train_loss_epoch=0.220]Epoch 12: Train Loss = 0.23597657680511475\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.222, train_loss_epoch=0.236]Epoch 13: Train Loss = 0.2218862920999527\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.207, train_loss_epoch=0.222]Epoch 14: Train Loss = 0.20731718838214874\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.190, train_loss_epoch=0.207]Epoch 15: Train Loss = 0.1898890882730484\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.203, train_loss_epoch=0.190]Epoch 16: Train Loss = 0.20275487005710602\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.194, train_loss_epoch=0.203]Epoch 17: Train Loss = 0.1942390501499176\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.198, train_loss_epoch=0.194]Epoch 18: Train Loss = 0.19821320474147797\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.174, train_loss_epoch=0.198]Epoch 19: Train Loss = 0.17396916449069977\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.165, train_loss_epoch=0.174]Epoch 20: Train Loss = 0.16498109698295593\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.180, train_loss_epoch=0.165]Epoch 21: Train Loss = 0.18048831820487976\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.177, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.1773475557565689\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.167, train_loss_epoch=0.177]Epoch 23: Train Loss = 0.16665975749492645\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.161, train_loss_epoch=0.167]Epoch 24: Train Loss = 0.16115424036979675\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.158, train_loss_epoch=0.161]Epoch 25: Train Loss = 0.15792250633239746\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.163, train_loss_epoch=0.158]Epoch 26: Train Loss = 0.16300328075885773\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.154, train_loss_epoch=0.163]Epoch 27: Train Loss = 0.1540151685476303\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.146, train_loss_epoch=0.154]Epoch 28: Train Loss = 0.14621753990650177\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.149, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.1494022160768509\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.142, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.14215907454490662\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.144, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.1438884139060974\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.142, train_loss_epoch=0.144]Epoch 32: Train Loss = 0.14151909947395325\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.135, train_loss_epoch=0.142]Epoch 33: Train Loss = 0.13519537448883057\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.134, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13449852168560028\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.134, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.13393747806549072\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.130, train_loss_epoch=0.134]Epoch 36: Train Loss = 0.12993170320987701\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.129, train_loss_epoch=0.130]Epoch 37: Train Loss = 0.12906792759895325\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.124, train_loss_epoch=0.129]Epoch 38: Train Loss = 0.12363045662641525\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.119, train_loss_epoch=0.124]Epoch 39: Train Loss = 0.119016632437706\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.117, train_loss_epoch=0.119]Epoch 40: Train Loss = 0.11678747832775116\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.119, train_loss_epoch=0.117]Epoch 41: Train Loss = 0.11867459118366241\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.116, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.116084523499012\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.111, train_loss_epoch=0.116]Epoch 43: Train Loss = 0.11104179173707962\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.113, train_loss_epoch=0.111]Epoch 44: Train Loss = 0.11304119974374771\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.106, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10640985518693924\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.107, train_loss_epoch=0.106]Epoch 46: Train Loss = 0.10722309350967407\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.102, train_loss_epoch=0.107]Epoch 47: Train Loss = 0.10243476927280426\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.100, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.10017968714237213\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.103, train_loss_epoch=0.100]Epoch 49: Train Loss = 0.10295917093753815\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0991, train_loss_epoch=0.103]Epoch 50: Train Loss = 0.09911581128835678\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.097, train_loss_epoch=0.0991] Epoch 51: Train Loss = 0.0970311388373375\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0965, train_loss_epoch=0.097]Epoch 52: Train Loss = 0.09653940051794052\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0936, train_loss_epoch=0.0965]Epoch 53: Train Loss = 0.09364575892686844\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0936, train_loss_epoch=0.0936]Epoch 54: Train Loss = 0.0936291366815567\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0928, train_loss_epoch=0.0936]Epoch 55: Train Loss = 0.0927845910191536\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0919, train_loss_epoch=0.0928]Epoch 56: Train Loss = 0.091912642121315\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0872, train_loss_epoch=0.0919]Epoch 57: Train Loss = 0.0871792584657669\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0884, train_loss_epoch=0.0872]Epoch 58: Train Loss = 0.08835215121507645\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0852, train_loss_epoch=0.0884]Epoch 59: Train Loss = 0.08519165217876434\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0833, train_loss_epoch=0.0852]Epoch 60: Train Loss = 0.08332938700914383\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0823, train_loss_epoch=0.0833]Epoch 61: Train Loss = 0.08226736634969711\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=234, train_loss_step=0.0804, train_loss_epoch=0.0823]Epoch 62: Train Loss = 0.08036131411790848\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0796, train_loss_epoch=0.0804]Epoch 63: Train Loss = 0.0796002745628357\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0763, train_loss_epoch=0.0796]Epoch 64: Train Loss = 0.07631544023752213\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0777, train_loss_epoch=0.0763]Epoch 65: Train Loss = 0.07769424468278885\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0759, train_loss_epoch=0.0777]Epoch 66: Train Loss = 0.0759381577372551\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0759, train_loss_epoch=0.0759]Epoch 67: Train Loss = 0.07585420459508896\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0749, train_loss_epoch=0.0759]Epoch 68: Train Loss = 0.07487610727548599\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0714, train_loss_epoch=0.0749]Epoch 69: Train Loss = 0.07139217108488083\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0716, train_loss_epoch=0.0714]Epoch 70: Train Loss = 0.07163123041391373\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.070, train_loss_epoch=0.0716] Epoch 71: Train Loss = 0.07003413885831833\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0687, train_loss_epoch=0.070]Epoch 72: Train Loss = 0.06866494566202164\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0682, train_loss_epoch=0.0687]Epoch 73: Train Loss = 0.06820597499608994\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0719, train_loss_epoch=0.0682]Epoch 74: Train Loss = 0.0719398781657219\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.068, train_loss_epoch=0.0719] Epoch 75: Train Loss = 0.06796345859766006\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0683, train_loss_epoch=0.068]Epoch 76: Train Loss = 0.06831463426351547\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0665, train_loss_epoch=0.0683]Epoch 77: Train Loss = 0.06649380922317505\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0701, train_loss_epoch=0.0665]Epoch 78: Train Loss = 0.07011641561985016\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0635, train_loss_epoch=0.0701]Epoch 79: Train Loss = 0.06354464590549469\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=234, train_loss_step=0.0681, train_loss_epoch=0.0635]Epoch 80: Train Loss = 0.06807901710271835\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0623, train_loss_epoch=0.0681]Epoch 81: Train Loss = 0.062303364276885986\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0671, train_loss_epoch=0.0623]Epoch 82: Train Loss = 0.06712993234395981\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0613, train_loss_epoch=0.0671]Epoch 83: Train Loss = 0.06129860877990723\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0632, train_loss_epoch=0.0613]Epoch 84: Train Loss = 0.06321000307798386\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=234, train_loss_step=0.0604, train_loss_epoch=0.0632]Epoch 85: Train Loss = 0.06040269881486893\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0606, train_loss_epoch=0.0604]Epoch 86: Train Loss = 0.0605538971722126\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0593, train_loss_epoch=0.0606]Epoch 87: Train Loss = 0.0592503696680069\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.059, train_loss_epoch=0.0593] Epoch 88: Train Loss = 0.05899864062666893\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0578, train_loss_epoch=0.059]Epoch 89: Train Loss = 0.05776039510965347\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0579, train_loss_epoch=0.0578]Epoch 90: Train Loss = 0.057932548224925995\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0576, train_loss_epoch=0.0579]Epoch 91: Train Loss = 0.05758172646164894\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0591, train_loss_epoch=0.0576]Epoch 92: Train Loss = 0.05909278243780136\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0552, train_loss_epoch=0.0591]Epoch 93: Train Loss = 0.05519389733672142\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0554, train_loss_epoch=0.0552]Epoch 94: Train Loss = 0.05537901073694229\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0563, train_loss_epoch=0.0554]Epoch 95: Train Loss = 0.056325893849134445\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0583, train_loss_epoch=0.0563]Epoch 96: Train Loss = 0.05829606205224991\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0531, train_loss_epoch=0.0583]Epoch 97: Train Loss = 0.053115248680114746\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0542, train_loss_epoch=0.0531]Epoch 98: Train Loss = 0.054217126220464706\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0521, train_loss_epoch=0.0542]Epoch 99: Train Loss = 0.05207861214876175\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0516, train_loss_epoch=0.0521]Epoch 100: Train Loss = 0.0516483373939991\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0523, train_loss_epoch=0.0516]Epoch 101: Train Loss = 0.05229875072836876\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0496, train_loss_epoch=0.0523]Epoch 102: Train Loss = 0.049560293555259705\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0503, train_loss_epoch=0.0496]Epoch 103: Train Loss = 0.05027918145060539\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0501, train_loss_epoch=0.0503]Epoch 104: Train Loss = 0.05011116713285446\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0486, train_loss_epoch=0.0501]Epoch 105: Train Loss = 0.04863778501749039\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0531, train_loss_epoch=0.0486]Epoch 106: Train Loss = 0.053077924996614456\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0529, train_loss_epoch=0.0531]Epoch 107: Train Loss = 0.05290047451853752\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0498, train_loss_epoch=0.0529]Epoch 108: Train Loss = 0.04976831004023552\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0514, train_loss_epoch=0.0498]Epoch 109: Train Loss = 0.05143408104777336\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0487, train_loss_epoch=0.0514]Epoch 110: Train Loss = 0.048724643886089325\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0516, train_loss_epoch=0.0487]Epoch 111: Train Loss = 0.051568616181612015\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0489, train_loss_epoch=0.0516]Epoch 112: Train Loss = 0.04885781928896904\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0504, train_loss_epoch=0.0489]Epoch 113: Train Loss = 0.05036565288901329\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0478, train_loss_epoch=0.0504]Epoch 114: Train Loss = 0.04782241955399513\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0496, train_loss_epoch=0.0478]Epoch 115: Train Loss = 0.04956882447004318\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0488, train_loss_epoch=0.0496]Epoch 116: Train Loss = 0.04879792407155037\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0511, train_loss_epoch=0.0488]Epoch 117: Train Loss = 0.05105733871459961\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0483, train_loss_epoch=0.0511]Epoch 118: Train Loss = 0.0483153872191906\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0524, train_loss_epoch=0.0483]Epoch 119: Train Loss = 0.052436474710702896\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0456, train_loss_epoch=0.0524]Epoch 120: Train Loss = 0.045642055571079254\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0469, train_loss_epoch=0.0456]Epoch 121: Train Loss = 0.046874769032001495\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0495, train_loss_epoch=0.0469]Epoch 122: Train Loss = 0.049545712769031525\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0453, train_loss_epoch=0.0495]Epoch 123: Train Loss = 0.04527927190065384\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0458, train_loss_epoch=0.0453]Epoch 124: Train Loss = 0.045836132019758224\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0446, train_loss_epoch=0.0458]Epoch 125: Train Loss = 0.04460962116718292\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0431, train_loss_epoch=0.0446]Epoch 126: Train Loss = 0.043093398213386536\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0435, train_loss_epoch=0.0431]Epoch 127: Train Loss = 0.04353255406022072\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0438, train_loss_epoch=0.0435]Epoch 128: Train Loss = 0.04381405562162399\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0432, train_loss_epoch=0.0438]Epoch 129: Train Loss = 0.04322524741292\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.045, train_loss_epoch=0.0432] Epoch 130: Train Loss = 0.04501328617334366\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0431, train_loss_epoch=0.045]Epoch 131: Train Loss = 0.043051157146692276\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.044, train_loss_epoch=0.0431] Epoch 132: Train Loss = 0.04399484768509865\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0415, train_loss_epoch=0.044]Epoch 133: Train Loss = 0.04153336584568024\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0438, train_loss_epoch=0.0415]Epoch 134: Train Loss = 0.04379099979996681\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0444, train_loss_epoch=0.0438]Epoch 135: Train Loss = 0.04444244131445885\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0441, train_loss_epoch=0.0444]Epoch 136: Train Loss = 0.044116292148828506\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0461, train_loss_epoch=0.0441]Epoch 137: Train Loss = 0.04612215980887413\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0405, train_loss_epoch=0.0461]Epoch 138: Train Loss = 0.04047678783535957\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0473, train_loss_epoch=0.0405]Epoch 139: Train Loss = 0.047319620847702026\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0445, train_loss_epoch=0.0473]Epoch 140: Train Loss = 0.04452155530452728\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0483, train_loss_epoch=0.0445]Epoch 141: Train Loss = 0.04833255335688591\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0446, train_loss_epoch=0.0483]Epoch 142: Train Loss = 0.04455319792032242\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0404, train_loss_epoch=0.0446]Epoch 143: Train Loss = 0.04038055241107941\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0479, train_loss_epoch=0.0404]Epoch 144: Train Loss = 0.047873519361019135\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0404, train_loss_epoch=0.0479]Epoch 145: Train Loss = 0.040419794619083405\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0419, train_loss_epoch=0.0404]Epoch 146: Train Loss = 0.04189208894968033\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0474, train_loss_epoch=0.0419]Epoch 147: Train Loss = 0.047374896705150604\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0403, train_loss_epoch=0.0474]Epoch 148: Train Loss = 0.04030206426978111\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0456, train_loss_epoch=0.0403]Epoch 149: Train Loss = 0.045634809881448746\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0394, train_loss_epoch=0.0456]Epoch 150: Train Loss = 0.03943881392478943\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0444, train_loss_epoch=0.0394]Epoch 151: Train Loss = 0.04435427486896515\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0398, train_loss_epoch=0.0444]Epoch 152: Train Loss = 0.03981340304017067\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0414, train_loss_epoch=0.0398]Epoch 153: Train Loss = 0.041365738958120346\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0415, train_loss_epoch=0.0414]Epoch 154: Train Loss = 0.04150304198265076\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0389, train_loss_epoch=0.0415]Epoch 155: Train Loss = 0.03892350196838379\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0489, train_loss_epoch=0.0389]Epoch 156: Train Loss = 0.04886394366621971\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0392, train_loss_epoch=0.0489]Epoch 157: Train Loss = 0.03919794410467148\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0422, train_loss_epoch=0.0392]Epoch 158: Train Loss = 0.04219767823815346\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=234, train_loss_step=0.0429, train_loss_epoch=0.0422]Epoch 159: Train Loss = 0.042910218238830566\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0381, train_loss_epoch=0.0429]Epoch 160: Train Loss = 0.03813975304365158\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0429, train_loss_epoch=0.0381]Epoch 161: Train Loss = 0.042915843427181244\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0397, train_loss_epoch=0.0429]Epoch 162: Train Loss = 0.03966977819800377\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.039, train_loss_epoch=0.0397] Epoch 163: Train Loss = 0.03898527845740318\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0482, train_loss_epoch=0.039]Epoch 164: Train Loss = 0.048171333968639374\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0373, train_loss_epoch=0.0482]Epoch 165: Train Loss = 0.03726131469011307\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0454, train_loss_epoch=0.0373]Epoch 166: Train Loss = 0.045440223067998886\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0366, train_loss_epoch=0.0454]Epoch 167: Train Loss = 0.036589980125427246\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0378, train_loss_epoch=0.0366]Epoch 168: Train Loss = 0.03776642680168152\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0364, train_loss_epoch=0.0378]Epoch 169: Train Loss = 0.03642774745821953\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0366, train_loss_epoch=0.0364]Epoch 170: Train Loss = 0.03656616061925888\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0369, train_loss_epoch=0.0366]Epoch 171: Train Loss = 0.03692714124917984\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0357, train_loss_epoch=0.0369]Epoch 172: Train Loss = 0.035727981477975845\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0365, train_loss_epoch=0.0357]Epoch 173: Train Loss = 0.03651951625943184\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0366, train_loss_epoch=0.0365]Epoch 174: Train Loss = 0.03660966828465462\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0373, train_loss_epoch=0.0366]Epoch 175: Train Loss = 0.03731554374098778\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0368, train_loss_epoch=0.0373]Epoch 176: Train Loss = 0.03679010644555092\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0356, train_loss_epoch=0.0368]Epoch 177: Train Loss = 0.03560832142829895\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.038, train_loss_epoch=0.0356] Epoch 178: Train Loss = 0.03802330791950226\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0361, train_loss_epoch=0.038]Epoch 179: Train Loss = 0.03607926890254021\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0365, train_loss_epoch=0.0361]Epoch 180: Train Loss = 0.03646673634648323\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0361, train_loss_epoch=0.0365]Epoch 181: Train Loss = 0.036096274852752686\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0374, train_loss_epoch=0.0361]Epoch 182: Train Loss = 0.03740398585796356\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0361, train_loss_epoch=0.0374]Epoch 183: Train Loss = 0.03607887774705887\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0353, train_loss_epoch=0.0361]Epoch 184: Train Loss = 0.03527213633060455\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0352, train_loss_epoch=0.0353]Epoch 185: Train Loss = 0.03516054525971413\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0368, train_loss_epoch=0.0352]Epoch 186: Train Loss = 0.036808643490076065\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0366, train_loss_epoch=0.0368]Epoch 187: Train Loss = 0.036619771271944046\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0377, train_loss_epoch=0.0366]Epoch 188: Train Loss = 0.037744153290987015\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0372, train_loss_epoch=0.0377]Epoch 189: Train Loss = 0.03724879398941994\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0359, train_loss_epoch=0.0372]Epoch 190: Train Loss = 0.03585159033536911\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0392, train_loss_epoch=0.0359]Epoch 191: Train Loss = 0.039238911122083664\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.035, train_loss_epoch=0.0392] Epoch 192: Train Loss = 0.0350492037832737\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0371, train_loss_epoch=0.035]Epoch 193: Train Loss = 0.03714722394943237\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0383, train_loss_epoch=0.0371]Epoch 194: Train Loss = 0.038298554718494415\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0346, train_loss_epoch=0.0383]Epoch 195: Train Loss = 0.034604862332344055\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0411, train_loss_epoch=0.0346]Epoch 196: Train Loss = 0.041131529957056046\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0356, train_loss_epoch=0.0411]Epoch 197: Train Loss = 0.03558060899376869\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0362, train_loss_epoch=0.0356]Epoch 198: Train Loss = 0.03620345517992973\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0394, train_loss_epoch=0.0362]Epoch 199: Train Loss = 0.039353273808956146\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0339, train_loss_epoch=0.0394]Epoch 200: Train Loss = 0.0338803194463253\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0391, train_loss_epoch=0.0339]Epoch 201: Train Loss = 0.03905690088868141\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0349, train_loss_epoch=0.0391]Epoch 202: Train Loss = 0.03491680696606636\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.035, train_loss_epoch=0.0349] Epoch 203: Train Loss = 0.03501582145690918\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0377, train_loss_epoch=0.035]Epoch 204: Train Loss = 0.03766497224569321\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0338, train_loss_epoch=0.0377]Epoch 205: Train Loss = 0.03384668752551079\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0344, train_loss_epoch=0.0338]Epoch 206: Train Loss = 0.03444262221455574\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.034, train_loss_epoch=0.0344] Epoch 207: Train Loss = 0.034048788249492645\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0344, train_loss_epoch=0.034]Epoch 208: Train Loss = 0.0344238318502903\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0372, train_loss_epoch=0.0344]Epoch 209: Train Loss = 0.03721339628100395\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0355, train_loss_epoch=0.0372]Epoch 210: Train Loss = 0.03549756482243538\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0333, train_loss_epoch=0.0355]Epoch 211: Train Loss = 0.033320169895887375\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0377, train_loss_epoch=0.0333]Epoch 212: Train Loss = 0.03771117702126503\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0334, train_loss_epoch=0.0377]Epoch 213: Train Loss = 0.033361274749040604\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=234, train_loss_step=0.0373, train_loss_epoch=0.0334]Epoch 214: Train Loss = 0.03726629540324211\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0339, train_loss_epoch=0.0373]Epoch 215: Train Loss = 0.03391899913549423\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0365, train_loss_epoch=0.0339]Epoch 216: Train Loss = 0.03653097152709961\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0342, train_loss_epoch=0.0365]Epoch 217: Train Loss = 0.034158747643232346\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0342, train_loss_epoch=0.0342]Epoch 218: Train Loss = 0.03416687995195389\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0335, train_loss_epoch=0.0342]Epoch 219: Train Loss = 0.03349817171692848\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0336, train_loss_epoch=0.0335]Epoch 220: Train Loss = 0.03358755633234978\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0353, train_loss_epoch=0.0336]Epoch 221: Train Loss = 0.03530697152018547\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0332, train_loss_epoch=0.0353]Epoch 222: Train Loss = 0.03323604166507721\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0346, train_loss_epoch=0.0332]Epoch 223: Train Loss = 0.034648023545742035\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0325, train_loss_epoch=0.0346]Epoch 224: Train Loss = 0.03245561197400093\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0354, train_loss_epoch=0.0325]Epoch 225: Train Loss = 0.03536945581436157\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0309, train_loss_epoch=0.0354]Epoch 226: Train Loss = 0.030945945531129837\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0325, train_loss_epoch=0.0309]Epoch 227: Train Loss = 0.032467760145664215\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0357, train_loss_epoch=0.0325]Epoch 228: Train Loss = 0.03568371385335922\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0319, train_loss_epoch=0.0357]Epoch 229: Train Loss = 0.031916432082653046\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0335, train_loss_epoch=0.0319]Epoch 230: Train Loss = 0.033467847853899\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0316, train_loss_epoch=0.0335]Epoch 231: Train Loss = 0.03161025792360306\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0325, train_loss_epoch=0.0316]Epoch 232: Train Loss = 0.03251264989376068\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=234, train_loss_step=0.0332, train_loss_epoch=0.0325]Epoch 233: Train Loss = 0.03322994336485863\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0326, train_loss_epoch=0.0332]Epoch 234: Train Loss = 0.032566580921411514\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0318, train_loss_epoch=0.0326]Epoch 235: Train Loss = 0.031765952706336975\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0319, train_loss_epoch=0.0318]Epoch 236: Train Loss = 0.03186394274234772\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0332, train_loss_epoch=0.0319]Epoch 237: Train Loss = 0.03321445360779762\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0326, train_loss_epoch=0.0332]Epoch 238: Train Loss = 0.03257068246603012\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0349, train_loss_epoch=0.0326]Epoch 239: Train Loss = 0.03486975282430649\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0313, train_loss_epoch=0.0349]Epoch 240: Train Loss = 0.0312950536608696\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=234, train_loss_step=0.0313, train_loss_epoch=0.0313]Epoch 241: Train Loss = 0.03128428757190704\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=234, train_loss_step=0.0316, train_loss_epoch=0.0313]Epoch 242: Train Loss = 0.03155118227005005\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0306, train_loss_epoch=0.0316]Epoch 243: Train Loss = 0.030646856874227524\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0308, train_loss_epoch=0.0306]Epoch 244: Train Loss = 0.030789272859692574\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0315, train_loss_epoch=0.0308]Epoch 245: Train Loss = 0.03148098289966583\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.0314, train_loss_epoch=0.0315]Epoch 246: Train Loss = 0.03138766437768936\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0315, train_loss_epoch=0.0314]Epoch 247: Train Loss = 0.03146114572882652\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=234, train_loss_step=0.031, train_loss_epoch=0.0315] Epoch 248: Train Loss = 0.0310423094779253\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0316, train_loss_epoch=0.031]Epoch 249: Train Loss = 0.03158339858055115\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0316, train_loss_epoch=0.0316]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=234, train_loss_step=0.0316, train_loss_epoch=0.0316]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 25: from 1998-11-02 00:00:00 to 2022-08-23 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.398]Epoch 0: Train Loss = 0.3983854651451111\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.493, train_loss_epoch=0.398]Epoch 1: Train Loss = 0.49328118562698364\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.367, train_loss_epoch=0.493]Epoch 2: Train Loss = 0.36735546588897705\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.246, train_loss_epoch=0.367]Epoch 3: Train Loss = 0.2457781881093979\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.308, train_loss_epoch=0.246]Epoch 4: Train Loss = 0.3079400658607483\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.308, train_loss_epoch=0.308]Epoch 5: Train Loss = 0.3079266846179962\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.255, train_loss_epoch=0.308]Epoch 6: Train Loss = 0.255452424287796\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.244, train_loss_epoch=0.255]Epoch 7: Train Loss = 0.24359256029129028\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.266, train_loss_epoch=0.244]Epoch 8: Train Loss = 0.2660387456417084\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.255, train_loss_epoch=0.266]Epoch 9: Train Loss = 0.25478941202163696\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.244, train_loss_epoch=0.255]Epoch 10: Train Loss = 0.24440760910511017\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.223, train_loss_epoch=0.244]Epoch 11: Train Loss = 0.22292809188365936\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.233, train_loss_epoch=0.223]Epoch 12: Train Loss = 0.23266038298606873\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.221, train_loss_epoch=0.233]Epoch 13: Train Loss = 0.22133241593837738\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.208, train_loss_epoch=0.221]Epoch 14: Train Loss = 0.20754596590995789\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.193, train_loss_epoch=0.208]Epoch 15: Train Loss = 0.19341178238391876\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=236, train_loss_step=0.199, train_loss_epoch=0.193]Epoch 16: Train Loss = 0.19915834069252014\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.193, train_loss_epoch=0.199]Epoch 17: Train Loss = 0.1932041049003601\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.200, train_loss_epoch=0.193]Epoch 18: Train Loss = 0.1998957395553589\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.175, train_loss_epoch=0.200]Epoch 19: Train Loss = 0.17483142018318176\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.167, train_loss_epoch=0.175]Epoch 20: Train Loss = 0.16749811172485352\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.180, train_loss_epoch=0.167]Epoch 21: Train Loss = 0.17969197034835815\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.181, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.1813729703426361\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.165, train_loss_epoch=0.181]Epoch 23: Train Loss = 0.16458258032798767\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.159, train_loss_epoch=0.165]Epoch 24: Train Loss = 0.15868452191352844\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.160, train_loss_epoch=0.159]Epoch 25: Train Loss = 0.1600826382637024\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.162, train_loss_epoch=0.160]Epoch 26: Train Loss = 0.16158385574817657\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.152, train_loss_epoch=0.162]Epoch 27: Train Loss = 0.1524956375360489\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.146, train_loss_epoch=0.152]Epoch 28: Train Loss = 0.1456362009048462\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.149, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.14907781779766083\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.142, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.14215432107448578\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.147, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.14687731862068176\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.138, train_loss_epoch=0.147]Epoch 32: Train Loss = 0.1379241943359375\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.137, train_loss_epoch=0.138]Epoch 33: Train Loss = 0.13659748435020447\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.137, train_loss_epoch=0.137]Epoch 34: Train Loss = 0.13659167289733887\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.132, train_loss_epoch=0.137]Epoch 35: Train Loss = 0.13197439908981323\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.131, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.13084398210048676\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.131, train_loss_epoch=0.131]Epoch 37: Train Loss = 0.13133592903614044\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.125, train_loss_epoch=0.131]Epoch 38: Train Loss = 0.12467706203460693\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.120, train_loss_epoch=0.125]Epoch 39: Train Loss = 0.1204175129532814\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.116, train_loss_epoch=0.120]Epoch 40: Train Loss = 0.11647334694862366\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.119, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11884443461894989\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.116, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.11550207436084747\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.110, train_loss_epoch=0.116]Epoch 43: Train Loss = 0.11002648621797562\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.115, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11464594304561615\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.107, train_loss_epoch=0.115]Epoch 45: Train Loss = 0.10666771233081818\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.106, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10611815005540848\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.104, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.10410518944263458\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.103, train_loss_epoch=0.104]Epoch 48: Train Loss = 0.10307002812623978\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.102, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.10248119384050369\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0995, train_loss_epoch=0.102]Epoch 50: Train Loss = 0.09948598593473434\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0989, train_loss_epoch=0.0995]Epoch 51: Train Loss = 0.09888540953397751\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0955, train_loss_epoch=0.0989]Epoch 52: Train Loss = 0.0955248773097992\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0936, train_loss_epoch=0.0955]Epoch 53: Train Loss = 0.09359133243560791\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=236, train_loss_step=0.0937, train_loss_epoch=0.0936]Epoch 54: Train Loss = 0.09373555332422256\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0915, train_loss_epoch=0.0937]Epoch 55: Train Loss = 0.09150731563568115\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0908, train_loss_epoch=0.0915]Epoch 56: Train Loss = 0.09082406014204025\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0875, train_loss_epoch=0.0908]Epoch 57: Train Loss = 0.08754609525203705\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0875, train_loss_epoch=0.0875]Epoch 58: Train Loss = 0.08752846717834473\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0856, train_loss_epoch=0.0875]Epoch 59: Train Loss = 0.08560048788785934\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.084, train_loss_epoch=0.0856] Epoch 60: Train Loss = 0.08398640155792236\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0819, train_loss_epoch=0.084]Epoch 61: Train Loss = 0.0819038674235344\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0817, train_loss_epoch=0.0819]Epoch 62: Train Loss = 0.08170964568853378\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0802, train_loss_epoch=0.0817]Epoch 63: Train Loss = 0.0802035704255104\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0775, train_loss_epoch=0.0802]Epoch 64: Train Loss = 0.07750425487756729\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.079, train_loss_epoch=0.0775] Epoch 65: Train Loss = 0.07904110848903656\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0762, train_loss_epoch=0.079]Epoch 66: Train Loss = 0.0762179046869278\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0821, train_loss_epoch=0.0762]Epoch 67: Train Loss = 0.08207415044307709\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=236, train_loss_step=0.0738, train_loss_epoch=0.0821]Epoch 68: Train Loss = 0.07377953827381134\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0775, train_loss_epoch=0.0738]Epoch 69: Train Loss = 0.07750175893306732\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.073, train_loss_epoch=0.0775] Epoch 70: Train Loss = 0.07304935902357101\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0784, train_loss_epoch=0.073]Epoch 71: Train Loss = 0.07840856164693832\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0723, train_loss_epoch=0.0784]Epoch 72: Train Loss = 0.07226937264204025\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0717, train_loss_epoch=0.0723]Epoch 73: Train Loss = 0.07167354971170425\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0761, train_loss_epoch=0.0717]Epoch 74: Train Loss = 0.07605365663766861\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0669, train_loss_epoch=0.0761]Epoch 75: Train Loss = 0.06685996055603027\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0752, train_loss_epoch=0.0669]Epoch 76: Train Loss = 0.07519294321537018\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0709, train_loss_epoch=0.0752]Epoch 77: Train Loss = 0.0708967074751854\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0689, train_loss_epoch=0.0709]Epoch 78: Train Loss = 0.06889545172452927\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0724, train_loss_epoch=0.0689]Epoch 79: Train Loss = 0.07240626960992813\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0645, train_loss_epoch=0.0724]Epoch 80: Train Loss = 0.06451572477817535\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0693, train_loss_epoch=0.0645]Epoch 81: Train Loss = 0.06925655901432037\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0669, train_loss_epoch=0.0693]Epoch 82: Train Loss = 0.06686532497406006\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.064, train_loss_epoch=0.0669] Epoch 83: Train Loss = 0.06398236006498337\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=236, train_loss_step=0.0668, train_loss_epoch=0.064]Epoch 84: Train Loss = 0.06684236228466034\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0616, train_loss_epoch=0.0668]Epoch 85: Train Loss = 0.06159959360957146\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0614, train_loss_epoch=0.0616]Epoch 86: Train Loss = 0.06142377480864525\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0635, train_loss_epoch=0.0614]Epoch 87: Train Loss = 0.06353693455457687\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.060, train_loss_epoch=0.0635] Epoch 88: Train Loss = 0.05998677387833595\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0632, train_loss_epoch=0.060]Epoch 89: Train Loss = 0.06319799274206161\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0591, train_loss_epoch=0.0632]Epoch 90: Train Loss = 0.05907287448644638\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0641, train_loss_epoch=0.0591]Epoch 91: Train Loss = 0.06409687548875809\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0564, train_loss_epoch=0.0641]Epoch 92: Train Loss = 0.05642842873930931\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0564, train_loss_epoch=0.0564]Epoch 93: Train Loss = 0.05635742098093033\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0574, train_loss_epoch=0.0564]Epoch 94: Train Loss = 0.05739152804017067\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0559, train_loss_epoch=0.0574]Epoch 95: Train Loss = 0.05589579418301582\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0559, train_loss_epoch=0.0559]Epoch 96: Train Loss = 0.05588147044181824\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0553, train_loss_epoch=0.0559]Epoch 97: Train Loss = 0.05533071979880333\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.056, train_loss_epoch=0.0553] Epoch 98: Train Loss = 0.05599987134337425\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0547, train_loss_epoch=0.056]Epoch 99: Train Loss = 0.05468657985329628\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0541, train_loss_epoch=0.0547]Epoch 100: Train Loss = 0.0540800616145134\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0536, train_loss_epoch=0.0541]Epoch 101: Train Loss = 0.05364718660712242\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0523, train_loss_epoch=0.0536]Epoch 102: Train Loss = 0.05231112241744995\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0513, train_loss_epoch=0.0523]Epoch 103: Train Loss = 0.05131126940250397\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0517, train_loss_epoch=0.0513]Epoch 104: Train Loss = 0.05168341472744942\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0515, train_loss_epoch=0.0517]Epoch 105: Train Loss = 0.05147941783070564\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0519, train_loss_epoch=0.0515]Epoch 106: Train Loss = 0.05190299078822136\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0518, train_loss_epoch=0.0519]Epoch 107: Train Loss = 0.05176163464784622\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0513, train_loss_epoch=0.0518]Epoch 108: Train Loss = 0.051284339278936386\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0525, train_loss_epoch=0.0513]Epoch 109: Train Loss = 0.05246376618742943\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.050, train_loss_epoch=0.0525] Epoch 110: Train Loss = 0.050044797360897064\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0515, train_loss_epoch=0.050]Epoch 111: Train Loss = 0.05147339776158333\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0493, train_loss_epoch=0.0515]Epoch 112: Train Loss = 0.04929855838418007\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0487, train_loss_epoch=0.0493]Epoch 113: Train Loss = 0.04871494323015213\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=236, train_loss_step=0.0475, train_loss_epoch=0.0487]Epoch 114: Train Loss = 0.0475262813270092\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0495, train_loss_epoch=0.0475]Epoch 115: Train Loss = 0.049541618674993515\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0477, train_loss_epoch=0.0495]Epoch 116: Train Loss = 0.0476643443107605\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0473, train_loss_epoch=0.0477]Epoch 117: Train Loss = 0.04734315350651741\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0467, train_loss_epoch=0.0473]Epoch 118: Train Loss = 0.04673393815755844\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0483, train_loss_epoch=0.0467]Epoch 119: Train Loss = 0.04827779158949852\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0467, train_loss_epoch=0.0483]Epoch 120: Train Loss = 0.04672565311193466\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0493, train_loss_epoch=0.0467]Epoch 121: Train Loss = 0.0493176244199276\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0459, train_loss_epoch=0.0493]Epoch 122: Train Loss = 0.0459442213177681\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0479, train_loss_epoch=0.0459]Epoch 123: Train Loss = 0.04792030528187752\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0452, train_loss_epoch=0.0479]Epoch 124: Train Loss = 0.0452311635017395\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0502, train_loss_epoch=0.0452]Epoch 125: Train Loss = 0.05019889026880264\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=236, train_loss_step=0.0447, train_loss_epoch=0.0502]Epoch 126: Train Loss = 0.04473315179347992\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0484, train_loss_epoch=0.0447]Epoch 127: Train Loss = 0.048412855714559555\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0441, train_loss_epoch=0.0484]Epoch 128: Train Loss = 0.044116146862506866\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0512, train_loss_epoch=0.0441]Epoch 129: Train Loss = 0.05124204233288765\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.044, train_loss_epoch=0.0512] Epoch 130: Train Loss = 0.043982040137052536\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0481, train_loss_epoch=0.044]Epoch 131: Train Loss = 0.0480891689658165\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0464, train_loss_epoch=0.0481]Epoch 132: Train Loss = 0.04638863354921341\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0433, train_loss_epoch=0.0464]Epoch 133: Train Loss = 0.04332930967211723\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0449, train_loss_epoch=0.0433]Epoch 134: Train Loss = 0.04491109773516655\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0429, train_loss_epoch=0.0449]Epoch 135: Train Loss = 0.04292628541588783\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0467, train_loss_epoch=0.0429]Epoch 136: Train Loss = 0.046662140637636185\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0428, train_loss_epoch=0.0467]Epoch 137: Train Loss = 0.042795974761247635\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0441, train_loss_epoch=0.0428]Epoch 138: Train Loss = 0.04408811777830124\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.042, train_loss_epoch=0.0441] Epoch 139: Train Loss = 0.04203960672020912\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0422, train_loss_epoch=0.042]Epoch 140: Train Loss = 0.042217519134283066\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0416, train_loss_epoch=0.0422]Epoch 141: Train Loss = 0.04155012220144272\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0419, train_loss_epoch=0.0416]Epoch 142: Train Loss = 0.04191738739609718\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0423, train_loss_epoch=0.0419]Epoch 143: Train Loss = 0.042262542992830276\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0405, train_loss_epoch=0.0423]Epoch 144: Train Loss = 0.040512390434741974\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0434, train_loss_epoch=0.0405]Epoch 145: Train Loss = 0.043397851288318634\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0421, train_loss_epoch=0.0434]Epoch 146: Train Loss = 0.04214559122920036\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0448, train_loss_epoch=0.0421]Epoch 147: Train Loss = 0.04480509087443352\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0445, train_loss_epoch=0.0448]Epoch 148: Train Loss = 0.04450133070349693\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0387, train_loss_epoch=0.0445]Epoch 149: Train Loss = 0.03867606073617935\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0393, train_loss_epoch=0.0387]Epoch 150: Train Loss = 0.039276283234357834\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=236, train_loss_step=0.0425, train_loss_epoch=0.0393]Epoch 151: Train Loss = 0.04248757287859917\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0396, train_loss_epoch=0.0425]Epoch 152: Train Loss = 0.03963301703333855\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0406, train_loss_epoch=0.0396]Epoch 153: Train Loss = 0.040641069412231445\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0471, train_loss_epoch=0.0406]Epoch 154: Train Loss = 0.04708026722073555\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0421, train_loss_epoch=0.0471]Epoch 155: Train Loss = 0.042059239000082016\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.047, train_loss_epoch=0.0421] Epoch 156: Train Loss = 0.046960778534412384\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.039, train_loss_epoch=0.047] Epoch 157: Train Loss = 0.038980644196271896\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0455, train_loss_epoch=0.039]Epoch 158: Train Loss = 0.045494046062231064\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0417, train_loss_epoch=0.0455]Epoch 159: Train Loss = 0.04172318056225777\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0416, train_loss_epoch=0.0417]Epoch 160: Train Loss = 0.041589342057704926\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0421, train_loss_epoch=0.0416]Epoch 161: Train Loss = 0.04211365431547165\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0375, train_loss_epoch=0.0421]Epoch 162: Train Loss = 0.0374503992497921\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0406, train_loss_epoch=0.0375]Epoch 163: Train Loss = 0.04055943712592125\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=236, train_loss_step=0.0407, train_loss_epoch=0.0406]Epoch 164: Train Loss = 0.04074067622423172\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0403, train_loss_epoch=0.0407]Epoch 165: Train Loss = 0.040328361093997955\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0409, train_loss_epoch=0.0403]Epoch 166: Train Loss = 0.040864646434783936\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=236, train_loss_step=0.0393, train_loss_epoch=0.0409]Epoch 167: Train Loss = 0.03925866633653641\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0371, train_loss_epoch=0.0393]Epoch 168: Train Loss = 0.03714781627058983\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0365, train_loss_epoch=0.0371]Epoch 169: Train Loss = 0.03653896972537041\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0372, train_loss_epoch=0.0365]Epoch 170: Train Loss = 0.03723898530006409\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0368, train_loss_epoch=0.0372]Epoch 171: Train Loss = 0.036787234246730804\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0374, train_loss_epoch=0.0368]Epoch 172: Train Loss = 0.037399861961603165\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0416, train_loss_epoch=0.0374]Epoch 173: Train Loss = 0.041594285517930984\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0387, train_loss_epoch=0.0416]Epoch 174: Train Loss = 0.03869204968214035\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0456, train_loss_epoch=0.0387]Epoch 175: Train Loss = 0.045642707496881485\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0379, train_loss_epoch=0.0456]Epoch 176: Train Loss = 0.03787903115153313\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0431, train_loss_epoch=0.0379]Epoch 177: Train Loss = 0.043059173971414566\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0366, train_loss_epoch=0.0431]Epoch 178: Train Loss = 0.03655054047703743\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0431, train_loss_epoch=0.0366]Epoch 179: Train Loss = 0.0430607944726944\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0373, train_loss_epoch=0.0431]Epoch 180: Train Loss = 0.03728242963552475\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0368, train_loss_epoch=0.0373]Epoch 181: Train Loss = 0.036842938512563705\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0407, train_loss_epoch=0.0368]Epoch 182: Train Loss = 0.04071703925728798\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0362, train_loss_epoch=0.0407]Epoch 183: Train Loss = 0.03624247759580612\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0359, train_loss_epoch=0.0362]Epoch 184: Train Loss = 0.03589684143662453\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0388, train_loss_epoch=0.0359]Epoch 185: Train Loss = 0.03877498209476471\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0366, train_loss_epoch=0.0388]Epoch 186: Train Loss = 0.03659796342253685\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.038, train_loss_epoch=0.0366] Epoch 187: Train Loss = 0.03802993521094322\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.034, train_loss_epoch=0.038] Epoch 188: Train Loss = 0.03395312651991844\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0381, train_loss_epoch=0.034]Epoch 189: Train Loss = 0.03809123858809471\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0365, train_loss_epoch=0.0381]Epoch 190: Train Loss = 0.0364595465362072\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0358, train_loss_epoch=0.0365]Epoch 191: Train Loss = 0.03577965497970581\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0382, train_loss_epoch=0.0358]Epoch 192: Train Loss = 0.03816702961921692\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0348, train_loss_epoch=0.0382]Epoch 193: Train Loss = 0.03482372686266899\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0379, train_loss_epoch=0.0348]Epoch 194: Train Loss = 0.037877049297094345\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0344, train_loss_epoch=0.0379]Epoch 195: Train Loss = 0.03443462401628494\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0352, train_loss_epoch=0.0344]Epoch 196: Train Loss = 0.035236604511737823\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0346, train_loss_epoch=0.0352]Epoch 197: Train Loss = 0.03459491208195686\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0351, train_loss_epoch=0.0346]Epoch 198: Train Loss = 0.03509565442800522\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0349, train_loss_epoch=0.0351]Epoch 199: Train Loss = 0.03494773805141449\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0333, train_loss_epoch=0.0349]Epoch 200: Train Loss = 0.03328755125403404\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0335, train_loss_epoch=0.0333]Epoch 201: Train Loss = 0.033503610640764236\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0343, train_loss_epoch=0.0335]Epoch 202: Train Loss = 0.0343342050909996\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=236, train_loss_step=0.0336, train_loss_epoch=0.0343]Epoch 203: Train Loss = 0.033550288528203964\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0358, train_loss_epoch=0.0336]Epoch 204: Train Loss = 0.0358274020254612\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0335, train_loss_epoch=0.0358]Epoch 205: Train Loss = 0.03348084166646004\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0332, train_loss_epoch=0.0335]Epoch 206: Train Loss = 0.03320621699094772\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=236, train_loss_step=0.0338, train_loss_epoch=0.0332]Epoch 207: Train Loss = 0.0337955616414547\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0331, train_loss_epoch=0.0338]Epoch 208: Train Loss = 0.033072128891944885\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0335, train_loss_epoch=0.0331]Epoch 209: Train Loss = 0.03346678242087364\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=236, train_loss_step=0.0345, train_loss_epoch=0.0335]Epoch 210: Train Loss = 0.03448599949479103\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0337, train_loss_epoch=0.0345]Epoch 211: Train Loss = 0.03373647853732109\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0335, train_loss_epoch=0.0337]Epoch 212: Train Loss = 0.03345339372754097\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0363, train_loss_epoch=0.0335]Epoch 213: Train Loss = 0.03625253587961197\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0331, train_loss_epoch=0.0363]Epoch 214: Train Loss = 0.033066995441913605\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0325, train_loss_epoch=0.0331]Epoch 215: Train Loss = 0.032458823174238205\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0334, train_loss_epoch=0.0325]Epoch 216: Train Loss = 0.03335763141512871\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0323, train_loss_epoch=0.0334]Epoch 217: Train Loss = 0.03230999410152435\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0341, train_loss_epoch=0.0323]Epoch 218: Train Loss = 0.034102655947208405\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.0328, train_loss_epoch=0.0341]Epoch 219: Train Loss = 0.032766636461019516\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=236, train_loss_step=0.0335, train_loss_epoch=0.0328]Epoch 220: Train Loss = 0.033532410860061646\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0318, train_loss_epoch=0.0335]Epoch 221: Train Loss = 0.031840503215789795\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0326, train_loss_epoch=0.0318]Epoch 222: Train Loss = 0.032555658370256424\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0337, train_loss_epoch=0.0326]Epoch 223: Train Loss = 0.03372124582529068\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0329, train_loss_epoch=0.0337]Epoch 224: Train Loss = 0.03288189694285393\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.039, train_loss_epoch=0.0329] Epoch 225: Train Loss = 0.03903106227517128\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0324, train_loss_epoch=0.039]Epoch 226: Train Loss = 0.03242915868759155\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0338, train_loss_epoch=0.0324]Epoch 227: Train Loss = 0.03379688784480095\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0351, train_loss_epoch=0.0338]Epoch 228: Train Loss = 0.0350923128426075\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=236, train_loss_step=0.036, train_loss_epoch=0.0351] Epoch 229: Train Loss = 0.03596922382712364\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.034, train_loss_epoch=0.036] Epoch 230: Train Loss = 0.033956971019506454\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0313, train_loss_epoch=0.034]Epoch 231: Train Loss = 0.03127635270357132\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.033, train_loss_epoch=0.0313] Epoch 232: Train Loss = 0.032952483743429184\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0326, train_loss_epoch=0.033]Epoch 233: Train Loss = 0.0325985923409462\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0329, train_loss_epoch=0.0326]Epoch 234: Train Loss = 0.03292336314916611\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0342, train_loss_epoch=0.0329]Epoch 235: Train Loss = 0.03417382761836052\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0327, train_loss_epoch=0.0342]Epoch 236: Train Loss = 0.03266748785972595\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0326, train_loss_epoch=0.0327]Epoch 237: Train Loss = 0.03260746970772743\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0356, train_loss_epoch=0.0326]Epoch 238: Train Loss = 0.0356091745197773\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0328, train_loss_epoch=0.0356]Epoch 239: Train Loss = 0.03277894854545593\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0345, train_loss_epoch=0.0328]Epoch 240: Train Loss = 0.03445913642644882\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0307, train_loss_epoch=0.0345]Epoch 241: Train Loss = 0.03069581463932991\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=236, train_loss_step=0.0336, train_loss_epoch=0.0307]Epoch 242: Train Loss = 0.03358757123351097\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0346, train_loss_epoch=0.0336]Epoch 243: Train Loss = 0.03457728028297424\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0348, train_loss_epoch=0.0346]Epoch 244: Train Loss = 0.034751150757074356\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0362, train_loss_epoch=0.0348]Epoch 245: Train Loss = 0.03622114658355713\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0313, train_loss_epoch=0.0362]Epoch 246: Train Loss = 0.03128939867019653\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=236, train_loss_step=0.0362, train_loss_epoch=0.0313]Epoch 247: Train Loss = 0.036198824644088745\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=236, train_loss_step=0.0318, train_loss_epoch=0.0362]Epoch 248: Train Loss = 0.031787801533937454\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=236, train_loss_step=0.0398, train_loss_epoch=0.0318]Epoch 249: Train Loss = 0.03976676985621452\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=236, train_loss_step=0.0398, train_loss_epoch=0.0398]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=236, train_loss_step=0.0398, train_loss_epoch=0.0398]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 26: from 1998-11-02 00:00:00 to 2022-09-01 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.404]Epoch 0: Train Loss = 0.4038998484611511\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.496, train_loss_epoch=0.404]Epoch 1: Train Loss = 0.4958254098892212\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.378, train_loss_epoch=0.496]Epoch 2: Train Loss = 0.3775010406970978\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.251, train_loss_epoch=0.378]Epoch 3: Train Loss = 0.25147104263305664\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.305, train_loss_epoch=0.251]Epoch 4: Train Loss = 0.3045746684074402\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.311, train_loss_epoch=0.305]Epoch 5: Train Loss = 0.31135010719299316\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.257, train_loss_epoch=0.311]Epoch 6: Train Loss = 0.2573576271533966\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.240, train_loss_epoch=0.257]Epoch 7: Train Loss = 0.23977959156036377\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.262, train_loss_epoch=0.240]Epoch 8: Train Loss = 0.2624838054180145\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.260, train_loss_epoch=0.262]Epoch 9: Train Loss = 0.26032155752182007\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.241, train_loss_epoch=0.260]Epoch 10: Train Loss = 0.24149931967258453\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.219, train_loss_epoch=0.241]Epoch 11: Train Loss = 0.2189367264509201\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.232, train_loss_epoch=0.219]Epoch 12: Train Loss = 0.2322983294725418\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.222, train_loss_epoch=0.232]Epoch 13: Train Loss = 0.22204473614692688\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.217, train_loss_epoch=0.222]Epoch 14: Train Loss = 0.21727780997753143\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.193, train_loss_epoch=0.217]Epoch 15: Train Loss = 0.19339169561862946\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.200, train_loss_epoch=0.193]Epoch 16: Train Loss = 0.19991518557071686\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.190, train_loss_epoch=0.200]Epoch 17: Train Loss = 0.19036437571048737\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.201, train_loss_epoch=0.190]Epoch 18: Train Loss = 0.20096668601036072\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.181, train_loss_epoch=0.201]Epoch 19: Train Loss = 0.1807992309331894\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.168, train_loss_epoch=0.181]Epoch 20: Train Loss = 0.16810423135757446\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.179, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.17853893339633942\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.181, train_loss_epoch=0.179]Epoch 22: Train Loss = 0.18145252764225006\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.169, train_loss_epoch=0.181]Epoch 23: Train Loss = 0.1692001223564148\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.162, train_loss_epoch=0.169]Epoch 24: Train Loss = 0.16165371239185333\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.156, train_loss_epoch=0.162]Epoch 25: Train Loss = 0.1556343138217926\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.161, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.16082584857940674\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.157, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.15651001036167145\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.149, train_loss_epoch=0.157]Epoch 28: Train Loss = 0.14922617375850677\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.152, train_loss_epoch=0.149]Epoch 29: Train Loss = 0.1516455113887787\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.142, train_loss_epoch=0.152]Epoch 30: Train Loss = 0.14249634742736816\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.144, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.1436372697353363\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.143, train_loss_epoch=0.144]Epoch 32: Train Loss = 0.14317022264003754\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.135, train_loss_epoch=0.143]Epoch 33: Train Loss = 0.13487718999385834\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.137, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.1369764506816864\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.136, train_loss_epoch=0.137]Epoch 35: Train Loss = 0.13611362874507904\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.133, train_loss_epoch=0.136]Epoch 36: Train Loss = 0.1325235515832901\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.133, train_loss_epoch=0.133]Epoch 37: Train Loss = 0.13272781670093536\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.125, train_loss_epoch=0.133]Epoch 38: Train Loss = 0.12501727044582367\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.121, train_loss_epoch=0.125]Epoch 39: Train Loss = 0.12117408961057663\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.117, train_loss_epoch=0.121]Epoch 40: Train Loss = 0.11732377856969833\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.120, train_loss_epoch=0.117]Epoch 41: Train Loss = 0.12031044065952301\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.118, train_loss_epoch=0.120]Epoch 42: Train Loss = 0.11848770081996918\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.112, train_loss_epoch=0.118]Epoch 43: Train Loss = 0.11209660768508911\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.116, train_loss_epoch=0.112]Epoch 44: Train Loss = 0.11622439324855804\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.107, train_loss_epoch=0.116]Epoch 45: Train Loss = 0.10722412914037704\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.108, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10830014199018478\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.103, train_loss_epoch=0.108]Epoch 47: Train Loss = 0.10342736542224884\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.104, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10382496565580368\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.105, train_loss_epoch=0.104]Epoch 49: Train Loss = 0.10548597574234009\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0996, train_loss_epoch=0.105]Epoch 50: Train Loss = 0.09963329136371613\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0985, train_loss_epoch=0.0996]Epoch 51: Train Loss = 0.09847082197666168\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0983, train_loss_epoch=0.0985]Epoch 52: Train Loss = 0.09832296520471573\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.095, train_loss_epoch=0.0983] Epoch 53: Train Loss = 0.0950050875544548\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0949, train_loss_epoch=0.095]Epoch 54: Train Loss = 0.09485559910535812\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0935, train_loss_epoch=0.0949]Epoch 55: Train Loss = 0.09350838512182236\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0906, train_loss_epoch=0.0935]Epoch 56: Train Loss = 0.09059649705886841\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0888, train_loss_epoch=0.0906]Epoch 57: Train Loss = 0.08883192390203476\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.089, train_loss_epoch=0.0888] Epoch 58: Train Loss = 0.08895399421453476\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0868, train_loss_epoch=0.089]Epoch 59: Train Loss = 0.08682011067867279\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0859, train_loss_epoch=0.0868]Epoch 60: Train Loss = 0.08590341359376907\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0825, train_loss_epoch=0.0859]Epoch 61: Train Loss = 0.08245411515235901\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0821, train_loss_epoch=0.0825]Epoch 62: Train Loss = 0.0821002647280693\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0809, train_loss_epoch=0.0821]Epoch 63: Train Loss = 0.08087269216775894\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0787, train_loss_epoch=0.0809]Epoch 64: Train Loss = 0.07872450351715088\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.080, train_loss_epoch=0.0787] Epoch 65: Train Loss = 0.08003511279821396\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0783, train_loss_epoch=0.080]Epoch 66: Train Loss = 0.07827528566122055\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0787, train_loss_epoch=0.0783]Epoch 67: Train Loss = 0.07871423661708832\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0749, train_loss_epoch=0.0787]Epoch 68: Train Loss = 0.07488282769918442\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0738, train_loss_epoch=0.0749]Epoch 69: Train Loss = 0.07375786453485489\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0734, train_loss_epoch=0.0738]Epoch 70: Train Loss = 0.07344544678926468\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0725, train_loss_epoch=0.0734]Epoch 71: Train Loss = 0.07252784818410873\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0699, train_loss_epoch=0.0725]Epoch 72: Train Loss = 0.06985093653202057\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0711, train_loss_epoch=0.0699]Epoch 73: Train Loss = 0.07111003249883652\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0707, train_loss_epoch=0.0711]Epoch 74: Train Loss = 0.0706615298986435\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0696, train_loss_epoch=0.0707]Epoch 75: Train Loss = 0.06960579752922058\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.067, train_loss_epoch=0.0696] Epoch 76: Train Loss = 0.06697209179401398\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0678, train_loss_epoch=0.067]Epoch 77: Train Loss = 0.0678260326385498\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0677, train_loss_epoch=0.0678]Epoch 78: Train Loss = 0.06771504878997803\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0651, train_loss_epoch=0.0677]Epoch 79: Train Loss = 0.06513816118240356\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0642, train_loss_epoch=0.0651]Epoch 80: Train Loss = 0.06417889893054962\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0635, train_loss_epoch=0.0642]Epoch 81: Train Loss = 0.06347642093896866\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0645, train_loss_epoch=0.0635]Epoch 82: Train Loss = 0.06453340500593185\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0616, train_loss_epoch=0.0645]Epoch 83: Train Loss = 0.0615883469581604\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0634, train_loss_epoch=0.0616]Epoch 84: Train Loss = 0.06342150270938873\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0603, train_loss_epoch=0.0634]Epoch 85: Train Loss = 0.06033705919981003\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0606, train_loss_epoch=0.0603]Epoch 86: Train Loss = 0.06056510657072067\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.059, train_loss_epoch=0.0606] Epoch 87: Train Loss = 0.059000253677368164\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0583, train_loss_epoch=0.059]Epoch 88: Train Loss = 0.05825885012745857\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0573, train_loss_epoch=0.0583]Epoch 89: Train Loss = 0.05726730078458786\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.058, train_loss_epoch=0.0573] Epoch 90: Train Loss = 0.05796579644083977\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0562, train_loss_epoch=0.058]Epoch 91: Train Loss = 0.05619122087955475\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0563, train_loss_epoch=0.0562]Epoch 92: Train Loss = 0.056335870176553726\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0554, train_loss_epoch=0.0563]Epoch 93: Train Loss = 0.05543765425682068\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0558, train_loss_epoch=0.0554]Epoch 94: Train Loss = 0.05577103793621063\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0534, train_loss_epoch=0.0558]Epoch 95: Train Loss = 0.053447164595127106\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0546, train_loss_epoch=0.0534]Epoch 96: Train Loss = 0.05457456409931183\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0535, train_loss_epoch=0.0546]Epoch 97: Train Loss = 0.053465720266103745\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0537, train_loss_epoch=0.0535]Epoch 98: Train Loss = 0.05374927073717117\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0524, train_loss_epoch=0.0537]Epoch 99: Train Loss = 0.05237508937716484\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0523, train_loss_epoch=0.0524]Epoch 100: Train Loss = 0.05234721675515175\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0536, train_loss_epoch=0.0523]Epoch 101: Train Loss = 0.05356656387448311\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0501, train_loss_epoch=0.0536]Epoch 102: Train Loss = 0.050115931779146194\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0494, train_loss_epoch=0.0501]Epoch 103: Train Loss = 0.049405183643102646\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0501, train_loss_epoch=0.0494]Epoch 104: Train Loss = 0.050121892243623734\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0487, train_loss_epoch=0.0501]Epoch 105: Train Loss = 0.04871576651930809\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0501, train_loss_epoch=0.0487]Epoch 106: Train Loss = 0.0500883087515831\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0492, train_loss_epoch=0.0501]Epoch 107: Train Loss = 0.04922695830464363\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0484, train_loss_epoch=0.0492]Epoch 108: Train Loss = 0.04844038933515549\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0478, train_loss_epoch=0.0484]Epoch 109: Train Loss = 0.04777902737259865\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0481, train_loss_epoch=0.0478]Epoch 110: Train Loss = 0.048075612634420395\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.047, train_loss_epoch=0.0481] Epoch 111: Train Loss = 0.04703423008322716\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0462, train_loss_epoch=0.047]Epoch 112: Train Loss = 0.04616692289710045\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0465, train_loss_epoch=0.0462]Epoch 113: Train Loss = 0.04646427556872368\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0465, train_loss_epoch=0.0465]Epoch 114: Train Loss = 0.0465049110352993\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=238, train_loss_step=0.0465, train_loss_epoch=0.0465]Epoch 115: Train Loss = 0.04654916003346443\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0446, train_loss_epoch=0.0465]Epoch 116: Train Loss = 0.04455789551138878\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0444, train_loss_epoch=0.0446]Epoch 117: Train Loss = 0.04436064139008522\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0443, train_loss_epoch=0.0444]Epoch 118: Train Loss = 0.04434794932603836\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0449, train_loss_epoch=0.0443]Epoch 119: Train Loss = 0.04492543265223503\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0427, train_loss_epoch=0.0449]Epoch 120: Train Loss = 0.04269512742757797\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0435, train_loss_epoch=0.0427]Epoch 121: Train Loss = 0.043457161635160446\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0442, train_loss_epoch=0.0435]Epoch 122: Train Loss = 0.04416900500655174\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0435, train_loss_epoch=0.0442]Epoch 123: Train Loss = 0.04351145401597023\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0445, train_loss_epoch=0.0435]Epoch 124: Train Loss = 0.04449821636080742\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0477, train_loss_epoch=0.0445]Epoch 125: Train Loss = 0.04768196493387222\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0417, train_loss_epoch=0.0477]Epoch 126: Train Loss = 0.041730355471372604\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.043, train_loss_epoch=0.0417] Epoch 127: Train Loss = 0.04297969862818718\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0414, train_loss_epoch=0.043]Epoch 128: Train Loss = 0.04140402749180794\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0441, train_loss_epoch=0.0414]Epoch 129: Train Loss = 0.04405570402741432\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0404, train_loss_epoch=0.0441]Epoch 130: Train Loss = 0.040403109043836594\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0421, train_loss_epoch=0.0404]Epoch 131: Train Loss = 0.04211268201470375\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0435, train_loss_epoch=0.0421]Epoch 132: Train Loss = 0.04351319745182991\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0405, train_loss_epoch=0.0435]Epoch 133: Train Loss = 0.040453169494867325\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0408, train_loss_epoch=0.0405]Epoch 134: Train Loss = 0.04081449285149574\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0401, train_loss_epoch=0.0408]Epoch 135: Train Loss = 0.04009591042995453\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0408, train_loss_epoch=0.0401]Epoch 136: Train Loss = 0.04082683473825455\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0404, train_loss_epoch=0.0408]Epoch 137: Train Loss = 0.04039531946182251\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0401, train_loss_epoch=0.0404]Epoch 138: Train Loss = 0.040141768753528595\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0403, train_loss_epoch=0.0401]Epoch 139: Train Loss = 0.04032289236783981\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0389, train_loss_epoch=0.0403]Epoch 140: Train Loss = 0.038850799202919006\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0423, train_loss_epoch=0.0389]Epoch 141: Train Loss = 0.04233003035187721\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0462, train_loss_epoch=0.0423]Epoch 142: Train Loss = 0.046218596398830414\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0409, train_loss_epoch=0.0462]Epoch 143: Train Loss = 0.04085426405072212\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0484, train_loss_epoch=0.0409]Epoch 144: Train Loss = 0.04839712008833885\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.040, train_loss_epoch=0.0484] Epoch 145: Train Loss = 0.039965447038412094\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0555, train_loss_epoch=0.040]Epoch 146: Train Loss = 0.05546931177377701\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0392, train_loss_epoch=0.0555]Epoch 147: Train Loss = 0.0392286442220211\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0527, train_loss_epoch=0.0392]Epoch 148: Train Loss = 0.05266621336340904\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0387, train_loss_epoch=0.0527]Epoch 149: Train Loss = 0.03874523565173149\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0432, train_loss_epoch=0.0387]Epoch 150: Train Loss = 0.043221235275268555\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0389, train_loss_epoch=0.0432]Epoch 151: Train Loss = 0.038851432502269745\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0369, train_loss_epoch=0.0389]Epoch 152: Train Loss = 0.036943309009075165\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0383, train_loss_epoch=0.0369]Epoch 153: Train Loss = 0.03832840174436569\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0381, train_loss_epoch=0.0383]Epoch 154: Train Loss = 0.03806222230195999\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0376, train_loss_epoch=0.0381]Epoch 155: Train Loss = 0.03756321594119072\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.038, train_loss_epoch=0.0376] Epoch 156: Train Loss = 0.03797050565481186\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0404, train_loss_epoch=0.038]Epoch 157: Train Loss = 0.04041465371847153\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0362, train_loss_epoch=0.0404]Epoch 158: Train Loss = 0.036218080669641495\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0361, train_loss_epoch=0.0362]Epoch 159: Train Loss = 0.03611163794994354\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0361, train_loss_epoch=0.0361]Epoch 160: Train Loss = 0.03613715618848801\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0369, train_loss_epoch=0.0361]Epoch 161: Train Loss = 0.036946214735507965\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0365, train_loss_epoch=0.0369]Epoch 162: Train Loss = 0.03649796545505524\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.036, train_loss_epoch=0.0365] Epoch 163: Train Loss = 0.036032259464263916\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0355, train_loss_epoch=0.036]Epoch 164: Train Loss = 0.035509489476680756\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0358, train_loss_epoch=0.0355]Epoch 165: Train Loss = 0.03579295799136162\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0345, train_loss_epoch=0.0358]Epoch 166: Train Loss = 0.03449983894824982\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.034, train_loss_epoch=0.0345] Epoch 167: Train Loss = 0.034034647047519684\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0343, train_loss_epoch=0.034]Epoch 168: Train Loss = 0.03428506851196289\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0362, train_loss_epoch=0.0343]Epoch 169: Train Loss = 0.03615983575582504\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.035, train_loss_epoch=0.0362] Epoch 170: Train Loss = 0.0349971204996109\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0344, train_loss_epoch=0.035]Epoch 171: Train Loss = 0.034441035240888596\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0352, train_loss_epoch=0.0344]Epoch 172: Train Loss = 0.035165369510650635\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0366, train_loss_epoch=0.0352]Epoch 173: Train Loss = 0.03661289066076279\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0341, train_loss_epoch=0.0366]Epoch 174: Train Loss = 0.03410256654024124\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0352, train_loss_epoch=0.0341]Epoch 175: Train Loss = 0.03524455055594444\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0347, train_loss_epoch=0.0352]Epoch 176: Train Loss = 0.03468773514032364\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0382, train_loss_epoch=0.0347]Epoch 177: Train Loss = 0.03824255242943764\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0352, train_loss_epoch=0.0382]Epoch 178: Train Loss = 0.03522738069295883\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0348, train_loss_epoch=0.0352]Epoch 179: Train Loss = 0.0347922183573246\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0344, train_loss_epoch=0.0348]Epoch 180: Train Loss = 0.03436058387160301\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0372, train_loss_epoch=0.0344]Epoch 181: Train Loss = 0.03721483424305916\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.034, train_loss_epoch=0.0372] Epoch 182: Train Loss = 0.03399054333567619\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0359, train_loss_epoch=0.034]Epoch 183: Train Loss = 0.035865090787410736\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0367, train_loss_epoch=0.0359]Epoch 184: Train Loss = 0.03671654313802719\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0424, train_loss_epoch=0.0367]Epoch 185: Train Loss = 0.042445361614227295\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0343, train_loss_epoch=0.0424]Epoch 186: Train Loss = 0.034288663417100906\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0408, train_loss_epoch=0.0343]Epoch 187: Train Loss = 0.040790293365716934\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0341, train_loss_epoch=0.0408]Epoch 188: Train Loss = 0.03406339883804321\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=238, train_loss_step=0.0425, train_loss_epoch=0.0341]Epoch 189: Train Loss = 0.04249880090355873\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=238, train_loss_step=0.0349, train_loss_epoch=0.0425]Epoch 190: Train Loss = 0.03485315293073654\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0439, train_loss_epoch=0.0349]Epoch 191: Train Loss = 0.043914224952459335\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=238, train_loss_step=0.0338, train_loss_epoch=0.0439]Epoch 192: Train Loss = 0.033843833953142166\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0381, train_loss_epoch=0.0338]Epoch 193: Train Loss = 0.0381123311817646\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0359, train_loss_epoch=0.0381]Epoch 194: Train Loss = 0.035869549959897995\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0367, train_loss_epoch=0.0359]Epoch 195: Train Loss = 0.03669101744890213\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0348, train_loss_epoch=0.0367]Epoch 196: Train Loss = 0.034799687564373016\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0344, train_loss_epoch=0.0348]Epoch 197: Train Loss = 0.034392524510622025\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0357, train_loss_epoch=0.0344]Epoch 198: Train Loss = 0.03573068976402283\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0326, train_loss_epoch=0.0357]Epoch 199: Train Loss = 0.03264360502362251\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0416, train_loss_epoch=0.0326]Epoch 200: Train Loss = 0.04160207509994507\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0329, train_loss_epoch=0.0416]Epoch 201: Train Loss = 0.03286481276154518\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0387, train_loss_epoch=0.0329]Epoch 202: Train Loss = 0.03874938562512398\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0375, train_loss_epoch=0.0387]Epoch 203: Train Loss = 0.03750639036297798\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0382, train_loss_epoch=0.0375]Epoch 204: Train Loss = 0.03815177455544472\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0365, train_loss_epoch=0.0382]Epoch 205: Train Loss = 0.03647755831480026\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0324, train_loss_epoch=0.0365]Epoch 206: Train Loss = 0.03235339745879173\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0354, train_loss_epoch=0.0324]Epoch 207: Train Loss = 0.03537682443857193\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0327, train_loss_epoch=0.0354]Epoch 208: Train Loss = 0.032723840326070786\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0339, train_loss_epoch=0.0327]Epoch 209: Train Loss = 0.03394487872719765\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0329, train_loss_epoch=0.0339]Epoch 210: Train Loss = 0.03286951035261154\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0317, train_loss_epoch=0.0329]Epoch 211: Train Loss = 0.031702399253845215\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0336, train_loss_epoch=0.0317]Epoch 212: Train Loss = 0.033612534403800964\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0331, train_loss_epoch=0.0336]Epoch 213: Train Loss = 0.033104948699474335\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0322, train_loss_epoch=0.0331]Epoch 214: Train Loss = 0.0321936197578907\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0328, train_loss_epoch=0.0322]Epoch 215: Train Loss = 0.03284813463687897\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0362, train_loss_epoch=0.0328]Epoch 216: Train Loss = 0.0361970029771328\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0325, train_loss_epoch=0.0362]Epoch 217: Train Loss = 0.03249978646636009\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0335, train_loss_epoch=0.0325]Epoch 218: Train Loss = 0.033486347645521164\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0356, train_loss_epoch=0.0335]Epoch 219: Train Loss = 0.0356157086789608\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0317, train_loss_epoch=0.0356]Epoch 220: Train Loss = 0.031725965440273285\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0334, train_loss_epoch=0.0317]Epoch 221: Train Loss = 0.03340434283018112\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0326, train_loss_epoch=0.0334]Epoch 222: Train Loss = 0.032593511044979095\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0333, train_loss_epoch=0.0326]Epoch 223: Train Loss = 0.033324502408504486\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0355, train_loss_epoch=0.0333]Epoch 224: Train Loss = 0.03554786369204521\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0326, train_loss_epoch=0.0355]Epoch 225: Train Loss = 0.03258415684103966\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=238, train_loss_step=0.0338, train_loss_epoch=0.0326]Epoch 226: Train Loss = 0.03378443419933319\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0314, train_loss_epoch=0.0338]Epoch 227: Train Loss = 0.031431011855602264\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0391, train_loss_epoch=0.0314]Epoch 228: Train Loss = 0.039052557200193405\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.031, train_loss_epoch=0.0391] Epoch 229: Train Loss = 0.031020475551486015\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0336, train_loss_epoch=0.031]Epoch 230: Train Loss = 0.0336395688354969\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0333, train_loss_epoch=0.0336]Epoch 231: Train Loss = 0.03328058123588562\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.034, train_loss_epoch=0.0333] Epoch 232: Train Loss = 0.03401400148868561\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0346, train_loss_epoch=0.034]Epoch 233: Train Loss = 0.034635331481695175\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0313, train_loss_epoch=0.0346]Epoch 234: Train Loss = 0.03129783272743225\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0359, train_loss_epoch=0.0313]Epoch 235: Train Loss = 0.03591284155845642\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0331, train_loss_epoch=0.0359]Epoch 236: Train Loss = 0.033143430948257446\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0336, train_loss_epoch=0.0331]Epoch 237: Train Loss = 0.03361211344599724\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0357, train_loss_epoch=0.0336]Epoch 238: Train Loss = 0.03570970520377159\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0317, train_loss_epoch=0.0357]Epoch 239: Train Loss = 0.031721439212560654\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.042, train_loss_epoch=0.0317] Epoch 240: Train Loss = 0.04195985570549965\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0343, train_loss_epoch=0.042]Epoch 241: Train Loss = 0.03434048965573311\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0332, train_loss_epoch=0.0343]Epoch 242: Train Loss = 0.033197227865457535\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0434, train_loss_epoch=0.0332]Epoch 243: Train Loss = 0.04338029399514198\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=238, train_loss_step=0.0347, train_loss_epoch=0.0434]Epoch 244: Train Loss = 0.03467965126037598\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0415, train_loss_epoch=0.0347]Epoch 245: Train Loss = 0.04154416546225548\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0401, train_loss_epoch=0.0415]Epoch 246: Train Loss = 0.04014877602458\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0316, train_loss_epoch=0.0401]Epoch 247: Train Loss = 0.031571030616760254\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0393, train_loss_epoch=0.0316]Epoch 248: Train Loss = 0.03929334133863449\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0333, train_loss_epoch=0.0393]Epoch 249: Train Loss = 0.03326781094074249\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0333, train_loss_epoch=0.0333]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=238, train_loss_step=0.0333, train_loss_epoch=0.0333]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 27: from 1998-11-02 00:00:00 to 2022-09-12 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.404]Epoch 0: Train Loss = 0.4039853513240814\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.493, train_loss_epoch=0.404]Epoch 1: Train Loss = 0.49321866035461426\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.377, train_loss_epoch=0.493]Epoch 2: Train Loss = 0.3768180012702942\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.252, train_loss_epoch=0.377]Epoch 3: Train Loss = 0.25186169147491455\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.305, train_loss_epoch=0.252]Epoch 4: Train Loss = 0.30477920174598694\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.307, train_loss_epoch=0.305]Epoch 5: Train Loss = 0.3069196939468384\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.265, train_loss_epoch=0.307]Epoch 6: Train Loss = 0.2647245526313782\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.246, train_loss_epoch=0.265]Epoch 7: Train Loss = 0.24633316695690155\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.267, train_loss_epoch=0.246]Epoch 8: Train Loss = 0.2667289972305298\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.260, train_loss_epoch=0.267]Epoch 9: Train Loss = 0.26039746403694153\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.239, train_loss_epoch=0.260]Epoch 10: Train Loss = 0.239126056432724\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.223, train_loss_epoch=0.239]Epoch 11: Train Loss = 0.22265221178531647\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.242, train_loss_epoch=0.223]Epoch 12: Train Loss = 0.24186697602272034\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.225, train_loss_epoch=0.242]Epoch 13: Train Loss = 0.22469785809516907\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.217, train_loss_epoch=0.225]Epoch 14: Train Loss = 0.21688364446163177\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.193, train_loss_epoch=0.217]Epoch 15: Train Loss = 0.19312405586242676\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.197, train_loss_epoch=0.193]Epoch 16: Train Loss = 0.1969621330499649\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.193, train_loss_epoch=0.197]Epoch 17: Train Loss = 0.1931418925523758\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.201, train_loss_epoch=0.193]Epoch 18: Train Loss = 0.20067064464092255\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.180, train_loss_epoch=0.201]Epoch 19: Train Loss = 0.180167093873024\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.172, train_loss_epoch=0.180]Epoch 20: Train Loss = 0.17203618586063385\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.181, train_loss_epoch=0.172]Epoch 21: Train Loss = 0.18085075914859772\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.177, train_loss_epoch=0.181]Epoch 22: Train Loss = 0.1769610345363617\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.162, train_loss_epoch=0.177]Epoch 23: Train Loss = 0.16242419183254242\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.159, train_loss_epoch=0.162]Epoch 24: Train Loss = 0.15943214297294617\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.157, train_loss_epoch=0.159]Epoch 25: Train Loss = 0.15726523101329803\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.163, train_loss_epoch=0.157]Epoch 26: Train Loss = 0.16308486461639404\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.154, train_loss_epoch=0.163]Epoch 27: Train Loss = 0.1541801542043686\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.148, train_loss_epoch=0.154]Epoch 28: Train Loss = 0.14772871136665344\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.148, train_loss_epoch=0.148]Epoch 29: Train Loss = 0.1483268439769745\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.142, train_loss_epoch=0.148]Epoch 30: Train Loss = 0.14187729358673096\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.146, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.14554044604301453\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.140, train_loss_epoch=0.146]Epoch 32: Train Loss = 0.13984952867031097\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.135, train_loss_epoch=0.140]Epoch 33: Train Loss = 0.13521289825439453\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.136, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13624794781208038\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.132, train_loss_epoch=0.136]Epoch 35: Train Loss = 0.13211458921432495\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.128, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.12774120271205902\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.130, train_loss_epoch=0.128]Epoch 37: Train Loss = 0.1302267462015152\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.124, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12407971918582916\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.121, train_loss_epoch=0.124]Epoch 39: Train Loss = 0.12083993852138519\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=240, train_loss_step=0.117, train_loss_epoch=0.121]Epoch 40: Train Loss = 0.11651971936225891\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.119, train_loss_epoch=0.117]Epoch 41: Train Loss = 0.11853043735027313\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.115, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.11509789526462555\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.110, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.10979890078306198\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.115, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11508415639400482\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.107, train_loss_epoch=0.115]Epoch 45: Train Loss = 0.10675360262393951\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.107, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10710036754608154\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.105, train_loss_epoch=0.107]Epoch 47: Train Loss = 0.10478432476520538\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.103, train_loss_epoch=0.105]Epoch 48: Train Loss = 0.10266539454460144\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.104, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.10373711585998535\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0985, train_loss_epoch=0.104]Epoch 50: Train Loss = 0.0984780415892601\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0976, train_loss_epoch=0.0985]Epoch 51: Train Loss = 0.09763161092996597\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0989, train_loss_epoch=0.0976]Epoch 52: Train Loss = 0.09889684617519379\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.093, train_loss_epoch=0.0989] Epoch 53: Train Loss = 0.09303949028253555\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0946, train_loss_epoch=0.093]Epoch 54: Train Loss = 0.09457571059465408\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0921, train_loss_epoch=0.0946]Epoch 55: Train Loss = 0.0921097844839096\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0921, train_loss_epoch=0.0921]Epoch 56: Train Loss = 0.0920644998550415\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0888, train_loss_epoch=0.0921]Epoch 57: Train Loss = 0.08875744044780731\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0891, train_loss_epoch=0.0888]Epoch 58: Train Loss = 0.08910942822694778\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0872, train_loss_epoch=0.0891]Epoch 59: Train Loss = 0.08723662048578262\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=240, train_loss_step=0.0836, train_loss_epoch=0.0872]Epoch 60: Train Loss = 0.08361303061246872\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0808, train_loss_epoch=0.0836]Epoch 61: Train Loss = 0.08077087253332138\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0825, train_loss_epoch=0.0808]Epoch 62: Train Loss = 0.08245478570461273\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0808, train_loss_epoch=0.0825]Epoch 63: Train Loss = 0.0807548463344574\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0777, train_loss_epoch=0.0808]Epoch 64: Train Loss = 0.07767391204833984\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0784, train_loss_epoch=0.0777]Epoch 65: Train Loss = 0.07844799757003784\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0783, train_loss_epoch=0.0784]Epoch 66: Train Loss = 0.07827939093112946\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=240, train_loss_step=0.0775, train_loss_epoch=0.0783]Epoch 67: Train Loss = 0.07751818746328354\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0742, train_loss_epoch=0.0775]Epoch 68: Train Loss = 0.07415949553251266\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0718, train_loss_epoch=0.0742]Epoch 69: Train Loss = 0.07175549119710922\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0723, train_loss_epoch=0.0718]Epoch 70: Train Loss = 0.07227564603090286\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0713, train_loss_epoch=0.0723]Epoch 71: Train Loss = 0.07131987065076828\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0703, train_loss_epoch=0.0713]Epoch 72: Train Loss = 0.07034505158662796\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0695, train_loss_epoch=0.0703]Epoch 73: Train Loss = 0.06946331262588501\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.069, train_loss_epoch=0.0695] Epoch 74: Train Loss = 0.06902160495519638\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0676, train_loss_epoch=0.069]Epoch 75: Train Loss = 0.06757946312427521\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0666, train_loss_epoch=0.0676]Epoch 76: Train Loss = 0.06655058264732361\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0684, train_loss_epoch=0.0666]Epoch 77: Train Loss = 0.06843563914299011\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0668, train_loss_epoch=0.0684]Epoch 78: Train Loss = 0.06684084981679916\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0642, train_loss_epoch=0.0668]Epoch 79: Train Loss = 0.06415993720293045\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0654, train_loss_epoch=0.0642]Epoch 80: Train Loss = 0.06535334885120392\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0652, train_loss_epoch=0.0654]Epoch 81: Train Loss = 0.06519089639186859\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0622, train_loss_epoch=0.0652]Epoch 82: Train Loss = 0.06221029907464981\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.061, train_loss_epoch=0.0622] Epoch 83: Train Loss = 0.06095191836357117\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0623, train_loss_epoch=0.061]Epoch 84: Train Loss = 0.062302492558956146\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0624, train_loss_epoch=0.0623]Epoch 85: Train Loss = 0.06239965930581093\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0603, train_loss_epoch=0.0624]Epoch 86: Train Loss = 0.06032361462712288\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0651, train_loss_epoch=0.0603]Epoch 87: Train Loss = 0.06509552150964737\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.057, train_loss_epoch=0.0651] Epoch 88: Train Loss = 0.05703075975179672\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0631, train_loss_epoch=0.057]Epoch 89: Train Loss = 0.06307437270879745\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0565, train_loss_epoch=0.0631]Epoch 90: Train Loss = 0.056466925889253616\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0588, train_loss_epoch=0.0565]Epoch 91: Train Loss = 0.058839038014411926\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0552, train_loss_epoch=0.0588]Epoch 92: Train Loss = 0.05521328002214432\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0559, train_loss_epoch=0.0552]Epoch 93: Train Loss = 0.055919911712408066\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0557, train_loss_epoch=0.0559]Epoch 94: Train Loss = 0.0557190403342247\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0526, train_loss_epoch=0.0557]Epoch 95: Train Loss = 0.05261481925845146\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0554, train_loss_epoch=0.0526]Epoch 96: Train Loss = 0.05535263568162918\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0538, train_loss_epoch=0.0554]Epoch 97: Train Loss = 0.05380750820040703\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0571, train_loss_epoch=0.0538]Epoch 98: Train Loss = 0.05708351731300354\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0533, train_loss_epoch=0.0571]Epoch 99: Train Loss = 0.05333268642425537\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0556, train_loss_epoch=0.0533]Epoch 100: Train Loss = 0.055599234998226166\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0509, train_loss_epoch=0.0556]Epoch 101: Train Loss = 0.05086863040924072\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0512, train_loss_epoch=0.0509]Epoch 102: Train Loss = 0.05121577903628349\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.050, train_loss_epoch=0.0512] Epoch 103: Train Loss = 0.04997368901968002\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0506, train_loss_epoch=0.050]Epoch 104: Train Loss = 0.05063355341553688\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0495, train_loss_epoch=0.0506]Epoch 105: Train Loss = 0.04950791224837303\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.049, train_loss_epoch=0.0495] Epoch 106: Train Loss = 0.04898944869637489\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=240, train_loss_step=0.0474, train_loss_epoch=0.049]Epoch 107: Train Loss = 0.047379910945892334\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=240, train_loss_step=0.0508, train_loss_epoch=0.0474]Epoch 108: Train Loss = 0.050815027207136154\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0486, train_loss_epoch=0.0508]Epoch 109: Train Loss = 0.04858282580971718\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0488, train_loss_epoch=0.0486]Epoch 110: Train Loss = 0.04877037554979324\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0526, train_loss_epoch=0.0488]Epoch 111: Train Loss = 0.05261509492993355\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0474, train_loss_epoch=0.0526]Epoch 112: Train Loss = 0.04740063101053238\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0471, train_loss_epoch=0.0474]Epoch 113: Train Loss = 0.047102682292461395\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.046, train_loss_epoch=0.0471] Epoch 114: Train Loss = 0.046048302203416824\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=240, train_loss_step=0.0456, train_loss_epoch=0.046]Epoch 115: Train Loss = 0.045614514499902725\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0456, train_loss_epoch=0.0456]Epoch 116: Train Loss = 0.04560931399464607\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0461, train_loss_epoch=0.0456]Epoch 117: Train Loss = 0.046064652502536774\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0449, train_loss_epoch=0.0461]Epoch 118: Train Loss = 0.044894613325595856\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0451, train_loss_epoch=0.0449]Epoch 119: Train Loss = 0.04514257237315178\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.044, train_loss_epoch=0.0451] Epoch 120: Train Loss = 0.04402421787381172\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0484, train_loss_epoch=0.044]Epoch 121: Train Loss = 0.048355598002672195\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=240, train_loss_step=0.0476, train_loss_epoch=0.0484]Epoch 122: Train Loss = 0.04755353182554245\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0441, train_loss_epoch=0.0476]Epoch 123: Train Loss = 0.04406817629933357\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0448, train_loss_epoch=0.0441]Epoch 124: Train Loss = 0.04475593939423561\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0434, train_loss_epoch=0.0448]Epoch 125: Train Loss = 0.04343752935528755\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0442, train_loss_epoch=0.0434]Epoch 126: Train Loss = 0.04421408846974373\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0439, train_loss_epoch=0.0442]Epoch 127: Train Loss = 0.04387040063738823\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.044, train_loss_epoch=0.0439] Epoch 128: Train Loss = 0.04399937391281128\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.044, train_loss_epoch=0.044] Epoch 129: Train Loss = 0.044024787843227386\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=240, train_loss_step=0.0421, train_loss_epoch=0.044]Epoch 130: Train Loss = 0.04207826778292656\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0467, train_loss_epoch=0.0421]Epoch 131: Train Loss = 0.04668699949979782\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0414, train_loss_epoch=0.0467]Epoch 132: Train Loss = 0.04142887517809868\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0417, train_loss_epoch=0.0414]Epoch 133: Train Loss = 0.04171353951096535\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0446, train_loss_epoch=0.0417]Epoch 134: Train Loss = 0.044586893171072006\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0424, train_loss_epoch=0.0446]Epoch 135: Train Loss = 0.04241351783275604\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0468, train_loss_epoch=0.0424]Epoch 136: Train Loss = 0.046752672642469406\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0434, train_loss_epoch=0.0468]Epoch 137: Train Loss = 0.04337098449468613\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.045, train_loss_epoch=0.0434] Epoch 138: Train Loss = 0.04497241601347923\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0428, train_loss_epoch=0.045]Epoch 139: Train Loss = 0.04280382767319679\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0428, train_loss_epoch=0.0428]Epoch 140: Train Loss = 0.042798545211553574\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0402, train_loss_epoch=0.0428]Epoch 141: Train Loss = 0.0402088463306427\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0508, train_loss_epoch=0.0402]Epoch 142: Train Loss = 0.05079098418354988\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0404, train_loss_epoch=0.0508]Epoch 143: Train Loss = 0.040418971329927444\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0552, train_loss_epoch=0.0404]Epoch 144: Train Loss = 0.05519023537635803\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0404, train_loss_epoch=0.0552]Epoch 145: Train Loss = 0.040421195328235626\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0444, train_loss_epoch=0.0404]Epoch 146: Train Loss = 0.04438420385122299\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.047, train_loss_epoch=0.0444] Epoch 147: Train Loss = 0.047023676335811615\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.042, train_loss_epoch=0.047] Epoch 148: Train Loss = 0.04204742610454559\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0435, train_loss_epoch=0.042]Epoch 149: Train Loss = 0.043545015156269073\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=240, train_loss_step=0.0395, train_loss_epoch=0.0435]Epoch 150: Train Loss = 0.03945033997297287\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0507, train_loss_epoch=0.0395]Epoch 151: Train Loss = 0.050680771470069885\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0408, train_loss_epoch=0.0507]Epoch 152: Train Loss = 0.040846701711416245\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0506, train_loss_epoch=0.0408]Epoch 153: Train Loss = 0.05061895772814751\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0453, train_loss_epoch=0.0506]Epoch 154: Train Loss = 0.04530281201004982\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0409, train_loss_epoch=0.0453]Epoch 155: Train Loss = 0.04093550145626068\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0513, train_loss_epoch=0.0409]Epoch 156: Train Loss = 0.0512910895049572\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0381, train_loss_epoch=0.0513]Epoch 157: Train Loss = 0.03810492530465126\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0468, train_loss_epoch=0.0381]Epoch 158: Train Loss = 0.04679970070719719\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0404, train_loss_epoch=0.0468]Epoch 159: Train Loss = 0.04036347195506096\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0401, train_loss_epoch=0.0404]Epoch 160: Train Loss = 0.04009220004081726\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0429, train_loss_epoch=0.0401]Epoch 161: Train Loss = 0.04292060807347298\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0395, train_loss_epoch=0.0429]Epoch 162: Train Loss = 0.03949088975787163\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=240, train_loss_step=0.0384, train_loss_epoch=0.0395]Epoch 163: Train Loss = 0.038393884897232056\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0385, train_loss_epoch=0.0384]Epoch 164: Train Loss = 0.03854656592011452\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0367, train_loss_epoch=0.0385]Epoch 165: Train Loss = 0.0367276556789875\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0377, train_loss_epoch=0.0367]Epoch 166: Train Loss = 0.037680402398109436\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0361, train_loss_epoch=0.0377]Epoch 167: Train Loss = 0.03612573817372322\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0362, train_loss_epoch=0.0361]Epoch 168: Train Loss = 0.0361986942589283\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0414, train_loss_epoch=0.0362]Epoch 169: Train Loss = 0.04142938181757927\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0368, train_loss_epoch=0.0414]Epoch 170: Train Loss = 0.0367901585996151\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0377, train_loss_epoch=0.0368]Epoch 171: Train Loss = 0.037721578031778336\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0371, train_loss_epoch=0.0377]Epoch 172: Train Loss = 0.037129465490579605\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0362, train_loss_epoch=0.0371]Epoch 173: Train Loss = 0.03622513636946678\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0371, train_loss_epoch=0.0362]Epoch 174: Train Loss = 0.03710585832595825\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0378, train_loss_epoch=0.0371]Epoch 175: Train Loss = 0.037789784371852875\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0377, train_loss_epoch=0.0378]Epoch 176: Train Loss = 0.037716805934906006\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0364, train_loss_epoch=0.0377]Epoch 177: Train Loss = 0.036398161202669144\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.036, train_loss_epoch=0.0364] Epoch 178: Train Loss = 0.03600066155195236\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0367, train_loss_epoch=0.036]Epoch 179: Train Loss = 0.03665127605199814\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0361, train_loss_epoch=0.0367]Epoch 180: Train Loss = 0.036104269325733185\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0411, train_loss_epoch=0.0361]Epoch 181: Train Loss = 0.04111408814787865\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.038, train_loss_epoch=0.0411] Epoch 182: Train Loss = 0.0379863902926445\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0376, train_loss_epoch=0.038]Epoch 183: Train Loss = 0.03755423426628113\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0412, train_loss_epoch=0.0376]Epoch 184: Train Loss = 0.04115452617406845\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0352, train_loss_epoch=0.0412]Epoch 185: Train Loss = 0.035230852663517\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0388, train_loss_epoch=0.0352]Epoch 186: Train Loss = 0.03875637426972389\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0359, train_loss_epoch=0.0388]Epoch 187: Train Loss = 0.035901039838790894\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0352, train_loss_epoch=0.0359]Epoch 188: Train Loss = 0.035195667296648026\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0366, train_loss_epoch=0.0352]Epoch 189: Train Loss = 0.03657302260398865\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0344, train_loss_epoch=0.0366]Epoch 190: Train Loss = 0.03443913906812668\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0357, train_loss_epoch=0.0344]Epoch 191: Train Loss = 0.03568030521273613\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0367, train_loss_epoch=0.0357]Epoch 192: Train Loss = 0.0367158018052578\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0344, train_loss_epoch=0.0367]Epoch 193: Train Loss = 0.0343904085457325\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0348, train_loss_epoch=0.0344]Epoch 194: Train Loss = 0.03482760861515999\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0383, train_loss_epoch=0.0348]Epoch 195: Train Loss = 0.03826873004436493\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0345, train_loss_epoch=0.0383]Epoch 196: Train Loss = 0.03449751064181328\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0392, train_loss_epoch=0.0345]Epoch 197: Train Loss = 0.039165277034044266\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0365, train_loss_epoch=0.0392]Epoch 198: Train Loss = 0.036475516855716705\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.039, train_loss_epoch=0.0365] Epoch 199: Train Loss = 0.03899871185421944\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0417, train_loss_epoch=0.039]Epoch 200: Train Loss = 0.04165087267756462\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.034, train_loss_epoch=0.0417] Epoch 201: Train Loss = 0.033954836428165436\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0364, train_loss_epoch=0.034]Epoch 202: Train Loss = 0.03637266159057617\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0349, train_loss_epoch=0.0364]Epoch 203: Train Loss = 0.03488001227378845\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0338, train_loss_epoch=0.0349]Epoch 204: Train Loss = 0.03383767977356911\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0407, train_loss_epoch=0.0338]Epoch 205: Train Loss = 0.040680110454559326\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0331, train_loss_epoch=0.0407]Epoch 206: Train Loss = 0.03312241658568382\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0363, train_loss_epoch=0.0331]Epoch 207: Train Loss = 0.03634217008948326\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=240, train_loss_step=0.0395, train_loss_epoch=0.0363]Epoch 208: Train Loss = 0.03947019949555397\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0332, train_loss_epoch=0.0395]Epoch 209: Train Loss = 0.03319820389151573\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0419, train_loss_epoch=0.0332]Epoch 210: Train Loss = 0.04193463921546936\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0348, train_loss_epoch=0.0419]Epoch 211: Train Loss = 0.03483915701508522\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0338, train_loss_epoch=0.0348]Epoch 212: Train Loss = 0.03382851555943489\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0408, train_loss_epoch=0.0338]Epoch 213: Train Loss = 0.04084593057632446\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0351, train_loss_epoch=0.0408]Epoch 214: Train Loss = 0.03509620949625969\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0393, train_loss_epoch=0.0351]Epoch 215: Train Loss = 0.039262596517801285\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0411, train_loss_epoch=0.0393]Epoch 216: Train Loss = 0.04108283296227455\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0328, train_loss_epoch=0.0411]Epoch 217: Train Loss = 0.03282918408513069\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0412, train_loss_epoch=0.0328]Epoch 218: Train Loss = 0.0411849282681942\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0343, train_loss_epoch=0.0412]Epoch 219: Train Loss = 0.034306131303310394\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0369, train_loss_epoch=0.0343]Epoch 220: Train Loss = 0.03686577081680298\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0363, train_loss_epoch=0.0369]Epoch 221: Train Loss = 0.03627733886241913\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0319, train_loss_epoch=0.0363]Epoch 222: Train Loss = 0.031927794218063354\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.039, train_loss_epoch=0.0319] Epoch 223: Train Loss = 0.0390421561896801\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=240, train_loss_step=0.0348, train_loss_epoch=0.039]Epoch 224: Train Loss = 0.03484031558036804\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0338, train_loss_epoch=0.0348]Epoch 225: Train Loss = 0.03382738679647446\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0338, train_loss_epoch=0.0338]Epoch 226: Train Loss = 0.03377517685294151\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=240, train_loss_step=0.0319, train_loss_epoch=0.0338]Epoch 227: Train Loss = 0.031881723552942276\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0328, train_loss_epoch=0.0319]Epoch 228: Train Loss = 0.03279599919915199\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0344, train_loss_epoch=0.0328]Epoch 229: Train Loss = 0.034429606050252914\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.033, train_loss_epoch=0.0344] Epoch 230: Train Loss = 0.0330163836479187\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=240, train_loss_step=0.0337, train_loss_epoch=0.033]Epoch 231: Train Loss = 0.03367990627884865\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0318, train_loss_epoch=0.0337]Epoch 232: Train Loss = 0.031763412058353424\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0333, train_loss_epoch=0.0318]Epoch 233: Train Loss = 0.033281974494457245\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0334, train_loss_epoch=0.0333]Epoch 234: Train Loss = 0.03340596333146095\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0314, train_loss_epoch=0.0334]Epoch 235: Train Loss = 0.03141605108976364\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0324, train_loss_epoch=0.0314]Epoch 236: Train Loss = 0.03237608075141907\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0337, train_loss_epoch=0.0324]Epoch 237: Train Loss = 0.03373335301876068\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0319, train_loss_epoch=0.0337]Epoch 238: Train Loss = 0.03185797482728958\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0322, train_loss_epoch=0.0319]Epoch 239: Train Loss = 0.0322239063680172\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0313, train_loss_epoch=0.0322]Epoch 240: Train Loss = 0.031323838979005814\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0324, train_loss_epoch=0.0313]Epoch 241: Train Loss = 0.03243707865476608\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0326, train_loss_epoch=0.0324]Epoch 242: Train Loss = 0.03257393836975098\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0312, train_loss_epoch=0.0326]Epoch 243: Train Loss = 0.031205441802740097\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0326, train_loss_epoch=0.0312]Epoch 244: Train Loss = 0.03259006515145302\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0311, train_loss_epoch=0.0326]Epoch 245: Train Loss = 0.03107360564172268\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0327, train_loss_epoch=0.0311]Epoch 246: Train Loss = 0.03265978395938873\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0308, train_loss_epoch=0.0327]Epoch 247: Train Loss = 0.030821586027741432\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0313, train_loss_epoch=0.0308]Epoch 248: Train Loss = 0.03128688782453537\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0305, train_loss_epoch=0.0313]Epoch 249: Train Loss = 0.030526187270879745\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0305, train_loss_epoch=0.0305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=240, train_loss_step=0.0305, train_loss_epoch=0.0305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 28: from 1998-11-02 00:00:00 to 2022-09-21 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.410]Epoch 0: Train Loss = 0.409587562084198\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.493, train_loss_epoch=0.410]Epoch 1: Train Loss = 0.49257948994636536\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.378, train_loss_epoch=0.493]Epoch 2: Train Loss = 0.37751030921936035\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.254, train_loss_epoch=0.378]Epoch 3: Train Loss = 0.25373679399490356\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.305, train_loss_epoch=0.254]Epoch 4: Train Loss = 0.30491822957992554\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.305, train_loss_epoch=0.305]Epoch 5: Train Loss = 0.3054808974266052\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.255, train_loss_epoch=0.305]Epoch 6: Train Loss = 0.255365252494812\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.241, train_loss_epoch=0.255]Epoch 7: Train Loss = 0.2409219741821289\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.261, train_loss_epoch=0.241]Epoch 8: Train Loss = 0.2613205909729004\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.261, train_loss_epoch=0.261]Epoch 9: Train Loss = 0.2606212794780731\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.239, train_loss_epoch=0.261]Epoch 10: Train Loss = 0.23943303525447845\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.223, train_loss_epoch=0.239]Epoch 11: Train Loss = 0.22251011431217194\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.234, train_loss_epoch=0.223]Epoch 12: Train Loss = 0.2341957986354828\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.221, train_loss_epoch=0.234]Epoch 13: Train Loss = 0.22145523130893707\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.211, train_loss_epoch=0.221]Epoch 14: Train Loss = 0.21095415949821472\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.190, train_loss_epoch=0.211]Epoch 15: Train Loss = 0.1896195113658905\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.201, train_loss_epoch=0.190]Epoch 16: Train Loss = 0.2005026787519455\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.195, train_loss_epoch=0.201]Epoch 17: Train Loss = 0.1945057362318039\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.197, train_loss_epoch=0.195]Epoch 18: Train Loss = 0.19658060371875763\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.175, train_loss_epoch=0.197]Epoch 19: Train Loss = 0.1746930032968521\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.168, train_loss_epoch=0.175]Epoch 20: Train Loss = 0.16804203391075134\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.180, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.18005160987377167\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.176, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.17581279575824738\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.166, train_loss_epoch=0.176]Epoch 23: Train Loss = 0.16613788902759552\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.157, train_loss_epoch=0.166]Epoch 24: Train Loss = 0.15729528665542603\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.159, train_loss_epoch=0.157]Epoch 25: Train Loss = 0.1585712730884552\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.163, train_loss_epoch=0.159]Epoch 26: Train Loss = 0.1629367619752884\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.154, train_loss_epoch=0.163]Epoch 27: Train Loss = 0.15405015647411346\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.145, train_loss_epoch=0.154]Epoch 28: Train Loss = 0.1452200561761856\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.149, train_loss_epoch=0.145]Epoch 29: Train Loss = 0.14892885088920593\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.142, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.1417902410030365\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.142, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.1419800966978073\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.138, train_loss_epoch=0.142]Epoch 32: Train Loss = 0.13793033361434937\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.135, train_loss_epoch=0.138]Epoch 33: Train Loss = 0.13495902717113495\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.136, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13570435345172882\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.132, train_loss_epoch=0.136]Epoch 35: Train Loss = 0.13154055178165436\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.130, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.13015063107013702\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.131, train_loss_epoch=0.130]Epoch 37: Train Loss = 0.1306755095720291\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.124, train_loss_epoch=0.131]Epoch 38: Train Loss = 0.12357562780380249\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.119, train_loss_epoch=0.124]Epoch 39: Train Loss = 0.11887203902006149\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.116, train_loss_epoch=0.119]Epoch 40: Train Loss = 0.11626479774713516\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.118, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11837852001190186\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.115, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.11465243250131607\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.110, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.11024033278226852\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.115, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11451809853315353\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.107, train_loss_epoch=0.115]Epoch 45: Train Loss = 0.10663177818059921\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.106, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10629620403051376\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.103, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.10282296687364578\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.101, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.1011267825961113\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.103, train_loss_epoch=0.101]Epoch 49: Train Loss = 0.10295901447534561\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0981, train_loss_epoch=0.103]Epoch 50: Train Loss = 0.09809837490320206\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.097, train_loss_epoch=0.0981] Epoch 51: Train Loss = 0.09699659794569016\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0974, train_loss_epoch=0.097]Epoch 52: Train Loss = 0.09735887497663498\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.092, train_loss_epoch=0.0974] Epoch 53: Train Loss = 0.09202442318201065\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0932, train_loss_epoch=0.092]Epoch 54: Train Loss = 0.09318932145833969\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0933, train_loss_epoch=0.0932]Epoch 55: Train Loss = 0.09326888620853424\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0906, train_loss_epoch=0.0933]Epoch 56: Train Loss = 0.09056659787893295\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0883, train_loss_epoch=0.0906]Epoch 57: Train Loss = 0.08828277885913849\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0878, train_loss_epoch=0.0883]Epoch 58: Train Loss = 0.08782508224248886\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0858, train_loss_epoch=0.0878]Epoch 59: Train Loss = 0.08578065782785416\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0841, train_loss_epoch=0.0858]Epoch 60: Train Loss = 0.08408388495445251\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0829, train_loss_epoch=0.0841]Epoch 61: Train Loss = 0.08286412805318832\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0798, train_loss_epoch=0.0829]Epoch 62: Train Loss = 0.0797586441040039\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.0791, train_loss_epoch=0.0798]Epoch 63: Train Loss = 0.07908648997545242\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0762, train_loss_epoch=0.0791]Epoch 64: Train Loss = 0.0761883407831192\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0787, train_loss_epoch=0.0762]Epoch 65: Train Loss = 0.07868371903896332\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0813, train_loss_epoch=0.0787]Epoch 66: Train Loss = 0.0812704786658287\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0757, train_loss_epoch=0.0813]Epoch 67: Train Loss = 0.07573100179433823\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0744, train_loss_epoch=0.0757]Epoch 68: Train Loss = 0.07436124235391617\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0714, train_loss_epoch=0.0744]Epoch 69: Train Loss = 0.07137817144393921\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0726, train_loss_epoch=0.0714]Epoch 70: Train Loss = 0.07255804538726807\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0695, train_loss_epoch=0.0726]Epoch 71: Train Loss = 0.06948762387037277\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.0701, train_loss_epoch=0.0695]Epoch 72: Train Loss = 0.07010036706924438\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0692, train_loss_epoch=0.0701]Epoch 73: Train Loss = 0.06915146857500076\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0684, train_loss_epoch=0.0692]Epoch 74: Train Loss = 0.06839318573474884\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.066, train_loss_epoch=0.0684] Epoch 75: Train Loss = 0.06600397825241089\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0658, train_loss_epoch=0.066]Epoch 76: Train Loss = 0.06575717777013779\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0663, train_loss_epoch=0.0658]Epoch 77: Train Loss = 0.06630296260118484\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0646, train_loss_epoch=0.0663]Epoch 78: Train Loss = 0.06464868783950806\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0627, train_loss_epoch=0.0646]Epoch 79: Train Loss = 0.06269828975200653\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0631, train_loss_epoch=0.0627]Epoch 80: Train Loss = 0.06309517472982407\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0625, train_loss_epoch=0.0631]Epoch 81: Train Loss = 0.0624530129134655\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0627, train_loss_epoch=0.0625]Epoch 82: Train Loss = 0.06273181736469269\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0619, train_loss_epoch=0.0627]Epoch 83: Train Loss = 0.06194315478205681\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0624, train_loss_epoch=0.0619]Epoch 84: Train Loss = 0.06239236146211624\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0618, train_loss_epoch=0.0624]Epoch 85: Train Loss = 0.061750274151563644\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0595, train_loss_epoch=0.0618]Epoch 86: Train Loss = 0.05948413535952568\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0688, train_loss_epoch=0.0595]Epoch 87: Train Loss = 0.06879284232854843\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0595, train_loss_epoch=0.0688]Epoch 88: Train Loss = 0.05952996760606766\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0642, train_loss_epoch=0.0595]Epoch 89: Train Loss = 0.06415059417486191\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0576, train_loss_epoch=0.0642]Epoch 90: Train Loss = 0.05759695917367935\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.058, train_loss_epoch=0.0576] Epoch 91: Train Loss = 0.05802827328443527\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.0558, train_loss_epoch=0.058]Epoch 92: Train Loss = 0.055793486535549164\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0587, train_loss_epoch=0.0558]Epoch 93: Train Loss = 0.05868399888277054\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0545, train_loss_epoch=0.0587]Epoch 94: Train Loss = 0.05454844981431961\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0547, train_loss_epoch=0.0545]Epoch 95: Train Loss = 0.05474834516644478\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0556, train_loss_epoch=0.0547]Epoch 96: Train Loss = 0.05561178922653198\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0538, train_loss_epoch=0.0556]Epoch 97: Train Loss = 0.053782664239406586\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0547, train_loss_epoch=0.0538]Epoch 98: Train Loss = 0.05468941107392311\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0515, train_loss_epoch=0.0547]Epoch 99: Train Loss = 0.051464006304740906\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0539, train_loss_epoch=0.0515]Epoch 100: Train Loss = 0.053919512778520584\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0513, train_loss_epoch=0.0539]Epoch 101: Train Loss = 0.05129648372530937\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0513, train_loss_epoch=0.0513]Epoch 102: Train Loss = 0.0513225682079792\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0504, train_loss_epoch=0.0513]Epoch 103: Train Loss = 0.0503990575671196\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0487, train_loss_epoch=0.0504]Epoch 104: Train Loss = 0.04870721697807312\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.052, train_loss_epoch=0.0487] Epoch 105: Train Loss = 0.05195773392915726\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0497, train_loss_epoch=0.052]Epoch 106: Train Loss = 0.04967207834124565\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0522, train_loss_epoch=0.0497]Epoch 107: Train Loss = 0.05221934616565704\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0489, train_loss_epoch=0.0522]Epoch 108: Train Loss = 0.04891357570886612\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0537, train_loss_epoch=0.0489]Epoch 109: Train Loss = 0.053677041083574295\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0483, train_loss_epoch=0.0537]Epoch 110: Train Loss = 0.04829486832022667\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0482, train_loss_epoch=0.0483]Epoch 111: Train Loss = 0.048169367015361786\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0481, train_loss_epoch=0.0482]Epoch 112: Train Loss = 0.04811215028166771\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0481, train_loss_epoch=0.0481]Epoch 113: Train Loss = 0.048050422221422195\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0488, train_loss_epoch=0.0481]Epoch 114: Train Loss = 0.04879233241081238\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0502, train_loss_epoch=0.0488]Epoch 115: Train Loss = 0.05020095035433769\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0458, train_loss_epoch=0.0502]Epoch 116: Train Loss = 0.045831382274627686\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0526, train_loss_epoch=0.0458]Epoch 117: Train Loss = 0.052596330642700195\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0442, train_loss_epoch=0.0526]Epoch 118: Train Loss = 0.04420929029583931\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0491, train_loss_epoch=0.0442]Epoch 119: Train Loss = 0.049059487879276276\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0437, train_loss_epoch=0.0491]Epoch 120: Train Loss = 0.04374091327190399\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0534, train_loss_epoch=0.0437]Epoch 121: Train Loss = 0.053394317626953125\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0439, train_loss_epoch=0.0534]Epoch 122: Train Loss = 0.043916016817092896\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0516, train_loss_epoch=0.0439]Epoch 123: Train Loss = 0.05162607133388519\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0445, train_loss_epoch=0.0516]Epoch 124: Train Loss = 0.04447038099169731\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0474, train_loss_epoch=0.0445]Epoch 125: Train Loss = 0.047431908547878265\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0451, train_loss_epoch=0.0474]Epoch 126: Train Loss = 0.04505396634340286\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0465, train_loss_epoch=0.0451]Epoch 127: Train Loss = 0.046543873846530914\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0462, train_loss_epoch=0.0465]Epoch 128: Train Loss = 0.04623860493302345\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0425, train_loss_epoch=0.0462]Epoch 129: Train Loss = 0.04248824343085289\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0449, train_loss_epoch=0.0425]Epoch 130: Train Loss = 0.04487025365233421\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0426, train_loss_epoch=0.0449]Epoch 131: Train Loss = 0.04260451719164848\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0432, train_loss_epoch=0.0426]Epoch 132: Train Loss = 0.043185506016016006\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0431, train_loss_epoch=0.0432]Epoch 133: Train Loss = 0.04306291043758392\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0412, train_loss_epoch=0.0431]Epoch 134: Train Loss = 0.041188571602106094\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.041, train_loss_epoch=0.0412] Epoch 135: Train Loss = 0.04104440286755562\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0428, train_loss_epoch=0.041]Epoch 136: Train Loss = 0.0427800714969635\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0411, train_loss_epoch=0.0428]Epoch 137: Train Loss = 0.04108357056975365\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0418, train_loss_epoch=0.0411]Epoch 138: Train Loss = 0.04178604856133461\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0415, train_loss_epoch=0.0418]Epoch 139: Train Loss = 0.04154256358742714\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.0401, train_loss_epoch=0.0415]Epoch 140: Train Loss = 0.040136292576789856\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0444, train_loss_epoch=0.0401]Epoch 141: Train Loss = 0.04435844346880913\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.0413, train_loss_epoch=0.0444]Epoch 142: Train Loss = 0.04131891205906868\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0447, train_loss_epoch=0.0413]Epoch 143: Train Loss = 0.04468169063329697\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0389, train_loss_epoch=0.0447]Epoch 144: Train Loss = 0.03894345089793205\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0451, train_loss_epoch=0.0389]Epoch 145: Train Loss = 0.04506704583764076\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0413, train_loss_epoch=0.0451]Epoch 146: Train Loss = 0.0413113608956337\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0446, train_loss_epoch=0.0413]Epoch 147: Train Loss = 0.044585149735212326\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0438, train_loss_epoch=0.0446]Epoch 148: Train Loss = 0.043761979788541794\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0441, train_loss_epoch=0.0438]Epoch 149: Train Loss = 0.044110603630542755\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.044, train_loss_epoch=0.0441] Epoch 150: Train Loss = 0.04397755116224289\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0401, train_loss_epoch=0.044]Epoch 151: Train Loss = 0.04007842019200325\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0467, train_loss_epoch=0.0401]Epoch 152: Train Loss = 0.046728089451789856\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.038, train_loss_epoch=0.0467] Epoch 153: Train Loss = 0.03798715025186539\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.046, train_loss_epoch=0.038] Epoch 154: Train Loss = 0.04603368416428566\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0379, train_loss_epoch=0.046]Epoch 155: Train Loss = 0.03788602724671364\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0402, train_loss_epoch=0.0379]Epoch 156: Train Loss = 0.04020245745778084\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0384, train_loss_epoch=0.0402]Epoch 157: Train Loss = 0.03836072236299515\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0385, train_loss_epoch=0.0384]Epoch 158: Train Loss = 0.038521867245435715\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0404, train_loss_epoch=0.0385]Epoch 159: Train Loss = 0.04037376865744591\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0378, train_loss_epoch=0.0404]Epoch 160: Train Loss = 0.03784376382827759\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0455, train_loss_epoch=0.0378]Epoch 161: Train Loss = 0.045514632016420364\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0374, train_loss_epoch=0.0455]Epoch 162: Train Loss = 0.03735249117016792\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0373, train_loss_epoch=0.0374]Epoch 163: Train Loss = 0.03731989860534668\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0417, train_loss_epoch=0.0373]Epoch 164: Train Loss = 0.04172881692647934\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0378, train_loss_epoch=0.0417]Epoch 165: Train Loss = 0.037802260369062424\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=242, train_loss_step=0.0403, train_loss_epoch=0.0378]Epoch 166: Train Loss = 0.040340498089790344\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0388, train_loss_epoch=0.0403]Epoch 167: Train Loss = 0.03882693871855736\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=242, train_loss_step=0.0365, train_loss_epoch=0.0388]Epoch 168: Train Loss = 0.03649405762553215\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0465, train_loss_epoch=0.0365]Epoch 169: Train Loss = 0.046459030359983444\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0397, train_loss_epoch=0.0465]Epoch 170: Train Loss = 0.039664376527071\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0395, train_loss_epoch=0.0397]Epoch 171: Train Loss = 0.03949913755059242\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0436, train_loss_epoch=0.0395]Epoch 172: Train Loss = 0.043638888746500015\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0366, train_loss_epoch=0.0436]Epoch 173: Train Loss = 0.036558978259563446\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0432, train_loss_epoch=0.0366]Epoch 174: Train Loss = 0.04318533465266228\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.40it/s, v_num=242, train_loss_step=0.0381, train_loss_epoch=0.0432]Epoch 175: Train Loss = 0.038091402500867844\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0388, train_loss_epoch=0.0381]Epoch 176: Train Loss = 0.038761164993047714\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0389, train_loss_epoch=0.0388]Epoch 177: Train Loss = 0.038934458047151566\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=242, train_loss_step=0.0357, train_loss_epoch=0.0389]Epoch 178: Train Loss = 0.03573702648282051\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0374, train_loss_epoch=0.0357]Epoch 179: Train Loss = 0.037377431988716125\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=242, train_loss_step=0.0375, train_loss_epoch=0.0374]Epoch 180: Train Loss = 0.03754238411784172\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.039, train_loss_epoch=0.0375] Epoch 181: Train Loss = 0.03895702585577965\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=242, train_loss_step=0.0384, train_loss_epoch=0.039]Epoch 182: Train Loss = 0.03844410553574562\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=242, train_loss_step=0.0369, train_loss_epoch=0.0384]Epoch 183: Train Loss = 0.03685362637042999\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0383, train_loss_epoch=0.0369]Epoch 184: Train Loss = 0.03825606405735016\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0348, train_loss_epoch=0.0383]Epoch 185: Train Loss = 0.034754686057567596\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=242, train_loss_step=0.0372, train_loss_epoch=0.0348]Epoch 186: Train Loss = 0.03718327730894089\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0352, train_loss_epoch=0.0372]Epoch 187: Train Loss = 0.03521374240517616\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0344, train_loss_epoch=0.0352]Epoch 188: Train Loss = 0.034447092562913895\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0359, train_loss_epoch=0.0344]Epoch 189: Train Loss = 0.03590639308094978\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0345, train_loss_epoch=0.0359]Epoch 190: Train Loss = 0.034464772790670395\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0352, train_loss_epoch=0.0345]Epoch 191: Train Loss = 0.03520340099930763\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0364, train_loss_epoch=0.0352]Epoch 192: Train Loss = 0.03635013848543167\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0345, train_loss_epoch=0.0364]Epoch 193: Train Loss = 0.034502092748880386\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0346, train_loss_epoch=0.0345]Epoch 194: Train Loss = 0.034585095942020416\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0367, train_loss_epoch=0.0346]Epoch 195: Train Loss = 0.03667909651994705\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.40it/s, v_num=242, train_loss_step=0.0356, train_loss_epoch=0.0367]Epoch 196: Train Loss = 0.03558501973748207\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=242, train_loss_step=0.0395, train_loss_epoch=0.0356]Epoch 197: Train Loss = 0.039487630128860474\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0342, train_loss_epoch=0.0395]Epoch 198: Train Loss = 0.03422892838716507\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0388, train_loss_epoch=0.0342]Epoch 199: Train Loss = 0.038798268884420395\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0339, train_loss_epoch=0.0388]Epoch 200: Train Loss = 0.03392050415277481\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0336, train_loss_epoch=0.0339]Epoch 201: Train Loss = 0.03364822268486023\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0368, train_loss_epoch=0.0336]Epoch 202: Train Loss = 0.036790940910577774\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0348, train_loss_epoch=0.0368]Epoch 203: Train Loss = 0.03479720652103424\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0344, train_loss_epoch=0.0348]Epoch 204: Train Loss = 0.034372542053461075\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0396, train_loss_epoch=0.0344]Epoch 205: Train Loss = 0.03955277428030968\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0329, train_loss_epoch=0.0396]Epoch 206: Train Loss = 0.032922811806201935\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0363, train_loss_epoch=0.0329]Epoch 207: Train Loss = 0.036334335803985596\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0347, train_loss_epoch=0.0363]Epoch 208: Train Loss = 0.034681785851716995\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0343, train_loss_epoch=0.0347]Epoch 209: Train Loss = 0.034269072115421295\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0359, train_loss_epoch=0.0343]Epoch 210: Train Loss = 0.03587755188345909\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0324, train_loss_epoch=0.0359]Epoch 211: Train Loss = 0.03240503370761871\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0348, train_loss_epoch=0.0324]Epoch 212: Train Loss = 0.03480774909257889\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0329, train_loss_epoch=0.0348]Epoch 213: Train Loss = 0.032901085913181305\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0332, train_loss_epoch=0.0329]Epoch 214: Train Loss = 0.033223774284124374\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.033, train_loss_epoch=0.0332] Epoch 215: Train Loss = 0.03303295373916626\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0327, train_loss_epoch=0.033]Epoch 216: Train Loss = 0.032733578234910965\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0345, train_loss_epoch=0.0327]Epoch 217: Train Loss = 0.034499846398830414\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0334, train_loss_epoch=0.0345]Epoch 218: Train Loss = 0.0334404818713665\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0338, train_loss_epoch=0.0334]Epoch 219: Train Loss = 0.03375280275940895\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.033, train_loss_epoch=0.0338] Epoch 220: Train Loss = 0.033026088029146194\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0326, train_loss_epoch=0.033]Epoch 221: Train Loss = 0.032626792788505554\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0356, train_loss_epoch=0.0326]Epoch 222: Train Loss = 0.03558559715747833\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0343, train_loss_epoch=0.0356]Epoch 223: Train Loss = 0.03433357924222946\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0329, train_loss_epoch=0.0343]Epoch 224: Train Loss = 0.032869745045900345\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0326, train_loss_epoch=0.0329]Epoch 225: Train Loss = 0.032649438828229904\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0317, train_loss_epoch=0.0326]Epoch 226: Train Loss = 0.03168440982699394\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0322, train_loss_epoch=0.0317]Epoch 227: Train Loss = 0.03216388449072838\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0332, train_loss_epoch=0.0322]Epoch 228: Train Loss = 0.0332435742020607\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0315, train_loss_epoch=0.0332]Epoch 229: Train Loss = 0.031465794891119\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0323, train_loss_epoch=0.0315]Epoch 230: Train Loss = 0.03231010586023331\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0332, train_loss_epoch=0.0323]Epoch 231: Train Loss = 0.03320236876606941\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.0315, train_loss_epoch=0.0332]Epoch 232: Train Loss = 0.03154316917061806\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0326, train_loss_epoch=0.0315]Epoch 233: Train Loss = 0.03262342885136604\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0316, train_loss_epoch=0.0326]Epoch 234: Train Loss = 0.0316329188644886\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0327, train_loss_epoch=0.0316]Epoch 235: Train Loss = 0.03270035609602928\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.031, train_loss_epoch=0.0327] Epoch 236: Train Loss = 0.030959876254200935\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0324, train_loss_epoch=0.031]Epoch 237: Train Loss = 0.032402027398347855\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0309, train_loss_epoch=0.0324]Epoch 238: Train Loss = 0.03092954121530056\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0319, train_loss_epoch=0.0309]Epoch 239: Train Loss = 0.031871192157268524\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.031, train_loss_epoch=0.0319] Epoch 240: Train Loss = 0.031014975160360336\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0316, train_loss_epoch=0.031]Epoch 241: Train Loss = 0.03162158280611038\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0311, train_loss_epoch=0.0316]Epoch 242: Train Loss = 0.031124183908104897\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0306, train_loss_epoch=0.0311]Epoch 243: Train Loss = 0.030584601685404778\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0316, train_loss_epoch=0.0306]Epoch 244: Train Loss = 0.031642138957977295\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0311, train_loss_epoch=0.0316]Epoch 245: Train Loss = 0.03110913746058941\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=242, train_loss_step=0.0323, train_loss_epoch=0.0311]Epoch 246: Train Loss = 0.03233499825000763\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=242, train_loss_step=0.0312, train_loss_epoch=0.0323]Epoch 247: Train Loss = 0.031232984736561775\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=242, train_loss_step=0.0308, train_loss_epoch=0.0312]Epoch 248: Train Loss = 0.030789408832788467\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0359, train_loss_epoch=0.0308]Epoch 249: Train Loss = 0.03589976578950882\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0359, train_loss_epoch=0.0359]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=242, train_loss_step=0.0359, train_loss_epoch=0.0359]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 29: from 1998-11-02 00:00:00 to 2022-09-30 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.405]Epoch 0: Train Loss = 0.4045202434062958\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.496, train_loss_epoch=0.405]Epoch 1: Train Loss = 0.4963861405849457\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.369, train_loss_epoch=0.496]Epoch 2: Train Loss = 0.36947375535964966\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.250, train_loss_epoch=0.369]Epoch 3: Train Loss = 0.24969294667243958\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.308, train_loss_epoch=0.250]Epoch 4: Train Loss = 0.3076186776161194\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.310, train_loss_epoch=0.308]Epoch 5: Train Loss = 0.3096303641796112\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.256, train_loss_epoch=0.310]Epoch 6: Train Loss = 0.2561507523059845\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.240, train_loss_epoch=0.256]Epoch 7: Train Loss = 0.2402878999710083\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.264, train_loss_epoch=0.240]Epoch 8: Train Loss = 0.263642817735672\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.257, train_loss_epoch=0.264]Epoch 9: Train Loss = 0.2570964992046356\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.239, train_loss_epoch=0.257]Epoch 10: Train Loss = 0.2385752648115158\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.223, train_loss_epoch=0.239]Epoch 11: Train Loss = 0.2226475477218628\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.231, train_loss_epoch=0.223]Epoch 12: Train Loss = 0.23087628185749054\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.219, train_loss_epoch=0.231]Epoch 13: Train Loss = 0.2191406935453415\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.209, train_loss_epoch=0.219]Epoch 14: Train Loss = 0.20863185822963715\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.189, train_loss_epoch=0.209]Epoch 15: Train Loss = 0.1887553185224533\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.199, train_loss_epoch=0.189]Epoch 16: Train Loss = 0.19855868816375732\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.191, train_loss_epoch=0.199]Epoch 17: Train Loss = 0.190543070435524\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.196, train_loss_epoch=0.191]Epoch 18: Train Loss = 0.19557054340839386\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.174, train_loss_epoch=0.196]Epoch 19: Train Loss = 0.17429344356060028\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.168, train_loss_epoch=0.174]Epoch 20: Train Loss = 0.16816450655460358\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.179, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.1788720339536667\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.177, train_loss_epoch=0.179]Epoch 22: Train Loss = 0.17677409946918488\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.160, train_loss_epoch=0.177]Epoch 23: Train Loss = 0.16023443639278412\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.157, train_loss_epoch=0.160]Epoch 24: Train Loss = 0.1574682891368866\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.156, train_loss_epoch=0.157]Epoch 25: Train Loss = 0.15574219822883606\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.159, train_loss_epoch=0.156]Epoch 26: Train Loss = 0.15885135531425476\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.151, train_loss_epoch=0.159]Epoch 27: Train Loss = 0.15112078189849854\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.144, train_loss_epoch=0.151]Epoch 28: Train Loss = 0.14434844255447388\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.150, train_loss_epoch=0.144]Epoch 29: Train Loss = 0.1499520093202591\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.140, train_loss_epoch=0.150]Epoch 30: Train Loss = 0.1402764767408371\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.141, train_loss_epoch=0.140]Epoch 31: Train Loss = 0.141486257314682\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.136, train_loss_epoch=0.141]Epoch 32: Train Loss = 0.13587245345115662\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.132, train_loss_epoch=0.136]Epoch 33: Train Loss = 0.13228009641170502\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.133, train_loss_epoch=0.132]Epoch 34: Train Loss = 0.13277459144592285\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.129, train_loss_epoch=0.133]Epoch 35: Train Loss = 0.12912647426128387\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.128, train_loss_epoch=0.129]Epoch 36: Train Loss = 0.12805388867855072\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.127, train_loss_epoch=0.128]Epoch 37: Train Loss = 0.12729212641716003\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.122, train_loss_epoch=0.127]Epoch 38: Train Loss = 0.12205858528614044\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.117, train_loss_epoch=0.122]Epoch 39: Train Loss = 0.11680124700069427\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.115, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11479943245649338\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.118, train_loss_epoch=0.115]Epoch 41: Train Loss = 0.11812271922826767\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.113, train_loss_epoch=0.118]Epoch 42: Train Loss = 0.11334530264139175\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.109, train_loss_epoch=0.113]Epoch 43: Train Loss = 0.10858260095119476\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.113, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11262160539627075\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.104, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10408835858106613\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.105, train_loss_epoch=0.104]Epoch 46: Train Loss = 0.10465417057275772\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.102, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.1015041247010231\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.100, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.09997584670782089\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.101, train_loss_epoch=0.100]Epoch 49: Train Loss = 0.10119061172008514\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0968, train_loss_epoch=0.101]Epoch 50: Train Loss = 0.09677306562662125\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0961, train_loss_epoch=0.0968]Epoch 51: Train Loss = 0.09605316072702408\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0958, train_loss_epoch=0.0961]Epoch 52: Train Loss = 0.09584014862775803\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0918, train_loss_epoch=0.0958]Epoch 53: Train Loss = 0.091824471950531\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0912, train_loss_epoch=0.0918]Epoch 54: Train Loss = 0.09115534275770187\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0902, train_loss_epoch=0.0912]Epoch 55: Train Loss = 0.09021420031785965\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0879, train_loss_epoch=0.0902]Epoch 56: Train Loss = 0.0879250094294548\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0866, train_loss_epoch=0.0879]Epoch 57: Train Loss = 0.08659757673740387\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.087, train_loss_epoch=0.0866] Epoch 58: Train Loss = 0.08696474879980087\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0834, train_loss_epoch=0.087]Epoch 59: Train Loss = 0.0833912044763565\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0815, train_loss_epoch=0.0834]Epoch 60: Train Loss = 0.08154436945915222\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.0814, train_loss_epoch=0.0815]Epoch 61: Train Loss = 0.08138158917427063\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0786, train_loss_epoch=0.0814]Epoch 62: Train Loss = 0.07855892181396484\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0803, train_loss_epoch=0.0786]Epoch 63: Train Loss = 0.08031009882688522\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0756, train_loss_epoch=0.0803]Epoch 64: Train Loss = 0.0755724087357521\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.077, train_loss_epoch=0.0756] Epoch 65: Train Loss = 0.07703345268964767\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0778, train_loss_epoch=0.077]Epoch 66: Train Loss = 0.07781986147165298\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0771, train_loss_epoch=0.0778]Epoch 67: Train Loss = 0.07713291049003601\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.0729, train_loss_epoch=0.0771]Epoch 68: Train Loss = 0.07286294549703598\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=244, train_loss_step=0.0714, train_loss_epoch=0.0729]Epoch 69: Train Loss = 0.07141301780939102\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.0712, train_loss_epoch=0.0714]Epoch 70: Train Loss = 0.07123365253210068\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0688, train_loss_epoch=0.0712]Epoch 71: Train Loss = 0.06883712857961655\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.069, train_loss_epoch=0.0688] Epoch 72: Train Loss = 0.06904563307762146\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0689, train_loss_epoch=0.069]Epoch 73: Train Loss = 0.06892714649438858\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0674, train_loss_epoch=0.0689]Epoch 74: Train Loss = 0.06736665964126587\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0659, train_loss_epoch=0.0674]Epoch 75: Train Loss = 0.0658554956316948\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0657, train_loss_epoch=0.0659]Epoch 76: Train Loss = 0.06569866091012955\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0667, train_loss_epoch=0.0657]Epoch 77: Train Loss = 0.0667068213224411\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0646, train_loss_epoch=0.0667]Epoch 78: Train Loss = 0.06460536271333694\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0621, train_loss_epoch=0.0646]Epoch 79: Train Loss = 0.06210745871067047\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0634, train_loss_epoch=0.0621]Epoch 80: Train Loss = 0.06338019669055939\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0658, train_loss_epoch=0.0634]Epoch 81: Train Loss = 0.06576250493526459\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0611, train_loss_epoch=0.0658]Epoch 82: Train Loss = 0.06108908727765083\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.066, train_loss_epoch=0.0611] Epoch 83: Train Loss = 0.06597881764173508\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0602, train_loss_epoch=0.066]Epoch 84: Train Loss = 0.060213930904865265\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0652, train_loss_epoch=0.0602]Epoch 85: Train Loss = 0.06515777111053467\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0578, train_loss_epoch=0.0652]Epoch 86: Train Loss = 0.057758595794439316\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0628, train_loss_epoch=0.0578]Epoch 87: Train Loss = 0.06284907460212708\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0564, train_loss_epoch=0.0628]Epoch 88: Train Loss = 0.056414347141981125\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0619, train_loss_epoch=0.0564]Epoch 89: Train Loss = 0.061854053288698196\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0581, train_loss_epoch=0.0619]Epoch 90: Train Loss = 0.05810945853590965\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0571, train_loss_epoch=0.0581]Epoch 91: Train Loss = 0.057092808187007904\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.056, train_loss_epoch=0.0571] Epoch 92: Train Loss = 0.05601632595062256\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.0559, train_loss_epoch=0.056]Epoch 93: Train Loss = 0.05593468248844147\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0582, train_loss_epoch=0.0559]Epoch 94: Train Loss = 0.05815087631344795\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0538, train_loss_epoch=0.0582]Epoch 95: Train Loss = 0.05380764603614807\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0613, train_loss_epoch=0.0538]Epoch 96: Train Loss = 0.0612928681075573\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0523, train_loss_epoch=0.0613]Epoch 97: Train Loss = 0.052281640470027924\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0572, train_loss_epoch=0.0523]Epoch 98: Train Loss = 0.0572037547826767\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.056, train_loss_epoch=0.0572] Epoch 99: Train Loss = 0.05599970743060112\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0573, train_loss_epoch=0.056]Epoch 100: Train Loss = 0.05731303244829178\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0588, train_loss_epoch=0.0573]Epoch 101: Train Loss = 0.05881396308541298\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0536, train_loss_epoch=0.0588]Epoch 102: Train Loss = 0.053585853427648544\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0535, train_loss_epoch=0.0536]Epoch 103: Train Loss = 0.05350050330162048\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0488, train_loss_epoch=0.0535]Epoch 104: Train Loss = 0.0488191694021225\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0543, train_loss_epoch=0.0488]Epoch 105: Train Loss = 0.054321855306625366\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.050, train_loss_epoch=0.0543] Epoch 106: Train Loss = 0.050015028566122055\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0534, train_loss_epoch=0.050]Epoch 107: Train Loss = 0.053433794528245926\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0503, train_loss_epoch=0.0534]Epoch 108: Train Loss = 0.05027834326028824\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0513, train_loss_epoch=0.0503]Epoch 109: Train Loss = 0.0512954480946064\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0515, train_loss_epoch=0.0513]Epoch 110: Train Loss = 0.051528722047805786\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0478, train_loss_epoch=0.0515]Epoch 111: Train Loss = 0.04782113432884216\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0521, train_loss_epoch=0.0478]Epoch 112: Train Loss = 0.05212154611945152\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0483, train_loss_epoch=0.0521]Epoch 113: Train Loss = 0.04825446382164955\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0477, train_loss_epoch=0.0483]Epoch 114: Train Loss = 0.047714222222566605\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0479, train_loss_epoch=0.0477]Epoch 115: Train Loss = 0.047864850610494614\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.045, train_loss_epoch=0.0479] Epoch 116: Train Loss = 0.04497586190700531\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0457, train_loss_epoch=0.045]Epoch 117: Train Loss = 0.04567398503422737\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0472, train_loss_epoch=0.0457]Epoch 118: Train Loss = 0.04715641215443611\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0454, train_loss_epoch=0.0472]Epoch 119: Train Loss = 0.04540344327688217\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0473, train_loss_epoch=0.0454]Epoch 120: Train Loss = 0.04733407869935036\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0481, train_loss_epoch=0.0473]Epoch 121: Train Loss = 0.048130735754966736\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0476, train_loss_epoch=0.0481]Epoch 122: Train Loss = 0.0476037822663784\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0489, train_loss_epoch=0.0476]Epoch 123: Train Loss = 0.0488758459687233\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0439, train_loss_epoch=0.0489]Epoch 124: Train Loss = 0.0439394935965538\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0482, train_loss_epoch=0.0439]Epoch 125: Train Loss = 0.04823268577456474\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0453, train_loss_epoch=0.0482]Epoch 126: Train Loss = 0.04526277631521225\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0469, train_loss_epoch=0.0453]Epoch 127: Train Loss = 0.04685072973370552\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0464, train_loss_epoch=0.0469]Epoch 128: Train Loss = 0.046432364732027054\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0434, train_loss_epoch=0.0464]Epoch 129: Train Loss = 0.04338511452078819\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0475, train_loss_epoch=0.0434]Epoch 130: Train Loss = 0.04748888313770294\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0428, train_loss_epoch=0.0475]Epoch 131: Train Loss = 0.0427568294107914\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0464, train_loss_epoch=0.0428]Epoch 132: Train Loss = 0.04643189534544945\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0426, train_loss_epoch=0.0464]Epoch 133: Train Loss = 0.042572058737277985\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0435, train_loss_epoch=0.0426]Epoch 134: Train Loss = 0.04348406568169594\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0424, train_loss_epoch=0.0435]Epoch 135: Train Loss = 0.04240189865231514\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.042, train_loss_epoch=0.0424] Epoch 136: Train Loss = 0.041969869285821915\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0421, train_loss_epoch=0.042]Epoch 137: Train Loss = 0.04212900251150131\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0424, train_loss_epoch=0.0421]Epoch 138: Train Loss = 0.04243404418230057\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0416, train_loss_epoch=0.0424]Epoch 139: Train Loss = 0.041626252233982086\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0424, train_loss_epoch=0.0416]Epoch 140: Train Loss = 0.04236672818660736\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0407, train_loss_epoch=0.0424]Epoch 141: Train Loss = 0.040679484605789185\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0405, train_loss_epoch=0.0407]Epoch 142: Train Loss = 0.04053996130824089\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.041, train_loss_epoch=0.0405] Epoch 143: Train Loss = 0.04100920632481575\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0404, train_loss_epoch=0.041]Epoch 144: Train Loss = 0.040400125086307526\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0421, train_loss_epoch=0.0404]Epoch 145: Train Loss = 0.042085207998752594\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0431, train_loss_epoch=0.0421]Epoch 146: Train Loss = 0.04305815324187279\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.039, train_loss_epoch=0.0431] Epoch 147: Train Loss = 0.038960643112659454\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0409, train_loss_epoch=0.039]Epoch 148: Train Loss = 0.040909528732299805\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0405, train_loss_epoch=0.0409]Epoch 149: Train Loss = 0.04054349660873413\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0406, train_loss_epoch=0.0405]Epoch 150: Train Loss = 0.04062073677778244\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0396, train_loss_epoch=0.0406]Epoch 151: Train Loss = 0.03960469365119934\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0397, train_loss_epoch=0.0396]Epoch 152: Train Loss = 0.03972000256180763\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0402, train_loss_epoch=0.0397]Epoch 153: Train Loss = 0.04017891734838486\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0404, train_loss_epoch=0.0402]Epoch 154: Train Loss = 0.040401309728622437\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0398, train_loss_epoch=0.0404]Epoch 155: Train Loss = 0.0397837795317173\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0391, train_loss_epoch=0.0398]Epoch 156: Train Loss = 0.03908191993832588\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0405, train_loss_epoch=0.0391]Epoch 157: Train Loss = 0.040522441267967224\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0378, train_loss_epoch=0.0405]Epoch 158: Train Loss = 0.0377565398812294\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0391, train_loss_epoch=0.0378]Epoch 159: Train Loss = 0.039055805653333664\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0377, train_loss_epoch=0.0391]Epoch 160: Train Loss = 0.03774389624595642\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0379, train_loss_epoch=0.0377]Epoch 161: Train Loss = 0.037947122007608414\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0372, train_loss_epoch=0.0379]Epoch 162: Train Loss = 0.037232834845781326\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0369, train_loss_epoch=0.0372]Epoch 163: Train Loss = 0.03689197450876236\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0375, train_loss_epoch=0.0369]Epoch 164: Train Loss = 0.03750252723693848\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0374, train_loss_epoch=0.0375]Epoch 165: Train Loss = 0.03742372617125511\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0375, train_loss_epoch=0.0374]Epoch 166: Train Loss = 0.03753511235117912\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.0368, train_loss_epoch=0.0375]Epoch 167: Train Loss = 0.036845918744802475\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.037, train_loss_epoch=0.0368] Epoch 168: Train Loss = 0.037033647298812866\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.0366, train_loss_epoch=0.037]Epoch 169: Train Loss = 0.03663621470332146\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0361, train_loss_epoch=0.0366]Epoch 170: Train Loss = 0.036081161350011826\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0377, train_loss_epoch=0.0361]Epoch 171: Train Loss = 0.0376867912709713\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0363, train_loss_epoch=0.0377]Epoch 172: Train Loss = 0.03627004846930504\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.039, train_loss_epoch=0.0363] Epoch 173: Train Loss = 0.03897299990057945\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0355, train_loss_epoch=0.039]Epoch 174: Train Loss = 0.03545386716723442\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0359, train_loss_epoch=0.0355]Epoch 175: Train Loss = 0.03588051348924637\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0374, train_loss_epoch=0.0359]Epoch 176: Train Loss = 0.037422265857458115\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0359, train_loss_epoch=0.0374]Epoch 177: Train Loss = 0.03587167710065842\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0368, train_loss_epoch=0.0359]Epoch 178: Train Loss = 0.03677135333418846\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0348, train_loss_epoch=0.0368]Epoch 179: Train Loss = 0.0348464772105217\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0364, train_loss_epoch=0.0348]Epoch 180: Train Loss = 0.0363597497344017\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0396, train_loss_epoch=0.0364]Epoch 181: Train Loss = 0.039551444351673126\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0379, train_loss_epoch=0.0396]Epoch 182: Train Loss = 0.037943582981824875\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0369, train_loss_epoch=0.0379]Epoch 183: Train Loss = 0.03692196309566498\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0352, train_loss_epoch=0.0369]Epoch 184: Train Loss = 0.03521088883280754\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0409, train_loss_epoch=0.0352]Epoch 185: Train Loss = 0.04088177904486656\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0349, train_loss_epoch=0.0409]Epoch 186: Train Loss = 0.034920159727334976\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0424, train_loss_epoch=0.0349]Epoch 187: Train Loss = 0.0424363873898983\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0345, train_loss_epoch=0.0424]Epoch 188: Train Loss = 0.03450236842036247\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0383, train_loss_epoch=0.0345]Epoch 189: Train Loss = 0.03825189545750618\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0346, train_loss_epoch=0.0383]Epoch 190: Train Loss = 0.03462781012058258\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0342, train_loss_epoch=0.0346]Epoch 191: Train Loss = 0.03417240455746651\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0357, train_loss_epoch=0.0342]Epoch 192: Train Loss = 0.035664334893226624\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0345, train_loss_epoch=0.0357]Epoch 193: Train Loss = 0.03445635363459587\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0342, train_loss_epoch=0.0345]Epoch 194: Train Loss = 0.034165702760219574\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0337, train_loss_epoch=0.0342]Epoch 195: Train Loss = 0.03368331491947174\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0343, train_loss_epoch=0.0337]Epoch 196: Train Loss = 0.034276410937309265\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0337, train_loss_epoch=0.0343]Epoch 197: Train Loss = 0.03366656228899956\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0337, train_loss_epoch=0.0337]Epoch 198: Train Loss = 0.03371664509177208\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0339, train_loss_epoch=0.0337]Epoch 199: Train Loss = 0.03391202911734581\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0335, train_loss_epoch=0.0339]Epoch 200: Train Loss = 0.0334770604968071\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0332, train_loss_epoch=0.0335]Epoch 201: Train Loss = 0.03315849229693413\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0332, train_loss_epoch=0.0332]Epoch 202: Train Loss = 0.03318343311548233\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0339, train_loss_epoch=0.0332]Epoch 203: Train Loss = 0.03390901908278465\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.033, train_loss_epoch=0.0339] Epoch 204: Train Loss = 0.03297783434391022\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0329, train_loss_epoch=0.033]Epoch 205: Train Loss = 0.03290761262178421\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.0331, train_loss_epoch=0.0329]Epoch 206: Train Loss = 0.03310837596654892\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0324, train_loss_epoch=0.0331]Epoch 207: Train Loss = 0.032353296875953674\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0333, train_loss_epoch=0.0324]Epoch 208: Train Loss = 0.033322494477033615\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0338, train_loss_epoch=0.0333]Epoch 209: Train Loss = 0.03381850942969322\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0338, train_loss_epoch=0.0338]Epoch 210: Train Loss = 0.03383136913180351\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0329, train_loss_epoch=0.0338]Epoch 211: Train Loss = 0.032854482531547546\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.037, train_loss_epoch=0.0329] Epoch 212: Train Loss = 0.036973610520362854\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0325, train_loss_epoch=0.037]Epoch 213: Train Loss = 0.03250298276543617\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.0332, train_loss_epoch=0.0325]Epoch 214: Train Loss = 0.03316240385174751\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0327, train_loss_epoch=0.0332]Epoch 215: Train Loss = 0.032696668058633804\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=244, train_loss_step=0.032, train_loss_epoch=0.0327] Epoch 216: Train Loss = 0.03198789805173874\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0319, train_loss_epoch=0.032]Epoch 217: Train Loss = 0.03192008659243584\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0323, train_loss_epoch=0.0319]Epoch 218: Train Loss = 0.032311297953128815\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0328, train_loss_epoch=0.0323]Epoch 219: Train Loss = 0.0327606201171875\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0326, train_loss_epoch=0.0328]Epoch 220: Train Loss = 0.03259282186627388\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0334, train_loss_epoch=0.0326]Epoch 221: Train Loss = 0.033362727612257004\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0329, train_loss_epoch=0.0334]Epoch 222: Train Loss = 0.03290148451924324\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0344, train_loss_epoch=0.0329]Epoch 223: Train Loss = 0.03443178907036781\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0357, train_loss_epoch=0.0344]Epoch 224: Train Loss = 0.035720858722925186\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0321, train_loss_epoch=0.0357]Epoch 225: Train Loss = 0.032127365469932556\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0363, train_loss_epoch=0.0321]Epoch 226: Train Loss = 0.03634277358651161\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0329, train_loss_epoch=0.0363]Epoch 227: Train Loss = 0.032943181693553925\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0358, train_loss_epoch=0.0329]Epoch 228: Train Loss = 0.03575408458709717\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0315, train_loss_epoch=0.0358]Epoch 229: Train Loss = 0.03145058825612068\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0317, train_loss_epoch=0.0315]Epoch 230: Train Loss = 0.031652893871068954\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0408, train_loss_epoch=0.0317]Epoch 231: Train Loss = 0.04082011058926582\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0369, train_loss_epoch=0.0408]Epoch 232: Train Loss = 0.036871444433927536\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0361, train_loss_epoch=0.0369]Epoch 233: Train Loss = 0.03612421825528145\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0327, train_loss_epoch=0.0361]Epoch 234: Train Loss = 0.03273266553878784\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0331, train_loss_epoch=0.0327]Epoch 235: Train Loss = 0.03308112174272537\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=244, train_loss_step=0.0317, train_loss_epoch=0.0331]Epoch 236: Train Loss = 0.03168192878365517\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0318, train_loss_epoch=0.0317]Epoch 237: Train Loss = 0.03176962956786156\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0306, train_loss_epoch=0.0318]Epoch 238: Train Loss = 0.030575605109333992\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0309, train_loss_epoch=0.0306]Epoch 239: Train Loss = 0.030886482447385788\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0331, train_loss_epoch=0.0309]Epoch 240: Train Loss = 0.033108633011579514\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0309, train_loss_epoch=0.0331]Epoch 241: Train Loss = 0.03085017018020153\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0315, train_loss_epoch=0.0309]Epoch 242: Train Loss = 0.03154592216014862\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0323, train_loss_epoch=0.0315]Epoch 243: Train Loss = 0.03234662488102913\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0303, train_loss_epoch=0.0323]Epoch 244: Train Loss = 0.030309056863188744\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0325, train_loss_epoch=0.0303]Epoch 245: Train Loss = 0.032511595636606216\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0311, train_loss_epoch=0.0325]Epoch 246: Train Loss = 0.031147051602602005\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0341, train_loss_epoch=0.0311]Epoch 247: Train Loss = 0.03412223234772682\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=244, train_loss_step=0.0339, train_loss_epoch=0.0341]Epoch 248: Train Loss = 0.03389380872249603\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0366, train_loss_epoch=0.0339]Epoch 249: Train Loss = 0.036617450416088104\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0366, train_loss_epoch=0.0366]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=244, train_loss_step=0.0366, train_loss_epoch=0.0366]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 30: from 1998-11-02 00:00:00 to 2022-10-11 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.408]Epoch 0: Train Loss = 0.40819185972213745\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.494, train_loss_epoch=0.408]Epoch 1: Train Loss = 0.4939507842063904\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.379, train_loss_epoch=0.494]Epoch 2: Train Loss = 0.37948888540267944\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.254, train_loss_epoch=0.379]Epoch 3: Train Loss = 0.25443440675735474\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.305, train_loss_epoch=0.254]Epoch 4: Train Loss = 0.30507102608680725\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.313, train_loss_epoch=0.305]Epoch 5: Train Loss = 0.3131421208381653\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.258, train_loss_epoch=0.313]Epoch 6: Train Loss = 0.2581321895122528\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.245, train_loss_epoch=0.258]Epoch 7: Train Loss = 0.24537669122219086\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.268, train_loss_epoch=0.245]Epoch 8: Train Loss = 0.267886221408844\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.263, train_loss_epoch=0.268]Epoch 9: Train Loss = 0.2633482813835144\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.245, train_loss_epoch=0.263]Epoch 10: Train Loss = 0.24491377174854279\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.225, train_loss_epoch=0.245]Epoch 11: Train Loss = 0.22479228675365448\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.241, train_loss_epoch=0.225]Epoch 12: Train Loss = 0.2410334199666977\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.224, train_loss_epoch=0.241]Epoch 13: Train Loss = 0.2243761122226715\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.215, train_loss_epoch=0.224]Epoch 14: Train Loss = 0.21471458673477173\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.192, train_loss_epoch=0.215]Epoch 15: Train Loss = 0.19223284721374512\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.200, train_loss_epoch=0.192]Epoch 16: Train Loss = 0.19952866435050964\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.194, train_loss_epoch=0.200]Epoch 17: Train Loss = 0.19424541294574738\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.201, train_loss_epoch=0.194]Epoch 18: Train Loss = 0.20064224302768707\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.181, train_loss_epoch=0.201]Epoch 19: Train Loss = 0.1808503121137619\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.169, train_loss_epoch=0.181]Epoch 20: Train Loss = 0.169145405292511\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.180, train_loss_epoch=0.169]Epoch 21: Train Loss = 0.18014635145664215\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.184, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.18360066413879395\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.168, train_loss_epoch=0.184]Epoch 23: Train Loss = 0.1682625114917755\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.164, train_loss_epoch=0.168]Epoch 24: Train Loss = 0.1641930490732193\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.155, train_loss_epoch=0.164]Epoch 25: Train Loss = 0.15533603727817535\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.160, train_loss_epoch=0.155]Epoch 26: Train Loss = 0.16024249792099\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.155, train_loss_epoch=0.160]Epoch 27: Train Loss = 0.15475334227085114\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.149, train_loss_epoch=0.155]Epoch 28: Train Loss = 0.14897549152374268\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.149, train_loss_epoch=0.149]Epoch 29: Train Loss = 0.14932511746883392\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.143, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.14307332038879395\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.147, train_loss_epoch=0.143]Epoch 31: Train Loss = 0.14669841527938843\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.140, train_loss_epoch=0.147]Epoch 32: Train Loss = 0.13988395035266876\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.136, train_loss_epoch=0.140]Epoch 33: Train Loss = 0.13592590391635895\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.136, train_loss_epoch=0.136]Epoch 34: Train Loss = 0.1363733410835266\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.134, train_loss_epoch=0.136]Epoch 35: Train Loss = 0.1339687705039978\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.131, train_loss_epoch=0.134]Epoch 36: Train Loss = 0.13056205213069916\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.130, train_loss_epoch=0.131]Epoch 37: Train Loss = 0.12953847646713257\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.124, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12374068796634674\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.120, train_loss_epoch=0.124]Epoch 39: Train Loss = 0.12002027779817581\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.116, train_loss_epoch=0.120]Epoch 40: Train Loss = 0.11605895310640335\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.119, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.11927862465381622\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.117, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.11700115352869034\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.113, train_loss_epoch=0.117]Epoch 43: Train Loss = 0.11282426118850708\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.116, train_loss_epoch=0.113]Epoch 44: Train Loss = 0.11552801728248596\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.108, train_loss_epoch=0.116]Epoch 45: Train Loss = 0.107883982360363\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.107, train_loss_epoch=0.108]Epoch 46: Train Loss = 0.10677098482847214\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.103, train_loss_epoch=0.107]Epoch 47: Train Loss = 0.10329847782850266\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.103, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10278938710689545\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.103, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.1028105691075325\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.100, train_loss_epoch=0.103]Epoch 50: Train Loss = 0.1004435122013092\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.098, train_loss_epoch=0.100]Epoch 51: Train Loss = 0.09801464527845383\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0974, train_loss_epoch=0.098]Epoch 52: Train Loss = 0.09741657227277756\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.095, train_loss_epoch=0.0974] Epoch 53: Train Loss = 0.09504543244838715\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0934, train_loss_epoch=0.095]Epoch 54: Train Loss = 0.09336366504430771\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0942, train_loss_epoch=0.0934]Epoch 55: Train Loss = 0.09416568279266357\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0901, train_loss_epoch=0.0942]Epoch 56: Train Loss = 0.09010127931833267\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0888, train_loss_epoch=0.0901]Epoch 57: Train Loss = 0.08877381682395935\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0889, train_loss_epoch=0.0888]Epoch 58: Train Loss = 0.08890555053949356\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.086, train_loss_epoch=0.0889] Epoch 59: Train Loss = 0.08604942262172699\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0844, train_loss_epoch=0.086]Epoch 60: Train Loss = 0.08442991971969604\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0832, train_loss_epoch=0.0844]Epoch 61: Train Loss = 0.08323833346366882\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0807, train_loss_epoch=0.0832]Epoch 62: Train Loss = 0.0806521624326706\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0808, train_loss_epoch=0.0807]Epoch 63: Train Loss = 0.08082633465528488\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0779, train_loss_epoch=0.0808]Epoch 64: Train Loss = 0.0779256671667099\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0779, train_loss_epoch=0.0779]Epoch 65: Train Loss = 0.07790718227624893\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0795, train_loss_epoch=0.0779]Epoch 66: Train Loss = 0.07949865609407425\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0765, train_loss_epoch=0.0795]Epoch 67: Train Loss = 0.0765109658241272\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0746, train_loss_epoch=0.0765]Epoch 68: Train Loss = 0.07462821900844574\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0725, train_loss_epoch=0.0746]Epoch 69: Train Loss = 0.07245182245969772\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0739, train_loss_epoch=0.0725]Epoch 70: Train Loss = 0.07387138903141022\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.070, train_loss_epoch=0.0739] Epoch 71: Train Loss = 0.07003787159919739\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0695, train_loss_epoch=0.070]Epoch 72: Train Loss = 0.06947211176156998\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0699, train_loss_epoch=0.0695]Epoch 73: Train Loss = 0.06993751227855682\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0685, train_loss_epoch=0.0699]Epoch 74: Train Loss = 0.06854016333818436\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0673, train_loss_epoch=0.0685]Epoch 75: Train Loss = 0.06731085479259491\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0675, train_loss_epoch=0.0673]Epoch 76: Train Loss = 0.067451611161232\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0658, train_loss_epoch=0.0675]Epoch 77: Train Loss = 0.06579511612653732\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0658, train_loss_epoch=0.0658]Epoch 78: Train Loss = 0.06584491580724716\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0649, train_loss_epoch=0.0658]Epoch 79: Train Loss = 0.06485988944768906\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0648, train_loss_epoch=0.0649]Epoch 80: Train Loss = 0.06477147340774536\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0631, train_loss_epoch=0.0648]Epoch 81: Train Loss = 0.06312637776136398\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0625, train_loss_epoch=0.0631]Epoch 82: Train Loss = 0.06249650940299034\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0613, train_loss_epoch=0.0625]Epoch 83: Train Loss = 0.06128948926925659\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0607, train_loss_epoch=0.0613]Epoch 84: Train Loss = 0.060676004737615585\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0589, train_loss_epoch=0.0607]Epoch 85: Train Loss = 0.058933645486831665\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0584, train_loss_epoch=0.0589]Epoch 86: Train Loss = 0.05835777521133423\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.059, train_loss_epoch=0.0584] Epoch 87: Train Loss = 0.05896853283047676\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0584, train_loss_epoch=0.059]Epoch 88: Train Loss = 0.05842791497707367\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0609, train_loss_epoch=0.0584]Epoch 89: Train Loss = 0.06086794286966324\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0594, train_loss_epoch=0.0609]Epoch 90: Train Loss = 0.05937988683581352\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0561, train_loss_epoch=0.0594]Epoch 91: Train Loss = 0.05607261881232262\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0574, train_loss_epoch=0.0561]Epoch 92: Train Loss = 0.05740566924214363\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0544, train_loss_epoch=0.0574]Epoch 93: Train Loss = 0.05436009168624878\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.056, train_loss_epoch=0.0544] Epoch 94: Train Loss = 0.0560375414788723\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0521, train_loss_epoch=0.056]Epoch 95: Train Loss = 0.05214013159275055\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0538, train_loss_epoch=0.0521]Epoch 96: Train Loss = 0.05381914973258972\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0532, train_loss_epoch=0.0538]Epoch 97: Train Loss = 0.05318448320031166\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.054, train_loss_epoch=0.0532] Epoch 98: Train Loss = 0.0539526604115963\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.053, train_loss_epoch=0.054] Epoch 99: Train Loss = 0.05295626446604729\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0545, train_loss_epoch=0.053]Epoch 100: Train Loss = 0.0545419305562973\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0518, train_loss_epoch=0.0545]Epoch 101: Train Loss = 0.05179356038570404\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0528, train_loss_epoch=0.0518]Epoch 102: Train Loss = 0.05280882120132446\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0502, train_loss_epoch=0.0528]Epoch 103: Train Loss = 0.05016215518116951\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0528, train_loss_epoch=0.0502]Epoch 104: Train Loss = 0.05280595272779465\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0488, train_loss_epoch=0.0528]Epoch 105: Train Loss = 0.048790670931339264\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0528, train_loss_epoch=0.0488]Epoch 106: Train Loss = 0.05276455730199814\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0482, train_loss_epoch=0.0528]Epoch 107: Train Loss = 0.04817306250333786\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0538, train_loss_epoch=0.0482]Epoch 108: Train Loss = 0.05378261208534241\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0474, train_loss_epoch=0.0538]Epoch 109: Train Loss = 0.047444019466638565\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0557, train_loss_epoch=0.0474]Epoch 110: Train Loss = 0.055662453174591064\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0477, train_loss_epoch=0.0557]Epoch 111: Train Loss = 0.04773818328976631\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0483, train_loss_epoch=0.0477]Epoch 112: Train Loss = 0.048263952136039734\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0471, train_loss_epoch=0.0483]Epoch 113: Train Loss = 0.04712972417473793\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0484, train_loss_epoch=0.0471]Epoch 114: Train Loss = 0.048385098576545715\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0476, train_loss_epoch=0.0484]Epoch 115: Train Loss = 0.04763297364115715\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0453, train_loss_epoch=0.0476]Epoch 116: Train Loss = 0.04529193788766861\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0524, train_loss_epoch=0.0453]Epoch 117: Train Loss = 0.05235525593161583\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0458, train_loss_epoch=0.0524]Epoch 118: Train Loss = 0.045781057327985764\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0511, train_loss_epoch=0.0458]Epoch 119: Train Loss = 0.05108264461159706\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0436, train_loss_epoch=0.0511]Epoch 120: Train Loss = 0.04361563175916672\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0552, train_loss_epoch=0.0436]Epoch 121: Train Loss = 0.05518876388669014\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.044, train_loss_epoch=0.0552] Epoch 122: Train Loss = 0.04398661106824875\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0542, train_loss_epoch=0.044]Epoch 123: Train Loss = 0.05422505736351013\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.044, train_loss_epoch=0.0542] Epoch 124: Train Loss = 0.04404535889625549\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0534, train_loss_epoch=0.044]Epoch 125: Train Loss = 0.05344626307487488\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0442, train_loss_epoch=0.0534]Epoch 126: Train Loss = 0.04420354589819908\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0486, train_loss_epoch=0.0442]Epoch 127: Train Loss = 0.04860449209809303\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0465, train_loss_epoch=0.0486]Epoch 128: Train Loss = 0.04653201624751091\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0486, train_loss_epoch=0.0465]Epoch 129: Train Loss = 0.048629697412252426\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0485, train_loss_epoch=0.0486]Epoch 130: Train Loss = 0.04848537594079971\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0441, train_loss_epoch=0.0485]Epoch 131: Train Loss = 0.04414617270231247\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0528, train_loss_epoch=0.0441]Epoch 132: Train Loss = 0.052761487662792206\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.041, train_loss_epoch=0.0528] Epoch 133: Train Loss = 0.041011977940797806\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0497, train_loss_epoch=0.041]Epoch 134: Train Loss = 0.04967280104756355\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0422, train_loss_epoch=0.0497]Epoch 135: Train Loss = 0.042157676070928574\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0447, train_loss_epoch=0.0422]Epoch 136: Train Loss = 0.0446772575378418\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0461, train_loss_epoch=0.0447]Epoch 137: Train Loss = 0.0461011566221714\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0411, train_loss_epoch=0.0461]Epoch 138: Train Loss = 0.04106384888291359\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0494, train_loss_epoch=0.0411]Epoch 139: Train Loss = 0.04939110949635506\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0401, train_loss_epoch=0.0494]Epoch 140: Train Loss = 0.04012211784720421\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0467, train_loss_epoch=0.0401]Epoch 141: Train Loss = 0.046662602573633194\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0412, train_loss_epoch=0.0467]Epoch 142: Train Loss = 0.041214678436517715\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0412, train_loss_epoch=0.0412]Epoch 143: Train Loss = 0.04119217395782471\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.040, train_loss_epoch=0.0412] Epoch 144: Train Loss = 0.04002677649259567\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0402, train_loss_epoch=0.040]Epoch 145: Train Loss = 0.04022709280252457\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0411, train_loss_epoch=0.0402]Epoch 146: Train Loss = 0.04113975912332535\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0387, train_loss_epoch=0.0411]Epoch 147: Train Loss = 0.038727760314941406\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0393, train_loss_epoch=0.0387]Epoch 148: Train Loss = 0.03931951895356178\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.040, train_loss_epoch=0.0393] Epoch 149: Train Loss = 0.04004822298884392\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0389, train_loss_epoch=0.040]Epoch 150: Train Loss = 0.038940735161304474\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0381, train_loss_epoch=0.0389]Epoch 151: Train Loss = 0.038100119680166245\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0382, train_loss_epoch=0.0381]Epoch 152: Train Loss = 0.03824367746710777\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.038, train_loss_epoch=0.0382] Epoch 153: Train Loss = 0.0379592664539814\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0396, train_loss_epoch=0.038]Epoch 154: Train Loss = 0.039569608867168427\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0382, train_loss_epoch=0.0396]Epoch 155: Train Loss = 0.038151148706674576\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0388, train_loss_epoch=0.0382]Epoch 156: Train Loss = 0.03875597193837166\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0389, train_loss_epoch=0.0388]Epoch 157: Train Loss = 0.03894146531820297\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0374, train_loss_epoch=0.0389]Epoch 158: Train Loss = 0.03735298663377762\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0381, train_loss_epoch=0.0374]Epoch 159: Train Loss = 0.03808138892054558\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0376, train_loss_epoch=0.0381]Epoch 160: Train Loss = 0.037614885717630386\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0382, train_loss_epoch=0.0376]Epoch 161: Train Loss = 0.03823007270693779\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0378, train_loss_epoch=0.0382]Epoch 162: Train Loss = 0.037816137075424194\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0371, train_loss_epoch=0.0378]Epoch 163: Train Loss = 0.0370536707341671\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0364, train_loss_epoch=0.0371]Epoch 164: Train Loss = 0.03642355650663376\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0372, train_loss_epoch=0.0364]Epoch 165: Train Loss = 0.03715928643941879\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0363, train_loss_epoch=0.0372]Epoch 166: Train Loss = 0.03631594404578209\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0369, train_loss_epoch=0.0363]Epoch 167: Train Loss = 0.03687593340873718\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0371, train_loss_epoch=0.0369]Epoch 168: Train Loss = 0.037147313356399536\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0357, train_loss_epoch=0.0371]Epoch 169: Train Loss = 0.03571411594748497\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0361, train_loss_epoch=0.0357]Epoch 170: Train Loss = 0.03613268584012985\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0364, train_loss_epoch=0.0361]Epoch 171: Train Loss = 0.036410488188266754\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0355, train_loss_epoch=0.0364]Epoch 172: Train Loss = 0.0355374850332737\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0365, train_loss_epoch=0.0355]Epoch 173: Train Loss = 0.036514632403850555\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0368, train_loss_epoch=0.0365]Epoch 174: Train Loss = 0.03684038668870926\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0357, train_loss_epoch=0.0368]Epoch 175: Train Loss = 0.0356624536216259\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.038, train_loss_epoch=0.0357] Epoch 176: Train Loss = 0.03799775615334511\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0495, train_loss_epoch=0.038]Epoch 177: Train Loss = 0.04947006702423096\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0365, train_loss_epoch=0.0495]Epoch 178: Train Loss = 0.036536507308483124\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0479, train_loss_epoch=0.0365]Epoch 179: Train Loss = 0.047927770763635635\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0373, train_loss_epoch=0.0479]Epoch 180: Train Loss = 0.03727325424551964\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0425, train_loss_epoch=0.0373]Epoch 181: Train Loss = 0.04252427816390991\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0382, train_loss_epoch=0.0425]Epoch 182: Train Loss = 0.03824765980243683\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0354, train_loss_epoch=0.0382]Epoch 183: Train Loss = 0.03543689846992493\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0446, train_loss_epoch=0.0354]Epoch 184: Train Loss = 0.044577281922101974\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0344, train_loss_epoch=0.0446]Epoch 185: Train Loss = 0.034364525228738785\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0365, train_loss_epoch=0.0344]Epoch 186: Train Loss = 0.03652229905128479\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0417, train_loss_epoch=0.0365]Epoch 187: Train Loss = 0.041702304035425186\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0358, train_loss_epoch=0.0417]Epoch 188: Train Loss = 0.03581763431429863\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0404, train_loss_epoch=0.0358]Epoch 189: Train Loss = 0.040434930473566055\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0347, train_loss_epoch=0.0404]Epoch 190: Train Loss = 0.03471845015883446\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0347, train_loss_epoch=0.0347]Epoch 191: Train Loss = 0.03470008820295334\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0333, train_loss_epoch=0.0347]Epoch 192: Train Loss = 0.033303312957286835\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0344, train_loss_epoch=0.0333]Epoch 193: Train Loss = 0.03436139225959778\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.035, train_loss_epoch=0.0344] Epoch 194: Train Loss = 0.035013504326343536\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0345, train_loss_epoch=0.035]Epoch 195: Train Loss = 0.03448094427585602\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0356, train_loss_epoch=0.0345]Epoch 196: Train Loss = 0.035609807819128036\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0341, train_loss_epoch=0.0356]Epoch 197: Train Loss = 0.03414469212293625\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0354, train_loss_epoch=0.0341]Epoch 198: Train Loss = 0.035444192588329315\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0344, train_loss_epoch=0.0354]Epoch 199: Train Loss = 0.03444376960396767\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0349, train_loss_epoch=0.0344]Epoch 200: Train Loss = 0.03487562760710716\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0337, train_loss_epoch=0.0349]Epoch 201: Train Loss = 0.03370961919426918\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0344, train_loss_epoch=0.0337]Epoch 202: Train Loss = 0.034351203590631485\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.035, train_loss_epoch=0.0344] Epoch 203: Train Loss = 0.035029102116823196\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0339, train_loss_epoch=0.035]Epoch 204: Train Loss = 0.033851251006126404\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0345, train_loss_epoch=0.0339]Epoch 205: Train Loss = 0.03452111780643463\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0335, train_loss_epoch=0.0345]Epoch 206: Train Loss = 0.03349630907177925\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0327, train_loss_epoch=0.0335]Epoch 207: Train Loss = 0.03273652121424675\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0328, train_loss_epoch=0.0327]Epoch 208: Train Loss = 0.03284846991300583\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0361, train_loss_epoch=0.0328]Epoch 209: Train Loss = 0.03607043996453285\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0332, train_loss_epoch=0.0361]Epoch 210: Train Loss = 0.033236462622880936\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0373, train_loss_epoch=0.0332]Epoch 211: Train Loss = 0.03725225850939751\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0333, train_loss_epoch=0.0373]Epoch 212: Train Loss = 0.03334593027830124\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0337, train_loss_epoch=0.0333]Epoch 213: Train Loss = 0.033715639263391495\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0348, train_loss_epoch=0.0337]Epoch 214: Train Loss = 0.03478140011429787\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0326, train_loss_epoch=0.0348]Epoch 215: Train Loss = 0.032614730298519135\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0348, train_loss_epoch=0.0326]Epoch 216: Train Loss = 0.03477909415960312\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0324, train_loss_epoch=0.0348]Epoch 217: Train Loss = 0.03236539289355278\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0338, train_loss_epoch=0.0324]Epoch 218: Train Loss = 0.033807750791311264\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0357, train_loss_epoch=0.0338]Epoch 219: Train Loss = 0.035740822553634644\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0332, train_loss_epoch=0.0357]Epoch 220: Train Loss = 0.03320835158228874\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0341, train_loss_epoch=0.0332]Epoch 221: Train Loss = 0.0341135673224926\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0334, train_loss_epoch=0.0341]Epoch 222: Train Loss = 0.033448778092861176\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0332, train_loss_epoch=0.0334]Epoch 223: Train Loss = 0.03319641575217247\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0326, train_loss_epoch=0.0332]Epoch 224: Train Loss = 0.032587893307209015\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0329, train_loss_epoch=0.0326]Epoch 225: Train Loss = 0.03288391977548599\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0328, train_loss_epoch=0.0329]Epoch 226: Train Loss = 0.03283916041254997\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0325, train_loss_epoch=0.0328]Epoch 227: Train Loss = 0.032496318221092224\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0317, train_loss_epoch=0.0325]Epoch 228: Train Loss = 0.03165653720498085\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0354, train_loss_epoch=0.0317]Epoch 229: Train Loss = 0.03538837656378746\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0315, train_loss_epoch=0.0354]Epoch 230: Train Loss = 0.03145527467131615\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0356, train_loss_epoch=0.0315]Epoch 231: Train Loss = 0.03561967983841896\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0314, train_loss_epoch=0.0356]Epoch 232: Train Loss = 0.03141443431377411\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0347, train_loss_epoch=0.0314]Epoch 233: Train Loss = 0.034687358886003494\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0325, train_loss_epoch=0.0347]Epoch 234: Train Loss = 0.03249711915850639\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0333, train_loss_epoch=0.0325]Epoch 235: Train Loss = 0.0333479680120945\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0313, train_loss_epoch=0.0333]Epoch 236: Train Loss = 0.03126015514135361\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0315, train_loss_epoch=0.0313]Epoch 237: Train Loss = 0.03150583431124687\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0319, train_loss_epoch=0.0315]Epoch 238: Train Loss = 0.03194716200232506\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0313, train_loss_epoch=0.0319]Epoch 239: Train Loss = 0.03129415214061737\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0309, train_loss_epoch=0.0313]Epoch 240: Train Loss = 0.030908476561307907\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=246, train_loss_step=0.0327, train_loss_epoch=0.0309]Epoch 241: Train Loss = 0.03272669017314911\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0316, train_loss_epoch=0.0327]Epoch 242: Train Loss = 0.03157300874590874\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0318, train_loss_epoch=0.0316]Epoch 243: Train Loss = 0.031785834580659866\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0317, train_loss_epoch=0.0318]Epoch 244: Train Loss = 0.03172726929187775\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0311, train_loss_epoch=0.0317]Epoch 245: Train Loss = 0.031145401298999786\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0313, train_loss_epoch=0.0311]Epoch 246: Train Loss = 0.03132987767457962\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=246, train_loss_step=0.0308, train_loss_epoch=0.0313]Epoch 247: Train Loss = 0.03079606592655182\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=246, train_loss_step=0.0313, train_loss_epoch=0.0308]Epoch 248: Train Loss = 0.03134723752737045\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0303, train_loss_epoch=0.0313]Epoch 249: Train Loss = 0.030349494889378548\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0303, train_loss_epoch=0.0303]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=246, train_loss_step=0.0303, train_loss_epoch=0.0303]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 31: from 1998-11-02 00:00:00 to 2022-10-20 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.401]Epoch 0: Train Loss = 0.40096622705459595\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.492, train_loss_epoch=0.401]Epoch 1: Train Loss = 0.49231383204460144\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.370, train_loss_epoch=0.492]Epoch 2: Train Loss = 0.3704582154750824\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.254, train_loss_epoch=0.370]Epoch 3: Train Loss = 0.25407078862190247\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.312, train_loss_epoch=0.254]Epoch 4: Train Loss = 0.3123960494995117\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.311, train_loss_epoch=0.312]Epoch 5: Train Loss = 0.31120896339416504\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.254, train_loss_epoch=0.311]Epoch 6: Train Loss = 0.25359803438186646\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.243, train_loss_epoch=0.254]Epoch 7: Train Loss = 0.24264128506183624\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.269, train_loss_epoch=0.243]Epoch 8: Train Loss = 0.2694076597690582\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.264, train_loss_epoch=0.269]Epoch 9: Train Loss = 0.2644144296646118\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.244, train_loss_epoch=0.264]Epoch 10: Train Loss = 0.244272381067276\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.220, train_loss_epoch=0.244]Epoch 11: Train Loss = 0.22024200856685638\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.235, train_loss_epoch=0.220]Epoch 12: Train Loss = 0.23504576086997986\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.228, train_loss_epoch=0.235]Epoch 13: Train Loss = 0.22791774570941925\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.216, train_loss_epoch=0.228]Epoch 14: Train Loss = 0.21581704914569855\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.190, train_loss_epoch=0.216]Epoch 15: Train Loss = 0.1901116520166397\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.201, train_loss_epoch=0.190]Epoch 16: Train Loss = 0.200858473777771\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.193, train_loss_epoch=0.201]Epoch 17: Train Loss = 0.1930626481771469\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.198, train_loss_epoch=0.193]Epoch 18: Train Loss = 0.19836601614952087\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.176, train_loss_epoch=0.198]Epoch 19: Train Loss = 0.17627383768558502\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.167, train_loss_epoch=0.176]Epoch 20: Train Loss = 0.1669282168149948\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.178, train_loss_epoch=0.167]Epoch 21: Train Loss = 0.17782661318778992\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.179, train_loss_epoch=0.178]Epoch 22: Train Loss = 0.17934231460094452\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.168, train_loss_epoch=0.179]Epoch 23: Train Loss = 0.16822725534439087\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.162, train_loss_epoch=0.168]Epoch 24: Train Loss = 0.16206678748130798\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.159, train_loss_epoch=0.162]Epoch 25: Train Loss = 0.15880990028381348\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.161, train_loss_epoch=0.159]Epoch 26: Train Loss = 0.161216601729393\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.154, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.15425968170166016\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.146, train_loss_epoch=0.154]Epoch 28: Train Loss = 0.14643952250480652\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.149, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.1488107293844223\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.144, train_loss_epoch=0.149]Epoch 30: Train Loss = 0.14358890056610107\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.144, train_loss_epoch=0.144]Epoch 31: Train Loss = 0.14350759983062744\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.140, train_loss_epoch=0.144]Epoch 32: Train Loss = 0.1397325098514557\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.134, train_loss_epoch=0.140]Epoch 33: Train Loss = 0.13354064524173737\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.137, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.13658422231674194\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.133, train_loss_epoch=0.137]Epoch 35: Train Loss = 0.13342423737049103\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.129, train_loss_epoch=0.133]Epoch 36: Train Loss = 0.12888862192630768\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.131, train_loss_epoch=0.129]Epoch 37: Train Loss = 0.13109809160232544\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.124, train_loss_epoch=0.131]Epoch 38: Train Loss = 0.12428613007068634\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.118, train_loss_epoch=0.124]Epoch 39: Train Loss = 0.1181759312748909\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.117, train_loss_epoch=0.118]Epoch 40: Train Loss = 0.11709249764680862\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.119, train_loss_epoch=0.117]Epoch 41: Train Loss = 0.11873195320367813\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.115, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.11486570537090302\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.110, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.10977596044540405\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.115, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.1145506501197815\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.109, train_loss_epoch=0.115]Epoch 45: Train Loss = 0.10857890546321869\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.106, train_loss_epoch=0.109]Epoch 46: Train Loss = 0.10624779015779495\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.103, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.10285535454750061\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.102, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10169249773025513\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.104, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.10390093922615051\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.101, train_loss_epoch=0.104]Epoch 50: Train Loss = 0.10107393562793732\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0974, train_loss_epoch=0.101]Epoch 51: Train Loss = 0.09736695885658264\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0966, train_loss_epoch=0.0974]Epoch 52: Train Loss = 0.09662450850009918\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0954, train_loss_epoch=0.0966]Epoch 53: Train Loss = 0.09542683511972427\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0935, train_loss_epoch=0.0954]Epoch 54: Train Loss = 0.09345535188913345\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0927, train_loss_epoch=0.0935]Epoch 55: Train Loss = 0.09273235499858856\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0902, train_loss_epoch=0.0927]Epoch 56: Train Loss = 0.09019940346479416\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0886, train_loss_epoch=0.0902]Epoch 57: Train Loss = 0.08858273923397064\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0877, train_loss_epoch=0.0886]Epoch 58: Train Loss = 0.08773939311504364\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0868, train_loss_epoch=0.0877]Epoch 59: Train Loss = 0.08680714666843414\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0859, train_loss_epoch=0.0868]Epoch 60: Train Loss = 0.08594442903995514\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.0859, train_loss_epoch=0.0859]Epoch 61: Train Loss = 0.08587957173585892\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0819, train_loss_epoch=0.0859]Epoch 62: Train Loss = 0.08192523568868637\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0816, train_loss_epoch=0.0819]Epoch 63: Train Loss = 0.08156103640794754\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0808, train_loss_epoch=0.0816]Epoch 64: Train Loss = 0.08082638680934906\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0784, train_loss_epoch=0.0808]Epoch 65: Train Loss = 0.07837268710136414\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0821, train_loss_epoch=0.0784]Epoch 66: Train Loss = 0.08214472979307175\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.077, train_loss_epoch=0.0821] Epoch 67: Train Loss = 0.07695791870355606\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0755, train_loss_epoch=0.077]Epoch 68: Train Loss = 0.07549440115690231\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0727, train_loss_epoch=0.0755]Epoch 69: Train Loss = 0.07270362228155136\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0751, train_loss_epoch=0.0727]Epoch 70: Train Loss = 0.07507898658514023\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0712, train_loss_epoch=0.0751]Epoch 71: Train Loss = 0.07123126834630966\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.071, train_loss_epoch=0.0712] Epoch 72: Train Loss = 0.0710383728146553\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0725, train_loss_epoch=0.071]Epoch 73: Train Loss = 0.07250835746526718\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0713, train_loss_epoch=0.0725]Epoch 74: Train Loss = 0.0713403970003128\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.068, train_loss_epoch=0.0713] Epoch 75: Train Loss = 0.06802262365818024\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0706, train_loss_epoch=0.068]Epoch 76: Train Loss = 0.07062110304832458\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0662, train_loss_epoch=0.0706]Epoch 77: Train Loss = 0.06619307398796082\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0746, train_loss_epoch=0.0662]Epoch 78: Train Loss = 0.07456056028604507\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.0635, train_loss_epoch=0.0746]Epoch 79: Train Loss = 0.06346140056848526\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0662, train_loss_epoch=0.0635]Epoch 80: Train Loss = 0.06619732081890106\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0691, train_loss_epoch=0.0662]Epoch 81: Train Loss = 0.06905760616064072\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0659, train_loss_epoch=0.0691]Epoch 82: Train Loss = 0.06588513404130936\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0673, train_loss_epoch=0.0659]Epoch 83: Train Loss = 0.06733954697847366\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0627, train_loss_epoch=0.0673]Epoch 84: Train Loss = 0.06266828626394272\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0667, train_loss_epoch=0.0627]Epoch 85: Train Loss = 0.06671306490898132\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0605, train_loss_epoch=0.0667]Epoch 86: Train Loss = 0.06049476936459541\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0638, train_loss_epoch=0.0605]Epoch 87: Train Loss = 0.06384129822254181\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.0587, train_loss_epoch=0.0638]Epoch 88: Train Loss = 0.05870489776134491\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0597, train_loss_epoch=0.0587]Epoch 89: Train Loss = 0.05970017984509468\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0591, train_loss_epoch=0.0597]Epoch 90: Train Loss = 0.05906977504491806\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0572, train_loss_epoch=0.0591]Epoch 91: Train Loss = 0.05720715969800949\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0608, train_loss_epoch=0.0572]Epoch 92: Train Loss = 0.060847315937280655\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0569, train_loss_epoch=0.0608]Epoch 93: Train Loss = 0.056886520236730576\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.063, train_loss_epoch=0.0569] Epoch 94: Train Loss = 0.0629967600107193\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0563, train_loss_epoch=0.063]Epoch 95: Train Loss = 0.05634729936718941\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0599, train_loss_epoch=0.0563]Epoch 96: Train Loss = 0.059862568974494934\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0551, train_loss_epoch=0.0599]Epoch 97: Train Loss = 0.055052123963832855\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0552, train_loss_epoch=0.0551]Epoch 98: Train Loss = 0.055209651589393616\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.055, train_loss_epoch=0.0552] Epoch 99: Train Loss = 0.05500900372862816\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0538, train_loss_epoch=0.055]Epoch 100: Train Loss = 0.053843025118112564\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0577, train_loss_epoch=0.0538]Epoch 101: Train Loss = 0.057726435363292694\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0522, train_loss_epoch=0.0577]Epoch 102: Train Loss = 0.052238255739212036\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0549, train_loss_epoch=0.0522]Epoch 103: Train Loss = 0.054924916476011276\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.0529, train_loss_epoch=0.0549]Epoch 104: Train Loss = 0.05290493369102478\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0537, train_loss_epoch=0.0529]Epoch 105: Train Loss = 0.05370480567216873\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.0509, train_loss_epoch=0.0537]Epoch 106: Train Loss = 0.0509193129837513\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0503, train_loss_epoch=0.0509]Epoch 107: Train Loss = 0.05031583458185196\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0505, train_loss_epoch=0.0503]Epoch 108: Train Loss = 0.050541967153549194\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0496, train_loss_epoch=0.0505]Epoch 109: Train Loss = 0.04961942508816719\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0491, train_loss_epoch=0.0496]Epoch 110: Train Loss = 0.04909021779894829\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0494, train_loss_epoch=0.0491]Epoch 111: Train Loss = 0.04941701516509056\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0485, train_loss_epoch=0.0494]Epoch 112: Train Loss = 0.04852445051074028\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.048, train_loss_epoch=0.0485] Epoch 113: Train Loss = 0.047951459884643555\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0483, train_loss_epoch=0.048]Epoch 114: Train Loss = 0.048295438289642334\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0475, train_loss_epoch=0.0483]Epoch 115: Train Loss = 0.04745857045054436\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0465, train_loss_epoch=0.0475]Epoch 116: Train Loss = 0.04652536287903786\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.046, train_loss_epoch=0.0465] Epoch 117: Train Loss = 0.046043090522289276\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0465, train_loss_epoch=0.046]Epoch 118: Train Loss = 0.046547383069992065\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0479, train_loss_epoch=0.0465]Epoch 119: Train Loss = 0.04789697751402855\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0462, train_loss_epoch=0.0479]Epoch 120: Train Loss = 0.046223435550928116\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0505, train_loss_epoch=0.0462]Epoch 121: Train Loss = 0.050508636981248856\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0452, train_loss_epoch=0.0505]Epoch 122: Train Loss = 0.045151133090257645\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0466, train_loss_epoch=0.0452]Epoch 123: Train Loss = 0.046602435410022736\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0457, train_loss_epoch=0.0466]Epoch 124: Train Loss = 0.0457000732421875\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0466, train_loss_epoch=0.0457]Epoch 125: Train Loss = 0.04656920209527016\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0493, train_loss_epoch=0.0466]Epoch 126: Train Loss = 0.04926947131752968\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0453, train_loss_epoch=0.0493]Epoch 127: Train Loss = 0.04527134820818901\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0508, train_loss_epoch=0.0453]Epoch 128: Train Loss = 0.0508006252348423\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0441, train_loss_epoch=0.0508]Epoch 129: Train Loss = 0.0440632663667202\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.049, train_loss_epoch=0.0441] Epoch 130: Train Loss = 0.049035027623176575\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0455, train_loss_epoch=0.049]Epoch 131: Train Loss = 0.04545559361577034\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0438, train_loss_epoch=0.0455]Epoch 132: Train Loss = 0.043783050030469894\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0519, train_loss_epoch=0.0438]Epoch 133: Train Loss = 0.05187300220131874\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0416, train_loss_epoch=0.0519]Epoch 134: Train Loss = 0.04160875827074051\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0482, train_loss_epoch=0.0416]Epoch 135: Train Loss = 0.048199981451034546\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0441, train_loss_epoch=0.0482]Epoch 136: Train Loss = 0.04406780004501343\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0447, train_loss_epoch=0.0441]Epoch 137: Train Loss = 0.04472559690475464\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0425, train_loss_epoch=0.0447]Epoch 138: Train Loss = 0.04249601811170578\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0421, train_loss_epoch=0.0425]Epoch 139: Train Loss = 0.04205629229545593\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0482, train_loss_epoch=0.0421]Epoch 140: Train Loss = 0.048173461109399796\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0415, train_loss_epoch=0.0482]Epoch 141: Train Loss = 0.041506264358758926\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0448, train_loss_epoch=0.0415]Epoch 142: Train Loss = 0.04475157707929611\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0429, train_loss_epoch=0.0448]Epoch 143: Train Loss = 0.042883049696683884\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0406, train_loss_epoch=0.0429]Epoch 144: Train Loss = 0.04064543917775154\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0444, train_loss_epoch=0.0406]Epoch 145: Train Loss = 0.044430267065763474\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0405, train_loss_epoch=0.0444]Epoch 146: Train Loss = 0.04051210358738899\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0491, train_loss_epoch=0.0405]Epoch 147: Train Loss = 0.049139805138111115\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0403, train_loss_epoch=0.0491]Epoch 148: Train Loss = 0.04032919928431511\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0447, train_loss_epoch=0.0403]Epoch 149: Train Loss = 0.04468294978141785\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0407, train_loss_epoch=0.0447]Epoch 150: Train Loss = 0.04074006527662277\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0455, train_loss_epoch=0.0407]Epoch 151: Train Loss = 0.04551340267062187\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0457, train_loss_epoch=0.0455]Epoch 152: Train Loss = 0.045676339417696\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0449, train_loss_epoch=0.0457]Epoch 153: Train Loss = 0.04489179328083992\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.0402, train_loss_epoch=0.0449]Epoch 154: Train Loss = 0.04022809490561485\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0391, train_loss_epoch=0.0402]Epoch 155: Train Loss = 0.039065245538949966\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0407, train_loss_epoch=0.0391]Epoch 156: Train Loss = 0.040745582431554794\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0419, train_loss_epoch=0.0407]Epoch 157: Train Loss = 0.041861094534397125\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0406, train_loss_epoch=0.0419]Epoch 158: Train Loss = 0.0406283400952816\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0415, train_loss_epoch=0.0406]Epoch 159: Train Loss = 0.041480448096990585\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0378, train_loss_epoch=0.0415]Epoch 160: Train Loss = 0.037753842771053314\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0396, train_loss_epoch=0.0378]Epoch 161: Train Loss = 0.039606254547834396\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0404, train_loss_epoch=0.0396]Epoch 162: Train Loss = 0.040428899228572845\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.039, train_loss_epoch=0.0404] Epoch 163: Train Loss = 0.03896545246243477\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0405, train_loss_epoch=0.039]Epoch 164: Train Loss = 0.040525585412979126\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0377, train_loss_epoch=0.0405]Epoch 165: Train Loss = 0.037656914442777634\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0447, train_loss_epoch=0.0377]Epoch 166: Train Loss = 0.04465237259864807\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0372, train_loss_epoch=0.0447]Epoch 167: Train Loss = 0.037180762737989426\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0423, train_loss_epoch=0.0372]Epoch 168: Train Loss = 0.042308591306209564\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0391, train_loss_epoch=0.0423]Epoch 169: Train Loss = 0.039130862802267075\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0374, train_loss_epoch=0.0391]Epoch 170: Train Loss = 0.0374084934592247\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0429, train_loss_epoch=0.0374]Epoch 171: Train Loss = 0.04288896545767784\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0359, train_loss_epoch=0.0429]Epoch 172: Train Loss = 0.035906556993722916\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0417, train_loss_epoch=0.0359]Epoch 173: Train Loss = 0.04167253151535988\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0397, train_loss_epoch=0.0417]Epoch 174: Train Loss = 0.039729684591293335\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.039, train_loss_epoch=0.0397] Epoch 175: Train Loss = 0.03898361697793007\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.044, train_loss_epoch=0.039] Epoch 176: Train Loss = 0.04401421546936035\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0363, train_loss_epoch=0.044]Epoch 177: Train Loss = 0.036282092332839966\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0428, train_loss_epoch=0.0363]Epoch 178: Train Loss = 0.04281696677207947\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0379, train_loss_epoch=0.0428]Epoch 179: Train Loss = 0.03793849050998688\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0365, train_loss_epoch=0.0379]Epoch 180: Train Loss = 0.03653157502412796\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0437, train_loss_epoch=0.0365]Epoch 181: Train Loss = 0.04366566985845566\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0354, train_loss_epoch=0.0437]Epoch 182: Train Loss = 0.03543971851468086\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0407, train_loss_epoch=0.0354]Epoch 183: Train Loss = 0.04073108360171318\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0361, train_loss_epoch=0.0407]Epoch 184: Train Loss = 0.03607325628399849\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0357, train_loss_epoch=0.0361]Epoch 185: Train Loss = 0.035731442272663116\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0361, train_loss_epoch=0.0357]Epoch 186: Train Loss = 0.03609945625066757\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0358, train_loss_epoch=0.0361]Epoch 187: Train Loss = 0.03578806295990944\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0362, train_loss_epoch=0.0358]Epoch 188: Train Loss = 0.03621691092848778\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0358, train_loss_epoch=0.0362]Epoch 189: Train Loss = 0.0357658751308918\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0362, train_loss_epoch=0.0358]Epoch 190: Train Loss = 0.03616185113787651\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.035, train_loss_epoch=0.0362] Epoch 191: Train Loss = 0.03495056554675102\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.0369, train_loss_epoch=0.035]Epoch 192: Train Loss = 0.036910269409418106\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0363, train_loss_epoch=0.0369]Epoch 193: Train Loss = 0.036266013979911804\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=248, train_loss_step=0.0374, train_loss_epoch=0.0363]Epoch 194: Train Loss = 0.03738690912723541\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0343, train_loss_epoch=0.0374]Epoch 195: Train Loss = 0.03430585935711861\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.037, train_loss_epoch=0.0343] Epoch 196: Train Loss = 0.03702319785952568\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0346, train_loss_epoch=0.037]Epoch 197: Train Loss = 0.03459399566054344\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0354, train_loss_epoch=0.0346]Epoch 198: Train Loss = 0.035449132323265076\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0443, train_loss_epoch=0.0354]Epoch 199: Train Loss = 0.04429509490728378\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0344, train_loss_epoch=0.0443]Epoch 200: Train Loss = 0.03437693044543266\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0405, train_loss_epoch=0.0344]Epoch 201: Train Loss = 0.04051389545202255\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0343, train_loss_epoch=0.0405]Epoch 202: Train Loss = 0.03426651284098625\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0344, train_loss_epoch=0.0343]Epoch 203: Train Loss = 0.03440277278423309\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0364, train_loss_epoch=0.0344]Epoch 204: Train Loss = 0.03638136759400368\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0334, train_loss_epoch=0.0364]Epoch 205: Train Loss = 0.03344292938709259\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0351, train_loss_epoch=0.0334]Epoch 206: Train Loss = 0.03509782999753952\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0343, train_loss_epoch=0.0351]Epoch 207: Train Loss = 0.034265026450157166\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0344, train_loss_epoch=0.0343]Epoch 208: Train Loss = 0.034350741654634476\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0335, train_loss_epoch=0.0344]Epoch 209: Train Loss = 0.03347502276301384\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0336, train_loss_epoch=0.0335]Epoch 210: Train Loss = 0.033599693328142166\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.033, train_loss_epoch=0.0336] Epoch 211: Train Loss = 0.032989270985126495\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0359, train_loss_epoch=0.033]Epoch 212: Train Loss = 0.035915203392505646\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0365, train_loss_epoch=0.0359]Epoch 213: Train Loss = 0.0365334115922451\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0341, train_loss_epoch=0.0365]Epoch 214: Train Loss = 0.03411541506648064\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0329, train_loss_epoch=0.0341]Epoch 215: Train Loss = 0.032858848571777344\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0334, train_loss_epoch=0.0329]Epoch 216: Train Loss = 0.03338509052991867\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.033, train_loss_epoch=0.0334] Epoch 217: Train Loss = 0.03295488655567169\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0329, train_loss_epoch=0.033]Epoch 218: Train Loss = 0.032878898084163666\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0335, train_loss_epoch=0.0329]Epoch 219: Train Loss = 0.033506423234939575\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0327, train_loss_epoch=0.0335]Epoch 220: Train Loss = 0.032664574682712555\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.033, train_loss_epoch=0.0327] Epoch 221: Train Loss = 0.03297295793890953\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0331, train_loss_epoch=0.033]Epoch 222: Train Loss = 0.033080074936151505\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0339, train_loss_epoch=0.0331]Epoch 223: Train Loss = 0.03390711173415184\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0336, train_loss_epoch=0.0339]Epoch 224: Train Loss = 0.03357518091797829\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0326, train_loss_epoch=0.0336]Epoch 225: Train Loss = 0.03260532394051552\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0331, train_loss_epoch=0.0326]Epoch 226: Train Loss = 0.033097583800554276\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0331, train_loss_epoch=0.0331]Epoch 227: Train Loss = 0.033141858875751495\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0372, train_loss_epoch=0.0331]Epoch 228: Train Loss = 0.03716322034597397\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0328, train_loss_epoch=0.0372]Epoch 229: Train Loss = 0.032849911600351334\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0327, train_loss_epoch=0.0328]Epoch 230: Train Loss = 0.032654136419296265\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0341, train_loss_epoch=0.0327]Epoch 231: Train Loss = 0.03406081721186638\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0325, train_loss_epoch=0.0341]Epoch 232: Train Loss = 0.03245028108358383\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0368, train_loss_epoch=0.0325]Epoch 233: Train Loss = 0.03679865226149559\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.033, train_loss_epoch=0.0368] Epoch 234: Train Loss = 0.0330389030277729\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0325, train_loss_epoch=0.033]Epoch 235: Train Loss = 0.032489385455846786\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0385, train_loss_epoch=0.0325]Epoch 236: Train Loss = 0.038480762392282486\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0319, train_loss_epoch=0.0385]Epoch 237: Train Loss = 0.03187309578061104\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0357, train_loss_epoch=0.0319]Epoch 238: Train Loss = 0.03574271872639656\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0327, train_loss_epoch=0.0357]Epoch 239: Train Loss = 0.03270360082387924\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0307, train_loss_epoch=0.0327]Epoch 240: Train Loss = 0.030749039724469185\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0375, train_loss_epoch=0.0307]Epoch 241: Train Loss = 0.03753611072897911\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0328, train_loss_epoch=0.0375]Epoch 242: Train Loss = 0.0327763557434082\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.039, train_loss_epoch=0.0328] Epoch 243: Train Loss = 0.03897234797477722\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0336, train_loss_epoch=0.039]Epoch 244: Train Loss = 0.03359898179769516\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.0324, train_loss_epoch=0.0336]Epoch 245: Train Loss = 0.03237355127930641\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0441, train_loss_epoch=0.0324]Epoch 246: Train Loss = 0.04407280310988426\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=248, train_loss_step=0.031, train_loss_epoch=0.0441] Epoch 247: Train Loss = 0.03099554404616356\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=248, train_loss_step=0.0319, train_loss_epoch=0.031]Epoch 248: Train Loss = 0.031888704746961594\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0334, train_loss_epoch=0.0319]Epoch 249: Train Loss = 0.033408135175704956\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0334, train_loss_epoch=0.0334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=248, train_loss_step=0.0334, train_loss_epoch=0.0334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 32: from 1998-11-02 00:00:00 to 2022-10-31 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.408]Epoch 0: Train Loss = 0.40754571557044983\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.489, train_loss_epoch=0.408]Epoch 1: Train Loss = 0.4888247549533844\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.378, train_loss_epoch=0.489]Epoch 2: Train Loss = 0.37764349579811096\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.249, train_loss_epoch=0.378]Epoch 3: Train Loss = 0.24929717183113098\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.307, train_loss_epoch=0.249]Epoch 4: Train Loss = 0.30704736709594727\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.311, train_loss_epoch=0.307]Epoch 5: Train Loss = 0.31058424711227417\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.256, train_loss_epoch=0.311]Epoch 6: Train Loss = 0.2559506297111511\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.244, train_loss_epoch=0.256]Epoch 7: Train Loss = 0.2444559782743454\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.266, train_loss_epoch=0.244]Epoch 8: Train Loss = 0.26590922474861145\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.259, train_loss_epoch=0.266]Epoch 9: Train Loss = 0.2593957185745239\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.240, train_loss_epoch=0.259]Epoch 10: Train Loss = 0.2403031289577484\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.220, train_loss_epoch=0.240]Epoch 11: Train Loss = 0.2201891988515854\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.237, train_loss_epoch=0.220]Epoch 12: Train Loss = 0.23672688007354736\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.219, train_loss_epoch=0.237]Epoch 13: Train Loss = 0.21893736720085144\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.212, train_loss_epoch=0.219]Epoch 14: Train Loss = 0.2116532176733017\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.191, train_loss_epoch=0.212]Epoch 15: Train Loss = 0.19067694246768951\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.200, train_loss_epoch=0.191]Epoch 16: Train Loss = 0.2002323567867279\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.192, train_loss_epoch=0.200]Epoch 17: Train Loss = 0.19196508824825287\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.197, train_loss_epoch=0.192]Epoch 18: Train Loss = 0.1968488097190857\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.175, train_loss_epoch=0.197]Epoch 19: Train Loss = 0.17505301535129547\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.168, train_loss_epoch=0.175]Epoch 20: Train Loss = 0.16780994832515717\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.180, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.17973853647708893\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.175, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.17462874948978424\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.164, train_loss_epoch=0.175]Epoch 23: Train Loss = 0.16361957788467407\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.158, train_loss_epoch=0.164]Epoch 24: Train Loss = 0.15786096453666687\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.157, train_loss_epoch=0.158]Epoch 25: Train Loss = 0.1573273241519928\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.159, train_loss_epoch=0.157]Epoch 26: Train Loss = 0.15941128134727478\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.151, train_loss_epoch=0.159]Epoch 27: Train Loss = 0.15065164864063263\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.145, train_loss_epoch=0.151]Epoch 28: Train Loss = 0.14465054869651794\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.151, train_loss_epoch=0.145]Epoch 29: Train Loss = 0.1514308601617813\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.142, train_loss_epoch=0.151]Epoch 30: Train Loss = 0.14209629595279694\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.142, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.1419500708580017\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.136, train_loss_epoch=0.142]Epoch 32: Train Loss = 0.13639429211616516\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.134, train_loss_epoch=0.136]Epoch 33: Train Loss = 0.1335291862487793\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.133, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.13260909914970398\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.129, train_loss_epoch=0.133]Epoch 35: Train Loss = 0.12891653180122375\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.130, train_loss_epoch=0.129]Epoch 36: Train Loss = 0.12951457500457764\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.130, train_loss_epoch=0.130]Epoch 37: Train Loss = 0.1295517534017563\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.121, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12138060480356216\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.117, train_loss_epoch=0.121]Epoch 39: Train Loss = 0.11692751944065094\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.117, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11677484959363937\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.117, train_loss_epoch=0.117]Epoch 41: Train Loss = 0.1168443113565445\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.113, train_loss_epoch=0.117]Epoch 42: Train Loss = 0.1129341647028923\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.109, train_loss_epoch=0.113]Epoch 43: Train Loss = 0.10928063839673996\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.113, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11289773136377335\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.107, train_loss_epoch=0.113]Epoch 45: Train Loss = 0.10742306709289551\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.105, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10488791763782501\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.102, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10225946456193924\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.101, train_loss_epoch=0.102]Epoch 48: Train Loss = 0.10052977502346039\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.101, train_loss_epoch=0.101]Epoch 49: Train Loss = 0.1006217747926712\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0973, train_loss_epoch=0.101]Epoch 50: Train Loss = 0.09726695716381073\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0971, train_loss_epoch=0.0973]Epoch 51: Train Loss = 0.09709823876619339\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0954, train_loss_epoch=0.0971]Epoch 52: Train Loss = 0.09538078308105469\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.094, train_loss_epoch=0.0954] Epoch 53: Train Loss = 0.09402462095022202\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0913, train_loss_epoch=0.094]Epoch 54: Train Loss = 0.09126173704862595\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0924, train_loss_epoch=0.0913]Epoch 55: Train Loss = 0.09239501506090164\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0911, train_loss_epoch=0.0924]Epoch 56: Train Loss = 0.09105373173952103\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0863, train_loss_epoch=0.0911]Epoch 57: Train Loss = 0.08631263673305511\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0883, train_loss_epoch=0.0863]Epoch 58: Train Loss = 0.08833913505077362\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0865, train_loss_epoch=0.0883]Epoch 59: Train Loss = 0.08654008060693741\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0835, train_loss_epoch=0.0865]Epoch 60: Train Loss = 0.08351463079452515\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.087, train_loss_epoch=0.0835] Epoch 61: Train Loss = 0.08697906136512756\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0793, train_loss_epoch=0.087]Epoch 62: Train Loss = 0.07929542660713196\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0817, train_loss_epoch=0.0793]Epoch 63: Train Loss = 0.08167677372694016\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0795, train_loss_epoch=0.0817]Epoch 64: Train Loss = 0.07953733205795288\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0768, train_loss_epoch=0.0795]Epoch 65: Train Loss = 0.07679624110460281\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0816, train_loss_epoch=0.0768]Epoch 66: Train Loss = 0.08162076026201248\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0754, train_loss_epoch=0.0816]Epoch 67: Train Loss = 0.07539531588554382\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0758, train_loss_epoch=0.0754]Epoch 68: Train Loss = 0.0758131891489029\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0722, train_loss_epoch=0.0758]Epoch 69: Train Loss = 0.07224586606025696\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0744, train_loss_epoch=0.0722]Epoch 70: Train Loss = 0.07440070807933807\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.070, train_loss_epoch=0.0744] Epoch 71: Train Loss = 0.0699811801314354\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0691, train_loss_epoch=0.070]Epoch 72: Train Loss = 0.06911473721265793\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.071, train_loss_epoch=0.0691] Epoch 73: Train Loss = 0.07101220637559891\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.070, train_loss_epoch=0.071] Epoch 74: Train Loss = 0.07002269476652145\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0685, train_loss_epoch=0.070]Epoch 75: Train Loss = 0.06851310282945633\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0672, train_loss_epoch=0.0685]Epoch 76: Train Loss = 0.06716369092464447\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0679, train_loss_epoch=0.0672]Epoch 77: Train Loss = 0.0678989440202713\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0681, train_loss_epoch=0.0679]Epoch 78: Train Loss = 0.06814128160476685\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0656, train_loss_epoch=0.0681]Epoch 79: Train Loss = 0.06563842296600342\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0655, train_loss_epoch=0.0656]Epoch 80: Train Loss = 0.06552980095148087\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0625, train_loss_epoch=0.0655]Epoch 81: Train Loss = 0.06254345923662186\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0683, train_loss_epoch=0.0625]Epoch 82: Train Loss = 0.06827037781476974\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0624, train_loss_epoch=0.0683]Epoch 83: Train Loss = 0.062350787222385406\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0684, train_loss_epoch=0.0624]Epoch 84: Train Loss = 0.06835262477397919\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0615, train_loss_epoch=0.0684]Epoch 85: Train Loss = 0.06153351441025734\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0614, train_loss_epoch=0.0615]Epoch 86: Train Loss = 0.0613589845597744\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0621, train_loss_epoch=0.0614]Epoch 87: Train Loss = 0.06205437704920769\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0578, train_loss_epoch=0.0621]Epoch 88: Train Loss = 0.05782117694616318\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.062, train_loss_epoch=0.0578] Epoch 89: Train Loss = 0.06197310611605644\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0578, train_loss_epoch=0.062]Epoch 90: Train Loss = 0.057757195085287094\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0579, train_loss_epoch=0.0578]Epoch 91: Train Loss = 0.057872116565704346\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0577, train_loss_epoch=0.0579]Epoch 92: Train Loss = 0.05769261717796326\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.057, train_loss_epoch=0.0577] Epoch 93: Train Loss = 0.056951090693473816\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0583, train_loss_epoch=0.057]Epoch 94: Train Loss = 0.05833149328827858\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0543, train_loss_epoch=0.0583]Epoch 95: Train Loss = 0.05429057031869888\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.064, train_loss_epoch=0.0543] Epoch 96: Train Loss = 0.06397086381912231\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0527, train_loss_epoch=0.064]Epoch 97: Train Loss = 0.05265636369585991\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0592, train_loss_epoch=0.0527]Epoch 98: Train Loss = 0.05916127935051918\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0531, train_loss_epoch=0.0592]Epoch 99: Train Loss = 0.053105585277080536\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0562, train_loss_epoch=0.0531]Epoch 100: Train Loss = 0.05616661533713341\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0545, train_loss_epoch=0.0562]Epoch 101: Train Loss = 0.05448906868696213\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.052, train_loss_epoch=0.0545] Epoch 102: Train Loss = 0.05204562470316887\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0533, train_loss_epoch=0.052]Epoch 103: Train Loss = 0.05327679216861725\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0507, train_loss_epoch=0.0533]Epoch 104: Train Loss = 0.05065932869911194\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0551, train_loss_epoch=0.0507]Epoch 105: Train Loss = 0.05507178232073784\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0506, train_loss_epoch=0.0551]Epoch 106: Train Loss = 0.05059528350830078\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0526, train_loss_epoch=0.0506]Epoch 107: Train Loss = 0.05264122039079666\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.050, train_loss_epoch=0.0526] Epoch 108: Train Loss = 0.04996362328529358\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.050, train_loss_epoch=0.050] Epoch 109: Train Loss = 0.05001775920391083\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0485, train_loss_epoch=0.050]Epoch 110: Train Loss = 0.048548292368650436\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0498, train_loss_epoch=0.0485]Epoch 111: Train Loss = 0.04982529953122139\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0483, train_loss_epoch=0.0498]Epoch 112: Train Loss = 0.04825253412127495\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0484, train_loss_epoch=0.0483]Epoch 113: Train Loss = 0.048350606113672256\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0495, train_loss_epoch=0.0484]Epoch 114: Train Loss = 0.04954276606440544\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0477, train_loss_epoch=0.0495]Epoch 115: Train Loss = 0.047728151082992554\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0485, train_loss_epoch=0.0477]Epoch 116: Train Loss = 0.04854942113161087\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.047, train_loss_epoch=0.0485] Epoch 117: Train Loss = 0.04701632261276245\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0454, train_loss_epoch=0.047]Epoch 118: Train Loss = 0.045370277017354965\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0472, train_loss_epoch=0.0454]Epoch 119: Train Loss = 0.047194041311740875\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0446, train_loss_epoch=0.0472]Epoch 120: Train Loss = 0.04458102956414223\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0459, train_loss_epoch=0.0446]Epoch 121: Train Loss = 0.045934658497571945\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0451, train_loss_epoch=0.0459]Epoch 122: Train Loss = 0.04508368298411369\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0454, train_loss_epoch=0.0451]Epoch 123: Train Loss = 0.04537634551525116\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0458, train_loss_epoch=0.0454]Epoch 124: Train Loss = 0.04578584432601929\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0445, train_loss_epoch=0.0458]Epoch 125: Train Loss = 0.04449121654033661\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0456, train_loss_epoch=0.0445]Epoch 126: Train Loss = 0.045610833913087845\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0451, train_loss_epoch=0.0456]Epoch 127: Train Loss = 0.0450763925909996\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0451, train_loss_epoch=0.0451]Epoch 128: Train Loss = 0.04511624574661255\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0437, train_loss_epoch=0.0451]Epoch 129: Train Loss = 0.043655071407556534\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0454, train_loss_epoch=0.0437]Epoch 130: Train Loss = 0.04536669701337814\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.045, train_loss_epoch=0.0454] Epoch 131: Train Loss = 0.044994745403528214\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0436, train_loss_epoch=0.045]Epoch 132: Train Loss = 0.043601229786872864\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.048, train_loss_epoch=0.0436] Epoch 133: Train Loss = 0.048040371388196945\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0429, train_loss_epoch=0.048]Epoch 134: Train Loss = 0.042910534888505936\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0468, train_loss_epoch=0.0429]Epoch 135: Train Loss = 0.04676729813218117\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0423, train_loss_epoch=0.0468]Epoch 136: Train Loss = 0.042283687740564346\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0483, train_loss_epoch=0.0423]Epoch 137: Train Loss = 0.04825267195701599\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0422, train_loss_epoch=0.0483]Epoch 138: Train Loss = 0.04219436272978783\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0421, train_loss_epoch=0.0422]Epoch 139: Train Loss = 0.04207136109471321\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0468, train_loss_epoch=0.0421]Epoch 140: Train Loss = 0.046793557703495026\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0427, train_loss_epoch=0.0468]Epoch 141: Train Loss = 0.0426749549806118\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0441, train_loss_epoch=0.0427]Epoch 142: Train Loss = 0.04412166029214859\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0415, train_loss_epoch=0.0441]Epoch 143: Train Loss = 0.04147108271718025\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0421, train_loss_epoch=0.0415]Epoch 144: Train Loss = 0.04207480698823929\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0405, train_loss_epoch=0.0421]Epoch 145: Train Loss = 0.040465451776981354\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0423, train_loss_epoch=0.0405]Epoch 146: Train Loss = 0.04234722629189491\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0392, train_loss_epoch=0.0423]Epoch 147: Train Loss = 0.03919915854930878\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0401, train_loss_epoch=0.0392]Epoch 148: Train Loss = 0.04013944789767265\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0401, train_loss_epoch=0.0401]Epoch 149: Train Loss = 0.040065474808216095\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.040, train_loss_epoch=0.0401] Epoch 150: Train Loss = 0.039963871240615845\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0411, train_loss_epoch=0.040]Epoch 151: Train Loss = 0.0410650260746479\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0405, train_loss_epoch=0.0411]Epoch 152: Train Loss = 0.04052601382136345\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0444, train_loss_epoch=0.0405]Epoch 153: Train Loss = 0.04435328021645546\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0421, train_loss_epoch=0.0444]Epoch 154: Train Loss = 0.04207019507884979\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0443, train_loss_epoch=0.0421]Epoch 155: Train Loss = 0.04427168518304825\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0402, train_loss_epoch=0.0443]Epoch 156: Train Loss = 0.04022589698433876\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0429, train_loss_epoch=0.0402]Epoch 157: Train Loss = 0.04290590062737465\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0376, train_loss_epoch=0.0429]Epoch 158: Train Loss = 0.03759961947798729\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0435, train_loss_epoch=0.0376]Epoch 159: Train Loss = 0.043537288904190063\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0381, train_loss_epoch=0.0435]Epoch 160: Train Loss = 0.03807003051042557\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.042, train_loss_epoch=0.0381] Epoch 161: Train Loss = 0.04199765995144844\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0383, train_loss_epoch=0.042]Epoch 162: Train Loss = 0.03832908347249031\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0401, train_loss_epoch=0.0383]Epoch 163: Train Loss = 0.04007164016366005\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0411, train_loss_epoch=0.0401]Epoch 164: Train Loss = 0.04108424857258797\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0385, train_loss_epoch=0.0411]Epoch 165: Train Loss = 0.03848365321755409\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0422, train_loss_epoch=0.0385]Epoch 166: Train Loss = 0.0422060564160347\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0362, train_loss_epoch=0.0422]Epoch 167: Train Loss = 0.03621412441134453\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0423, train_loss_epoch=0.0362]Epoch 168: Train Loss = 0.04226688668131828\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0376, train_loss_epoch=0.0423]Epoch 169: Train Loss = 0.03761899843811989\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0415, train_loss_epoch=0.0376]Epoch 170: Train Loss = 0.04150484874844551\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0369, train_loss_epoch=0.0415]Epoch 171: Train Loss = 0.036878980696201324\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0365, train_loss_epoch=0.0369]Epoch 172: Train Loss = 0.03652673214673996\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0394, train_loss_epoch=0.0365]Epoch 173: Train Loss = 0.039407964795827866\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0366, train_loss_epoch=0.0394]Epoch 174: Train Loss = 0.03662433102726936\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0399, train_loss_epoch=0.0366]Epoch 175: Train Loss = 0.03986472263932228\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0358, train_loss_epoch=0.0399]Epoch 176: Train Loss = 0.03584801405668259\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0422, train_loss_epoch=0.0358]Epoch 177: Train Loss = 0.042224496603012085\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0373, train_loss_epoch=0.0422]Epoch 178: Train Loss = 0.03728417307138443\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.043, train_loss_epoch=0.0373] Epoch 179: Train Loss = 0.04300827905535698\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.036, train_loss_epoch=0.043] Epoch 180: Train Loss = 0.03599052131175995\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.037, train_loss_epoch=0.036]Epoch 181: Train Loss = 0.03702868893742561\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0374, train_loss_epoch=0.037]Epoch 182: Train Loss = 0.03741469979286194\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.036, train_loss_epoch=0.0374] Epoch 183: Train Loss = 0.03596183657646179\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0399, train_loss_epoch=0.036]Epoch 184: Train Loss = 0.039923761039972305\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0354, train_loss_epoch=0.0399]Epoch 185: Train Loss = 0.03535237908363342\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0383, train_loss_epoch=0.0354]Epoch 186: Train Loss = 0.03828764706850052\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0369, train_loss_epoch=0.0383]Epoch 187: Train Loss = 0.03685203939676285\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0351, train_loss_epoch=0.0369]Epoch 188: Train Loss = 0.03514553979039192\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0393, train_loss_epoch=0.0351]Epoch 189: Train Loss = 0.039295583963394165\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0375, train_loss_epoch=0.0393]Epoch 190: Train Loss = 0.037462037056684494\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0356, train_loss_epoch=0.0375]Epoch 191: Train Loss = 0.03556526079773903\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0417, train_loss_epoch=0.0356]Epoch 192: Train Loss = 0.04172935336828232\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0349, train_loss_epoch=0.0417]Epoch 193: Train Loss = 0.034947242587804794\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0395, train_loss_epoch=0.0349]Epoch 194: Train Loss = 0.039504460990428925\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.034, train_loss_epoch=0.0395] Epoch 195: Train Loss = 0.03396189212799072\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0375, train_loss_epoch=0.034]Epoch 196: Train Loss = 0.03753769025206566\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0344, train_loss_epoch=0.0375]Epoch 197: Train Loss = 0.03441823646426201\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0337, train_loss_epoch=0.0344]Epoch 198: Train Loss = 0.033749256283044815\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0338, train_loss_epoch=0.0337]Epoch 199: Train Loss = 0.033780161291360855\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0337, train_loss_epoch=0.0338]Epoch 200: Train Loss = 0.033697791397571564\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0336, train_loss_epoch=0.0337]Epoch 201: Train Loss = 0.03362974151968956\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0344, train_loss_epoch=0.0336]Epoch 202: Train Loss = 0.034435708075761795\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0336, train_loss_epoch=0.0344]Epoch 203: Train Loss = 0.033644020557403564\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0335, train_loss_epoch=0.0336]Epoch 204: Train Loss = 0.03345399349927902\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.037, train_loss_epoch=0.0335] Epoch 205: Train Loss = 0.037017881870269775\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0335, train_loss_epoch=0.037]Epoch 206: Train Loss = 0.03354671970009804\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0338, train_loss_epoch=0.0335]Epoch 207: Train Loss = 0.03379373997449875\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0334, train_loss_epoch=0.0338]Epoch 208: Train Loss = 0.03341410681605339\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.034, train_loss_epoch=0.0334] Epoch 209: Train Loss = 0.0339609757065773\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0354, train_loss_epoch=0.034]Epoch 210: Train Loss = 0.03543809428811073\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0333, train_loss_epoch=0.0354]Epoch 211: Train Loss = 0.03327937051653862\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0354, train_loss_epoch=0.0333]Epoch 212: Train Loss = 0.03539193049073219\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.033, train_loss_epoch=0.0354] Epoch 213: Train Loss = 0.03301047533750534\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0341, train_loss_epoch=0.033]Epoch 214: Train Loss = 0.03406890481710434\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.034, train_loss_epoch=0.0341] Epoch 215: Train Loss = 0.034040484577417374\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0347, train_loss_epoch=0.034]Epoch 216: Train Loss = 0.03471497818827629\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0336, train_loss_epoch=0.0347]Epoch 217: Train Loss = 0.03358727693557739\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0352, train_loss_epoch=0.0336]Epoch 218: Train Loss = 0.035211630165576935\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0352, train_loss_epoch=0.0352]Epoch 219: Train Loss = 0.03518036752939224\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0358, train_loss_epoch=0.0352]Epoch 220: Train Loss = 0.035841841250658035\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0333, train_loss_epoch=0.0358]Epoch 221: Train Loss = 0.033289916813373566\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0341, train_loss_epoch=0.0333]Epoch 222: Train Loss = 0.03413165733218193\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0327, train_loss_epoch=0.0341]Epoch 223: Train Loss = 0.0327034518122673\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0329, train_loss_epoch=0.0327]Epoch 224: Train Loss = 0.03294830396771431\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0323, train_loss_epoch=0.0329]Epoch 225: Train Loss = 0.032281544059515\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0332, train_loss_epoch=0.0323]Epoch 226: Train Loss = 0.033205777406692505\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0321, train_loss_epoch=0.0332]Epoch 227: Train Loss = 0.03211601823568344\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0319, train_loss_epoch=0.0321]Epoch 228: Train Loss = 0.03186844289302826\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0334, train_loss_epoch=0.0319]Epoch 229: Train Loss = 0.03335524722933769\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0318, train_loss_epoch=0.0334]Epoch 230: Train Loss = 0.03183629363775253\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0329, train_loss_epoch=0.0318]Epoch 231: Train Loss = 0.032855402678251266\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0328, train_loss_epoch=0.0329]Epoch 232: Train Loss = 0.03280791640281677\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0319, train_loss_epoch=0.0328]Epoch 233: Train Loss = 0.03192002326250076\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0326, train_loss_epoch=0.0319]Epoch 234: Train Loss = 0.03255932405591011\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0327, train_loss_epoch=0.0326]Epoch 235: Train Loss = 0.03265674412250519\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0353, train_loss_epoch=0.0327]Epoch 236: Train Loss = 0.03532596305012703\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.033, train_loss_epoch=0.0353] Epoch 237: Train Loss = 0.03303074091672897\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0348, train_loss_epoch=0.033]Epoch 238: Train Loss = 0.03480768948793411\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0334, train_loss_epoch=0.0348]Epoch 239: Train Loss = 0.03339908644556999\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0322, train_loss_epoch=0.0334]Epoch 240: Train Loss = 0.03216002136468887\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0326, train_loss_epoch=0.0322]Epoch 241: Train Loss = 0.03261564299464226\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=250, train_loss_step=0.0312, train_loss_epoch=0.0326]Epoch 242: Train Loss = 0.031170343980193138\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=250, train_loss_step=0.0314, train_loss_epoch=0.0312]Epoch 243: Train Loss = 0.03139976039528847\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0309, train_loss_epoch=0.0314]Epoch 244: Train Loss = 0.030948331579566002\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.031, train_loss_epoch=0.0309] Epoch 245: Train Loss = 0.031046632677316666\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0317, train_loss_epoch=0.031]Epoch 246: Train Loss = 0.03166118264198303\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=250, train_loss_step=0.0319, train_loss_epoch=0.0317]Epoch 247: Train Loss = 0.0319000743329525\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0304, train_loss_epoch=0.0319]Epoch 248: Train Loss = 0.030401313677430153\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0324, train_loss_epoch=0.0304]Epoch 249: Train Loss = 0.032381150871515274\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0324, train_loss_epoch=0.0324]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=250, train_loss_step=0.0324, train_loss_epoch=0.0324]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 33: from 1998-11-02 00:00:00 to 2022-11-09 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.404]Epoch 0: Train Loss = 0.4039496183395386\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.491, train_loss_epoch=0.404]Epoch 1: Train Loss = 0.49101898074150085\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.377, train_loss_epoch=0.491]Epoch 2: Train Loss = 0.37712371349334717\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.252, train_loss_epoch=0.377]Epoch 3: Train Loss = 0.25160056352615356\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.311, train_loss_epoch=0.252]Epoch 4: Train Loss = 0.31085145473480225\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.311, train_loss_epoch=0.311]Epoch 5: Train Loss = 0.31145668029785156\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.259, train_loss_epoch=0.311]Epoch 6: Train Loss = 0.25918275117874146\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.239, train_loss_epoch=0.259]Epoch 7: Train Loss = 0.23876024782657623\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.266, train_loss_epoch=0.239]Epoch 8: Train Loss = 0.2664375305175781\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.262, train_loss_epoch=0.266]Epoch 9: Train Loss = 0.26218119263648987\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.244, train_loss_epoch=0.262]Epoch 10: Train Loss = 0.2435000240802765\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.221, train_loss_epoch=0.244]Epoch 11: Train Loss = 0.2208290845155716\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.236, train_loss_epoch=0.221]Epoch 12: Train Loss = 0.23553724586963654\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.218, train_loss_epoch=0.236]Epoch 13: Train Loss = 0.2181510478258133\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.215, train_loss_epoch=0.218]Epoch 14: Train Loss = 0.21478430926799774\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.198, train_loss_epoch=0.215]Epoch 15: Train Loss = 0.19848786294460297\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.200, train_loss_epoch=0.198]Epoch 16: Train Loss = 0.19999007880687714\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.193, train_loss_epoch=0.200]Epoch 17: Train Loss = 0.1933470070362091\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.198, train_loss_epoch=0.193]Epoch 18: Train Loss = 0.19821499288082123\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.176, train_loss_epoch=0.198]Epoch 19: Train Loss = 0.1758844554424286\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.168, train_loss_epoch=0.176]Epoch 20: Train Loss = 0.1684257835149765\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.180, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.17958137392997742\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.178, train_loss_epoch=0.180]Epoch 22: Train Loss = 0.17820127308368683\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.171, train_loss_epoch=0.178]Epoch 23: Train Loss = 0.17135192453861237\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.161, train_loss_epoch=0.171]Epoch 24: Train Loss = 0.16121642291545868\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.153, train_loss_epoch=0.161]Epoch 25: Train Loss = 0.1526843011379242\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.161, train_loss_epoch=0.153]Epoch 26: Train Loss = 0.1611078977584839\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.156, train_loss_epoch=0.161]Epoch 27: Train Loss = 0.15579120814800262\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.150, train_loss_epoch=0.156]Epoch 28: Train Loss = 0.15015390515327454\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.152, train_loss_epoch=0.150]Epoch 29: Train Loss = 0.15196013450622559\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.142, train_loss_epoch=0.152]Epoch 30: Train Loss = 0.14216242730617523\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.141, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.14103266596794128\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.142, train_loss_epoch=0.141]Epoch 32: Train Loss = 0.14217910170555115\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.133, train_loss_epoch=0.142]Epoch 33: Train Loss = 0.13296887278556824\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.134, train_loss_epoch=0.133]Epoch 34: Train Loss = 0.134304940700531\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.133, train_loss_epoch=0.134]Epoch 35: Train Loss = 0.13273851573467255\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.130, train_loss_epoch=0.133]Epoch 36: Train Loss = 0.13016392290592194\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.131, train_loss_epoch=0.130]Epoch 37: Train Loss = 0.13114196062088013\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.123, train_loss_epoch=0.131]Epoch 38: Train Loss = 0.12250161170959473\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.117, train_loss_epoch=0.123]Epoch 39: Train Loss = 0.11734703183174133\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.116, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11619587987661362\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.119, train_loss_epoch=0.116]Epoch 41: Train Loss = 0.1190744936466217\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.116, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.11621028929948807\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.109, train_loss_epoch=0.116]Epoch 43: Train Loss = 0.10924818366765976\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.114, train_loss_epoch=0.109]Epoch 44: Train Loss = 0.11435182392597198\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.107, train_loss_epoch=0.114]Epoch 45: Train Loss = 0.10736524313688278\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.107, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10659301280975342\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.104, train_loss_epoch=0.107]Epoch 47: Train Loss = 0.1035974994301796\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.102, train_loss_epoch=0.104]Epoch 48: Train Loss = 0.10230627655982971\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.102, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.10223323851823807\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0984, train_loss_epoch=0.102]Epoch 50: Train Loss = 0.09844450652599335\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0972, train_loss_epoch=0.0984]Epoch 51: Train Loss = 0.0972113162279129\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0956, train_loss_epoch=0.0972]Epoch 52: Train Loss = 0.09557238221168518\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0952, train_loss_epoch=0.0956]Epoch 53: Train Loss = 0.09523649513721466\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0924, train_loss_epoch=0.0952]Epoch 54: Train Loss = 0.09239495545625687\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=252, train_loss_step=0.0917, train_loss_epoch=0.0924]Epoch 55: Train Loss = 0.09173053503036499\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0894, train_loss_epoch=0.0917]Epoch 56: Train Loss = 0.08940350264310837\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0875, train_loss_epoch=0.0894]Epoch 57: Train Loss = 0.08749975264072418\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0876, train_loss_epoch=0.0875]Epoch 58: Train Loss = 0.08762477338314056\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0853, train_loss_epoch=0.0876]Epoch 59: Train Loss = 0.08526237308979034\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0844, train_loss_epoch=0.0853]Epoch 60: Train Loss = 0.08437595516443253\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0829, train_loss_epoch=0.0844]Epoch 61: Train Loss = 0.08288183063268661\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0794, train_loss_epoch=0.0829]Epoch 62: Train Loss = 0.07939644157886505\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0794, train_loss_epoch=0.0794]Epoch 63: Train Loss = 0.07943142205476761\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0786, train_loss_epoch=0.0794]Epoch 64: Train Loss = 0.07860907167196274\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0786, train_loss_epoch=0.0786]Epoch 65: Train Loss = 0.0785757452249527\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0782, train_loss_epoch=0.0786]Epoch 66: Train Loss = 0.07823516428470612\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0787, train_loss_epoch=0.0782]Epoch 67: Train Loss = 0.07865454256534576\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0735, train_loss_epoch=0.0787]Epoch 68: Train Loss = 0.07352552562952042\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0742, train_loss_epoch=0.0735]Epoch 69: Train Loss = 0.07420246303081512\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.073, train_loss_epoch=0.0742] Epoch 70: Train Loss = 0.07297760248184204\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0722, train_loss_epoch=0.073]Epoch 71: Train Loss = 0.07217467576265335\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0688, train_loss_epoch=0.0722]Epoch 72: Train Loss = 0.06882079690694809\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0696, train_loss_epoch=0.0688]Epoch 73: Train Loss = 0.06963004916906357\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.069, train_loss_epoch=0.0696] Epoch 74: Train Loss = 0.06898912787437439\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0658, train_loss_epoch=0.069]Epoch 75: Train Loss = 0.06583822518587112\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0676, train_loss_epoch=0.0658]Epoch 76: Train Loss = 0.06755311787128448\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0659, train_loss_epoch=0.0676]Epoch 77: Train Loss = 0.06590897589921951\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0663, train_loss_epoch=0.0659]Epoch 78: Train Loss = 0.06633532792329788\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0632, train_loss_epoch=0.0663]Epoch 79: Train Loss = 0.06317972391843796\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0691, train_loss_epoch=0.0632]Epoch 80: Train Loss = 0.06907094269990921\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0623, train_loss_epoch=0.0691]Epoch 81: Train Loss = 0.062277764081954956\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0682, train_loss_epoch=0.0623]Epoch 82: Train Loss = 0.06823965907096863\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.061, train_loss_epoch=0.0682] Epoch 83: Train Loss = 0.06097572669386864\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0654, train_loss_epoch=0.061]Epoch 84: Train Loss = 0.0653623417019844\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0612, train_loss_epoch=0.0654]Epoch 85: Train Loss = 0.06120363622903824\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0641, train_loss_epoch=0.0612]Epoch 86: Train Loss = 0.06412844359874725\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0619, train_loss_epoch=0.0641]Epoch 87: Train Loss = 0.06186574324965477\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0622, train_loss_epoch=0.0619]Epoch 88: Train Loss = 0.06224306300282478\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0609, train_loss_epoch=0.0622]Epoch 89: Train Loss = 0.06089438870549202\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.058, train_loss_epoch=0.0609] Epoch 90: Train Loss = 0.057999491691589355\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0607, train_loss_epoch=0.058]Epoch 91: Train Loss = 0.06065106764435768\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0559, train_loss_epoch=0.0607]Epoch 92: Train Loss = 0.05593210831284523\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0641, train_loss_epoch=0.0559]Epoch 93: Train Loss = 0.06408984959125519\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0552, train_loss_epoch=0.0641]Epoch 94: Train Loss = 0.05516080558300018\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.066, train_loss_epoch=0.0552] Epoch 95: Train Loss = 0.06602977961301804\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0562, train_loss_epoch=0.066]Epoch 96: Train Loss = 0.056190334260463715\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0574, train_loss_epoch=0.0562]Epoch 97: Train Loss = 0.0573575459420681\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0593, train_loss_epoch=0.0574]Epoch 98: Train Loss = 0.059262972325086594\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.054, train_loss_epoch=0.0593] Epoch 99: Train Loss = 0.05400592088699341\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0563, train_loss_epoch=0.054]Epoch 100: Train Loss = 0.05627935752272606\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0531, train_loss_epoch=0.0563]Epoch 101: Train Loss = 0.05305137485265732\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0515, train_loss_epoch=0.0531]Epoch 102: Train Loss = 0.05150504782795906\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0537, train_loss_epoch=0.0515]Epoch 103: Train Loss = 0.05374051630496979\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0509, train_loss_epoch=0.0537]Epoch 104: Train Loss = 0.05094994232058525\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.051, train_loss_epoch=0.0509] Epoch 105: Train Loss = 0.05096506327390671\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0503, train_loss_epoch=0.051]Epoch 106: Train Loss = 0.05026788264513016\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0502, train_loss_epoch=0.0503]Epoch 107: Train Loss = 0.05022372677922249\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0499, train_loss_epoch=0.0502]Epoch 108: Train Loss = 0.049882467836141586\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.050, train_loss_epoch=0.0499] Epoch 109: Train Loss = 0.04996766522526741\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0498, train_loss_epoch=0.050]Epoch 110: Train Loss = 0.04977165535092354\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0492, train_loss_epoch=0.0498]Epoch 111: Train Loss = 0.04915093630552292\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0491, train_loss_epoch=0.0492]Epoch 112: Train Loss = 0.04908379167318344\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0482, train_loss_epoch=0.0491]Epoch 113: Train Loss = 0.04824084788560867\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0502, train_loss_epoch=0.0482]Epoch 114: Train Loss = 0.05024636164307594\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.048, train_loss_epoch=0.0502] Epoch 115: Train Loss = 0.04799342900514603\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0515, train_loss_epoch=0.048]Epoch 116: Train Loss = 0.051519352942705154\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0481, train_loss_epoch=0.0515]Epoch 117: Train Loss = 0.04810827597975731\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0492, train_loss_epoch=0.0481]Epoch 118: Train Loss = 0.04922832176089287\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0516, train_loss_epoch=0.0492]Epoch 119: Train Loss = 0.05158155411481857\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=252, train_loss_step=0.0472, train_loss_epoch=0.0516]Epoch 120: Train Loss = 0.047227125614881516\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0532, train_loss_epoch=0.0472]Epoch 121: Train Loss = 0.053240660578012466\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0465, train_loss_epoch=0.0532]Epoch 122: Train Loss = 0.04648706689476967\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0533, train_loss_epoch=0.0465]Epoch 123: Train Loss = 0.05330632999539375\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0458, train_loss_epoch=0.0533]Epoch 124: Train Loss = 0.04576938971877098\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0486, train_loss_epoch=0.0458]Epoch 125: Train Loss = 0.048570260405540466\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0435, train_loss_epoch=0.0486]Epoch 126: Train Loss = 0.04350125789642334\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0487, train_loss_epoch=0.0435]Epoch 127: Train Loss = 0.04869784414768219\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0433, train_loss_epoch=0.0487]Epoch 128: Train Loss = 0.04332961514592171\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0452, train_loss_epoch=0.0433]Epoch 129: Train Loss = 0.045165110379457474\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0429, train_loss_epoch=0.0452]Epoch 130: Train Loss = 0.04292948916554451\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0439, train_loss_epoch=0.0429]Epoch 131: Train Loss = 0.043872639536857605\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0483, train_loss_epoch=0.0439]Epoch 132: Train Loss = 0.04825647547841072\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0435, train_loss_epoch=0.0483]Epoch 133: Train Loss = 0.0435403510928154\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0467, train_loss_epoch=0.0435]Epoch 134: Train Loss = 0.046731214970350266\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0427, train_loss_epoch=0.0467]Epoch 135: Train Loss = 0.0427105538547039\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0424, train_loss_epoch=0.0427]Epoch 136: Train Loss = 0.04244058206677437\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0416, train_loss_epoch=0.0424]Epoch 137: Train Loss = 0.04163987189531326\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0431, train_loss_epoch=0.0416]Epoch 138: Train Loss = 0.04311598837375641\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0428, train_loss_epoch=0.0431]Epoch 139: Train Loss = 0.042842961847782135\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0412, train_loss_epoch=0.0428]Epoch 140: Train Loss = 0.0411982536315918\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0409, train_loss_epoch=0.0412]Epoch 141: Train Loss = 0.040923137217760086\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0421, train_loss_epoch=0.0409]Epoch 142: Train Loss = 0.04213448613882065\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0429, train_loss_epoch=0.0421]Epoch 143: Train Loss = 0.042901091277599335\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0414, train_loss_epoch=0.0429]Epoch 144: Train Loss = 0.04143156483769417\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0413, train_loss_epoch=0.0414]Epoch 145: Train Loss = 0.04129365459084511\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0415, train_loss_epoch=0.0413]Epoch 146: Train Loss = 0.041480135172605515\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0404, train_loss_epoch=0.0415]Epoch 147: Train Loss = 0.04038962721824646\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0417, train_loss_epoch=0.0404]Epoch 148: Train Loss = 0.04172135889530182\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0404, train_loss_epoch=0.0417]Epoch 149: Train Loss = 0.04035819694399834\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0408, train_loss_epoch=0.0404]Epoch 150: Train Loss = 0.04081122204661369\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0384, train_loss_epoch=0.0408]Epoch 151: Train Loss = 0.038380689918994904\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0426, train_loss_epoch=0.0384]Epoch 152: Train Loss = 0.042628731578588486\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0391, train_loss_epoch=0.0426]Epoch 153: Train Loss = 0.03911498934030533\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0401, train_loss_epoch=0.0391]Epoch 154: Train Loss = 0.04008728638291359\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0412, train_loss_epoch=0.0401]Epoch 155: Train Loss = 0.041209183633327484\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0399, train_loss_epoch=0.0412]Epoch 156: Train Loss = 0.039941709488630295\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0433, train_loss_epoch=0.0399]Epoch 157: Train Loss = 0.04325275123119354\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0386, train_loss_epoch=0.0433]Epoch 158: Train Loss = 0.03856858238577843\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0436, train_loss_epoch=0.0386]Epoch 159: Train Loss = 0.043589577078819275\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0394, train_loss_epoch=0.0436]Epoch 160: Train Loss = 0.039359014481306076\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0427, train_loss_epoch=0.0394]Epoch 161: Train Loss = 0.04271106421947479\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0386, train_loss_epoch=0.0427]Epoch 162: Train Loss = 0.03864521160721779\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0409, train_loss_epoch=0.0386]Epoch 163: Train Loss = 0.04088144749403\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0374, train_loss_epoch=0.0409]Epoch 164: Train Loss = 0.037407636642456055\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0386, train_loss_epoch=0.0374]Epoch 165: Train Loss = 0.038648225367069244\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0362, train_loss_epoch=0.0386]Epoch 166: Train Loss = 0.03621780127286911\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0367, train_loss_epoch=0.0362]Epoch 167: Train Loss = 0.03671298548579216\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0375, train_loss_epoch=0.0367]Epoch 168: Train Loss = 0.03746815398335457\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0366, train_loss_epoch=0.0375]Epoch 169: Train Loss = 0.03658823296427727\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.037, train_loss_epoch=0.0366] Epoch 170: Train Loss = 0.03702295571565628\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0401, train_loss_epoch=0.037]Epoch 171: Train Loss = 0.040121547877788544\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0374, train_loss_epoch=0.0401]Epoch 172: Train Loss = 0.037407226860523224\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0415, train_loss_epoch=0.0374]Epoch 173: Train Loss = 0.04148152843117714\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0369, train_loss_epoch=0.0415]Epoch 174: Train Loss = 0.036922063678503036\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0473, train_loss_epoch=0.0369]Epoch 175: Train Loss = 0.0472705103456974\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0374, train_loss_epoch=0.0473]Epoch 176: Train Loss = 0.03738311678171158\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0454, train_loss_epoch=0.0374]Epoch 177: Train Loss = 0.04537596553564072\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0434, train_loss_epoch=0.0454]Epoch 178: Train Loss = 0.04335123673081398\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0398, train_loss_epoch=0.0434]Epoch 179: Train Loss = 0.03978880122303963\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0461, train_loss_epoch=0.0398]Epoch 180: Train Loss = 0.04605061560869217\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0362, train_loss_epoch=0.0461]Epoch 181: Train Loss = 0.03624158352613449\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.048, train_loss_epoch=0.0362] Epoch 182: Train Loss = 0.047993894666433334\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0391, train_loss_epoch=0.048]Epoch 183: Train Loss = 0.039087921380996704\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0355, train_loss_epoch=0.0391]Epoch 184: Train Loss = 0.035537686198949814\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0452, train_loss_epoch=0.0355]Epoch 185: Train Loss = 0.04523118585348129\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0367, train_loss_epoch=0.0452]Epoch 186: Train Loss = 0.03665489703416824\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0413, train_loss_epoch=0.0367]Epoch 187: Train Loss = 0.041318126022815704\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0423, train_loss_epoch=0.0413]Epoch 188: Train Loss = 0.04227452725172043\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0362, train_loss_epoch=0.0423]Epoch 189: Train Loss = 0.036187317222356796\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0433, train_loss_epoch=0.0362]Epoch 190: Train Loss = 0.04332275688648224\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0371, train_loss_epoch=0.0433]Epoch 191: Train Loss = 0.03706364706158638\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0374, train_loss_epoch=0.0371]Epoch 192: Train Loss = 0.0374181903898716\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=252, train_loss_step=0.0442, train_loss_epoch=0.0374]Epoch 193: Train Loss = 0.04423239454627037\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0352, train_loss_epoch=0.0442]Epoch 194: Train Loss = 0.03515331447124481\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0443, train_loss_epoch=0.0352]Epoch 195: Train Loss = 0.0442810021340847\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0416, train_loss_epoch=0.0443]Epoch 196: Train Loss = 0.041609808802604675\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0398, train_loss_epoch=0.0416]Epoch 197: Train Loss = 0.03984445706009865\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0427, train_loss_epoch=0.0398]Epoch 198: Train Loss = 0.042662885040044785\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0339, train_loss_epoch=0.0427]Epoch 199: Train Loss = 0.03393235802650452\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0413, train_loss_epoch=0.0339]Epoch 200: Train Loss = 0.041251543909311295\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0384, train_loss_epoch=0.0413]Epoch 201: Train Loss = 0.038437336683273315\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.038, train_loss_epoch=0.0384] Epoch 202: Train Loss = 0.03795735165476799\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.042, train_loss_epoch=0.038] Epoch 203: Train Loss = 0.042034637182950974\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0338, train_loss_epoch=0.042]Epoch 204: Train Loss = 0.03384082019329071\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0383, train_loss_epoch=0.0338]Epoch 205: Train Loss = 0.03825361654162407\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0402, train_loss_epoch=0.0383]Epoch 206: Train Loss = 0.0402030274271965\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0339, train_loss_epoch=0.0402]Epoch 207: Train Loss = 0.033879511058330536\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0454, train_loss_epoch=0.0339]Epoch 208: Train Loss = 0.04535110294818878\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0343, train_loss_epoch=0.0454]Epoch 209: Train Loss = 0.034335292875766754\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0341, train_loss_epoch=0.0343]Epoch 210: Train Loss = 0.03406957909464836\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.039, train_loss_epoch=0.0341] Epoch 211: Train Loss = 0.03901715576648712\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0343, train_loss_epoch=0.039]Epoch 212: Train Loss = 0.03429470956325531\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0337, train_loss_epoch=0.0343]Epoch 213: Train Loss = 0.033660128712654114\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0377, train_loss_epoch=0.0337]Epoch 214: Train Loss = 0.03769534081220627\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0348, train_loss_epoch=0.0377]Epoch 215: Train Loss = 0.03476225957274437\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.034, train_loss_epoch=0.0348] Epoch 216: Train Loss = 0.03398871794342995\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0352, train_loss_epoch=0.034]Epoch 217: Train Loss = 0.035213321447372437\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0346, train_loss_epoch=0.0352]Epoch 218: Train Loss = 0.03456364944577217\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0361, train_loss_epoch=0.0346]Epoch 219: Train Loss = 0.03613892197608948\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0364, train_loss_epoch=0.0361]Epoch 220: Train Loss = 0.03643859550356865\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0329, train_loss_epoch=0.0364]Epoch 221: Train Loss = 0.03291783481836319\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0368, train_loss_epoch=0.0329]Epoch 222: Train Loss = 0.03679189831018448\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0327, train_loss_epoch=0.0368]Epoch 223: Train Loss = 0.03273824602365494\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0333, train_loss_epoch=0.0327]Epoch 224: Train Loss = 0.03330075740814209\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0337, train_loss_epoch=0.0333]Epoch 225: Train Loss = 0.0337337926030159\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=252, train_loss_step=0.0346, train_loss_epoch=0.0337]Epoch 226: Train Loss = 0.03459972143173218\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0334, train_loss_epoch=0.0346]Epoch 227: Train Loss = 0.03339427337050438\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0369, train_loss_epoch=0.0334]Epoch 228: Train Loss = 0.036885593086481094\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0327, train_loss_epoch=0.0369]Epoch 229: Train Loss = 0.03269030153751373\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0332, train_loss_epoch=0.0327]Epoch 230: Train Loss = 0.033248841762542725\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0349, train_loss_epoch=0.0332]Epoch 231: Train Loss = 0.034923043102025986\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0333, train_loss_epoch=0.0349]Epoch 232: Train Loss = 0.03329610452055931\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0378, train_loss_epoch=0.0333]Epoch 233: Train Loss = 0.03777313604950905\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0328, train_loss_epoch=0.0378]Epoch 234: Train Loss = 0.03276670724153519\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0343, train_loss_epoch=0.0328]Epoch 235: Train Loss = 0.03431875631213188\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.032, train_loss_epoch=0.0343] Epoch 236: Train Loss = 0.03201751410961151\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0341, train_loss_epoch=0.032]Epoch 237: Train Loss = 0.03406837582588196\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0318, train_loss_epoch=0.0341]Epoch 238: Train Loss = 0.031753093004226685\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0326, train_loss_epoch=0.0318]Epoch 239: Train Loss = 0.03255655989050865\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0323, train_loss_epoch=0.0326]Epoch 240: Train Loss = 0.03231227025389671\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0322, train_loss_epoch=0.0323]Epoch 241: Train Loss = 0.032195281237363815\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.032, train_loss_epoch=0.0322] Epoch 242: Train Loss = 0.032003551721572876\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0324, train_loss_epoch=0.032]Epoch 243: Train Loss = 0.032399971038103104\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=252, train_loss_step=0.0304, train_loss_epoch=0.0324]Epoch 244: Train Loss = 0.03040602244436741\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0323, train_loss_epoch=0.0304]Epoch 245: Train Loss = 0.032286740839481354\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=252, train_loss_step=0.0317, train_loss_epoch=0.0323]Epoch 246: Train Loss = 0.031690437346696854\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0325, train_loss_epoch=0.0317]Epoch 247: Train Loss = 0.03250739723443985\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=252, train_loss_step=0.0318, train_loss_epoch=0.0325]Epoch 248: Train Loss = 0.03184998407959938\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0319, train_loss_epoch=0.0318]Epoch 249: Train Loss = 0.03189393877983093\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0319, train_loss_epoch=0.0319]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=252, train_loss_step=0.0319, train_loss_epoch=0.0319]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 34: from 1998-11-02 00:00:00 to 2022-11-18 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.401]Epoch 0: Train Loss = 0.40116026997566223\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.494, train_loss_epoch=0.401]Epoch 1: Train Loss = 0.49367666244506836\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.374, train_loss_epoch=0.494]Epoch 2: Train Loss = 0.3743535578250885\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.253, train_loss_epoch=0.374]Epoch 3: Train Loss = 0.25251927971839905\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.304, train_loss_epoch=0.253]Epoch 4: Train Loss = 0.30411937832832336\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=254, train_loss_step=0.306, train_loss_epoch=0.304]Epoch 5: Train Loss = 0.3055837154388428\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.251, train_loss_epoch=0.306]Epoch 6: Train Loss = 0.2507699429988861\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.245, train_loss_epoch=0.251]Epoch 7: Train Loss = 0.2452922910451889\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.265, train_loss_epoch=0.245]Epoch 8: Train Loss = 0.2646435499191284\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.256, train_loss_epoch=0.265]Epoch 9: Train Loss = 0.2558779716491699\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.235, train_loss_epoch=0.256]Epoch 10: Train Loss = 0.23545044660568237\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.224, train_loss_epoch=0.235]Epoch 11: Train Loss = 0.22391867637634277\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.236, train_loss_epoch=0.224]Epoch 12: Train Loss = 0.23618058860301971\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.219, train_loss_epoch=0.236]Epoch 13: Train Loss = 0.21879765391349792\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.206, train_loss_epoch=0.219]Epoch 14: Train Loss = 0.2057524472475052\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.185, train_loss_epoch=0.206]Epoch 15: Train Loss = 0.18543775379657745\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.204, train_loss_epoch=0.185]Epoch 16: Train Loss = 0.20366671681404114\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.192, train_loss_epoch=0.204]Epoch 17: Train Loss = 0.1919265240430832\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.191, train_loss_epoch=0.192]Epoch 18: Train Loss = 0.19082613289356232\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.170, train_loss_epoch=0.191]Epoch 19: Train Loss = 0.16980481147766113\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.167, train_loss_epoch=0.170]Epoch 20: Train Loss = 0.1669454276561737\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.181, train_loss_epoch=0.167]Epoch 21: Train Loss = 0.18114294111728668\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.180, train_loss_epoch=0.181]Epoch 22: Train Loss = 0.18021614849567413\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.163, train_loss_epoch=0.180]Epoch 23: Train Loss = 0.16269348561763763\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.157, train_loss_epoch=0.163]Epoch 24: Train Loss = 0.15661707520484924\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.159, train_loss_epoch=0.157]Epoch 25: Train Loss = 0.15942440927028656\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=254, train_loss_step=0.160, train_loss_epoch=0.159]Epoch 26: Train Loss = 0.15965420007705688\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.150, train_loss_epoch=0.160]Epoch 27: Train Loss = 0.14976274967193604\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.145, train_loss_epoch=0.150]Epoch 28: Train Loss = 0.1449347883462906\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.154, train_loss_epoch=0.145]Epoch 29: Train Loss = 0.15363813936710358\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.141, train_loss_epoch=0.154]Epoch 30: Train Loss = 0.14143338799476624\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.140, train_loss_epoch=0.141]Epoch 31: Train Loss = 0.14028328657150269\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=254, train_loss_step=0.136, train_loss_epoch=0.140]Epoch 32: Train Loss = 0.13612857460975647\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.135, train_loss_epoch=0.136]Epoch 33: Train Loss = 0.13479797542095184\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.136, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.1358884871006012\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.131, train_loss_epoch=0.136]Epoch 35: Train Loss = 0.13075746595859528\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.130, train_loss_epoch=0.131]Epoch 36: Train Loss = 0.12995664775371552\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.133, train_loss_epoch=0.130]Epoch 37: Train Loss = 0.13307878375053406\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.121, train_loss_epoch=0.133]Epoch 38: Train Loss = 0.12092269957065582\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.117, train_loss_epoch=0.121]Epoch 39: Train Loss = 0.11684800684452057\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.118, train_loss_epoch=0.117]Epoch 40: Train Loss = 0.11836927384138107\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.120, train_loss_epoch=0.118]Epoch 41: Train Loss = 0.11950843781232834\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.117, train_loss_epoch=0.120]Epoch 42: Train Loss = 0.11657388508319855\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.110, train_loss_epoch=0.117]Epoch 43: Train Loss = 0.10976804792881012\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.112, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11172163486480713\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.106, train_loss_epoch=0.112]Epoch 45: Train Loss = 0.10612805932760239\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.106, train_loss_epoch=0.106]Epoch 46: Train Loss = 0.10631968826055527\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.103, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.10262925177812576\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.102, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10178292542695999\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.104, train_loss_epoch=0.102]Epoch 49: Train Loss = 0.10365466773509979\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.100, train_loss_epoch=0.104]Epoch 50: Train Loss = 0.1000794842839241\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0974, train_loss_epoch=0.100]Epoch 51: Train Loss = 0.0973837673664093\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0974, train_loss_epoch=0.0974]Epoch 52: Train Loss = 0.09738606214523315\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0926, train_loss_epoch=0.0974]Epoch 53: Train Loss = 0.09256738424301147\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0932, train_loss_epoch=0.0926]Epoch 54: Train Loss = 0.09318828582763672\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0915, train_loss_epoch=0.0932]Epoch 55: Train Loss = 0.09146607667207718\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0897, train_loss_epoch=0.0915]Epoch 56: Train Loss = 0.08974720537662506\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0876, train_loss_epoch=0.0897]Epoch 57: Train Loss = 0.08760157972574234\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0871, train_loss_epoch=0.0876]Epoch 58: Train Loss = 0.08713909983634949\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0862, train_loss_epoch=0.0871]Epoch 59: Train Loss = 0.0862433984875679\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0861, train_loss_epoch=0.0862]Epoch 60: Train Loss = 0.0860736072063446\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0847, train_loss_epoch=0.0861]Epoch 61: Train Loss = 0.08466167002916336\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=254, train_loss_step=0.081, train_loss_epoch=0.0847] Epoch 62: Train Loss = 0.08101457357406616\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0809, train_loss_epoch=0.081]Epoch 63: Train Loss = 0.08087731897830963\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.081, train_loss_epoch=0.0809] Epoch 64: Train Loss = 0.08099686354398727\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0781, train_loss_epoch=0.081]Epoch 65: Train Loss = 0.07813820242881775\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.080, train_loss_epoch=0.0781] Epoch 66: Train Loss = 0.08002736419439316\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0776, train_loss_epoch=0.080]Epoch 67: Train Loss = 0.0776272714138031\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.076, train_loss_epoch=0.0776] Epoch 68: Train Loss = 0.0760284811258316\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0766, train_loss_epoch=0.076]Epoch 69: Train Loss = 0.07661189883947372\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0735, train_loss_epoch=0.0766]Epoch 70: Train Loss = 0.07352928817272186\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0718, train_loss_epoch=0.0735]Epoch 71: Train Loss = 0.07179868966341019\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0698, train_loss_epoch=0.0718]Epoch 72: Train Loss = 0.06981196999549866\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0721, train_loss_epoch=0.0698]Epoch 73: Train Loss = 0.07205028831958771\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0704, train_loss_epoch=0.0721]Epoch 74: Train Loss = 0.07035830616950989\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0679, train_loss_epoch=0.0704]Epoch 75: Train Loss = 0.06789560616016388\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0696, train_loss_epoch=0.0679]Epoch 76: Train Loss = 0.06957188993692398\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0675, train_loss_epoch=0.0696]Epoch 77: Train Loss = 0.06745821237564087\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0677, train_loss_epoch=0.0675]Epoch 78: Train Loss = 0.0676591694355011\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0637, train_loss_epoch=0.0677]Epoch 79: Train Loss = 0.06372566521167755\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0637, train_loss_epoch=0.0637]Epoch 80: Train Loss = 0.06374411284923553\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0628, train_loss_epoch=0.0637]Epoch 81: Train Loss = 0.06281814724206924\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.063, train_loss_epoch=0.0628] Epoch 82: Train Loss = 0.06304369121789932\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0628, train_loss_epoch=0.063]Epoch 83: Train Loss = 0.06275462359189987\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0618, train_loss_epoch=0.0628]Epoch 84: Train Loss = 0.06182752177119255\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0602, train_loss_epoch=0.0618]Epoch 85: Train Loss = 0.06019959598779678\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0597, train_loss_epoch=0.0602]Epoch 86: Train Loss = 0.05972021445631981\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0591, train_loss_epoch=0.0597]Epoch 87: Train Loss = 0.0591416172683239\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0583, train_loss_epoch=0.0591]Epoch 88: Train Loss = 0.058287154883146286\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0598, train_loss_epoch=0.0583]Epoch 89: Train Loss = 0.05983683094382286\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0579, train_loss_epoch=0.0598]Epoch 90: Train Loss = 0.05794544890522957\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.056, train_loss_epoch=0.0579] Epoch 91: Train Loss = 0.05597405508160591\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0555, train_loss_epoch=0.056]Epoch 92: Train Loss = 0.055534135550260544\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0557, train_loss_epoch=0.0555]Epoch 93: Train Loss = 0.05571437627077103\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0554, train_loss_epoch=0.0557]Epoch 94: Train Loss = 0.055386196821928024\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0534, train_loss_epoch=0.0554]Epoch 95: Train Loss = 0.0534236803650856\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.054, train_loss_epoch=0.0534] Epoch 96: Train Loss = 0.05398768559098244\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.053, train_loss_epoch=0.054] Epoch 97: Train Loss = 0.05303216725587845\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0531, train_loss_epoch=0.053]Epoch 98: Train Loss = 0.0531335175037384\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0526, train_loss_epoch=0.0531]Epoch 99: Train Loss = 0.052628397941589355\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0519, train_loss_epoch=0.0526]Epoch 100: Train Loss = 0.05192505940794945\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0513, train_loss_epoch=0.0519]Epoch 101: Train Loss = 0.051346175372600555\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.050, train_loss_epoch=0.0513] Epoch 102: Train Loss = 0.050039809197187424\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0491, train_loss_epoch=0.050]Epoch 103: Train Loss = 0.04907689988613129\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0493, train_loss_epoch=0.0491]Epoch 104: Train Loss = 0.04931270703673363\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0498, train_loss_epoch=0.0493]Epoch 105: Train Loss = 0.049836061894893646\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0493, train_loss_epoch=0.0498]Epoch 106: Train Loss = 0.04930371418595314\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0516, train_loss_epoch=0.0493]Epoch 107: Train Loss = 0.051594119518995285\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0499, train_loss_epoch=0.0516]Epoch 108: Train Loss = 0.049878962337970734\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0479, train_loss_epoch=0.0499]Epoch 109: Train Loss = 0.0479472279548645\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.047, train_loss_epoch=0.0479] Epoch 110: Train Loss = 0.04697926715016365\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0489, train_loss_epoch=0.047]Epoch 111: Train Loss = 0.048870742321014404\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0473, train_loss_epoch=0.0489]Epoch 112: Train Loss = 0.0473032221198082\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0476, train_loss_epoch=0.0473]Epoch 113: Train Loss = 0.047619014978408813\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.047, train_loss_epoch=0.0476] Epoch 114: Train Loss = 0.04697343334555626\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0501, train_loss_epoch=0.047]Epoch 115: Train Loss = 0.05006803572177887\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.052, train_loss_epoch=0.0501] Epoch 116: Train Loss = 0.05201167240738869\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0494, train_loss_epoch=0.052]Epoch 117: Train Loss = 0.049409154802560806\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0562, train_loss_epoch=0.0494]Epoch 118: Train Loss = 0.056194763630628586\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.050, train_loss_epoch=0.0562] Epoch 119: Train Loss = 0.049951083958148956\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.054, train_loss_epoch=0.050] Epoch 120: Train Loss = 0.054041896015405655\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0498, train_loss_epoch=0.054]Epoch 121: Train Loss = 0.04977405071258545\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0491, train_loss_epoch=0.0498]Epoch 122: Train Loss = 0.04914644733071327\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.053, train_loss_epoch=0.0491] Epoch 123: Train Loss = 0.05295024812221527\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0451, train_loss_epoch=0.053]Epoch 124: Train Loss = 0.0450577512383461\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0579, train_loss_epoch=0.0451]Epoch 125: Train Loss = 0.05787772685289383\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0425, train_loss_epoch=0.0579]Epoch 126: Train Loss = 0.042463429272174835\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0512, train_loss_epoch=0.0425]Epoch 127: Train Loss = 0.051242318004369736\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0416, train_loss_epoch=0.0512]Epoch 128: Train Loss = 0.04156361147761345\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0463, train_loss_epoch=0.0416]Epoch 129: Train Loss = 0.046315863728523254\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0424, train_loss_epoch=0.0463]Epoch 130: Train Loss = 0.04242492839694023\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0458, train_loss_epoch=0.0424]Epoch 131: Train Loss = 0.045769188553094864\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0453, train_loss_epoch=0.0458]Epoch 132: Train Loss = 0.04528215155005455\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0415, train_loss_epoch=0.0453]Epoch 133: Train Loss = 0.04153107479214668\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.047, train_loss_epoch=0.0415] Epoch 134: Train Loss = 0.047035444527864456\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0418, train_loss_epoch=0.047]Epoch 135: Train Loss = 0.04180354252457619\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0457, train_loss_epoch=0.0418]Epoch 136: Train Loss = 0.04569534957408905\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0429, train_loss_epoch=0.0457]Epoch 137: Train Loss = 0.04292304068803787\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0428, train_loss_epoch=0.0429]Epoch 138: Train Loss = 0.0428001694381237\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0465, train_loss_epoch=0.0428]Epoch 139: Train Loss = 0.046452347189188004\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.042, train_loss_epoch=0.0465] Epoch 140: Train Loss = 0.042011041194200516\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0426, train_loss_epoch=0.042]Epoch 141: Train Loss = 0.04263542219996452\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0402, train_loss_epoch=0.0426]Epoch 142: Train Loss = 0.04022478684782982\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0411, train_loss_epoch=0.0402]Epoch 143: Train Loss = 0.0410723052918911\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0404, train_loss_epoch=0.0411]Epoch 144: Train Loss = 0.040410563349723816\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0395, train_loss_epoch=0.0404]Epoch 145: Train Loss = 0.039518628269433975\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0424, train_loss_epoch=0.0395]Epoch 146: Train Loss = 0.04239407926797867\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=254, train_loss_step=0.0388, train_loss_epoch=0.0424]Epoch 147: Train Loss = 0.03883969411253929\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0396, train_loss_epoch=0.0388]Epoch 148: Train Loss = 0.039593931287527084\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0398, train_loss_epoch=0.0396]Epoch 149: Train Loss = 0.039849426597356796\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0387, train_loss_epoch=0.0398]Epoch 150: Train Loss = 0.03872879967093468\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0396, train_loss_epoch=0.0387]Epoch 151: Train Loss = 0.039648957550525665\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0394, train_loss_epoch=0.0396]Epoch 152: Train Loss = 0.03937453031539917\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0394, train_loss_epoch=0.0394]Epoch 153: Train Loss = 0.03939756378531456\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0396, train_loss_epoch=0.0394]Epoch 154: Train Loss = 0.039556801319122314\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0376, train_loss_epoch=0.0396]Epoch 155: Train Loss = 0.037603139877319336\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0387, train_loss_epoch=0.0376]Epoch 156: Train Loss = 0.038729339838027954\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0379, train_loss_epoch=0.0387]Epoch 157: Train Loss = 0.0378895066678524\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0387, train_loss_epoch=0.0379]Epoch 158: Train Loss = 0.0386611633002758\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0379, train_loss_epoch=0.0387]Epoch 159: Train Loss = 0.0378599651157856\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0383, train_loss_epoch=0.0379]Epoch 160: Train Loss = 0.038323774933815\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0405, train_loss_epoch=0.0383]Epoch 161: Train Loss = 0.04045312479138374\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0398, train_loss_epoch=0.0405]Epoch 162: Train Loss = 0.039781469851732254\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0381, train_loss_epoch=0.0398]Epoch 163: Train Loss = 0.038096845149993896\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0393, train_loss_epoch=0.0381]Epoch 164: Train Loss = 0.039276596158742905\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0398, train_loss_epoch=0.0393]Epoch 165: Train Loss = 0.039840660989284515\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.039, train_loss_epoch=0.0398] Epoch 166: Train Loss = 0.03898137807846069\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0426, train_loss_epoch=0.039]Epoch 167: Train Loss = 0.04259151220321655\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0407, train_loss_epoch=0.0426]Epoch 168: Train Loss = 0.04073753207921982\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0416, train_loss_epoch=0.0407]Epoch 169: Train Loss = 0.041632164269685745\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0373, train_loss_epoch=0.0416]Epoch 170: Train Loss = 0.037272050976753235\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0425, train_loss_epoch=0.0373]Epoch 171: Train Loss = 0.04252868890762329\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0362, train_loss_epoch=0.0425]Epoch 172: Train Loss = 0.036196015775203705\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0441, train_loss_epoch=0.0362]Epoch 173: Train Loss = 0.04411041736602783\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0366, train_loss_epoch=0.0441]Epoch 174: Train Loss = 0.03664834424853325\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0384, train_loss_epoch=0.0366]Epoch 175: Train Loss = 0.038401320576667786\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0381, train_loss_epoch=0.0384]Epoch 176: Train Loss = 0.038144830614328384\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0376, train_loss_epoch=0.0381]Epoch 177: Train Loss = 0.03760072961449623\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0382, train_loss_epoch=0.0376]Epoch 178: Train Loss = 0.03820820897817612\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0354, train_loss_epoch=0.0382]Epoch 179: Train Loss = 0.035382919013500214\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0358, train_loss_epoch=0.0354]Epoch 180: Train Loss = 0.035843510180711746\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0366, train_loss_epoch=0.0358]Epoch 181: Train Loss = 0.03663114085793495\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0346, train_loss_epoch=0.0366]Epoch 182: Train Loss = 0.034641947597265244\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0407, train_loss_epoch=0.0346]Epoch 183: Train Loss = 0.040692929178476334\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.035, train_loss_epoch=0.0407] Epoch 184: Train Loss = 0.03497229516506195\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.036, train_loss_epoch=0.035] Epoch 185: Train Loss = 0.03595645725727081\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0374, train_loss_epoch=0.036]Epoch 186: Train Loss = 0.037359099835157394\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0372, train_loss_epoch=0.0374]Epoch 187: Train Loss = 0.03720057010650635\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0363, train_loss_epoch=0.0372]Epoch 188: Train Loss = 0.03630732744932175\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0374, train_loss_epoch=0.0363]Epoch 189: Train Loss = 0.037429045885801315\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0347, train_loss_epoch=0.0374]Epoch 190: Train Loss = 0.03473072871565819\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0336, train_loss_epoch=0.0347]Epoch 191: Train Loss = 0.03360036015510559\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0362, train_loss_epoch=0.0336]Epoch 192: Train Loss = 0.036249566823244095\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.035, train_loss_epoch=0.0362] Epoch 193: Train Loss = 0.03501061722636223\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0342, train_loss_epoch=0.035]Epoch 194: Train Loss = 0.034233711659908295\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0342, train_loss_epoch=0.0342]Epoch 195: Train Loss = 0.03420424461364746\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0345, train_loss_epoch=0.0342]Epoch 196: Train Loss = 0.03450002521276474\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0346, train_loss_epoch=0.0345]Epoch 197: Train Loss = 0.03462502360343933\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0351, train_loss_epoch=0.0346]Epoch 198: Train Loss = 0.035067118704319\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0345, train_loss_epoch=0.0351]Epoch 199: Train Loss = 0.034455206245183945\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.035, train_loss_epoch=0.0345] Epoch 200: Train Loss = 0.034954000264406204\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0354, train_loss_epoch=0.035]Epoch 201: Train Loss = 0.035359833389520645\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0338, train_loss_epoch=0.0354]Epoch 202: Train Loss = 0.03382273018360138\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0332, train_loss_epoch=0.0338]Epoch 203: Train Loss = 0.03320218250155449\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0352, train_loss_epoch=0.0332]Epoch 204: Train Loss = 0.03517218679189682\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0338, train_loss_epoch=0.0352]Epoch 205: Train Loss = 0.03375507891178131\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.034, train_loss_epoch=0.0338] Epoch 206: Train Loss = 0.0340401791036129\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0373, train_loss_epoch=0.034]Epoch 207: Train Loss = 0.03729086369276047\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.036, train_loss_epoch=0.0373] Epoch 208: Train Loss = 0.036021407693624496\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0357, train_loss_epoch=0.036]Epoch 209: Train Loss = 0.03571543097496033\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=254, train_loss_step=0.0336, train_loss_epoch=0.0357]Epoch 210: Train Loss = 0.0335899218916893\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.035, train_loss_epoch=0.0336] Epoch 211: Train Loss = 0.035003188997507095\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0345, train_loss_epoch=0.035]Epoch 212: Train Loss = 0.034457381814718246\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0389, train_loss_epoch=0.0345]Epoch 213: Train Loss = 0.03893193230032921\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=254, train_loss_step=0.0331, train_loss_epoch=0.0389]Epoch 214: Train Loss = 0.03314101696014404\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0328, train_loss_epoch=0.0331]Epoch 215: Train Loss = 0.03278861939907074\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0333, train_loss_epoch=0.0328]Epoch 216: Train Loss = 0.033312443643808365\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0323, train_loss_epoch=0.0333]Epoch 217: Train Loss = 0.03230194374918938\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0335, train_loss_epoch=0.0323]Epoch 218: Train Loss = 0.03352409973740578\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0329, train_loss_epoch=0.0335]Epoch 219: Train Loss = 0.03293345123529434\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0321, train_loss_epoch=0.0329]Epoch 220: Train Loss = 0.032106224447488785\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=254, train_loss_step=0.0321, train_loss_epoch=0.0321]Epoch 221: Train Loss = 0.03208009898662567\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0322, train_loss_epoch=0.0321]Epoch 222: Train Loss = 0.032170556485652924\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0317, train_loss_epoch=0.0322]Epoch 223: Train Loss = 0.03167916461825371\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0336, train_loss_epoch=0.0317]Epoch 224: Train Loss = 0.03361335024237633\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.032, train_loss_epoch=0.0336] Epoch 225: Train Loss = 0.03196239843964577\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0317, train_loss_epoch=0.032]Epoch 226: Train Loss = 0.03166647255420685\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0332, train_loss_epoch=0.0317]Epoch 227: Train Loss = 0.033171169459819794\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0332, train_loss_epoch=0.0332]Epoch 228: Train Loss = 0.03320619836449623\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0347, train_loss_epoch=0.0332]Epoch 229: Train Loss = 0.03472909331321716\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=254, train_loss_step=0.0326, train_loss_epoch=0.0347]Epoch 230: Train Loss = 0.03255274146795273\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0372, train_loss_epoch=0.0326]Epoch 231: Train Loss = 0.037193164229393005\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.032, train_loss_epoch=0.0372] Epoch 232: Train Loss = 0.03200216591358185\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0358, train_loss_epoch=0.032]Epoch 233: Train Loss = 0.03583773598074913\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.033, train_loss_epoch=0.0358] Epoch 234: Train Loss = 0.032989151775836945\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=254, train_loss_step=0.0331, train_loss_epoch=0.033]Epoch 235: Train Loss = 0.03311999887228012\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0324, train_loss_epoch=0.0331]Epoch 236: Train Loss = 0.03244506195187569\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0344, train_loss_epoch=0.0324]Epoch 237: Train Loss = 0.034410830587148666\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0315, train_loss_epoch=0.0344]Epoch 238: Train Loss = 0.03150311857461929\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=254, train_loss_step=0.0323, train_loss_epoch=0.0315]Epoch 239: Train Loss = 0.032338351011276245\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0296, train_loss_epoch=0.0323]Epoch 240: Train Loss = 0.02960995025932789\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0341, train_loss_epoch=0.0296]Epoch 241: Train Loss = 0.034067194908857346\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0309, train_loss_epoch=0.0341]Epoch 242: Train Loss = 0.03093624860048294\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0329, train_loss_epoch=0.0309]Epoch 243: Train Loss = 0.03292511776089668\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0306, train_loss_epoch=0.0329]Epoch 244: Train Loss = 0.030634788796305656\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=254, train_loss_step=0.0352, train_loss_epoch=0.0306]Epoch 245: Train Loss = 0.035231221467256546\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=254, train_loss_step=0.0318, train_loss_epoch=0.0352]Epoch 246: Train Loss = 0.03183935210108757\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.032, train_loss_epoch=0.0318] Epoch 247: Train Loss = 0.031958747655153275\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0318, train_loss_epoch=0.032]Epoch 248: Train Loss = 0.031824562698602676\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0342, train_loss_epoch=0.0318]Epoch 249: Train Loss = 0.034223318099975586\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0342, train_loss_epoch=0.0342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=254, train_loss_step=0.0342, train_loss_epoch=0.0342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 160.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 35: from 1998-11-02 00:00:00 to 2022-11-29 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.410]Epoch 0: Train Loss = 0.4095933139324188\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.492, train_loss_epoch=0.410]Epoch 1: Train Loss = 0.4920569956302643\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.387, train_loss_epoch=0.492]Epoch 2: Train Loss = 0.38696807622909546\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.256, train_loss_epoch=0.387]Epoch 3: Train Loss = 0.2564069330692291\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.300, train_loss_epoch=0.256]Epoch 4: Train Loss = 0.29952919483184814\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.312, train_loss_epoch=0.300]Epoch 5: Train Loss = 0.3120706379413605\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.259, train_loss_epoch=0.312]Epoch 6: Train Loss = 0.2592684328556061\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.249, train_loss_epoch=0.259]Epoch 7: Train Loss = 0.24911469221115112\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.267, train_loss_epoch=0.249]Epoch 8: Train Loss = 0.26689040660858154\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.261, train_loss_epoch=0.267]Epoch 9: Train Loss = 0.26093626022338867\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.239, train_loss_epoch=0.261]Epoch 10: Train Loss = 0.2391851246356964\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.218, train_loss_epoch=0.239]Epoch 11: Train Loss = 0.2184404581785202\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.238, train_loss_epoch=0.218]Epoch 12: Train Loss = 0.238352432847023\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.222, train_loss_epoch=0.238]Epoch 13: Train Loss = 0.22249658405780792\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.213, train_loss_epoch=0.222]Epoch 14: Train Loss = 0.21293015778064728\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.190, train_loss_epoch=0.213]Epoch 15: Train Loss = 0.189519003033638\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.199, train_loss_epoch=0.190]Epoch 16: Train Loss = 0.19914975762367249\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.192, train_loss_epoch=0.199]Epoch 17: Train Loss = 0.19188053905963898\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.199, train_loss_epoch=0.192]Epoch 18: Train Loss = 0.198578342795372\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.175, train_loss_epoch=0.199]Epoch 19: Train Loss = 0.17522761225700378\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.171, train_loss_epoch=0.175]Epoch 20: Train Loss = 0.1709594428539276\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.182, train_loss_epoch=0.171]Epoch 21: Train Loss = 0.18215501308441162\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.178, train_loss_epoch=0.182]Epoch 22: Train Loss = 0.17831529676914215\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.165, train_loss_epoch=0.178]Epoch 23: Train Loss = 0.1648457795381546\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.158, train_loss_epoch=0.165]Epoch 24: Train Loss = 0.15826261043548584\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.160, train_loss_epoch=0.158]Epoch 25: Train Loss = 0.1599535495042801\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.167, train_loss_epoch=0.160]Epoch 26: Train Loss = 0.16678445041179657\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.155, train_loss_epoch=0.167]Epoch 27: Train Loss = 0.15473058819770813\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.148, train_loss_epoch=0.155]Epoch 28: Train Loss = 0.1483241766691208\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.150, train_loss_epoch=0.148]Epoch 29: Train Loss = 0.1499270498752594\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.142, train_loss_epoch=0.150]Epoch 30: Train Loss = 0.1423911452293396\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.143, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.14299742877483368\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.141, train_loss_epoch=0.143]Epoch 32: Train Loss = 0.14055457711219788\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.134, train_loss_epoch=0.141]Epoch 33: Train Loss = 0.1343534290790558\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.139, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.13923506438732147\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.134, train_loss_epoch=0.139]Epoch 35: Train Loss = 0.1339697390794754\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.129, train_loss_epoch=0.134]Epoch 36: Train Loss = 0.1293640285730362\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.130, train_loss_epoch=0.129]Epoch 37: Train Loss = 0.13035686314105988\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.123, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.12301106005907059\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.121, train_loss_epoch=0.123]Epoch 39: Train Loss = 0.12128972262144089\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.118, train_loss_epoch=0.121]Epoch 40: Train Loss = 0.11795617640018463\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.121, train_loss_epoch=0.118]Epoch 41: Train Loss = 0.12090637534856796\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.118, train_loss_epoch=0.121]Epoch 42: Train Loss = 0.11797763407230377\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.110, train_loss_epoch=0.118]Epoch 43: Train Loss = 0.10976412147283554\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.115, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11480706930160522\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.109, train_loss_epoch=0.115]Epoch 45: Train Loss = 0.10910997539758682\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.107, train_loss_epoch=0.109]Epoch 46: Train Loss = 0.1072317510843277\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.105, train_loss_epoch=0.107]Epoch 47: Train Loss = 0.10506404936313629\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.106, train_loss_epoch=0.105]Epoch 48: Train Loss = 0.10625623911619186\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.105, train_loss_epoch=0.106]Epoch 49: Train Loss = 0.10456119477748871\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.100, train_loss_epoch=0.105]Epoch 50: Train Loss = 0.1000712588429451\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0989, train_loss_epoch=0.100]Epoch 51: Train Loss = 0.09894470125436783\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0975, train_loss_epoch=0.0989]Epoch 52: Train Loss = 0.09752713143825531\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0963, train_loss_epoch=0.0975]Epoch 53: Train Loss = 0.09632081538438797\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0964, train_loss_epoch=0.0963]Epoch 54: Train Loss = 0.09641338884830475\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0926, train_loss_epoch=0.0964]Epoch 55: Train Loss = 0.09264051914215088\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0937, train_loss_epoch=0.0926]Epoch 56: Train Loss = 0.09365785121917725\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0905, train_loss_epoch=0.0937]Epoch 57: Train Loss = 0.09049323201179504\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0901, train_loss_epoch=0.0905]Epoch 58: Train Loss = 0.09007126837968826\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=256, train_loss_step=0.0904, train_loss_epoch=0.0901]Epoch 59: Train Loss = 0.09040993452072144\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.085, train_loss_epoch=0.0904] Epoch 60: Train Loss = 0.08504514396190643\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0844, train_loss_epoch=0.085]Epoch 61: Train Loss = 0.0844312384724617\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0824, train_loss_epoch=0.0844]Epoch 62: Train Loss = 0.08241111040115356\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0822, train_loss_epoch=0.0824]Epoch 63: Train Loss = 0.08219218254089355\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0802, train_loss_epoch=0.0822]Epoch 64: Train Loss = 0.08017898350954056\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0792, train_loss_epoch=0.0802]Epoch 65: Train Loss = 0.0791621133685112\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0781, train_loss_epoch=0.0792]Epoch 66: Train Loss = 0.07813085615634918\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0784, train_loss_epoch=0.0781]Epoch 67: Train Loss = 0.07840492576360703\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0757, train_loss_epoch=0.0784]Epoch 68: Train Loss = 0.07574432343244553\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0755, train_loss_epoch=0.0757]Epoch 69: Train Loss = 0.07550173252820969\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0743, train_loss_epoch=0.0755]Epoch 70: Train Loss = 0.07427576929330826\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0735, train_loss_epoch=0.0743]Epoch 71: Train Loss = 0.07352770119905472\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=256, train_loss_step=0.073, train_loss_epoch=0.0735] Epoch 72: Train Loss = 0.0729864239692688\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.072, train_loss_epoch=0.073] Epoch 73: Train Loss = 0.07201482355594635\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0708, train_loss_epoch=0.072]Epoch 74: Train Loss = 0.07075804471969604\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0694, train_loss_epoch=0.0708]Epoch 75: Train Loss = 0.06935083866119385\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0682, train_loss_epoch=0.0694]Epoch 76: Train Loss = 0.06824887543916702\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.069, train_loss_epoch=0.0682] Epoch 77: Train Loss = 0.06899256259202957\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0692, train_loss_epoch=0.069]Epoch 78: Train Loss = 0.06920221447944641\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=256, train_loss_step=0.0645, train_loss_epoch=0.0692]Epoch 79: Train Loss = 0.06450607627630234\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0648, train_loss_epoch=0.0645]Epoch 80: Train Loss = 0.06477850675582886\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0636, train_loss_epoch=0.0648]Epoch 81: Train Loss = 0.0635516569018364\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0636, train_loss_epoch=0.0636]Epoch 82: Train Loss = 0.06357541680335999\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0627, train_loss_epoch=0.0636]Epoch 83: Train Loss = 0.06265886127948761\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0623, train_loss_epoch=0.0627]Epoch 84: Train Loss = 0.06226633861660957\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0614, train_loss_epoch=0.0623]Epoch 85: Train Loss = 0.06141447275876999\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0607, train_loss_epoch=0.0614]Epoch 86: Train Loss = 0.06065257638692856\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0611, train_loss_epoch=0.0607]Epoch 87: Train Loss = 0.061070576310157776\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0583, train_loss_epoch=0.0611]Epoch 88: Train Loss = 0.05832996591925621\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0605, train_loss_epoch=0.0583]Epoch 89: Train Loss = 0.06051015853881836\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0607, train_loss_epoch=0.0605]Epoch 90: Train Loss = 0.06070101261138916\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0576, train_loss_epoch=0.0607]Epoch 91: Train Loss = 0.057618461549282074\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0611, train_loss_epoch=0.0576]Epoch 92: Train Loss = 0.06108679994940758\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0553, train_loss_epoch=0.0611]Epoch 93: Train Loss = 0.05529776215553284\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.060, train_loss_epoch=0.0553] Epoch 94: Train Loss = 0.05998587980866432\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0562, train_loss_epoch=0.060]Epoch 95: Train Loss = 0.05615456774830818\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0546, train_loss_epoch=0.0562]Epoch 96: Train Loss = 0.05455300584435463\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0542, train_loss_epoch=0.0546]Epoch 97: Train Loss = 0.05418847128748894\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0555, train_loss_epoch=0.0542]Epoch 98: Train Loss = 0.05549652874469757\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0532, train_loss_epoch=0.0555]Epoch 99: Train Loss = 0.0532393604516983\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=256, train_loss_step=0.0525, train_loss_epoch=0.0532]Epoch 100: Train Loss = 0.05252605304121971\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=256, train_loss_step=0.0529, train_loss_epoch=0.0525]Epoch 101: Train Loss = 0.05287107452750206\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0526, train_loss_epoch=0.0529]Epoch 102: Train Loss = 0.05263756215572357\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=256, train_loss_step=0.0502, train_loss_epoch=0.0526]Epoch 103: Train Loss = 0.050150442868471146\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0505, train_loss_epoch=0.0502]Epoch 104: Train Loss = 0.05050751194357872\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0504, train_loss_epoch=0.0505]Epoch 105: Train Loss = 0.05037287622690201\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0517, train_loss_epoch=0.0504]Epoch 106: Train Loss = 0.05171806737780571\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0487, train_loss_epoch=0.0517]Epoch 107: Train Loss = 0.048715319484472275\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0501, train_loss_epoch=0.0487]Epoch 108: Train Loss = 0.050116050988435745\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0485, train_loss_epoch=0.0501]Epoch 109: Train Loss = 0.04849127307534218\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0479, train_loss_epoch=0.0485]Epoch 110: Train Loss = 0.047941405326128006\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0489, train_loss_epoch=0.0479]Epoch 111: Train Loss = 0.04890473932027817\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0479, train_loss_epoch=0.0489]Epoch 112: Train Loss = 0.04792098328471184\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0476, train_loss_epoch=0.0479]Epoch 113: Train Loss = 0.04755166172981262\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0472, train_loss_epoch=0.0476]Epoch 114: Train Loss = 0.04716121777892113\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0464, train_loss_epoch=0.0472]Epoch 115: Train Loss = 0.046434614807367325\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0461, train_loss_epoch=0.0464]Epoch 116: Train Loss = 0.046061258763074875\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0462, train_loss_epoch=0.0461]Epoch 117: Train Loss = 0.046152472496032715\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0469, train_loss_epoch=0.0462]Epoch 118: Train Loss = 0.046944696456193924\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.046, train_loss_epoch=0.0469] Epoch 119: Train Loss = 0.045984722673892975\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0459, train_loss_epoch=0.046]Epoch 120: Train Loss = 0.04588410258293152\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0455, train_loss_epoch=0.0459]Epoch 121: Train Loss = 0.04551762342453003\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0452, train_loss_epoch=0.0455]Epoch 122: Train Loss = 0.04523378983139992\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0473, train_loss_epoch=0.0452]Epoch 123: Train Loss = 0.047348689287900925\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.047, train_loss_epoch=0.0473] Epoch 124: Train Loss = 0.04704645648598671\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.045, train_loss_epoch=0.047] Epoch 125: Train Loss = 0.04498816654086113\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0478, train_loss_epoch=0.045]Epoch 126: Train Loss = 0.04776236042380333\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0436, train_loss_epoch=0.0478]Epoch 127: Train Loss = 0.04358755052089691\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0511, train_loss_epoch=0.0436]Epoch 128: Train Loss = 0.05114027112722397\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0441, train_loss_epoch=0.0511]Epoch 129: Train Loss = 0.044078875333070755\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0448, train_loss_epoch=0.0441]Epoch 130: Train Loss = 0.044835060834884644\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0462, train_loss_epoch=0.0448]Epoch 131: Train Loss = 0.046246618032455444\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0447, train_loss_epoch=0.0462]Epoch 132: Train Loss = 0.044724855571985245\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0466, train_loss_epoch=0.0447]Epoch 133: Train Loss = 0.046584419906139374\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0433, train_loss_epoch=0.0466]Epoch 134: Train Loss = 0.04328908771276474\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0452, train_loss_epoch=0.0433]Epoch 135: Train Loss = 0.04523756355047226\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0444, train_loss_epoch=0.0452]Epoch 136: Train Loss = 0.04443087428808212\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.046, train_loss_epoch=0.0444] Epoch 137: Train Loss = 0.045951154083013535\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0422, train_loss_epoch=0.046]Epoch 138: Train Loss = 0.04224805533885956\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0443, train_loss_epoch=0.0422]Epoch 139: Train Loss = 0.04434851184487343\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0435, train_loss_epoch=0.0443]Epoch 140: Train Loss = 0.04350949823856354\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0415, train_loss_epoch=0.0435]Epoch 141: Train Loss = 0.041477058082818985\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0549, train_loss_epoch=0.0415]Epoch 142: Train Loss = 0.054866913706064224\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0433, train_loss_epoch=0.0549]Epoch 143: Train Loss = 0.04334337264299393\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0506, train_loss_epoch=0.0433]Epoch 144: Train Loss = 0.05061480775475502\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0391, train_loss_epoch=0.0506]Epoch 145: Train Loss = 0.03910151496529579\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0512, train_loss_epoch=0.0391]Epoch 146: Train Loss = 0.05120270699262619\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=256, train_loss_step=0.0392, train_loss_epoch=0.0512]Epoch 147: Train Loss = 0.03915413096547127\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0504, train_loss_epoch=0.0392]Epoch 148: Train Loss = 0.050353582948446274\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0421, train_loss_epoch=0.0504]Epoch 149: Train Loss = 0.04209867864847183\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.041, train_loss_epoch=0.0421] Epoch 150: Train Loss = 0.04096658155322075\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.049, train_loss_epoch=0.041] Epoch 151: Train Loss = 0.0490255244076252\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=256, train_loss_step=0.0387, train_loss_epoch=0.049]Epoch 152: Train Loss = 0.038748305290937424\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0513, train_loss_epoch=0.0387]Epoch 153: Train Loss = 0.051267240196466446\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0403, train_loss_epoch=0.0513]Epoch 154: Train Loss = 0.04032895341515541\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0433, train_loss_epoch=0.0403]Epoch 155: Train Loss = 0.04325896129012108\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0445, train_loss_epoch=0.0433]Epoch 156: Train Loss = 0.04453936591744423\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0392, train_loss_epoch=0.0445]Epoch 157: Train Loss = 0.03922691196203232\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0403, train_loss_epoch=0.0392]Epoch 158: Train Loss = 0.04030423238873482\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0424, train_loss_epoch=0.0403]Epoch 159: Train Loss = 0.042358629405498505\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0401, train_loss_epoch=0.0424]Epoch 160: Train Loss = 0.040083467960357666\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0437, train_loss_epoch=0.0401]Epoch 161: Train Loss = 0.04372186213731766\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0378, train_loss_epoch=0.0437]Epoch 162: Train Loss = 0.03782429173588753\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0383, train_loss_epoch=0.0378]Epoch 163: Train Loss = 0.03831145167350769\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0404, train_loss_epoch=0.0383]Epoch 164: Train Loss = 0.04040713235735893\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0378, train_loss_epoch=0.0404]Epoch 165: Train Loss = 0.03781861811876297\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0427, train_loss_epoch=0.0378]Epoch 166: Train Loss = 0.04274453967809677\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0373, train_loss_epoch=0.0427]Epoch 167: Train Loss = 0.03725297749042511\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=256, train_loss_step=0.041, train_loss_epoch=0.0373] Epoch 168: Train Loss = 0.04100397974252701\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0403, train_loss_epoch=0.041]Epoch 169: Train Loss = 0.04030513018369675\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0368, train_loss_epoch=0.0403]Epoch 170: Train Loss = 0.03683524578809738\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0447, train_loss_epoch=0.0368]Epoch 171: Train Loss = 0.04467674344778061\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0369, train_loss_epoch=0.0447]Epoch 172: Train Loss = 0.03691877797245979\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0431, train_loss_epoch=0.0369]Epoch 173: Train Loss = 0.04306976869702339\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0417, train_loss_epoch=0.0431]Epoch 174: Train Loss = 0.041713785380125046\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0381, train_loss_epoch=0.0417]Epoch 175: Train Loss = 0.038127511739730835\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0424, train_loss_epoch=0.0381]Epoch 176: Train Loss = 0.0423923023045063\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=256, train_loss_step=0.0362, train_loss_epoch=0.0424]Epoch 177: Train Loss = 0.036156296730041504\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0392, train_loss_epoch=0.0362]Epoch 178: Train Loss = 0.039200518280267715\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0415, train_loss_epoch=0.0392]Epoch 179: Train Loss = 0.04153557866811752\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0352, train_loss_epoch=0.0415]Epoch 180: Train Loss = 0.03524506464600563\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0439, train_loss_epoch=0.0352]Epoch 181: Train Loss = 0.043894458562135696\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.039, train_loss_epoch=0.0439] Epoch 182: Train Loss = 0.03903328254818916\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.042, train_loss_epoch=0.039] Epoch 183: Train Loss = 0.042027413845062256\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0387, train_loss_epoch=0.042]Epoch 184: Train Loss = 0.03872194141149521\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0356, train_loss_epoch=0.0387]Epoch 185: Train Loss = 0.03560541197657585\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0359, train_loss_epoch=0.0356]Epoch 186: Train Loss = 0.035891879349946976\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.035, train_loss_epoch=0.0359] Epoch 187: Train Loss = 0.03496965765953064\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0366, train_loss_epoch=0.035]Epoch 188: Train Loss = 0.036632031202316284\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0352, train_loss_epoch=0.0366]Epoch 189: Train Loss = 0.03519304469227791\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0357, train_loss_epoch=0.0352]Epoch 190: Train Loss = 0.03566305339336395\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0352, train_loss_epoch=0.0357]Epoch 191: Train Loss = 0.03518438711762428\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0352, train_loss_epoch=0.0352]Epoch 192: Train Loss = 0.03516580909490585\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0351, train_loss_epoch=0.0352]Epoch 193: Train Loss = 0.035082243382930756\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0347, train_loss_epoch=0.0351]Epoch 194: Train Loss = 0.03468189388513565\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0347, train_loss_epoch=0.0347]Epoch 195: Train Loss = 0.034664083272218704\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0342, train_loss_epoch=0.0347]Epoch 196: Train Loss = 0.034196194261312485\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0367, train_loss_epoch=0.0342]Epoch 197: Train Loss = 0.03669818490743637\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0348, train_loss_epoch=0.0367]Epoch 198: Train Loss = 0.034754082560539246\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0342, train_loss_epoch=0.0348]Epoch 199: Train Loss = 0.034186411648988724\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0335, train_loss_epoch=0.0342]Epoch 200: Train Loss = 0.0335281565785408\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0346, train_loss_epoch=0.0335]Epoch 201: Train Loss = 0.03456728905439377\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0337, train_loss_epoch=0.0346]Epoch 202: Train Loss = 0.033689551055431366\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0379, train_loss_epoch=0.0337]Epoch 203: Train Loss = 0.0378761887550354\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0353, train_loss_epoch=0.0379]Epoch 204: Train Loss = 0.03530501946806908\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0346, train_loss_epoch=0.0353]Epoch 205: Train Loss = 0.034625761210918427\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0357, train_loss_epoch=0.0346]Epoch 206: Train Loss = 0.035681791603565216\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0331, train_loss_epoch=0.0357]Epoch 207: Train Loss = 0.0331401452422142\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0334, train_loss_epoch=0.0331]Epoch 208: Train Loss = 0.03337870165705681\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0333, train_loss_epoch=0.0334]Epoch 209: Train Loss = 0.03333377093076706\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0339, train_loss_epoch=0.0333]Epoch 210: Train Loss = 0.0339062437415123\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0348, train_loss_epoch=0.0339]Epoch 211: Train Loss = 0.03477911278605461\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.033, train_loss_epoch=0.0348] Epoch 212: Train Loss = 0.033011604100465775\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0332, train_loss_epoch=0.033]Epoch 213: Train Loss = 0.03316354379057884\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=256, train_loss_step=0.036, train_loss_epoch=0.0332] Epoch 214: Train Loss = 0.03604018688201904\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0327, train_loss_epoch=0.036]Epoch 215: Train Loss = 0.0327446311712265\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0365, train_loss_epoch=0.0327]Epoch 216: Train Loss = 0.036517687141895294\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0326, train_loss_epoch=0.0365]Epoch 217: Train Loss = 0.03263062238693237\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0351, train_loss_epoch=0.0326]Epoch 218: Train Loss = 0.03514739125967026\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0356, train_loss_epoch=0.0351]Epoch 219: Train Loss = 0.03560798242688179\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0336, train_loss_epoch=0.0356]Epoch 220: Train Loss = 0.03361379727721214\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0358, train_loss_epoch=0.0336]Epoch 221: Train Loss = 0.03580101579427719\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0329, train_loss_epoch=0.0358]Epoch 222: Train Loss = 0.03286604955792427\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0362, train_loss_epoch=0.0329]Epoch 223: Train Loss = 0.03615039587020874\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.035, train_loss_epoch=0.0362] Epoch 224: Train Loss = 0.03499113768339157\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0318, train_loss_epoch=0.035]Epoch 225: Train Loss = 0.031820934265851974\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0372, train_loss_epoch=0.0318]Epoch 226: Train Loss = 0.03718238323926926\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0327, train_loss_epoch=0.0372]Epoch 227: Train Loss = 0.032743047922849655\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0346, train_loss_epoch=0.0327]Epoch 228: Train Loss = 0.034608352929353714\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0318, train_loss_epoch=0.0346]Epoch 229: Train Loss = 0.031769733875989914\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0339, train_loss_epoch=0.0318]Epoch 230: Train Loss = 0.0339275598526001\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0321, train_loss_epoch=0.0339]Epoch 231: Train Loss = 0.03207480534911156\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0317, train_loss_epoch=0.0321]Epoch 232: Train Loss = 0.03171888366341591\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0328, train_loss_epoch=0.0317]Epoch 233: Train Loss = 0.03276160731911659\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.032, train_loss_epoch=0.0328] Epoch 234: Train Loss = 0.03197736665606499\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0325, train_loss_epoch=0.032]Epoch 235: Train Loss = 0.03254151716828346\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0318, train_loss_epoch=0.0325]Epoch 236: Train Loss = 0.03179943189024925\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0318, train_loss_epoch=0.0318]Epoch 237: Train Loss = 0.0317506417632103\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0313, train_loss_epoch=0.0318]Epoch 238: Train Loss = 0.03125026449561119\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0321, train_loss_epoch=0.0313]Epoch 239: Train Loss = 0.032094910740852356\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0333, train_loss_epoch=0.0321]Epoch 240: Train Loss = 0.033258382230997086\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0313, train_loss_epoch=0.0333]Epoch 241: Train Loss = 0.03125489130616188\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0349, train_loss_epoch=0.0313]Epoch 242: Train Loss = 0.034866005182266235\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0321, train_loss_epoch=0.0349]Epoch 243: Train Loss = 0.03208001330494881\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0321, train_loss_epoch=0.0321]Epoch 244: Train Loss = 0.03213834390044212\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=256, train_loss_step=0.0378, train_loss_epoch=0.0321]Epoch 245: Train Loss = 0.03781264275312424\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.0319, train_loss_epoch=0.0378]Epoch 246: Train Loss = 0.03188043832778931\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0351, train_loss_epoch=0.0319]Epoch 247: Train Loss = 0.03507780283689499\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=256, train_loss_step=0.0337, train_loss_epoch=0.0351]Epoch 248: Train Loss = 0.03374449908733368\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.033, train_loss_epoch=0.0337] Epoch 249: Train Loss = 0.03303510323166847\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.033, train_loss_epoch=0.033] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=256, train_loss_step=0.033, train_loss_epoch=0.033]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 36: from 1998-11-02 00:00:00 to 2022-12-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.406]Epoch 0: Train Loss = 0.40646108984947205\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.492, train_loss_epoch=0.406]Epoch 1: Train Loss = 0.492029070854187\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.377, train_loss_epoch=0.492]Epoch 2: Train Loss = 0.3769755959510803\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.253, train_loss_epoch=0.377]Epoch 3: Train Loss = 0.2530585527420044\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.301, train_loss_epoch=0.253]Epoch 4: Train Loss = 0.3010545074939728\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.312, train_loss_epoch=0.301]Epoch 5: Train Loss = 0.31151700019836426\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.257, train_loss_epoch=0.312]Epoch 6: Train Loss = 0.2567533552646637\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.248, train_loss_epoch=0.257]Epoch 7: Train Loss = 0.24825426936149597\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.264, train_loss_epoch=0.248]Epoch 8: Train Loss = 0.2642776072025299\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.257, train_loss_epoch=0.264]Epoch 9: Train Loss = 0.2566644549369812\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.241, train_loss_epoch=0.257]Epoch 10: Train Loss = 0.24067412316799164\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.224, train_loss_epoch=0.241]Epoch 11: Train Loss = 0.22395391762256622\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.243, train_loss_epoch=0.224]Epoch 12: Train Loss = 0.2426883429288864\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.226, train_loss_epoch=0.243]Epoch 13: Train Loss = 0.22612862288951874\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.207, train_loss_epoch=0.226]Epoch 14: Train Loss = 0.20689797401428223\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.192, train_loss_epoch=0.207]Epoch 15: Train Loss = 0.19183172285556793\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.203, train_loss_epoch=0.192]Epoch 16: Train Loss = 0.2034161388874054\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.193, train_loss_epoch=0.203]Epoch 17: Train Loss = 0.19347187876701355\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.195, train_loss_epoch=0.193]Epoch 18: Train Loss = 0.19502155482769012\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.175, train_loss_epoch=0.195]Epoch 19: Train Loss = 0.17453992366790771\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.169, train_loss_epoch=0.175]Epoch 20: Train Loss = 0.16949482262134552\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.181, train_loss_epoch=0.169]Epoch 21: Train Loss = 0.1812005341053009\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.175, train_loss_epoch=0.181]Epoch 22: Train Loss = 0.17492370307445526\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.162, train_loss_epoch=0.175]Epoch 23: Train Loss = 0.1622144877910614\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.159, train_loss_epoch=0.162]Epoch 24: Train Loss = 0.15930481255054474\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.160, train_loss_epoch=0.159]Epoch 25: Train Loss = 0.1599995642900467\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.164, train_loss_epoch=0.160]Epoch 26: Train Loss = 0.16357992589473724\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.154, train_loss_epoch=0.164]Epoch 27: Train Loss = 0.154397115111351\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.146, train_loss_epoch=0.154]Epoch 28: Train Loss = 0.14614030718803406\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.150, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.15019920468330383\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.139, train_loss_epoch=0.150]Epoch 30: Train Loss = 0.13940104842185974\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.143, train_loss_epoch=0.139]Epoch 31: Train Loss = 0.14314834773540497\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.140, train_loss_epoch=0.143]Epoch 32: Train Loss = 0.14014624059200287\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.136, train_loss_epoch=0.140]Epoch 33: Train Loss = 0.1355484277009964\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.136, train_loss_epoch=0.136]Epoch 34: Train Loss = 0.13646958768367767\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.132, train_loss_epoch=0.136]Epoch 35: Train Loss = 0.13248403370380402\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.130, train_loss_epoch=0.132]Epoch 36: Train Loss = 0.1299639493227005\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.130, train_loss_epoch=0.130]Epoch 37: Train Loss = 0.12998366355895996\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.122, train_loss_epoch=0.130]Epoch 38: Train Loss = 0.1217293068766594\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.119, train_loss_epoch=0.122]Epoch 39: Train Loss = 0.11902106553316116\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.117, train_loss_epoch=0.119]Epoch 40: Train Loss = 0.11744659394025803\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.119, train_loss_epoch=0.117]Epoch 41: Train Loss = 0.11900702118873596\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.115, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.1151617094874382\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.110, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.10973554849624634\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.115, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11505648493766785\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.107, train_loss_epoch=0.115]Epoch 45: Train Loss = 0.10700850188732147\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.105, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10527656227350235\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.103, train_loss_epoch=0.105]Epoch 47: Train Loss = 0.10343784838914871\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.103, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10253970324993134\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.104, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.10354001820087433\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.100, train_loss_epoch=0.104]Epoch 50: Train Loss = 0.1004079282283783\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0975, train_loss_epoch=0.100]Epoch 51: Train Loss = 0.09747186303138733\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.097, train_loss_epoch=0.0975] Epoch 52: Train Loss = 0.09698456525802612\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0945, train_loss_epoch=0.097]Epoch 53: Train Loss = 0.09449172765016556\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0914, train_loss_epoch=0.0945]Epoch 54: Train Loss = 0.09141512215137482\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0931, train_loss_epoch=0.0914]Epoch 55: Train Loss = 0.0931045338511467\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0898, train_loss_epoch=0.0931]Epoch 56: Train Loss = 0.08975718915462494\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0868, train_loss_epoch=0.0898]Epoch 57: Train Loss = 0.0868455022573471\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0876, train_loss_epoch=0.0868]Epoch 58: Train Loss = 0.08761891722679138\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0846, train_loss_epoch=0.0876]Epoch 59: Train Loss = 0.08463108539581299\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0857, train_loss_epoch=0.0846]Epoch 60: Train Loss = 0.08567234128713608\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0806, train_loss_epoch=0.0857]Epoch 61: Train Loss = 0.08061333000659943\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0807, train_loss_epoch=0.0806]Epoch 62: Train Loss = 0.08068204671144485\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0795, train_loss_epoch=0.0807]Epoch 63: Train Loss = 0.07946749776601791\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0776, train_loss_epoch=0.0795]Epoch 64: Train Loss = 0.0776292011141777\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0768, train_loss_epoch=0.0776]Epoch 65: Train Loss = 0.07678015530109406\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0765, train_loss_epoch=0.0768]Epoch 66: Train Loss = 0.07647676765918732\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0766, train_loss_epoch=0.0765]Epoch 67: Train Loss = 0.07664608210325241\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0731, train_loss_epoch=0.0766]Epoch 68: Train Loss = 0.0730927512049675\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.0736, train_loss_epoch=0.0731]Epoch 69: Train Loss = 0.07359926402568817\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0716, train_loss_epoch=0.0736]Epoch 70: Train Loss = 0.07164249569177628\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0705, train_loss_epoch=0.0716]Epoch 71: Train Loss = 0.07052464783191681\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0734, train_loss_epoch=0.0705]Epoch 72: Train Loss = 0.07336056977510452\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0706, train_loss_epoch=0.0734]Epoch 73: Train Loss = 0.0706225112080574\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0694, train_loss_epoch=0.0706]Epoch 74: Train Loss = 0.0694071501493454\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.0661, train_loss_epoch=0.0694]Epoch 75: Train Loss = 0.06613718718290329\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0667, train_loss_epoch=0.0661]Epoch 76: Train Loss = 0.06665809452533722\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.068, train_loss_epoch=0.0667] Epoch 77: Train Loss = 0.06803479045629501\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0677, train_loss_epoch=0.068]Epoch 78: Train Loss = 0.06773951649665833\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0635, train_loss_epoch=0.0677]Epoch 79: Train Loss = 0.0634547770023346\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0636, train_loss_epoch=0.0635]Epoch 80: Train Loss = 0.0635618269443512\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0627, train_loss_epoch=0.0636]Epoch 81: Train Loss = 0.06272952258586884\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0635, train_loss_epoch=0.0627]Epoch 82: Train Loss = 0.063503198325634\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.0623, train_loss_epoch=0.0635]Epoch 83: Train Loss = 0.06228257715702057\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0619, train_loss_epoch=0.0623]Epoch 84: Train Loss = 0.06185169145464897\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0595, train_loss_epoch=0.0619]Epoch 85: Train Loss = 0.05953837186098099\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0657, train_loss_epoch=0.0595]Epoch 86: Train Loss = 0.06571974605321884\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0595, train_loss_epoch=0.0657]Epoch 87: Train Loss = 0.05950838327407837\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0622, train_loss_epoch=0.0595]Epoch 88: Train Loss = 0.062162745743989944\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.057, train_loss_epoch=0.0622] Epoch 89: Train Loss = 0.057003218680620193\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0682, train_loss_epoch=0.057]Epoch 90: Train Loss = 0.06822280585765839\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0564, train_loss_epoch=0.0682]Epoch 91: Train Loss = 0.05639674514532089\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0637, train_loss_epoch=0.0564]Epoch 92: Train Loss = 0.06370499730110168\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0559, train_loss_epoch=0.0637]Epoch 93: Train Loss = 0.05586058646440506\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.060, train_loss_epoch=0.0559] Epoch 94: Train Loss = 0.06001259759068489\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0549, train_loss_epoch=0.060]Epoch 95: Train Loss = 0.054905280470848083\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0556, train_loss_epoch=0.0549]Epoch 96: Train Loss = 0.055616892874240875\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0587, train_loss_epoch=0.0556]Epoch 97: Train Loss = 0.05865619331598282\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0547, train_loss_epoch=0.0587]Epoch 98: Train Loss = 0.0547240674495697\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0579, train_loss_epoch=0.0547]Epoch 99: Train Loss = 0.05791127681732178\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.052, train_loss_epoch=0.0579] Epoch 100: Train Loss = 0.05202279984951019\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0548, train_loss_epoch=0.052]Epoch 101: Train Loss = 0.05475066229701042\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=258, train_loss_step=0.0526, train_loss_epoch=0.0548]Epoch 102: Train Loss = 0.05257292836904526\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0511, train_loss_epoch=0.0526]Epoch 103: Train Loss = 0.05110279098153114\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0541, train_loss_epoch=0.0511]Epoch 104: Train Loss = 0.05411102995276451\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0494, train_loss_epoch=0.0541]Epoch 105: Train Loss = 0.04937905818223953\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.0584, train_loss_epoch=0.0494]Epoch 106: Train Loss = 0.058408211916685104\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.050, train_loss_epoch=0.0584] Epoch 107: Train Loss = 0.050038158893585205\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.053, train_loss_epoch=0.050] Epoch 108: Train Loss = 0.052990350872278214\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.052, train_loss_epoch=0.053]Epoch 109: Train Loss = 0.05201159045100212\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0493, train_loss_epoch=0.052]Epoch 110: Train Loss = 0.049265891313552856\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0564, train_loss_epoch=0.0493]Epoch 111: Train Loss = 0.056360866874456406\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0473, train_loss_epoch=0.0564]Epoch 112: Train Loss = 0.047289226204156876\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0532, train_loss_epoch=0.0473]Epoch 113: Train Loss = 0.05319878086447716\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.049, train_loss_epoch=0.0532] Epoch 114: Train Loss = 0.04904134199023247\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0485, train_loss_epoch=0.049]Epoch 115: Train Loss = 0.04850102961063385\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0512, train_loss_epoch=0.0485]Epoch 116: Train Loss = 0.05124403163790703\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0455, train_loss_epoch=0.0512]Epoch 117: Train Loss = 0.045518338680267334\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0519, train_loss_epoch=0.0455]Epoch 118: Train Loss = 0.051890645176172256\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0465, train_loss_epoch=0.0519]Epoch 119: Train Loss = 0.0464579202234745\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0459, train_loss_epoch=0.0465]Epoch 120: Train Loss = 0.04592317342758179\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0468, train_loss_epoch=0.0459]Epoch 121: Train Loss = 0.046827737241983414\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0453, train_loss_epoch=0.0468]Epoch 122: Train Loss = 0.04528433829545975\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0471, train_loss_epoch=0.0453]Epoch 123: Train Loss = 0.0470857210457325\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0444, train_loss_epoch=0.0471]Epoch 124: Train Loss = 0.04441777616739273\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0453, train_loss_epoch=0.0444]Epoch 125: Train Loss = 0.04531809687614441\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0428, train_loss_epoch=0.0453]Epoch 126: Train Loss = 0.042824260890483856\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0456, train_loss_epoch=0.0428]Epoch 127: Train Loss = 0.04563554748892784\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0423, train_loss_epoch=0.0456]Epoch 128: Train Loss = 0.04230465367436409\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0429, train_loss_epoch=0.0423]Epoch 129: Train Loss = 0.042923975735902786\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0425, train_loss_epoch=0.0429]Epoch 130: Train Loss = 0.042456913739442825\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0432, train_loss_epoch=0.0425]Epoch 131: Train Loss = 0.0432150661945343\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0427, train_loss_epoch=0.0432]Epoch 132: Train Loss = 0.04269816353917122\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.043, train_loss_epoch=0.0427] Epoch 133: Train Loss = 0.042974572628736496\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0428, train_loss_epoch=0.043]Epoch 134: Train Loss = 0.042757727205753326\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0424, train_loss_epoch=0.0428]Epoch 135: Train Loss = 0.04235249385237694\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.044, train_loss_epoch=0.0424] Epoch 136: Train Loss = 0.04402322322130203\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0416, train_loss_epoch=0.044]Epoch 137: Train Loss = 0.04159634932875633\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0423, train_loss_epoch=0.0416]Epoch 138: Train Loss = 0.04231980815529823\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0422, train_loss_epoch=0.0423]Epoch 139: Train Loss = 0.042222704738378525\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0422, train_loss_epoch=0.0422]Epoch 140: Train Loss = 0.04221157357096672\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0408, train_loss_epoch=0.0422]Epoch 141: Train Loss = 0.040813107043504715\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0412, train_loss_epoch=0.0408]Epoch 142: Train Loss = 0.041216012090444565\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.041, train_loss_epoch=0.0412] Epoch 143: Train Loss = 0.041007064282894135\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0458, train_loss_epoch=0.041]Epoch 144: Train Loss = 0.04583365470170975\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0407, train_loss_epoch=0.0458]Epoch 145: Train Loss = 0.040710777044296265\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.043, train_loss_epoch=0.0407] Epoch 146: Train Loss = 0.04298122227191925\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.0403, train_loss_epoch=0.043]Epoch 147: Train Loss = 0.040348414331674576\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0437, train_loss_epoch=0.0403]Epoch 148: Train Loss = 0.04368588700890541\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0407, train_loss_epoch=0.0437]Epoch 149: Train Loss = 0.04066638648509979\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0407, train_loss_epoch=0.0407]Epoch 150: Train Loss = 0.040705468505620956\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0418, train_loss_epoch=0.0407]Epoch 151: Train Loss = 0.041826508939266205\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.040, train_loss_epoch=0.0418] Epoch 152: Train Loss = 0.04001883417367935\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0422, train_loss_epoch=0.040]Epoch 153: Train Loss = 0.042170099914073944\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0399, train_loss_epoch=0.0422]Epoch 154: Train Loss = 0.0399247407913208\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0407, train_loss_epoch=0.0399]Epoch 155: Train Loss = 0.04068032279610634\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0394, train_loss_epoch=0.0407]Epoch 156: Train Loss = 0.03943905234336853\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.038, train_loss_epoch=0.0394] Epoch 157: Train Loss = 0.03796390816569328\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0385, train_loss_epoch=0.038]Epoch 158: Train Loss = 0.0384875163435936\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.0387, train_loss_epoch=0.0385]Epoch 159: Train Loss = 0.03874487429857254\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.0378, train_loss_epoch=0.0387]Epoch 160: Train Loss = 0.03777755796909332\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0384, train_loss_epoch=0.0378]Epoch 161: Train Loss = 0.03835592046380043\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0378, train_loss_epoch=0.0384]Epoch 162: Train Loss = 0.03783571720123291\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0386, train_loss_epoch=0.0378]Epoch 163: Train Loss = 0.038636889308691025\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0373, train_loss_epoch=0.0386]Epoch 164: Train Loss = 0.037254396826028824\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0431, train_loss_epoch=0.0373]Epoch 165: Train Loss = 0.0431368425488472\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0381, train_loss_epoch=0.0431]Epoch 166: Train Loss = 0.03806477040052414\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0407, train_loss_epoch=0.0381]Epoch 167: Train Loss = 0.040694452822208405\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0394, train_loss_epoch=0.0407]Epoch 168: Train Loss = 0.03938251733779907\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0383, train_loss_epoch=0.0394]Epoch 169: Train Loss = 0.03825641795992851\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0364, train_loss_epoch=0.0383]Epoch 170: Train Loss = 0.03640957549214363\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.0378, train_loss_epoch=0.0364]Epoch 171: Train Loss = 0.037756290286779404\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.036, train_loss_epoch=0.0378] Epoch 172: Train Loss = 0.036028094589710236\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0369, train_loss_epoch=0.036]Epoch 173: Train Loss = 0.03691575303673744\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0361, train_loss_epoch=0.0369]Epoch 174: Train Loss = 0.03607003018260002\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0366, train_loss_epoch=0.0361]Epoch 175: Train Loss = 0.036552779376506805\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0359, train_loss_epoch=0.0366]Epoch 176: Train Loss = 0.035858217626810074\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0377, train_loss_epoch=0.0359]Epoch 177: Train Loss = 0.03765321522951126\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0375, train_loss_epoch=0.0377]Epoch 178: Train Loss = 0.03752831369638443\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0365, train_loss_epoch=0.0375]Epoch 179: Train Loss = 0.036548513919115067\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0355, train_loss_epoch=0.0365]Epoch 180: Train Loss = 0.03546709939837456\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0352, train_loss_epoch=0.0355]Epoch 181: Train Loss = 0.035224419087171555\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0388, train_loss_epoch=0.0352]Epoch 182: Train Loss = 0.03880712017416954\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0354, train_loss_epoch=0.0388]Epoch 183: Train Loss = 0.03536007180809975\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0381, train_loss_epoch=0.0354]Epoch 184: Train Loss = 0.038062382489442825\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0349, train_loss_epoch=0.0381]Epoch 185: Train Loss = 0.034867215901613235\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0412, train_loss_epoch=0.0349]Epoch 186: Train Loss = 0.041237723082304\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0345, train_loss_epoch=0.0412]Epoch 187: Train Loss = 0.03454762324690819\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0359, train_loss_epoch=0.0345]Epoch 188: Train Loss = 0.035919930785894394\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0363, train_loss_epoch=0.0359]Epoch 189: Train Loss = 0.03627968952059746\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0347, train_loss_epoch=0.0363]Epoch 190: Train Loss = 0.034740567207336426\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0359, train_loss_epoch=0.0347]Epoch 191: Train Loss = 0.03586382418870926\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0347, train_loss_epoch=0.0359]Epoch 192: Train Loss = 0.03471650555729866\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0367, train_loss_epoch=0.0347]Epoch 193: Train Loss = 0.03673268482089043\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0354, train_loss_epoch=0.0367]Epoch 194: Train Loss = 0.035413723438978195\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0341, train_loss_epoch=0.0354]Epoch 195: Train Loss = 0.03406580165028572\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0342, train_loss_epoch=0.0341]Epoch 196: Train Loss = 0.03415520489215851\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0339, train_loss_epoch=0.0342]Epoch 197: Train Loss = 0.03390423581004143\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.034, train_loss_epoch=0.0339] Epoch 198: Train Loss = 0.033997565507888794\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0344, train_loss_epoch=0.034]Epoch 199: Train Loss = 0.034429457038640976\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0337, train_loss_epoch=0.0344]Epoch 200: Train Loss = 0.03372117131948471\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.035, train_loss_epoch=0.0337] Epoch 201: Train Loss = 0.03495196998119354\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0351, train_loss_epoch=0.035]Epoch 202: Train Loss = 0.035135429352521896\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0331, train_loss_epoch=0.0351]Epoch 203: Train Loss = 0.03313230723142624\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0362, train_loss_epoch=0.0331]Epoch 204: Train Loss = 0.036219969391822815\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0333, train_loss_epoch=0.0362]Epoch 205: Train Loss = 0.033314112573862076\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.0356, train_loss_epoch=0.0333]Epoch 206: Train Loss = 0.03560230880975723\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=258, train_loss_step=0.033, train_loss_epoch=0.0356] Epoch 207: Train Loss = 0.032952696084976196\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0335, train_loss_epoch=0.033]Epoch 208: Train Loss = 0.0334937684237957\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0329, train_loss_epoch=0.0335]Epoch 209: Train Loss = 0.03290984779596329\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0349, train_loss_epoch=0.0329]Epoch 210: Train Loss = 0.03491470217704773\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0328, train_loss_epoch=0.0349]Epoch 211: Train Loss = 0.03283276408910751\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.033, train_loss_epoch=0.0328] Epoch 212: Train Loss = 0.03300344944000244\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0338, train_loss_epoch=0.033]Epoch 213: Train Loss = 0.03380881994962692\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0359, train_loss_epoch=0.0338]Epoch 214: Train Loss = 0.03585156053304672\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0329, train_loss_epoch=0.0359]Epoch 215: Train Loss = 0.03294428437948227\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0344, train_loss_epoch=0.0329]Epoch 216: Train Loss = 0.034399885684251785\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0335, train_loss_epoch=0.0344]Epoch 217: Train Loss = 0.03345368430018425\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0327, train_loss_epoch=0.0335]Epoch 218: Train Loss = 0.03272009640932083\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.032, train_loss_epoch=0.0327] Epoch 219: Train Loss = 0.031988829374313354\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0322, train_loss_epoch=0.032]Epoch 220: Train Loss = 0.03218157961964607\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0323, train_loss_epoch=0.0322]Epoch 221: Train Loss = 0.03232567012310028\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.032, train_loss_epoch=0.0323] Epoch 222: Train Loss = 0.03202293813228607\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0332, train_loss_epoch=0.032]Epoch 223: Train Loss = 0.03323397785425186\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0337, train_loss_epoch=0.0332]Epoch 224: Train Loss = 0.03369531407952309\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=258, train_loss_step=0.034, train_loss_epoch=0.0337] Epoch 225: Train Loss = 0.033978067338466644\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0326, train_loss_epoch=0.034]Epoch 226: Train Loss = 0.03260694071650505\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0331, train_loss_epoch=0.0326]Epoch 227: Train Loss = 0.03308995068073273\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0322, train_loss_epoch=0.0331]Epoch 228: Train Loss = 0.03224639222025871\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0338, train_loss_epoch=0.0322]Epoch 229: Train Loss = 0.03384625166654587\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.032, train_loss_epoch=0.0338] Epoch 230: Train Loss = 0.03204549103975296\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0336, train_loss_epoch=0.032]Epoch 231: Train Loss = 0.03363250941038132\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0319, train_loss_epoch=0.0336]Epoch 232: Train Loss = 0.031880635768175125\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0334, train_loss_epoch=0.0319]Epoch 233: Train Loss = 0.03335409238934517\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0318, train_loss_epoch=0.0334]Epoch 234: Train Loss = 0.031834401190280914\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0318, train_loss_epoch=0.0318]Epoch 235: Train Loss = 0.03183823823928833\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0319, train_loss_epoch=0.0318]Epoch 236: Train Loss = 0.03189900517463684\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0315, train_loss_epoch=0.0319]Epoch 237: Train Loss = 0.03154759854078293\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0357, train_loss_epoch=0.0315]Epoch 238: Train Loss = 0.03572431206703186\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0338, train_loss_epoch=0.0357]Epoch 239: Train Loss = 0.033827122300863266\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0324, train_loss_epoch=0.0338]Epoch 240: Train Loss = 0.032383669167757034\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0321, train_loss_epoch=0.0324]Epoch 241: Train Loss = 0.0320761539041996\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.033, train_loss_epoch=0.0321] Epoch 242: Train Loss = 0.0329936258494854\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0333, train_loss_epoch=0.033]Epoch 243: Train Loss = 0.03331667184829712\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0299, train_loss_epoch=0.0333]Epoch 244: Train Loss = 0.02992956154048443\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0326, train_loss_epoch=0.0299]Epoch 245: Train Loss = 0.032607756555080414\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=258, train_loss_step=0.0335, train_loss_epoch=0.0326]Epoch 246: Train Loss = 0.03346777334809303\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0322, train_loss_epoch=0.0335]Epoch 247: Train Loss = 0.03222448006272316\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=258, train_loss_step=0.0301, train_loss_epoch=0.0322]Epoch 248: Train Loss = 0.03014044277369976\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0314, train_loss_epoch=0.0301]Epoch 249: Train Loss = 0.031428415328264236\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0314, train_loss_epoch=0.0314]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=258, train_loss_step=0.0314, train_loss_epoch=0.0314]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.76it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 37: from 1998-11-02 00:00:00 to 2022-12-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.412]Epoch 0: Train Loss = 0.4115019142627716\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.490, train_loss_epoch=0.412]Epoch 1: Train Loss = 0.48985323309898376\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.385, train_loss_epoch=0.490]Epoch 2: Train Loss = 0.38477176427841187\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.256, train_loss_epoch=0.385]Epoch 3: Train Loss = 0.2556080222129822\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.301, train_loss_epoch=0.256]Epoch 4: Train Loss = 0.3009328544139862\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.310, train_loss_epoch=0.301]Epoch 5: Train Loss = 0.3099372386932373\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.261, train_loss_epoch=0.310]Epoch 6: Train Loss = 0.2612607181072235\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.243, train_loss_epoch=0.261]Epoch 7: Train Loss = 0.24272993206977844\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.269, train_loss_epoch=0.243]Epoch 8: Train Loss = 0.26880374550819397\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.260, train_loss_epoch=0.269]Epoch 9: Train Loss = 0.25977012515068054\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.242, train_loss_epoch=0.260]Epoch 10: Train Loss = 0.24159778654575348\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.222, train_loss_epoch=0.242]Epoch 11: Train Loss = 0.22189150750637054\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.240, train_loss_epoch=0.222]Epoch 12: Train Loss = 0.2400457113981247\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.222, train_loss_epoch=0.240]Epoch 13: Train Loss = 0.22191229462623596\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.212, train_loss_epoch=0.222]Epoch 14: Train Loss = 0.21183107793331146\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.191, train_loss_epoch=0.212]Epoch 15: Train Loss = 0.19080370664596558\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.200, train_loss_epoch=0.191]Epoch 16: Train Loss = 0.19965386390686035\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.193, train_loss_epoch=0.200]Epoch 17: Train Loss = 0.1925477832555771\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.196, train_loss_epoch=0.193]Epoch 18: Train Loss = 0.19644922018051147\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.175, train_loss_epoch=0.196]Epoch 19: Train Loss = 0.17544430494308472\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.169, train_loss_epoch=0.175]Epoch 20: Train Loss = 0.16911956667900085\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.184, train_loss_epoch=0.169]Epoch 21: Train Loss = 0.18377313017845154\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.177, train_loss_epoch=0.184]Epoch 22: Train Loss = 0.17741617560386658\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.164, train_loss_epoch=0.177]Epoch 23: Train Loss = 0.16411231458187103\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.159, train_loss_epoch=0.164]Epoch 24: Train Loss = 0.15920673310756683\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.158, train_loss_epoch=0.159]Epoch 25: Train Loss = 0.15789160132408142\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.162, train_loss_epoch=0.158]Epoch 26: Train Loss = 0.1620940864086151\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.154, train_loss_epoch=0.162]Epoch 27: Train Loss = 0.15425392985343933\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.146, train_loss_epoch=0.154]Epoch 28: Train Loss = 0.14591506123542786\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.147, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.14653313159942627\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.142, train_loss_epoch=0.147]Epoch 30: Train Loss = 0.1424442082643509\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.144, train_loss_epoch=0.142]Epoch 31: Train Loss = 0.14392820000648499\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.141, train_loss_epoch=0.144]Epoch 32: Train Loss = 0.14110048115253448\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.134, train_loss_epoch=0.141]Epoch 33: Train Loss = 0.13366957008838654\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.135, train_loss_epoch=0.134]Epoch 34: Train Loss = 0.13480296730995178\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.134, train_loss_epoch=0.135]Epoch 35: Train Loss = 0.13404372334480286\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.129, train_loss_epoch=0.134]Epoch 36: Train Loss = 0.12901310622692108\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.131, train_loss_epoch=0.129]Epoch 37: Train Loss = 0.1305495649576187\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.124, train_loss_epoch=0.131]Epoch 38: Train Loss = 0.12401435524225235\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.119, train_loss_epoch=0.124]Epoch 39: Train Loss = 0.11934086680412292\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.117, train_loss_epoch=0.119]Epoch 40: Train Loss = 0.11652623116970062\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.117, train_loss_epoch=0.117]Epoch 41: Train Loss = 0.11710036545991898\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.115, train_loss_epoch=0.117]Epoch 42: Train Loss = 0.11456269770860672\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.110, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.11008269339799881\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.115, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11501628905534744\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.107, train_loss_epoch=0.115]Epoch 45: Train Loss = 0.10738319158554077\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.106, train_loss_epoch=0.107]Epoch 46: Train Loss = 0.10583953559398651\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.103, train_loss_epoch=0.106]Epoch 47: Train Loss = 0.10324818640947342\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.103, train_loss_epoch=0.103]Epoch 48: Train Loss = 0.10327710956335068\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.104, train_loss_epoch=0.103]Epoch 49: Train Loss = 0.10412006825208664\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.101, train_loss_epoch=0.104]Epoch 50: Train Loss = 0.1011095643043518\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0989, train_loss_epoch=0.101]Epoch 51: Train Loss = 0.09888460487127304\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0967, train_loss_epoch=0.0989]Epoch 52: Train Loss = 0.09670888632535934\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0948, train_loss_epoch=0.0967]Epoch 53: Train Loss = 0.09477545320987701\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.092, train_loss_epoch=0.0948] Epoch 54: Train Loss = 0.09199871122837067\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0922, train_loss_epoch=0.092]Epoch 55: Train Loss = 0.09216812998056412\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.092, train_loss_epoch=0.0922] Epoch 56: Train Loss = 0.09196535497903824\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0888, train_loss_epoch=0.092]Epoch 57: Train Loss = 0.08875704556703568\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0888, train_loss_epoch=0.0888]Epoch 58: Train Loss = 0.08884330838918686\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0859, train_loss_epoch=0.0888]Epoch 59: Train Loss = 0.08589494973421097\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0842, train_loss_epoch=0.0859]Epoch 60: Train Loss = 0.08420758694410324\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0822, train_loss_epoch=0.0842]Epoch 61: Train Loss = 0.08217546343803406\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0806, train_loss_epoch=0.0822]Epoch 62: Train Loss = 0.08063880354166031\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.0805, train_loss_epoch=0.0806]Epoch 63: Train Loss = 0.08050437271595001\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0786, train_loss_epoch=0.0805]Epoch 64: Train Loss = 0.07859738916158676\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0773, train_loss_epoch=0.0786]Epoch 65: Train Loss = 0.07727845758199692\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0773, train_loss_epoch=0.0773]Epoch 66: Train Loss = 0.07726500928401947\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0761, train_loss_epoch=0.0773]Epoch 67: Train Loss = 0.0761450007557869\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.074, train_loss_epoch=0.0761] Epoch 68: Train Loss = 0.07402686774730682\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0722, train_loss_epoch=0.074]Epoch 69: Train Loss = 0.07220442593097687\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0726, train_loss_epoch=0.0722]Epoch 70: Train Loss = 0.07264427095651627\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0711, train_loss_epoch=0.0726]Epoch 71: Train Loss = 0.07106956839561462\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0703, train_loss_epoch=0.0711]Epoch 72: Train Loss = 0.07032696157693863\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0698, train_loss_epoch=0.0703]Epoch 73: Train Loss = 0.06982440501451492\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0702, train_loss_epoch=0.0698]Epoch 74: Train Loss = 0.07015974819660187\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0665, train_loss_epoch=0.0702]Epoch 75: Train Loss = 0.06646694242954254\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0677, train_loss_epoch=0.0665]Epoch 76: Train Loss = 0.0676545575261116\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0678, train_loss_epoch=0.0677]Epoch 77: Train Loss = 0.06778200715780258\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0656, train_loss_epoch=0.0678]Epoch 78: Train Loss = 0.06564883142709732\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0645, train_loss_epoch=0.0656]Epoch 79: Train Loss = 0.06446158140897751\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.0648, train_loss_epoch=0.0645]Epoch 80: Train Loss = 0.06475583463907242\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0644, train_loss_epoch=0.0648]Epoch 81: Train Loss = 0.06442718952894211\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.062, train_loss_epoch=0.0644] Epoch 82: Train Loss = 0.06197136268019676\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0615, train_loss_epoch=0.062]Epoch 83: Train Loss = 0.06146635487675667\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0606, train_loss_epoch=0.0615]Epoch 84: Train Loss = 0.06062961742281914\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0587, train_loss_epoch=0.0606]Epoch 85: Train Loss = 0.058664869517087936\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0595, train_loss_epoch=0.0587]Epoch 86: Train Loss = 0.05954901501536369\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0588, train_loss_epoch=0.0595]Epoch 87: Train Loss = 0.058786965906620026\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0575, train_loss_epoch=0.0588]Epoch 88: Train Loss = 0.05751058831810951\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0584, train_loss_epoch=0.0575]Epoch 89: Train Loss = 0.05842879042029381\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0573, train_loss_epoch=0.0584]Epoch 90: Train Loss = 0.05726313963532448\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0575, train_loss_epoch=0.0573]Epoch 91: Train Loss = 0.057483185082674026\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0561, train_loss_epoch=0.0575]Epoch 92: Train Loss = 0.056118037551641464\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0552, train_loss_epoch=0.0561]Epoch 93: Train Loss = 0.055155135691165924\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0564, train_loss_epoch=0.0552]Epoch 94: Train Loss = 0.05636526644229889\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0538, train_loss_epoch=0.0564]Epoch 95: Train Loss = 0.05376550927758217\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0584, train_loss_epoch=0.0538]Epoch 96: Train Loss = 0.058352142572402954\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0527, train_loss_epoch=0.0584]Epoch 97: Train Loss = 0.05272258073091507\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.0582, train_loss_epoch=0.0527]Epoch 98: Train Loss = 0.05822454020380974\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=260, train_loss_step=0.0531, train_loss_epoch=0.0582]Epoch 99: Train Loss = 0.05309491977095604\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0677, train_loss_epoch=0.0531]Epoch 100: Train Loss = 0.06766804307699203\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0508, train_loss_epoch=0.0677]Epoch 101: Train Loss = 0.05080442875623703\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0594, train_loss_epoch=0.0508]Epoch 102: Train Loss = 0.05935260280966759\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0508, train_loss_epoch=0.0594]Epoch 103: Train Loss = 0.050815191119909286\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0563, train_loss_epoch=0.0508]Epoch 104: Train Loss = 0.05630205199122429\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0569, train_loss_epoch=0.0563]Epoch 105: Train Loss = 0.056888677179813385\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0555, train_loss_epoch=0.0569]Epoch 106: Train Loss = 0.05551673099398613\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0573, train_loss_epoch=0.0555]Epoch 107: Train Loss = 0.05729532241821289\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0502, train_loss_epoch=0.0573]Epoch 108: Train Loss = 0.05022977665066719\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0604, train_loss_epoch=0.0502]Epoch 109: Train Loss = 0.060398273169994354\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0479, train_loss_epoch=0.0604]Epoch 110: Train Loss = 0.04794444143772125\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0552, train_loss_epoch=0.0479]Epoch 111: Train Loss = 0.05524936690926552\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0489, train_loss_epoch=0.0552]Epoch 112: Train Loss = 0.04890372231602669\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0513, train_loss_epoch=0.0489]Epoch 113: Train Loss = 0.05129358172416687\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0545, train_loss_epoch=0.0513]Epoch 114: Train Loss = 0.05450543016195297\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=260, train_loss_step=0.0478, train_loss_epoch=0.0545]Epoch 115: Train Loss = 0.047839947044849396\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0478, train_loss_epoch=0.0478]Epoch 116: Train Loss = 0.04782933369278908\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0476, train_loss_epoch=0.0478]Epoch 117: Train Loss = 0.04760068655014038\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0491, train_loss_epoch=0.0476]Epoch 118: Train Loss = 0.04911601543426514\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0478, train_loss_epoch=0.0491]Epoch 119: Train Loss = 0.04776862636208534\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.0465, train_loss_epoch=0.0478]Epoch 120: Train Loss = 0.04650813713669777\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.0473, train_loss_epoch=0.0465]Epoch 121: Train Loss = 0.04731777310371399\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0451, train_loss_epoch=0.0473]Epoch 122: Train Loss = 0.045144759118556976\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.047, train_loss_epoch=0.0451] Epoch 123: Train Loss = 0.046971920877695084\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.046, train_loss_epoch=0.047] Epoch 124: Train Loss = 0.04597372189164162\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0485, train_loss_epoch=0.046]Epoch 125: Train Loss = 0.04853025823831558\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0462, train_loss_epoch=0.0485]Epoch 126: Train Loss = 0.04618227109313011\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0499, train_loss_epoch=0.0462]Epoch 127: Train Loss = 0.049868203699588776\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.046, train_loss_epoch=0.0499] Epoch 128: Train Loss = 0.046019114553928375\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0454, train_loss_epoch=0.046]Epoch 129: Train Loss = 0.045429527759552\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0437, train_loss_epoch=0.0454]Epoch 130: Train Loss = 0.04373795539140701\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0439, train_loss_epoch=0.0437]Epoch 131: Train Loss = 0.043882936239242554\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0439, train_loss_epoch=0.0439]Epoch 132: Train Loss = 0.0438978336751461\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0446, train_loss_epoch=0.0439]Epoch 133: Train Loss = 0.04456721618771553\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0428, train_loss_epoch=0.0446]Epoch 134: Train Loss = 0.04277368634939194\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0445, train_loss_epoch=0.0428]Epoch 135: Train Loss = 0.0444725900888443\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.042, train_loss_epoch=0.0445] Epoch 136: Train Loss = 0.042048655450344086\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0416, train_loss_epoch=0.042]Epoch 137: Train Loss = 0.041590720415115356\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0466, train_loss_epoch=0.0416]Epoch 138: Train Loss = 0.046556565910577774\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0433, train_loss_epoch=0.0466]Epoch 139: Train Loss = 0.04329388961195946\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0443, train_loss_epoch=0.0433]Epoch 140: Train Loss = 0.04425748437643051\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0409, train_loss_epoch=0.0443]Epoch 141: Train Loss = 0.04092299938201904\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0425, train_loss_epoch=0.0409]Epoch 142: Train Loss = 0.042477261275053024\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0423, train_loss_epoch=0.0425]Epoch 143: Train Loss = 0.04226820915937424\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0397, train_loss_epoch=0.0423]Epoch 144: Train Loss = 0.039683014154434204\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0475, train_loss_epoch=0.0397]Epoch 145: Train Loss = 0.04753003641963005\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0407, train_loss_epoch=0.0475]Epoch 146: Train Loss = 0.0406615324318409\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0451, train_loss_epoch=0.0407]Epoch 147: Train Loss = 0.0450650155544281\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.042, train_loss_epoch=0.0451] Epoch 148: Train Loss = 0.0420461930334568\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0406, train_loss_epoch=0.042]Epoch 149: Train Loss = 0.04061924293637276\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0415, train_loss_epoch=0.0406]Epoch 150: Train Loss = 0.0415085144340992\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0386, train_loss_epoch=0.0415]Epoch 151: Train Loss = 0.038620300590991974\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0404, train_loss_epoch=0.0386]Epoch 152: Train Loss = 0.04036388918757439\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.0384, train_loss_epoch=0.0404]Epoch 153: Train Loss = 0.03843819350004196\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0409, train_loss_epoch=0.0384]Epoch 154: Train Loss = 0.04087654501199722\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0414, train_loss_epoch=0.0409]Epoch 155: Train Loss = 0.04141772538423538\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0389, train_loss_epoch=0.0414]Epoch 156: Train Loss = 0.038871318101882935\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.042, train_loss_epoch=0.0389] Epoch 157: Train Loss = 0.04202458634972572\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0379, train_loss_epoch=0.042]Epoch 158: Train Loss = 0.03786010295152664\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0393, train_loss_epoch=0.0379]Epoch 159: Train Loss = 0.039307206869125366\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0381, train_loss_epoch=0.0393]Epoch 160: Train Loss = 0.03808940201997757\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0384, train_loss_epoch=0.0381]Epoch 161: Train Loss = 0.03844749927520752\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0375, train_loss_epoch=0.0384]Epoch 162: Train Loss = 0.03745752200484276\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0402, train_loss_epoch=0.0375]Epoch 163: Train Loss = 0.04024659842252731\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0383, train_loss_epoch=0.0402]Epoch 164: Train Loss = 0.03826657682657242\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0409, train_loss_epoch=0.0383]Epoch 165: Train Loss = 0.04090319946408272\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0391, train_loss_epoch=0.0409]Epoch 166: Train Loss = 0.03910559043288231\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=260, train_loss_step=0.0393, train_loss_epoch=0.0391]Epoch 167: Train Loss = 0.039271336048841476\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0407, train_loss_epoch=0.0393]Epoch 168: Train Loss = 0.04074406623840332\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.037, train_loss_epoch=0.0407] Epoch 169: Train Loss = 0.03699285537004471\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0402, train_loss_epoch=0.037]Epoch 170: Train Loss = 0.040172457695007324\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0376, train_loss_epoch=0.0402]Epoch 171: Train Loss = 0.03761282190680504\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.040, train_loss_epoch=0.0376] Epoch 172: Train Loss = 0.03996237367391586\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0369, train_loss_epoch=0.040]Epoch 173: Train Loss = 0.036928944289684296\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0361, train_loss_epoch=0.0369]Epoch 174: Train Loss = 0.03612160682678223\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0377, train_loss_epoch=0.0361]Epoch 175: Train Loss = 0.037699270993471146\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0358, train_loss_epoch=0.0377]Epoch 176: Train Loss = 0.03579528257250786\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0369, train_loss_epoch=0.0358]Epoch 177: Train Loss = 0.03694719821214676\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0387, train_loss_epoch=0.0369]Epoch 178: Train Loss = 0.038721051067113876\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0375, train_loss_epoch=0.0387]Epoch 179: Train Loss = 0.037525374442338943\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0367, train_loss_epoch=0.0375]Epoch 180: Train Loss = 0.036651983857154846\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0378, train_loss_epoch=0.0367]Epoch 181: Train Loss = 0.03775179013609886\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0354, train_loss_epoch=0.0378]Epoch 182: Train Loss = 0.03538815304636955\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0396, train_loss_epoch=0.0354]Epoch 183: Train Loss = 0.03956829383969307\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.0375, train_loss_epoch=0.0396]Epoch 184: Train Loss = 0.03751775249838829\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0383, train_loss_epoch=0.0375]Epoch 185: Train Loss = 0.03825216740369797\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0385, train_loss_epoch=0.0383]Epoch 186: Train Loss = 0.03846625238656998\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.0354, train_loss_epoch=0.0385]Epoch 187: Train Loss = 0.03540930151939392\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.041, train_loss_epoch=0.0354] Epoch 188: Train Loss = 0.04100124165415764\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0348, train_loss_epoch=0.041]Epoch 189: Train Loss = 0.034777700901031494\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0366, train_loss_epoch=0.0348]Epoch 190: Train Loss = 0.03661923110485077\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0343, train_loss_epoch=0.0366]Epoch 191: Train Loss = 0.03434088081121445\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.035, train_loss_epoch=0.0343] Epoch 192: Train Loss = 0.03501712903380394\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.038, train_loss_epoch=0.035] Epoch 193: Train Loss = 0.0380304716527462\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0355, train_loss_epoch=0.038]Epoch 194: Train Loss = 0.03547569736838341\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0384, train_loss_epoch=0.0355]Epoch 195: Train Loss = 0.03836315497756004\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.036, train_loss_epoch=0.0384] Epoch 196: Train Loss = 0.03597439453005791\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0349, train_loss_epoch=0.036]Epoch 197: Train Loss = 0.03487605229020119\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0394, train_loss_epoch=0.0349]Epoch 198: Train Loss = 0.03942834585905075\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.0341, train_loss_epoch=0.0394]Epoch 199: Train Loss = 0.034079354256391525\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0347, train_loss_epoch=0.0341]Epoch 200: Train Loss = 0.03473282977938652\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0364, train_loss_epoch=0.0347]Epoch 201: Train Loss = 0.03641865402460098\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0337, train_loss_epoch=0.0364]Epoch 202: Train Loss = 0.03366865590214729\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0367, train_loss_epoch=0.0337]Epoch 203: Train Loss = 0.03670508414506912\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0349, train_loss_epoch=0.0367]Epoch 204: Train Loss = 0.034850649535655975\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0348, train_loss_epoch=0.0349]Epoch 205: Train Loss = 0.03478085994720459\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0358, train_loss_epoch=0.0348]Epoch 206: Train Loss = 0.03577703237533569\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0334, train_loss_epoch=0.0358]Epoch 207: Train Loss = 0.033388651907444\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0378, train_loss_epoch=0.0334]Epoch 208: Train Loss = 0.037843991070985794\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.034, train_loss_epoch=0.0378] Epoch 209: Train Loss = 0.03403304144740105\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0357, train_loss_epoch=0.034]Epoch 210: Train Loss = 0.035730719566345215\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0358, train_loss_epoch=0.0357]Epoch 211: Train Loss = 0.03583548218011856\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0339, train_loss_epoch=0.0358]Epoch 212: Train Loss = 0.03389039263129234\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0425, train_loss_epoch=0.0339]Epoch 213: Train Loss = 0.04254268854856491\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0369, train_loss_epoch=0.0425]Epoch 214: Train Loss = 0.03686260059475899\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.037, train_loss_epoch=0.0369] Epoch 215: Train Loss = 0.03704378381371498\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0399, train_loss_epoch=0.037]Epoch 216: Train Loss = 0.03985617309808731\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0333, train_loss_epoch=0.0399]Epoch 217: Train Loss = 0.03326881676912308\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0465, train_loss_epoch=0.0333]Epoch 218: Train Loss = 0.046524301171302795\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0363, train_loss_epoch=0.0465]Epoch 219: Train Loss = 0.03627055510878563\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0377, train_loss_epoch=0.0363]Epoch 220: Train Loss = 0.03770127519965172\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0367, train_loss_epoch=0.0377]Epoch 221: Train Loss = 0.03671110421419144\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0347, train_loss_epoch=0.0367]Epoch 222: Train Loss = 0.034680478274822235\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0419, train_loss_epoch=0.0347]Epoch 223: Train Loss = 0.04190874844789505\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0334, train_loss_epoch=0.0419]Epoch 224: Train Loss = 0.033410344272851944\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0346, train_loss_epoch=0.0334]Epoch 225: Train Loss = 0.03455134108662605\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.036, train_loss_epoch=0.0346] Epoch 226: Train Loss = 0.03596420958638191\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0333, train_loss_epoch=0.036]Epoch 227: Train Loss = 0.03327634930610657\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0367, train_loss_epoch=0.0333]Epoch 228: Train Loss = 0.036724936217069626\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0357, train_loss_epoch=0.0367]Epoch 229: Train Loss = 0.03574678301811218\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0351, train_loss_epoch=0.0357]Epoch 230: Train Loss = 0.035079482942819595\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0354, train_loss_epoch=0.0351]Epoch 231: Train Loss = 0.03540815785527229\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0326, train_loss_epoch=0.0354]Epoch 232: Train Loss = 0.03255937248468399\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0377, train_loss_epoch=0.0326]Epoch 233: Train Loss = 0.03774276748299599\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0328, train_loss_epoch=0.0377]Epoch 234: Train Loss = 0.032817479223012924\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0349, train_loss_epoch=0.0328]Epoch 235: Train Loss = 0.03492489457130432\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0355, train_loss_epoch=0.0349]Epoch 236: Train Loss = 0.03551347553730011\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0322, train_loss_epoch=0.0355]Epoch 237: Train Loss = 0.032242726534605026\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0383, train_loss_epoch=0.0322]Epoch 238: Train Loss = 0.03829655423760414\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0356, train_loss_epoch=0.0383]Epoch 239: Train Loss = 0.035607315599918365\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0344, train_loss_epoch=0.0356]Epoch 240: Train Loss = 0.034441027790308\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0393, train_loss_epoch=0.0344]Epoch 241: Train Loss = 0.03927997872233391\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0322, train_loss_epoch=0.0393]Epoch 242: Train Loss = 0.0321713387966156\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=260, train_loss_step=0.0369, train_loss_epoch=0.0322]Epoch 243: Train Loss = 0.03690009564161301\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0359, train_loss_epoch=0.0369]Epoch 244: Train Loss = 0.03592461720108986\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.033, train_loss_epoch=0.0359] Epoch 245: Train Loss = 0.03303385525941849\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0402, train_loss_epoch=0.033]Epoch 246: Train Loss = 0.04018157720565796\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.033, train_loss_epoch=0.0402] Epoch 247: Train Loss = 0.03295719996094704\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=260, train_loss_step=0.0324, train_loss_epoch=0.033]Epoch 248: Train Loss = 0.03238362446427345\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=260, train_loss_step=0.0357, train_loss_epoch=0.0324]Epoch 249: Train Loss = 0.03567971661686897\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0357, train_loss_epoch=0.0357]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=260, train_loss_step=0.0357, train_loss_epoch=0.0357]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 38: from 1998-11-02 00:00:00 to 2022-12-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MAE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 384    | train\n",
      "4 | dec_embedding | DataEmbedding | 384    | train\n",
      "5 | encoder       | TransEncoder  | 199 K  | train\n",
      "6 | decoder       | TransDecoder  | 141 K  | train\n",
      "--------------------------------------------------------\n",
      "341 K     Trainable params\n",
      "0         Non-trainable params\n",
      "341 K     Total params\n",
      "1.368     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.403]Epoch 0: Train Loss = 0.4027848541736603\n",
      "Epoch 1: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.489, train_loss_epoch=0.403]Epoch 1: Train Loss = 0.4893265664577484\n",
      "Epoch 2: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.378, train_loss_epoch=0.489]Epoch 2: Train Loss = 0.37829095125198364\n",
      "Epoch 3: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.250, train_loss_epoch=0.378]Epoch 3: Train Loss = 0.2502553164958954\n",
      "Epoch 4: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.307, train_loss_epoch=0.250]Epoch 4: Train Loss = 0.3065984547138214\n",
      "Epoch 5: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.313, train_loss_epoch=0.307]Epoch 5: Train Loss = 0.31343573331832886\n",
      "Epoch 6: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.260, train_loss_epoch=0.313]Epoch 6: Train Loss = 0.2598421573638916\n",
      "Epoch 7: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.243, train_loss_epoch=0.260]Epoch 7: Train Loss = 0.24302224814891815\n",
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.268, train_loss_epoch=0.243]Epoch 8: Train Loss = 0.2680944800376892\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.261, train_loss_epoch=0.268]Epoch 9: Train Loss = 0.2608688175678253\n",
      "Epoch 10: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.243, train_loss_epoch=0.261]Epoch 10: Train Loss = 0.24346622824668884\n",
      "Epoch 11: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.224, train_loss_epoch=0.243]Epoch 11: Train Loss = 0.2236371487379074\n",
      "Epoch 12: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.234, train_loss_epoch=0.224]Epoch 12: Train Loss = 0.23394319415092468\n",
      "Epoch 13: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.218, train_loss_epoch=0.234]Epoch 13: Train Loss = 0.21785937249660492\n",
      "Epoch 14: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.211, train_loss_epoch=0.218]Epoch 14: Train Loss = 0.21097156405448914\n",
      "Epoch 15: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.196, train_loss_epoch=0.211]Epoch 15: Train Loss = 0.19551195204257965\n",
      "Epoch 16: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.203, train_loss_epoch=0.196]Epoch 16: Train Loss = 0.20332074165344238\n",
      "Epoch 17: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.196, train_loss_epoch=0.203]Epoch 17: Train Loss = 0.19608119130134583\n",
      "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.198, train_loss_epoch=0.196]Epoch 18: Train Loss = 0.1979714184999466\n",
      "Epoch 19: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.173, train_loss_epoch=0.198]Epoch 19: Train Loss = 0.17272944748401642\n",
      "Epoch 20: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.168, train_loss_epoch=0.173]Epoch 20: Train Loss = 0.16803570091724396\n",
      "Epoch 21: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.184, train_loss_epoch=0.168]Epoch 21: Train Loss = 0.18388989567756653\n",
      "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.182, train_loss_epoch=0.184]Epoch 22: Train Loss = 0.18157681822776794\n",
      "Epoch 23: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.168, train_loss_epoch=0.182]Epoch 23: Train Loss = 0.16803692281246185\n",
      "Epoch 24: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.160, train_loss_epoch=0.168]Epoch 24: Train Loss = 0.1603182703256607\n",
      "Epoch 25: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.159, train_loss_epoch=0.160]Epoch 25: Train Loss = 0.15926511585712433\n",
      "Epoch 26: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.163, train_loss_epoch=0.159]Epoch 26: Train Loss = 0.16306641697883606\n",
      "Epoch 27: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.153, train_loss_epoch=0.163]Epoch 27: Train Loss = 0.15331730246543884\n",
      "Epoch 28: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.146, train_loss_epoch=0.153]Epoch 28: Train Loss = 0.14611032605171204\n",
      "Epoch 29: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.153, train_loss_epoch=0.146]Epoch 29: Train Loss = 0.15268032252788544\n",
      "Epoch 30: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.147, train_loss_epoch=0.153]Epoch 30: Train Loss = 0.14724287390708923\n",
      "Epoch 31: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.143, train_loss_epoch=0.147]Epoch 31: Train Loss = 0.14289551973342896\n",
      "Epoch 32: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.138, train_loss_epoch=0.143]Epoch 32: Train Loss = 0.13776995241641998\n",
      "Epoch 33: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.135, train_loss_epoch=0.138]Epoch 33: Train Loss = 0.13544856011867523\n",
      "Epoch 34: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.137, train_loss_epoch=0.135]Epoch 34: Train Loss = 0.13741816580295563\n",
      "Epoch 35: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.133, train_loss_epoch=0.137]Epoch 35: Train Loss = 0.13311336934566498\n",
      "Epoch 36: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.132, train_loss_epoch=0.133]Epoch 36: Train Loss = 0.13238976895809174\n",
      "Epoch 37: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.131, train_loss_epoch=0.132]Epoch 37: Train Loss = 0.1310133934020996\n",
      "Epoch 38: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.124, train_loss_epoch=0.131]Epoch 38: Train Loss = 0.12389753013849258\n",
      "Epoch 39: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.119, train_loss_epoch=0.124]Epoch 39: Train Loss = 0.11866343766450882\n",
      "Epoch 40: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.118, train_loss_epoch=0.119]Epoch 40: Train Loss = 0.11778586357831955\n",
      "Epoch 41: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.119, train_loss_epoch=0.118]Epoch 41: Train Loss = 0.11910875886678696\n",
      "Epoch 42: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.115, train_loss_epoch=0.119]Epoch 42: Train Loss = 0.11545789986848831\n",
      "Epoch 43: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.110, train_loss_epoch=0.115]Epoch 43: Train Loss = 0.1097472533583641\n",
      "Epoch 44: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.116, train_loss_epoch=0.110]Epoch 44: Train Loss = 0.11610421538352966\n",
      "Epoch 45: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.109, train_loss_epoch=0.116]Epoch 45: Train Loss = 0.10862202197313309\n",
      "Epoch 46: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.107, train_loss_epoch=0.109]Epoch 46: Train Loss = 0.10664654523134232\n",
      "Epoch 47: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.105, train_loss_epoch=0.107]Epoch 47: Train Loss = 0.10452918708324432\n",
      "Epoch 48: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.105, train_loss_epoch=0.105]Epoch 48: Train Loss = 0.10474865138530731\n",
      "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.104, train_loss_epoch=0.105]Epoch 49: Train Loss = 0.10415277630090714\n",
      "Epoch 50: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.102, train_loss_epoch=0.104]Epoch 50: Train Loss = 0.10189905762672424\n",
      "Epoch 51: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0975, train_loss_epoch=0.102]Epoch 51: Train Loss = 0.09749869257211685\n",
      "Epoch 52: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0982, train_loss_epoch=0.0975]Epoch 52: Train Loss = 0.09820378571748734\n",
      "Epoch 53: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0944, train_loss_epoch=0.0982]Epoch 53: Train Loss = 0.09442061930894852\n",
      "Epoch 54: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0932, train_loss_epoch=0.0944]Epoch 54: Train Loss = 0.09318321943283081\n",
      "Epoch 55: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0931, train_loss_epoch=0.0932]Epoch 55: Train Loss = 0.09312253445386887\n",
      "Epoch 56: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.091, train_loss_epoch=0.0931] Epoch 56: Train Loss = 0.09100168198347092\n",
      "Epoch 57: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0888, train_loss_epoch=0.091]Epoch 57: Train Loss = 0.08883123099803925\n",
      "Epoch 58: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0885, train_loss_epoch=0.0888]Epoch 58: Train Loss = 0.08846480399370193\n",
      "Epoch 59: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0855, train_loss_epoch=0.0885]Epoch 59: Train Loss = 0.08550476282835007\n",
      "Epoch 60: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0851, train_loss_epoch=0.0855]Epoch 60: Train Loss = 0.08511298894882202\n",
      "Epoch 61: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0817, train_loss_epoch=0.0851]Epoch 61: Train Loss = 0.08171050995588303\n",
      "Epoch 62: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0809, train_loss_epoch=0.0817]Epoch 62: Train Loss = 0.08088337630033493\n",
      "Epoch 63: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.0806, train_loss_epoch=0.0809]Epoch 63: Train Loss = 0.08059801906347275\n",
      "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0797, train_loss_epoch=0.0806]Epoch 64: Train Loss = 0.07972213625907898\n",
      "Epoch 65: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0777, train_loss_epoch=0.0797]Epoch 65: Train Loss = 0.07774262130260468\n",
      "Epoch 66: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0789, train_loss_epoch=0.0777]Epoch 66: Train Loss = 0.07888878136873245\n",
      "Epoch 67: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=262, train_loss_step=0.0774, train_loss_epoch=0.0789]Epoch 67: Train Loss = 0.0774463415145874\n",
      "Epoch 68: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0762, train_loss_epoch=0.0774]Epoch 68: Train Loss = 0.07617145031690598\n",
      "Epoch 69: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0715, train_loss_epoch=0.0762]Epoch 69: Train Loss = 0.07145172357559204\n",
      "Epoch 70: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0783, train_loss_epoch=0.0715]Epoch 70: Train Loss = 0.07828352600336075\n",
      "Epoch 71: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0704, train_loss_epoch=0.0783]Epoch 71: Train Loss = 0.07039165496826172\n",
      "Epoch 72: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0757, train_loss_epoch=0.0704]Epoch 72: Train Loss = 0.0757172703742981\n",
      "Epoch 73: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0695, train_loss_epoch=0.0757]Epoch 73: Train Loss = 0.06947866082191467\n",
      "Epoch 74: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0743, train_loss_epoch=0.0695]Epoch 74: Train Loss = 0.07427505403757095\n",
      "Epoch 75: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.067, train_loss_epoch=0.0743] Epoch 75: Train Loss = 0.0670340359210968\n",
      "Epoch 76: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0681, train_loss_epoch=0.067]Epoch 76: Train Loss = 0.06808985769748688\n",
      "Epoch 77: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0675, train_loss_epoch=0.0681]Epoch 77: Train Loss = 0.067487932741642\n",
      "Epoch 78: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.068, train_loss_epoch=0.0675] Epoch 78: Train Loss = 0.06800319254398346\n",
      "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0643, train_loss_epoch=0.068]Epoch 79: Train Loss = 0.06425967067480087\n",
      "Epoch 80: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0652, train_loss_epoch=0.0643]Epoch 80: Train Loss = 0.06521676480770111\n",
      "Epoch 81: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0636, train_loss_epoch=0.0652]Epoch 81: Train Loss = 0.06362955272197723\n",
      "Epoch 82: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0641, train_loss_epoch=0.0636]Epoch 82: Train Loss = 0.0640605017542839\n",
      "Epoch 83: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.0628, train_loss_epoch=0.0641]Epoch 83: Train Loss = 0.0627809688448906\n",
      "Epoch 84: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0623, train_loss_epoch=0.0628]Epoch 84: Train Loss = 0.06229540333151817\n",
      "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.0619, train_loss_epoch=0.0623]Epoch 85: Train Loss = 0.061872489750385284\n",
      "Epoch 86: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0603, train_loss_epoch=0.0619]Epoch 86: Train Loss = 0.06033598631620407\n",
      "Epoch 87: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0593, train_loss_epoch=0.0603]Epoch 87: Train Loss = 0.05931824818253517\n",
      "Epoch 88: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0587, train_loss_epoch=0.0593]Epoch 88: Train Loss = 0.05865934118628502\n",
      "Epoch 89: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0583, train_loss_epoch=0.0587]Epoch 89: Train Loss = 0.058304302394390106\n",
      "Epoch 90: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0591, train_loss_epoch=0.0583]Epoch 90: Train Loss = 0.05908733606338501\n",
      "Epoch 91: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0563, train_loss_epoch=0.0591]Epoch 91: Train Loss = 0.056340254843235016\n",
      "Epoch 92: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0572, train_loss_epoch=0.0563]Epoch 92: Train Loss = 0.05719172582030296\n",
      "Epoch 93: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0566, train_loss_epoch=0.0572]Epoch 93: Train Loss = 0.056589990854263306\n",
      "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.056, train_loss_epoch=0.0566] Epoch 94: Train Loss = 0.05603274703025818\n",
      "Epoch 95: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0577, train_loss_epoch=0.056]Epoch 95: Train Loss = 0.057749878615140915\n",
      "Epoch 96: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0576, train_loss_epoch=0.0577]Epoch 96: Train Loss = 0.057629287242889404\n",
      "Epoch 97: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0604, train_loss_epoch=0.0576]Epoch 97: Train Loss = 0.06036187335848808\n",
      "Epoch 98: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0576, train_loss_epoch=0.0604]Epoch 98: Train Loss = 0.057628948241472244\n",
      "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0558, train_loss_epoch=0.0576]Epoch 99: Train Loss = 0.05577537789940834\n",
      "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0581, train_loss_epoch=0.0558]Epoch 100: Train Loss = 0.0581129789352417\n",
      "Epoch 101: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0542, train_loss_epoch=0.0581]Epoch 101: Train Loss = 0.054162461310625076\n",
      "Epoch 102: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0597, train_loss_epoch=0.0542]Epoch 102: Train Loss = 0.05968090891838074\n",
      "Epoch 103: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0497, train_loss_epoch=0.0597]Epoch 103: Train Loss = 0.049693938344717026\n",
      "Epoch 104: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0633, train_loss_epoch=0.0497]Epoch 104: Train Loss = 0.06333504617214203\n",
      "Epoch 105: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0518, train_loss_epoch=0.0633]Epoch 105: Train Loss = 0.05175088346004486\n",
      "Epoch 106: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0672, train_loss_epoch=0.0518]Epoch 106: Train Loss = 0.06716211885213852\n",
      "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0543, train_loss_epoch=0.0672]Epoch 107: Train Loss = 0.05431506782770157\n",
      "Epoch 108: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0521, train_loss_epoch=0.0543]Epoch 108: Train Loss = 0.05205288901925087\n",
      "Epoch 109: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0632, train_loss_epoch=0.0521]Epoch 109: Train Loss = 0.06322391331195831\n",
      "Epoch 110: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0504, train_loss_epoch=0.0632]Epoch 110: Train Loss = 0.05036303400993347\n",
      "Epoch 111: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0601, train_loss_epoch=0.0504]Epoch 111: Train Loss = 0.06009838730096817\n",
      "Epoch 112: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0553, train_loss_epoch=0.0601]Epoch 112: Train Loss = 0.05529456585645676\n",
      "Epoch 113: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0503, train_loss_epoch=0.0553]Epoch 113: Train Loss = 0.050252534449100494\n",
      "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.057, train_loss_epoch=0.0503] Epoch 114: Train Loss = 0.057028524577617645\n",
      "Epoch 115: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0477, train_loss_epoch=0.057]Epoch 115: Train Loss = 0.0477059967815876\n",
      "Epoch 116: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.051, train_loss_epoch=0.0477] Epoch 116: Train Loss = 0.05097493156790733\n",
      "Epoch 117: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0497, train_loss_epoch=0.051]Epoch 117: Train Loss = 0.04973044618964195\n",
      "Epoch 118: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0477, train_loss_epoch=0.0497]Epoch 118: Train Loss = 0.047700438648462296\n",
      "Epoch 119: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.0497, train_loss_epoch=0.0477]Epoch 119: Train Loss = 0.0497266948223114\n",
      "Epoch 120: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0461, train_loss_epoch=0.0497]Epoch 120: Train Loss = 0.046050023287534714\n",
      "Epoch 121: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0474, train_loss_epoch=0.0461]Epoch 121: Train Loss = 0.04742080345749855\n",
      "Epoch 122: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0493, train_loss_epoch=0.0474]Epoch 122: Train Loss = 0.04928186163306236\n",
      "Epoch 123: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.0464, train_loss_epoch=0.0493]Epoch 123: Train Loss = 0.04640713334083557\n",
      "Epoch 124: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0487, train_loss_epoch=0.0464]Epoch 124: Train Loss = 0.048712052404880524\n",
      "Epoch 125: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.045, train_loss_epoch=0.0487] Epoch 125: Train Loss = 0.04502985626459122\n",
      "Epoch 126: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0466, train_loss_epoch=0.045]Epoch 126: Train Loss = 0.04661785438656807\n",
      "Epoch 127: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0458, train_loss_epoch=0.0466]Epoch 127: Train Loss = 0.04576721787452698\n",
      "Epoch 128: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0451, train_loss_epoch=0.0458]Epoch 128: Train Loss = 0.045095622539520264\n",
      "Epoch 129: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0447, train_loss_epoch=0.0451]Epoch 129: Train Loss = 0.04470014199614525\n",
      "Epoch 130: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.043, train_loss_epoch=0.0447] Epoch 130: Train Loss = 0.04297114536166191\n",
      "Epoch 131: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.0478, train_loss_epoch=0.043]Epoch 131: Train Loss = 0.04778337851166725\n",
      "Epoch 132: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0435, train_loss_epoch=0.0478]Epoch 132: Train Loss = 0.0434991680085659\n",
      "Epoch 133: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0451, train_loss_epoch=0.0435]Epoch 133: Train Loss = 0.04514134302735329\n",
      "Epoch 134: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0427, train_loss_epoch=0.0451]Epoch 134: Train Loss = 0.04271666333079338\n",
      "Epoch 135: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0445, train_loss_epoch=0.0427]Epoch 135: Train Loss = 0.044508498162031174\n",
      "Epoch 136: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0448, train_loss_epoch=0.0445]Epoch 136: Train Loss = 0.044761769473552704\n",
      "Epoch 137: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0413, train_loss_epoch=0.0448]Epoch 137: Train Loss = 0.04132658615708351\n",
      "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0464, train_loss_epoch=0.0413]Epoch 138: Train Loss = 0.046435609459877014\n",
      "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.0421, train_loss_epoch=0.0464]Epoch 139: Train Loss = 0.04206102341413498\n",
      "Epoch 140: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0437, train_loss_epoch=0.0421]Epoch 140: Train Loss = 0.04367051646113396\n",
      "Epoch 141: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0457, train_loss_epoch=0.0437]Epoch 141: Train Loss = 0.045699648559093475\n",
      "Epoch 142: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0414, train_loss_epoch=0.0457]Epoch 142: Train Loss = 0.04142148792743683\n",
      "Epoch 143: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.0456, train_loss_epoch=0.0414]Epoch 143: Train Loss = 0.04564613103866577\n",
      "Epoch 144: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0472, train_loss_epoch=0.0456]Epoch 144: Train Loss = 0.04719347134232521\n",
      "Epoch 145: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0443, train_loss_epoch=0.0472]Epoch 145: Train Loss = 0.044348832219839096\n",
      "Epoch 146: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.051, train_loss_epoch=0.0443] Epoch 146: Train Loss = 0.050993598997592926\n",
      "Epoch 147: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0403, train_loss_epoch=0.051]Epoch 147: Train Loss = 0.04026094824075699\n",
      "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0468, train_loss_epoch=0.0403]Epoch 148: Train Loss = 0.046805575489997864\n",
      "Epoch 149: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0431, train_loss_epoch=0.0468]Epoch 149: Train Loss = 0.0430535152554512\n",
      "Epoch 150: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0416, train_loss_epoch=0.0431]Epoch 150: Train Loss = 0.04163642227649689\n",
      "Epoch 151: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.048, train_loss_epoch=0.0416] Epoch 151: Train Loss = 0.0479767881333828\n",
      "Epoch 152: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0403, train_loss_epoch=0.048]Epoch 152: Train Loss = 0.040286656469106674\n",
      "Epoch 153: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0484, train_loss_epoch=0.0403]Epoch 153: Train Loss = 0.048417091369628906\n",
      "Epoch 154: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0483, train_loss_epoch=0.0484]Epoch 154: Train Loss = 0.04831991344690323\n",
      "Epoch 155: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0435, train_loss_epoch=0.0483]Epoch 155: Train Loss = 0.0435393787920475\n",
      "Epoch 156: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0501, train_loss_epoch=0.0435]Epoch 156: Train Loss = 0.05013715848326683\n",
      "Epoch 157: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0408, train_loss_epoch=0.0501]Epoch 157: Train Loss = 0.04084854573011398\n",
      "Epoch 158: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0421, train_loss_epoch=0.0408]Epoch 158: Train Loss = 0.04214433208107948\n",
      "Epoch 159: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0437, train_loss_epoch=0.0421]Epoch 159: Train Loss = 0.04372754693031311\n",
      "Epoch 160: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0385, train_loss_epoch=0.0437]Epoch 160: Train Loss = 0.03847159817814827\n",
      "Epoch 161: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0436, train_loss_epoch=0.0385]Epoch 161: Train Loss = 0.043580908328294754\n",
      "Epoch 162: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0422, train_loss_epoch=0.0436]Epoch 162: Train Loss = 0.0421980619430542\n",
      "Epoch 163: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0424, train_loss_epoch=0.0422]Epoch 163: Train Loss = 0.04243851080536842\n",
      "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0487, train_loss_epoch=0.0424]Epoch 164: Train Loss = 0.048669494688510895\n",
      "Epoch 165: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0388, train_loss_epoch=0.0487]Epoch 165: Train Loss = 0.0388314388692379\n",
      "Epoch 166: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.048, train_loss_epoch=0.0388] Epoch 166: Train Loss = 0.04795698821544647\n",
      "Epoch 167: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0404, train_loss_epoch=0.048]Epoch 167: Train Loss = 0.04043371230363846\n",
      "Epoch 168: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0378, train_loss_epoch=0.0404]Epoch 168: Train Loss = 0.0378413051366806\n",
      "Epoch 169: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0476, train_loss_epoch=0.0378]Epoch 169: Train Loss = 0.04759878292679787\n",
      "Epoch 170: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0429, train_loss_epoch=0.0476]Epoch 170: Train Loss = 0.04285316914319992\n",
      "Epoch 171: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.047, train_loss_epoch=0.0429] Epoch 171: Train Loss = 0.04699943959712982\n",
      "Epoch 172: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.042, train_loss_epoch=0.047] Epoch 172: Train Loss = 0.04200742021203041\n",
      "Epoch 173: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0374, train_loss_epoch=0.042]Epoch 173: Train Loss = 0.03737481310963631\n",
      "Epoch 174: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0462, train_loss_epoch=0.0374]Epoch 174: Train Loss = 0.046188291162252426\n",
      "Epoch 175: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0414, train_loss_epoch=0.0462]Epoch 175: Train Loss = 0.041405584663152695\n",
      "Epoch 176: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0377, train_loss_epoch=0.0414]Epoch 176: Train Loss = 0.037688110023736954\n",
      "Epoch 177: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0443, train_loss_epoch=0.0377]Epoch 177: Train Loss = 0.04429689422249794\n",
      "Epoch 178: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.042, train_loss_epoch=0.0443] Epoch 178: Train Loss = 0.04198954626917839\n",
      "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0406, train_loss_epoch=0.042]Epoch 179: Train Loss = 0.04064062982797623\n",
      "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.0431, train_loss_epoch=0.0406]Epoch 180: Train Loss = 0.043109774589538574\n",
      "Epoch 181: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.0372, train_loss_epoch=0.0431]Epoch 181: Train Loss = 0.03724204748868942\n",
      "Epoch 182: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0389, train_loss_epoch=0.0372]Epoch 182: Train Loss = 0.03892798349261284\n",
      "Epoch 183: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0436, train_loss_epoch=0.0389]Epoch 183: Train Loss = 0.043639276176691055\n",
      "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0364, train_loss_epoch=0.0436]Epoch 184: Train Loss = 0.03644749894738197\n",
      "Epoch 185: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0427, train_loss_epoch=0.0364]Epoch 185: Train Loss = 0.04272789508104324\n",
      "Epoch 186: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.038, train_loss_epoch=0.0427] Epoch 186: Train Loss = 0.037987980991601944\n",
      "Epoch 187: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0424, train_loss_epoch=0.038]Epoch 187: Train Loss = 0.04239335283637047\n",
      "Epoch 188: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0396, train_loss_epoch=0.0424]Epoch 188: Train Loss = 0.039563849568367004\n",
      "Epoch 189: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0358, train_loss_epoch=0.0396]Epoch 189: Train Loss = 0.03583833575248718\n",
      "Epoch 190: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.039, train_loss_epoch=0.0358] Epoch 190: Train Loss = 0.0390004962682724\n",
      "Epoch 191: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0383, train_loss_epoch=0.039]Epoch 191: Train Loss = 0.03831373155117035\n",
      "Epoch 192: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0358, train_loss_epoch=0.0383]Epoch 192: Train Loss = 0.03577021136879921\n",
      "Epoch 193: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0424, train_loss_epoch=0.0358]Epoch 193: Train Loss = 0.042423661798238754\n",
      "Epoch 194: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0374, train_loss_epoch=0.0424]Epoch 194: Train Loss = 0.03740469366312027\n",
      "Epoch 195: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0405, train_loss_epoch=0.0374]Epoch 195: Train Loss = 0.04053361341357231\n",
      "Epoch 196: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0362, train_loss_epoch=0.0405]Epoch 196: Train Loss = 0.03618502989411354\n",
      "Epoch 197: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0354, train_loss_epoch=0.0362]Epoch 197: Train Loss = 0.035434432327747345\n",
      "Epoch 198: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0365, train_loss_epoch=0.0354]Epoch 198: Train Loss = 0.03652225807309151\n",
      "Epoch 199: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0347, train_loss_epoch=0.0365]Epoch 199: Train Loss = 0.034707654267549515\n",
      "Epoch 200: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0362, train_loss_epoch=0.0347]Epoch 200: Train Loss = 0.03623373433947563\n",
      "Epoch 201: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=262, train_loss_step=0.036, train_loss_epoch=0.0362] Epoch 201: Train Loss = 0.036043498665094376\n",
      "Epoch 202: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.035, train_loss_epoch=0.036] Epoch 202: Train Loss = 0.034977082163095474\n",
      "Epoch 203: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0347, train_loss_epoch=0.035]Epoch 203: Train Loss = 0.034686751663684845\n",
      "Epoch 204: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.035, train_loss_epoch=0.0347] Epoch 204: Train Loss = 0.035013388842344284\n",
      "Epoch 205: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0348, train_loss_epoch=0.035]Epoch 205: Train Loss = 0.034839779138565063\n",
      "Epoch 206: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0357, train_loss_epoch=0.0348]Epoch 206: Train Loss = 0.03566138818860054\n",
      "Epoch 207: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0337, train_loss_epoch=0.0357]Epoch 207: Train Loss = 0.033749379217624664\n",
      "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0357, train_loss_epoch=0.0337]Epoch 208: Train Loss = 0.03572038188576698\n",
      "Epoch 209: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0359, train_loss_epoch=0.0357]Epoch 209: Train Loss = 0.03585188463330269\n",
      "Epoch 210: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0373, train_loss_epoch=0.0359]Epoch 210: Train Loss = 0.03731042146682739\n",
      "Epoch 211: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0342, train_loss_epoch=0.0373]Epoch 211: Train Loss = 0.03419124335050583\n",
      "Epoch 212: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0348, train_loss_epoch=0.0342]Epoch 212: Train Loss = 0.03479140251874924\n",
      "Epoch 213: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0353, train_loss_epoch=0.0348]Epoch 213: Train Loss = 0.035349100828170776\n",
      "Epoch 214: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0338, train_loss_epoch=0.0353]Epoch 214: Train Loss = 0.033784493803977966\n",
      "Epoch 215: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0347, train_loss_epoch=0.0338]Epoch 215: Train Loss = 0.03467921167612076\n",
      "Epoch 216: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0348, train_loss_epoch=0.0347]Epoch 216: Train Loss = 0.03482430428266525\n",
      "Epoch 217: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0341, train_loss_epoch=0.0348]Epoch 217: Train Loss = 0.03406349942088127\n",
      "Epoch 218: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0357, train_loss_epoch=0.0341]Epoch 218: Train Loss = 0.035689063370227814\n",
      "Epoch 219: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0346, train_loss_epoch=0.0357]Epoch 219: Train Loss = 0.03464917466044426\n",
      "Epoch 220: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0352, train_loss_epoch=0.0346]Epoch 220: Train Loss = 0.035241447389125824\n",
      "Epoch 221: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0328, train_loss_epoch=0.0352]Epoch 221: Train Loss = 0.032848697155714035\n",
      "Epoch 222: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0339, train_loss_epoch=0.0328]Epoch 222: Train Loss = 0.03392071649432182\n",
      "Epoch 223: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0351, train_loss_epoch=0.0339]Epoch 223: Train Loss = 0.03514130786061287\n",
      "Epoch 224: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0339, train_loss_epoch=0.0351]Epoch 224: Train Loss = 0.03386065736413002\n",
      "Epoch 225: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0336, train_loss_epoch=0.0339]Epoch 225: Train Loss = 0.03357304260134697\n",
      "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0326, train_loss_epoch=0.0336]Epoch 226: Train Loss = 0.032600197941064835\n",
      "Epoch 227: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0333, train_loss_epoch=0.0326]Epoch 227: Train Loss = 0.033286094665527344\n",
      "Epoch 228: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0338, train_loss_epoch=0.0333]Epoch 228: Train Loss = 0.033848028630018234\n",
      "Epoch 229: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0342, train_loss_epoch=0.0338]Epoch 229: Train Loss = 0.03415927663445473\n",
      "Epoch 230: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.033, train_loss_epoch=0.0342] Epoch 230: Train Loss = 0.032989367842674255\n",
      "Epoch 231: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0358, train_loss_epoch=0.033]Epoch 231: Train Loss = 0.03583812341094017\n",
      "Epoch 232: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0338, train_loss_epoch=0.0358]Epoch 232: Train Loss = 0.03377973660826683\n",
      "Epoch 233: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0339, train_loss_epoch=0.0338]Epoch 233: Train Loss = 0.03393517807126045\n",
      "Epoch 234: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0352, train_loss_epoch=0.0339]Epoch 234: Train Loss = 0.03518650680780411\n",
      "Epoch 235: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0337, train_loss_epoch=0.0352]Epoch 235: Train Loss = 0.03367198258638382\n",
      "Epoch 236: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0339, train_loss_epoch=0.0337]Epoch 236: Train Loss = 0.03394369035959244\n",
      "Epoch 237: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0339, train_loss_epoch=0.0339]Epoch 237: Train Loss = 0.03385842591524124\n",
      "Epoch 238: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0334, train_loss_epoch=0.0339]Epoch 238: Train Loss = 0.033353060483932495\n",
      "Epoch 239: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0326, train_loss_epoch=0.0334]Epoch 239: Train Loss = 0.03262029215693474\n",
      "Epoch 240: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0326, train_loss_epoch=0.0326]Epoch 240: Train Loss = 0.03262202814221382\n",
      "Epoch 241: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0326, train_loss_epoch=0.0326]Epoch 241: Train Loss = 0.03255525976419449\n",
      "Epoch 242: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0321, train_loss_epoch=0.0326]Epoch 242: Train Loss = 0.0320824533700943\n",
      "Epoch 243: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0337, train_loss_epoch=0.0321]Epoch 243: Train Loss = 0.033744897693395615\n",
      "Epoch 244: 100%|██████████| 1/1 [00:02<00:00,  0.45it/s, v_num=262, train_loss_step=0.0324, train_loss_epoch=0.0337]Epoch 244: Train Loss = 0.03240954130887985\n",
      "Epoch 245: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0325, train_loss_epoch=0.0324]Epoch 245: Train Loss = 0.03245396167039871\n",
      "Epoch 246: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0325, train_loss_epoch=0.0325]Epoch 246: Train Loss = 0.032511722296476364\n",
      "Epoch 247: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.032, train_loss_epoch=0.0325] Epoch 247: Train Loss = 0.03200697898864746\n",
      "Epoch 248: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=262, train_loss_step=0.0365, train_loss_epoch=0.032]Epoch 248: Train Loss = 0.0364530123770237\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0329, train_loss_epoch=0.0365]Epoch 249: Train Loss = 0.032862402498722076\n",
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0329, train_loss_epoch=0.0329]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=262, train_loss_step=0.0329, train_loss_epoch=0.0329]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the trainer\n",
    "trainer = ModelTrainer(sbi_data, scaler_close, save_loss_callback, pl_trainer_kwargs)\n",
    "\n",
    "# Training and prediction loop\n",
    "window_number = 1\n",
    "while True:\n",
    "    train_data = sbi_data.loc[:training_end_date]\n",
    "    print(f\"Training window {window_number}: from {train_data.index.min()} to {train_data.index.max()}\")\n",
    "\n",
    "    # Train the model and get predictions\n",
    "    dates, pred_values = trainer.train_model(train_data, window_number)\n",
    "\n",
    "    if len(dates) == 0:\n",
    "        print(\"No future dates were generated. Exiting the loop.\")\n",
    "        break\n",
    "\n",
    "    # Store the predictions\n",
    "    predictions_df = pd.DataFrame({'Date': dates, 'Predicted Value': pred_values.flatten()})\n",
    "    final_predictions.append(predictions_df)\n",
    "\n",
    "    # Update training_end_date for the next window only if dates exist\n",
    "    training_end_date = dates.iloc[-1] if len(dates) > 0 else training_end_date\n",
    "\n",
    "    # Break if we reach the end of the data\n",
    "    if training_end_date >= sbi_data.index.max():\n",
    "        break\n",
    "\n",
    "    window_number += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to prediction_using_window_method_informer_model_one_year.csv\n",
      "Training Losses: []\n"
     ]
    }
   ],
   "source": [
    "# Combine predictions and save\n",
    "all_predictions_df = pd.concat(final_predictions, ignore_index=True)\n",
    "output_csv_file = 'prediction_using_window_method_informer_model_one_year.csv'\n",
    "all_predictions_df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_csv_file}\")\n",
    "\n",
    "# Print the logged training losses\n",
    "print(\"Training Losses:\", save_loss_callback.training_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
