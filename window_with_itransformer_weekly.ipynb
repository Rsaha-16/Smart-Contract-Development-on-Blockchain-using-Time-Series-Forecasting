{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neuralforecast in ./tpvenv/lib/python3.10/site-packages (1.7.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (2.4.1)\n",
      "Requirement already satisfied: pytorch-lightning>=2.0.0 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (2.4.0)\n",
      "Requirement already satisfied: utilsforecast>=0.0.25 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (0.2.5)\n",
      "Requirement already satisfied: optuna in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (1.26.4)\n",
      "Requirement already satisfied: ray[tune]>=2.2.0 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (2.37.0)\n",
      "Requirement already satisfied: pandas>=1.3.5 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (2.2.3)\n",
      "Requirement already satisfied: coreforecast>=0.0.6 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (0.0.12)\n",
      "Requirement already satisfied: fsspec in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (2024.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./tpvenv/lib/python3.10/site-packages (from pandas>=1.3.5->neuralforecast) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./tpvenv/lib/python3.10/site-packages (from pandas>=1.3.5->neuralforecast) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./tpvenv/lib/python3.10/site-packages (from pandas>=1.3.5->neuralforecast) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.66.5)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (24.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (0.11.7)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (1.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.12.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (5.28.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (1.1.0)\n",
      "Requirement already satisfied: frozenlist in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (1.4.1)\n",
      "Requirement already satisfied: aiosignal in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (1.3.1)\n",
      "Requirement already satisfied: requests in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (2.32.3)\n",
      "Requirement already satisfied: filelock in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (3.16.1)\n",
      "Requirement already satisfied: jsonschema in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (4.23.0)\n",
      "Requirement already satisfied: click>=7.0 in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (8.1.7)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (17.0.0)\n",
      "Requirement already satisfied: triton==3.0.0 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (3.0.0)\n",
      "Requirement already satisfied: networkx in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (3.1.4)\n",
      "Requirement already satisfied: sympy in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (1.13.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (2.20.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./tpvenv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->neuralforecast) (12.6.68)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./tpvenv/lib/python3.10/site-packages (from optuna->neuralforecast) (2.0.35)\n",
      "Requirement already satisfied: colorlog in ./tpvenv/lib/python3.10/site-packages (from optuna->neuralforecast) (6.8.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./tpvenv/lib/python3.10/site-packages (from optuna->neuralforecast) (1.13.3)\n",
      "Requirement already satisfied: Mako in ./tpvenv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->neuralforecast) (1.3.5)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./tpvenv/lib/python3.10/site-packages (from fsspec->neuralforecast) (3.10.5)\n",
      "Requirement already satisfied: setuptools in ./tpvenv/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=2.0.0->neuralforecast) (59.6.0)\n",
      "Requirement already satisfied: six>=1.5 in ./tpvenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->neuralforecast) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./tpvenv/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->neuralforecast) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./tpvenv/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->neuralforecast) (2.1.5)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./tpvenv/lib/python3.10/site-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.20.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./tpvenv/lib/python3.10/site-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (24.2.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./tpvenv/lib/python3.10/site-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.35.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./tpvenv/lib/python3.10/site-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (2023.12.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./tpvenv/lib/python3.10/site-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./tpvenv/lib/python3.10/site-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./tpvenv/lib/python3.10/site-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./tpvenv/lib/python3.10/site-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (2.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./tpvenv/lib/python3.10/site-packages (from sympy->torch>=2.0.0->neuralforecast) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./tpvenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (1.12.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./tpvenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (6.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./tpvenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (2.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./tpvenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (4.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install neuralforecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import iTransformer\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to save training losses at each epoch\n",
    "class SaveTrainingLossCallback(pl.Callback):\n",
    "    def __init__(self, log_file='epoch_loss_log_window_itransformer_model_six_months_nifty_weekly.txt'):\n",
    "        self.training_losses = []\n",
    "        self.log_file = log_file\n",
    "        self.window_number = 0\n",
    "        with open(self.log_file, 'w') as f:\n",
    "            f.write('Epoch,Train_Loss,Window\\n')\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # Save the training loss at the end of each epoch\n",
    "        train_loss = trainer.callback_metrics['train_loss'].item()\n",
    "        self.training_losses.append(train_loss)\n",
    "        print(f\"Epoch {trainer.current_epoch}: Train Loss = {train_loss}\")\n",
    "        \n",
    "        # Log the loss to the file\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write(f'{trainer.current_epoch},{train_loss},{self.window_number}\\n')\n",
    "\n",
    "    def set_window_number(self, window_number):\n",
    "        self.window_number = window_number\n",
    "\n",
    "# Initialize callbacks\n",
    "save_loss_callback = SaveTrainingLossCallback()\n",
    "pl_trainer_kwargs = {\"callbacks\": [save_loss_callback], \"accelerator\": \"cpu\", \"devices\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess the data\n",
    "csv_file_path = '/home/raj/Rajarshi/Term Project/notebook_files/data/^NSEI_week.csv'\n",
    "data = pd.read_csv(csv_file_path, parse_dates=['Date'])\n",
    "data.dropna(inplace=True)\n",
    "data.set_index('Date', inplace=True)\n",
    "data = data.asfreq('B', method='pad')\n",
    "\n",
    "# Create scalers\n",
    "scaler_close = MinMaxScaler()\n",
    "data['Open_Close_Diff'] = data['Open'] - data['Close']\n",
    "data['Close'] = scaler_close.fit_transform(data[['Close']])\n",
    "\n",
    "# Initialize variables\n",
    "training_end_date = data.index.max() - pd.DateOffset(months=6)  # Train using last 1 year of data\n",
    "final_predictions = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window management and model training class\n",
    "class ModelTrainer:\n",
    "    def __init__(self, data, scaler_close, save_loss_callback, pl_trainer_kwargs):\n",
    "        self.data = data\n",
    "        self.scaler_close = scaler_close\n",
    "        self.save_loss_callback = save_loss_callback\n",
    "        self.pl_trainer_kwargs = pl_trainer_kwargs\n",
    "\n",
    "    def train_model(self, train_data, window_number):\n",
    "        # Set the window number for the callback\n",
    "        self.save_loss_callback.set_window_number(window_number)\n",
    "\n",
    "        # Prepare the training data\n",
    "        Y_train_df = train_data.reset_index().rename(columns={'Date': 'ds', 'Close': 'y'})\n",
    "        # Y_train_df['unique_id'] = 'SBIN'\n",
    "        Y_train_df['unique_id'] = 'NSEI'\n",
    "\n",
    "        # Initialize and train the iTransformer model\n",
    "        model = iTransformer(\n",
    "            h=7,  # Output horizon (prediction length)\n",
    "            input_size=60,  # Input window size\n",
    "            n_series=1,  # Number of time series (SBIN in this case)\n",
    "            hidden_size=512,  # Adjusted for iTransformer\n",
    "            n_heads=8,\n",
    "            e_layers=2,\n",
    "            d_layers=1,\n",
    "            d_ff=2048,\n",
    "            factor=1,\n",
    "            dropout=0.1,\n",
    "            use_norm=True,\n",
    "            loss=MAE(),\n",
    "            learning_rate=0.001,\n",
    "            max_steps=500,  # Adjusted as per your code\n",
    "            **{'callbacks': [self.save_loss_callback]}  # Pass the callback directly here\n",
    "        )\n",
    "\n",
    "        # NeuralForecast object to handle model training\n",
    "        nf = NeuralForecast(models=[model], freq='B')\n",
    "        nf.fit(df=Y_train_df)\n",
    "\n",
    "        # Generate future dataframe automatically\n",
    "        futr_df = nf.make_future_dataframe()\n",
    "\n",
    "        # Generate predictions\n",
    "        forecasts = nf.predict(futr_df=futr_df)\n",
    "        \n",
    "        pred_values = self.scaler_close.inverse_transform(forecasts[['iTransformer']].values)\n",
    "        dates = futr_df['ds']\n",
    "\n",
    "        return dates, pred_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training window 1: from 2008-05-12 00:00:00 to 2022-06-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:12<00:00,  0.08it/s, v_num=320, train_loss_step=0.0175]Epoch 0: Train Loss = 0.01750914752483368\n",
      "Epoch 1: 100%|██████████| 1/1 [00:01<00:00,  0.58it/s, v_num=320, train_loss_step=0.0337, train_loss_epoch=0.0175]Epoch 1: Train Loss = 0.033705003559589386\n",
      "Epoch 2: 100%|██████████| 1/1 [00:01<00:00,  0.69it/s, v_num=320, train_loss_step=0.0267, train_loss_epoch=0.0337]Epoch 2: Train Loss = 0.026653196662664413\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=320, train_loss_step=0.0204, train_loss_epoch=0.0267]Epoch 3: Train Loss = 0.020416244864463806\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=320, train_loss_step=0.0176, train_loss_epoch=0.0204]Epoch 4: Train Loss = 0.017643941566348076\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=320, train_loss_step=0.0164, train_loss_epoch=0.0176]Epoch 5: Train Loss = 0.01644403487443924\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=320, train_loss_step=0.0165, train_loss_epoch=0.0164]Epoch 6: Train Loss = 0.016536150127649307\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=320, train_loss_step=0.0146, train_loss_epoch=0.0165]Epoch 7: Train Loss = 0.014637683518230915\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=320, train_loss_step=0.0128, train_loss_epoch=0.0146]Epoch 8: Train Loss = 0.012758816592395306\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=320, train_loss_step=0.0134, train_loss_epoch=0.0128]Epoch 9: Train Loss = 0.013372974470257759\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=320, train_loss_step=0.013, train_loss_epoch=0.0134] Epoch 10: Train Loss = 0.013049698434770107\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=320, train_loss_step=0.0196, train_loss_epoch=0.013]Epoch 11: Train Loss = 0.019617095589637756\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=320, train_loss_step=0.0151, train_loss_epoch=0.0196]Epoch 12: Train Loss = 0.01507483422756195\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.0151]Epoch 13: Train Loss = 0.012743143364787102\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=320, train_loss_step=0.0141, train_loss_epoch=0.0127]Epoch 14: Train Loss = 0.014128053560853004\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=320, train_loss_step=0.0125, train_loss_epoch=0.0141]Epoch 15: Train Loss = 0.012507242150604725\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=320, train_loss_step=0.0135, train_loss_epoch=0.0125]Epoch 16: Train Loss = 0.01347860973328352\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=320, train_loss_step=0.0138, train_loss_epoch=0.0135]Epoch 17: Train Loss = 0.013844413682818413\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=320, train_loss_step=0.0135, train_loss_epoch=0.0138]Epoch 18: Train Loss = 0.013464560732245445\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=320, train_loss_step=0.0138, train_loss_epoch=0.0135]Epoch 19: Train Loss = 0.01378797460347414\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=320, train_loss_step=0.0135, train_loss_epoch=0.0138]Epoch 20: Train Loss = 0.013517351821064949\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=320, train_loss_step=0.0149, train_loss_epoch=0.0135]Epoch 21: Train Loss = 0.014908703044056892\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=320, train_loss_step=0.0199, train_loss_epoch=0.0149]Epoch 22: Train Loss = 0.019890712574124336\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=320, train_loss_step=0.0116, train_loss_epoch=0.0199]Epoch 23: Train Loss = 0.011562068946659565\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s, v_num=320, train_loss_step=0.0198, train_loss_epoch=0.0116]Epoch 24: Train Loss = 0.0197860449552536\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=320, train_loss_step=0.0215, train_loss_epoch=0.0198]Epoch 25: Train Loss = 0.021512862294912338\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=320, train_loss_step=0.0135, train_loss_epoch=0.0215]Epoch 26: Train Loss = 0.013534597121179104\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=320, train_loss_step=0.0151, train_loss_epoch=0.0135]Epoch 27: Train Loss = 0.015103025361895561\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=320, train_loss_step=0.0123, train_loss_epoch=0.0151]Epoch 28: Train Loss = 0.012320652604103088\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=320, train_loss_step=0.0211, train_loss_epoch=0.0123]Epoch 29: Train Loss = 0.021071141585707664\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=320, train_loss_step=0.014, train_loss_epoch=0.0211] Epoch 30: Train Loss = 0.014025172218680382\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=320, train_loss_step=0.0126, train_loss_epoch=0.014]Epoch 31: Train Loss = 0.012592286802828312\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=320, train_loss_step=0.0101, train_loss_epoch=0.0126]Epoch 32: Train Loss = 0.010094366036355495\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=320, train_loss_step=0.0128, train_loss_epoch=0.0101]Epoch 33: Train Loss = 0.012757331132888794\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=320, train_loss_step=0.0112, train_loss_epoch=0.0128]Epoch 34: Train Loss = 0.011229218915104866\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=320, train_loss_step=0.010, train_loss_epoch=0.0112] Epoch 35: Train Loss = 0.010014571249485016\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=320, train_loss_step=0.0139, train_loss_epoch=0.010]Epoch 36: Train Loss = 0.01393215823918581\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=320, train_loss_step=0.0142, train_loss_epoch=0.0139]Epoch 37: Train Loss = 0.014247982762753963\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.0142] Epoch 38: Train Loss = 0.011986097320914268\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=320, train_loss_step=0.00954, train_loss_epoch=0.012]Epoch 39: Train Loss = 0.009541640058159828\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=320, train_loss_step=0.0129, train_loss_epoch=0.00954] Epoch 40: Train Loss = 0.012923740781843662\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=320, train_loss_step=0.0149, train_loss_epoch=0.0129] Epoch 41: Train Loss = 0.01485454011708498\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=320, train_loss_step=0.0156, train_loss_epoch=0.0149]Epoch 42: Train Loss = 0.015559383668005466\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=320, train_loss_step=0.00967, train_loss_epoch=0.0156]Epoch 43: Train Loss = 0.009667749516665936\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=320, train_loss_step=0.0146, train_loss_epoch=0.00967] Epoch 44: Train Loss = 0.014556537382304668\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=320, train_loss_step=0.0166, train_loss_epoch=0.0146] Epoch 45: Train Loss = 0.01658037304878235\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=320, train_loss_step=0.0109, train_loss_epoch=0.0166]Epoch 46: Train Loss = 0.010898083448410034\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=320, train_loss_step=0.0137, train_loss_epoch=0.0109]Epoch 47: Train Loss = 0.01366390846669674\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.0137]Epoch 48: Train Loss = 0.011502782814204693\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=320, train_loss_step=0.013, train_loss_epoch=0.0115] Epoch 49: Train Loss = 0.01302636694163084\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=320, train_loss_step=0.0125, train_loss_epoch=0.013]Epoch 50: Train Loss = 0.012459158897399902\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=320, train_loss_step=0.0132, train_loss_epoch=0.0125]Epoch 51: Train Loss = 0.013169693760573864\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.0132]Epoch 52: Train Loss = 0.012672982178628445\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=320, train_loss_step=0.0121, train_loss_epoch=0.0127]Epoch 53: Train Loss = 0.012113104574382305\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=320, train_loss_step=0.0117, train_loss_epoch=0.0121]Epoch 54: Train Loss = 0.011663996614515781\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.0117] Epoch 55: Train Loss = 0.01204464491456747\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=320, train_loss_step=0.0111, train_loss_epoch=0.012]Epoch 56: Train Loss = 0.011133885942399502\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=320, train_loss_step=0.0157, train_loss_epoch=0.0111]Epoch 57: Train Loss = 0.015732888132333755\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=320, train_loss_step=0.0145, train_loss_epoch=0.0157]Epoch 58: Train Loss = 0.014497469179332256\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=320, train_loss_step=0.0149, train_loss_epoch=0.0145]Epoch 59: Train Loss = 0.014904431067407131\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.0149]Epoch 60: Train Loss = 0.012667219154536724\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.0127]Epoch 61: Train Loss = 0.012651941739022732\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=320, train_loss_step=0.0138, train_loss_epoch=0.0127]Epoch 62: Train Loss = 0.01381741464138031\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=320, train_loss_step=0.0134, train_loss_epoch=0.0138]Epoch 63: Train Loss = 0.013383889570832253\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s, v_num=320, train_loss_step=0.0144, train_loss_epoch=0.0134]Epoch 64: Train Loss = 0.014436818659305573\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s, v_num=320, train_loss_step=0.0121, train_loss_epoch=0.0144]Epoch 65: Train Loss = 0.012057842686772346\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=320, train_loss_step=0.00961, train_loss_epoch=0.0121]Epoch 66: Train Loss = 0.009605084545910358\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=320, train_loss_step=0.00852, train_loss_epoch=0.00961]Epoch 67: Train Loss = 0.008521027863025665\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=320, train_loss_step=0.0119, train_loss_epoch=0.00852] Epoch 68: Train Loss = 0.011906652711331844\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.0119] Epoch 69: Train Loss = 0.010657456703484058\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=320, train_loss_step=0.0163, train_loss_epoch=0.0107]Epoch 70: Train Loss = 0.016321584582328796\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=320, train_loss_step=0.00844, train_loss_epoch=0.0163]Epoch 71: Train Loss = 0.008442084304988384\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s, v_num=320, train_loss_step=0.0116, train_loss_epoch=0.00844] Epoch 72: Train Loss = 0.011622095480561256\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=320, train_loss_step=0.0154, train_loss_epoch=0.0116] Epoch 73: Train Loss = 0.01539526879787445\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=320, train_loss_step=0.0113, train_loss_epoch=0.0154]Epoch 74: Train Loss = 0.01132128480821848\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=320, train_loss_step=0.017, train_loss_epoch=0.0113] Epoch 75: Train Loss = 0.017031770199537277\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=320, train_loss_step=0.0136, train_loss_epoch=0.017]Epoch 76: Train Loss = 0.013647493906319141\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=320, train_loss_step=0.0114, train_loss_epoch=0.0136]Epoch 77: Train Loss = 0.01140621118247509\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=320, train_loss_step=0.0137, train_loss_epoch=0.0114]Epoch 78: Train Loss = 0.013662074692547321\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=320, train_loss_step=0.0132, train_loss_epoch=0.0137]Epoch 79: Train Loss = 0.013195100240409374\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=320, train_loss_step=0.0141, train_loss_epoch=0.0132]Epoch 80: Train Loss = 0.014145225286483765\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s, v_num=320, train_loss_step=0.0192, train_loss_epoch=0.0141]Epoch 81: Train Loss = 0.019231736660003662\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=320, train_loss_step=0.0143, train_loss_epoch=0.0192]Epoch 82: Train Loss = 0.014336766675114632\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=320, train_loss_step=0.00981, train_loss_epoch=0.0143]Epoch 83: Train Loss = 0.00980908889323473\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=320, train_loss_step=0.0121, train_loss_epoch=0.00981] Epoch 84: Train Loss = 0.012097918428480625\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=320, train_loss_step=0.0146, train_loss_epoch=0.0121] Epoch 85: Train Loss = 0.014588975347578526\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=320, train_loss_step=0.013, train_loss_epoch=0.0146] Epoch 86: Train Loss = 0.012959952466189861\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=320, train_loss_step=0.0126, train_loss_epoch=0.013]Epoch 87: Train Loss = 0.012588356621563435\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=320, train_loss_step=0.0108, train_loss_epoch=0.0126]Epoch 88: Train Loss = 0.010817359201610088\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=320, train_loss_step=0.0104, train_loss_epoch=0.0108]Epoch 89: Train Loss = 0.010423100553452969\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=320, train_loss_step=0.0118, train_loss_epoch=0.0104]Epoch 90: Train Loss = 0.011814645491540432\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=320, train_loss_step=0.0172, train_loss_epoch=0.0118]Epoch 91: Train Loss = 0.01722228340804577\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=320, train_loss_step=0.0133, train_loss_epoch=0.0172]Epoch 92: Train Loss = 0.013266382738947868\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=320, train_loss_step=0.0196, train_loss_epoch=0.0133]Epoch 93: Train Loss = 0.019645841792225838\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=320, train_loss_step=0.0137, train_loss_epoch=0.0196]Epoch 94: Train Loss = 0.013691811822354794\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s, v_num=320, train_loss_step=0.0135, train_loss_epoch=0.0137]Epoch 95: Train Loss = 0.01353558897972107\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=320, train_loss_step=0.0131, train_loss_epoch=0.0135]Epoch 96: Train Loss = 0.013076039031147957\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.0131]Epoch 97: Train Loss = 0.011452649720013142\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=320, train_loss_step=0.0133, train_loss_epoch=0.0115]Epoch 98: Train Loss = 0.013254372403025627\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=320, train_loss_step=0.0106, train_loss_epoch=0.0133]Epoch 99: Train Loss = 0.010624655522406101\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=320, train_loss_step=0.0109, train_loss_epoch=0.0106]Epoch 100: Train Loss = 0.010887250304222107\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.0109]Epoch 101: Train Loss = 0.010715645737946033\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=320, train_loss_step=0.0149, train_loss_epoch=0.0107]Epoch 102: Train Loss = 0.014899726025760174\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=320, train_loss_step=0.0128, train_loss_epoch=0.0149]Epoch 103: Train Loss = 0.012758634053170681\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=320, train_loss_step=0.0148, train_loss_epoch=0.0128]Epoch 104: Train Loss = 0.014767755754292011\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.0148]Epoch 105: Train Loss = 0.012742097489535809\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=320, train_loss_step=0.0147, train_loss_epoch=0.0127]Epoch 106: Train Loss = 0.0146797401830554\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=320, train_loss_step=0.0103, train_loss_epoch=0.0147]Epoch 107: Train Loss = 0.010329477488994598\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=320, train_loss_step=0.013, train_loss_epoch=0.0103] Epoch 108: Train Loss = 0.01298962626606226\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.013]Epoch 109: Train Loss = 0.012701752595603466\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=320, train_loss_step=0.0125, train_loss_epoch=0.0127]Epoch 110: Train Loss = 0.012531003914773464\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=320, train_loss_step=0.0101, train_loss_epoch=0.0125]Epoch 111: Train Loss = 0.010054774582386017\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=320, train_loss_step=0.0119, train_loss_epoch=0.0101]Epoch 112: Train Loss = 0.011887403205037117\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.0119]Epoch 113: Train Loss = 0.011450318619608879\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=320, train_loss_step=0.0174, train_loss_epoch=0.0115]Epoch 114: Train Loss = 0.01735128089785576\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.0174] Epoch 115: Train Loss = 0.01196768693625927\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=320, train_loss_step=0.0124, train_loss_epoch=0.012]Epoch 116: Train Loss = 0.012423532083630562\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=320, train_loss_step=0.0126, train_loss_epoch=0.0124]Epoch 117: Train Loss = 0.012648748233914375\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=320, train_loss_step=0.0118, train_loss_epoch=0.0126]Epoch 118: Train Loss = 0.01184411533176899\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=320, train_loss_step=0.0131, train_loss_epoch=0.0118]Epoch 119: Train Loss = 0.013053764589130878\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=320, train_loss_step=0.0109, train_loss_epoch=0.0131]Epoch 120: Train Loss = 0.01092548482120037\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=320, train_loss_step=0.0101, train_loss_epoch=0.0109]Epoch 121: Train Loss = 0.010059155523777008\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=320, train_loss_step=0.0175, train_loss_epoch=0.0101]Epoch 122: Train Loss = 0.017524663358926773\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.0175] Epoch 123: Train Loss = 0.012031510472297668\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=320, train_loss_step=0.0116, train_loss_epoch=0.012]Epoch 124: Train Loss = 0.011556570418179035\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=320, train_loss_step=0.00868, train_loss_epoch=0.0116]Epoch 125: Train Loss = 0.008679882623255253\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=320, train_loss_step=0.0104, train_loss_epoch=0.00868] Epoch 126: Train Loss = 0.010395792312920094\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=320, train_loss_step=0.0131, train_loss_epoch=0.0104] Epoch 127: Train Loss = 0.01307294238358736\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=320, train_loss_step=0.0167, train_loss_epoch=0.0131]Epoch 128: Train Loss = 0.016650933772325516\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=320, train_loss_step=0.0142, train_loss_epoch=0.0167]Epoch 129: Train Loss = 0.014234627597033978\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=320, train_loss_step=0.0102, train_loss_epoch=0.0142]Epoch 130: Train Loss = 0.010229645296931267\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.0102] Epoch 131: Train Loss = 0.012006315402686596\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=320, train_loss_step=0.0138, train_loss_epoch=0.012]Epoch 132: Train Loss = 0.013835134916007519\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=320, train_loss_step=0.0135, train_loss_epoch=0.0138]Epoch 133: Train Loss = 0.013465890660881996\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=320, train_loss_step=0.0141, train_loss_epoch=0.0135]Epoch 134: Train Loss = 0.014134138822555542\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=320, train_loss_step=0.00928, train_loss_epoch=0.0141]Epoch 135: Train Loss = 0.009281769394874573\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=320, train_loss_step=0.0118, train_loss_epoch=0.00928] Epoch 136: Train Loss = 0.011792228557169437\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=320, train_loss_step=0.0143, train_loss_epoch=0.0118] Epoch 137: Train Loss = 0.014338175766170025\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=320, train_loss_step=0.0117, train_loss_epoch=0.0143]Epoch 138: Train Loss = 0.01169311162084341\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 10.22it/s, v_num=320, train_loss_step=0.0104, train_loss_epoch=0.0117]Epoch 139: Train Loss = 0.01042182557284832\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=320, train_loss_step=0.00906, train_loss_epoch=0.0104]Epoch 140: Train Loss = 0.009056804701685905\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=320, train_loss_step=0.0122, train_loss_epoch=0.00906] Epoch 141: Train Loss = 0.012191100046038628\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=320, train_loss_step=0.0121, train_loss_epoch=0.0122] Epoch 142: Train Loss = 0.012063364498317242\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.0121]Epoch 143: Train Loss = 0.010482022538781166\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=320, train_loss_step=0.0119, train_loss_epoch=0.0105]Epoch 144: Train Loss = 0.011860886588692665\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=320, train_loss_step=0.0121, train_loss_epoch=0.0119]Epoch 145: Train Loss = 0.012089831754565239\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=320, train_loss_step=0.00998, train_loss_epoch=0.0121]Epoch 146: Train Loss = 0.009980445727705956\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=320, train_loss_step=0.0102, train_loss_epoch=0.00998] Epoch 147: Train Loss = 0.010239253751933575\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=320, train_loss_step=0.0157, train_loss_epoch=0.0102] Epoch 148: Train Loss = 0.015731047838926315\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=320, train_loss_step=0.00932, train_loss_epoch=0.0157]Epoch 149: Train Loss = 0.009322783909738064\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.00932] Epoch 150: Train Loss = 0.012652404606342316\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.0127] Epoch 151: Train Loss = 0.010458199307322502\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=320, train_loss_step=0.0117, train_loss_epoch=0.0105]Epoch 152: Train Loss = 0.011655368842184544\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=320, train_loss_step=0.0156, train_loss_epoch=0.0117]Epoch 153: Train Loss = 0.015643153339624405\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=320, train_loss_step=0.00866, train_loss_epoch=0.0156]Epoch 154: Train Loss = 0.008660349063575268\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=320, train_loss_step=0.0128, train_loss_epoch=0.00866] Epoch 155: Train Loss = 0.012846559286117554\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=320, train_loss_step=0.00973, train_loss_epoch=0.0128]Epoch 156: Train Loss = 0.009730944409966469\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=320, train_loss_step=0.0129, train_loss_epoch=0.00973] Epoch 157: Train Loss = 0.012875772081315517\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=320, train_loss_step=0.0111, train_loss_epoch=0.0129] Epoch 158: Train Loss = 0.01111092884093523\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=320, train_loss_step=0.00975, train_loss_epoch=0.0111]Epoch 159: Train Loss = 0.00975186936557293\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.00975] Epoch 160: Train Loss = 0.01265434455126524\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=320, train_loss_step=0.0116, train_loss_epoch=0.0127] Epoch 161: Train Loss = 0.011563709005713463\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=320, train_loss_step=0.0141, train_loss_epoch=0.0116]Epoch 162: Train Loss = 0.01411763858050108\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=320, train_loss_step=0.00732, train_loss_epoch=0.0141]Epoch 163: Train Loss = 0.007324361242353916\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=320, train_loss_step=0.0094, train_loss_epoch=0.00732] Epoch 164: Train Loss = 0.009400011040270329\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=320, train_loss_step=0.0104, train_loss_epoch=0.0094] Epoch 165: Train Loss = 0.010367058217525482\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=320, train_loss_step=0.00962, train_loss_epoch=0.0104]Epoch 166: Train Loss = 0.009622232988476753\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=320, train_loss_step=0.00846, train_loss_epoch=0.00962]Epoch 167: Train Loss = 0.008464111015200615\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=320, train_loss_step=0.00905, train_loss_epoch=0.00846]Epoch 168: Train Loss = 0.009050203487277031\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.00905]  Epoch 169: Train Loss = 0.01198370661586523\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=320, train_loss_step=0.00891, train_loss_epoch=0.012]Epoch 170: Train Loss = 0.008906068280339241\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=320, train_loss_step=0.0116, train_loss_epoch=0.00891] Epoch 171: Train Loss = 0.011552968062460423\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s, v_num=320, train_loss_step=0.0113, train_loss_epoch=0.0116] Epoch 172: Train Loss = 0.011311216279864311\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=320, train_loss_step=0.0124, train_loss_epoch=0.0113]Epoch 173: Train Loss = 0.012379026971757412\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=320, train_loss_step=0.0118, train_loss_epoch=0.0124]Epoch 174: Train Loss = 0.01183105818927288\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=320, train_loss_step=0.0103, train_loss_epoch=0.0118]Epoch 175: Train Loss = 0.01033810991793871\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=320, train_loss_step=0.00936, train_loss_epoch=0.0103]Epoch 176: Train Loss = 0.009360513649880886\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=320, train_loss_step=0.0144, train_loss_epoch=0.00936] Epoch 177: Train Loss = 0.014437288045883179\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.0144] Epoch 178: Train Loss = 0.010736591182649136\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=320, train_loss_step=0.00968, train_loss_epoch=0.0107]Epoch 179: Train Loss = 0.009675667621195316\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=320, train_loss_step=0.00968, train_loss_epoch=0.00968]Epoch 180: Train Loss = 0.009677077643573284\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.00968] Epoch 181: Train Loss = 0.012725090608000755\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=320, train_loss_step=0.0103, train_loss_epoch=0.0127] Epoch 182: Train Loss = 0.010277577675879002\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.0103]Epoch 183: Train Loss = 0.01074723619967699\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=320, train_loss_step=0.00948, train_loss_epoch=0.0107]Epoch 184: Train Loss = 0.009479931555688381\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=320, train_loss_step=0.00849, train_loss_epoch=0.00948]Epoch 185: Train Loss = 0.008487326093018055\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.00849] Epoch 186: Train Loss = 0.011453892104327679\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s, v_num=320, train_loss_step=0.0102, train_loss_epoch=0.0115] Epoch 187: Train Loss = 0.01019380148500204\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=320, train_loss_step=0.0104, train_loss_epoch=0.0102]Epoch 188: Train Loss = 0.010396539233624935\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.0104]Epoch 189: Train Loss = 0.010457560420036316\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=320, train_loss_step=0.0144, train_loss_epoch=0.0105]Epoch 190: Train Loss = 0.014384132809937\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=320, train_loss_step=0.0112, train_loss_epoch=0.0144]Epoch 191: Train Loss = 0.0111888712272048\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=320, train_loss_step=0.00869, train_loss_epoch=0.0112]Epoch 192: Train Loss = 0.008686376735568047\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=320, train_loss_step=0.0111, train_loss_epoch=0.00869] Epoch 193: Train Loss = 0.011095562018454075\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.0111] Epoch 194: Train Loss = 0.010536333546042442\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=320, train_loss_step=0.00943, train_loss_epoch=0.0105]Epoch 195: Train Loss = 0.009430655278265476\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=320, train_loss_step=0.00867, train_loss_epoch=0.00943]Epoch 196: Train Loss = 0.00866837427020073\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=320, train_loss_step=0.00884, train_loss_epoch=0.00867]Epoch 197: Train Loss = 0.00883996207267046\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=320, train_loss_step=0.0104, train_loss_epoch=0.00884] Epoch 198: Train Loss = 0.010375631973147392\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=320, train_loss_step=0.00966, train_loss_epoch=0.0104]Epoch 199: Train Loss = 0.00965801440179348\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s, v_num=320, train_loss_step=0.0087, train_loss_epoch=0.00966] Epoch 200: Train Loss = 0.008699038065969944\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=320, train_loss_step=0.011, train_loss_epoch=0.0087]  Epoch 201: Train Loss = 0.01096979808062315\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=320, train_loss_step=0.00942, train_loss_epoch=0.011]Epoch 202: Train Loss = 0.00942334532737732\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=320, train_loss_step=0.013, train_loss_epoch=0.00942]  Epoch 203: Train Loss = 0.012969988398253918\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s, v_num=320, train_loss_step=0.00978, train_loss_epoch=0.013]Epoch 204: Train Loss = 0.009780846536159515\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=320, train_loss_step=0.0135, train_loss_epoch=0.00978] Epoch 205: Train Loss = 0.013545578345656395\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=320, train_loss_step=0.0123, train_loss_epoch=0.0135] Epoch 206: Train Loss = 0.01233804039657116\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=320, train_loss_step=0.00996, train_loss_epoch=0.0123]Epoch 207: Train Loss = 0.009955451823771\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=320, train_loss_step=0.0106, train_loss_epoch=0.00996] Epoch 208: Train Loss = 0.010611395351588726\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=320, train_loss_step=0.00934, train_loss_epoch=0.0106]Epoch 209: Train Loss = 0.009340046904981136\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=320, train_loss_step=0.00972, train_loss_epoch=0.00934]Epoch 210: Train Loss = 0.009723825380206108\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, v_num=320, train_loss_step=0.00764, train_loss_epoch=0.00972]Epoch 211: Train Loss = 0.007635787595063448\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=320, train_loss_step=0.0102, train_loss_epoch=0.00764] Epoch 212: Train Loss = 0.01023278571665287\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=320, train_loss_step=0.0108, train_loss_epoch=0.0102] Epoch 213: Train Loss = 0.010833529755473137\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=320, train_loss_step=0.0148, train_loss_epoch=0.0108]Epoch 214: Train Loss = 0.014769566245377064\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=320, train_loss_step=0.0079, train_loss_epoch=0.0148]Epoch 215: Train Loss = 0.007897725328803062\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=320, train_loss_step=0.0114, train_loss_epoch=0.0079]Epoch 216: Train Loss = 0.011445560492575169\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 10.36it/s, v_num=320, train_loss_step=0.0134, train_loss_epoch=0.0114]Epoch 217: Train Loss = 0.013354441151022911\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.0134] Epoch 218: Train Loss = 0.012031993828713894\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=320, train_loss_step=0.00815, train_loss_epoch=0.012]Epoch 219: Train Loss = 0.008150989189743996\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=320, train_loss_step=0.00938, train_loss_epoch=0.00815]Epoch 220: Train Loss = 0.009381729178130627\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.00938] Epoch 221: Train Loss = 0.01154849398881197\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=320, train_loss_step=0.00957, train_loss_epoch=0.0115]Epoch 222: Train Loss = 0.009565748274326324\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.00957] Epoch 223: Train Loss = 0.010745545849204063\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=320, train_loss_step=0.00705, train_loss_epoch=0.0107]Epoch 224: Train Loss = 0.007050551939755678\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.00705] Epoch 225: Train Loss = 0.010728495195508003\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=320, train_loss_step=0.00714, train_loss_epoch=0.0107]Epoch 226: Train Loss = 0.007136531639844179\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=320, train_loss_step=0.013, train_loss_epoch=0.00714]  Epoch 227: Train Loss = 0.01303276140242815\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 10.24it/s, v_num=320, train_loss_step=0.00885, train_loss_epoch=0.013]Epoch 228: Train Loss = 0.008849714882671833\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.00885] Epoch 229: Train Loss = 0.011547565460205078\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=320, train_loss_step=0.00947, train_loss_epoch=0.0115]Epoch 230: Train Loss = 0.009466583840548992\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=320, train_loss_step=0.0154, train_loss_epoch=0.00947] Epoch 231: Train Loss = 0.015385044738650322\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=320, train_loss_step=0.00876, train_loss_epoch=0.0154]Epoch 232: Train Loss = 0.008756270632147789\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=320, train_loss_step=0.0102, train_loss_epoch=0.00876] Epoch 233: Train Loss = 0.010161654092371464\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=320, train_loss_step=0.00981, train_loss_epoch=0.0102]Epoch 234: Train Loss = 0.009814162738621235\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=320, train_loss_step=0.00822, train_loss_epoch=0.00981]Epoch 235: Train Loss = 0.008223959244787693\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=320, train_loss_step=0.0109, train_loss_epoch=0.00822] Epoch 236: Train Loss = 0.010868889279663563\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=320, train_loss_step=0.0118, train_loss_epoch=0.0109] Epoch 237: Train Loss = 0.011751549318432808\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=320, train_loss_step=0.00909, train_loss_epoch=0.0118]Epoch 238: Train Loss = 0.009092767722904682\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=320, train_loss_step=0.0125, train_loss_epoch=0.00909] Epoch 239: Train Loss = 0.012484395876526833\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=320, train_loss_step=0.00977, train_loss_epoch=0.0125]Epoch 240: Train Loss = 0.009774998761713505\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.00977] Epoch 241: Train Loss = 0.010506277903914452\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=320, train_loss_step=0.00867, train_loss_epoch=0.0105]Epoch 242: Train Loss = 0.008669785223901272\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=320, train_loss_step=0.0096, train_loss_epoch=0.00867] Epoch 243: Train Loss = 0.009599274024367332\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=320, train_loss_step=0.0114, train_loss_epoch=0.0096] Epoch 244: Train Loss = 0.011360938660800457\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.0114]Epoch 245: Train Loss = 0.010729199275374413\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=320, train_loss_step=0.00758, train_loss_epoch=0.0107]Epoch 246: Train Loss = 0.007584615610539913\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=320, train_loss_step=0.0119, train_loss_epoch=0.00758] Epoch 247: Train Loss = 0.011920154094696045\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=320, train_loss_step=0.00934, train_loss_epoch=0.0119]Epoch 248: Train Loss = 0.009338701143860817\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=320, train_loss_step=0.0139, train_loss_epoch=0.00934] Epoch 249: Train Loss = 0.01390168722718954\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=320, train_loss_step=0.0114, train_loss_epoch=0.0139] Epoch 250: Train Loss = 0.011391079053282738\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=320, train_loss_step=0.0086, train_loss_epoch=0.0114]Epoch 251: Train Loss = 0.008595778606832027\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=320, train_loss_step=0.0087, train_loss_epoch=0.0086]Epoch 252: Train Loss = 0.00870364811271429\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=320, train_loss_step=0.00819, train_loss_epoch=0.0087]Epoch 253: Train Loss = 0.008190948516130447\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=320, train_loss_step=0.0117, train_loss_epoch=0.00819] Epoch 254: Train Loss = 0.011714041233062744\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=320, train_loss_step=0.0101, train_loss_epoch=0.0117] Epoch 255: Train Loss = 0.010051245801150799\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=320, train_loss_step=0.00905, train_loss_epoch=0.0101]Epoch 256: Train Loss = 0.009045247919857502\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=320, train_loss_step=0.0101, train_loss_epoch=0.00905] Epoch 257: Train Loss = 0.010058174841105938\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=320, train_loss_step=0.0156, train_loss_epoch=0.0101] Epoch 258: Train Loss = 0.015590657480061054\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=320, train_loss_step=0.00753, train_loss_epoch=0.0156]Epoch 259: Train Loss = 0.007529352325946093\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=320, train_loss_step=0.00977, train_loss_epoch=0.00753]Epoch 260: Train Loss = 0.009771576151251793\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.00977] Epoch 261: Train Loss = 0.01050227228552103\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=320, train_loss_step=0.0114, train_loss_epoch=0.0105] Epoch 262: Train Loss = 0.0113975303247571\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=320, train_loss_step=0.0104, train_loss_epoch=0.0114]Epoch 263: Train Loss = 0.010377961210906506\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=320, train_loss_step=0.00993, train_loss_epoch=0.0104]Epoch 264: Train Loss = 0.009931758046150208\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  9.60it/s, v_num=320, train_loss_step=0.00872, train_loss_epoch=0.00993]Epoch 265: Train Loss = 0.008718433789908886\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=320, train_loss_step=0.0101, train_loss_epoch=0.00872] Epoch 266: Train Loss = 0.010054784826934338\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=320, train_loss_step=0.010, train_loss_epoch=0.0101]  Epoch 267: Train Loss = 0.01001872681081295\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=320, train_loss_step=0.0138, train_loss_epoch=0.010]Epoch 268: Train Loss = 0.013809851370751858\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=320, train_loss_step=0.00825, train_loss_epoch=0.0138]Epoch 269: Train Loss = 0.008249685168266296\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=320, train_loss_step=0.00898, train_loss_epoch=0.00825]Epoch 270: Train Loss = 0.008984132669866085\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=320, train_loss_step=0.0123, train_loss_epoch=0.00898] Epoch 271: Train Loss = 0.012339426204562187\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=320, train_loss_step=0.0108, train_loss_epoch=0.0123] Epoch 272: Train Loss = 0.010762286372482777\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=320, train_loss_step=0.00981, train_loss_epoch=0.0108]Epoch 273: Train Loss = 0.009814362041652203\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=320, train_loss_step=0.00973, train_loss_epoch=0.00981]Epoch 274: Train Loss = 0.00972630362957716\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=320, train_loss_step=0.00845, train_loss_epoch=0.00973]Epoch 275: Train Loss = 0.008454912342131138\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.00845] Epoch 276: Train Loss = 0.011524786241352558\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=320, train_loss_step=0.00945, train_loss_epoch=0.0115]Epoch 277: Train Loss = 0.009448491036891937\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=320, train_loss_step=0.0104, train_loss_epoch=0.00945] Epoch 278: Train Loss = 0.010373438708484173\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=320, train_loss_step=0.0111, train_loss_epoch=0.0104] Epoch 279: Train Loss = 0.011148320510983467\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=320, train_loss_step=0.0136, train_loss_epoch=0.0111]Epoch 280: Train Loss = 0.013592587783932686\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=320, train_loss_step=0.00848, train_loss_epoch=0.0136]Epoch 281: Train Loss = 0.008484586142003536\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=320, train_loss_step=0.00939, train_loss_epoch=0.00848]Epoch 282: Train Loss = 0.009389965794980526\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=320, train_loss_step=0.00885, train_loss_epoch=0.00939]Epoch 283: Train Loss = 0.008846317417919636\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=320, train_loss_step=0.00876, train_loss_epoch=0.00885]Epoch 284: Train Loss = 0.008756180293858051\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=320, train_loss_step=0.0129, train_loss_epoch=0.00876] Epoch 285: Train Loss = 0.012946720235049725\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=320, train_loss_step=0.0122, train_loss_epoch=0.0129] Epoch 286: Train Loss = 0.012153916992247105\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=320, train_loss_step=0.0108, train_loss_epoch=0.0122]Epoch 287: Train Loss = 0.010777871124446392\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=320, train_loss_step=0.00944, train_loss_epoch=0.0108]Epoch 288: Train Loss = 0.009437493048608303\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=320, train_loss_step=0.0111, train_loss_epoch=0.00944] Epoch 289: Train Loss = 0.01105121523141861\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=320, train_loss_step=0.00793, train_loss_epoch=0.0111]Epoch 290: Train Loss = 0.007932795211672783\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.00793] Epoch 291: Train Loss = 0.010527280159294605\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.0105] Epoch 292: Train Loss = 0.010735588148236275\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=320, train_loss_step=0.00906, train_loss_epoch=0.0107]Epoch 293: Train Loss = 0.009063296020030975\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=320, train_loss_step=0.00869, train_loss_epoch=0.00906]Epoch 294: Train Loss = 0.008694043383002281\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=320, train_loss_step=0.00933, train_loss_epoch=0.00869]Epoch 295: Train Loss = 0.00932660885155201\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=320, train_loss_step=0.0101, train_loss_epoch=0.00933] Epoch 296: Train Loss = 0.010117466561496258\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=320, train_loss_step=0.00898, train_loss_epoch=0.0101]Epoch 297: Train Loss = 0.008978181518614292\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=320, train_loss_step=0.0114, train_loss_epoch=0.00898] Epoch 298: Train Loss = 0.011425101198256016\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=320, train_loss_step=0.0106, train_loss_epoch=0.0114] Epoch 299: Train Loss = 0.010579414665699005\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=320, train_loss_step=0.0125, train_loss_epoch=0.0106]Epoch 300: Train Loss = 0.012507474049925804\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=320, train_loss_step=0.0088, train_loss_epoch=0.0125]Epoch 301: Train Loss = 0.008798192255198956\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=320, train_loss_step=0.00841, train_loss_epoch=0.0088]Epoch 302: Train Loss = 0.008410989306867123\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=320, train_loss_step=0.00959, train_loss_epoch=0.00841]Epoch 303: Train Loss = 0.00958697684109211\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=320, train_loss_step=0.0148, train_loss_epoch=0.00959] Epoch 304: Train Loss = 0.01481980737298727\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=320, train_loss_step=0.0093, train_loss_epoch=0.0148] Epoch 305: Train Loss = 0.009303933009505272\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s, v_num=320, train_loss_step=0.0106, train_loss_epoch=0.0093]Epoch 306: Train Loss = 0.010626748204231262\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.0106]Epoch 307: Train Loss = 0.010525146499276161\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=320, train_loss_step=0.00884, train_loss_epoch=0.0105]Epoch 308: Train Loss = 0.00884019024670124\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, v_num=320, train_loss_step=0.00975, train_loss_epoch=0.00884]Epoch 309: Train Loss = 0.009746813215315342\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=320, train_loss_step=0.0109, train_loss_epoch=0.00975] Epoch 310: Train Loss = 0.010899594984948635\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.0109] Epoch 311: Train Loss = 0.012650671415030956\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=320, train_loss_step=0.0114, train_loss_epoch=0.0127]Epoch 312: Train Loss = 0.011437354609370232\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=320, train_loss_step=0.00945, train_loss_epoch=0.0114]Epoch 313: Train Loss = 0.009449941106140614\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=320, train_loss_step=0.0108, train_loss_epoch=0.00945] Epoch 314: Train Loss = 0.010764994658529758\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=320, train_loss_step=0.0111, train_loss_epoch=0.0108] Epoch 315: Train Loss = 0.011122732423245907\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=320, train_loss_step=0.00969, train_loss_epoch=0.0111]Epoch 316: Train Loss = 0.00968515407294035\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=320, train_loss_step=0.0118, train_loss_epoch=0.00969] Epoch 317: Train Loss = 0.011846714653074741\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=320, train_loss_step=0.0134, train_loss_epoch=0.0118] Epoch 318: Train Loss = 0.013396007940173149\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=320, train_loss_step=0.0101, train_loss_epoch=0.0134]Epoch 319: Train Loss = 0.010136164724826813\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.0101]Epoch 320: Train Loss = 0.010541943833231926\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=320, train_loss_step=0.0162, train_loss_epoch=0.0105]Epoch 321: Train Loss = 0.016192268580198288\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=320, train_loss_step=0.00985, train_loss_epoch=0.0162]Epoch 322: Train Loss = 0.009849390015006065\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=320, train_loss_step=0.00831, train_loss_epoch=0.00985]Epoch 323: Train Loss = 0.008311896584928036\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=320, train_loss_step=0.0112, train_loss_epoch=0.00831] Epoch 324: Train Loss = 0.011202876456081867\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=320, train_loss_step=0.0133, train_loss_epoch=0.0112] Epoch 325: Train Loss = 0.013339349068701267\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=320, train_loss_step=0.0122, train_loss_epoch=0.0133]Epoch 326: Train Loss = 0.01223021186888218\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=320, train_loss_step=0.00779, train_loss_epoch=0.0122]Epoch 327: Train Loss = 0.00778606254607439\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=320, train_loss_step=0.00801, train_loss_epoch=0.00779]Epoch 328: Train Loss = 0.008012104779481888\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.00801] Epoch 329: Train Loss = 0.011450919322669506\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=320, train_loss_step=0.0155, train_loss_epoch=0.0115] Epoch 330: Train Loss = 0.015494018793106079\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=320, train_loss_step=0.0128, train_loss_epoch=0.0155]Epoch 331: Train Loss = 0.012763945385813713\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=320, train_loss_step=0.0112, train_loss_epoch=0.0128]Epoch 332: Train Loss = 0.011176986619830132\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=320, train_loss_step=0.0149, train_loss_epoch=0.0112]Epoch 333: Train Loss = 0.014851095154881477\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=320, train_loss_step=0.010, train_loss_epoch=0.0149] Epoch 334: Train Loss = 0.01002174336463213\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.010] Epoch 335: Train Loss = 0.011996435932815075\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=320, train_loss_step=0.0119, train_loss_epoch=0.012]Epoch 336: Train Loss = 0.011949353851377964\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=320, train_loss_step=0.00908, train_loss_epoch=0.0119]Epoch 337: Train Loss = 0.009084156714379787\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s, v_num=320, train_loss_step=0.0121, train_loss_epoch=0.00908] Epoch 338: Train Loss = 0.012100234627723694\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=320, train_loss_step=0.0108, train_loss_epoch=0.0121] Epoch 339: Train Loss = 0.010811522603034973\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=320, train_loss_step=0.0116, train_loss_epoch=0.0108]Epoch 340: Train Loss = 0.01159061398357153\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=320, train_loss_step=0.010, train_loss_epoch=0.0116] Epoch 341: Train Loss = 0.010016175918281078\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=320, train_loss_step=0.0116, train_loss_epoch=0.010]Epoch 342: Train Loss = 0.011644910089671612\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.0116]Epoch 343: Train Loss = 0.010457956232130527\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=320, train_loss_step=0.0102, train_loss_epoch=0.0105]Epoch 344: Train Loss = 0.010220185853540897\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s, v_num=320, train_loss_step=0.0177, train_loss_epoch=0.0102]Epoch 345: Train Loss = 0.01774047687649727\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.0177]Epoch 346: Train Loss = 0.011512133292853832\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=320, train_loss_step=0.0128, train_loss_epoch=0.0115]Epoch 347: Train Loss = 0.012768587097525597\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=320, train_loss_step=0.0102, train_loss_epoch=0.0128]Epoch 348: Train Loss = 0.010164364241063595\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=320, train_loss_step=0.00871, train_loss_epoch=0.0102]Epoch 349: Train Loss = 0.008705281652510166\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=320, train_loss_step=0.0137, train_loss_epoch=0.00871] Epoch 350: Train Loss = 0.013740326277911663\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=320, train_loss_step=0.00993, train_loss_epoch=0.0137]Epoch 351: Train Loss = 0.009931160137057304\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=320, train_loss_step=0.011, train_loss_epoch=0.00993]  Epoch 352: Train Loss = 0.011027062311768532\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 10.52it/s, v_num=320, train_loss_step=0.0118, train_loss_epoch=0.011] Epoch 353: Train Loss = 0.011829471215605736\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=320, train_loss_step=0.013, train_loss_epoch=0.0118] Epoch 354: Train Loss = 0.012955667451024055\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=320, train_loss_step=0.00954, train_loss_epoch=0.013]Epoch 355: Train Loss = 0.00954472366720438\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=320, train_loss_step=0.008, train_loss_epoch=0.00954]  Epoch 356: Train Loss = 0.007995197549462318\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=320, train_loss_step=0.00844, train_loss_epoch=0.008]Epoch 357: Train Loss = 0.008440030738711357\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=320, train_loss_step=0.0135, train_loss_epoch=0.00844] Epoch 358: Train Loss = 0.013484997674822807\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=320, train_loss_step=0.00956, train_loss_epoch=0.0135]Epoch 359: Train Loss = 0.00955964159220457\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=320, train_loss_step=0.0147, train_loss_epoch=0.00956] Epoch 360: Train Loss = 0.014740543439984322\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=320, train_loss_step=0.00961, train_loss_epoch=0.0147]Epoch 361: Train Loss = 0.009611910209059715\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 10.95it/s, v_num=320, train_loss_step=0.0113, train_loss_epoch=0.00961] Epoch 362: Train Loss = 0.011327491141855717\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=320, train_loss_step=0.0119, train_loss_epoch=0.0113] Epoch 363: Train Loss = 0.01185634732246399\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s, v_num=320, train_loss_step=0.00928, train_loss_epoch=0.0119]Epoch 364: Train Loss = 0.009275509044528008\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=320, train_loss_step=0.0109, train_loss_epoch=0.00928] Epoch 365: Train Loss = 0.010871538892388344\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=320, train_loss_step=0.00823, train_loss_epoch=0.0109]Epoch 366: Train Loss = 0.00823200959712267\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=320, train_loss_step=0.00799, train_loss_epoch=0.00823]Epoch 367: Train Loss = 0.007990242913365364\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.00799]  Epoch 368: Train Loss = 0.011959775350987911\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=320, train_loss_step=0.00746, train_loss_epoch=0.012]Epoch 369: Train Loss = 0.007460418157279491\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.00746]  Epoch 370: Train Loss = 0.011980128474533558\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s, v_num=320, train_loss_step=0.00798, train_loss_epoch=0.012]Epoch 371: Train Loss = 0.007979365065693855\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=320, train_loss_step=0.00752, train_loss_epoch=0.00798]Epoch 372: Train Loss = 0.00751708447933197\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=320, train_loss_step=0.0099, train_loss_epoch=0.00752] Epoch 373: Train Loss = 0.009897291660308838\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=320, train_loss_step=0.010, train_loss_epoch=0.0099]  Epoch 374: Train Loss = 0.010022914968430996\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=320, train_loss_step=0.011, train_loss_epoch=0.010] Epoch 375: Train Loss = 0.011025398038327694\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=320, train_loss_step=0.0143, train_loss_epoch=0.011]Epoch 376: Train Loss = 0.01428095530718565\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=320, train_loss_step=0.0118, train_loss_epoch=0.0143]Epoch 377: Train Loss = 0.011778471991419792\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=320, train_loss_step=0.0114, train_loss_epoch=0.0118]Epoch 378: Train Loss = 0.011403138749301434\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=320, train_loss_step=0.00701, train_loss_epoch=0.0114]Epoch 379: Train Loss = 0.007005690131336451\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=320, train_loss_step=0.0113, train_loss_epoch=0.00701] Epoch 380: Train Loss = 0.01131663378328085\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=320, train_loss_step=0.00924, train_loss_epoch=0.0113]Epoch 381: Train Loss = 0.009237557649612427\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=320, train_loss_step=0.0113, train_loss_epoch=0.00924] Epoch 382: Train Loss = 0.0112669812515378\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=320, train_loss_step=0.011, train_loss_epoch=0.0113]  Epoch 383: Train Loss = 0.011026466265320778\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=320, train_loss_step=0.00943, train_loss_epoch=0.011]Epoch 384: Train Loss = 0.00943062361329794\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=320, train_loss_step=0.0116, train_loss_epoch=0.00943] Epoch 385: Train Loss = 0.01160829421132803\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=320, train_loss_step=0.00995, train_loss_epoch=0.0116]Epoch 386: Train Loss = 0.009953451342880726\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=320, train_loss_step=0.0097, train_loss_epoch=0.00995] Epoch 387: Train Loss = 0.009701193310320377\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=320, train_loss_step=0.00875, train_loss_epoch=0.0097]Epoch 388: Train Loss = 0.008750573731958866\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=320, train_loss_step=0.00902, train_loss_epoch=0.00875]Epoch 389: Train Loss = 0.009022529236972332\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=320, train_loss_step=0.00973, train_loss_epoch=0.00902]Epoch 390: Train Loss = 0.009732193313539028\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=320, train_loss_step=0.00895, train_loss_epoch=0.00973]Epoch 391: Train Loss = 0.008952975273132324\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=320, train_loss_step=0.00793, train_loss_epoch=0.00895]Epoch 392: Train Loss = 0.0079345116391778\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=320, train_loss_step=0.00859, train_loss_epoch=0.00793]Epoch 393: Train Loss = 0.008590662851929665\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=320, train_loss_step=0.0094, train_loss_epoch=0.00859] Epoch 394: Train Loss = 0.009398111142218113\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=320, train_loss_step=0.0091, train_loss_epoch=0.0094] Epoch 395: Train Loss = 0.009098955430090427\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=320, train_loss_step=0.00954, train_loss_epoch=0.0091]Epoch 396: Train Loss = 0.00954353529959917\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=320, train_loss_step=0.00985, train_loss_epoch=0.00954]Epoch 397: Train Loss = 0.009853423573076725\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=320, train_loss_step=0.00965, train_loss_epoch=0.00985]Epoch 398: Train Loss = 0.009654187597334385\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=320, train_loss_step=0.0095, train_loss_epoch=0.00965] Epoch 399: Train Loss = 0.009504454210400581\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=320, train_loss_step=0.00866, train_loss_epoch=0.0095]Epoch 400: Train Loss = 0.008656312711536884\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=320, train_loss_step=0.00906, train_loss_epoch=0.00866]Epoch 401: Train Loss = 0.009057342074811459\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=320, train_loss_step=0.00725, train_loss_epoch=0.00906]Epoch 402: Train Loss = 0.007254436612129211\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=320, train_loss_step=0.00946, train_loss_epoch=0.00725]Epoch 403: Train Loss = 0.009455704130232334\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.00946] Epoch 404: Train Loss = 0.010516315698623657\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=320, train_loss_step=0.00939, train_loss_epoch=0.0105]Epoch 405: Train Loss = 0.00939157698303461\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=320, train_loss_step=0.00946, train_loss_epoch=0.00939]Epoch 406: Train Loss = 0.009461560286581516\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=320, train_loss_step=0.00906, train_loss_epoch=0.00946]Epoch 407: Train Loss = 0.009061271324753761\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=320, train_loss_step=0.0117, train_loss_epoch=0.00906] Epoch 408: Train Loss = 0.011720784939825535\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=320, train_loss_step=0.0088, train_loss_epoch=0.0117] Epoch 409: Train Loss = 0.008800478652119637\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=320, train_loss_step=0.00932, train_loss_epoch=0.0088]Epoch 410: Train Loss = 0.009321705438196659\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=320, train_loss_step=0.00925, train_loss_epoch=0.00932]Epoch 411: Train Loss = 0.009246121160686016\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=320, train_loss_step=0.0082, train_loss_epoch=0.00925] Epoch 412: Train Loss = 0.008196022361516953\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=320, train_loss_step=0.00968, train_loss_epoch=0.0082]Epoch 413: Train Loss = 0.009676522575318813\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=320, train_loss_step=0.011, train_loss_epoch=0.00968]  Epoch 414: Train Loss = 0.01098173949867487\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=320, train_loss_step=0.011, train_loss_epoch=0.011]  Epoch 415: Train Loss = 0.010951252654194832\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=320, train_loss_step=0.00987, train_loss_epoch=0.011]Epoch 416: Train Loss = 0.0098686208948493\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=320, train_loss_step=0.00933, train_loss_epoch=0.00987]Epoch 417: Train Loss = 0.009328185580670834\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=320, train_loss_step=0.0109, train_loss_epoch=0.00933] Epoch 418: Train Loss = 0.01092553324997425\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=320, train_loss_step=0.0127, train_loss_epoch=0.0109] Epoch 419: Train Loss = 0.01266499888151884\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=320, train_loss_step=0.00898, train_loss_epoch=0.0127]Epoch 420: Train Loss = 0.008980177342891693\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=320, train_loss_step=0.00991, train_loss_epoch=0.00898]Epoch 421: Train Loss = 0.009910507127642632\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=320, train_loss_step=0.00837, train_loss_epoch=0.00991]Epoch 422: Train Loss = 0.008374427445232868\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=320, train_loss_step=0.0101, train_loss_epoch=0.00837] Epoch 423: Train Loss = 0.010069014504551888\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=320, train_loss_step=0.00965, train_loss_epoch=0.0101]Epoch 424: Train Loss = 0.009650918655097485\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=320, train_loss_step=0.0112, train_loss_epoch=0.00965] Epoch 425: Train Loss = 0.011182783171534538\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=320, train_loss_step=0.0117, train_loss_epoch=0.0112] Epoch 426: Train Loss = 0.011658781208097935\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=320, train_loss_step=0.00827, train_loss_epoch=0.0117]Epoch 427: Train Loss = 0.008269780315458775\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=320, train_loss_step=0.00841, train_loss_epoch=0.00827]Epoch 428: Train Loss = 0.008410271257162094\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=320, train_loss_step=0.00933, train_loss_epoch=0.00841]Epoch 429: Train Loss = 0.00932538602501154\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=320, train_loss_step=0.0119, train_loss_epoch=0.00933] Epoch 430: Train Loss = 0.011878354474902153\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.0119] Epoch 431: Train Loss = 0.010520135052502155\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=320, train_loss_step=0.0125, train_loss_epoch=0.0105]Epoch 432: Train Loss = 0.012520081363618374\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=320, train_loss_step=0.0124, train_loss_epoch=0.0125]Epoch 433: Train Loss = 0.012431612238287926\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=320, train_loss_step=0.0157, train_loss_epoch=0.0124]Epoch 434: Train Loss = 0.01566728763282299\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=320, train_loss_step=0.010, train_loss_epoch=0.0157] Epoch 435: Train Loss = 0.010038673877716064\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=320, train_loss_step=0.016, train_loss_epoch=0.010] Epoch 436: Train Loss = 0.015989812090992928\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=320, train_loss_step=0.0181, train_loss_epoch=0.016]Epoch 437: Train Loss = 0.018087981268763542\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=320, train_loss_step=0.011, train_loss_epoch=0.0181] Epoch 438: Train Loss = 0.010984303429722786\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=320, train_loss_step=0.0063, train_loss_epoch=0.011]Epoch 439: Train Loss = 0.006300716660916805\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=320, train_loss_step=0.0113, train_loss_epoch=0.0063]Epoch 440: Train Loss = 0.011323440819978714\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=320, train_loss_step=0.0158, train_loss_epoch=0.0113]Epoch 441: Train Loss = 0.015798630192875862\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=320, train_loss_step=0.0117, train_loss_epoch=0.0158]Epoch 442: Train Loss = 0.011705040000379086\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=320, train_loss_step=0.0155, train_loss_epoch=0.0117]Epoch 443: Train Loss = 0.015458905138075352\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=320, train_loss_step=0.0123, train_loss_epoch=0.0155]Epoch 444: Train Loss = 0.012348533608019352\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=320, train_loss_step=0.0126, train_loss_epoch=0.0123]Epoch 445: Train Loss = 0.012626984156668186\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=320, train_loss_step=0.0114, train_loss_epoch=0.0126]Epoch 446: Train Loss = 0.011447497643530369\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=320, train_loss_step=0.0122, train_loss_epoch=0.0114]Epoch 447: Train Loss = 0.012209981679916382\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 10.22it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.0122]Epoch 448: Train Loss = 0.011521647684276104\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=320, train_loss_step=0.0112, train_loss_epoch=0.0115]Epoch 449: Train Loss = 0.011171079240739346\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=320, train_loss_step=0.00908, train_loss_epoch=0.0112]Epoch 450: Train Loss = 0.00907873548567295\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 10.98it/s, v_num=320, train_loss_step=0.0108, train_loss_epoch=0.00908] Epoch 451: Train Loss = 0.01080156210809946\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.0108] Epoch 452: Train Loss = 0.01070342306047678\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=320, train_loss_step=0.0103, train_loss_epoch=0.0107]Epoch 453: Train Loss = 0.01034518238157034\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=320, train_loss_step=0.0157, train_loss_epoch=0.0103]Epoch 454: Train Loss = 0.015711495652794838\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=320, train_loss_step=0.0125, train_loss_epoch=0.0157]Epoch 455: Train Loss = 0.012539098039269447\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=320, train_loss_step=0.0143, train_loss_epoch=0.0125]Epoch 456: Train Loss = 0.01426553912460804\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.0143] Epoch 457: Train Loss = 0.012029205448925495\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=320, train_loss_step=0.00849, train_loss_epoch=0.012]Epoch 458: Train Loss = 0.008493447676301003\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=320, train_loss_step=0.00962, train_loss_epoch=0.00849]Epoch 459: Train Loss = 0.009622995741665363\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=320, train_loss_step=0.0117, train_loss_epoch=0.00962] Epoch 460: Train Loss = 0.011695990338921547\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.0117] Epoch 461: Train Loss = 0.01066016498953104\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=320, train_loss_step=0.00969, train_loss_epoch=0.0107]Epoch 462: Train Loss = 0.009694799780845642\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=320, train_loss_step=0.0139, train_loss_epoch=0.00969] Epoch 463: Train Loss = 0.01389622874557972\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=320, train_loss_step=0.0101, train_loss_epoch=0.0139] Epoch 464: Train Loss = 0.010127732530236244\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=320, train_loss_step=0.00953, train_loss_epoch=0.0101]Epoch 465: Train Loss = 0.009534882381558418\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=320, train_loss_step=0.00868, train_loss_epoch=0.00953]Epoch 466: Train Loss = 0.008676663041114807\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=320, train_loss_step=0.0133, train_loss_epoch=0.00868] Epoch 467: Train Loss = 0.013300767168402672\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=320, train_loss_step=0.0124, train_loss_epoch=0.0133] Epoch 468: Train Loss = 0.01244309451431036\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=320, train_loss_step=0.00846, train_loss_epoch=0.0124]Epoch 469: Train Loss = 0.008456386625766754\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=320, train_loss_step=0.0144, train_loss_epoch=0.00846] Epoch 470: Train Loss = 0.014443005435168743\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=320, train_loss_step=0.012, train_loss_epoch=0.0144]  Epoch 471: Train Loss = 0.012049352750182152\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=320, train_loss_step=0.0112, train_loss_epoch=0.012]Epoch 472: Train Loss = 0.011187284253537655\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=320, train_loss_step=0.00935, train_loss_epoch=0.0112]Epoch 473: Train Loss = 0.009353102184832096\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=320, train_loss_step=0.0105, train_loss_epoch=0.00935] Epoch 474: Train Loss = 0.01052525918930769\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=320, train_loss_step=0.0108, train_loss_epoch=0.0105] Epoch 475: Train Loss = 0.010842639021575451\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=320, train_loss_step=0.0104, train_loss_epoch=0.0108]Epoch 476: Train Loss = 0.010407903231680393\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=320, train_loss_step=0.0121, train_loss_epoch=0.0104]Epoch 477: Train Loss = 0.01208560261875391\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=320, train_loss_step=0.0114, train_loss_epoch=0.0121]Epoch 478: Train Loss = 0.011350647546350956\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=320, train_loss_step=0.0116, train_loss_epoch=0.0114]Epoch 479: Train Loss = 0.011556969955563545\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=320, train_loss_step=0.0108, train_loss_epoch=0.0116]Epoch 480: Train Loss = 0.010829849168658257\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=320, train_loss_step=0.00952, train_loss_epoch=0.0108]Epoch 481: Train Loss = 0.009517223574221134\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=320, train_loss_step=0.0124, train_loss_epoch=0.00952] Epoch 482: Train Loss = 0.012416086159646511\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s, v_num=320, train_loss_step=0.0139, train_loss_epoch=0.0124] Epoch 483: Train Loss = 0.013887877576053143\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=320, train_loss_step=0.00825, train_loss_epoch=0.0139]Epoch 484: Train Loss = 0.008252950385212898\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=320, train_loss_step=0.0129, train_loss_epoch=0.00825] Epoch 485: Train Loss = 0.01292659342288971\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=320, train_loss_step=0.0136, train_loss_epoch=0.0129] Epoch 486: Train Loss = 0.013643861748278141\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=320, train_loss_step=0.0119, train_loss_epoch=0.0136]Epoch 487: Train Loss = 0.01193965133279562\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=320, train_loss_step=0.0134, train_loss_epoch=0.0119]Epoch 488: Train Loss = 0.013393153436481953\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=320, train_loss_step=0.0131, train_loss_epoch=0.0134]Epoch 489: Train Loss = 0.013068759813904762\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=320, train_loss_step=0.00856, train_loss_epoch=0.0131]Epoch 490: Train Loss = 0.008559126406908035\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=320, train_loss_step=0.0103, train_loss_epoch=0.00856] Epoch 491: Train Loss = 0.01033704075962305\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=320, train_loss_step=0.0175, train_loss_epoch=0.0103] Epoch 492: Train Loss = 0.01752765104174614\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=320, train_loss_step=0.0115, train_loss_epoch=0.0175]Epoch 493: Train Loss = 0.0114919263869524\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=320, train_loss_step=0.0107, train_loss_epoch=0.0115]Epoch 494: Train Loss = 0.01069806981831789\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=320, train_loss_step=0.00806, train_loss_epoch=0.0107]Epoch 495: Train Loss = 0.008059457875788212\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=320, train_loss_step=0.00951, train_loss_epoch=0.00806]Epoch 496: Train Loss = 0.009513982571661472\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=320, train_loss_step=0.00852, train_loss_epoch=0.00951]Epoch 497: Train Loss = 0.00851814728230238\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=320, train_loss_step=0.0106, train_loss_epoch=0.00852] Epoch 498: Train Loss = 0.010570315644145012\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=320, train_loss_step=0.013, train_loss_epoch=0.0106]  Epoch 499: Train Loss = 0.01303758192807436\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=320, train_loss_step=0.013, train_loss_epoch=0.013] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=320, train_loss_step=0.013, train_loss_epoch=0.013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 2: from 2008-05-12 00:00:00 to 2022-07-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=326, train_loss_step=0.0194]Epoch 0: Train Loss = 0.019377347081899643\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=326, train_loss_step=0.0284, train_loss_epoch=0.0194]Epoch 1: Train Loss = 0.0284271202981472\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=326, train_loss_step=0.0296, train_loss_epoch=0.0284]Epoch 2: Train Loss = 0.029615014791488647\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=326, train_loss_step=0.0223, train_loss_epoch=0.0296]Epoch 3: Train Loss = 0.02229081280529499\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=326, train_loss_step=0.0215, train_loss_epoch=0.0223]Epoch 4: Train Loss = 0.021513154730200768\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=326, train_loss_step=0.0163, train_loss_epoch=0.0215]Epoch 5: Train Loss = 0.01628856547176838\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 10.55it/s, v_num=326, train_loss_step=0.0143, train_loss_epoch=0.0163]Epoch 6: Train Loss = 0.014288508333265781\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=326, train_loss_step=0.0141, train_loss_epoch=0.0143]Epoch 7: Train Loss = 0.014127272181212902\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=326, train_loss_step=0.0175, train_loss_epoch=0.0141]Epoch 8: Train Loss = 0.01752047799527645\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=326, train_loss_step=0.0126, train_loss_epoch=0.0175]Epoch 9: Train Loss = 0.012555503286421299\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=326, train_loss_step=0.0144, train_loss_epoch=0.0126]Epoch 10: Train Loss = 0.014354142360389233\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=326, train_loss_step=0.0161, train_loss_epoch=0.0144]Epoch 11: Train Loss = 0.016134021803736687\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=326, train_loss_step=0.0109, train_loss_epoch=0.0161]Epoch 12: Train Loss = 0.010922588407993317\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=326, train_loss_step=0.0123, train_loss_epoch=0.0109]Epoch 13: Train Loss = 0.012348965741693974\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=326, train_loss_step=0.0139, train_loss_epoch=0.0123]Epoch 14: Train Loss = 0.013877264223992825\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=326, train_loss_step=0.0123, train_loss_epoch=0.0139]Epoch 15: Train Loss = 0.012262805365025997\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=326, train_loss_step=0.0126, train_loss_epoch=0.0123]Epoch 16: Train Loss = 0.01259942539036274\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=326, train_loss_step=0.0118, train_loss_epoch=0.0126]Epoch 17: Train Loss = 0.011785098351538181\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=326, train_loss_step=0.0135, train_loss_epoch=0.0118]Epoch 18: Train Loss = 0.013473041355609894\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=326, train_loss_step=0.0109, train_loss_epoch=0.0135]Epoch 19: Train Loss = 0.010893567465245724\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=326, train_loss_step=0.00838, train_loss_epoch=0.0109]Epoch 20: Train Loss = 0.008379903621971607\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=326, train_loss_step=0.0144, train_loss_epoch=0.00838] Epoch 21: Train Loss = 0.01435170229524374\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=326, train_loss_step=0.0151, train_loss_epoch=0.0144] Epoch 22: Train Loss = 0.015114806592464447\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 10.49it/s, v_num=326, train_loss_step=0.0117, train_loss_epoch=0.0151]Epoch 23: Train Loss = 0.011718790046870708\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=326, train_loss_step=0.0144, train_loss_epoch=0.0117]Epoch 24: Train Loss = 0.014429152943193913\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=326, train_loss_step=0.0106, train_loss_epoch=0.0144]Epoch 25: Train Loss = 0.010557879693806171\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=326, train_loss_step=0.014, train_loss_epoch=0.0106] Epoch 26: Train Loss = 0.014032198116183281\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=326, train_loss_step=0.0105, train_loss_epoch=0.014]Epoch 27: Train Loss = 0.01045479066669941\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s, v_num=326, train_loss_step=0.0149, train_loss_epoch=0.0105]Epoch 28: Train Loss = 0.01485188864171505\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=326, train_loss_step=0.00999, train_loss_epoch=0.0149]Epoch 29: Train Loss = 0.00998919177800417\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=326, train_loss_step=0.00926, train_loss_epoch=0.00999]Epoch 30: Train Loss = 0.009262321516871452\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=326, train_loss_step=0.0122, train_loss_epoch=0.00926] Epoch 31: Train Loss = 0.012237053364515305\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.0122] Epoch 32: Train Loss = 0.01067894883453846\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=326, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 33: Train Loss = 0.011588729918003082\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=326, train_loss_step=0.00855, train_loss_epoch=0.0116]Epoch 34: Train Loss = 0.008549022488296032\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=326, train_loss_step=0.00906, train_loss_epoch=0.00855]Epoch 35: Train Loss = 0.00905864592641592\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=326, train_loss_step=0.0144, train_loss_epoch=0.00906] Epoch 36: Train Loss = 0.014447174966335297\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=326, train_loss_step=0.00975, train_loss_epoch=0.0144]Epoch 37: Train Loss = 0.009751451201736927\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=326, train_loss_step=0.0146, train_loss_epoch=0.00975] Epoch 38: Train Loss = 0.01463132444769144\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=326, train_loss_step=0.0115, train_loss_epoch=0.0146] Epoch 39: Train Loss = 0.011512734927237034\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.0115]Epoch 40: Train Loss = 0.010714178904891014\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=326, train_loss_step=0.0134, train_loss_epoch=0.0107]Epoch 41: Train Loss = 0.013413160108029842\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=326, train_loss_step=0.00921, train_loss_epoch=0.0134]Epoch 42: Train Loss = 0.009214222431182861\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=326, train_loss_step=0.0155, train_loss_epoch=0.00921] Epoch 43: Train Loss = 0.015497715212404728\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=326, train_loss_step=0.0133, train_loss_epoch=0.0155] Epoch 44: Train Loss = 0.013308435678482056\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=326, train_loss_step=0.00884, train_loss_epoch=0.0133]Epoch 45: Train Loss = 0.008842496201395988\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=326, train_loss_step=0.013, train_loss_epoch=0.00884]  Epoch 46: Train Loss = 0.012998287566006184\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=326, train_loss_step=0.0122, train_loss_epoch=0.013] Epoch 47: Train Loss = 0.012215916998684406\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=326, train_loss_step=0.0122, train_loss_epoch=0.0122]Epoch 48: Train Loss = 0.012168741784989834\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=326, train_loss_step=0.0114, train_loss_epoch=0.0122]Epoch 49: Train Loss = 0.011370643973350525\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=326, train_loss_step=0.0136, train_loss_epoch=0.0114]Epoch 50: Train Loss = 0.013584560714662075\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.0136] Epoch 51: Train Loss = 0.011018014512956142\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=326, train_loss_step=0.00864, train_loss_epoch=0.011]Epoch 52: Train Loss = 0.008635654114186764\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.00864] Epoch 53: Train Loss = 0.010381083004176617\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=326, train_loss_step=0.0113, train_loss_epoch=0.0104] Epoch 54: Train Loss = 0.011328811757266521\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=326, train_loss_step=0.0118, train_loss_epoch=0.0113]Epoch 55: Train Loss = 0.011755927465856075\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=326, train_loss_step=0.0108, train_loss_epoch=0.0118]Epoch 56: Train Loss = 0.010827933438122272\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=326, train_loss_step=0.0141, train_loss_epoch=0.0108]Epoch 57: Train Loss = 0.014149501919746399\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=326, train_loss_step=0.0116, train_loss_epoch=0.0141]Epoch 58: Train Loss = 0.011622835882008076\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=326, train_loss_step=0.0142, train_loss_epoch=0.0116]Epoch 59: Train Loss = 0.014184609986841679\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=326, train_loss_step=0.0115, train_loss_epoch=0.0142]Epoch 60: Train Loss = 0.011451909318566322\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=326, train_loss_step=0.00957, train_loss_epoch=0.0115]Epoch 61: Train Loss = 0.009571345522999763\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=326, train_loss_step=0.0116, train_loss_epoch=0.00957] Epoch 62: Train Loss = 0.011616368778049946\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=326, train_loss_step=0.0116, train_loss_epoch=0.0116] Epoch 63: Train Loss = 0.011574880219995975\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=326, train_loss_step=0.0123, train_loss_epoch=0.0116]Epoch 64: Train Loss = 0.012260125018656254\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=326, train_loss_step=0.0109, train_loss_epoch=0.0123]Epoch 65: Train Loss = 0.010931369848549366\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.0109]Epoch 66: Train Loss = 0.010670811869204044\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=326, train_loss_step=0.0113, train_loss_epoch=0.0107]Epoch 67: Train Loss = 0.011251300573348999\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.0113]Epoch 68: Train Loss = 0.011128299869596958\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=326, train_loss_step=0.00897, train_loss_epoch=0.0111]Epoch 69: Train Loss = 0.008971557021141052\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=326, train_loss_step=0.00921, train_loss_epoch=0.00897]Epoch 70: Train Loss = 0.009205287322402\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=326, train_loss_step=0.00951, train_loss_epoch=0.00921]Epoch 71: Train Loss = 0.009506097994744778\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=326, train_loss_step=0.00947, train_loss_epoch=0.00951]Epoch 72: Train Loss = 0.009473493322730064\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=326, train_loss_step=0.00888, train_loss_epoch=0.00947]Epoch 73: Train Loss = 0.008884887211024761\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.00888] Epoch 74: Train Loss = 0.010420267470180988\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=326, train_loss_step=0.0139, train_loss_epoch=0.0104] Epoch 75: Train Loss = 0.0139006981626153\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=326, train_loss_step=0.012, train_loss_epoch=0.0139] Epoch 76: Train Loss = 0.0120425159111619\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=326, train_loss_step=0.00885, train_loss_epoch=0.012]Epoch 77: Train Loss = 0.008852439932525158\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=326, train_loss_step=0.0109, train_loss_epoch=0.00885] Epoch 78: Train Loss = 0.010940775275230408\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=326, train_loss_step=0.00875, train_loss_epoch=0.0109]Epoch 79: Train Loss = 0.008749674074351788\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=326, train_loss_step=0.00899, train_loss_epoch=0.00875]Epoch 80: Train Loss = 0.008992740884423256\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=326, train_loss_step=0.00953, train_loss_epoch=0.00899]Epoch 81: Train Loss = 0.00952735636383295\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=326, train_loss_step=0.00973, train_loss_epoch=0.00953]Epoch 82: Train Loss = 0.009734506718814373\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=326, train_loss_step=0.0085, train_loss_epoch=0.00973] Epoch 83: Train Loss = 0.008495870046317577\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=326, train_loss_step=0.0124, train_loss_epoch=0.0085] Epoch 84: Train Loss = 0.012353569269180298\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.0124]Epoch 85: Train Loss = 0.01108462642878294\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=326, train_loss_step=0.00881, train_loss_epoch=0.0111]Epoch 86: Train Loss = 0.008809126913547516\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=326, train_loss_step=0.00957, train_loss_epoch=0.00881]Epoch 87: Train Loss = 0.009565078653395176\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=326, train_loss_step=0.0118, train_loss_epoch=0.00957] Epoch 88: Train Loss = 0.0118303457275033\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.0118] Epoch 89: Train Loss = 0.01068636029958725\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=326, train_loss_step=0.013, train_loss_epoch=0.0107] Epoch 90: Train Loss = 0.012975811958312988\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=326, train_loss_step=0.0115, train_loss_epoch=0.013]Epoch 91: Train Loss = 0.01146363653242588\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=326, train_loss_step=0.00923, train_loss_epoch=0.0115]Epoch 92: Train Loss = 0.009228806011378765\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=326, train_loss_step=0.0114, train_loss_epoch=0.00923] Epoch 93: Train Loss = 0.011411731131374836\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.0114]  Epoch 94: Train Loss = 0.011023065075278282\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=326, train_loss_step=0.0105, train_loss_epoch=0.011]Epoch 95: Train Loss = 0.010468943044543266\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=326, train_loss_step=0.00958, train_loss_epoch=0.0105]Epoch 96: Train Loss = 0.009579475037753582\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s, v_num=326, train_loss_step=0.0142, train_loss_epoch=0.00958] Epoch 97: Train Loss = 0.014177687466144562\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=326, train_loss_step=0.0144, train_loss_epoch=0.0142] Epoch 98: Train Loss = 0.014440282247960567\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=326, train_loss_step=0.0132, train_loss_epoch=0.0144]Epoch 99: Train Loss = 0.013192949816584587\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.0132]Epoch 100: Train Loss = 0.011149512603878975\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.0111] Epoch 101: Train Loss = 0.010984664782881737\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=326, train_loss_step=0.00821, train_loss_epoch=0.011]Epoch 102: Train Loss = 0.008214570581912994\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=326, train_loss_step=0.00997, train_loss_epoch=0.00821]Epoch 103: Train Loss = 0.009972748346626759\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=326, train_loss_step=0.00954, train_loss_epoch=0.00997]Epoch 104: Train Loss = 0.00954283308237791\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.00954] Epoch 105: Train Loss = 0.010410715825855732\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=326, train_loss_step=0.00955, train_loss_epoch=0.0104]Epoch 106: Train Loss = 0.009545974433422089\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=326, train_loss_step=0.00811, train_loss_epoch=0.00955]Epoch 107: Train Loss = 0.008108698762953281\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=326, train_loss_step=0.00733, train_loss_epoch=0.00811]Epoch 108: Train Loss = 0.007333841640502214\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.00733]  Epoch 109: Train Loss = 0.011039002798497677\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=326, train_loss_step=0.0102, train_loss_epoch=0.011] Epoch 110: Train Loss = 0.010221824049949646\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s, v_num=326, train_loss_step=0.0102, train_loss_epoch=0.0102]Epoch 111: Train Loss = 0.010249623097479343\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=326, train_loss_step=0.0118, train_loss_epoch=0.0102]Epoch 112: Train Loss = 0.0117947394028306\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=326, train_loss_step=0.0113, train_loss_epoch=0.0118]Epoch 113: Train Loss = 0.011333754286170006\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=326, train_loss_step=0.0122, train_loss_epoch=0.0113]Epoch 114: Train Loss = 0.012242141179740429\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=326, train_loss_step=0.0119, train_loss_epoch=0.0122]Epoch 115: Train Loss = 0.011889330111443996\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=326, train_loss_step=0.00975, train_loss_epoch=0.0119]Epoch 116: Train Loss = 0.009747504256665707\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=326, train_loss_step=0.00847, train_loss_epoch=0.00975]Epoch 117: Train Loss = 0.008471177890896797\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=326, train_loss_step=0.00751, train_loss_epoch=0.00847]Epoch 118: Train Loss = 0.007511742413043976\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=326, train_loss_step=0.0164, train_loss_epoch=0.00751] Epoch 119: Train Loss = 0.016403060406446457\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=326, train_loss_step=0.0098, train_loss_epoch=0.0164] Epoch 120: Train Loss = 0.009804194793105125\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 10.08it/s, v_num=326, train_loss_step=0.010, train_loss_epoch=0.0098] Epoch 121: Train Loss = 0.010005704127252102\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.010] Epoch 122: Train Loss = 0.010996239259839058\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=326, train_loss_step=0.00893, train_loss_epoch=0.011]Epoch 123: Train Loss = 0.008931035175919533\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=326, train_loss_step=0.00903, train_loss_epoch=0.00893]Epoch 124: Train Loss = 0.009032422676682472\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=326, train_loss_step=0.0102, train_loss_epoch=0.00903] Epoch 125: Train Loss = 0.010203280486166477\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=326, train_loss_step=0.0154, train_loss_epoch=0.0102] Epoch 126: Train Loss = 0.015358041040599346\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=326, train_loss_step=0.00984, train_loss_epoch=0.0154]Epoch 127: Train Loss = 0.009844817221164703\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.00984] Epoch 128: Train Loss = 0.011110961437225342\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.0111] Epoch 129: Train Loss = 0.010735884308815002\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=326, train_loss_step=0.00954, train_loss_epoch=0.0107]Epoch 130: Train Loss = 0.00954348687082529\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=326, train_loss_step=0.00924, train_loss_epoch=0.00954]Epoch 131: Train Loss = 0.009238728322088718\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=326, train_loss_step=0.00955, train_loss_epoch=0.00924]Epoch 132: Train Loss = 0.009551857598125935\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=326, train_loss_step=0.0139, train_loss_epoch=0.00955] Epoch 133: Train Loss = 0.013914359733462334\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=326, train_loss_step=0.00804, train_loss_epoch=0.0139]Epoch 134: Train Loss = 0.00804213248193264\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=326, train_loss_step=0.0112, train_loss_epoch=0.00804] Epoch 135: Train Loss = 0.011214619502425194\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=326, train_loss_step=0.0143, train_loss_epoch=0.0112] Epoch 136: Train Loss = 0.014290621504187584\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=326, train_loss_step=0.0121, train_loss_epoch=0.0143]Epoch 137: Train Loss = 0.01207065861672163\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=326, train_loss_step=0.0109, train_loss_epoch=0.0121]Epoch 138: Train Loss = 0.010852138511836529\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.0109]Epoch 139: Train Loss = 0.011136687360703945\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=326, train_loss_step=0.0141, train_loss_epoch=0.0111]Epoch 140: Train Loss = 0.014091375283896923\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=326, train_loss_step=0.0122, train_loss_epoch=0.0141]Epoch 141: Train Loss = 0.012174149043858051\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=326, train_loss_step=0.0119, train_loss_epoch=0.0122]Epoch 142: Train Loss = 0.011880338191986084\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=326, train_loss_step=0.00958, train_loss_epoch=0.0119]Epoch 143: Train Loss = 0.009577905759215355\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=326, train_loss_step=0.0109, train_loss_epoch=0.00958] Epoch 144: Train Loss = 0.010911671444773674\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=326, train_loss_step=0.0119, train_loss_epoch=0.0109] Epoch 145: Train Loss = 0.011929438449442387\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=326, train_loss_step=0.0143, train_loss_epoch=0.0119]Epoch 146: Train Loss = 0.014260615222156048\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=326, train_loss_step=0.0103, train_loss_epoch=0.0143]Epoch 147: Train Loss = 0.010281541384756565\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=326, train_loss_step=0.00826, train_loss_epoch=0.0103]Epoch 148: Train Loss = 0.00826193019747734\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=326, train_loss_step=0.0127, train_loss_epoch=0.00826] Epoch 149: Train Loss = 0.012695045210421085\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=326, train_loss_step=0.014, train_loss_epoch=0.0127]  Epoch 150: Train Loss = 0.014037324115633965\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.014]Epoch 151: Train Loss = 0.01007599476724863\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=326, train_loss_step=0.00756, train_loss_epoch=0.0101]Epoch 152: Train Loss = 0.007562574464827776\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, v_num=326, train_loss_step=0.0139, train_loss_epoch=0.00756] Epoch 153: Train Loss = 0.013935557566583157\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.0139] Epoch 154: Train Loss = 0.010408335365355015\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=326, train_loss_step=0.0112, train_loss_epoch=0.0104]Epoch 155: Train Loss = 0.011175021529197693\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=326, train_loss_step=0.0106, train_loss_epoch=0.0112]Epoch 156: Train Loss = 0.010589451529085636\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=326, train_loss_step=0.00859, train_loss_epoch=0.0106]Epoch 157: Train Loss = 0.008590185083448887\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s, v_num=326, train_loss_step=0.00995, train_loss_epoch=0.00859]Epoch 158: Train Loss = 0.009951763786375523\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=326, train_loss_step=0.0143, train_loss_epoch=0.00995] Epoch 159: Train Loss = 0.01431041769683361\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=326, train_loss_step=0.0171, train_loss_epoch=0.0143] Epoch 160: Train Loss = 0.017120128497481346\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=326, train_loss_step=0.0132, train_loss_epoch=0.0171]Epoch 161: Train Loss = 0.013192081823945045\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=326, train_loss_step=0.0144, train_loss_epoch=0.0132]Epoch 162: Train Loss = 0.01442524790763855\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=326, train_loss_step=0.00942, train_loss_epoch=0.0144]Epoch 163: Train Loss = 0.00942184217274189\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=326, train_loss_step=0.00915, train_loss_epoch=0.00942]Epoch 164: Train Loss = 0.009145818650722504\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=326, train_loss_step=0.00851, train_loss_epoch=0.00915]Epoch 165: Train Loss = 0.008509724400937557\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=326, train_loss_step=0.0135, train_loss_epoch=0.00851] Epoch 166: Train Loss = 0.013536862097680569\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=326, train_loss_step=0.013, train_loss_epoch=0.0135]  Epoch 167: Train Loss = 0.012952440418303013\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=326, train_loss_step=0.0116, train_loss_epoch=0.013]Epoch 168: Train Loss = 0.011582604609429836\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.0116]Epoch 169: Train Loss = 0.010719992220401764\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=326, train_loss_step=0.00995, train_loss_epoch=0.0107]Epoch 170: Train Loss = 0.0099478242918849\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s, v_num=326, train_loss_step=0.00996, train_loss_epoch=0.00995]Epoch 171: Train Loss = 0.009960104711353779\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 10.55it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.00996] Epoch 172: Train Loss = 0.010694305412471294\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=326, train_loss_step=0.012, train_loss_epoch=0.0107]  Epoch 173: Train Loss = 0.012011761777102947\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=326, train_loss_step=0.00891, train_loss_epoch=0.012]Epoch 174: Train Loss = 0.008912681601941586\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=326, train_loss_step=0.00981, train_loss_epoch=0.00891]Epoch 175: Train Loss = 0.009808381088078022\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=326, train_loss_step=0.00994, train_loss_epoch=0.00981]Epoch 176: Train Loss = 0.009944619610905647\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=326, train_loss_step=0.0142, train_loss_epoch=0.00994] Epoch 177: Train Loss = 0.014158523641526699\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=326, train_loss_step=0.0116, train_loss_epoch=0.0142] Epoch 178: Train Loss = 0.011598215438425541\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=326, train_loss_step=0.0124, train_loss_epoch=0.0116]Epoch 179: Train Loss = 0.01242601778358221\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=326, train_loss_step=0.0102, train_loss_epoch=0.0124]Epoch 180: Train Loss = 0.01020680833607912\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=326, train_loss_step=0.00947, train_loss_epoch=0.0102]Epoch 181: Train Loss = 0.009470207616686821\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.00947]  Epoch 182: Train Loss = 0.010964532382786274\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.011]  Epoch 183: Train Loss = 0.010980059392750263\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=326, train_loss_step=0.0094, train_loss_epoch=0.011]Epoch 184: Train Loss = 0.009397038258612156\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=326, train_loss_step=0.012, train_loss_epoch=0.0094] Epoch 185: Train Loss = 0.011975795030593872\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=326, train_loss_step=0.0125, train_loss_epoch=0.012]Epoch 186: Train Loss = 0.012465585954487324\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=326, train_loss_step=0.010, train_loss_epoch=0.0125] Epoch 187: Train Loss = 0.010042043402791023\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.010]Epoch 188: Train Loss = 0.010726241394877434\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=326, train_loss_step=0.0105, train_loss_epoch=0.0107]Epoch 189: Train Loss = 0.010520229116082191\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=326, train_loss_step=0.00956, train_loss_epoch=0.0105]Epoch 190: Train Loss = 0.00956088025122881\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=326, train_loss_step=0.00806, train_loss_epoch=0.00956]Epoch 191: Train Loss = 0.008059102110564709\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.00806] Epoch 192: Train Loss = 0.011076631024479866\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=326, train_loss_step=0.00936, train_loss_epoch=0.0111]Epoch 193: Train Loss = 0.009357322938740253\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=326, train_loss_step=0.00772, train_loss_epoch=0.00936]Epoch 194: Train Loss = 0.007722295820713043\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=326, train_loss_step=0.00792, train_loss_epoch=0.00772]Epoch 195: Train Loss = 0.00791544932872057\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=326, train_loss_step=0.00866, train_loss_epoch=0.00792]Epoch 196: Train Loss = 0.00865950621664524\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=326, train_loss_step=0.00694, train_loss_epoch=0.00866]Epoch 197: Train Loss = 0.006943574640899897\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=326, train_loss_step=0.0103, train_loss_epoch=0.00694] Epoch 198: Train Loss = 0.010339991189539433\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=326, train_loss_step=0.0128, train_loss_epoch=0.0103] Epoch 199: Train Loss = 0.012760140001773834\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=326, train_loss_step=0.00885, train_loss_epoch=0.0128]Epoch 200: Train Loss = 0.008847231976687908\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=326, train_loss_step=0.0143, train_loss_epoch=0.00885] Epoch 201: Train Loss = 0.014270939864218235\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=326, train_loss_step=0.0126, train_loss_epoch=0.0143] Epoch 202: Train Loss = 0.01263442076742649\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s, v_num=326, train_loss_step=0.00846, train_loss_epoch=0.0126]Epoch 203: Train Loss = 0.008456992916762829\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=326, train_loss_step=0.0099, train_loss_epoch=0.00846] Epoch 204: Train Loss = 0.009896017611026764\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=326, train_loss_step=0.0148, train_loss_epoch=0.0099] Epoch 205: Train Loss = 0.014781536534428596\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=326, train_loss_step=0.0132, train_loss_epoch=0.0148]Epoch 206: Train Loss = 0.01318180002272129\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=326, train_loss_step=0.00934, train_loss_epoch=0.0132]Epoch 207: Train Loss = 0.00933877658098936\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=326, train_loss_step=0.00951, train_loss_epoch=0.00934]Epoch 208: Train Loss = 0.009507770650088787\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=326, train_loss_step=0.014, train_loss_epoch=0.00951]  Epoch 209: Train Loss = 0.013996782712638378\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=326, train_loss_step=0.0127, train_loss_epoch=0.014] Epoch 210: Train Loss = 0.012696572579443455\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=326, train_loss_step=0.0103, train_loss_epoch=0.0127]Epoch 211: Train Loss = 0.010318572632968426\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=326, train_loss_step=0.00946, train_loss_epoch=0.0103]Epoch 212: Train Loss = 0.009458855725824833\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=326, train_loss_step=0.0109, train_loss_epoch=0.00946] Epoch 213: Train Loss = 0.010872340761125088\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.0109] Epoch 214: Train Loss = 0.010674160905182362\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=326, train_loss_step=0.00963, train_loss_epoch=0.0107]Epoch 215: Train Loss = 0.009632297791540623\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=326, train_loss_step=0.0114, train_loss_epoch=0.00963] Epoch 216: Train Loss = 0.011360685341060162\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=326, train_loss_step=0.0089, train_loss_epoch=0.0114] Epoch 217: Train Loss = 0.008897530846297741\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=326, train_loss_step=0.0108, train_loss_epoch=0.0089]Epoch 218: Train Loss = 0.010800455696880817\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=326, train_loss_step=0.00966, train_loss_epoch=0.0108]Epoch 219: Train Loss = 0.009664826095104218\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=326, train_loss_step=0.0109, train_loss_epoch=0.00966] Epoch 220: Train Loss = 0.010917283594608307\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=326, train_loss_step=0.0113, train_loss_epoch=0.0109] Epoch 221: Train Loss = 0.011342009529471397\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=326, train_loss_step=0.0108, train_loss_epoch=0.0113]Epoch 222: Train Loss = 0.010818098671734333\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=326, train_loss_step=0.0127, train_loss_epoch=0.0108]Epoch 223: Train Loss = 0.012730845250189304\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=326, train_loss_step=0.0102, train_loss_epoch=0.0127]Epoch 224: Train Loss = 0.010246719233691692\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=326, train_loss_step=0.0124, train_loss_epoch=0.0102]Epoch 225: Train Loss = 0.012422872707247734\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.0124] Epoch 226: Train Loss = 0.011048437096178532\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=326, train_loss_step=0.00963, train_loss_epoch=0.011]Epoch 227: Train Loss = 0.009631824679672718\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=326, train_loss_step=0.0135, train_loss_epoch=0.00963] Epoch 228: Train Loss = 0.01352863572537899\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=326, train_loss_step=0.0149, train_loss_epoch=0.0135] Epoch 229: Train Loss = 0.01486803125590086\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=326, train_loss_step=0.0137, train_loss_epoch=0.0149]Epoch 230: Train Loss = 0.013730781152844429\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=326, train_loss_step=0.00989, train_loss_epoch=0.0137]Epoch 231: Train Loss = 0.009890389628708363\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=326, train_loss_step=0.0118, train_loss_epoch=0.00989] Epoch 232: Train Loss = 0.011792355217039585\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.0118] Epoch 233: Train Loss = 0.011101104319095612\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=326, train_loss_step=0.00937, train_loss_epoch=0.0111]Epoch 234: Train Loss = 0.009370153769850731\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=326, train_loss_step=0.010, train_loss_epoch=0.00937]  Epoch 235: Train Loss = 0.010005386546254158\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=326, train_loss_step=0.00992, train_loss_epoch=0.010]Epoch 236: Train Loss = 0.009921940974891186\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=326, train_loss_step=0.00888, train_loss_epoch=0.00992]Epoch 237: Train Loss = 0.008882447145879269\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=326, train_loss_step=0.00798, train_loss_epoch=0.00888]Epoch 238: Train Loss = 0.00798006821423769\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.00798] Epoch 239: Train Loss = 0.011141691356897354\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=326, train_loss_step=0.00858, train_loss_epoch=0.0111]Epoch 240: Train Loss = 0.008579907938838005\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.00858] Epoch 241: Train Loss = 0.010083032771945\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=326, train_loss_step=0.00779, train_loss_epoch=0.0101]Epoch 242: Train Loss = 0.007789507042616606\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=326, train_loss_step=0.0114, train_loss_epoch=0.00779] Epoch 243: Train Loss = 0.011439927853643894\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=326, train_loss_step=0.0115, train_loss_epoch=0.0114] Epoch 244: Train Loss = 0.01151906419545412\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=326, train_loss_step=0.00845, train_loss_epoch=0.0115]Epoch 245: Train Loss = 0.008447548374533653\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=326, train_loss_step=0.0103, train_loss_epoch=0.00845] Epoch 246: Train Loss = 0.010277524590492249\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=326, train_loss_step=0.00816, train_loss_epoch=0.0103]Epoch 247: Train Loss = 0.008161209523677826\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=326, train_loss_step=0.0123, train_loss_epoch=0.00816] Epoch 248: Train Loss = 0.012348569929599762\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.0123]  Epoch 249: Train Loss = 0.011022577993571758\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=326, train_loss_step=0.0128, train_loss_epoch=0.011]Epoch 250: Train Loss = 0.01284162886440754\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.0128]Epoch 251: Train Loss = 0.011066263541579247\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=326, train_loss_step=0.0106, train_loss_epoch=0.0111]Epoch 252: Train Loss = 0.010573568753898144\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=326, train_loss_step=0.00954, train_loss_epoch=0.0106]Epoch 253: Train Loss = 0.009541423991322517\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=326, train_loss_step=0.014, train_loss_epoch=0.00954]  Epoch 254: Train Loss = 0.013985256664454937\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  9.42it/s, v_num=326, train_loss_step=0.0125, train_loss_epoch=0.014] Epoch 255: Train Loss = 0.012484622187912464\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.0125]Epoch 256: Train Loss = 0.010427191853523254\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=326, train_loss_step=0.0128, train_loss_epoch=0.0104]Epoch 257: Train Loss = 0.012827334925532341\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=326, train_loss_step=0.0113, train_loss_epoch=0.0128]Epoch 258: Train Loss = 0.011324301362037659\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=326, train_loss_step=0.00788, train_loss_epoch=0.0113]Epoch 259: Train Loss = 0.00788138061761856\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.00788] Epoch 260: Train Loss = 0.011137932538986206\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=326, train_loss_step=0.00927, train_loss_epoch=0.0111]Epoch 261: Train Loss = 0.00926827359944582\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=326, train_loss_step=0.0126, train_loss_epoch=0.00927] Epoch 262: Train Loss = 0.012623020447790623\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.0126] Epoch 263: Train Loss = 0.010428248904645443\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=326, train_loss_step=0.010, train_loss_epoch=0.0104] Epoch 264: Train Loss = 0.010009467601776123\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s, v_num=326, train_loss_step=0.0112, train_loss_epoch=0.010]Epoch 265: Train Loss = 0.011158181354403496\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 10.74it/s, v_num=326, train_loss_step=0.0132, train_loss_epoch=0.0112]Epoch 266: Train Loss = 0.013232567347586155\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=326, train_loss_step=0.00939, train_loss_epoch=0.0132]Epoch 267: Train Loss = 0.009393195621669292\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=326, train_loss_step=0.0105, train_loss_epoch=0.00939] Epoch 268: Train Loss = 0.01045042835175991\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=326, train_loss_step=0.00978, train_loss_epoch=0.0105]Epoch 269: Train Loss = 0.00977941881865263\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.00978] Epoch 270: Train Loss = 0.010100754909217358\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=326, train_loss_step=0.00776, train_loss_epoch=0.0101]Epoch 271: Train Loss = 0.007761943154036999\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 12.97it/s, v_num=326, train_loss_step=0.00684, train_loss_epoch=0.00776]Epoch 272: Train Loss = 0.006837694905698299\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=326, train_loss_step=0.00754, train_loss_epoch=0.00684]Epoch 273: Train Loss = 0.0075365700758993626\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=326, train_loss_step=0.010, train_loss_epoch=0.00754]  Epoch 274: Train Loss = 0.01000624056905508\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=326, train_loss_step=0.0106, train_loss_epoch=0.010] Epoch 275: Train Loss = 0.010606644675135612\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=326, train_loss_step=0.00728, train_loss_epoch=0.0106]Epoch 276: Train Loss = 0.007280468475073576\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=326, train_loss_step=0.0103, train_loss_epoch=0.00728] Epoch 277: Train Loss = 0.010272798128426075\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=326, train_loss_step=0.00942, train_loss_epoch=0.0103]Epoch 278: Train Loss = 0.009422189556062222\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=326, train_loss_step=0.00873, train_loss_epoch=0.00942]Epoch 279: Train Loss = 0.008732080459594727\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=326, train_loss_step=0.0116, train_loss_epoch=0.00873] Epoch 280: Train Loss = 0.01162764523178339\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=326, train_loss_step=0.00903, train_loss_epoch=0.0116]Epoch 281: Train Loss = 0.009026991203427315\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=326, train_loss_step=0.0106, train_loss_epoch=0.00903] Epoch 282: Train Loss = 0.010605045594274998\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=326, train_loss_step=0.00998, train_loss_epoch=0.0106]Epoch 283: Train Loss = 0.00998395774513483\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=326, train_loss_step=0.0116, train_loss_epoch=0.00998] Epoch 284: Train Loss = 0.011585227213799953\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=326, train_loss_step=0.00956, train_loss_epoch=0.0116]Epoch 285: Train Loss = 0.009556720033288002\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=326, train_loss_step=0.0126, train_loss_epoch=0.00956] Epoch 286: Train Loss = 0.0125504732131958\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s, v_num=326, train_loss_step=0.00858, train_loss_epoch=0.0126]Epoch 287: Train Loss = 0.008582335896790028\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=326, train_loss_step=0.00964, train_loss_epoch=0.00858]Epoch 288: Train Loss = 0.009636864066123962\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=326, train_loss_step=0.00851, train_loss_epoch=0.00964]Epoch 289: Train Loss = 0.008512311615049839\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=326, train_loss_step=0.00958, train_loss_epoch=0.00851]Epoch 290: Train Loss = 0.009583326987922192\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=326, train_loss_step=0.0106, train_loss_epoch=0.00958] Epoch 291: Train Loss = 0.010595390573143959\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=326, train_loss_step=0.00904, train_loss_epoch=0.0106]Epoch 292: Train Loss = 0.00904313288629055\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=326, train_loss_step=0.0106, train_loss_epoch=0.00904] Epoch 293: Train Loss = 0.010631640441715717\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=326, train_loss_step=0.00711, train_loss_epoch=0.0106]Epoch 294: Train Loss = 0.0071058012545108795\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=326, train_loss_step=0.0123, train_loss_epoch=0.00711] Epoch 295: Train Loss = 0.012281130068004131\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=326, train_loss_step=0.0143, train_loss_epoch=0.0123] Epoch 296: Train Loss = 0.014299064874649048\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=326, train_loss_step=0.0102, train_loss_epoch=0.0143]Epoch 297: Train Loss = 0.010207933373749256\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=326, train_loss_step=0.0118, train_loss_epoch=0.0102]Epoch 298: Train Loss = 0.011835059151053429\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=326, train_loss_step=0.00892, train_loss_epoch=0.0118]Epoch 299: Train Loss = 0.008922421373426914\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=326, train_loss_step=0.00716, train_loss_epoch=0.00892]Epoch 300: Train Loss = 0.007159607019275427\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=326, train_loss_step=0.00897, train_loss_epoch=0.00716]Epoch 301: Train Loss = 0.008967767469584942\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=326, train_loss_step=0.0106, train_loss_epoch=0.00897] Epoch 302: Train Loss = 0.010571819730103016\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=326, train_loss_step=0.00972, train_loss_epoch=0.0106]Epoch 303: Train Loss = 0.009717866778373718\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.00972] Epoch 304: Train Loss = 0.010063856840133667\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=326, train_loss_step=0.00933, train_loss_epoch=0.0101]Epoch 305: Train Loss = 0.009329275228083134\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=326, train_loss_step=0.00777, train_loss_epoch=0.00933]Epoch 306: Train Loss = 0.00777464872226119\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 11.59it/s, v_num=326, train_loss_step=0.0105, train_loss_epoch=0.00777] Epoch 307: Train Loss = 0.010483860038220882\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.0105] Epoch 308: Train Loss = 0.010412313975393772\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=326, train_loss_step=0.00995, train_loss_epoch=0.0104]Epoch 309: Train Loss = 0.009952181950211525\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=326, train_loss_step=0.0112, train_loss_epoch=0.00995] Epoch 310: Train Loss = 0.011187049560248852\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=326, train_loss_step=0.00957, train_loss_epoch=0.0112]Epoch 311: Train Loss = 0.009569444693624973\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=326, train_loss_step=0.00812, train_loss_epoch=0.00957]Epoch 312: Train Loss = 0.008120700716972351\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 13.20it/s, v_num=326, train_loss_step=0.00974, train_loss_epoch=0.00812]Epoch 313: Train Loss = 0.009735309518873692\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 10.45it/s, v_num=326, train_loss_step=0.00851, train_loss_epoch=0.00974]Epoch 314: Train Loss = 0.008512275293469429\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 13.01it/s, v_num=326, train_loss_step=0.00906, train_loss_epoch=0.00851]Epoch 315: Train Loss = 0.00905588362365961\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=326, train_loss_step=0.00949, train_loss_epoch=0.00906]Epoch 316: Train Loss = 0.009493679739534855\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=326, train_loss_step=0.0123, train_loss_epoch=0.00949] Epoch 317: Train Loss = 0.012285338714718819\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.0123] Epoch 318: Train Loss = 0.010651826858520508\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=326, train_loss_step=0.0129, train_loss_epoch=0.0107]Epoch 319: Train Loss = 0.01287540327757597\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=326, train_loss_step=0.00956, train_loss_epoch=0.0129]Epoch 320: Train Loss = 0.009560912847518921\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=326, train_loss_step=0.0103, train_loss_epoch=0.00956] Epoch 321: Train Loss = 0.010290835984051228\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=326, train_loss_step=0.00839, train_loss_epoch=0.0103]Epoch 322: Train Loss = 0.008389950729906559\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=326, train_loss_step=0.0152, train_loss_epoch=0.00839] Epoch 323: Train Loss = 0.015240508131682873\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=326, train_loss_step=0.00992, train_loss_epoch=0.0152]Epoch 324: Train Loss = 0.009922178462147713\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.00992]  Epoch 325: Train Loss = 0.010982559993863106\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=326, train_loss_step=0.0135, train_loss_epoch=0.011] Epoch 326: Train Loss = 0.013482751324772835\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s, v_num=326, train_loss_step=0.00916, train_loss_epoch=0.0135]Epoch 327: Train Loss = 0.009159346111118793\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=326, train_loss_step=0.0105, train_loss_epoch=0.00916] Epoch 328: Train Loss = 0.010489672422409058\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=326, train_loss_step=0.0112, train_loss_epoch=0.0105] Epoch 329: Train Loss = 0.011156492866575718\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=326, train_loss_step=0.00927, train_loss_epoch=0.0112]Epoch 330: Train Loss = 0.00927186943590641\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=326, train_loss_step=0.00922, train_loss_epoch=0.00927]Epoch 331: Train Loss = 0.009224573150277138\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.00922] Epoch 332: Train Loss = 0.010115190409123898\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=326, train_loss_step=0.00869, train_loss_epoch=0.0101]Epoch 333: Train Loss = 0.008689235895872116\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=326, train_loss_step=0.012, train_loss_epoch=0.00869]  Epoch 334: Train Loss = 0.012041168287396431\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=326, train_loss_step=0.00931, train_loss_epoch=0.012]Epoch 335: Train Loss = 0.009307222440838814\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=326, train_loss_step=0.00992, train_loss_epoch=0.00931]Epoch 336: Train Loss = 0.009917947463691235\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=326, train_loss_step=0.00675, train_loss_epoch=0.00992]Epoch 337: Train Loss = 0.006746490951627493\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=326, train_loss_step=0.00986, train_loss_epoch=0.00675]Epoch 338: Train Loss = 0.00985842663794756\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=326, train_loss_step=0.0129, train_loss_epoch=0.00986] Epoch 339: Train Loss = 0.012859532609581947\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=326, train_loss_step=0.00934, train_loss_epoch=0.0129]Epoch 340: Train Loss = 0.00933778379112482\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.00934]  Epoch 341: Train Loss = 0.011038321070373058\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=326, train_loss_step=0.00991, train_loss_epoch=0.011]Epoch 342: Train Loss = 0.009907340630888939\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=326, train_loss_step=0.00951, train_loss_epoch=0.00991]Epoch 343: Train Loss = 0.00951429270207882\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=326, train_loss_step=0.0106, train_loss_epoch=0.00951] Epoch 344: Train Loss = 0.01063467562198639\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=326, train_loss_step=0.0133, train_loss_epoch=0.0106] Epoch 345: Train Loss = 0.013282434083521366\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=326, train_loss_step=0.00994, train_loss_epoch=0.0133]Epoch 346: Train Loss = 0.009942730888724327\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=326, train_loss_step=0.0125, train_loss_epoch=0.00994] Epoch 347: Train Loss = 0.012544221244752407\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=326, train_loss_step=0.0115, train_loss_epoch=0.0125] Epoch 348: Train Loss = 0.011542023159563541\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.0115]Epoch 349: Train Loss = 0.010060570202767849\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.0101]Epoch 350: Train Loss = 0.010371528565883636\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=326, train_loss_step=0.00989, train_loss_epoch=0.0104]Epoch 351: Train Loss = 0.009894727729260921\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=326, train_loss_step=0.00844, train_loss_epoch=0.00989]Epoch 352: Train Loss = 0.008444132283329964\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=326, train_loss_step=0.00828, train_loss_epoch=0.00844]Epoch 353: Train Loss = 0.008279476314783096\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=326, train_loss_step=0.0157, train_loss_epoch=0.00828] Epoch 354: Train Loss = 0.015659203752875328\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=326, train_loss_step=0.00876, train_loss_epoch=0.0157]Epoch 355: Train Loss = 0.008762744255363941\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=326, train_loss_step=0.00838, train_loss_epoch=0.00876]Epoch 356: Train Loss = 0.008384281769394875\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s, v_num=326, train_loss_step=0.0122, train_loss_epoch=0.00838] Epoch 357: Train Loss = 0.012205514125525951\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=326, train_loss_step=0.0087, train_loss_epoch=0.0122] Epoch 358: Train Loss = 0.008695908822119236\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=326, train_loss_step=0.00915, train_loss_epoch=0.0087]Epoch 359: Train Loss = 0.009145672433078289\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=326, train_loss_step=0.00859, train_loss_epoch=0.00915]Epoch 360: Train Loss = 0.008586745709180832\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=326, train_loss_step=0.0133, train_loss_epoch=0.00859] Epoch 361: Train Loss = 0.013307033106684685\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=326, train_loss_step=0.010, train_loss_epoch=0.0133]  Epoch 362: Train Loss = 0.010000339709222317\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=326, train_loss_step=0.010, train_loss_epoch=0.010] Epoch 363: Train Loss = 0.010005154646933079\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=326, train_loss_step=0.0126, train_loss_epoch=0.010]Epoch 364: Train Loss = 0.01262162160128355\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=326, train_loss_step=0.0133, train_loss_epoch=0.0126]Epoch 365: Train Loss = 0.013252747245132923\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=326, train_loss_step=0.0128, train_loss_epoch=0.0133]Epoch 366: Train Loss = 0.012763376347720623\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=326, train_loss_step=0.00969, train_loss_epoch=0.0128]Epoch 367: Train Loss = 0.009692375548183918\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.00969] Epoch 368: Train Loss = 0.010436120443046093\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=326, train_loss_step=0.0126, train_loss_epoch=0.0104] Epoch 369: Train Loss = 0.012554927729070187\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=326, train_loss_step=0.0142, train_loss_epoch=0.0126]Epoch 370: Train Loss = 0.014222119934856892\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=326, train_loss_step=0.00883, train_loss_epoch=0.0142]Epoch 371: Train Loss = 0.008827888406813145\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=326, train_loss_step=0.00874, train_loss_epoch=0.00883]Epoch 372: Train Loss = 0.008744767867028713\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.00874] Epoch 373: Train Loss = 0.0104279899969697\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=326, train_loss_step=0.00831, train_loss_epoch=0.0104]Epoch 374: Train Loss = 0.00831115897744894\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=326, train_loss_step=0.0084, train_loss_epoch=0.00831] Epoch 375: Train Loss = 0.008400778286159039\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=326, train_loss_step=0.00924, train_loss_epoch=0.0084]Epoch 376: Train Loss = 0.009235270321369171\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=326, train_loss_step=0.012, train_loss_epoch=0.00924]  Epoch 377: Train Loss = 0.012032272294163704\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=326, train_loss_step=0.0108, train_loss_epoch=0.012] Epoch 378: Train Loss = 0.010810637846589088\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=326, train_loss_step=0.0115, train_loss_epoch=0.0108]Epoch 379: Train Loss = 0.011474894359707832\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=326, train_loss_step=0.00861, train_loss_epoch=0.0115]Epoch 380: Train Loss = 0.008612877689301968\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.00861]  Epoch 381: Train Loss = 0.011042303405702114\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=326, train_loss_step=0.0108, train_loss_epoch=0.011] Epoch 382: Train Loss = 0.010753561742603779\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=326, train_loss_step=0.00779, train_loss_epoch=0.0108]Epoch 383: Train Loss = 0.0077895731665194035\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=326, train_loss_step=0.0113, train_loss_epoch=0.00779] Epoch 384: Train Loss = 0.011288178153336048\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=326, train_loss_step=0.00953, train_loss_epoch=0.0113]Epoch 385: Train Loss = 0.009529638104140759\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=326, train_loss_step=0.0125, train_loss_epoch=0.00953] Epoch 386: Train Loss = 0.012514197267591953\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.0125] Epoch 387: Train Loss = 0.010088406503200531\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.0101]Epoch 388: Train Loss = 0.011097083799540997\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.0111]Epoch 389: Train Loss = 0.011119985952973366\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=326, train_loss_step=0.00767, train_loss_epoch=0.0111]Epoch 390: Train Loss = 0.007672558538615704\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.00767] Epoch 391: Train Loss = 0.010099023580551147\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=326, train_loss_step=0.00761, train_loss_epoch=0.0101]Epoch 392: Train Loss = 0.007614024914801121\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.00761] Epoch 393: Train Loss = 0.01008452195674181\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=326, train_loss_step=0.0117, train_loss_epoch=0.0101] Epoch 394: Train Loss = 0.011717402376234531\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=326, train_loss_step=0.00987, train_loss_epoch=0.0117]Epoch 395: Train Loss = 0.009871579706668854\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=326, train_loss_step=0.00878, train_loss_epoch=0.00987]Epoch 396: Train Loss = 0.00877666100859642\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=326, train_loss_step=0.00845, train_loss_epoch=0.00878]Epoch 397: Train Loss = 0.008450938388705254\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=326, train_loss_step=0.00831, train_loss_epoch=0.00845]Epoch 398: Train Loss = 0.008313978090882301\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=326, train_loss_step=0.0122, train_loss_epoch=0.00831] Epoch 399: Train Loss = 0.012243872508406639\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=326, train_loss_step=0.00984, train_loss_epoch=0.0122]Epoch 400: Train Loss = 0.009842155501246452\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=326, train_loss_step=0.00959, train_loss_epoch=0.00984]Epoch 401: Train Loss = 0.00959042739123106\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=326, train_loss_step=0.0124, train_loss_epoch=0.00959] Epoch 402: Train Loss = 0.012431835755705833\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=326, train_loss_step=0.0113, train_loss_epoch=0.0124] Epoch 403: Train Loss = 0.011349229142069817\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=326, train_loss_step=0.0088, train_loss_epoch=0.0113]Epoch 404: Train Loss = 0.008801152929663658\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=326, train_loss_step=0.00813, train_loss_epoch=0.0088]Epoch 405: Train Loss = 0.00812993012368679\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=326, train_loss_step=0.00985, train_loss_epoch=0.00813]Epoch 406: Train Loss = 0.009851507842540741\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=326, train_loss_step=0.0121, train_loss_epoch=0.00985] Epoch 407: Train Loss = 0.012052123434841633\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=326, train_loss_step=0.00959, train_loss_epoch=0.0121]Epoch 408: Train Loss = 0.009585206396877766\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=326, train_loss_step=0.00924, train_loss_epoch=0.00959]Epoch 409: Train Loss = 0.009244379587471485\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=326, train_loss_step=0.00897, train_loss_epoch=0.00924]Epoch 410: Train Loss = 0.008972610346972942\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.00897] Epoch 411: Train Loss = 0.010144633240997791\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=326, train_loss_step=0.0114, train_loss_epoch=0.0101] Epoch 412: Train Loss = 0.011430054903030396\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=326, train_loss_step=0.00827, train_loss_epoch=0.0114]Epoch 413: Train Loss = 0.008267059922218323\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=326, train_loss_step=0.0122, train_loss_epoch=0.00827] Epoch 414: Train Loss = 0.01223820261657238\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=326, train_loss_step=0.0106, train_loss_epoch=0.0122] Epoch 415: Train Loss = 0.010631649754941463\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=326, train_loss_step=0.00952, train_loss_epoch=0.0106]Epoch 416: Train Loss = 0.00952240638434887\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=326, train_loss_step=0.0105, train_loss_epoch=0.00952] Epoch 417: Train Loss = 0.010491659864783287\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=326, train_loss_step=0.014, train_loss_epoch=0.0105]  Epoch 418: Train Loss = 0.014006444253027439\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=326, train_loss_step=0.00691, train_loss_epoch=0.014]Epoch 419: Train Loss = 0.00691232131794095\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=326, train_loss_step=0.00931, train_loss_epoch=0.00691]Epoch 420: Train Loss = 0.009309368208050728\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=326, train_loss_step=0.0112, train_loss_epoch=0.00931] Epoch 421: Train Loss = 0.01119303610175848\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=326, train_loss_step=0.00879, train_loss_epoch=0.0112]Epoch 422: Train Loss = 0.008794087916612625\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=326, train_loss_step=0.0103, train_loss_epoch=0.00879] Epoch 423: Train Loss = 0.010267266072332859\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=326, train_loss_step=0.0137, train_loss_epoch=0.0103] Epoch 424: Train Loss = 0.01370234601199627\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=326, train_loss_step=0.00886, train_loss_epoch=0.0137]Epoch 425: Train Loss = 0.008859162218868732\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=326, train_loss_step=0.0094, train_loss_epoch=0.00886] Epoch 426: Train Loss = 0.00939622987061739\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=326, train_loss_step=0.0127, train_loss_epoch=0.0094] Epoch 427: Train Loss = 0.01271313987672329\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=326, train_loss_step=0.0105, train_loss_epoch=0.0127]Epoch 428: Train Loss = 0.010499224066734314\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=326, train_loss_step=0.0102, train_loss_epoch=0.0105]Epoch 429: Train Loss = 0.010217050090432167\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=326, train_loss_step=0.00775, train_loss_epoch=0.0102]Epoch 430: Train Loss = 0.007750785443931818\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.00775] Epoch 431: Train Loss = 0.010422157123684883\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=326, train_loss_step=0.012, train_loss_epoch=0.0104]  Epoch 432: Train Loss = 0.012045001611113548\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=326, train_loss_step=0.00934, train_loss_epoch=0.012]Epoch 433: Train Loss = 0.009339491836726665\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=326, train_loss_step=0.0114, train_loss_epoch=0.00934] Epoch 434: Train Loss = 0.011438804678618908\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=326, train_loss_step=0.00808, train_loss_epoch=0.0114]Epoch 435: Train Loss = 0.008084806613624096\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=326, train_loss_step=0.0099, train_loss_epoch=0.00808] Epoch 436: Train Loss = 0.009898553602397442\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=326, train_loss_step=0.00869, train_loss_epoch=0.0099]Epoch 437: Train Loss = 0.008692908100783825\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=326, train_loss_step=0.0128, train_loss_epoch=0.00869] Epoch 438: Train Loss = 0.012775410898029804\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=326, train_loss_step=0.00857, train_loss_epoch=0.0128]Epoch 439: Train Loss = 0.008573985658586025\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.00857] Epoch 440: Train Loss = 0.010139680467545986\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.0101] Epoch 441: Train Loss = 0.011074238456785679\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=326, train_loss_step=0.00841, train_loss_epoch=0.0111]Epoch 442: Train Loss = 0.008407569490373135\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=326, train_loss_step=0.00897, train_loss_epoch=0.00841]Epoch 443: Train Loss = 0.008966095745563507\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.00897] Epoch 444: Train Loss = 0.010060884989798069\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=326, train_loss_step=0.017, train_loss_epoch=0.0101]  Epoch 445: Train Loss = 0.01700371690094471\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=326, train_loss_step=0.012, train_loss_epoch=0.017] Epoch 446: Train Loss = 0.011971915140748024\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s, v_num=326, train_loss_step=0.0095, train_loss_epoch=0.012]Epoch 447: Train Loss = 0.009502182714641094\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=326, train_loss_step=0.0127, train_loss_epoch=0.0095]Epoch 448: Train Loss = 0.012660074047744274\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=326, train_loss_step=0.010, train_loss_epoch=0.0127] Epoch 449: Train Loss = 0.010022099129855633\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=326, train_loss_step=0.0116, train_loss_epoch=0.010]Epoch 450: Train Loss = 0.011583941988646984\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=326, train_loss_step=0.00852, train_loss_epoch=0.0116]Epoch 451: Train Loss = 0.008519710972905159\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=326, train_loss_step=0.00934, train_loss_epoch=0.00852]Epoch 452: Train Loss = 0.009340607561171055\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=326, train_loss_step=0.00908, train_loss_epoch=0.00934]Epoch 453: Train Loss = 0.009080365300178528\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=326, train_loss_step=0.00813, train_loss_epoch=0.00908]Epoch 454: Train Loss = 0.008134303614497185\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=326, train_loss_step=0.00781, train_loss_epoch=0.00813]Epoch 455: Train Loss = 0.007814282551407814\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=326, train_loss_step=0.0115, train_loss_epoch=0.00781] Epoch 456: Train Loss = 0.011457880958914757\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=326, train_loss_step=0.0108, train_loss_epoch=0.0115] Epoch 457: Train Loss = 0.010815702378749847\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=326, train_loss_step=0.0102, train_loss_epoch=0.0108]Epoch 458: Train Loss = 0.010236610658466816\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=326, train_loss_step=0.0128, train_loss_epoch=0.0102]Epoch 459: Train Loss = 0.012834317982196808\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=326, train_loss_step=0.0142, train_loss_epoch=0.0128]Epoch 460: Train Loss = 0.014183694496750832\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=326, train_loss_step=0.00994, train_loss_epoch=0.0142]Epoch 461: Train Loss = 0.009941326454281807\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=326, train_loss_step=0.00942, train_loss_epoch=0.00994]Epoch 462: Train Loss = 0.00942305289208889\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=326, train_loss_step=0.00941, train_loss_epoch=0.00942]Epoch 463: Train Loss = 0.00941369216889143\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=326, train_loss_step=0.0131, train_loss_epoch=0.00941] Epoch 464: Train Loss = 0.013112281449139118\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=326, train_loss_step=0.00977, train_loss_epoch=0.0131]Epoch 465: Train Loss = 0.009771214798092842\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=326, train_loss_step=0.00908, train_loss_epoch=0.00977]Epoch 466: Train Loss = 0.009079731069505215\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=326, train_loss_step=0.00862, train_loss_epoch=0.00908]Epoch 467: Train Loss = 0.008617226965725422\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=326, train_loss_step=0.00904, train_loss_epoch=0.00862]Epoch 468: Train Loss = 0.009038514457643032\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=326, train_loss_step=0.010, train_loss_epoch=0.00904]  Epoch 469: Train Loss = 0.010023885406553745\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.010] Epoch 470: Train Loss = 0.010105924680829048\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=326, train_loss_step=0.0104, train_loss_epoch=0.0101]Epoch 471: Train Loss = 0.010427246801555157\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.0104]Epoch 472: Train Loss = 0.010080466978251934\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=326, train_loss_step=0.00778, train_loss_epoch=0.0101]Epoch 473: Train Loss = 0.007779550272971392\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=326, train_loss_step=0.00877, train_loss_epoch=0.00778]Epoch 474: Train Loss = 0.008771814405918121\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=326, train_loss_step=0.00959, train_loss_epoch=0.00877]Epoch 475: Train Loss = 0.00959269143640995\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=326, train_loss_step=0.00897, train_loss_epoch=0.00959]Epoch 476: Train Loss = 0.008974329568445683\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=326, train_loss_step=0.00919, train_loss_epoch=0.00897]Epoch 477: Train Loss = 0.009190802462399006\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=326, train_loss_step=0.00809, train_loss_epoch=0.00919]Epoch 478: Train Loss = 0.008086145855486393\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=326, train_loss_step=0.0115, train_loss_epoch=0.00809] Epoch 479: Train Loss = 0.0114770932123065\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=326, train_loss_step=0.014, train_loss_epoch=0.0115]  Epoch 480: Train Loss = 0.01402701623737812\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=326, train_loss_step=0.0111, train_loss_epoch=0.014]Epoch 481: Train Loss = 0.011119727976620197\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=326, train_loss_step=0.0101, train_loss_epoch=0.0111]Epoch 482: Train Loss = 0.010070666670799255\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=326, train_loss_step=0.00929, train_loss_epoch=0.0101]Epoch 483: Train Loss = 0.009292393922805786\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=326, train_loss_step=0.00741, train_loss_epoch=0.00929]Epoch 484: Train Loss = 0.0074117411859333515\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=326, train_loss_step=0.00919, train_loss_epoch=0.00741]Epoch 485: Train Loss = 0.009193065576255322\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=326, train_loss_step=0.00875, train_loss_epoch=0.00919]Epoch 486: Train Loss = 0.008747176267206669\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=326, train_loss_step=0.00775, train_loss_epoch=0.00875]Epoch 487: Train Loss = 0.007749461103230715\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=326, train_loss_step=0.00879, train_loss_epoch=0.00775]Epoch 488: Train Loss = 0.008787039667367935\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=326, train_loss_step=0.0141, train_loss_epoch=0.00879] Epoch 489: Train Loss = 0.014112952165305614\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=326, train_loss_step=0.0116, train_loss_epoch=0.0141] Epoch 490: Train Loss = 0.011645634658634663\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=326, train_loss_step=0.0121, train_loss_epoch=0.0116]Epoch 491: Train Loss = 0.012061177752912045\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=326, train_loss_step=0.00755, train_loss_epoch=0.0121]Epoch 492: Train Loss = 0.007548960391432047\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=326, train_loss_step=0.0119, train_loss_epoch=0.00755] Epoch 493: Train Loss = 0.011931933462619781\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=326, train_loss_step=0.0107, train_loss_epoch=0.0119] Epoch 494: Train Loss = 0.010662337765097618\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=326, train_loss_step=0.0124, train_loss_epoch=0.0107]Epoch 495: Train Loss = 0.012445342727005482\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=326, train_loss_step=0.0098, train_loss_epoch=0.0124]Epoch 496: Train Loss = 0.009804521687328815\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=326, train_loss_step=0.011, train_loss_epoch=0.0098] Epoch 497: Train Loss = 0.011019702069461346\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=326, train_loss_step=0.00705, train_loss_epoch=0.011]Epoch 498: Train Loss = 0.007051191292703152\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=326, train_loss_step=0.00928, train_loss_epoch=0.00705]Epoch 499: Train Loss = 0.00927781779319048\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=326, train_loss_step=0.00928, train_loss_epoch=0.00928]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=326, train_loss_step=0.00928, train_loss_epoch=0.00928]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 3: from 2008-05-12 00:00:00 to 2022-07-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=330, train_loss_step=0.0237]Epoch 0: Train Loss = 0.023683395236730576\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=330, train_loss_step=0.0336, train_loss_epoch=0.0237]Epoch 1: Train Loss = 0.03360742703080177\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=330, train_loss_step=0.0218, train_loss_epoch=0.0336]Epoch 2: Train Loss = 0.021801752969622612\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=330, train_loss_step=0.020, train_loss_epoch=0.0218] Epoch 3: Train Loss = 0.019979145377874374\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=330, train_loss_step=0.0155, train_loss_epoch=0.020]Epoch 4: Train Loss = 0.01548013836145401\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=330, train_loss_step=0.0187, train_loss_epoch=0.0155]Epoch 5: Train Loss = 0.0186797846108675\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 13.77it/s, v_num=330, train_loss_step=0.0169, train_loss_epoch=0.0187]Epoch 6: Train Loss = 0.01687636412680149\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=330, train_loss_step=0.0165, train_loss_epoch=0.0169]Epoch 7: Train Loss = 0.01651669852435589\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=330, train_loss_step=0.0132, train_loss_epoch=0.0165]Epoch 8: Train Loss = 0.013151375576853752\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=330, train_loss_step=0.0167, train_loss_epoch=0.0132]Epoch 9: Train Loss = 0.016729220747947693\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=330, train_loss_step=0.0141, train_loss_epoch=0.0167]Epoch 10: Train Loss = 0.014057640917599201\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.0141]Epoch 11: Train Loss = 0.010568835772573948\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=330, train_loss_step=0.0216, train_loss_epoch=0.0106]Epoch 12: Train Loss = 0.021587161347270012\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=330, train_loss_step=0.0162, train_loss_epoch=0.0216]Epoch 13: Train Loss = 0.016237806528806686\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=330, train_loss_step=0.0175, train_loss_epoch=0.0162]Epoch 14: Train Loss = 0.01749502122402191\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=330, train_loss_step=0.0163, train_loss_epoch=0.0175]Epoch 15: Train Loss = 0.016269652172923088\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=330, train_loss_step=0.0165, train_loss_epoch=0.0163]Epoch 16: Train Loss = 0.016507579013705254\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=330, train_loss_step=0.0121, train_loss_epoch=0.0165]Epoch 17: Train Loss = 0.012077429331839085\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.0121]Epoch 18: Train Loss = 0.011555500328540802\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=330, train_loss_step=0.0171, train_loss_epoch=0.0116]Epoch 19: Train Loss = 0.01708228699862957\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=330, train_loss_step=0.0123, train_loss_epoch=0.0171]Epoch 20: Train Loss = 0.012272548861801624\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=330, train_loss_step=0.0144, train_loss_epoch=0.0123]Epoch 21: Train Loss = 0.014380590990185738\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=330, train_loss_step=0.0136, train_loss_epoch=0.0144]Epoch 22: Train Loss = 0.013590247370302677\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=330, train_loss_step=0.0143, train_loss_epoch=0.0136]Epoch 23: Train Loss = 0.014255336485803127\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=330, train_loss_step=0.0137, train_loss_epoch=0.0143]Epoch 24: Train Loss = 0.013671700842678547\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=330, train_loss_step=0.0125, train_loss_epoch=0.0137]Epoch 25: Train Loss = 0.012511353008449078\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=330, train_loss_step=0.0115, train_loss_epoch=0.0125]Epoch 26: Train Loss = 0.01149366982281208\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=330, train_loss_step=0.0119, train_loss_epoch=0.0115]Epoch 27: Train Loss = 0.011941737495362759\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=330, train_loss_step=0.0182, train_loss_epoch=0.0119]Epoch 28: Train Loss = 0.018164372071623802\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=330, train_loss_step=0.0147, train_loss_epoch=0.0182]Epoch 29: Train Loss = 0.014723028056323528\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=330, train_loss_step=0.0115, train_loss_epoch=0.0147]Epoch 30: Train Loss = 0.011503237299621105\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=330, train_loss_step=0.0148, train_loss_epoch=0.0115]Epoch 31: Train Loss = 0.014827289618551731\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=330, train_loss_step=0.015, train_loss_epoch=0.0148] Epoch 32: Train Loss = 0.014972872100770473\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=330, train_loss_step=0.0174, train_loss_epoch=0.015]Epoch 33: Train Loss = 0.017384300008416176\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.0174]Epoch 34: Train Loss = 0.011373965069651604\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=330, train_loss_step=0.00893, train_loss_epoch=0.0114]Epoch 35: Train Loss = 0.008927704766392708\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=330, train_loss_step=0.0121, train_loss_epoch=0.00893] Epoch 36: Train Loss = 0.012142126448452473\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.0121]  Epoch 37: Train Loss = 0.010001378133893013\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=330, train_loss_step=0.0172, train_loss_epoch=0.010]Epoch 38: Train Loss = 0.017172131687402725\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=330, train_loss_step=0.0137, train_loss_epoch=0.0172]Epoch 39: Train Loss = 0.013661778531968594\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=330, train_loss_step=0.0129, train_loss_epoch=0.0137]Epoch 40: Train Loss = 0.012941678054630756\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=330, train_loss_step=0.0136, train_loss_epoch=0.0129]Epoch 41: Train Loss = 0.013556978665292263\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.0136]Epoch 42: Train Loss = 0.011620631441473961\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=330, train_loss_step=0.0134, train_loss_epoch=0.0116]Epoch 43: Train Loss = 0.013439883477985859\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.0134]Epoch 44: Train Loss = 0.010751915164291859\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=330, train_loss_step=0.0137, train_loss_epoch=0.0108]Epoch 45: Train Loss = 0.013655178248882294\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=330, train_loss_step=0.0117, train_loss_epoch=0.0137]Epoch 46: Train Loss = 0.011661135591566563\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=330, train_loss_step=0.0124, train_loss_epoch=0.0117]Epoch 47: Train Loss = 0.01235745009034872\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=330, train_loss_step=0.013, train_loss_epoch=0.0124] Epoch 48: Train Loss = 0.013036140240728855\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.013] Epoch 49: Train Loss = 0.009999179281294346\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=330, train_loss_step=0.00823, train_loss_epoch=0.010]Epoch 50: Train Loss = 0.008228727616369724\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.00823] Epoch 51: Train Loss = 0.011367212049663067\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=330, train_loss_step=0.0125, train_loss_epoch=0.0114] Epoch 52: Train Loss = 0.012533660046756268\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.0125]Epoch 53: Train Loss = 0.011633005924522877\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=330, train_loss_step=0.0123, train_loss_epoch=0.0116]Epoch 54: Train Loss = 0.01233639009296894\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=330, train_loss_step=0.00969, train_loss_epoch=0.0123]Epoch 55: Train Loss = 0.009685971774160862\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=330, train_loss_step=0.00953, train_loss_epoch=0.00969]Epoch 56: Train Loss = 0.009531043469905853\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=330, train_loss_step=0.0112, train_loss_epoch=0.00953] Epoch 57: Train Loss = 0.011155630461871624\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  9.60it/s, v_num=330, train_loss_step=0.00951, train_loss_epoch=0.0112]Epoch 58: Train Loss = 0.009505725465714931\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=330, train_loss_step=0.0128, train_loss_epoch=0.00951] Epoch 59: Train Loss = 0.012790558859705925\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=330, train_loss_step=0.0119, train_loss_epoch=0.0128] Epoch 60: Train Loss = 0.011919287964701653\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=330, train_loss_step=0.012, train_loss_epoch=0.0119] Epoch 61: Train Loss = 0.011985604651272297\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=330, train_loss_step=0.0107, train_loss_epoch=0.012]Epoch 62: Train Loss = 0.010742583312094212\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0107]Epoch 63: Train Loss = 0.01019576471298933\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=330, train_loss_step=0.0128, train_loss_epoch=0.0102]Epoch 64: Train Loss = 0.012802735902369022\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=330, train_loss_step=0.00975, train_loss_epoch=0.0128]Epoch 65: Train Loss = 0.009750597178936005\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.00975] Epoch 66: Train Loss = 0.01141307596117258\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=330, train_loss_step=0.0103, train_loss_epoch=0.0114] Epoch 67: Train Loss = 0.010282903909683228\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.0103]Epoch 68: Train Loss = 0.01163501013070345\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=330, train_loss_step=0.0132, train_loss_epoch=0.0116]Epoch 69: Train Loss = 0.013228162191808224\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=330, train_loss_step=0.012, train_loss_epoch=0.0132] Epoch 70: Train Loss = 0.012012000195682049\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=330, train_loss_step=0.0112, train_loss_epoch=0.012]Epoch 71: Train Loss = 0.011247053742408752\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.0112]Epoch 72: Train Loss = 0.010833753272891045\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=330, train_loss_step=0.014, train_loss_epoch=0.0108] Epoch 73: Train Loss = 0.013952508568763733\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=330, train_loss_step=0.0156, train_loss_epoch=0.014]Epoch 74: Train Loss = 0.015586976893246174\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s, v_num=330, train_loss_step=0.0132, train_loss_epoch=0.0156]Epoch 75: Train Loss = 0.013235594145953655\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=330, train_loss_step=0.00937, train_loss_epoch=0.0132]Epoch 76: Train Loss = 0.009365088306367397\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=330, train_loss_step=0.0133, train_loss_epoch=0.00937] Epoch 77: Train Loss = 0.013263779692351818\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=330, train_loss_step=0.00792, train_loss_epoch=0.0133]Epoch 78: Train Loss = 0.007916545495390892\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.00792]  Epoch 79: Train Loss = 0.011025404557585716\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=330, train_loss_step=0.0119, train_loss_epoch=0.011] Epoch 80: Train Loss = 0.011892725713551044\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=330, train_loss_step=0.0145, train_loss_epoch=0.0119]Epoch 81: Train Loss = 0.014519661664962769\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=330, train_loss_step=0.0154, train_loss_epoch=0.0145]Epoch 82: Train Loss = 0.01539343036711216\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=330, train_loss_step=0.00931, train_loss_epoch=0.0154]Epoch 83: Train Loss = 0.00930839218199253\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=330, train_loss_step=0.00787, train_loss_epoch=0.00931]Epoch 84: Train Loss = 0.007870768196880817\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=330, train_loss_step=0.0128, train_loss_epoch=0.00787] Epoch 85: Train Loss = 0.012779694981873035\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=330, train_loss_step=0.0103, train_loss_epoch=0.0128] Epoch 86: Train Loss = 0.010336567647755146\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.0103] Epoch 87: Train Loss = 0.01098727062344551\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=330, train_loss_step=0.0129, train_loss_epoch=0.011]Epoch 88: Train Loss = 0.012893428094685078\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=330, train_loss_step=0.00847, train_loss_epoch=0.0129]Epoch 89: Train Loss = 0.008465355262160301\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=330, train_loss_step=0.00907, train_loss_epoch=0.00847]Epoch 90: Train Loss = 0.009067626670002937\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=330, train_loss_step=0.00846, train_loss_epoch=0.00907]Epoch 91: Train Loss = 0.008455066941678524\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.00846]  Epoch 92: Train Loss = 0.011036133393645287\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=330, train_loss_step=0.0141, train_loss_epoch=0.011] Epoch 93: Train Loss = 0.014065472409129143\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=330, train_loss_step=0.00984, train_loss_epoch=0.0141]Epoch 94: Train Loss = 0.00984382163733244\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=330, train_loss_step=0.00973, train_loss_epoch=0.00984]Epoch 95: Train Loss = 0.009728960692882538\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.00973] Epoch 96: Train Loss = 0.011371222324669361\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=330, train_loss_step=0.0153, train_loss_epoch=0.0114] Epoch 97: Train Loss = 0.015273593366146088\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=330, train_loss_step=0.0125, train_loss_epoch=0.0153]Epoch 98: Train Loss = 0.012537644244730473\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=330, train_loss_step=0.0112, train_loss_epoch=0.0125]Epoch 99: Train Loss = 0.01120176911354065\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.0112]Epoch 100: Train Loss = 0.011423110030591488\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.0114]Epoch 101: Train Loss = 0.010814244858920574\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=330, train_loss_step=0.0176, train_loss_epoch=0.0108]Epoch 102: Train Loss = 0.01758430339396\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=330, train_loss_step=0.0115, train_loss_epoch=0.0176]Epoch 103: Train Loss = 0.011515557765960693\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=330, train_loss_step=0.0126, train_loss_epoch=0.0115]Epoch 104: Train Loss = 0.0126273138448596\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=330, train_loss_step=0.0161, train_loss_epoch=0.0126]Epoch 105: Train Loss = 0.016135133802890778\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=330, train_loss_step=0.0179, train_loss_epoch=0.0161]Epoch 106: Train Loss = 0.017945757135748863\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=330, train_loss_step=0.0112, train_loss_epoch=0.0179]Epoch 107: Train Loss = 0.011151893064379692\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=330, train_loss_step=0.0125, train_loss_epoch=0.0112]Epoch 108: Train Loss = 0.012528950348496437\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.0125]Epoch 109: Train Loss = 0.01164642721414566\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=330, train_loss_step=0.0111, train_loss_epoch=0.0116]Epoch 110: Train Loss = 0.011059855110943317\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=330, train_loss_step=0.0134, train_loss_epoch=0.0111]Epoch 111: Train Loss = 0.013404371216893196\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=330, train_loss_step=0.0115, train_loss_epoch=0.0134]Epoch 112: Train Loss = 0.011529524810612202\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0115]Epoch 113: Train Loss = 0.010879529640078545\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.0109]Epoch 114: Train Loss = 0.010596648789942265\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=330, train_loss_step=0.0121, train_loss_epoch=0.0106]Epoch 115: Train Loss = 0.012085900641977787\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=330, train_loss_step=0.012, train_loss_epoch=0.0121] Epoch 116: Train Loss = 0.011962270364165306\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=330, train_loss_step=0.0132, train_loss_epoch=0.012]Epoch 117: Train Loss = 0.013222992420196533\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=330, train_loss_step=0.0101, train_loss_epoch=0.0132]Epoch 118: Train Loss = 0.010122915729880333\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=330, train_loss_step=0.0101, train_loss_epoch=0.0101]Epoch 119: Train Loss = 0.010067627765238285\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=330, train_loss_step=0.0133, train_loss_epoch=0.0101]Epoch 120: Train Loss = 0.01330044399946928\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=330, train_loss_step=0.0123, train_loss_epoch=0.0133]Epoch 121: Train Loss = 0.012332604266703129\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=330, train_loss_step=0.0117, train_loss_epoch=0.0123]Epoch 122: Train Loss = 0.011652323417365551\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.0117] Epoch 123: Train Loss = 0.010044960305094719\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.010]Epoch 124: Train Loss = 0.011385427787899971\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=330, train_loss_step=0.00996, train_loss_epoch=0.0114]Epoch 125: Train Loss = 0.009955750778317451\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=330, train_loss_step=0.0107, train_loss_epoch=0.00996] Epoch 126: Train Loss = 0.010724727995693684\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.0107]  Epoch 127: Train Loss = 0.010030187666416168\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.010]Epoch 128: Train Loss = 0.011617927812039852\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0116]Epoch 129: Train Loss = 0.010946697555482388\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=330, train_loss_step=0.0104, train_loss_epoch=0.0109]Epoch 130: Train Loss = 0.010426555760204792\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.0104]Epoch 131: Train Loss = 0.010568222962319851\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=330, train_loss_step=0.00763, train_loss_epoch=0.0106]Epoch 132: Train Loss = 0.007628148887306452\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.00763] Epoch 133: Train Loss = 0.010765209794044495\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.0108]  Epoch 134: Train Loss = 0.01002594642341137\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=330, train_loss_step=0.0132, train_loss_epoch=0.010]Epoch 135: Train Loss = 0.013204212300479412\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.0132]Epoch 136: Train Loss = 0.011349677108228207\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=330, train_loss_step=0.0112, train_loss_epoch=0.0113]Epoch 137: Train Loss = 0.011170538142323494\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.0112]Epoch 138: Train Loss = 0.010627145878970623\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=330, train_loss_step=0.00827, train_loss_epoch=0.0106]Epoch 139: Train Loss = 0.008271178230643272\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=330, train_loss_step=0.0123, train_loss_epoch=0.00827] Epoch 140: Train Loss = 0.01226100791245699\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=330, train_loss_step=0.0124, train_loss_epoch=0.0123] Epoch 141: Train Loss = 0.01242840476334095\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0124]Epoch 142: Train Loss = 0.010165777988731861\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s, v_num=330, train_loss_step=0.00982, train_loss_epoch=0.0102]Epoch 143: Train Loss = 0.009820994921028614\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=330, train_loss_step=0.0105, train_loss_epoch=0.00982] Epoch 144: Train Loss = 0.010461919941008091\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=330, train_loss_step=0.00929, train_loss_epoch=0.0105]Epoch 145: Train Loss = 0.009289354085922241\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=330, train_loss_step=0.00913, train_loss_epoch=0.00929]Epoch 146: Train Loss = 0.009127874858677387\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=330, train_loss_step=0.0115, train_loss_epoch=0.00913] Epoch 147: Train Loss = 0.011465407907962799\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=330, train_loss_step=0.0145, train_loss_epoch=0.0115] Epoch 148: Train Loss = 0.014546608552336693\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=330, train_loss_step=0.013, train_loss_epoch=0.0145] Epoch 149: Train Loss = 0.012981731444597244\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.013]Epoch 150: Train Loss = 0.010243653319776058\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=330, train_loss_step=0.0107, train_loss_epoch=0.0102]Epoch 151: Train Loss = 0.010680361650884151\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=330, train_loss_step=0.0146, train_loss_epoch=0.0107]Epoch 152: Train Loss = 0.014600181020796299\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=330, train_loss_step=0.0087, train_loss_epoch=0.0146]Epoch 153: Train Loss = 0.008704922161996365\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=330, train_loss_step=0.0148, train_loss_epoch=0.0087]Epoch 154: Train Loss = 0.014798087067902088\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=330, train_loss_step=0.00874, train_loss_epoch=0.0148]Epoch 155: Train Loss = 0.00874451082199812\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=330, train_loss_step=0.0101, train_loss_epoch=0.00874] Epoch 156: Train Loss = 0.010114573873579502\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=330, train_loss_step=0.0162, train_loss_epoch=0.0101] Epoch 157: Train Loss = 0.016195209696888924\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.0162]Epoch 158: Train Loss = 0.011287940666079521\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.0113] Epoch 159: Train Loss = 0.010979599319398403\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=330, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 160: Train Loss = 0.012464525178074837\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.0125] Epoch 161: Train Loss = 0.010029584169387817\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=330, train_loss_step=0.0107, train_loss_epoch=0.010]Epoch 162: Train Loss = 0.01067262887954712\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=330, train_loss_step=0.00902, train_loss_epoch=0.0107]Epoch 163: Train Loss = 0.009019319899380207\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.00902] Epoch 164: Train Loss = 0.010848239064216614\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.0108] Epoch 165: Train Loss = 0.011308401823043823\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.0113] Epoch 166: Train Loss = 0.010049084201455116\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=330, train_loss_step=0.00925, train_loss_epoch=0.010]Epoch 167: Train Loss = 0.009254532866179943\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=330, train_loss_step=0.00897, train_loss_epoch=0.00925]Epoch 168: Train Loss = 0.00897024106234312\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=330, train_loss_step=0.0125, train_loss_epoch=0.00897] Epoch 169: Train Loss = 0.012489847838878632\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=330, train_loss_step=0.0117, train_loss_epoch=0.0125] Epoch 170: Train Loss = 0.011713149957358837\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=330, train_loss_step=0.0163, train_loss_epoch=0.0117]Epoch 171: Train Loss = 0.01632857508957386\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.0163]Epoch 172: Train Loss = 0.01156680379062891\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=330, train_loss_step=0.0126, train_loss_epoch=0.0116]Epoch 173: Train Loss = 0.012557166628539562\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.0126]Epoch 174: Train Loss = 0.01063663698732853\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=330, train_loss_step=0.0138, train_loss_epoch=0.0106]Epoch 175: Train Loss = 0.013830393552780151\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=330, train_loss_step=0.0138, train_loss_epoch=0.0138]Epoch 176: Train Loss = 0.013838855549693108\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.0138] Epoch 177: Train Loss = 0.010955787263810635\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=330, train_loss_step=0.0089, train_loss_epoch=0.011]Epoch 178: Train Loss = 0.008895567618310452\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=330, train_loss_step=0.00909, train_loss_epoch=0.0089]Epoch 179: Train Loss = 0.00908509362488985\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 10.67it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.00909] Epoch 180: Train Loss = 0.01130608655512333\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=330, train_loss_step=0.00717, train_loss_epoch=0.0113]Epoch 181: Train Loss = 0.00716688996180892\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.00717] Epoch 182: Train Loss = 0.01094082836061716\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=330, train_loss_step=0.0107, train_loss_epoch=0.0109] Epoch 183: Train Loss = 0.010683022439479828\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=330, train_loss_step=0.00893, train_loss_epoch=0.0107]Epoch 184: Train Loss = 0.00892519112676382\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=330, train_loss_step=0.0125, train_loss_epoch=0.00893] Epoch 185: Train Loss = 0.012538311071693897\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=330, train_loss_step=0.0112, train_loss_epoch=0.0125] Epoch 186: Train Loss = 0.011151586659252644\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.0112]Epoch 187: Train Loss = 0.010810007341206074\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0108]Epoch 188: Train Loss = 0.010910655371844769\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=330, train_loss_step=0.0118, train_loss_epoch=0.0109]Epoch 189: Train Loss = 0.011770649813115597\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=330, train_loss_step=0.0138, train_loss_epoch=0.0118]Epoch 190: Train Loss = 0.013829812407493591\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0138]Epoch 191: Train Loss = 0.010230577550828457\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=330, train_loss_step=0.0124, train_loss_epoch=0.0102]Epoch 192: Train Loss = 0.012362958863377571\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0124]Epoch 193: Train Loss = 0.010888585820794106\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=330, train_loss_step=0.00771, train_loss_epoch=0.0109]Epoch 194: Train Loss = 0.007710595615208149\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=330, train_loss_step=0.00959, train_loss_epoch=0.00771]Epoch 195: Train Loss = 0.009590229950845242\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=330, train_loss_step=0.00875, train_loss_epoch=0.00959]Epoch 196: Train Loss = 0.008751637302339077\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.00875]  Epoch 197: Train Loss = 0.010007195174694061\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=330, train_loss_step=0.013, train_loss_epoch=0.010]  Epoch 198: Train Loss = 0.012984671629965305\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=330, train_loss_step=0.0118, train_loss_epoch=0.013]Epoch 199: Train Loss = 0.011837326921522617\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.0118]Epoch 200: Train Loss = 0.01075023878365755\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=330, train_loss_step=0.0103, train_loss_epoch=0.0108]Epoch 201: Train Loss = 0.01033136248588562\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=330, train_loss_step=0.0137, train_loss_epoch=0.0103]Epoch 202: Train Loss = 0.013678910210728645\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s, v_num=330, train_loss_step=0.00924, train_loss_epoch=0.0137]Epoch 203: Train Loss = 0.009244791232049465\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=330, train_loss_step=0.00934, train_loss_epoch=0.00924]Epoch 204: Train Loss = 0.009336233139038086\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=330, train_loss_step=0.00906, train_loss_epoch=0.00934]Epoch 205: Train Loss = 0.009057135321199894\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=330, train_loss_step=0.013, train_loss_epoch=0.00906]  Epoch 206: Train Loss = 0.012960937805473804\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=330, train_loss_step=0.00826, train_loss_epoch=0.013]Epoch 207: Train Loss = 0.008257992565631866\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=330, train_loss_step=0.00963, train_loss_epoch=0.00826]Epoch 208: Train Loss = 0.009632783941924572\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=330, train_loss_step=0.00946, train_loss_epoch=0.00963]Epoch 209: Train Loss = 0.009462990798056126\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.00946] Epoch 210: Train Loss = 0.011557355523109436\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=330, train_loss_step=0.0133, train_loss_epoch=0.0116] Epoch 211: Train Loss = 0.013344347476959229\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.0133] Epoch 212: Train Loss = 0.010031372308731079\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.010]Epoch 213: Train Loss = 0.01058857049793005\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0106]Epoch 214: Train Loss = 0.010853086598217487\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=330, train_loss_step=0.0129, train_loss_epoch=0.0109]Epoch 215: Train Loss = 0.012883675284683704\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0129]Epoch 216: Train Loss = 0.010204051621258259\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=330, train_loss_step=0.0151, train_loss_epoch=0.0102]Epoch 217: Train Loss = 0.015052737668156624\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0151]Epoch 218: Train Loss = 0.01018806267529726\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=330, train_loss_step=0.00935, train_loss_epoch=0.0102]Epoch 219: Train Loss = 0.009349795989692211\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=330, train_loss_step=0.0143, train_loss_epoch=0.00935] Epoch 220: Train Loss = 0.014268872328102589\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=330, train_loss_step=0.0097, train_loss_epoch=0.0143] Epoch 221: Train Loss = 0.009700467810034752\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=330, train_loss_step=0.0118, train_loss_epoch=0.0097]Epoch 222: Train Loss = 0.011792980134487152\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=330, train_loss_step=0.00987, train_loss_epoch=0.0118]Epoch 223: Train Loss = 0.009870843961834908\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=330, train_loss_step=0.0126, train_loss_epoch=0.00987] Epoch 224: Train Loss = 0.012600505724549294\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=330, train_loss_step=0.0138, train_loss_epoch=0.0126] Epoch 225: Train Loss = 0.013845047913491726\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.0138]Epoch 226: Train Loss = 0.01134573481976986\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s, v_num=330, train_loss_step=0.00898, train_loss_epoch=0.0113]Epoch 227: Train Loss = 0.008978993631899357\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.00898] Epoch 228: Train Loss = 0.010181027464568615\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=330, train_loss_step=0.0105, train_loss_epoch=0.0102] Epoch 229: Train Loss = 0.010540510527789593\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0105]Epoch 230: Train Loss = 0.010187797248363495\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=330, train_loss_step=0.0103, train_loss_epoch=0.0102]Epoch 231: Train Loss = 0.010346810333430767\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=330, train_loss_step=0.00945, train_loss_epoch=0.0103]Epoch 232: Train Loss = 0.009449010714888573\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=330, train_loss_step=0.0086, train_loss_epoch=0.00945] Epoch 233: Train Loss = 0.008596453815698624\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=330, train_loss_step=0.00916, train_loss_epoch=0.0086]Epoch 234: Train Loss = 0.009160223416984081\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=330, train_loss_step=0.0104, train_loss_epoch=0.00916] Epoch 235: Train Loss = 0.010355645790696144\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=330, train_loss_step=0.0112, train_loss_epoch=0.0104] Epoch 236: Train Loss = 0.011151932179927826\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=330, train_loss_step=0.0138, train_loss_epoch=0.0112]Epoch 237: Train Loss = 0.013844797387719154\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=330, train_loss_step=0.0118, train_loss_epoch=0.0138]Epoch 238: Train Loss = 0.01177430059760809\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s, v_num=330, train_loss_step=0.0129, train_loss_epoch=0.0118]Epoch 239: Train Loss = 0.012914838269352913\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=330, train_loss_step=0.0129, train_loss_epoch=0.0129]Epoch 240: Train Loss = 0.012884465977549553\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.0129]Epoch 241: Train Loss = 0.011297164484858513\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.0113] Epoch 242: Train Loss = 0.011025004088878632\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=330, train_loss_step=0.0132, train_loss_epoch=0.011]Epoch 243: Train Loss = 0.01317664422094822\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s, v_num=330, train_loss_step=0.0121, train_loss_epoch=0.0132]Epoch 244: Train Loss = 0.012109006755053997\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.0121]Epoch 245: Train Loss = 0.011438061483204365\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=330, train_loss_step=0.00801, train_loss_epoch=0.0114]Epoch 246: Train Loss = 0.008012997917830944\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=330, train_loss_step=0.00987, train_loss_epoch=0.00801]Epoch 247: Train Loss = 0.009871979244053364\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=330, train_loss_step=0.00953, train_loss_epoch=0.00987]Epoch 248: Train Loss = 0.009534860961139202\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=330, train_loss_step=0.0123, train_loss_epoch=0.00953] Epoch 249: Train Loss = 0.0122870784252882\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=330, train_loss_step=0.0111, train_loss_epoch=0.0123] Epoch 250: Train Loss = 0.01111256517469883\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=330, train_loss_step=0.0124, train_loss_epoch=0.0111]Epoch 251: Train Loss = 0.012385502457618713\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=330, train_loss_step=0.00741, train_loss_epoch=0.0124]Epoch 252: Train Loss = 0.007405223790556192\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=330, train_loss_step=0.00896, train_loss_epoch=0.00741]Epoch 253: Train Loss = 0.008960050530731678\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.00896] Epoch 254: Train Loss = 0.010917345061898232\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=330, train_loss_step=0.0117, train_loss_epoch=0.0109] Epoch 255: Train Loss = 0.011674067005515099\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.0117]Epoch 256: Train Loss = 0.010578748770058155\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=330, train_loss_step=0.00805, train_loss_epoch=0.0106]Epoch 257: Train Loss = 0.008050164207816124\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=330, train_loss_step=0.00998, train_loss_epoch=0.00805]Epoch 258: Train Loss = 0.009975343942642212\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=330, train_loss_step=0.0107, train_loss_epoch=0.00998] Epoch 259: Train Loss = 0.010710999369621277\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.0107] Epoch 260: Train Loss = 0.010584691539406776\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.0106]Epoch 261: Train Loss = 0.011378922499716282\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=330, train_loss_step=0.00953, train_loss_epoch=0.0114]Epoch 262: Train Loss = 0.009526756592094898\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=330, train_loss_step=0.00892, train_loss_epoch=0.00953]Epoch 263: Train Loss = 0.008924094028770924\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=330, train_loss_step=0.0117, train_loss_epoch=0.00892] Epoch 264: Train Loss = 0.01165279932320118\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.0117] Epoch 265: Train Loss = 0.010788661427795887\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=330, train_loss_step=0.0104, train_loss_epoch=0.0108]Epoch 266: Train Loss = 0.010409831069409847\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=330, train_loss_step=0.00782, train_loss_epoch=0.0104]Epoch 267: Train Loss = 0.007819375023245811\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=330, train_loss_step=0.0128, train_loss_epoch=0.00782] Epoch 268: Train Loss = 0.012774331495165825\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0128] Epoch 269: Train Loss = 0.010928018018603325\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=330, train_loss_step=0.0128, train_loss_epoch=0.0109]Epoch 270: Train Loss = 0.012790138833224773\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.0128]Epoch 271: Train Loss = 0.011265735141932964\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0113]Epoch 272: Train Loss = 0.010934822261333466\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=330, train_loss_step=0.0105, train_loss_epoch=0.0109]Epoch 273: Train Loss = 0.010457529686391354\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=330, train_loss_step=0.0079, train_loss_epoch=0.0105]Epoch 274: Train Loss = 0.007895569317042828\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=330, train_loss_step=0.0133, train_loss_epoch=0.0079]Epoch 275: Train Loss = 0.013277767226099968\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=330, train_loss_step=0.0125, train_loss_epoch=0.0133]Epoch 276: Train Loss = 0.012544532306492329\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.0125]Epoch 277: Train Loss = 0.010567933320999146\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=330, train_loss_step=0.0107, train_loss_epoch=0.0106]Epoch 278: Train Loss = 0.010684930719435215\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=330, train_loss_step=0.0131, train_loss_epoch=0.0107]Epoch 279: Train Loss = 0.013106807135045528\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=330, train_loss_step=0.0112, train_loss_epoch=0.0131]Epoch 280: Train Loss = 0.011183954775333405\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=330, train_loss_step=0.00882, train_loss_epoch=0.0112]Epoch 281: Train Loss = 0.008823796175420284\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.00882] Epoch 282: Train Loss = 0.01126125454902649\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=330, train_loss_step=0.00967, train_loss_epoch=0.0113]Epoch 283: Train Loss = 0.009671472012996674\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=330, train_loss_step=0.0104, train_loss_epoch=0.00967] Epoch 284: Train Loss = 0.010396851226687431\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=330, train_loss_step=0.00991, train_loss_epoch=0.0104]Epoch 285: Train Loss = 0.009907839819788933\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.00991] Epoch 286: Train Loss = 0.010561165399849415\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=330, train_loss_step=0.0126, train_loss_epoch=0.0106] Epoch 287: Train Loss = 0.012585803866386414\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0126]Epoch 288: Train Loss = 0.010196029208600521\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=330, train_loss_step=0.00914, train_loss_epoch=0.0102]Epoch 289: Train Loss = 0.009143219329416752\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.00914] Epoch 290: Train Loss = 0.011588511988520622\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=330, train_loss_step=0.0121, train_loss_epoch=0.0116] Epoch 291: Train Loss = 0.012052617967128754\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.0121]Epoch 292: Train Loss = 0.010769650340080261\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=330, train_loss_step=0.0103, train_loss_epoch=0.0108]Epoch 293: Train Loss = 0.010289544239640236\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=330, train_loss_step=0.00988, train_loss_epoch=0.0103]Epoch 294: Train Loss = 0.009883365593850613\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=330, train_loss_step=0.00948, train_loss_epoch=0.00988]Epoch 295: Train Loss = 0.00947610568255186\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=330, train_loss_step=0.00932, train_loss_epoch=0.00948]Epoch 296: Train Loss = 0.00931779108941555\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=330, train_loss_step=0.0111, train_loss_epoch=0.00932] Epoch 297: Train Loss = 0.011127209290862083\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.0111]  Epoch 298: Train Loss = 0.01100747287273407\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=330, train_loss_step=0.00966, train_loss_epoch=0.011]Epoch 299: Train Loss = 0.00966485682874918\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=330, train_loss_step=0.00754, train_loss_epoch=0.00966]Epoch 300: Train Loss = 0.007540643215179443\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=330, train_loss_step=0.0112, train_loss_epoch=0.00754] Epoch 301: Train Loss = 0.011220027692615986\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=330, train_loss_step=0.0111, train_loss_epoch=0.0112] Epoch 302: Train Loss = 0.011083641089498997\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=330, train_loss_step=0.0094, train_loss_epoch=0.0111]Epoch 303: Train Loss = 0.009402116760611534\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=330, train_loss_step=0.00921, train_loss_epoch=0.0094]Epoch 304: Train Loss = 0.00920984148979187\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s, v_num=330, train_loss_step=0.0103, train_loss_epoch=0.00921] Epoch 305: Train Loss = 0.010296200402081013\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=330, train_loss_step=0.00966, train_loss_epoch=0.0103]Epoch 306: Train Loss = 0.00965943094342947\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=330, train_loss_step=0.0147, train_loss_epoch=0.00966] Epoch 307: Train Loss = 0.014740307815372944\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=330, train_loss_step=0.0122, train_loss_epoch=0.0147] Epoch 308: Train Loss = 0.01217044610530138\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=330, train_loss_step=0.00923, train_loss_epoch=0.0122]Epoch 309: Train Loss = 0.009228033944964409\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=330, train_loss_step=0.00766, train_loss_epoch=0.00923]Epoch 310: Train Loss = 0.007658610586076975\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=330, train_loss_step=0.0119, train_loss_epoch=0.00766] Epoch 311: Train Loss = 0.011881324462592602\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.0119] Epoch 312: Train Loss = 0.011406895704567432\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=330, train_loss_step=0.0132, train_loss_epoch=0.0114]Epoch 313: Train Loss = 0.013217230327427387\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=330, train_loss_step=0.00838, train_loss_epoch=0.0132]Epoch 314: Train Loss = 0.00838490016758442\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=330, train_loss_step=0.0131, train_loss_epoch=0.00838] Epoch 315: Train Loss = 0.013106956146657467\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=330, train_loss_step=0.00992, train_loss_epoch=0.0131]Epoch 316: Train Loss = 0.009923717007040977\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.00992] Epoch 317: Train Loss = 0.011368502862751484\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=330, train_loss_step=0.0104, train_loss_epoch=0.0114] Epoch 318: Train Loss = 0.010368755087256432\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=330, train_loss_step=0.0103, train_loss_epoch=0.0104]Epoch 319: Train Loss = 0.01029774360358715\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=330, train_loss_step=0.00961, train_loss_epoch=0.0103]Epoch 320: Train Loss = 0.009607850573956966\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=330, train_loss_step=0.0124, train_loss_epoch=0.00961] Epoch 321: Train Loss = 0.012366039678454399\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s, v_num=330, train_loss_step=0.0128, train_loss_epoch=0.0124] Epoch 322: Train Loss = 0.012812403962016106\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=330, train_loss_step=0.0137, train_loss_epoch=0.0128]Epoch 323: Train Loss = 0.013703805394470692\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=330, train_loss_step=0.00885, train_loss_epoch=0.0137]Epoch 324: Train Loss = 0.008853117004036903\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=330, train_loss_step=0.0129, train_loss_epoch=0.00885] Epoch 325: Train Loss = 0.01292414776980877\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=330, train_loss_step=0.0136, train_loss_epoch=0.0129] Epoch 326: Train Loss = 0.01355011761188507\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0136]Epoch 327: Train Loss = 0.010857214219868183\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.0109]Epoch 328: Train Loss = 0.011567605659365654\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=330, train_loss_step=0.00889, train_loss_epoch=0.0116]Epoch 329: Train Loss = 0.008891197852790356\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=330, train_loss_step=0.0147, train_loss_epoch=0.00889] Epoch 330: Train Loss = 0.014734750613570213\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.0147] Epoch 331: Train Loss = 0.01141135860234499\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.0114]Epoch 332: Train Loss = 0.011313567869365215\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=330, train_loss_step=0.0095, train_loss_epoch=0.0113]Epoch 333: Train Loss = 0.009500709362328053\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=330, train_loss_step=0.00932, train_loss_epoch=0.0095]Epoch 334: Train Loss = 0.009318651631474495\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=330, train_loss_step=0.0105, train_loss_epoch=0.00932] Epoch 335: Train Loss = 0.01049100048840046\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=330, train_loss_step=0.0124, train_loss_epoch=0.0105] Epoch 336: Train Loss = 0.012381096370518208\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=330, train_loss_step=0.00899, train_loss_epoch=0.0124]Epoch 337: Train Loss = 0.008991054259240627\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=330, train_loss_step=0.00979, train_loss_epoch=0.00899]Epoch 338: Train Loss = 0.009785101749002934\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.00979] Epoch 339: Train Loss = 0.01089086476713419\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=330, train_loss_step=0.0121, train_loss_epoch=0.0109] Epoch 340: Train Loss = 0.012129982002079487\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0121]Epoch 341: Train Loss = 0.010223443619906902\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=330, train_loss_step=0.0118, train_loss_epoch=0.0102]Epoch 342: Train Loss = 0.011764930561184883\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s, v_num=330, train_loss_step=0.00926, train_loss_epoch=0.0118]Epoch 343: Train Loss = 0.009259977377951145\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=330, train_loss_step=0.00925, train_loss_epoch=0.00926]Epoch 344: Train Loss = 0.00924829114228487\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.00925]  Epoch 345: Train Loss = 0.011033495888113976\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=330, train_loss_step=0.00724, train_loss_epoch=0.011]Epoch 346: Train Loss = 0.007235056255012751\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=330, train_loss_step=0.0143, train_loss_epoch=0.00724] Epoch 347: Train Loss = 0.014259455725550652\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=330, train_loss_step=0.0095, train_loss_epoch=0.0143] Epoch 348: Train Loss = 0.009499287232756615\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=330, train_loss_step=0.00965, train_loss_epoch=0.0095]Epoch 349: Train Loss = 0.009645482525229454\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=330, train_loss_step=0.0111, train_loss_epoch=0.00965] Epoch 350: Train Loss = 0.011096721515059471\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.0111] Epoch 351: Train Loss = 0.010633559897542\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.0106]Epoch 352: Train Loss = 0.01142553985118866\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=330, train_loss_step=0.00887, train_loss_epoch=0.0114]Epoch 353: Train Loss = 0.008869140408933163\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.00887] Epoch 354: Train Loss = 0.01076941005885601\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0108] Epoch 355: Train Loss = 0.010165122337639332\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=330, train_loss_step=0.00978, train_loss_epoch=0.0102]Epoch 356: Train Loss = 0.009784051217138767\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=330, train_loss_step=0.0105, train_loss_epoch=0.00978] Epoch 357: Train Loss = 0.010482792742550373\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=330, train_loss_step=0.00791, train_loss_epoch=0.0105]Epoch 358: Train Loss = 0.007905342616140842\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=330, train_loss_step=0.00944, train_loss_epoch=0.00791]Epoch 359: Train Loss = 0.009442688897252083\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=330, train_loss_step=0.00908, train_loss_epoch=0.00944]Epoch 360: Train Loss = 0.009080282412469387\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=330, train_loss_step=0.00809, train_loss_epoch=0.00908]Epoch 361: Train Loss = 0.008085883222520351\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=330, train_loss_step=0.00969, train_loss_epoch=0.00809]Epoch 362: Train Loss = 0.009688409976661205\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.00969] Epoch 363: Train Loss = 0.010876948945224285\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0109] Epoch 364: Train Loss = 0.010927642695605755\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=330, train_loss_step=0.00839, train_loss_epoch=0.0109]Epoch 365: Train Loss = 0.00838776957243681\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=330, train_loss_step=0.00867, train_loss_epoch=0.00839]Epoch 366: Train Loss = 0.008666749112308025\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=330, train_loss_step=0.0125, train_loss_epoch=0.00867] Epoch 367: Train Loss = 0.012529735453426838\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=330, train_loss_step=0.00902, train_loss_epoch=0.0125]Epoch 368: Train Loss = 0.009023628197610378\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.00902] Epoch 369: Train Loss = 0.011630875058472157\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=330, train_loss_step=0.00996, train_loss_epoch=0.0116]Epoch 370: Train Loss = 0.009963887743651867\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.00996] Epoch 371: Train Loss = 0.010619915090501308\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=330, train_loss_step=0.0099, train_loss_epoch=0.0106] Epoch 372: Train Loss = 0.009902605786919594\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=330, train_loss_step=0.00987, train_loss_epoch=0.0099]Epoch 373: Train Loss = 0.00986761786043644\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=330, train_loss_step=0.0105, train_loss_epoch=0.00987] Epoch 374: Train Loss = 0.010537042282521725\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=330, train_loss_step=0.00996, train_loss_epoch=0.0105]Epoch 375: Train Loss = 0.009964121505618095\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.00996] Epoch 376: Train Loss = 0.010202771052718163\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=330, train_loss_step=0.0126, train_loss_epoch=0.0102] Epoch 377: Train Loss = 0.012634809128940105\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=330, train_loss_step=0.0123, train_loss_epoch=0.0126]Epoch 378: Train Loss = 0.012263938784599304\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0123]Epoch 379: Train Loss = 0.010152152739465237\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=330, train_loss_step=0.0154, train_loss_epoch=0.0102]Epoch 380: Train Loss = 0.01543665211647749\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=330, train_loss_step=0.0127, train_loss_epoch=0.0154]Epoch 381: Train Loss = 0.012724957428872585\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=330, train_loss_step=0.00948, train_loss_epoch=0.0127]Epoch 382: Train Loss = 0.009478150866925716\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=330, train_loss_step=0.00959, train_loss_epoch=0.00948]Epoch 383: Train Loss = 0.009588774293661118\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.00959] Epoch 384: Train Loss = 0.01158610824495554\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=330, train_loss_step=0.00981, train_loss_epoch=0.0116]Epoch 385: Train Loss = 0.0098117021843791\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=330, train_loss_step=0.0184, train_loss_epoch=0.00981] Epoch 386: Train Loss = 0.018419358879327774\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s, v_num=330, train_loss_step=0.0103, train_loss_epoch=0.0184] Epoch 387: Train Loss = 0.010333843529224396\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=330, train_loss_step=0.00928, train_loss_epoch=0.0103]Epoch 388: Train Loss = 0.009280593134462833\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.00928] Epoch 389: Train Loss = 0.010642505250871181\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=330, train_loss_step=0.0147, train_loss_epoch=0.0106] Epoch 390: Train Loss = 0.014729971997439861\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=330, train_loss_step=0.00881, train_loss_epoch=0.0147]Epoch 391: Train Loss = 0.008812726475298405\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=330, train_loss_step=0.0129, train_loss_epoch=0.00881] Epoch 392: Train Loss = 0.012923338450491428\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=330, train_loss_step=0.0097, train_loss_epoch=0.0129] Epoch 393: Train Loss = 0.009704952128231525\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.0097]Epoch 394: Train Loss = 0.011330276727676392\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.0113]Epoch 395: Train Loss = 0.011610323563218117\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=330, train_loss_step=0.00836, train_loss_epoch=0.0116]Epoch 396: Train Loss = 0.008357932791113853\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=330, train_loss_step=0.0089, train_loss_epoch=0.00836] Epoch 397: Train Loss = 0.008901330642402172\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=330, train_loss_step=0.0124, train_loss_epoch=0.0089] Epoch 398: Train Loss = 0.012365566566586494\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=330, train_loss_step=0.00922, train_loss_epoch=0.0124]Epoch 399: Train Loss = 0.009218955412507057\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=330, train_loss_step=0.0118, train_loss_epoch=0.00922] Epoch 400: Train Loss = 0.011839321814477444\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=330, train_loss_step=0.00982, train_loss_epoch=0.0118]Epoch 401: Train Loss = 0.009822621941566467\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=330, train_loss_step=0.00786, train_loss_epoch=0.00982]Epoch 402: Train Loss = 0.007862023077905178\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=330, train_loss_step=0.00961, train_loss_epoch=0.00786]Epoch 403: Train Loss = 0.009611441753804684\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=330, train_loss_step=0.00942, train_loss_epoch=0.00961]Epoch 404: Train Loss = 0.009416061453521252\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=330, train_loss_step=0.0126, train_loss_epoch=0.00942] Epoch 405: Train Loss = 0.012574649415910244\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.0126]  Epoch 406: Train Loss = 0.011018695309758186\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=330, train_loss_step=0.00873, train_loss_epoch=0.011]Epoch 407: Train Loss = 0.00873391143977642\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=330, train_loss_step=0.0101, train_loss_epoch=0.00873] Epoch 408: Train Loss = 0.01013944111764431\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=330, train_loss_step=0.0116, train_loss_epoch=0.0101] Epoch 409: Train Loss = 0.011574494652450085\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=330, train_loss_step=0.00825, train_loss_epoch=0.0116]Epoch 410: Train Loss = 0.008253657259047031\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.00825] Epoch 411: Train Loss = 0.010885598137974739\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=330, train_loss_step=0.0118, train_loss_epoch=0.0109] Epoch 412: Train Loss = 0.011798719875514507\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.0118] Epoch 413: Train Loss = 0.01095092948526144\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=330, train_loss_step=0.00983, train_loss_epoch=0.011]Epoch 414: Train Loss = 0.009826323948800564\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=330, train_loss_step=0.0107, train_loss_epoch=0.00983] Epoch 415: Train Loss = 0.010700804181396961\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=330, train_loss_step=0.00647, train_loss_epoch=0.0107]Epoch 416: Train Loss = 0.006472639739513397\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=330, train_loss_step=0.0117, train_loss_epoch=0.00647] Epoch 417: Train Loss = 0.011704018339514732\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0117] Epoch 418: Train Loss = 0.010903515852987766\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=330, train_loss_step=0.00884, train_loss_epoch=0.0109]Epoch 419: Train Loss = 0.008841591887176037\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.00884] Epoch 420: Train Loss = 0.010774752125144005\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=330, train_loss_step=0.00885, train_loss_epoch=0.0108]Epoch 421: Train Loss = 0.008846825920045376\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=330, train_loss_step=0.0108, train_loss_epoch=0.00885] Epoch 422: Train Loss = 0.010763904079794884\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s, v_num=330, train_loss_step=0.00944, train_loss_epoch=0.0108]Epoch 423: Train Loss = 0.009441888891160488\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=330, train_loss_step=0.0119, train_loss_epoch=0.00944] Epoch 424: Train Loss = 0.011893228627741337\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=330, train_loss_step=0.00909, train_loss_epoch=0.0119]Epoch 425: Train Loss = 0.009091118350625038\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=330, train_loss_step=0.008, train_loss_epoch=0.00909]  Epoch 426: Train Loss = 0.007996042259037495\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=330, train_loss_step=0.0137, train_loss_epoch=0.008] Epoch 427: Train Loss = 0.013685116544365883\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=330, train_loss_step=0.00923, train_loss_epoch=0.0137]Epoch 428: Train Loss = 0.009228488430380821\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=330, train_loss_step=0.00874, train_loss_epoch=0.00923]Epoch 429: Train Loss = 0.008742548525333405\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=330, train_loss_step=0.00975, train_loss_epoch=0.00874]Epoch 430: Train Loss = 0.009745443239808083\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=330, train_loss_step=0.00794, train_loss_epoch=0.00975]Epoch 431: Train Loss = 0.007936893962323666\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=330, train_loss_step=0.0118, train_loss_epoch=0.00794] Epoch 432: Train Loss = 0.011816431768238544\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=330, train_loss_step=0.00871, train_loss_epoch=0.0118]Epoch 433: Train Loss = 0.008707286790013313\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=330, train_loss_step=0.00814, train_loss_epoch=0.00871]Epoch 434: Train Loss = 0.008140523917973042\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=330, train_loss_step=0.0081, train_loss_epoch=0.00814] Epoch 435: Train Loss = 0.008099080063402653\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=330, train_loss_step=0.0096, train_loss_epoch=0.0081] Epoch 436: Train Loss = 0.00960308127105236\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=330, train_loss_step=0.00787, train_loss_epoch=0.0096]Epoch 437: Train Loss = 0.007870028726756573\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=330, train_loss_step=0.0089, train_loss_epoch=0.00787] Epoch 438: Train Loss = 0.00889691524207592\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=330, train_loss_step=0.00897, train_loss_epoch=0.0089]Epoch 439: Train Loss = 0.00897187739610672\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=330, train_loss_step=0.0101, train_loss_epoch=0.00897] Epoch 440: Train Loss = 0.010129867121577263\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=330, train_loss_step=0.00955, train_loss_epoch=0.0101]Epoch 441: Train Loss = 0.009554187767207623\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=330, train_loss_step=0.0128, train_loss_epoch=0.00955] Epoch 442: Train Loss = 0.012815641239285469\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=330, train_loss_step=0.0129, train_loss_epoch=0.0128] Epoch 443: Train Loss = 0.012896026484668255\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=330, train_loss_step=0.0105, train_loss_epoch=0.0129]Epoch 444: Train Loss = 0.010464777238667011\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=330, train_loss_step=0.00808, train_loss_epoch=0.0105]Epoch 445: Train Loss = 0.008082592859864235\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=330, train_loss_step=0.00696, train_loss_epoch=0.00808]Epoch 446: Train Loss = 0.006961131934076548\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=330, train_loss_step=0.00997, train_loss_epoch=0.00696]Epoch 447: Train Loss = 0.009970086626708508\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=330, train_loss_step=0.00939, train_loss_epoch=0.00997]Epoch 448: Train Loss = 0.009388096630573273\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.00939] Epoch 449: Train Loss = 0.011341431178152561\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=330, train_loss_step=0.00956, train_loss_epoch=0.0113]Epoch 450: Train Loss = 0.009559949859976768\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=330, train_loss_step=0.00963, train_loss_epoch=0.00956]Epoch 451: Train Loss = 0.009632347151637077\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=330, train_loss_step=0.00702, train_loss_epoch=0.00963]Epoch 452: Train Loss = 0.0070207309909164906\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=330, train_loss_step=0.00808, train_loss_epoch=0.00702]Epoch 453: Train Loss = 0.008076784200966358\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=330, train_loss_step=0.00885, train_loss_epoch=0.00808]Epoch 454: Train Loss = 0.008845777250826359\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=330, train_loss_step=0.0149, train_loss_epoch=0.00885] Epoch 455: Train Loss = 0.01485513336956501\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=330, train_loss_step=0.00958, train_loss_epoch=0.0149]Epoch 456: Train Loss = 0.009580126963555813\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=330, train_loss_step=0.00982, train_loss_epoch=0.00958]Epoch 457: Train Loss = 0.009822140447795391\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=330, train_loss_step=0.00893, train_loss_epoch=0.00982]Epoch 458: Train Loss = 0.008926657028496265\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=330, train_loss_step=0.00855, train_loss_epoch=0.00893]Epoch 459: Train Loss = 0.008549820631742477\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=330, train_loss_step=0.0111, train_loss_epoch=0.00855] Epoch 460: Train Loss = 0.011114528402686119\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0111] Epoch 461: Train Loss = 0.010159309022128582\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=330, train_loss_step=0.00904, train_loss_epoch=0.0102]Epoch 462: Train Loss = 0.009044767357409\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=330, train_loss_step=0.00861, train_loss_epoch=0.00904]Epoch 463: Train Loss = 0.008605548180639744\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=330, train_loss_step=0.00925, train_loss_epoch=0.00861]Epoch 464: Train Loss = 0.009253707714378834\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=330, train_loss_step=0.0133, train_loss_epoch=0.00925] Epoch 465: Train Loss = 0.013283437117934227\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=330, train_loss_step=0.0121, train_loss_epoch=0.0133] Epoch 466: Train Loss = 0.0120814498513937\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=330, train_loss_step=0.0132, train_loss_epoch=0.0121]Epoch 467: Train Loss = 0.013217487372457981\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=330, train_loss_step=0.0127, train_loss_epoch=0.0132]Epoch 468: Train Loss = 0.012676618993282318\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=330, train_loss_step=0.00952, train_loss_epoch=0.0127]Epoch 469: Train Loss = 0.009519594721496105\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=330, train_loss_step=0.0127, train_loss_epoch=0.00952] Epoch 470: Train Loss = 0.012691035866737366\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=330, train_loss_step=0.00764, train_loss_epoch=0.0127]Epoch 471: Train Loss = 0.007640422787517309\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=330, train_loss_step=0.00861, train_loss_epoch=0.00764]Epoch 472: Train Loss = 0.00861426442861557\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=330, train_loss_step=0.0113, train_loss_epoch=0.00861] Epoch 473: Train Loss = 0.011334513314068317\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.0113] Epoch 474: Train Loss = 0.011359719559550285\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0114]Epoch 475: Train Loss = 0.01020541787147522\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=330, train_loss_step=0.0102, train_loss_epoch=0.0102]Epoch 476: Train Loss = 0.010217957198619843\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=330, train_loss_step=0.00934, train_loss_epoch=0.0102]Epoch 477: Train Loss = 0.00934389978647232\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=330, train_loss_step=0.00962, train_loss_epoch=0.00934]Epoch 478: Train Loss = 0.00961980875581503\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s, v_num=330, train_loss_step=0.00945, train_loss_epoch=0.00962]Epoch 479: Train Loss = 0.009453595615923405\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=330, train_loss_step=0.00801, train_loss_epoch=0.00945]Epoch 480: Train Loss = 0.00801082793623209\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=330, train_loss_step=0.00831, train_loss_epoch=0.00801]Epoch 481: Train Loss = 0.008306678384542465\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=330, train_loss_step=0.00904, train_loss_epoch=0.00831]Epoch 482: Train Loss = 0.009037748910486698\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=330, train_loss_step=0.0112, train_loss_epoch=0.00904] Epoch 483: Train Loss = 0.011212396435439587\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=330, train_loss_step=0.0082, train_loss_epoch=0.0112] Epoch 484: Train Loss = 0.008196758106350899\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=330, train_loss_step=0.0107, train_loss_epoch=0.0082]Epoch 485: Train Loss = 0.010749922133982182\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=330, train_loss_step=0.0114, train_loss_epoch=0.0107]Epoch 486: Train Loss = 0.011395546607673168\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=330, train_loss_step=0.00917, train_loss_epoch=0.0114]Epoch 487: Train Loss = 0.009165509603917599\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=330, train_loss_step=0.00995, train_loss_epoch=0.00917]Epoch 488: Train Loss = 0.0099534522742033\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=330, train_loss_step=0.00912, train_loss_epoch=0.00995]Epoch 489: Train Loss = 0.009122079238295555\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.00912] Epoch 490: Train Loss = 0.010869256220757961\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=330, train_loss_step=0.0106, train_loss_epoch=0.0109] Epoch 491: Train Loss = 0.010621139779686928\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=330, train_loss_step=0.0072, train_loss_epoch=0.0106]Epoch 492: Train Loss = 0.007203310262411833\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.0072] Epoch 493: Train Loss = 0.010042736306786537\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=330, train_loss_step=0.010, train_loss_epoch=0.010] Epoch 494: Train Loss = 0.010047410614788532\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=330, train_loss_step=0.0146, train_loss_epoch=0.010]Epoch 495: Train Loss = 0.014611968770623207\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=330, train_loss_step=0.0146, train_loss_epoch=0.0146]Epoch 496: Train Loss = 0.014643780887126923\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=330, train_loss_step=0.0139, train_loss_epoch=0.0146]Epoch 497: Train Loss = 0.013916967436671257\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=330, train_loss_step=0.0109, train_loss_epoch=0.0139]Epoch 498: Train Loss = 0.010863350704312325\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.0109] Epoch 499: Train Loss = 0.011005451902747154\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.011] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=330, train_loss_step=0.011, train_loss_epoch=0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.89it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 4: from 2008-05-12 00:00:00 to 2022-07-29 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=334, train_loss_step=0.0237]Epoch 0: Train Loss = 0.023711781948804855\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=334, train_loss_step=0.0385, train_loss_epoch=0.0237]Epoch 1: Train Loss = 0.038453638553619385\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=334, train_loss_step=0.0363, train_loss_epoch=0.0385]Epoch 2: Train Loss = 0.03634501248598099\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=334, train_loss_step=0.0257, train_loss_epoch=0.0363]Epoch 3: Train Loss = 0.025723924860358238\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=334, train_loss_step=0.0195, train_loss_epoch=0.0257]Epoch 4: Train Loss = 0.0195403341203928\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=334, train_loss_step=0.0212, train_loss_epoch=0.0195]Epoch 5: Train Loss = 0.021244065836071968\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=334, train_loss_step=0.0167, train_loss_epoch=0.0212]Epoch 6: Train Loss = 0.01668763905763626\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=334, train_loss_step=0.0136, train_loss_epoch=0.0167]Epoch 7: Train Loss = 0.013582714833319187\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=334, train_loss_step=0.0157, train_loss_epoch=0.0136]Epoch 8: Train Loss = 0.015669744461774826\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=334, train_loss_step=0.0144, train_loss_epoch=0.0157]Epoch 9: Train Loss = 0.014380581676959991\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=334, train_loss_step=0.0138, train_loss_epoch=0.0144]Epoch 10: Train Loss = 0.013844701461493969\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s, v_num=334, train_loss_step=0.0142, train_loss_epoch=0.0138]Epoch 11: Train Loss = 0.014239640906453133\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=334, train_loss_step=0.0167, train_loss_epoch=0.0142]Epoch 12: Train Loss = 0.016721906140446663\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=334, train_loss_step=0.0157, train_loss_epoch=0.0167]Epoch 13: Train Loss = 0.015672020614147186\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=334, train_loss_step=0.0144, train_loss_epoch=0.0157]Epoch 14: Train Loss = 0.014372122474014759\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.0144]Epoch 15: Train Loss = 0.01167070958763361\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=334, train_loss_step=0.0171, train_loss_epoch=0.0117]Epoch 16: Train Loss = 0.01709633693099022\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=334, train_loss_step=0.013, train_loss_epoch=0.0171] Epoch 17: Train Loss = 0.013043800368905067\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=334, train_loss_step=0.0139, train_loss_epoch=0.013]Epoch 18: Train Loss = 0.01389986090362072\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=334, train_loss_step=0.0134, train_loss_epoch=0.0139]Epoch 19: Train Loss = 0.013369672000408173\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=334, train_loss_step=0.0134, train_loss_epoch=0.0134]Epoch 20: Train Loss = 0.013411219231784344\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.0134]Epoch 21: Train Loss = 0.010523040778934956\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=334, train_loss_step=0.0124, train_loss_epoch=0.0105]Epoch 22: Train Loss = 0.01238346565514803\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=334, train_loss_step=0.0144, train_loss_epoch=0.0124]Epoch 23: Train Loss = 0.014355550520122051\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=334, train_loss_step=0.0131, train_loss_epoch=0.0144]Epoch 24: Train Loss = 0.01311598252505064\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=334, train_loss_step=0.015, train_loss_epoch=0.0131] Epoch 25: Train Loss = 0.015006947331130505\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=334, train_loss_step=0.0139, train_loss_epoch=0.015]Epoch 26: Train Loss = 0.013860412873327732\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.0139]Epoch 27: Train Loss = 0.010456745512783527\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=334, train_loss_step=0.00998, train_loss_epoch=0.0105]Epoch 28: Train Loss = 0.00997920986264944\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.00998] Epoch 29: Train Loss = 0.011408641003072262\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.0114] Epoch 30: Train Loss = 0.01062623132020235\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=334, train_loss_step=0.0146, train_loss_epoch=0.0106]Epoch 31: Train Loss = 0.014561708085238934\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=334, train_loss_step=0.0135, train_loss_epoch=0.0146]Epoch 32: Train Loss = 0.013476709835231304\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=334, train_loss_step=0.00967, train_loss_epoch=0.0135]Epoch 33: Train Loss = 0.009666784666478634\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=334, train_loss_step=0.0157, train_loss_epoch=0.00967] Epoch 34: Train Loss = 0.015668293461203575\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.0157] Epoch 35: Train Loss = 0.012061967514455318\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=334, train_loss_step=0.0166, train_loss_epoch=0.0121]Epoch 36: Train Loss = 0.01660659722983837\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=334, train_loss_step=0.0139, train_loss_epoch=0.0166]Epoch 37: Train Loss = 0.013939360156655312\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=334, train_loss_step=0.0108, train_loss_epoch=0.0139]Epoch 38: Train Loss = 0.010774107649922371\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.0108] Epoch 39: Train Loss = 0.010010969825088978\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=334, train_loss_step=0.0104, train_loss_epoch=0.010]Epoch 40: Train Loss = 0.010388228110969067\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=334, train_loss_step=0.00997, train_loss_epoch=0.0104]Epoch 41: Train Loss = 0.009967529214918613\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=334, train_loss_step=0.0113, train_loss_epoch=0.00997] Epoch 42: Train Loss = 0.011268122121691704\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.0113] Epoch 43: Train Loss = 0.010529810562729836\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.0105]Epoch 44: Train Loss = 0.011136523447930813\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 10.51it/s, v_num=334, train_loss_step=0.0113, train_loss_epoch=0.0111]Epoch 45: Train Loss = 0.011264007538557053\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.0113]Epoch 46: Train Loss = 0.01167868822813034\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.0117]Epoch 47: Train Loss = 0.010120658203959465\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=334, train_loss_step=0.0192, train_loss_epoch=0.0101]Epoch 48: Train Loss = 0.019175905734300613\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=334, train_loss_step=0.00941, train_loss_epoch=0.0192]Epoch 49: Train Loss = 0.009405383840203285\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=334, train_loss_step=0.00907, train_loss_epoch=0.00941]Epoch 50: Train Loss = 0.00906929187476635\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=334, train_loss_step=0.00961, train_loss_epoch=0.00907]Epoch 51: Train Loss = 0.00961369276046753\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=334, train_loss_step=0.0108, train_loss_epoch=0.00961] Epoch 52: Train Loss = 0.010778761468827724\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=334, train_loss_step=0.0168, train_loss_epoch=0.0108] Epoch 53: Train Loss = 0.016801904886960983\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.0168]Epoch 54: Train Loss = 0.01028689555823803\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=334, train_loss_step=0.011, train_loss_epoch=0.0103] Epoch 55: Train Loss = 0.010950090363621712\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=334, train_loss_step=0.012, train_loss_epoch=0.011] Epoch 56: Train Loss = 0.01200962346047163\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=334, train_loss_step=0.00879, train_loss_epoch=0.012]Epoch 57: Train Loss = 0.008790403604507446\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=334, train_loss_step=0.009, train_loss_epoch=0.00879]  Epoch 58: Train Loss = 0.008995375595986843\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=334, train_loss_step=0.00946, train_loss_epoch=0.009]Epoch 59: Train Loss = 0.009459844790399075\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=334, train_loss_step=0.00993, train_loss_epoch=0.00946]Epoch 60: Train Loss = 0.009927675127983093\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=334, train_loss_step=0.00707, train_loss_epoch=0.00993]Epoch 61: Train Loss = 0.00706635182723403\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=334, train_loss_step=0.0145, train_loss_epoch=0.00707] Epoch 62: Train Loss = 0.014517560601234436\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=334, train_loss_step=0.0102, train_loss_epoch=0.0145] Epoch 63: Train Loss = 0.0101613225415349\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.0102]Epoch 64: Train Loss = 0.011568154208362103\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=334, train_loss_step=0.012, train_loss_epoch=0.0116] Epoch 65: Train Loss = 0.011964069679379463\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=334, train_loss_step=0.00837, train_loss_epoch=0.012]Epoch 66: Train Loss = 0.008366492576897144\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=334, train_loss_step=0.0139, train_loss_epoch=0.00837] Epoch 67: Train Loss = 0.013873353600502014\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=334, train_loss_step=0.0119, train_loss_epoch=0.0139] Epoch 68: Train Loss = 0.01189421396702528\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=334, train_loss_step=0.0107, train_loss_epoch=0.0119]Epoch 69: Train Loss = 0.010666840709745884\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=334, train_loss_step=0.00994, train_loss_epoch=0.0107]Epoch 70: Train Loss = 0.009938851930201054\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.00994] Epoch 71: Train Loss = 0.01029584463685751\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=334, train_loss_step=0.0151, train_loss_epoch=0.0103] Epoch 72: Train Loss = 0.015077675692737103\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=334, train_loss_step=0.00977, train_loss_epoch=0.0151]Epoch 73: Train Loss = 0.009773819707334042\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.00977] Epoch 74: Train Loss = 0.01144549809396267\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.0114] Epoch 75: Train Loss = 0.012111330404877663\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.0121] Epoch 76: Train Loss = 0.010018047876656055\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=334, train_loss_step=0.012, train_loss_epoch=0.010] Epoch 77: Train Loss = 0.012005927041172981\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=334, train_loss_step=0.00961, train_loss_epoch=0.012]Epoch 78: Train Loss = 0.009608589112758636\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=334, train_loss_step=0.00883, train_loss_epoch=0.00961]Epoch 79: Train Loss = 0.00882713496685028\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=334, train_loss_step=0.0102, train_loss_epoch=0.00883] Epoch 80: Train Loss = 0.010219225659966469\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=334, train_loss_step=0.00981, train_loss_epoch=0.0102]Epoch 81: Train Loss = 0.009813458658754826\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.00981] Epoch 82: Train Loss = 0.011755700223147869\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s, v_num=334, train_loss_step=0.0131, train_loss_epoch=0.0118] Epoch 83: Train Loss = 0.013132289983332157\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=334, train_loss_step=0.00958, train_loss_epoch=0.0131]Epoch 84: Train Loss = 0.00958335306495428\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=334, train_loss_step=0.0134, train_loss_epoch=0.00958] Epoch 85: Train Loss = 0.013372985646128654\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=334, train_loss_step=0.0148, train_loss_epoch=0.0134] Epoch 86: Train Loss = 0.014843178912997246\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.0148]Epoch 87: Train Loss = 0.010506181977689266\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=334, train_loss_step=0.0166, train_loss_epoch=0.0105]Epoch 88: Train Loss = 0.01663202978670597\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=334, train_loss_step=0.0139, train_loss_epoch=0.0166]Epoch 89: Train Loss = 0.013889218680560589\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=334, train_loss_step=0.0185, train_loss_epoch=0.0139]Epoch 90: Train Loss = 0.018466081470251083\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=334, train_loss_step=0.00927, train_loss_epoch=0.0185]Epoch 91: Train Loss = 0.009273002855479717\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.00927] Epoch 92: Train Loss = 0.01139974594116211\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=334, train_loss_step=0.0129, train_loss_epoch=0.0114] Epoch 93: Train Loss = 0.012949543073773384\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.0129]Epoch 94: Train Loss = 0.010126849636435509\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=334, train_loss_step=0.0142, train_loss_epoch=0.0101]Epoch 95: Train Loss = 0.014164106920361519\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=334, train_loss_step=0.0122, train_loss_epoch=0.0142]Epoch 96: Train Loss = 0.01223087776452303\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=334, train_loss_step=0.012, train_loss_epoch=0.0122] Epoch 97: Train Loss = 0.011956389993429184\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=334, train_loss_step=0.0133, train_loss_epoch=0.012]Epoch 98: Train Loss = 0.013318996876478195\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.0133]Epoch 99: Train Loss = 0.011132398620247841\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=334, train_loss_step=0.0136, train_loss_epoch=0.0111]Epoch 100: Train Loss = 0.0136271296069026\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.0136]Epoch 101: Train Loss = 0.010527104139328003\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=334, train_loss_step=0.0136, train_loss_epoch=0.0105]Epoch 102: Train Loss = 0.013562372885644436\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=334, train_loss_step=0.0124, train_loss_epoch=0.0136]Epoch 103: Train Loss = 0.012398138642311096\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=334, train_loss_step=0.0184, train_loss_epoch=0.0124]Epoch 104: Train Loss = 0.018412593752145767\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.0184]Epoch 105: Train Loss = 0.01135351974517107\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.0114]Epoch 106: Train Loss = 0.012054024264216423\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=334, train_loss_step=0.00911, train_loss_epoch=0.0121]Epoch 107: Train Loss = 0.00910788495093584\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=334, train_loss_step=0.0102, train_loss_epoch=0.00911] Epoch 108: Train Loss = 0.010217085480690002\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=334, train_loss_step=0.00919, train_loss_epoch=0.0102]Epoch 109: Train Loss = 0.00919476617127657\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=334, train_loss_step=0.0155, train_loss_epoch=0.00919] Epoch 110: Train Loss = 0.01545181218534708\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  3.46it/s, v_num=334, train_loss_step=0.0097, train_loss_epoch=0.0155] Epoch 111: Train Loss = 0.009700671769678593\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.0097]Epoch 112: Train Loss = 0.011586514301598072\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s, v_num=334, train_loss_step=0.00904, train_loss_epoch=0.0116]Epoch 113: Train Loss = 0.009041821584105492\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.00904] Epoch 114: Train Loss = 0.010287946090102196\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=334, train_loss_step=0.0107, train_loss_epoch=0.0103] Epoch 115: Train Loss = 0.01070981752127409\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=334, train_loss_step=0.0123, train_loss_epoch=0.0107]Epoch 116: Train Loss = 0.012279684655368328\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.0123]Epoch 117: Train Loss = 0.011684967204928398\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.0117]Epoch 118: Train Loss = 0.010630369186401367\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.0106]Epoch 119: Train Loss = 0.011847494170069695\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=334, train_loss_step=0.011, train_loss_epoch=0.0118] Epoch 120: Train Loss = 0.010962569154798985\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.011]Epoch 121: Train Loss = 0.01059808675199747\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.0106]Epoch 122: Train Loss = 0.010058573447167873\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=334, train_loss_step=0.0122, train_loss_epoch=0.0101]Epoch 123: Train Loss = 0.012229040265083313\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=334, train_loss_step=0.00838, train_loss_epoch=0.0122]Epoch 124: Train Loss = 0.008377520367503166\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=334, train_loss_step=0.0132, train_loss_epoch=0.00838] Epoch 125: Train Loss = 0.01317988894879818\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, v_num=334, train_loss_step=0.00919, train_loss_epoch=0.0132]Epoch 126: Train Loss = 0.009185063652694225\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.00919] Epoch 127: Train Loss = 0.010460468009114265\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.0105] Epoch 128: Train Loss = 0.011374657042324543\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=334, train_loss_step=0.0102, train_loss_epoch=0.0114]Epoch 129: Train Loss = 0.010195111855864525\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.0102]Epoch 130: Train Loss = 0.011643758043646812\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s, v_num=334, train_loss_step=0.0122, train_loss_epoch=0.0116]Epoch 131: Train Loss = 0.012182846665382385\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.0122]Epoch 132: Train Loss = 0.011671893298625946\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=334, train_loss_step=0.013, train_loss_epoch=0.0117] Epoch 133: Train Loss = 0.012997408397495747\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=334, train_loss_step=0.0112, train_loss_epoch=0.013]Epoch 134: Train Loss = 0.011191521771252155\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.0112]Epoch 135: Train Loss = 0.010301021859049797\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=334, train_loss_step=0.00865, train_loss_epoch=0.0103]Epoch 136: Train Loss = 0.008649117313325405\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s, v_num=334, train_loss_step=0.0132, train_loss_epoch=0.00865] Epoch 137: Train Loss = 0.013169461861252785\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=334, train_loss_step=0.0088, train_loss_epoch=0.0132] Epoch 138: Train Loss = 0.008798197843134403\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=334, train_loss_step=0.0147, train_loss_epoch=0.0088]Epoch 139: Train Loss = 0.014689242467284203\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.0147]Epoch 140: Train Loss = 0.011817940510809422\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=334, train_loss_step=0.0128, train_loss_epoch=0.0118]Epoch 141: Train Loss = 0.01275093387812376\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=334, train_loss_step=0.0147, train_loss_epoch=0.0128]Epoch 142: Train Loss = 0.014678520150482655\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=334, train_loss_step=0.014, train_loss_epoch=0.0147] Epoch 143: Train Loss = 0.013990258798003197\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=334, train_loss_step=0.00967, train_loss_epoch=0.014]Epoch 144: Train Loss = 0.00967408623546362\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.00967] Epoch 145: Train Loss = 0.010143131949007511\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.0101] Epoch 146: Train Loss = 0.011603770777583122\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=334, train_loss_step=0.0156, train_loss_epoch=0.0116]Epoch 147: Train Loss = 0.015577648766338825\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.0156]Epoch 148: Train Loss = 0.011093361303210258\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=334, train_loss_step=0.0109, train_loss_epoch=0.0111]Epoch 149: Train Loss = 0.010884159244596958\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=334, train_loss_step=0.00955, train_loss_epoch=0.0109]Epoch 150: Train Loss = 0.009545433335006237\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=334, train_loss_step=0.00908, train_loss_epoch=0.00955]Epoch 151: Train Loss = 0.009075431153178215\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=334, train_loss_step=0.011, train_loss_epoch=0.00908]  Epoch 152: Train Loss = 0.011006359942257404\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=334, train_loss_step=0.0112, train_loss_epoch=0.011] Epoch 153: Train Loss = 0.011151619255542755\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=334, train_loss_step=0.0139, train_loss_epoch=0.0112]Epoch 154: Train Loss = 0.01386322733014822\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=334, train_loss_step=0.0137, train_loss_epoch=0.0139]Epoch 155: Train Loss = 0.013671763241291046\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=334, train_loss_step=0.0108, train_loss_epoch=0.0137]Epoch 156: Train Loss = 0.010849256999790668\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.0108]Epoch 157: Train Loss = 0.012129038572311401\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.0121]Epoch 158: Train Loss = 0.01154728140681982\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s, v_num=334, train_loss_step=0.0141, train_loss_epoch=0.0115]Epoch 159: Train Loss = 0.014075945131480694\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=334, train_loss_step=0.0153, train_loss_epoch=0.0141]Epoch 160: Train Loss = 0.015275699086487293\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s, v_num=334, train_loss_step=0.0158, train_loss_epoch=0.0153]Epoch 161: Train Loss = 0.015763359144330025\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=334, train_loss_step=0.0133, train_loss_epoch=0.0158]Epoch 162: Train Loss = 0.013331102207303047\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=334, train_loss_step=0.0108, train_loss_epoch=0.0133]Epoch 163: Train Loss = 0.010791935957968235\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s, v_num=334, train_loss_step=0.0112, train_loss_epoch=0.0108]Epoch 164: Train Loss = 0.011190599761903286\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s, v_num=334, train_loss_step=0.012, train_loss_epoch=0.0112] Epoch 165: Train Loss = 0.012029053643345833\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=334, train_loss_step=0.0134, train_loss_epoch=0.012]Epoch 166: Train Loss = 0.013353203423321247\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.0134]Epoch 167: Train Loss = 0.011765158735215664\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.0118]Epoch 168: Train Loss = 0.011397059075534344\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.0114]Epoch 169: Train Loss = 0.011450894176959991\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=334, train_loss_step=0.00905, train_loss_epoch=0.0115]Epoch 170: Train Loss = 0.009048017673194408\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.00905] Epoch 171: Train Loss = 0.010259456932544708\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=334, train_loss_step=0.00996, train_loss_epoch=0.0103]Epoch 172: Train Loss = 0.009961510077118874\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=334, train_loss_step=0.0124, train_loss_epoch=0.00996] Epoch 173: Train Loss = 0.01239970326423645\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, v_num=334, train_loss_step=0.0107, train_loss_epoch=0.0124] Epoch 174: Train Loss = 0.010745963081717491\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=334, train_loss_step=0.0104, train_loss_epoch=0.0107]Epoch 175: Train Loss = 0.010404606349766254\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=334, train_loss_step=0.00887, train_loss_epoch=0.0104]Epoch 176: Train Loss = 0.008871599100530148\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.00887] Epoch 177: Train Loss = 0.010097895748913288\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.0101]  Epoch 178: Train Loss = 0.010017228312790394\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=334, train_loss_step=0.00934, train_loss_epoch=0.010]Epoch 179: Train Loss = 0.009340094402432442\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=334, train_loss_step=0.00856, train_loss_epoch=0.00934]Epoch 180: Train Loss = 0.008559863083064556\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=334, train_loss_step=0.0091, train_loss_epoch=0.00856] Epoch 181: Train Loss = 0.009099563583731651\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=334, train_loss_step=0.0119, train_loss_epoch=0.0091] Epoch 182: Train Loss = 0.011861673556268215\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.0119]Epoch 183: Train Loss = 0.010494175367057323\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.0105]Epoch 184: Train Loss = 0.011670316569507122\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=334, train_loss_step=0.00803, train_loss_epoch=0.0117]Epoch 185: Train Loss = 0.008032928220927715\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=334, train_loss_step=0.00872, train_loss_epoch=0.00803]Epoch 186: Train Loss = 0.008716198615729809\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.00872] Epoch 187: Train Loss = 0.010573698207736015\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=334, train_loss_step=0.0125, train_loss_epoch=0.0106] Epoch 188: Train Loss = 0.01249082200229168\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=334, train_loss_step=0.0108, train_loss_epoch=0.0125]Epoch 189: Train Loss = 0.010776334442198277\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.0108]Epoch 190: Train Loss = 0.011571241542696953\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.0116]Epoch 191: Train Loss = 0.011810596100986004\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.0118]Epoch 192: Train Loss = 0.010264577344059944\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.0103]Epoch 193: Train Loss = 0.011830824427306652\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=334, train_loss_step=0.0122, train_loss_epoch=0.0118]Epoch 194: Train Loss = 0.012156723067164421\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s, v_num=334, train_loss_step=0.0161, train_loss_epoch=0.0122]Epoch 195: Train Loss = 0.016131345182657242\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=334, train_loss_step=0.0104, train_loss_epoch=0.0161]Epoch 196: Train Loss = 0.01037632953375578\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=334, train_loss_step=0.0125, train_loss_epoch=0.0104]Epoch 197: Train Loss = 0.012456160970032215\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=334, train_loss_step=0.0108, train_loss_epoch=0.0125]Epoch 198: Train Loss = 0.010774149559438229\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.0108]Epoch 199: Train Loss = 0.010147861205041409\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.0101]Epoch 200: Train Loss = 0.010127068497240543\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=334, train_loss_step=0.0132, train_loss_epoch=0.0101]Epoch 201: Train Loss = 0.01315191388130188\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=334, train_loss_step=0.0156, train_loss_epoch=0.0132]Epoch 202: Train Loss = 0.01555602066218853\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=334, train_loss_step=0.0108, train_loss_epoch=0.0156]Epoch 203: Train Loss = 0.010754676535725594\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.0108]Epoch 204: Train Loss = 0.011560018174350262\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.0116] Epoch 205: Train Loss = 0.010047093033790588\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=334, train_loss_step=0.0127, train_loss_epoch=0.010]Epoch 206: Train Loss = 0.012656062841415405\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.0127]Epoch 207: Train Loss = 0.012118542566895485\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.0121]Epoch 208: Train Loss = 0.011622610501945019\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=334, train_loss_step=0.00859, train_loss_epoch=0.0116]Epoch 209: Train Loss = 0.008593798615038395\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=334, train_loss_step=0.0108, train_loss_epoch=0.00859] Epoch 210: Train Loss = 0.010766206309199333\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=334, train_loss_step=0.00965, train_loss_epoch=0.0108]Epoch 211: Train Loss = 0.009651646949350834\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=334, train_loss_step=0.0086, train_loss_epoch=0.00965] Epoch 212: Train Loss = 0.008601097390055656\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=334, train_loss_step=0.00706, train_loss_epoch=0.0086]Epoch 213: Train Loss = 0.007055870722979307\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=334, train_loss_step=0.0102, train_loss_epoch=0.00706] Epoch 214: Train Loss = 0.01017500925809145\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.0102] Epoch 215: Train Loss = 0.010086460039019585\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=334, train_loss_step=0.0122, train_loss_epoch=0.0101]Epoch 216: Train Loss = 0.012207137420773506\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.0122] Epoch 217: Train Loss = 0.010007158853113651\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.010]Epoch 218: Train Loss = 0.011478460393846035\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=334, train_loss_step=0.00994, train_loss_epoch=0.0115]Epoch 219: Train Loss = 0.009937205351889133\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.00994] Epoch 220: Train Loss = 0.01112403068691492\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.0111] Epoch 221: Train Loss = 0.01176229864358902\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=334, train_loss_step=0.00827, train_loss_epoch=0.0118]Epoch 222: Train Loss = 0.008266705088317394\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.00827] Epoch 223: Train Loss = 0.01211454812437296\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=334, train_loss_step=0.0112, train_loss_epoch=0.0121] Epoch 224: Train Loss = 0.011200490407645702\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=334, train_loss_step=0.0096, train_loss_epoch=0.0112]Epoch 225: Train Loss = 0.009603790007531643\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=334, train_loss_step=0.0083, train_loss_epoch=0.0096]Epoch 226: Train Loss = 0.008301760070025921\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=334, train_loss_step=0.0102, train_loss_epoch=0.0083]Epoch 227: Train Loss = 0.010166826657950878\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=334, train_loss_step=0.00991, train_loss_epoch=0.0102]Epoch 228: Train Loss = 0.00990853738039732\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=334, train_loss_step=0.00908, train_loss_epoch=0.00991]Epoch 229: Train Loss = 0.00907844491302967\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=334, train_loss_step=0.0087, train_loss_epoch=0.00908] Epoch 230: Train Loss = 0.008702113293111324\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.0087] Epoch 231: Train Loss = 0.01059064082801342\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=334, train_loss_step=0.00918, train_loss_epoch=0.0106]Epoch 232: Train Loss = 0.009179108776152134\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.00918] Epoch 233: Train Loss = 0.011436080560088158\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=334, train_loss_step=0.00829, train_loss_epoch=0.0114]Epoch 234: Train Loss = 0.008289427496492863\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=334, train_loss_step=0.0102, train_loss_epoch=0.00829] Epoch 235: Train Loss = 0.010169425047934055\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=334, train_loss_step=0.0128, train_loss_epoch=0.0102] Epoch 236: Train Loss = 0.012825309298932552\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=334, train_loss_step=0.0109, train_loss_epoch=0.0128]Epoch 237: Train Loss = 0.010935770347714424\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=334, train_loss_step=0.0158, train_loss_epoch=0.0109]Epoch 238: Train Loss = 0.015821531414985657\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=334, train_loss_step=0.0164, train_loss_epoch=0.0158]Epoch 239: Train Loss = 0.016394780948758125\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=334, train_loss_step=0.0122, train_loss_epoch=0.0164]Epoch 240: Train Loss = 0.012153293006122112\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=334, train_loss_step=0.00873, train_loss_epoch=0.0122]Epoch 241: Train Loss = 0.008728323504328728\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=334, train_loss_step=0.00928, train_loss_epoch=0.00873]Epoch 242: Train Loss = 0.0092848539352417\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=334, train_loss_step=0.0102, train_loss_epoch=0.00928] Epoch 243: Train Loss = 0.010201580822467804\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.0102] Epoch 244: Train Loss = 0.011672449298202991\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.0117]Epoch 245: Train Loss = 0.010336299426853657\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=334, train_loss_step=0.00704, train_loss_epoch=0.0103]Epoch 246: Train Loss = 0.007043969351798296\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.00704] Epoch 247: Train Loss = 0.011506587266921997\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.0115] Epoch 248: Train Loss = 0.010090567171573639\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=334, train_loss_step=0.0157, train_loss_epoch=0.0101]Epoch 249: Train Loss = 0.015671381726861\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=334, train_loss_step=0.0122, train_loss_epoch=0.0157]Epoch 250: Train Loss = 0.012158757075667381\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=334, train_loss_step=0.00942, train_loss_epoch=0.0122]Epoch 251: Train Loss = 0.00942067988216877\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.00942] Epoch 252: Train Loss = 0.010098693892359734\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.0101] Epoch 253: Train Loss = 0.011137507855892181\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=334, train_loss_step=0.0095, train_loss_epoch=0.0111]Epoch 254: Train Loss = 0.009502607397735119\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=334, train_loss_step=0.0123, train_loss_epoch=0.0095]Epoch 255: Train Loss = 0.012307030148804188\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=334, train_loss_step=0.0104, train_loss_epoch=0.0123]Epoch 256: Train Loss = 0.0104055879637599\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.0104]Epoch 257: Train Loss = 0.012091743759810925\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=334, train_loss_step=0.0112, train_loss_epoch=0.0121]Epoch 258: Train Loss = 0.011183196678757668\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.0112]Epoch 259: Train Loss = 0.011757451109588146\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=334, train_loss_step=0.00995, train_loss_epoch=0.0118]Epoch 260: Train Loss = 0.00994801614433527\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.00995] Epoch 261: Train Loss = 0.011453592218458652\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=334, train_loss_step=0.00872, train_loss_epoch=0.0115]Epoch 262: Train Loss = 0.008715623058378696\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.00872] Epoch 263: Train Loss = 0.010525635443627834\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=334, train_loss_step=0.00976, train_loss_epoch=0.0105]Epoch 264: Train Loss = 0.009757613763213158\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.00976] Epoch 265: Train Loss = 0.010147737339138985\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.0101] Epoch 266: Train Loss = 0.010088829323649406\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=334, train_loss_step=0.00913, train_loss_epoch=0.0101]Epoch 267: Train Loss = 0.00913360994309187\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=334, train_loss_step=0.00788, train_loss_epoch=0.00913]Epoch 268: Train Loss = 0.007884600199759007\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.00788] Epoch 269: Train Loss = 0.011146380566060543\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=334, train_loss_step=0.00957, train_loss_epoch=0.0111]Epoch 270: Train Loss = 0.009570449590682983\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=334, train_loss_step=0.00798, train_loss_epoch=0.00957]Epoch 271: Train Loss = 0.007982653565704823\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=334, train_loss_step=0.00837, train_loss_epoch=0.00798]Epoch 272: Train Loss = 0.008371582254767418\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.00837]  Epoch 273: Train Loss = 0.009995542466640472\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.010] Epoch 274: Train Loss = 0.011560252867639065\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=334, train_loss_step=0.0153, train_loss_epoch=0.0116]Epoch 275: Train Loss = 0.015262647531926632\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=334, train_loss_step=0.00838, train_loss_epoch=0.0153]Epoch 276: Train Loss = 0.00837509986013174\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=334, train_loss_step=0.00905, train_loss_epoch=0.00838]Epoch 277: Train Loss = 0.009045653976500034\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=334, train_loss_step=0.0122, train_loss_epoch=0.00905] Epoch 278: Train Loss = 0.012157884426414967\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=334, train_loss_step=0.00725, train_loss_epoch=0.0122]Epoch 279: Train Loss = 0.007248621433973312\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=334, train_loss_step=0.00984, train_loss_epoch=0.00725]Epoch 280: Train Loss = 0.009841075167059898\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=334, train_loss_step=0.00937, train_loss_epoch=0.00984]Epoch 281: Train Loss = 0.009372432716190815\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.00937] Epoch 282: Train Loss = 0.010570469312369823\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=334, train_loss_step=0.0109, train_loss_epoch=0.0106] Epoch 283: Train Loss = 0.010854867286980152\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=334, train_loss_step=0.0124, train_loss_epoch=0.0109]Epoch 284: Train Loss = 0.012417837977409363\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.0124]Epoch 285: Train Loss = 0.010453002527356148\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.0105]Epoch 286: Train Loss = 0.011509665288031101\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.0115]Epoch 287: Train Loss = 0.011649362742900848\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=334, train_loss_step=0.0136, train_loss_epoch=0.0116]Epoch 288: Train Loss = 0.01355139259248972\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=334, train_loss_step=0.00905, train_loss_epoch=0.0136]Epoch 289: Train Loss = 0.009053243324160576\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.00905] Epoch 290: Train Loss = 0.01145815011113882\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.0115] Epoch 291: Train Loss = 0.01149795949459076\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.0115]Epoch 292: Train Loss = 0.011132856830954552\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=334, train_loss_step=0.00916, train_loss_epoch=0.0111]Epoch 293: Train Loss = 0.009163846261799335\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=334, train_loss_step=0.00904, train_loss_epoch=0.00916]Epoch 294: Train Loss = 0.009039056487381458\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s, v_num=334, train_loss_step=0.0151, train_loss_epoch=0.00904] Epoch 295: Train Loss = 0.015120627358555794\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=334, train_loss_step=0.0107, train_loss_epoch=0.0151] Epoch 296: Train Loss = 0.010687842965126038\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.0107]Epoch 297: Train Loss = 0.010480178520083427\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=334, train_loss_step=0.0099, train_loss_epoch=0.0105]Epoch 298: Train Loss = 0.009899256750941277\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=334, train_loss_step=0.0113, train_loss_epoch=0.0099]Epoch 299: Train Loss = 0.011287258937954903\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=334, train_loss_step=0.0136, train_loss_epoch=0.0113]Epoch 300: Train Loss = 0.013611373491585255\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=334, train_loss_step=0.0131, train_loss_epoch=0.0136]Epoch 301: Train Loss = 0.013084843754768372\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=334, train_loss_step=0.0136, train_loss_epoch=0.0131]Epoch 302: Train Loss = 0.013602233491837978\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s, v_num=334, train_loss_step=0.0119, train_loss_epoch=0.0136]Epoch 303: Train Loss = 0.011895651929080486\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.0119]Epoch 304: Train Loss = 0.010570592246949673\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.0106]Epoch 305: Train Loss = 0.012099643237888813\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=334, train_loss_step=0.013, train_loss_epoch=0.0121] Epoch 306: Train Loss = 0.013048711232841015\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=334, train_loss_step=0.0104, train_loss_epoch=0.013]Epoch 307: Train Loss = 0.010426031425595284\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=334, train_loss_step=0.00728, train_loss_epoch=0.0104]Epoch 308: Train Loss = 0.007283330895006657\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=334, train_loss_step=0.0163, train_loss_epoch=0.00728] Epoch 309: Train Loss = 0.016329824924468994\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=334, train_loss_step=0.0113, train_loss_epoch=0.0163] Epoch 310: Train Loss = 0.01134567055851221\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=334, train_loss_step=0.0092, train_loss_epoch=0.0113]Epoch 311: Train Loss = 0.009201966226100922\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=334, train_loss_step=0.0109, train_loss_epoch=0.0092]Epoch 312: Train Loss = 0.010873831808567047\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.0109]Epoch 313: Train Loss = 0.011352800764143467\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=334, train_loss_step=0.0107, train_loss_epoch=0.0114]Epoch 314: Train Loss = 0.010736831463873386\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=334, train_loss_step=0.00887, train_loss_epoch=0.0107]Epoch 315: Train Loss = 0.008866206742823124\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=334, train_loss_step=0.00926, train_loss_epoch=0.00887]Epoch 316: Train Loss = 0.00926361046731472\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.00926] Epoch 317: Train Loss = 0.010294901207089424\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=334, train_loss_step=0.0107, train_loss_epoch=0.0103] Epoch 318: Train Loss = 0.01071107853204012\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=334, train_loss_step=0.00862, train_loss_epoch=0.0107]Epoch 319: Train Loss = 0.008615926839411259\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.00862] Epoch 320: Train Loss = 0.011453576385974884\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=334, train_loss_step=0.0137, train_loss_epoch=0.0115] Epoch 321: Train Loss = 0.013713649474084377\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=334, train_loss_step=0.00856, train_loss_epoch=0.0137]Epoch 322: Train Loss = 0.008558315224945545\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.00856] Epoch 323: Train Loss = 0.011847746558487415\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.0118] Epoch 324: Train Loss = 0.010286892764270306\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=334, train_loss_step=0.0112, train_loss_epoch=0.0103]Epoch 325: Train Loss = 0.011168159544467926\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=334, train_loss_step=0.012, train_loss_epoch=0.0112] Epoch 326: Train Loss = 0.012000170536339283\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.012]Epoch 327: Train Loss = 0.012128799222409725\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=334, train_loss_step=0.00727, train_loss_epoch=0.0121]Epoch 328: Train Loss = 0.007268717046827078\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=334, train_loss_step=0.00949, train_loss_epoch=0.00727]Epoch 329: Train Loss = 0.009489089250564575\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=334, train_loss_step=0.00955, train_loss_epoch=0.00949]Epoch 330: Train Loss = 0.009545637294650078\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.00955] Epoch 331: Train Loss = 0.011709877289831638\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=334, train_loss_step=0.00967, train_loss_epoch=0.0117]Epoch 332: Train Loss = 0.009671458043158054\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s, v_num=334, train_loss_step=0.0128, train_loss_epoch=0.00967] Epoch 333: Train Loss = 0.012813533656299114\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=334, train_loss_step=0.0109, train_loss_epoch=0.0128] Epoch 334: Train Loss = 0.010906186886131763\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=334, train_loss_step=0.0126, train_loss_epoch=0.0109]Epoch 335: Train Loss = 0.01257359329611063\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 10.17it/s, v_num=334, train_loss_step=0.0113, train_loss_epoch=0.0126]Epoch 336: Train Loss = 0.011312602087855339\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.0113] Epoch 337: Train Loss = 0.010046822018921375\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 13.74it/s, v_num=334, train_loss_step=0.0104, train_loss_epoch=0.010]Epoch 338: Train Loss = 0.01042790524661541\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 12.67it/s, v_num=334, train_loss_step=0.0091, train_loss_epoch=0.0104]Epoch 339: Train Loss = 0.009097130037844181\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.0091] Epoch 340: Train Loss = 0.010044149123132229\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.010]Epoch 341: Train Loss = 0.01108157355338335\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=334, train_loss_step=0.00796, train_loss_epoch=0.0111]Epoch 342: Train Loss = 0.007955712266266346\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.00796] Epoch 343: Train Loss = 0.01112364698201418\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=334, train_loss_step=0.0126, train_loss_epoch=0.0111] Epoch 344: Train Loss = 0.01263575442135334\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=334, train_loss_step=0.00876, train_loss_epoch=0.0126]Epoch 345: Train Loss = 0.008756536059081554\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=334, train_loss_step=0.00941, train_loss_epoch=0.00876]Epoch 346: Train Loss = 0.009410242550075054\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=334, train_loss_step=0.00872, train_loss_epoch=0.00941]Epoch 347: Train Loss = 0.008720040321350098\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.00872] Epoch 348: Train Loss = 0.01032234262675047\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=334, train_loss_step=0.00997, train_loss_epoch=0.0103]Epoch 349: Train Loss = 0.009971468709409237\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=334, train_loss_step=0.00839, train_loss_epoch=0.00997]Epoch 350: Train Loss = 0.00839180313050747\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.00839] Epoch 351: Train Loss = 0.011050627566874027\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=334, train_loss_step=0.00912, train_loss_epoch=0.0111]Epoch 352: Train Loss = 0.009115164168179035\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=334, train_loss_step=0.00983, train_loss_epoch=0.00912]Epoch 353: Train Loss = 0.009827515110373497\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=334, train_loss_step=0.0131, train_loss_epoch=0.00983] Epoch 354: Train Loss = 0.013115765526890755\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=334, train_loss_step=0.00643, train_loss_epoch=0.0131]Epoch 355: Train Loss = 0.00643067667260766\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=334, train_loss_step=0.00846, train_loss_epoch=0.00643]Epoch 356: Train Loss = 0.008455857634544373\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=334, train_loss_step=0.0132, train_loss_epoch=0.00846] Epoch 357: Train Loss = 0.013218683190643787\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=334, train_loss_step=0.00776, train_loss_epoch=0.0132]Epoch 358: Train Loss = 0.00775547232478857\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 10.24it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.00776] Epoch 359: Train Loss = 0.010283736512064934\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=334, train_loss_step=0.00934, train_loss_epoch=0.0103]Epoch 360: Train Loss = 0.009340966120362282\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=334, train_loss_step=0.0134, train_loss_epoch=0.00934] Epoch 361: Train Loss = 0.013363800011575222\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=334, train_loss_step=0.00662, train_loss_epoch=0.0134]Epoch 362: Train Loss = 0.006616869010031223\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=334, train_loss_step=0.00955, train_loss_epoch=0.00662]Epoch 363: Train Loss = 0.00954772625118494\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=334, train_loss_step=0.00849, train_loss_epoch=0.00955]Epoch 364: Train Loss = 0.008487504906952381\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.00849] Epoch 365: Train Loss = 0.011608118191361427\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=334, train_loss_step=0.00871, train_loss_epoch=0.0116]Epoch 366: Train Loss = 0.008714129216969013\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=334, train_loss_step=0.00998, train_loss_epoch=0.00871]Epoch 367: Train Loss = 0.009979262948036194\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.00998] Epoch 368: Train Loss = 0.0102964136749506\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.0103] Epoch 369: Train Loss = 0.011417808011174202\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=334, train_loss_step=0.0109, train_loss_epoch=0.0114]Epoch 370: Train Loss = 0.010865927673876286\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=334, train_loss_step=0.0133, train_loss_epoch=0.0109]Epoch 371: Train Loss = 0.01326791848987341\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=334, train_loss_step=0.00967, train_loss_epoch=0.0133]Epoch 372: Train Loss = 0.009669429622590542\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=334, train_loss_step=0.00827, train_loss_epoch=0.00967]Epoch 373: Train Loss = 0.008267874829471111\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=334, train_loss_step=0.00867, train_loss_epoch=0.00827]Epoch 374: Train Loss = 0.008672592230141163\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=334, train_loss_step=0.011, train_loss_epoch=0.00867]  Epoch 375: Train Loss = 0.010973158292472363\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=334, train_loss_step=0.0099, train_loss_epoch=0.011] Epoch 376: Train Loss = 0.009900054894387722\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=334, train_loss_step=0.00823, train_loss_epoch=0.0099]Epoch 377: Train Loss = 0.008233834989368916\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=334, train_loss_step=0.00946, train_loss_epoch=0.00823]Epoch 378: Train Loss = 0.009458494372665882\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=334, train_loss_step=0.00778, train_loss_epoch=0.00946]Epoch 379: Train Loss = 0.007781027816236019\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.00778] Epoch 380: Train Loss = 0.011101544834673405\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=334, train_loss_step=0.0135, train_loss_epoch=0.0111] Epoch 381: Train Loss = 0.01345868967473507\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.0135]Epoch 382: Train Loss = 0.012121602892875671\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=334, train_loss_step=0.0109, train_loss_epoch=0.0121]Epoch 383: Train Loss = 0.010855392552912235\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=334, train_loss_step=0.0108, train_loss_epoch=0.0109]Epoch 384: Train Loss = 0.010822688229382038\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=334, train_loss_step=0.012, train_loss_epoch=0.0108] Epoch 385: Train Loss = 0.01201313640922308\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=334, train_loss_step=0.00974, train_loss_epoch=0.012]Epoch 386: Train Loss = 0.009739072062075138\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s, v_num=334, train_loss_step=0.0142, train_loss_epoch=0.00974] Epoch 387: Train Loss = 0.014236566610634327\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=334, train_loss_step=0.0112, train_loss_epoch=0.0142] Epoch 388: Train Loss = 0.011178521439433098\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=334, train_loss_step=0.0163, train_loss_epoch=0.0112]Epoch 389: Train Loss = 0.016252461820840836\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=334, train_loss_step=0.0119, train_loss_epoch=0.0163]Epoch 390: Train Loss = 0.011852441355586052\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=334, train_loss_step=0.0131, train_loss_epoch=0.0119]Epoch 391: Train Loss = 0.01307494193315506\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.0131]Epoch 392: Train Loss = 0.011430388316512108\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.0114]Epoch 393: Train Loss = 0.010462416335940361\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=334, train_loss_step=0.00936, train_loss_epoch=0.0105]Epoch 394: Train Loss = 0.00935877300798893\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.00936] Epoch 395: Train Loss = 0.011496133171021938\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=334, train_loss_step=0.013, train_loss_epoch=0.0115]  Epoch 396: Train Loss = 0.012958458624780178\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=334, train_loss_step=0.0098, train_loss_epoch=0.013]Epoch 397: Train Loss = 0.009798137471079826\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=334, train_loss_step=0.0142, train_loss_epoch=0.0098]Epoch 398: Train Loss = 0.01420322060585022\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.0142]Epoch 399: Train Loss = 0.011742999777197838\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=334, train_loss_step=0.0142, train_loss_epoch=0.0117]Epoch 400: Train Loss = 0.014168595895171165\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.0142]Epoch 401: Train Loss = 0.011463189497590065\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=334, train_loss_step=0.0125, train_loss_epoch=0.0115]Epoch 402: Train Loss = 0.01251375675201416\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=334, train_loss_step=0.0109, train_loss_epoch=0.0125]Epoch 403: Train Loss = 0.010896158404648304\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=334, train_loss_step=0.014, train_loss_epoch=0.0109] Epoch 404: Train Loss = 0.013953253626823425\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=334, train_loss_step=0.011, train_loss_epoch=0.014] Epoch 405: Train Loss = 0.011024200357496738\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.011]Epoch 406: Train Loss = 0.01174907386302948\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=334, train_loss_step=0.00773, train_loss_epoch=0.0117]Epoch 407: Train Loss = 0.007728855591267347\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=334, train_loss_step=0.00957, train_loss_epoch=0.00773]Epoch 408: Train Loss = 0.00956782978028059\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=334, train_loss_step=0.0111, train_loss_epoch=0.00957] Epoch 409: Train Loss = 0.01113100815564394\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=334, train_loss_step=0.0128, train_loss_epoch=0.0111] Epoch 410: Train Loss = 0.012843926437199116\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s, v_num=334, train_loss_step=0.0107, train_loss_epoch=0.0128]Epoch 411: Train Loss = 0.01065319124609232\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.0107]Epoch 412: Train Loss = 0.01183084212243557\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=334, train_loss_step=0.00946, train_loss_epoch=0.0118]Epoch 413: Train Loss = 0.0094563914462924\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=334, train_loss_step=0.0129, train_loss_epoch=0.00946] Epoch 414: Train Loss = 0.012891736812889576\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=334, train_loss_step=0.0137, train_loss_epoch=0.0129] Epoch 415: Train Loss = 0.013744071125984192\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.0137]Epoch 416: Train Loss = 0.01160483993589878\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=334, train_loss_step=0.0139, train_loss_epoch=0.0116]Epoch 417: Train Loss = 0.013850496150553226\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=334, train_loss_step=0.0104, train_loss_epoch=0.0139]Epoch 418: Train Loss = 0.010409707203507423\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=334, train_loss_step=0.0118, train_loss_epoch=0.0104]Epoch 419: Train Loss = 0.011764505878090858\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=334, train_loss_step=0.0113, train_loss_epoch=0.0118]Epoch 420: Train Loss = 0.011291530914604664\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=334, train_loss_step=0.00953, train_loss_epoch=0.0113]Epoch 421: Train Loss = 0.009527327492833138\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=334, train_loss_step=0.00932, train_loss_epoch=0.00953]Epoch 422: Train Loss = 0.009319597855210304\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=334, train_loss_step=0.00925, train_loss_epoch=0.00932]Epoch 423: Train Loss = 0.009245472960174084\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=334, train_loss_step=0.00873, train_loss_epoch=0.00925]Epoch 424: Train Loss = 0.008731828071177006\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=334, train_loss_step=0.0104, train_loss_epoch=0.00873] Epoch 425: Train Loss = 0.010447291657328606\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=334, train_loss_step=0.00956, train_loss_epoch=0.0104]Epoch 426: Train Loss = 0.009564384818077087\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=334, train_loss_step=0.00888, train_loss_epoch=0.00956]Epoch 427: Train Loss = 0.008880384266376495\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=334, train_loss_step=0.0122, train_loss_epoch=0.00888] Epoch 428: Train Loss = 0.012188591994345188\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=334, train_loss_step=0.00968, train_loss_epoch=0.0122]Epoch 429: Train Loss = 0.009683617390692234\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=334, train_loss_step=0.00992, train_loss_epoch=0.00968]Epoch 430: Train Loss = 0.009917126968502998\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=334, train_loss_step=0.00944, train_loss_epoch=0.00992]Epoch 431: Train Loss = 0.009444253519177437\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=334, train_loss_step=0.00921, train_loss_epoch=0.00944]Epoch 432: Train Loss = 0.009212352335453033\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.00921] Epoch 433: Train Loss = 0.011703035794198513\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.0117] Epoch 434: Train Loss = 0.011385783553123474\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.0114]Epoch 435: Train Loss = 0.010603348724544048\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=334, train_loss_step=0.0163, train_loss_epoch=0.0106]Epoch 436: Train Loss = 0.01628543809056282\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=334, train_loss_step=0.0116, train_loss_epoch=0.0163]Epoch 437: Train Loss = 0.011618838645517826\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=334, train_loss_step=0.00977, train_loss_epoch=0.0116]Epoch 438: Train Loss = 0.009768783114850521\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=334, train_loss_step=0.0119, train_loss_epoch=0.00977] Epoch 439: Train Loss = 0.01186266541481018\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=334, train_loss_step=0.0126, train_loss_epoch=0.0119] Epoch 440: Train Loss = 0.012627413496375084\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.0126]Epoch 441: Train Loss = 0.0115255331620574\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.0115]Epoch 442: Train Loss = 0.01007494144141674\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=334, train_loss_step=0.0149, train_loss_epoch=0.0101]Epoch 443: Train Loss = 0.014930938370525837\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s, v_num=334, train_loss_step=0.0135, train_loss_epoch=0.0149]Epoch 444: Train Loss = 0.013485439121723175\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=334, train_loss_step=0.0102, train_loss_epoch=0.0135]Epoch 445: Train Loss = 0.010216928087174892\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=334, train_loss_step=0.0113, train_loss_epoch=0.0102]Epoch 446: Train Loss = 0.01128917932510376\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s, v_num=334, train_loss_step=0.0109, train_loss_epoch=0.0113]Epoch 447: Train Loss = 0.010870705358684063\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=334, train_loss_step=0.00962, train_loss_epoch=0.0109]Epoch 448: Train Loss = 0.009623375721275806\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.00962] Epoch 449: Train Loss = 0.012137037701904774\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=334, train_loss_step=0.011, train_loss_epoch=0.0121]  Epoch 450: Train Loss = 0.011022261343896389\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=334, train_loss_step=0.00915, train_loss_epoch=0.011]Epoch 451: Train Loss = 0.009153126738965511\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.00915]  Epoch 452: Train Loss = 0.010004009120166302\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=334, train_loss_step=0.014, train_loss_epoch=0.010]  Epoch 453: Train Loss = 0.014001153409481049\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=334, train_loss_step=0.00982, train_loss_epoch=0.014]Epoch 454: Train Loss = 0.009817634709179401\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=334, train_loss_step=0.0113, train_loss_epoch=0.00982] Epoch 455: Train Loss = 0.01125907339155674\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=334, train_loss_step=0.0112, train_loss_epoch=0.0113] Epoch 456: Train Loss = 0.011177755892276764\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=334, train_loss_step=0.0112, train_loss_epoch=0.0112]Epoch 457: Train Loss = 0.011152064427733421\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=334, train_loss_step=0.00998, train_loss_epoch=0.0112]Epoch 458: Train Loss = 0.009981023147702217\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.00998] Epoch 459: Train Loss = 0.012058104388415813\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.0121] Epoch 460: Train Loss = 0.012124761007726192\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=334, train_loss_step=0.013, train_loss_epoch=0.0121] Epoch 461: Train Loss = 0.013019770383834839\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=334, train_loss_step=0.00759, train_loss_epoch=0.013]Epoch 462: Train Loss = 0.007585728075355291\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.00759] Epoch 463: Train Loss = 0.010277673602104187\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=334, train_loss_step=0.00891, train_loss_epoch=0.0103]Epoch 464: Train Loss = 0.008909279480576515\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=334, train_loss_step=0.009, train_loss_epoch=0.00891]  Epoch 465: Train Loss = 0.009002109989523888\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=334, train_loss_step=0.0107, train_loss_epoch=0.009] Epoch 466: Train Loss = 0.010715789161622524\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.0107]Epoch 467: Train Loss = 0.010298460721969604\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=334, train_loss_step=0.00979, train_loss_epoch=0.0103]Epoch 468: Train Loss = 0.009787924587726593\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=334, train_loss_step=0.0117, train_loss_epoch=0.00979] Epoch 469: Train Loss = 0.011693720705807209\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=334, train_loss_step=0.0129, train_loss_epoch=0.0117] Epoch 470: Train Loss = 0.012913217768073082\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=334, train_loss_step=0.0153, train_loss_epoch=0.0129]Epoch 471: Train Loss = 0.015302197076380253\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=334, train_loss_step=0.00728, train_loss_epoch=0.0153]Epoch 472: Train Loss = 0.007275799755007029\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=334, train_loss_step=0.00884, train_loss_epoch=0.00728]Epoch 473: Train Loss = 0.008842448703944683\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.00884] Epoch 474: Train Loss = 0.01007861364632845\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=334, train_loss_step=0.0105, train_loss_epoch=0.0101] Epoch 475: Train Loss = 0.010450388304889202\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.0105] Epoch 476: Train Loss = 0.010006105527281761\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=334, train_loss_step=0.0075, train_loss_epoch=0.010]Epoch 477: Train Loss = 0.007499867584556341\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=334, train_loss_step=0.00898, train_loss_epoch=0.0075]Epoch 478: Train Loss = 0.008975706063210964\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=334, train_loss_step=0.013, train_loss_epoch=0.00898]  Epoch 479: Train Loss = 0.012951326556503773\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=334, train_loss_step=0.00957, train_loss_epoch=0.013]Epoch 480: Train Loss = 0.009567673318088055\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=334, train_loss_step=0.00981, train_loss_epoch=0.00957]Epoch 481: Train Loss = 0.009813417680561543\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=334, train_loss_step=0.0122, train_loss_epoch=0.00981] Epoch 482: Train Loss = 0.012194772250950336\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=334, train_loss_step=0.00854, train_loss_epoch=0.0122]Epoch 483: Train Loss = 0.008535200729966164\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=334, train_loss_step=0.0137, train_loss_epoch=0.00854] Epoch 484: Train Loss = 0.013700544834136963\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=334, train_loss_step=0.0115, train_loss_epoch=0.0137] Epoch 485: Train Loss = 0.01145356148481369\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=334, train_loss_step=0.00884, train_loss_epoch=0.0115]Epoch 486: Train Loss = 0.008838444016873837\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=334, train_loss_step=0.00775, train_loss_epoch=0.00884]Epoch 487: Train Loss = 0.007751765660941601\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=334, train_loss_step=0.0114, train_loss_epoch=0.00775] Epoch 488: Train Loss = 0.011418916285037994\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=334, train_loss_step=0.00861, train_loss_epoch=0.0114]Epoch 489: Train Loss = 0.008610685355961323\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=334, train_loss_step=0.0101, train_loss_epoch=0.00861] Epoch 490: Train Loss = 0.010123895481228828\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=334, train_loss_step=0.010, train_loss_epoch=0.0101]  Epoch 491: Train Loss = 0.010024233721196651\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=334, train_loss_step=0.00875, train_loss_epoch=0.010]Epoch 492: Train Loss = 0.008747615851461887\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=334, train_loss_step=0.00965, train_loss_epoch=0.00875]Epoch 493: Train Loss = 0.009648346342146397\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=334, train_loss_step=0.00779, train_loss_epoch=0.00965]Epoch 494: Train Loss = 0.007790414150804281\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=334, train_loss_step=0.00921, train_loss_epoch=0.00779]Epoch 495: Train Loss = 0.00921026524156332\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=334, train_loss_step=0.0103, train_loss_epoch=0.00921] Epoch 496: Train Loss = 0.010340487584471703\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=334, train_loss_step=0.0121, train_loss_epoch=0.0103] Epoch 497: Train Loss = 0.012100900523364544\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=334, train_loss_step=0.00977, train_loss_epoch=0.0121]Epoch 498: Train Loss = 0.009770810604095459\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.00977] Epoch 499: Train Loss = 0.010644589550793171\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.0106] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=334, train_loss_step=0.0106, train_loss_epoch=0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 5: from 2008-05-12 00:00:00 to 2022-08-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=338, train_loss_step=0.0233]Epoch 0: Train Loss = 0.023304343223571777\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=338, train_loss_step=0.0326, train_loss_epoch=0.0233]Epoch 1: Train Loss = 0.0326317623257637\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=338, train_loss_step=0.0268, train_loss_epoch=0.0326]Epoch 2: Train Loss = 0.026771608740091324\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=338, train_loss_step=0.0193, train_loss_epoch=0.0268]Epoch 3: Train Loss = 0.01931752637028694\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=338, train_loss_step=0.0248, train_loss_epoch=0.0193]Epoch 4: Train Loss = 0.024756988510489464\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=338, train_loss_step=0.0203, train_loss_epoch=0.0248]Epoch 5: Train Loss = 0.02030140720307827\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=338, train_loss_step=0.0164, train_loss_epoch=0.0203]Epoch 6: Train Loss = 0.016388969495892525\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.0164]Epoch 7: Train Loss = 0.012208359315991402\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=338, train_loss_step=0.0149, train_loss_epoch=0.0122]Epoch 8: Train Loss = 0.014900327660143375\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=338, train_loss_step=0.0145, train_loss_epoch=0.0149]Epoch 9: Train Loss = 0.014476753771305084\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=338, train_loss_step=0.0161, train_loss_epoch=0.0145]Epoch 10: Train Loss = 0.01613765023648739\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=338, train_loss_step=0.0137, train_loss_epoch=0.0161]Epoch 11: Train Loss = 0.013683906756341457\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=338, train_loss_step=0.0141, train_loss_epoch=0.0137]Epoch 12: Train Loss = 0.014074549078941345\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=338, train_loss_step=0.0139, train_loss_epoch=0.0141]Epoch 13: Train Loss = 0.01386189367622137\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=338, train_loss_step=0.0127, train_loss_epoch=0.0139]Epoch 14: Train Loss = 0.012710544280707836\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=338, train_loss_step=0.0113, train_loss_epoch=0.0127]Epoch 15: Train Loss = 0.011304443702101707\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=338, train_loss_step=0.0133, train_loss_epoch=0.0113]Epoch 16: Train Loss = 0.013268464244902134\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=338, train_loss_step=0.0118, train_loss_epoch=0.0133]Epoch 17: Train Loss = 0.011775328777730465\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=338, train_loss_step=0.0165, train_loss_epoch=0.0118]Epoch 18: Train Loss = 0.016506260260939598\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=338, train_loss_step=0.0143, train_loss_epoch=0.0165]Epoch 19: Train Loss = 0.014335313811898232\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=338, train_loss_step=0.0136, train_loss_epoch=0.0143]Epoch 20: Train Loss = 0.01357229333370924\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=338, train_loss_step=0.0136, train_loss_epoch=0.0136]Epoch 21: Train Loss = 0.01357762236148119\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=338, train_loss_step=0.0113, train_loss_epoch=0.0136]Epoch 22: Train Loss = 0.011267157271504402\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=338, train_loss_step=0.0136, train_loss_epoch=0.0113]Epoch 23: Train Loss = 0.01356178242713213\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=338, train_loss_step=0.0144, train_loss_epoch=0.0136]Epoch 24: Train Loss = 0.014375724829733372\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=338, train_loss_step=0.010, train_loss_epoch=0.0144] Epoch 25: Train Loss = 0.010004551149904728\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=338, train_loss_step=0.0148, train_loss_epoch=0.010]Epoch 26: Train Loss = 0.014784298837184906\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=338, train_loss_step=0.0113, train_loss_epoch=0.0148]Epoch 27: Train Loss = 0.01126274187117815\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=338, train_loss_step=0.015, train_loss_epoch=0.0113] Epoch 28: Train Loss = 0.01498699001967907\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=338, train_loss_step=0.0174, train_loss_epoch=0.015]Epoch 29: Train Loss = 0.017448505386710167\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=338, train_loss_step=0.00938, train_loss_epoch=0.0174]Epoch 30: Train Loss = 0.009377519600093365\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=338, train_loss_step=0.0148, train_loss_epoch=0.00938] Epoch 31: Train Loss = 0.014766165055334568\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=338, train_loss_step=0.0133, train_loss_epoch=0.0148] Epoch 32: Train Loss = 0.013312225230038166\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=338, train_loss_step=0.0108, train_loss_epoch=0.0133]Epoch 33: Train Loss = 0.010832280851900578\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, v_num=338, train_loss_step=0.0159, train_loss_epoch=0.0108]Epoch 34: Train Loss = 0.01585443690419197\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s, v_num=338, train_loss_step=0.0126, train_loss_epoch=0.0159]Epoch 35: Train Loss = 0.012614472769200802\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=338, train_loss_step=0.012, train_loss_epoch=0.0126] Epoch 36: Train Loss = 0.012026657350361347\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=338, train_loss_step=0.0111, train_loss_epoch=0.012]Epoch 37: Train Loss = 0.011095781810581684\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=338, train_loss_step=0.0153, train_loss_epoch=0.0111]Epoch 38: Train Loss = 0.015287109650671482\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.0153] Epoch 39: Train Loss = 0.01100786030292511\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=338, train_loss_step=0.0105, train_loss_epoch=0.011]Epoch 40: Train Loss = 0.010521761141717434\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=338, train_loss_step=0.0124, train_loss_epoch=0.0105]Epoch 41: Train Loss = 0.012400895357131958\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=338, train_loss_step=0.015, train_loss_epoch=0.0124] Epoch 42: Train Loss = 0.015018370933830738\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.015]Epoch 43: Train Loss = 0.011726407334208488\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=338, train_loss_step=0.0125, train_loss_epoch=0.0117]Epoch 44: Train Loss = 0.012478714808821678\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=338, train_loss_step=0.00897, train_loss_epoch=0.0125]Epoch 45: Train Loss = 0.008968221955001354\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=338, train_loss_step=0.0145, train_loss_epoch=0.00897] Epoch 46: Train Loss = 0.01447498518973589\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=338, train_loss_step=0.0139, train_loss_epoch=0.0145] Epoch 47: Train Loss = 0.01386331021785736\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=338, train_loss_step=0.00914, train_loss_epoch=0.0139]Epoch 48: Train Loss = 0.009139186702668667\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=338, train_loss_step=0.00907, train_loss_epoch=0.00914]Epoch 49: Train Loss = 0.00907182414084673\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=338, train_loss_step=0.00937, train_loss_epoch=0.00907]Epoch 50: Train Loss = 0.009373507462441921\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=338, train_loss_step=0.0121, train_loss_epoch=0.00937] Epoch 51: Train Loss = 0.012120664119720459\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=338, train_loss_step=0.00987, train_loss_epoch=0.0121]Epoch 52: Train Loss = 0.009867995046079159\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=338, train_loss_step=0.00994, train_loss_epoch=0.00987]Epoch 53: Train Loss = 0.009942456148564816\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.00994] Epoch 54: Train Loss = 0.01172944251447916\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s, v_num=338, train_loss_step=0.0103, train_loss_epoch=0.0117] Epoch 55: Train Loss = 0.01033964566886425\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=338, train_loss_step=0.00969, train_loss_epoch=0.0103]Epoch 56: Train Loss = 0.009688079357147217\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=338, train_loss_step=0.0107, train_loss_epoch=0.00969] Epoch 57: Train Loss = 0.010740654543042183\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=338, train_loss_step=0.00883, train_loss_epoch=0.0107]Epoch 58: Train Loss = 0.008832915686070919\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=338, train_loss_step=0.0095, train_loss_epoch=0.00883] Epoch 59: Train Loss = 0.009499894455075264\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=338, train_loss_step=0.00919, train_loss_epoch=0.0095]Epoch 60: Train Loss = 0.009192713536322117\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=338, train_loss_step=0.0131, train_loss_epoch=0.00919] Epoch 61: Train Loss = 0.013078990392386913\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=338, train_loss_step=0.00986, train_loss_epoch=0.0131]Epoch 62: Train Loss = 0.009857885539531708\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=338, train_loss_step=0.0109, train_loss_epoch=0.00986] Epoch 63: Train Loss = 0.010859380476176739\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=338, train_loss_step=0.0115, train_loss_epoch=0.0109] Epoch 64: Train Loss = 0.011452707462012768\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=338, train_loss_step=0.0119, train_loss_epoch=0.0115]Epoch 65: Train Loss = 0.011868881992995739\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=338, train_loss_step=0.00897, train_loss_epoch=0.0119]Epoch 66: Train Loss = 0.008965595625340939\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.00897] Epoch 67: Train Loss = 0.011173203587532043\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=338, train_loss_step=0.0108, train_loss_epoch=0.0112] Epoch 68: Train Loss = 0.010844935663044453\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=338, train_loss_step=0.0146, train_loss_epoch=0.0108]Epoch 69: Train Loss = 0.014566265977919102\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=338, train_loss_step=0.0107, train_loss_epoch=0.0146]Epoch 70: Train Loss = 0.010732293128967285\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=338, train_loss_step=0.0067, train_loss_epoch=0.0107]Epoch 71: Train Loss = 0.006700760684907436\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=338, train_loss_step=0.00995, train_loss_epoch=0.0067]Epoch 72: Train Loss = 0.009946925565600395\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=338, train_loss_step=0.00931, train_loss_epoch=0.00995]Epoch 73: Train Loss = 0.00930874701589346\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=338, train_loss_step=0.00977, train_loss_epoch=0.00931]Epoch 74: Train Loss = 0.009765961207449436\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.00977]  Epoch 75: Train Loss = 0.010954237543046474\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=338, train_loss_step=0.00882, train_loss_epoch=0.011]Epoch 76: Train Loss = 0.008819573558866978\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.00882] Epoch 77: Train Loss = 0.01172181498259306\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s, v_num=338, train_loss_step=0.00835, train_loss_epoch=0.0117]Epoch 78: Train Loss = 0.0083494633436203\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s, v_num=338, train_loss_step=0.00922, train_loss_epoch=0.00835]Epoch 79: Train Loss = 0.00921592116355896\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=338, train_loss_step=0.00897, train_loss_epoch=0.00922]Epoch 80: Train Loss = 0.008974057622253895\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.00897] Epoch 81: Train Loss = 0.011359959840774536\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=338, train_loss_step=0.0135, train_loss_epoch=0.0114] Epoch 82: Train Loss = 0.013524127192795277\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.0135]Epoch 83: Train Loss = 0.012224718928337097\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=338, train_loss_step=0.00824, train_loss_epoch=0.0122]Epoch 84: Train Loss = 0.008244355209171772\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=338, train_loss_step=0.0125, train_loss_epoch=0.00824] Epoch 85: Train Loss = 0.012499821372330189\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.0125] Epoch 86: Train Loss = 0.011232760734856129\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=338, train_loss_step=0.00801, train_loss_epoch=0.0112]Epoch 87: Train Loss = 0.008006120100617409\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=338, train_loss_step=0.0103, train_loss_epoch=0.00801] Epoch 88: Train Loss = 0.010307908058166504\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=338, train_loss_step=0.00964, train_loss_epoch=0.0103]Epoch 89: Train Loss = 0.009639614261686802\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=338, train_loss_step=0.0121, train_loss_epoch=0.00964] Epoch 90: Train Loss = 0.012124655768275261\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s, v_num=338, train_loss_step=0.0121, train_loss_epoch=0.0121] Epoch 91: Train Loss = 0.01209202129393816\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.0121]Epoch 92: Train Loss = 0.01165852602571249\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=338, train_loss_step=0.0135, train_loss_epoch=0.0117]Epoch 93: Train Loss = 0.013490342535078526\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=338, train_loss_step=0.0124, train_loss_epoch=0.0135]Epoch 94: Train Loss = 0.012416399084031582\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.0124]Epoch 95: Train Loss = 0.012165672145783901\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=338, train_loss_step=0.0132, train_loss_epoch=0.0122]Epoch 96: Train Loss = 0.013243994675576687\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=338, train_loss_step=0.0106, train_loss_epoch=0.0132]Epoch 97: Train Loss = 0.010640344582498074\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=338, train_loss_step=0.0119, train_loss_epoch=0.0106]Epoch 98: Train Loss = 0.011895795352756977\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=338, train_loss_step=0.0139, train_loss_epoch=0.0119]Epoch 99: Train Loss = 0.01393390167504549\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=338, train_loss_step=0.0136, train_loss_epoch=0.0139]Epoch 100: Train Loss = 0.013613815419375896\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.0136]Epoch 101: Train Loss = 0.012156798504292965\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=338, train_loss_step=0.0126, train_loss_epoch=0.0122]Epoch 102: Train Loss = 0.012605381198227406\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=338, train_loss_step=0.0138, train_loss_epoch=0.0126]Epoch 103: Train Loss = 0.013816582970321178\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=338, train_loss_step=0.0124, train_loss_epoch=0.0138]Epoch 104: Train Loss = 0.012441113591194153\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=338, train_loss_step=0.0106, train_loss_epoch=0.0124]Epoch 105: Train Loss = 0.010635442100465298\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=338, train_loss_step=0.00919, train_loss_epoch=0.0106]Epoch 106: Train Loss = 0.009194388054311275\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.00919] Epoch 107: Train Loss = 0.011705480515956879\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.0117] Epoch 108: Train Loss = 0.012188638560473919\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=338, train_loss_step=0.0136, train_loss_epoch=0.0122]Epoch 109: Train Loss = 0.01360112614929676\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=338, train_loss_step=0.0111, train_loss_epoch=0.0136]Epoch 110: Train Loss = 0.01113708596676588\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=338, train_loss_step=0.00937, train_loss_epoch=0.0111]Epoch 111: Train Loss = 0.009370292536914349\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=338, train_loss_step=0.0109, train_loss_epoch=0.00937] Epoch 112: Train Loss = 0.010859322734177113\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=338, train_loss_step=0.0127, train_loss_epoch=0.0109] Epoch 113: Train Loss = 0.012706635519862175\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=338, train_loss_step=0.0103, train_loss_epoch=0.0127]Epoch 114: Train Loss = 0.010284028947353363\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=338, train_loss_step=0.00981, train_loss_epoch=0.0103]Epoch 115: Train Loss = 0.009813929907977581\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=338, train_loss_step=0.0105, train_loss_epoch=0.00981] Epoch 116: Train Loss = 0.010534025728702545\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0105] Epoch 117: Train Loss = 0.011386147700250149\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=338, train_loss_step=0.00834, train_loss_epoch=0.0114]Epoch 118: Train Loss = 0.008338854648172855\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=338, train_loss_step=0.0106, train_loss_epoch=0.00834] Epoch 119: Train Loss = 0.010555395856499672\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0106] Epoch 120: Train Loss = 0.011377066373825073\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.0114]Epoch 121: Train Loss = 0.012176841497421265\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=338, train_loss_step=0.0115, train_loss_epoch=0.0122]Epoch 122: Train Loss = 0.011546020396053791\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=338, train_loss_step=0.0124, train_loss_epoch=0.0115]Epoch 123: Train Loss = 0.012432568706572056\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=338, train_loss_step=0.0109, train_loss_epoch=0.0124]Epoch 124: Train Loss = 0.010914155282080173\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=338, train_loss_step=0.0107, train_loss_epoch=0.0109]Epoch 125: Train Loss = 0.010720514692366123\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=338, train_loss_step=0.0109, train_loss_epoch=0.0107]Epoch 126: Train Loss = 0.010899469256401062\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=338, train_loss_step=0.0123, train_loss_epoch=0.0109]Epoch 127: Train Loss = 0.01229795254766941\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=338, train_loss_step=0.0119, train_loss_epoch=0.0123]Epoch 128: Train Loss = 0.01190747320652008\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=338, train_loss_step=0.0138, train_loss_epoch=0.0119]Epoch 129: Train Loss = 0.01378482487052679\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.0138] Epoch 130: Train Loss = 0.010973633266985416\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=338, train_loss_step=0.0128, train_loss_epoch=0.011]Epoch 131: Train Loss = 0.012777725234627724\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=338, train_loss_step=0.0123, train_loss_epoch=0.0128]Epoch 132: Train Loss = 0.012306737713515759\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.0123]Epoch 133: Train Loss = 0.01222214661538601\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=338, train_loss_step=0.015, train_loss_epoch=0.0122] Epoch 134: Train Loss = 0.015014898963272572\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=338, train_loss_step=0.0126, train_loss_epoch=0.015]Epoch 135: Train Loss = 0.012630586512386799\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=338, train_loss_step=0.0138, train_loss_epoch=0.0126]Epoch 136: Train Loss = 0.013781349174678326\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0138]Epoch 137: Train Loss = 0.011434533633291721\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=338, train_loss_step=0.0108, train_loss_epoch=0.0114]Epoch 138: Train Loss = 0.010779432952404022\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=338, train_loss_step=0.0152, train_loss_epoch=0.0108]Epoch 139: Train Loss = 0.015167027711868286\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=338, train_loss_step=0.0119, train_loss_epoch=0.0152]Epoch 140: Train Loss = 0.011924536898732185\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 10.55it/s, v_num=338, train_loss_step=0.0113, train_loss_epoch=0.0119]Epoch 141: Train Loss = 0.011290040798485279\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=338, train_loss_step=0.0106, train_loss_epoch=0.0113]Epoch 142: Train Loss = 0.010587596334517002\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=338, train_loss_step=0.0118, train_loss_epoch=0.0106]Epoch 143: Train Loss = 0.011813550256192684\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=338, train_loss_step=0.00868, train_loss_epoch=0.0118]Epoch 144: Train Loss = 0.008682063780725002\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=338, train_loss_step=0.0098, train_loss_epoch=0.00868] Epoch 145: Train Loss = 0.009801057167351246\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=338, train_loss_step=0.0103, train_loss_epoch=0.0098] Epoch 146: Train Loss = 0.010343415662646294\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=338, train_loss_step=0.0138, train_loss_epoch=0.0103]Epoch 147: Train Loss = 0.01376528013497591\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=338, train_loss_step=0.012, train_loss_epoch=0.0138] Epoch 148: Train Loss = 0.012047809548676014\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=338, train_loss_step=0.0119, train_loss_epoch=0.012]Epoch 149: Train Loss = 0.011892341077327728\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=338, train_loss_step=0.0121, train_loss_epoch=0.0119]Epoch 150: Train Loss = 0.012148226611316204\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=338, train_loss_step=0.0121, train_loss_epoch=0.0121]Epoch 151: Train Loss = 0.012066428549587727\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=338, train_loss_step=0.0103, train_loss_epoch=0.0121]Epoch 152: Train Loss = 0.010291783139109612\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=338, train_loss_step=0.0147, train_loss_epoch=0.0103]Epoch 153: Train Loss = 0.014729231595993042\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.0147]Epoch 154: Train Loss = 0.012214339338243008\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.0122] Epoch 155: Train Loss = 0.010950724594295025\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=338, train_loss_step=0.0121, train_loss_epoch=0.011]Epoch 156: Train Loss = 0.01211586780846119\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=338, train_loss_step=0.0125, train_loss_epoch=0.0121]Epoch 157: Train Loss = 0.012514264322817326\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0125]Epoch 158: Train Loss = 0.011376097798347473\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=338, train_loss_step=0.0123, train_loss_epoch=0.0114]Epoch 159: Train Loss = 0.012254767119884491\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.0123]Epoch 160: Train Loss = 0.011196671053767204\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=338, train_loss_step=0.0141, train_loss_epoch=0.0112]Epoch 161: Train Loss = 0.014060442335903645\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=338, train_loss_step=0.0102, train_loss_epoch=0.0141]Epoch 162: Train Loss = 0.01016527134925127\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=338, train_loss_step=0.0118, train_loss_epoch=0.0102]Epoch 163: Train Loss = 0.011806138791143894\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0118]Epoch 164: Train Loss = 0.011440371163189411\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=338, train_loss_step=0.0118, train_loss_epoch=0.0114]Epoch 165: Train Loss = 0.011825092136859894\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=338, train_loss_step=0.00922, train_loss_epoch=0.0118]Epoch 166: Train Loss = 0.009218585677444935\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=338, train_loss_step=0.0133, train_loss_epoch=0.00922] Epoch 167: Train Loss = 0.013328037224709988\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=338, train_loss_step=0.00981, train_loss_epoch=0.0133]Epoch 168: Train Loss = 0.00981143955141306\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s, v_num=338, train_loss_step=0.0121, train_loss_epoch=0.00981] Epoch 169: Train Loss = 0.012074917554855347\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=338, train_loss_step=0.00989, train_loss_epoch=0.0121]Epoch 170: Train Loss = 0.009888947010040283\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=338, train_loss_step=0.0107, train_loss_epoch=0.00989] Epoch 171: Train Loss = 0.010686149820685387\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=338, train_loss_step=0.0127, train_loss_epoch=0.0107] Epoch 172: Train Loss = 0.012739707715809345\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=338, train_loss_step=0.0103, train_loss_epoch=0.0127]Epoch 173: Train Loss = 0.01029668003320694\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.0103]Epoch 174: Train Loss = 0.010374600999057293\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=338, train_loss_step=0.0103, train_loss_epoch=0.0104]Epoch 175: Train Loss = 0.010346456430852413\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=338, train_loss_step=0.0137, train_loss_epoch=0.0103]Epoch 176: Train Loss = 0.013723478652536869\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s, v_num=338, train_loss_step=0.00921, train_loss_epoch=0.0137]Epoch 177: Train Loss = 0.009214759804308414\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=338, train_loss_step=0.0125, train_loss_epoch=0.00921] Epoch 178: Train Loss = 0.012463423423469067\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=338, train_loss_step=0.00991, train_loss_epoch=0.0125]Epoch 179: Train Loss = 0.009907672181725502\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=338, train_loss_step=0.0107, train_loss_epoch=0.00991] Epoch 180: Train Loss = 0.010732941329479218\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=338, train_loss_step=0.0107, train_loss_epoch=0.0107] Epoch 181: Train Loss = 0.01073522586375475\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=338, train_loss_step=0.00839, train_loss_epoch=0.0107]Epoch 182: Train Loss = 0.008392061106860638\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.00839] Epoch 183: Train Loss = 0.011154485866427422\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=338, train_loss_step=0.0144, train_loss_epoch=0.0112] Epoch 184: Train Loss = 0.01440329197794199\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s, v_num=338, train_loss_step=0.0119, train_loss_epoch=0.0144]Epoch 185: Train Loss = 0.011880521662533283\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=338, train_loss_step=0.00898, train_loss_epoch=0.0119]Epoch 186: Train Loss = 0.008979735895991325\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.00898] Epoch 187: Train Loss = 0.011654287576675415\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=338, train_loss_step=0.0105, train_loss_epoch=0.0117] Epoch 188: Train Loss = 0.010467018000781536\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=338, train_loss_step=0.0125, train_loss_epoch=0.0105]Epoch 189: Train Loss = 0.012542619369924068\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=338, train_loss_step=0.0116, train_loss_epoch=0.0125]Epoch 190: Train Loss = 0.011635548435151577\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=338, train_loss_step=0.0142, train_loss_epoch=0.0116]Epoch 191: Train Loss = 0.014150843024253845\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=338, train_loss_step=0.0137, train_loss_epoch=0.0142]Epoch 192: Train Loss = 0.013661029748618603\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.0137] Epoch 193: Train Loss = 0.01097781676799059\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=338, train_loss_step=0.0124, train_loss_epoch=0.011]Epoch 194: Train Loss = 0.01241463515907526\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=338, train_loss_step=0.0124, train_loss_epoch=0.0124]Epoch 195: Train Loss = 0.012360678985714912\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=338, train_loss_step=0.0107, train_loss_epoch=0.0124]Epoch 196: Train Loss = 0.010732030496001244\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=338, train_loss_step=0.00941, train_loss_epoch=0.0107]Epoch 197: Train Loss = 0.0094142472371459\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=338, train_loss_step=0.013, train_loss_epoch=0.00941]  Epoch 198: Train Loss = 0.013043085113167763\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=338, train_loss_step=0.0147, train_loss_epoch=0.013] Epoch 199: Train Loss = 0.014690520241856575\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s, v_num=338, train_loss_step=0.0111, train_loss_epoch=0.0147]Epoch 200: Train Loss = 0.011090012267231941\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=338, train_loss_step=0.0123, train_loss_epoch=0.0111]Epoch 201: Train Loss = 0.012335713021457195\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=338, train_loss_step=0.00919, train_loss_epoch=0.0123]Epoch 202: Train Loss = 0.009191862307488918\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.00919] Epoch 203: Train Loss = 0.012193849310278893\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=338, train_loss_step=0.0124, train_loss_epoch=0.0122] Epoch 204: Train Loss = 0.012391207739710808\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=338, train_loss_step=0.0127, train_loss_epoch=0.0124]Epoch 205: Train Loss = 0.012659675441682339\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=338, train_loss_step=0.0126, train_loss_epoch=0.0127]Epoch 206: Train Loss = 0.012577992863953114\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=338, train_loss_step=0.0118, train_loss_epoch=0.0126]Epoch 207: Train Loss = 0.01175637822598219\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, v_num=338, train_loss_step=0.00867, train_loss_epoch=0.0118]Epoch 208: Train Loss = 0.008669198490679264\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=338, train_loss_step=0.0109, train_loss_epoch=0.00867] Epoch 209: Train Loss = 0.01089390181005001\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=338, train_loss_step=0.0126, train_loss_epoch=0.0109] Epoch 210: Train Loss = 0.012643863447010517\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=338, train_loss_step=0.0105, train_loss_epoch=0.0126]Epoch 211: Train Loss = 0.010531234554946423\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.0105]Epoch 212: Train Loss = 0.010402913205325603\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=338, train_loss_step=0.0113, train_loss_epoch=0.0104]Epoch 213: Train Loss = 0.011336475610733032\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 10.72it/s, v_num=338, train_loss_step=0.0102, train_loss_epoch=0.0113]Epoch 214: Train Loss = 0.010195423848927021\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=338, train_loss_step=0.0129, train_loss_epoch=0.0102]Epoch 215: Train Loss = 0.012862937524914742\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.0129] Epoch 216: Train Loss = 0.011009815149009228\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=338, train_loss_step=0.0151, train_loss_epoch=0.011]Epoch 217: Train Loss = 0.015101502649486065\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=338, train_loss_step=0.0102, train_loss_epoch=0.0151]Epoch 218: Train Loss = 0.010196506977081299\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s, v_num=338, train_loss_step=0.00807, train_loss_epoch=0.0102]Epoch 219: Train Loss = 0.00806777086108923\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.00807] Epoch 220: Train Loss = 0.010381902568042278\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=338, train_loss_step=0.0125, train_loss_epoch=0.0104] Epoch 221: Train Loss = 0.012482831254601479\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=338, train_loss_step=0.0115, train_loss_epoch=0.0125]Epoch 222: Train Loss = 0.01150556094944477\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=338, train_loss_step=0.0173, train_loss_epoch=0.0115]Epoch 223: Train Loss = 0.01731409877538681\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=338, train_loss_step=0.0136, train_loss_epoch=0.0173]Epoch 224: Train Loss = 0.01356371957808733\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=338, train_loss_step=0.013, train_loss_epoch=0.0136] Epoch 225: Train Loss = 0.01302856020629406\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, v_num=338, train_loss_step=0.0155, train_loss_epoch=0.013]Epoch 226: Train Loss = 0.015484651550650597\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=338, train_loss_step=0.0096, train_loss_epoch=0.0155]Epoch 227: Train Loss = 0.00959851499646902\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=338, train_loss_step=0.0132, train_loss_epoch=0.0096]Epoch 228: Train Loss = 0.013196034356951714\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=338, train_loss_step=0.0107, train_loss_epoch=0.0132]Epoch 229: Train Loss = 0.010683014057576656\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.0107]Epoch 230: Train Loss = 0.011183441616594791\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=338, train_loss_step=0.0126, train_loss_epoch=0.0112]Epoch 231: Train Loss = 0.012590733356773853\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=338, train_loss_step=0.0118, train_loss_epoch=0.0126]Epoch 232: Train Loss = 0.011800259351730347\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0118]Epoch 233: Train Loss = 0.011440565809607506\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=338, train_loss_step=0.0118, train_loss_epoch=0.0114]Epoch 234: Train Loss = 0.011786538176238537\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=338, train_loss_step=0.0127, train_loss_epoch=0.0118]Epoch 235: Train Loss = 0.012661224231123924\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=338, train_loss_step=0.00979, train_loss_epoch=0.0127]Epoch 236: Train Loss = 0.009791831485927105\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=338, train_loss_step=0.0123, train_loss_epoch=0.00979] Epoch 237: Train Loss = 0.012296346016228199\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=338, train_loss_step=0.00979, train_loss_epoch=0.0123]Epoch 238: Train Loss = 0.009789912961423397\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=338, train_loss_step=0.014, train_loss_epoch=0.00979]  Epoch 239: Train Loss = 0.013951512053608894\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=338, train_loss_step=0.00978, train_loss_epoch=0.014]Epoch 240: Train Loss = 0.009777079336345196\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.00978] Epoch 241: Train Loss = 0.011181548237800598\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=338, train_loss_step=0.0137, train_loss_epoch=0.0112] Epoch 242: Train Loss = 0.013692506588995457\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.0137]Epoch 243: Train Loss = 0.011171453632414341\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=338, train_loss_step=0.0152, train_loss_epoch=0.0112]Epoch 244: Train Loss = 0.015217394568026066\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0152]Epoch 245: Train Loss = 0.011358155868947506\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.0114]Epoch 246: Train Loss = 0.011723393574357033\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=338, train_loss_step=0.014, train_loss_epoch=0.0117] Epoch 247: Train Loss = 0.013994468376040459\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.014] Epoch 248: Train Loss = 0.010958067141473293\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=338, train_loss_step=0.0108, train_loss_epoch=0.011]Epoch 249: Train Loss = 0.010840744711458683\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=338, train_loss_step=0.0119, train_loss_epoch=0.0108]Epoch 250: Train Loss = 0.011907338164746761\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=338, train_loss_step=0.0129, train_loss_epoch=0.0119]Epoch 251: Train Loss = 0.012888294644653797\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=338, train_loss_step=0.00986, train_loss_epoch=0.0129]Epoch 252: Train Loss = 0.009858543984591961\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=338, train_loss_step=0.0129, train_loss_epoch=0.00986] Epoch 253: Train Loss = 0.012926560826599598\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=338, train_loss_step=0.00797, train_loss_epoch=0.0129]Epoch 254: Train Loss = 0.007974007166922092\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.00797] Epoch 255: Train Loss = 0.01119156088680029\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=338, train_loss_step=0.0106, train_loss_epoch=0.0112] Epoch 256: Train Loss = 0.010583766736090183\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=338, train_loss_step=0.0106, train_loss_epoch=0.0106]Epoch 257: Train Loss = 0.010570053942501545\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=338, train_loss_step=0.0109, train_loss_epoch=0.0106]Epoch 258: Train Loss = 0.010902924463152885\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=338, train_loss_step=0.00791, train_loss_epoch=0.0109]Epoch 259: Train Loss = 0.007909003645181656\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=338, train_loss_step=0.0137, train_loss_epoch=0.00791] Epoch 260: Train Loss = 0.013724712654948235\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=338, train_loss_step=0.00749, train_loss_epoch=0.0137]Epoch 261: Train Loss = 0.007489257026463747\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.00749] Epoch 262: Train Loss = 0.01216495968401432\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=338, train_loss_step=0.00786, train_loss_epoch=0.0122]Epoch 263: Train Loss = 0.007860331796109676\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=338, train_loss_step=0.0156, train_loss_epoch=0.00786] Epoch 264: Train Loss = 0.01563030108809471\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=338, train_loss_step=0.0068, train_loss_epoch=0.0156] Epoch 265: Train Loss = 0.00679836655035615\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=338, train_loss_step=0.0135, train_loss_epoch=0.0068]Epoch 266: Train Loss = 0.013476281426846981\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=338, train_loss_step=0.0102, train_loss_epoch=0.0135]Epoch 267: Train Loss = 0.010175633244216442\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 13.32it/s, v_num=338, train_loss_step=0.00969, train_loss_epoch=0.0102]Epoch 268: Train Loss = 0.009694620966911316\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=338, train_loss_step=0.00805, train_loss_epoch=0.00969]Epoch 269: Train Loss = 0.008050509728491306\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=338, train_loss_step=0.0125, train_loss_epoch=0.00805] Epoch 270: Train Loss = 0.0124684302136302\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s, v_num=338, train_loss_step=0.010, train_loss_epoch=0.0125]  Epoch 271: Train Loss = 0.010044114664196968\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=338, train_loss_step=0.00853, train_loss_epoch=0.010]Epoch 272: Train Loss = 0.008533705025911331\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=338, train_loss_step=0.00987, train_loss_epoch=0.00853]Epoch 273: Train Loss = 0.009868740104138851\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=338, train_loss_step=0.00993, train_loss_epoch=0.00987]Epoch 274: Train Loss = 0.00993258971720934\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=338, train_loss_step=0.009, train_loss_epoch=0.00993]  Epoch 275: Train Loss = 0.009003879502415657\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=338, train_loss_step=0.0142, train_loss_epoch=0.009] Epoch 276: Train Loss = 0.014243939891457558\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=338, train_loss_step=0.0118, train_loss_epoch=0.0142]Epoch 277: Train Loss = 0.011762798763811588\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=338, train_loss_step=0.0153, train_loss_epoch=0.0118]Epoch 278: Train Loss = 0.01533866673707962\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.0153]Epoch 279: Train Loss = 0.01169725600630045\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=338, train_loss_step=0.0121, train_loss_epoch=0.0117]Epoch 280: Train Loss = 0.01207841094583273\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0121]Epoch 281: Train Loss = 0.011426749639213085\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=338, train_loss_step=0.00963, train_loss_epoch=0.0114]Epoch 282: Train Loss = 0.009630740620195866\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=338, train_loss_step=0.00742, train_loss_epoch=0.00963]Epoch 283: Train Loss = 0.007416271138936281\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=338, train_loss_step=0.00933, train_loss_epoch=0.00742]Epoch 284: Train Loss = 0.009325405582785606\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=338, train_loss_step=0.0135, train_loss_epoch=0.00933] Epoch 285: Train Loss = 0.013500967063009739\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=338, train_loss_step=0.0109, train_loss_epoch=0.0135] Epoch 286: Train Loss = 0.010852242819964886\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.0109]Epoch 287: Train Loss = 0.010360747575759888\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0104]Epoch 288: Train Loss = 0.011429068632423878\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0114]Epoch 289: Train Loss = 0.011438432149589062\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=338, train_loss_step=0.0106, train_loss_epoch=0.0114]Epoch 290: Train Loss = 0.010591932572424412\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=338, train_loss_step=0.00925, train_loss_epoch=0.0106]Epoch 291: Train Loss = 0.009252792224287987\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=338, train_loss_step=0.0108, train_loss_epoch=0.00925] Epoch 292: Train Loss = 0.010809595696628094\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=338, train_loss_step=0.0132, train_loss_epoch=0.0108] Epoch 293: Train Loss = 0.013174586929380894\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=338, train_loss_step=0.00957, train_loss_epoch=0.0132]Epoch 294: Train Loss = 0.009568337351083755\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 10.97it/s, v_num=338, train_loss_step=0.0125, train_loss_epoch=0.00957] Epoch 295: Train Loss = 0.012452760711312294\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.0125] Epoch 296: Train Loss = 0.01035240851342678\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=338, train_loss_step=0.00924, train_loss_epoch=0.0104]Epoch 297: Train Loss = 0.009237918071448803\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=338, train_loss_step=0.00794, train_loss_epoch=0.00924]Epoch 298: Train Loss = 0.007942428812384605\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=338, train_loss_step=0.0074, train_loss_epoch=0.00794] Epoch 299: Train Loss = 0.007402620278298855\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=338, train_loss_step=0.00913, train_loss_epoch=0.0074]Epoch 300: Train Loss = 0.009129446931183338\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=338, train_loss_step=0.0115, train_loss_epoch=0.00913] Epoch 301: Train Loss = 0.0115429712459445\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=338, train_loss_step=0.00872, train_loss_epoch=0.0115]Epoch 302: Train Loss = 0.008723335340619087\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=338, train_loss_step=0.0116, train_loss_epoch=0.00872] Epoch 303: Train Loss = 0.011606389656662941\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.0116] Epoch 304: Train Loss = 0.012199998833239079\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.0122] Epoch 305: Train Loss = 0.011013330891728401\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=338, train_loss_step=0.0102, train_loss_epoch=0.011]Epoch 306: Train Loss = 0.010216964408755302\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=338, train_loss_step=0.0145, train_loss_epoch=0.0102]Epoch 307: Train Loss = 0.014453091658651829\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=338, train_loss_step=0.0113, train_loss_epoch=0.0145]Epoch 308: Train Loss = 0.011297213844954967\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.0113]Epoch 309: Train Loss = 0.010376541875302792\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.0104] Epoch 310: Train Loss = 0.011009620502591133\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=338, train_loss_step=0.0128, train_loss_epoch=0.011]Epoch 311: Train Loss = 0.012758538126945496\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=338, train_loss_step=0.00846, train_loss_epoch=0.0128]Epoch 312: Train Loss = 0.008458239026367664\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 11.27it/s, v_num=338, train_loss_step=0.0111, train_loss_epoch=0.00846] Epoch 313: Train Loss = 0.011084041558206081\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=338, train_loss_step=0.00991, train_loss_epoch=0.0111]Epoch 314: Train Loss = 0.0099127646535635\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.00991] Epoch 315: Train Loss = 0.010445661842823029\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=338, train_loss_step=0.0129, train_loss_epoch=0.0104] Epoch 316: Train Loss = 0.012894981540739536\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=338, train_loss_step=0.00861, train_loss_epoch=0.0129]Epoch 317: Train Loss = 0.008610794320702553\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=338, train_loss_step=0.0126, train_loss_epoch=0.00861] Epoch 318: Train Loss = 0.012646627612411976\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.0126] Epoch 319: Train Loss = 0.010387168265879154\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=338, train_loss_step=0.0123, train_loss_epoch=0.0104]Epoch 320: Train Loss = 0.012255224399268627\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=338, train_loss_step=0.00811, train_loss_epoch=0.0123]Epoch 321: Train Loss = 0.008111962117254734\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s, v_num=338, train_loss_step=0.00958, train_loss_epoch=0.00811]Epoch 322: Train Loss = 0.009583092294633389\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=338, train_loss_step=0.0129, train_loss_epoch=0.00958] Epoch 323: Train Loss = 0.012882866896688938\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=338, train_loss_step=0.00841, train_loss_epoch=0.0129]Epoch 324: Train Loss = 0.008412486873567104\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=338, train_loss_step=0.0113, train_loss_epoch=0.00841] Epoch 325: Train Loss = 0.011260163970291615\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=338, train_loss_step=0.0124, train_loss_epoch=0.0113] Epoch 326: Train Loss = 0.012362650595605373\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=338, train_loss_step=0.0118, train_loss_epoch=0.0124]Epoch 327: Train Loss = 0.011811593547463417\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=338, train_loss_step=0.013, train_loss_epoch=0.0118] Epoch 328: Train Loss = 0.013007166795432568\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=338, train_loss_step=0.0079, train_loss_epoch=0.013]Epoch 329: Train Loss = 0.007897446863353252\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=338, train_loss_step=0.0101, train_loss_epoch=0.0079]Epoch 330: Train Loss = 0.010131287388503551\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=338, train_loss_step=0.0115, train_loss_epoch=0.0101]Epoch 331: Train Loss = 0.011465252377092838\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=338, train_loss_step=0.0142, train_loss_epoch=0.0115]Epoch 332: Train Loss = 0.01418486051261425\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=338, train_loss_step=0.00993, train_loss_epoch=0.0142]Epoch 333: Train Loss = 0.009932330809533596\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=338, train_loss_step=0.0144, train_loss_epoch=0.00993] Epoch 334: Train Loss = 0.014421959407627583\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=338, train_loss_step=0.00913, train_loss_epoch=0.0144]Epoch 335: Train Loss = 0.009128924459218979\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=338, train_loss_step=0.0119, train_loss_epoch=0.00913] Epoch 336: Train Loss = 0.011876271106302738\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=338, train_loss_step=0.0102, train_loss_epoch=0.0119] Epoch 337: Train Loss = 0.01022112276405096\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=338, train_loss_step=0.0121, train_loss_epoch=0.0102]Epoch 338: Train Loss = 0.012128688395023346\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=338, train_loss_step=0.0111, train_loss_epoch=0.0121]Epoch 339: Train Loss = 0.01111871562898159\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=338, train_loss_step=0.00968, train_loss_epoch=0.0111]Epoch 340: Train Loss = 0.009680673480033875\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.00968] Epoch 341: Train Loss = 0.011696591973304749\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=338, train_loss_step=0.00871, train_loss_epoch=0.0117]Epoch 342: Train Loss = 0.008714196272194386\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=338, train_loss_step=0.00855, train_loss_epoch=0.00871]Epoch 343: Train Loss = 0.008550317026674747\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.00855] Epoch 344: Train Loss = 0.011235780082643032\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=338, train_loss_step=0.0147, train_loss_epoch=0.0112] Epoch 345: Train Loss = 0.01469171978533268\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=338, train_loss_step=0.0076, train_loss_epoch=0.0147]Epoch 346: Train Loss = 0.007601070683449507\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=338, train_loss_step=0.0076, train_loss_epoch=0.0076]Epoch 347: Train Loss = 0.007598807569593191\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.0076]Epoch 348: Train Loss = 0.010396293364465237\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=338, train_loss_step=0.0101, train_loss_epoch=0.0104]Epoch 349: Train Loss = 0.010137529112398624\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=338, train_loss_step=0.00995, train_loss_epoch=0.0101]Epoch 350: Train Loss = 0.00995413213968277\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=338, train_loss_step=0.0116, train_loss_epoch=0.00995] Epoch 351: Train Loss = 0.01160368137061596\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.0116] Epoch 352: Train Loss = 0.012194120325148106\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=338, train_loss_step=0.00832, train_loss_epoch=0.0122]Epoch 353: Train Loss = 0.008315855637192726\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=338, train_loss_step=0.00973, train_loss_epoch=0.00832]Epoch 354: Train Loss = 0.009728757664561272\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=338, train_loss_step=0.00994, train_loss_epoch=0.00973]Epoch 355: Train Loss = 0.009938384406268597\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=338, train_loss_step=0.0133, train_loss_epoch=0.00994] Epoch 356: Train Loss = 0.013334310613572598\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=338, train_loss_step=0.00863, train_loss_epoch=0.0133]Epoch 357: Train Loss = 0.008629697374999523\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=338, train_loss_step=0.00995, train_loss_epoch=0.00863]Epoch 358: Train Loss = 0.009953767992556095\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=338, train_loss_step=0.00832, train_loss_epoch=0.00995]Epoch 359: Train Loss = 0.008323049172759056\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=338, train_loss_step=0.0137, train_loss_epoch=0.00832] Epoch 360: Train Loss = 0.01371449138969183\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=338, train_loss_step=0.0113, train_loss_epoch=0.0137] Epoch 361: Train Loss = 0.011253648437559605\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=338, train_loss_step=0.00776, train_loss_epoch=0.0113]Epoch 362: Train Loss = 0.007761597633361816\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=338, train_loss_step=0.0109, train_loss_epoch=0.00776] Epoch 363: Train Loss = 0.010896117426455021\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=338, train_loss_step=0.0109, train_loss_epoch=0.0109] Epoch 364: Train Loss = 0.010915976949036121\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=338, train_loss_step=0.00941, train_loss_epoch=0.0109]Epoch 365: Train Loss = 0.009411145932972431\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=338, train_loss_step=0.00902, train_loss_epoch=0.00941]Epoch 366: Train Loss = 0.009020579047501087\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=338, train_loss_step=0.00875, train_loss_epoch=0.00902]Epoch 367: Train Loss = 0.00874683354049921\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=338, train_loss_step=0.0101, train_loss_epoch=0.00875] Epoch 368: Train Loss = 0.010065244510769844\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=338, train_loss_step=0.0111, train_loss_epoch=0.0101] Epoch 369: Train Loss = 0.011136760003864765\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=338, train_loss_step=0.00909, train_loss_epoch=0.0111]Epoch 370: Train Loss = 0.009086626581847668\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=338, train_loss_step=0.00863, train_loss_epoch=0.00909]Epoch 371: Train Loss = 0.00863049365580082\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=338, train_loss_step=0.013, train_loss_epoch=0.00863]  Epoch 372: Train Loss = 0.013034538365900517\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, v_num=338, train_loss_step=0.0138, train_loss_epoch=0.013] Epoch 373: Train Loss = 0.013779298402369022\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=338, train_loss_step=0.00896, train_loss_epoch=0.0138]Epoch 374: Train Loss = 0.008957495912909508\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=338, train_loss_step=0.00914, train_loss_epoch=0.00896]Epoch 375: Train Loss = 0.009141569957137108\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=338, train_loss_step=0.00897, train_loss_epoch=0.00914]Epoch 376: Train Loss = 0.0089705940335989\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=338, train_loss_step=0.0102, train_loss_epoch=0.00897] Epoch 377: Train Loss = 0.010218004696071148\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=338, train_loss_step=0.0105, train_loss_epoch=0.0102] Epoch 378: Train Loss = 0.01052255928516388\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s, v_num=338, train_loss_step=0.00986, train_loss_epoch=0.0105]Epoch 379: Train Loss = 0.00985897146165371\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=338, train_loss_step=0.00929, train_loss_epoch=0.00986]Epoch 380: Train Loss = 0.009289388544857502\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s, v_num=338, train_loss_step=0.00856, train_loss_epoch=0.00929]Epoch 381: Train Loss = 0.008563853800296783\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=338, train_loss_step=0.00945, train_loss_epoch=0.00856]Epoch 382: Train Loss = 0.00945145171135664\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=338, train_loss_step=0.00944, train_loss_epoch=0.00945]Epoch 383: Train Loss = 0.00944454688578844\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=338, train_loss_step=0.0108, train_loss_epoch=0.00944] Epoch 384: Train Loss = 0.01082679908722639\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=338, train_loss_step=0.00869, train_loss_epoch=0.0108]Epoch 385: Train Loss = 0.008688307367265224\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.00869] Epoch 386: Train Loss = 0.011242805980145931\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0112] Epoch 387: Train Loss = 0.011446746066212654\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=338, train_loss_step=0.00943, train_loss_epoch=0.0114]Epoch 388: Train Loss = 0.009427917189896107\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=338, train_loss_step=0.00787, train_loss_epoch=0.00943]Epoch 389: Train Loss = 0.007867882959544659\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=338, train_loss_step=0.0115, train_loss_epoch=0.00787] Epoch 390: Train Loss = 0.0115449707955122\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=338, train_loss_step=0.00933, train_loss_epoch=0.0115]Epoch 391: Train Loss = 0.009332920424640179\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.00933] Epoch 392: Train Loss = 0.011157802306115627\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=338, train_loss_step=0.00844, train_loss_epoch=0.0112]Epoch 393: Train Loss = 0.00843691173940897\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=338, train_loss_step=0.00755, train_loss_epoch=0.00844]Epoch 394: Train Loss = 0.007552311290055513\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=338, train_loss_step=0.0101, train_loss_epoch=0.00755] Epoch 395: Train Loss = 0.010136165656149387\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=338, train_loss_step=0.00897, train_loss_epoch=0.0101]Epoch 396: Train Loss = 0.008968843147158623\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=338, train_loss_step=0.00863, train_loss_epoch=0.00897]Epoch 397: Train Loss = 0.008631651289761066\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=338, train_loss_step=0.0103, train_loss_epoch=0.00863] Epoch 398: Train Loss = 0.010316943749785423\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s, v_num=338, train_loss_step=0.00911, train_loss_epoch=0.0103]Epoch 399: Train Loss = 0.00911339558660984\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=338, train_loss_step=0.00958, train_loss_epoch=0.00911]Epoch 400: Train Loss = 0.009581737220287323\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=338, train_loss_step=0.00913, train_loss_epoch=0.00958]Epoch 401: Train Loss = 0.009133175946772099\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=338, train_loss_step=0.00851, train_loss_epoch=0.00913]Epoch 402: Train Loss = 0.008512095548212528\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s, v_num=338, train_loss_step=0.00978, train_loss_epoch=0.00851]Epoch 403: Train Loss = 0.009780113585293293\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=338, train_loss_step=0.0096, train_loss_epoch=0.00978] Epoch 404: Train Loss = 0.009596512652933598\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=338, train_loss_step=0.00944, train_loss_epoch=0.0096]Epoch 405: Train Loss = 0.009435795247554779\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=338, train_loss_step=0.00861, train_loss_epoch=0.00944]Epoch 406: Train Loss = 0.008612879551947117\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=338, train_loss_step=0.00979, train_loss_epoch=0.00861]Epoch 407: Train Loss = 0.009787521325051785\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.00979] Epoch 408: Train Loss = 0.01219808030873537\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=338, train_loss_step=0.00881, train_loss_epoch=0.0122]Epoch 409: Train Loss = 0.008807354606688023\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=338, train_loss_step=0.0108, train_loss_epoch=0.00881] Epoch 410: Train Loss = 0.010798548348248005\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=338, train_loss_step=0.0125, train_loss_epoch=0.0108] Epoch 411: Train Loss = 0.012512105517089367\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=338, train_loss_step=0.00754, train_loss_epoch=0.0125]Epoch 412: Train Loss = 0.007540270686149597\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=338, train_loss_step=0.00957, train_loss_epoch=0.00754]Epoch 413: Train Loss = 0.00957140140235424\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=338, train_loss_step=0.0108, train_loss_epoch=0.00957] Epoch 414: Train Loss = 0.010766332037746906\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=338, train_loss_step=0.0116, train_loss_epoch=0.0108] Epoch 415: Train Loss = 0.011618779972195625\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=338, train_loss_step=0.0114, train_loss_epoch=0.0116]Epoch 416: Train Loss = 0.011354455724358559\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=338, train_loss_step=0.00937, train_loss_epoch=0.0114]Epoch 417: Train Loss = 0.00937062781304121\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=338, train_loss_step=0.0098, train_loss_epoch=0.00937] Epoch 418: Train Loss = 0.009797313250601292\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.0098]  Epoch 419: Train Loss = 0.011015648022294044\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s, v_num=338, train_loss_step=0.00817, train_loss_epoch=0.011]Epoch 420: Train Loss = 0.008166396990418434\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=338, train_loss_step=0.0128, train_loss_epoch=0.00817] Epoch 421: Train Loss = 0.012805616483092308\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=338, train_loss_step=0.0101, train_loss_epoch=0.0128] Epoch 422: Train Loss = 0.010058684274554253\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=338, train_loss_step=0.00847, train_loss_epoch=0.0101]Epoch 423: Train Loss = 0.00846739299595356\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=338, train_loss_step=0.0123, train_loss_epoch=0.00847] Epoch 424: Train Loss = 0.012278184294700623\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=338, train_loss_step=0.0108, train_loss_epoch=0.0123] Epoch 425: Train Loss = 0.010848143137991428\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=338, train_loss_step=0.00988, train_loss_epoch=0.0108]Epoch 426: Train Loss = 0.009882098063826561\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=338, train_loss_step=0.00817, train_loss_epoch=0.00988]Epoch 427: Train Loss = 0.008171072229743004\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=338, train_loss_step=0.0096, train_loss_epoch=0.00817] Epoch 428: Train Loss = 0.009597739204764366\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=338, train_loss_step=0.00724, train_loss_epoch=0.0096]Epoch 429: Train Loss = 0.007235965225845575\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=338, train_loss_step=0.00948, train_loss_epoch=0.00724]Epoch 430: Train Loss = 0.009483002126216888\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=338, train_loss_step=0.00833, train_loss_epoch=0.00948]Epoch 431: Train Loss = 0.008332958444952965\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=338, train_loss_step=0.00748, train_loss_epoch=0.00833]Epoch 432: Train Loss = 0.007475463207811117\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=338, train_loss_step=0.00974, train_loss_epoch=0.00748]Epoch 433: Train Loss = 0.009735314175486565\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=338, train_loss_step=0.00934, train_loss_epoch=0.00974]Epoch 434: Train Loss = 0.009338024072349072\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.00934] Epoch 435: Train Loss = 0.011692412197589874\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=338, train_loss_step=0.0103, train_loss_epoch=0.0117] Epoch 436: Train Loss = 0.010342882946133614\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.0103] Epoch 437: Train Loss = 0.01099433097988367\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=338, train_loss_step=0.00967, train_loss_epoch=0.011]Epoch 438: Train Loss = 0.009674251079559326\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=338, train_loss_step=0.00766, train_loss_epoch=0.00967]Epoch 439: Train Loss = 0.007659574504941702\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=338, train_loss_step=0.0141, train_loss_epoch=0.00766] Epoch 440: Train Loss = 0.014076241292059422\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=338, train_loss_step=0.00846, train_loss_epoch=0.0141]Epoch 441: Train Loss = 0.00846096221357584\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=338, train_loss_step=0.00755, train_loss_epoch=0.00846]Epoch 442: Train Loss = 0.007554598618298769\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=338, train_loss_step=0.0107, train_loss_epoch=0.00755] Epoch 443: Train Loss = 0.01073569804430008\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=338, train_loss_step=0.00826, train_loss_epoch=0.0107]Epoch 444: Train Loss = 0.008259996771812439\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=338, train_loss_step=0.0097, train_loss_epoch=0.00826] Epoch 445: Train Loss = 0.009696966968476772\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=338, train_loss_step=0.00861, train_loss_epoch=0.0097]Epoch 446: Train Loss = 0.008610601536929607\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=338, train_loss_step=0.00833, train_loss_epoch=0.00861]Epoch 447: Train Loss = 0.008330196142196655\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=338, train_loss_step=0.0131, train_loss_epoch=0.00833] Epoch 448: Train Loss = 0.013118588365614414\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=338, train_loss_step=0.0075, train_loss_epoch=0.0131] Epoch 449: Train Loss = 0.007500047329813242\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=338, train_loss_step=0.0115, train_loss_epoch=0.0075]Epoch 450: Train Loss = 0.011451736092567444\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=338, train_loss_step=0.011, train_loss_epoch=0.0115] Epoch 451: Train Loss = 0.01097891479730606\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=338, train_loss_step=0.0122, train_loss_epoch=0.011]Epoch 452: Train Loss = 0.012193369679152966\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=338, train_loss_step=0.0106, train_loss_epoch=0.0122]Epoch 453: Train Loss = 0.010583273135125637\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s, v_num=338, train_loss_step=0.00979, train_loss_epoch=0.0106]Epoch 454: Train Loss = 0.009792089462280273\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=338, train_loss_step=0.0101, train_loss_epoch=0.00979] Epoch 455: Train Loss = 0.010126878507435322\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=338, train_loss_step=0.0094, train_loss_epoch=0.0101] Epoch 456: Train Loss = 0.00940391980111599\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=338, train_loss_step=0.00734, train_loss_epoch=0.0094]Epoch 457: Train Loss = 0.007335831876844168\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=338, train_loss_step=0.00959, train_loss_epoch=0.00734]Epoch 458: Train Loss = 0.0095879677683115\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=338, train_loss_step=0.00825, train_loss_epoch=0.00959]Epoch 459: Train Loss = 0.008254015818238258\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=338, train_loss_step=0.0105, train_loss_epoch=0.00825] Epoch 460: Train Loss = 0.010459438897669315\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=338, train_loss_step=0.0121, train_loss_epoch=0.0105] Epoch 461: Train Loss = 0.012127652764320374\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=338, train_loss_step=0.00828, train_loss_epoch=0.0121]Epoch 462: Train Loss = 0.008282606489956379\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=338, train_loss_step=0.0086, train_loss_epoch=0.00828] Epoch 463: Train Loss = 0.008596723899245262\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=338, train_loss_step=0.0118, train_loss_epoch=0.0086] Epoch 464: Train Loss = 0.011791260913014412\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, v_num=338, train_loss_step=0.0117, train_loss_epoch=0.0118]Epoch 465: Train Loss = 0.011701872572302818\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=338, train_loss_step=0.00866, train_loss_epoch=0.0117]Epoch 466: Train Loss = 0.008664635941386223\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=338, train_loss_step=0.00787, train_loss_epoch=0.00866]Epoch 467: Train Loss = 0.007865493185818195\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=338, train_loss_step=0.00968, train_loss_epoch=0.00787]Epoch 468: Train Loss = 0.00967655424028635\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=338, train_loss_step=0.0102, train_loss_epoch=0.00968] Epoch 469: Train Loss = 0.010176063515245914\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=338, train_loss_step=0.00897, train_loss_epoch=0.0102]Epoch 470: Train Loss = 0.008965165354311466\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=338, train_loss_step=0.00796, train_loss_epoch=0.00897]Epoch 471: Train Loss = 0.007960686460137367\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=338, train_loss_step=0.0106, train_loss_epoch=0.00796] Epoch 472: Train Loss = 0.010634860023856163\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=338, train_loss_step=0.00954, train_loss_epoch=0.0106]Epoch 473: Train Loss = 0.009540005587041378\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=338, train_loss_step=0.00898, train_loss_epoch=0.00954]Epoch 474: Train Loss = 0.00897976290434599\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=338, train_loss_step=0.00889, train_loss_epoch=0.00898]Epoch 475: Train Loss = 0.008892524056136608\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=338, train_loss_step=0.00907, train_loss_epoch=0.00889]Epoch 476: Train Loss = 0.00906639825552702\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=338, train_loss_step=0.00847, train_loss_epoch=0.00907]Epoch 477: Train Loss = 0.008465247228741646\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=338, train_loss_step=0.00746, train_loss_epoch=0.00847]Epoch 478: Train Loss = 0.007459466811269522\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=338, train_loss_step=0.010, train_loss_epoch=0.00746]  Epoch 479: Train Loss = 0.01003385428339243\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.010] Epoch 480: Train Loss = 0.01041970681399107\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=338, train_loss_step=0.0104, train_loss_epoch=0.0104]Epoch 481: Train Loss = 0.01043805293738842\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=338, train_loss_step=0.00968, train_loss_epoch=0.0104]Epoch 482: Train Loss = 0.009679238311946392\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=338, train_loss_step=0.00944, train_loss_epoch=0.00968]Epoch 483: Train Loss = 0.009436093270778656\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=338, train_loss_step=0.00907, train_loss_epoch=0.00944]Epoch 484: Train Loss = 0.009074562229216099\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=338, train_loss_step=0.0112, train_loss_epoch=0.00907] Epoch 485: Train Loss = 0.0112334955483675\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=338, train_loss_step=0.00835, train_loss_epoch=0.0112]Epoch 486: Train Loss = 0.008350570686161518\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=338, train_loss_step=0.0082, train_loss_epoch=0.00835] Epoch 487: Train Loss = 0.008201592601835728\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=338, train_loss_step=0.00972, train_loss_epoch=0.0082]Epoch 488: Train Loss = 0.009722767397761345\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=338, train_loss_step=0.0107, train_loss_epoch=0.00972] Epoch 489: Train Loss = 0.010732317343354225\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=338, train_loss_step=0.00851, train_loss_epoch=0.0107]Epoch 490: Train Loss = 0.00850649457424879\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=338, train_loss_step=0.0108, train_loss_epoch=0.00851] Epoch 491: Train Loss = 0.010807940736413002\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=338, train_loss_step=0.00947, train_loss_epoch=0.0108]Epoch 492: Train Loss = 0.009466205723583698\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=338, train_loss_step=0.0086, train_loss_epoch=0.00947] Epoch 493: Train Loss = 0.008596272207796574\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 11.50it/s, v_num=338, train_loss_step=0.0126, train_loss_epoch=0.0086] Epoch 494: Train Loss = 0.012632637284696102\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=338, train_loss_step=0.00838, train_loss_epoch=0.0126]Epoch 495: Train Loss = 0.008378992788493633\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s, v_num=338, train_loss_step=0.00897, train_loss_epoch=0.00838]Epoch 496: Train Loss = 0.008965312503278255\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=338, train_loss_step=0.00983, train_loss_epoch=0.00897]Epoch 497: Train Loss = 0.009827584028244019\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=338, train_loss_step=0.00922, train_loss_epoch=0.00983]Epoch 498: Train Loss = 0.009220324456691742\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=338, train_loss_step=0.00859, train_loss_epoch=0.00922]Epoch 499: Train Loss = 0.008592608384788036\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=338, train_loss_step=0.00859, train_loss_epoch=0.00859]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=338, train_loss_step=0.00859, train_loss_epoch=0.00859]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.36it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 6: from 2008-05-12 00:00:00 to 2022-08-18 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=342, train_loss_step=0.0219]Epoch 0: Train Loss = 0.021857116371393204\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=342, train_loss_step=0.0334, train_loss_epoch=0.0219]Epoch 1: Train Loss = 0.033394720405340195\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=342, train_loss_step=0.0346, train_loss_epoch=0.0334]Epoch 2: Train Loss = 0.03457224741578102\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=342, train_loss_step=0.0166, train_loss_epoch=0.0346]Epoch 3: Train Loss = 0.016613153740763664\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=342, train_loss_step=0.0224, train_loss_epoch=0.0166]Epoch 4: Train Loss = 0.02237122878432274\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=342, train_loss_step=0.0157, train_loss_epoch=0.0224]Epoch 5: Train Loss = 0.015655944123864174\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=342, train_loss_step=0.0203, train_loss_epoch=0.0157]Epoch 6: Train Loss = 0.020288169384002686\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=342, train_loss_step=0.019, train_loss_epoch=0.0203] Epoch 7: Train Loss = 0.01899472437798977\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=342, train_loss_step=0.0141, train_loss_epoch=0.019]Epoch 8: Train Loss = 0.014137993566691875\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=342, train_loss_step=0.0168, train_loss_epoch=0.0141]Epoch 9: Train Loss = 0.016803447157144547\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=342, train_loss_step=0.0191, train_loss_epoch=0.0168]Epoch 10: Train Loss = 0.01905246078968048\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=342, train_loss_step=0.0158, train_loss_epoch=0.0191]Epoch 11: Train Loss = 0.015794914215803146\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=342, train_loss_step=0.0151, train_loss_epoch=0.0158]Epoch 12: Train Loss = 0.015053137205541134\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=342, train_loss_step=0.0147, train_loss_epoch=0.0151]Epoch 13: Train Loss = 0.014741667546331882\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=342, train_loss_step=0.0151, train_loss_epoch=0.0147]Epoch 14: Train Loss = 0.015084339305758476\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=342, train_loss_step=0.0164, train_loss_epoch=0.0151]Epoch 15: Train Loss = 0.016391079872846603\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=342, train_loss_step=0.0142, train_loss_epoch=0.0164]Epoch 16: Train Loss = 0.014198442921042442\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=342, train_loss_step=0.0176, train_loss_epoch=0.0142]Epoch 17: Train Loss = 0.017598802223801613\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s, v_num=342, train_loss_step=0.0135, train_loss_epoch=0.0176]Epoch 18: Train Loss = 0.013471036218106747\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=342, train_loss_step=0.011, train_loss_epoch=0.0135] Epoch 19: Train Loss = 0.01099720411002636\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=342, train_loss_step=0.0116, train_loss_epoch=0.011]Epoch 20: Train Loss = 0.01162211038172245\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=342, train_loss_step=0.0101, train_loss_epoch=0.0116]Epoch 21: Train Loss = 0.010068245232105255\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=342, train_loss_step=0.0112, train_loss_epoch=0.0101]Epoch 22: Train Loss = 0.011228146031498909\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=342, train_loss_step=0.0176, train_loss_epoch=0.0112]Epoch 23: Train Loss = 0.01762976124882698\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=342, train_loss_step=0.0106, train_loss_epoch=0.0176]Epoch 24: Train Loss = 0.010610691271722317\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=342, train_loss_step=0.0113, train_loss_epoch=0.0106]Epoch 25: Train Loss = 0.0113051263615489\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=342, train_loss_step=0.0112, train_loss_epoch=0.0113]Epoch 26: Train Loss = 0.01124939788132906\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=342, train_loss_step=0.00927, train_loss_epoch=0.0112]Epoch 27: Train Loss = 0.009267902001738548\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=342, train_loss_step=0.00973, train_loss_epoch=0.00927]Epoch 28: Train Loss = 0.009725654497742653\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=342, train_loss_step=0.0158, train_loss_epoch=0.00973] Epoch 29: Train Loss = 0.015797073021531105\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=342, train_loss_step=0.0117, train_loss_epoch=0.0158] Epoch 30: Train Loss = 0.0116939228028059\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=342, train_loss_step=0.00995, train_loss_epoch=0.0117]Epoch 31: Train Loss = 0.009949968196451664\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=342, train_loss_step=0.0127, train_loss_epoch=0.00995] Epoch 32: Train Loss = 0.012737847864627838\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.0127] Epoch 33: Train Loss = 0.010685427114367485\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=342, train_loss_step=0.0126, train_loss_epoch=0.0107]Epoch 34: Train Loss = 0.012622586451470852\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=342, train_loss_step=0.0125, train_loss_epoch=0.0126]Epoch 35: Train Loss = 0.012476365081965923\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=342, train_loss_step=0.0141, train_loss_epoch=0.0125]Epoch 36: Train Loss = 0.014052591286599636\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=342, train_loss_step=0.0121, train_loss_epoch=0.0141]Epoch 37: Train Loss = 0.012084713205695152\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=342, train_loss_step=0.00917, train_loss_epoch=0.0121]Epoch 38: Train Loss = 0.009168305434286594\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=342, train_loss_step=0.00953, train_loss_epoch=0.00917]Epoch 39: Train Loss = 0.009525704197585583\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=342, train_loss_step=0.0127, train_loss_epoch=0.00953] Epoch 40: Train Loss = 0.012723681516945362\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=342, train_loss_step=0.0118, train_loss_epoch=0.0127] Epoch 41: Train Loss = 0.011828205548226833\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=342, train_loss_step=0.0168, train_loss_epoch=0.0118]Epoch 42: Train Loss = 0.01681554690003395\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=342, train_loss_step=0.0114, train_loss_epoch=0.0168]Epoch 43: Train Loss = 0.011404437944293022\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.0114]Epoch 44: Train Loss = 0.011504239402711391\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=342, train_loss_step=0.00939, train_loss_epoch=0.0115]Epoch 45: Train Loss = 0.009388884529471397\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=342, train_loss_step=0.0106, train_loss_epoch=0.00939] Epoch 46: Train Loss = 0.010648068971931934\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=342, train_loss_step=0.0134, train_loss_epoch=0.0106] Epoch 47: Train Loss = 0.013375988230109215\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=342, train_loss_step=0.014, train_loss_epoch=0.0134] Epoch 48: Train Loss = 0.013984804973006248\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=342, train_loss_step=0.011, train_loss_epoch=0.014] Epoch 49: Train Loss = 0.010983960703015327\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=342, train_loss_step=0.0171, train_loss_epoch=0.011]Epoch 50: Train Loss = 0.017105672508478165\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=342, train_loss_step=0.00989, train_loss_epoch=0.0171]Epoch 51: Train Loss = 0.009886021725833416\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=342, train_loss_step=0.00785, train_loss_epoch=0.00989]Epoch 52: Train Loss = 0.007847878150641918\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=342, train_loss_step=0.0103, train_loss_epoch=0.00785] Epoch 53: Train Loss = 0.010275731794536114\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.0103] Epoch 54: Train Loss = 0.01149116363376379\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=342, train_loss_step=0.0123, train_loss_epoch=0.0115]Epoch 55: Train Loss = 0.012324516661465168\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=342, train_loss_step=0.015, train_loss_epoch=0.0123] Epoch 56: Train Loss = 0.01504917535930872\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s, v_num=342, train_loss_step=0.00904, train_loss_epoch=0.015]Epoch 57: Train Loss = 0.009035883471369743\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=342, train_loss_step=0.0104, train_loss_epoch=0.00904] Epoch 58: Train Loss = 0.010354796424508095\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=342, train_loss_step=0.0119, train_loss_epoch=0.0104] Epoch 59: Train Loss = 0.011864461936056614\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=342, train_loss_step=0.0149, train_loss_epoch=0.0119]Epoch 60: Train Loss = 0.014935140497982502\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=342, train_loss_step=0.00872, train_loss_epoch=0.0149]Epoch 61: Train Loss = 0.008717604912817478\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=342, train_loss_step=0.0168, train_loss_epoch=0.00872] Epoch 62: Train Loss = 0.016848215833306313\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=342, train_loss_step=0.0111, train_loss_epoch=0.0168] Epoch 63: Train Loss = 0.011108333244919777\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=342, train_loss_step=0.012, train_loss_epoch=0.0111] Epoch 64: Train Loss = 0.011961863376200199\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=342, train_loss_step=0.0114, train_loss_epoch=0.012]Epoch 65: Train Loss = 0.011410760693252087\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=342, train_loss_step=0.0166, train_loss_epoch=0.0114]Epoch 66: Train Loss = 0.01656242273747921\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=342, train_loss_step=0.0138, train_loss_epoch=0.0166]Epoch 67: Train Loss = 0.013833391480147839\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=342, train_loss_step=0.013, train_loss_epoch=0.0138] Epoch 68: Train Loss = 0.01297737006098032\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.013]Epoch 69: Train Loss = 0.010724070481956005\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=342, train_loss_step=0.0129, train_loss_epoch=0.0107]Epoch 70: Train Loss = 0.012945880182087421\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=342, train_loss_step=0.00976, train_loss_epoch=0.0129]Epoch 71: Train Loss = 0.00976331252604723\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=342, train_loss_step=0.00844, train_loss_epoch=0.00976]Epoch 72: Train Loss = 0.008439900353550911\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=342, train_loss_step=0.0104, train_loss_epoch=0.00844] Epoch 73: Train Loss = 0.010387984104454517\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=342, train_loss_step=0.0123, train_loss_epoch=0.0104] Epoch 74: Train Loss = 0.01229814626276493\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=342, train_loss_step=0.0111, train_loss_epoch=0.0123]Epoch 75: Train Loss = 0.011090121231973171\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=342, train_loss_step=0.0159, train_loss_epoch=0.0111]Epoch 76: Train Loss = 0.015850158408284187\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=342, train_loss_step=0.0103, train_loss_epoch=0.0159]Epoch 77: Train Loss = 0.010328332893550396\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 11.08it/s, v_num=342, train_loss_step=0.0122, train_loss_epoch=0.0103]Epoch 78: Train Loss = 0.01223055087029934\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.0122]Epoch 79: Train Loss = 0.010692070238292217\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=342, train_loss_step=0.0128, train_loss_epoch=0.0107]Epoch 80: Train Loss = 0.01283056940883398\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=342, train_loss_step=0.00826, train_loss_epoch=0.0128]Epoch 81: Train Loss = 0.008256147615611553\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.00826] Epoch 82: Train Loss = 0.011455700732767582\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=342, train_loss_step=0.0134, train_loss_epoch=0.0115] Epoch 83: Train Loss = 0.013424311764538288\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=342, train_loss_step=0.00971, train_loss_epoch=0.0134]Epoch 84: Train Loss = 0.009707593359053135\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=342, train_loss_step=0.0102, train_loss_epoch=0.00971] Epoch 85: Train Loss = 0.01022242195904255\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=342, train_loss_step=0.0121, train_loss_epoch=0.0102] Epoch 86: Train Loss = 0.01208240445703268\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=342, train_loss_step=0.013, train_loss_epoch=0.0121] Epoch 87: Train Loss = 0.013049224391579628\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=342, train_loss_step=0.011, train_loss_epoch=0.013] Epoch 88: Train Loss = 0.010984576307237148\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=342, train_loss_step=0.0108, train_loss_epoch=0.011]Epoch 89: Train Loss = 0.010786534287035465\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=342, train_loss_step=0.0126, train_loss_epoch=0.0108]Epoch 90: Train Loss = 0.012633527629077435\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=342, train_loss_step=0.0119, train_loss_epoch=0.0126]Epoch 91: Train Loss = 0.011923568323254585\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=342, train_loss_step=0.0109, train_loss_epoch=0.0119]Epoch 92: Train Loss = 0.010934165678918362\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=342, train_loss_step=0.00919, train_loss_epoch=0.0109]Epoch 93: Train Loss = 0.009191913530230522\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=342, train_loss_step=0.00875, train_loss_epoch=0.00919]Epoch 94: Train Loss = 0.008746408857405186\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=342, train_loss_step=0.00901, train_loss_epoch=0.00875]Epoch 95: Train Loss = 0.009013349190354347\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=342, train_loss_step=0.0134, train_loss_epoch=0.00901] Epoch 96: Train Loss = 0.01341851893812418\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=342, train_loss_step=0.00743, train_loss_epoch=0.0134]Epoch 97: Train Loss = 0.007427288684993982\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=342, train_loss_step=0.0103, train_loss_epoch=0.00743] Epoch 98: Train Loss = 0.010337121784687042\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s, v_num=342, train_loss_step=0.00937, train_loss_epoch=0.0103]Epoch 99: Train Loss = 0.009372338652610779\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=342, train_loss_step=0.00806, train_loss_epoch=0.00937]Epoch 100: Train Loss = 0.008063476532697678\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=342, train_loss_step=0.00827, train_loss_epoch=0.00806]Epoch 101: Train Loss = 0.00827440619468689\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=342, train_loss_step=0.0114, train_loss_epoch=0.00827] Epoch 102: Train Loss = 0.011395103298127651\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=342, train_loss_step=0.0102, train_loss_epoch=0.0114] Epoch 103: Train Loss = 0.010224021039903164\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=342, train_loss_step=0.00916, train_loss_epoch=0.0102]Epoch 104: Train Loss = 0.009157347492873669\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=342, train_loss_step=0.00885, train_loss_epoch=0.00916]Epoch 105: Train Loss = 0.00884974841028452\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=342, train_loss_step=0.0137, train_loss_epoch=0.00885] Epoch 106: Train Loss = 0.013682551681995392\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=342, train_loss_step=0.00928, train_loss_epoch=0.0137]Epoch 107: Train Loss = 0.009275679476559162\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=342, train_loss_step=0.0103, train_loss_epoch=0.00928] Epoch 108: Train Loss = 0.0103417057543993\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=342, train_loss_step=0.00985, train_loss_epoch=0.0103]Epoch 109: Train Loss = 0.009851926937699318\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=342, train_loss_step=0.0132, train_loss_epoch=0.00985] Epoch 110: Train Loss = 0.013200904242694378\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=342, train_loss_step=0.00934, train_loss_epoch=0.0132]Epoch 111: Train Loss = 0.009341035969555378\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=342, train_loss_step=0.0119, train_loss_epoch=0.00934] Epoch 112: Train Loss = 0.01188894547522068\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=342, train_loss_step=0.00924, train_loss_epoch=0.0119]Epoch 113: Train Loss = 0.009239534847438335\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=342, train_loss_step=0.012, train_loss_epoch=0.00924]  Epoch 114: Train Loss = 0.011999934911727905\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=342, train_loss_step=0.0098, train_loss_epoch=0.012] Epoch 115: Train Loss = 0.009803041815757751\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=342, train_loss_step=0.0142, train_loss_epoch=0.0098]Epoch 116: Train Loss = 0.014152155257761478\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=342, train_loss_step=0.0108, train_loss_epoch=0.0142]Epoch 117: Train Loss = 0.010812937282025814\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=342, train_loss_step=0.0132, train_loss_epoch=0.0108]Epoch 118: Train Loss = 0.0132127795368433\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=342, train_loss_step=0.00851, train_loss_epoch=0.0132]Epoch 119: Train Loss = 0.008514068089425564\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=342, train_loss_step=0.0126, train_loss_epoch=0.00851] Epoch 120: Train Loss = 0.012589280493557453\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=342, train_loss_step=0.0138, train_loss_epoch=0.0126] Epoch 121: Train Loss = 0.01380072720348835\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=342, train_loss_step=0.0123, train_loss_epoch=0.0138]Epoch 122: Train Loss = 0.012320195324718952\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=342, train_loss_step=0.00998, train_loss_epoch=0.0123]Epoch 123: Train Loss = 0.00998230092227459\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=342, train_loss_step=0.0177, train_loss_epoch=0.00998] Epoch 124: Train Loss = 0.01766647771000862\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=342, train_loss_step=0.00985, train_loss_epoch=0.0177]Epoch 125: Train Loss = 0.009854808449745178\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=342, train_loss_step=0.0158, train_loss_epoch=0.00985] Epoch 126: Train Loss = 0.01582607440650463\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=342, train_loss_step=0.00942, train_loss_epoch=0.0158]Epoch 127: Train Loss = 0.009415424428880215\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=342, train_loss_step=0.0102, train_loss_epoch=0.00942] Epoch 128: Train Loss = 0.010175873525440693\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=342, train_loss_step=0.0146, train_loss_epoch=0.0102] Epoch 129: Train Loss = 0.014609509147703648\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.0146]Epoch 130: Train Loss = 0.011489513330161572\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=342, train_loss_step=0.0117, train_loss_epoch=0.0115]Epoch 131: Train Loss = 0.0116740046069026\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=342, train_loss_step=0.0122, train_loss_epoch=0.0117]Epoch 132: Train Loss = 0.01221239473670721\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=342, train_loss_step=0.00968, train_loss_epoch=0.0122]Epoch 133: Train Loss = 0.009677554480731487\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 10.28it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.00968] Epoch 134: Train Loss = 0.010685442946851254\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=342, train_loss_step=0.0116, train_loss_epoch=0.0107] Epoch 135: Train Loss = 0.011556603945791721\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=342, train_loss_step=0.00862, train_loss_epoch=0.0116]Epoch 136: Train Loss = 0.008619523607194424\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=342, train_loss_step=0.0106, train_loss_epoch=0.00862] Epoch 137: Train Loss = 0.01059170812368393\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=342, train_loss_step=0.0125, train_loss_epoch=0.0106] Epoch 138: Train Loss = 0.012457749806344509\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=342, train_loss_step=0.00895, train_loss_epoch=0.0125]Epoch 139: Train Loss = 0.008948358707129955\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=342, train_loss_step=0.0103, train_loss_epoch=0.00895] Epoch 140: Train Loss = 0.010347125120460987\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=342, train_loss_step=0.0085, train_loss_epoch=0.0103] Epoch 141: Train Loss = 0.008496169932186604\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=342, train_loss_step=0.0122, train_loss_epoch=0.0085]Epoch 142: Train Loss = 0.012200425378978252\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=342, train_loss_step=0.00946, train_loss_epoch=0.0122]Epoch 143: Train Loss = 0.009461595676839352\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=342, train_loss_step=0.0152, train_loss_epoch=0.00946] Epoch 144: Train Loss = 0.015167768113315105\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=342, train_loss_step=0.0121, train_loss_epoch=0.0152] Epoch 145: Train Loss = 0.012111188843846321\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=342, train_loss_step=0.014, train_loss_epoch=0.0121] Epoch 146: Train Loss = 0.013988182879984379\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=342, train_loss_step=0.0116, train_loss_epoch=0.014]Epoch 147: Train Loss = 0.011575707234442234\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=342, train_loss_step=0.0177, train_loss_epoch=0.0116]Epoch 148: Train Loss = 0.017653513699769974\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=342, train_loss_step=0.0144, train_loss_epoch=0.0177]Epoch 149: Train Loss = 0.014381611719727516\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=342, train_loss_step=0.0171, train_loss_epoch=0.0144]Epoch 150: Train Loss = 0.017116617411375046\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=342, train_loss_step=0.0164, train_loss_epoch=0.0171]Epoch 151: Train Loss = 0.016368374228477478\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=342, train_loss_step=0.0131, train_loss_epoch=0.0164]Epoch 152: Train Loss = 0.01305441465228796\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=342, train_loss_step=0.0124, train_loss_epoch=0.0131]Epoch 153: Train Loss = 0.012420815415680408\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=342, train_loss_step=0.0112, train_loss_epoch=0.0124]Epoch 154: Train Loss = 0.011206110939383507\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=342, train_loss_step=0.0146, train_loss_epoch=0.0112]Epoch 155: Train Loss = 0.01457446999847889\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=342, train_loss_step=0.0142, train_loss_epoch=0.0146]Epoch 156: Train Loss = 0.01422489620745182\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.0142]Epoch 157: Train Loss = 0.010735148563981056\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=342, train_loss_step=0.0126, train_loss_epoch=0.0107]Epoch 158: Train Loss = 0.012596406042575836\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=342, train_loss_step=0.0109, train_loss_epoch=0.0126]Epoch 159: Train Loss = 0.010850249789655209\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=342, train_loss_step=0.0123, train_loss_epoch=0.0109]Epoch 160: Train Loss = 0.012327468954026699\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.0123]Epoch 161: Train Loss = 0.011515863239765167\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=342, train_loss_step=0.0123, train_loss_epoch=0.0115]Epoch 162: Train Loss = 0.012258857488632202\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=342, train_loss_step=0.0111, train_loss_epoch=0.0123]Epoch 163: Train Loss = 0.011063484475016594\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=342, train_loss_step=0.0124, train_loss_epoch=0.0111]Epoch 164: Train Loss = 0.012394778430461884\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=342, train_loss_step=0.0104, train_loss_epoch=0.0124]Epoch 165: Train Loss = 0.010401477105915546\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=342, train_loss_step=0.0154, train_loss_epoch=0.0104]Epoch 166: Train Loss = 0.015398106537759304\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=342, train_loss_step=0.0111, train_loss_epoch=0.0154]Epoch 167: Train Loss = 0.011113204061985016\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=342, train_loss_step=0.0109, train_loss_epoch=0.0111]Epoch 168: Train Loss = 0.010892479680478573\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=342, train_loss_step=0.00778, train_loss_epoch=0.0109]Epoch 169: Train Loss = 0.007775626145303249\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=342, train_loss_step=0.013, train_loss_epoch=0.00778]  Epoch 170: Train Loss = 0.013047044165432453\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s, v_num=342, train_loss_step=0.0154, train_loss_epoch=0.013] Epoch 171: Train Loss = 0.01536913774907589\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=342, train_loss_step=0.0119, train_loss_epoch=0.0154]Epoch 172: Train Loss = 0.011873125098645687\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=342, train_loss_step=0.0106, train_loss_epoch=0.0119]Epoch 173: Train Loss = 0.010638895444571972\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=342, train_loss_step=0.0126, train_loss_epoch=0.0106]Epoch 174: Train Loss = 0.01256848406046629\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=342, train_loss_step=0.0144, train_loss_epoch=0.0126]Epoch 175: Train Loss = 0.014393038116395473\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=342, train_loss_step=0.0148, train_loss_epoch=0.0144]Epoch 176: Train Loss = 0.014764063060283661\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=342, train_loss_step=0.00872, train_loss_epoch=0.0148]Epoch 177: Train Loss = 0.008722222410142422\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.00872] Epoch 178: Train Loss = 0.011505791917443275\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.0115] Epoch 179: Train Loss = 0.011456465348601341\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=342, train_loss_step=0.0087, train_loss_epoch=0.0115]Epoch 180: Train Loss = 0.008704678155481815\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=342, train_loss_step=0.00944, train_loss_epoch=0.0087]Epoch 181: Train Loss = 0.009435201995074749\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=342, train_loss_step=0.00881, train_loss_epoch=0.00944]Epoch 182: Train Loss = 0.00881373230367899\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=342, train_loss_step=0.0128, train_loss_epoch=0.00881] Epoch 183: Train Loss = 0.012848341837525368\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=342, train_loss_step=0.00881, train_loss_epoch=0.0128]Epoch 184: Train Loss = 0.008811644278466702\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=342, train_loss_step=0.0121, train_loss_epoch=0.00881] Epoch 185: Train Loss = 0.012116419151425362\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=342, train_loss_step=0.0137, train_loss_epoch=0.0121] Epoch 186: Train Loss = 0.01372090820223093\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 11.60it/s, v_num=342, train_loss_step=0.0111, train_loss_epoch=0.0137]Epoch 187: Train Loss = 0.011086645536124706\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=342, train_loss_step=0.0108, train_loss_epoch=0.0111]Epoch 188: Train Loss = 0.010814563371241093\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=342, train_loss_step=0.00917, train_loss_epoch=0.0108]Epoch 189: Train Loss = 0.009173840284347534\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=342, train_loss_step=0.012, train_loss_epoch=0.00917]  Epoch 190: Train Loss = 0.01203249953687191\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=342, train_loss_step=0.0121, train_loss_epoch=0.012] Epoch 191: Train Loss = 0.012101558968424797\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=342, train_loss_step=0.00752, train_loss_epoch=0.0121]Epoch 192: Train Loss = 0.007518433034420013\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=342, train_loss_step=0.0134, train_loss_epoch=0.00752] Epoch 193: Train Loss = 0.013442360796034336\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  3.46it/s, v_num=342, train_loss_step=0.011, train_loss_epoch=0.0134]  Epoch 194: Train Loss = 0.01098797656595707\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=342, train_loss_step=0.00842, train_loss_epoch=0.011]Epoch 195: Train Loss = 0.00842269603163004\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=342, train_loss_step=0.0135, train_loss_epoch=0.00842] Epoch 196: Train Loss = 0.013526014983654022\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=342, train_loss_step=0.0126, train_loss_epoch=0.0135] Epoch 197: Train Loss = 0.012577548623085022\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=342, train_loss_step=0.0116, train_loss_epoch=0.0126]Epoch 198: Train Loss = 0.011564896441996098\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=342, train_loss_step=0.0108, train_loss_epoch=0.0116]Epoch 199: Train Loss = 0.010798312723636627\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=342, train_loss_step=0.0119, train_loss_epoch=0.0108]Epoch 200: Train Loss = 0.011911699548363686\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=342, train_loss_step=0.0098, train_loss_epoch=0.0119]Epoch 201: Train Loss = 0.00979501474648714\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=342, train_loss_step=0.0123, train_loss_epoch=0.0098]Epoch 202: Train Loss = 0.012275640852749348\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 11.60it/s, v_num=342, train_loss_step=0.0109, train_loss_epoch=0.0123]Epoch 203: Train Loss = 0.010892890393733978\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=342, train_loss_step=0.0143, train_loss_epoch=0.0109]Epoch 204: Train Loss = 0.014282806776463985\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=342, train_loss_step=0.010, train_loss_epoch=0.0143] Epoch 205: Train Loss = 0.01000893022865057\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=342, train_loss_step=0.0106, train_loss_epoch=0.010]Epoch 206: Train Loss = 0.010562842711806297\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=342, train_loss_step=0.00833, train_loss_epoch=0.0106]Epoch 207: Train Loss = 0.00833237636834383\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=342, train_loss_step=0.0148, train_loss_epoch=0.00833] Epoch 208: Train Loss = 0.014831077307462692\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=342, train_loss_step=0.0132, train_loss_epoch=0.0148] Epoch 209: Train Loss = 0.013208368793129921\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=342, train_loss_step=0.0103, train_loss_epoch=0.0132]Epoch 210: Train Loss = 0.010277966968715191\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=342, train_loss_step=0.00798, train_loss_epoch=0.0103]Epoch 211: Train Loss = 0.007979310117661953\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=342, train_loss_step=0.0123, train_loss_epoch=0.00798] Epoch 212: Train Loss = 0.012325446121394634\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=342, train_loss_step=0.00987, train_loss_epoch=0.0123]Epoch 213: Train Loss = 0.009866724722087383\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.00987] Epoch 214: Train Loss = 0.011469396762549877\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=342, train_loss_step=0.0154, train_loss_epoch=0.0115] Epoch 215: Train Loss = 0.015367581509053707\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=342, train_loss_step=0.0109, train_loss_epoch=0.0154]Epoch 216: Train Loss = 0.010887712240219116\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=342, train_loss_step=0.015, train_loss_epoch=0.0109] Epoch 217: Train Loss = 0.015013921074569225\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=342, train_loss_step=0.012, train_loss_epoch=0.015] Epoch 218: Train Loss = 0.01202752161771059\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=342, train_loss_step=0.0134, train_loss_epoch=0.012]Epoch 219: Train Loss = 0.013416768983006477\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=342, train_loss_step=0.0101, train_loss_epoch=0.0134]Epoch 220: Train Loss = 0.010101704858243465\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s, v_num=342, train_loss_step=0.0131, train_loss_epoch=0.0101]Epoch 221: Train Loss = 0.013057409785687923\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s, v_num=342, train_loss_step=0.0121, train_loss_epoch=0.0131]Epoch 222: Train Loss = 0.012077895924448967\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=342, train_loss_step=0.011, train_loss_epoch=0.0121] Epoch 223: Train Loss = 0.010981251485645771\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=342, train_loss_step=0.012, train_loss_epoch=0.011] Epoch 224: Train Loss = 0.01198895275592804\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.012]Epoch 225: Train Loss = 0.01068499218672514\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.0107]Epoch 226: Train Loss = 0.010693478398025036\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=342, train_loss_step=0.0123, train_loss_epoch=0.0107]Epoch 227: Train Loss = 0.01234685443341732\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=342, train_loss_step=0.012, train_loss_epoch=0.0123] Epoch 228: Train Loss = 0.012014198116958141\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=342, train_loss_step=0.0138, train_loss_epoch=0.012]Epoch 229: Train Loss = 0.013828782364726067\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=342, train_loss_step=0.0132, train_loss_epoch=0.0138]Epoch 230: Train Loss = 0.013232271187007427\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s, v_num=342, train_loss_step=0.0135, train_loss_epoch=0.0132]Epoch 231: Train Loss = 0.013515411876142025\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=342, train_loss_step=0.00927, train_loss_epoch=0.0135]Epoch 232: Train Loss = 0.009270978160202503\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=342, train_loss_step=0.00984, train_loss_epoch=0.00927]Epoch 233: Train Loss = 0.009840006940066814\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=342, train_loss_step=0.00998, train_loss_epoch=0.00984]Epoch 234: Train Loss = 0.009976337663829327\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=342, train_loss_step=0.0113, train_loss_epoch=0.00998] Epoch 235: Train Loss = 0.011288992129266262\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=342, train_loss_step=0.0114, train_loss_epoch=0.0113] Epoch 236: Train Loss = 0.011370250023901463\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=342, train_loss_step=0.0099, train_loss_epoch=0.0114]Epoch 237: Train Loss = 0.009898354299366474\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 11.21it/s, v_num=342, train_loss_step=0.0106, train_loss_epoch=0.0099]Epoch 238: Train Loss = 0.010616013780236244\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=342, train_loss_step=0.00959, train_loss_epoch=0.0106]Epoch 239: Train Loss = 0.009585852734744549\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=342, train_loss_step=0.0122, train_loss_epoch=0.00959] Epoch 240: Train Loss = 0.012168781831860542\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=342, train_loss_step=0.00857, train_loss_epoch=0.0122]Epoch 241: Train Loss = 0.008565355092287064\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.00857] Epoch 242: Train Loss = 0.01070251315832138\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=342, train_loss_step=0.0104, train_loss_epoch=0.0107] Epoch 243: Train Loss = 0.010417007841169834\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=342, train_loss_step=0.0129, train_loss_epoch=0.0104]Epoch 244: Train Loss = 0.012879996560513973\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=342, train_loss_step=0.0103, train_loss_epoch=0.0129]Epoch 245: Train Loss = 0.01025389600545168\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=342, train_loss_step=0.00868, train_loss_epoch=0.0103]Epoch 246: Train Loss = 0.008677746169269085\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s, v_num=342, train_loss_step=0.00932, train_loss_epoch=0.00868]Epoch 247: Train Loss = 0.009319580160081387\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=342, train_loss_step=0.00797, train_loss_epoch=0.00932]Epoch 248: Train Loss = 0.00796897616237402\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=342, train_loss_step=0.0113, train_loss_epoch=0.00797] Epoch 249: Train Loss = 0.011281909421086311\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=342, train_loss_step=0.0102, train_loss_epoch=0.0113] Epoch 250: Train Loss = 0.010168363340198994\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=342, train_loss_step=0.0108, train_loss_epoch=0.0102]Epoch 251: Train Loss = 0.010785199701786041\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=342, train_loss_step=0.010, train_loss_epoch=0.0108] Epoch 252: Train Loss = 0.010013019666075706\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=342, train_loss_step=0.0135, train_loss_epoch=0.010]Epoch 253: Train Loss = 0.013540782034397125\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=342, train_loss_step=0.00889, train_loss_epoch=0.0135]Epoch 254: Train Loss = 0.008894923143088818\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=342, train_loss_step=0.0153, train_loss_epoch=0.00889] Epoch 255: Train Loss = 0.015332137234508991\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=342, train_loss_step=0.00892, train_loss_epoch=0.0153]Epoch 256: Train Loss = 0.008919662795960903\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=342, train_loss_step=0.0088, train_loss_epoch=0.00892] Epoch 257: Train Loss = 0.008796785026788712\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=342, train_loss_step=0.00788, train_loss_epoch=0.0088]Epoch 258: Train Loss = 0.007883738726377487\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=342, train_loss_step=0.00805, train_loss_epoch=0.00788]Epoch 259: Train Loss = 0.00804735254496336\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=342, train_loss_step=0.0112, train_loss_epoch=0.00805] Epoch 260: Train Loss = 0.011206335388123989\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=342, train_loss_step=0.0112, train_loss_epoch=0.0112] Epoch 261: Train Loss = 0.011233089491724968\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=342, train_loss_step=0.0111, train_loss_epoch=0.0112]Epoch 262: Train Loss = 0.011070461943745613\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=342, train_loss_step=0.00871, train_loss_epoch=0.0111]Epoch 263: Train Loss = 0.00871389638632536\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=342, train_loss_step=0.0109, train_loss_epoch=0.00871] Epoch 264: Train Loss = 0.010851520113646984\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=342, train_loss_step=0.0135, train_loss_epoch=0.0109] Epoch 265: Train Loss = 0.013547909446060658\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=342, train_loss_step=0.0114, train_loss_epoch=0.0135]Epoch 266: Train Loss = 0.01141621358692646\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=342, train_loss_step=0.00872, train_loss_epoch=0.0114]Epoch 267: Train Loss = 0.008721588179469109\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=342, train_loss_step=0.00906, train_loss_epoch=0.00872]Epoch 268: Train Loss = 0.009058485738933086\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=342, train_loss_step=0.00953, train_loss_epoch=0.00906]Epoch 269: Train Loss = 0.009525803849101067\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=342, train_loss_step=0.0128, train_loss_epoch=0.00953] Epoch 270: Train Loss = 0.012793361209332943\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=342, train_loss_step=0.0134, train_loss_epoch=0.0128] Epoch 271: Train Loss = 0.01337212324142456\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=342, train_loss_step=0.0113, train_loss_epoch=0.0134]Epoch 272: Train Loss = 0.011329521425068378\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=342, train_loss_step=0.00987, train_loss_epoch=0.0113]Epoch 273: Train Loss = 0.00986550934612751\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=342, train_loss_step=0.00974, train_loss_epoch=0.00987]Epoch 274: Train Loss = 0.009739800356328487\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.00974] Epoch 275: Train Loss = 0.011516834609210491\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=342, train_loss_step=0.00878, train_loss_epoch=0.0115]Epoch 276: Train Loss = 0.008780596777796745\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=342, train_loss_step=0.00966, train_loss_epoch=0.00878]Epoch 277: Train Loss = 0.009657059796154499\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=342, train_loss_step=0.0119, train_loss_epoch=0.00966] Epoch 278: Train Loss = 0.011941964738070965\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=342, train_loss_step=0.00847, train_loss_epoch=0.0119]Epoch 279: Train Loss = 0.0084657808765769\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=342, train_loss_step=0.0132, train_loss_epoch=0.00847] Epoch 280: Train Loss = 0.013249390758574009\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=342, train_loss_step=0.0111, train_loss_epoch=0.0132] Epoch 281: Train Loss = 0.011131653562188148\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=342, train_loss_step=0.0127, train_loss_epoch=0.0111]Epoch 282: Train Loss = 0.012692438438534737\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=342, train_loss_step=0.0108, train_loss_epoch=0.0127]Epoch 283: Train Loss = 0.010814164765179157\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=342, train_loss_step=0.0114, train_loss_epoch=0.0108]Epoch 284: Train Loss = 0.011431967839598656\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=342, train_loss_step=0.0113, train_loss_epoch=0.0114]Epoch 285: Train Loss = 0.011344782076776028\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=342, train_loss_step=0.00797, train_loss_epoch=0.0113]Epoch 286: Train Loss = 0.007972334511578083\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=342, train_loss_step=0.0138, train_loss_epoch=0.00797] Epoch 287: Train Loss = 0.013787717558443546\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.0138] Epoch 288: Train Loss = 0.010678238235414028\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=342, train_loss_step=0.00975, train_loss_epoch=0.0107]Epoch 289: Train Loss = 0.009746371768414974\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s, v_num=342, train_loss_step=0.0145, train_loss_epoch=0.00975] Epoch 290: Train Loss = 0.014508825726807117\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=342, train_loss_step=0.00977, train_loss_epoch=0.0145]Epoch 291: Train Loss = 0.009766311384737492\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=342, train_loss_step=0.00911, train_loss_epoch=0.00977]Epoch 292: Train Loss = 0.009108553640544415\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=342, train_loss_step=0.0089, train_loss_epoch=0.00911] Epoch 293: Train Loss = 0.008897220715880394\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=342, train_loss_step=0.0105, train_loss_epoch=0.0089] Epoch 294: Train Loss = 0.010482518933713436\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=342, train_loss_step=0.00966, train_loss_epoch=0.0105]Epoch 295: Train Loss = 0.009656326845288277\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=342, train_loss_step=0.00818, train_loss_epoch=0.00966]Epoch 296: Train Loss = 0.00817557517439127\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=342, train_loss_step=0.0147, train_loss_epoch=0.00818] Epoch 297: Train Loss = 0.01466996781527996\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=342, train_loss_step=0.0124, train_loss_epoch=0.0147] Epoch 298: Train Loss = 0.012393219396471977\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=342, train_loss_step=0.009, train_loss_epoch=0.0124] Epoch 299: Train Loss = 0.00899694673717022\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=342, train_loss_step=0.0103, train_loss_epoch=0.009]Epoch 300: Train Loss = 0.010304505005478859\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=342, train_loss_step=0.0111, train_loss_epoch=0.0103]Epoch 301: Train Loss = 0.011124812066555023\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=342, train_loss_step=0.0117, train_loss_epoch=0.0111]Epoch 302: Train Loss = 0.01172702293843031\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=342, train_loss_step=0.0134, train_loss_epoch=0.0117]Epoch 303: Train Loss = 0.01337928231805563\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=342, train_loss_step=0.0141, train_loss_epoch=0.0134]Epoch 304: Train Loss = 0.014099090360105038\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=342, train_loss_step=0.0112, train_loss_epoch=0.0141]Epoch 305: Train Loss = 0.011229882016777992\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=342, train_loss_step=0.012, train_loss_epoch=0.0112] Epoch 306: Train Loss = 0.011969096958637238\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s, v_num=342, train_loss_step=0.0132, train_loss_epoch=0.012]Epoch 307: Train Loss = 0.013193969614803791\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=342, train_loss_step=0.0139, train_loss_epoch=0.0132]Epoch 308: Train Loss = 0.013899371027946472\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=342, train_loss_step=0.00802, train_loss_epoch=0.0139]Epoch 309: Train Loss = 0.008023700676858425\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.00802] Epoch 310: Train Loss = 0.011516342870891094\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=342, train_loss_step=0.0124, train_loss_epoch=0.0115] Epoch 311: Train Loss = 0.012435222044587135\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.0124]Epoch 312: Train Loss = 0.010731392540037632\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=342, train_loss_step=0.00934, train_loss_epoch=0.0107]Epoch 313: Train Loss = 0.00934445671737194\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=342, train_loss_step=0.00948, train_loss_epoch=0.00934]Epoch 314: Train Loss = 0.009476975537836552\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=342, train_loss_step=0.00737, train_loss_epoch=0.00948]Epoch 315: Train Loss = 0.007374805398285389\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=342, train_loss_step=0.00827, train_loss_epoch=0.00737]Epoch 316: Train Loss = 0.00827064085751772\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=342, train_loss_step=0.0104, train_loss_epoch=0.00827] Epoch 317: Train Loss = 0.010407567955553532\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=342, train_loss_step=0.00861, train_loss_epoch=0.0104]Epoch 318: Train Loss = 0.008612134493887424\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=342, train_loss_step=0.015, train_loss_epoch=0.00861]  Epoch 319: Train Loss = 0.014966337010264397\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=342, train_loss_step=0.010, train_loss_epoch=0.015]  Epoch 320: Train Loss = 0.010014848783612251\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=342, train_loss_step=0.00883, train_loss_epoch=0.010]Epoch 321: Train Loss = 0.008828491903841496\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=342, train_loss_step=0.0102, train_loss_epoch=0.00883] Epoch 322: Train Loss = 0.010218915529549122\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=342, train_loss_step=0.00901, train_loss_epoch=0.0102]Epoch 323: Train Loss = 0.009013844653964043\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s, v_num=342, train_loss_step=0.00948, train_loss_epoch=0.00901]Epoch 324: Train Loss = 0.00947748962789774\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=342, train_loss_step=0.0083, train_loss_epoch=0.00948] Epoch 325: Train Loss = 0.008298727683722973\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=342, train_loss_step=0.0127, train_loss_epoch=0.0083] Epoch 326: Train Loss = 0.012741590850055218\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=342, train_loss_step=0.0102, train_loss_epoch=0.0127]Epoch 327: Train Loss = 0.010202397592365742\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=342, train_loss_step=0.0125, train_loss_epoch=0.0102]Epoch 328: Train Loss = 0.012464424595236778\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=342, train_loss_step=0.00866, train_loss_epoch=0.0125]Epoch 329: Train Loss = 0.008658169768750668\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=342, train_loss_step=0.00814, train_loss_epoch=0.00866]Epoch 330: Train Loss = 0.008142250590026379\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=342, train_loss_step=0.0111, train_loss_epoch=0.00814] Epoch 331: Train Loss = 0.011130989529192448\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 11.08it/s, v_num=342, train_loss_step=0.011, train_loss_epoch=0.0111]  Epoch 332: Train Loss = 0.01103994157165289\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=342, train_loss_step=0.00989, train_loss_epoch=0.011]Epoch 333: Train Loss = 0.009887941181659698\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=342, train_loss_step=0.0132, train_loss_epoch=0.00989] Epoch 334: Train Loss = 0.013221154920756817\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.0132] Epoch 335: Train Loss = 0.010711034759879112\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=342, train_loss_step=0.0088, train_loss_epoch=0.0107]Epoch 336: Train Loss = 0.008797252550721169\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=342, train_loss_step=0.0147, train_loss_epoch=0.0088]Epoch 337: Train Loss = 0.014712716452777386\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=342, train_loss_step=0.0106, train_loss_epoch=0.0147]Epoch 338: Train Loss = 0.010583976283669472\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=342, train_loss_step=0.0128, train_loss_epoch=0.0106]Epoch 339: Train Loss = 0.012809941545128822\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=342, train_loss_step=0.00998, train_loss_epoch=0.0128]Epoch 340: Train Loss = 0.00997529923915863\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=342, train_loss_step=0.0112, train_loss_epoch=0.00998] Epoch 341: Train Loss = 0.011193742975592613\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=342, train_loss_step=0.00957, train_loss_epoch=0.0112]Epoch 342: Train Loss = 0.009567064233124256\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s, v_num=342, train_loss_step=0.0132, train_loss_epoch=0.00957] Epoch 343: Train Loss = 0.01321222074329853\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=342, train_loss_step=0.013, train_loss_epoch=0.0132]  Epoch 344: Train Loss = 0.013008227571845055\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s, v_num=342, train_loss_step=0.00854, train_loss_epoch=0.013]Epoch 345: Train Loss = 0.00854361243546009\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=342, train_loss_step=0.00895, train_loss_epoch=0.00854]Epoch 346: Train Loss = 0.008947688154876232\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=342, train_loss_step=0.0112, train_loss_epoch=0.00895] Epoch 347: Train Loss = 0.011164620518684387\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 12.91it/s, v_num=342, train_loss_step=0.00997, train_loss_epoch=0.0112]Epoch 348: Train Loss = 0.009970501996576786\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=342, train_loss_step=0.00741, train_loss_epoch=0.00997]Epoch 349: Train Loss = 0.007409772370010614\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=342, train_loss_step=0.0112, train_loss_epoch=0.00741] Epoch 350: Train Loss = 0.011212548241019249\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=342, train_loss_step=0.0104, train_loss_epoch=0.0112] Epoch 351: Train Loss = 0.010385491885244846\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=342, train_loss_step=0.011, train_loss_epoch=0.0104] Epoch 352: Train Loss = 0.010983167216181755\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=342, train_loss_step=0.0135, train_loss_epoch=0.011]Epoch 353: Train Loss = 0.0135026341304183\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s, v_num=342, train_loss_step=0.00819, train_loss_epoch=0.0135]Epoch 354: Train Loss = 0.008194531314074993\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=342, train_loss_step=0.00945, train_loss_epoch=0.00819]Epoch 355: Train Loss = 0.00944735761731863\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=342, train_loss_step=0.00884, train_loss_epoch=0.00945]Epoch 356: Train Loss = 0.00883969385176897\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s, v_num=342, train_loss_step=0.0071, train_loss_epoch=0.00884] Epoch 357: Train Loss = 0.0070970081724226475\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=342, train_loss_step=0.00931, train_loss_epoch=0.0071]Epoch 358: Train Loss = 0.009314249269664288\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=342, train_loss_step=0.00892, train_loss_epoch=0.00931]Epoch 359: Train Loss = 0.008917797356843948\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=342, train_loss_step=0.0091, train_loss_epoch=0.00892] Epoch 360: Train Loss = 0.009099413640797138\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=342, train_loss_step=0.0125, train_loss_epoch=0.0091] Epoch 361: Train Loss = 0.012485099025070667\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=342, train_loss_step=0.0153, train_loss_epoch=0.0125]Epoch 362: Train Loss = 0.015302583575248718\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=342, train_loss_step=0.012, train_loss_epoch=0.0153] Epoch 363: Train Loss = 0.011952504515647888\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=342, train_loss_step=0.00968, train_loss_epoch=0.012]Epoch 364: Train Loss = 0.009677263908088207\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=342, train_loss_step=0.00794, train_loss_epoch=0.00968]Epoch 365: Train Loss = 0.007941283285617828\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=342, train_loss_step=0.00877, train_loss_epoch=0.00794]Epoch 366: Train Loss = 0.008768942207098007\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=342, train_loss_step=0.014, train_loss_epoch=0.00877]  Epoch 367: Train Loss = 0.013958916068077087\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=342, train_loss_step=0.00998, train_loss_epoch=0.014]Epoch 368: Train Loss = 0.009981480427086353\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=342, train_loss_step=0.0105, train_loss_epoch=0.00998] Epoch 369: Train Loss = 0.010527347214519978\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=342, train_loss_step=0.0121, train_loss_epoch=0.0105] Epoch 370: Train Loss = 0.012099404819309711\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=342, train_loss_step=0.0122, train_loss_epoch=0.0121]Epoch 371: Train Loss = 0.012161122635006905\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=342, train_loss_step=0.0106, train_loss_epoch=0.0122]Epoch 372: Train Loss = 0.01055881381034851\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=342, train_loss_step=0.00916, train_loss_epoch=0.0106]Epoch 373: Train Loss = 0.00916136335581541\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=342, train_loss_step=0.00968, train_loss_epoch=0.00916]Epoch 374: Train Loss = 0.00967790000140667\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=342, train_loss_step=0.0129, train_loss_epoch=0.00968] Epoch 375: Train Loss = 0.012921137735247612\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.0129] Epoch 376: Train Loss = 0.011487319134175777\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=342, train_loss_step=0.0117, train_loss_epoch=0.0115]Epoch 377: Train Loss = 0.011703257448971272\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=342, train_loss_step=0.00992, train_loss_epoch=0.0117]Epoch 378: Train Loss = 0.009917412884533405\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=342, train_loss_step=0.0137, train_loss_epoch=0.00992] Epoch 379: Train Loss = 0.013691036030650139\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=342, train_loss_step=0.00909, train_loss_epoch=0.0137]Epoch 380: Train Loss = 0.00908811204135418\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=342, train_loss_step=0.0104, train_loss_epoch=0.00909] Epoch 381: Train Loss = 0.010411707684397697\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=342, train_loss_step=0.00854, train_loss_epoch=0.0104]Epoch 382: Train Loss = 0.00854172371327877\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=342, train_loss_step=0.0116, train_loss_epoch=0.00854] Epoch 383: Train Loss = 0.011590114794671535\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=342, train_loss_step=0.0118, train_loss_epoch=0.0116] Epoch 384: Train Loss = 0.01178629882633686\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=342, train_loss_step=0.0123, train_loss_epoch=0.0118]Epoch 385: Train Loss = 0.012294096872210503\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=342, train_loss_step=0.0104, train_loss_epoch=0.0123]Epoch 386: Train Loss = 0.010402503423392773\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=342, train_loss_step=0.00969, train_loss_epoch=0.0104]Epoch 387: Train Loss = 0.009692847728729248\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=342, train_loss_step=0.0145, train_loss_epoch=0.00969] Epoch 388: Train Loss = 0.014499299228191376\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=342, train_loss_step=0.00704, train_loss_epoch=0.0145]Epoch 389: Train Loss = 0.0070411344058811665\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=342, train_loss_step=0.00783, train_loss_epoch=0.00704]Epoch 390: Train Loss = 0.007832781411707401\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=342, train_loss_step=0.0101, train_loss_epoch=0.00783] Epoch 391: Train Loss = 0.01010055746883154\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=342, train_loss_step=0.00966, train_loss_epoch=0.0101]Epoch 392: Train Loss = 0.009660464711487293\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s, v_num=342, train_loss_step=0.00813, train_loss_epoch=0.00966]Epoch 393: Train Loss = 0.008133688010275364\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.00813] Epoch 394: Train Loss = 0.011529865674674511\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=342, train_loss_step=0.0133, train_loss_epoch=0.0115] Epoch 395: Train Loss = 0.013309798203408718\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=342, train_loss_step=0.0124, train_loss_epoch=0.0133]Epoch 396: Train Loss = 0.012399591505527496\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=342, train_loss_step=0.0127, train_loss_epoch=0.0124]Epoch 397: Train Loss = 0.012737440876662731\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=342, train_loss_step=0.00838, train_loss_epoch=0.0127]Epoch 398: Train Loss = 0.008380440063774586\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=342, train_loss_step=0.0102, train_loss_epoch=0.00838] Epoch 399: Train Loss = 0.01019891444593668\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=342, train_loss_step=0.00985, train_loss_epoch=0.0102]Epoch 400: Train Loss = 0.00984919536858797\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=342, train_loss_step=0.0105, train_loss_epoch=0.00985] Epoch 401: Train Loss = 0.010534941218793392\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=342, train_loss_step=0.00889, train_loss_epoch=0.0105]Epoch 402: Train Loss = 0.008890785276889801\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=342, train_loss_step=0.00896, train_loss_epoch=0.00889]Epoch 403: Train Loss = 0.008957823738455772\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=342, train_loss_step=0.0114, train_loss_epoch=0.00896] Epoch 404: Train Loss = 0.011369643732905388\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=342, train_loss_step=0.00672, train_loss_epoch=0.0114]Epoch 405: Train Loss = 0.006718919612467289\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=342, train_loss_step=0.00892, train_loss_epoch=0.00672]Epoch 406: Train Loss = 0.008917881175875664\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=342, train_loss_step=0.00841, train_loss_epoch=0.00892]Epoch 407: Train Loss = 0.008411012589931488\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.00841] Epoch 408: Train Loss = 0.01147121749818325\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=342, train_loss_step=0.0114, train_loss_epoch=0.0115] Epoch 409: Train Loss = 0.0114304069429636\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=342, train_loss_step=0.00949, train_loss_epoch=0.0114]Epoch 410: Train Loss = 0.00949277076870203\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=342, train_loss_step=0.0104, train_loss_epoch=0.00949] Epoch 411: Train Loss = 0.010402952320873737\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=342, train_loss_step=0.0121, train_loss_epoch=0.0104] Epoch 412: Train Loss = 0.012132769450545311\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=342, train_loss_step=0.0124, train_loss_epoch=0.0121]Epoch 413: Train Loss = 0.012434372678399086\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=342, train_loss_step=0.00843, train_loss_epoch=0.0124]Epoch 414: Train Loss = 0.008431472815573215\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=342, train_loss_step=0.0116, train_loss_epoch=0.00843] Epoch 415: Train Loss = 0.01158690545707941\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=342, train_loss_step=0.00943, train_loss_epoch=0.0116]Epoch 416: Train Loss = 0.009430721402168274\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=342, train_loss_step=0.00779, train_loss_epoch=0.00943]Epoch 417: Train Loss = 0.007787608541548252\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=342, train_loss_step=0.0113, train_loss_epoch=0.00779] Epoch 418: Train Loss = 0.011296979151666164\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=342, train_loss_step=0.00948, train_loss_epoch=0.0113]Epoch 419: Train Loss = 0.009480216540396214\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=342, train_loss_step=0.0121, train_loss_epoch=0.00948] Epoch 420: Train Loss = 0.012091984041035175\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=342, train_loss_step=0.00988, train_loss_epoch=0.0121]Epoch 421: Train Loss = 0.009884210303425789\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=342, train_loss_step=0.00907, train_loss_epoch=0.00988]Epoch 422: Train Loss = 0.009073702618479729\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=342, train_loss_step=0.0132, train_loss_epoch=0.00907] Epoch 423: Train Loss = 0.013190518133342266\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=342, train_loss_step=0.0122, train_loss_epoch=0.0132] Epoch 424: Train Loss = 0.012189971283078194\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=342, train_loss_step=0.00959, train_loss_epoch=0.0122]Epoch 425: Train Loss = 0.00959168840199709\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=342, train_loss_step=0.0126, train_loss_epoch=0.00959] Epoch 426: Train Loss = 0.01255317497998476\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=342, train_loss_step=0.0101, train_loss_epoch=0.0126] Epoch 427: Train Loss = 0.010138767771422863\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=342, train_loss_step=0.0133, train_loss_epoch=0.0101]Epoch 428: Train Loss = 0.01325188297778368\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=342, train_loss_step=0.00941, train_loss_epoch=0.0133]Epoch 429: Train Loss = 0.009408501908183098\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=342, train_loss_step=0.00776, train_loss_epoch=0.00941]Epoch 430: Train Loss = 0.007763911969959736\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=342, train_loss_step=0.0106, train_loss_epoch=0.00776] Epoch 431: Train Loss = 0.010626534931361675\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=342, train_loss_step=0.0108, train_loss_epoch=0.0106] Epoch 432: Train Loss = 0.010805927217006683\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=342, train_loss_step=0.00897, train_loss_epoch=0.0108]Epoch 433: Train Loss = 0.00897289253771305\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=342, train_loss_step=0.00867, train_loss_epoch=0.00897]Epoch 434: Train Loss = 0.008665923960506916\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=342, train_loss_step=0.00877, train_loss_epoch=0.00867]Epoch 435: Train Loss = 0.008771893568336964\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=342, train_loss_step=0.0115, train_loss_epoch=0.00877] Epoch 436: Train Loss = 0.01152340043336153\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=342, train_loss_step=0.00791, train_loss_epoch=0.0115]Epoch 437: Train Loss = 0.007909238338470459\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=342, train_loss_step=0.0126, train_loss_epoch=0.00791] Epoch 438: Train Loss = 0.01255697850137949\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=342, train_loss_step=0.0144, train_loss_epoch=0.0126] Epoch 439: Train Loss = 0.0143782589584589\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=342, train_loss_step=0.00967, train_loss_epoch=0.0144]Epoch 440: Train Loss = 0.009673376567661762\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=342, train_loss_step=0.0175, train_loss_epoch=0.00967] Epoch 441: Train Loss = 0.01752397231757641\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=342, train_loss_step=0.00996, train_loss_epoch=0.0175]Epoch 442: Train Loss = 0.00996225792914629\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=342, train_loss_step=0.015, train_loss_epoch=0.00996]  Epoch 443: Train Loss = 0.014979660511016846\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=342, train_loss_step=0.00986, train_loss_epoch=0.015]Epoch 444: Train Loss = 0.009856479242444038\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=342, train_loss_step=0.00918, train_loss_epoch=0.00986]Epoch 445: Train Loss = 0.00917992927134037\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=342, train_loss_step=0.00981, train_loss_epoch=0.00918]Epoch 446: Train Loss = 0.009812318719923496\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=342, train_loss_step=0.00755, train_loss_epoch=0.00981]Epoch 447: Train Loss = 0.00755120487883687\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=342, train_loss_step=0.0088, train_loss_epoch=0.00755] Epoch 448: Train Loss = 0.008797048591077328\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=342, train_loss_step=0.0117, train_loss_epoch=0.0088] Epoch 449: Train Loss = 0.011700683273375034\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=342, train_loss_step=0.00982, train_loss_epoch=0.0117]Epoch 450: Train Loss = 0.009820647537708282\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=342, train_loss_step=0.012, train_loss_epoch=0.00982]  Epoch 451: Train Loss = 0.011951616033911705\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=342, train_loss_step=0.0112, train_loss_epoch=0.012] Epoch 452: Train Loss = 0.011167491786181927\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=342, train_loss_step=0.00989, train_loss_epoch=0.0112]Epoch 453: Train Loss = 0.009893336333334446\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=342, train_loss_step=0.0083, train_loss_epoch=0.00989] Epoch 454: Train Loss = 0.008296674117445946\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=342, train_loss_step=0.00986, train_loss_epoch=0.0083]Epoch 455: Train Loss = 0.009857525117695332\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=342, train_loss_step=0.00951, train_loss_epoch=0.00986]Epoch 456: Train Loss = 0.009510659612715244\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=342, train_loss_step=0.0118, train_loss_epoch=0.00951] Epoch 457: Train Loss = 0.011791019700467587\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=342, train_loss_step=0.0147, train_loss_epoch=0.0118] Epoch 458: Train Loss = 0.014736561104655266\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=342, train_loss_step=0.0109, train_loss_epoch=0.0147]Epoch 459: Train Loss = 0.01091576088219881\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=342, train_loss_step=0.013, train_loss_epoch=0.0109] Epoch 460: Train Loss = 0.012964678928256035\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=342, train_loss_step=0.0117, train_loss_epoch=0.013]Epoch 461: Train Loss = 0.011679449118673801\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=342, train_loss_step=0.00943, train_loss_epoch=0.0117]Epoch 462: Train Loss = 0.009429804049432278\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s, v_num=342, train_loss_step=0.00807, train_loss_epoch=0.00943]Epoch 463: Train Loss = 0.008065863512456417\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=342, train_loss_step=0.00939, train_loss_epoch=0.00807]Epoch 464: Train Loss = 0.009387261234223843\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=342, train_loss_step=0.00845, train_loss_epoch=0.00939]Epoch 465: Train Loss = 0.008449399843811989\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=342, train_loss_step=0.010, train_loss_epoch=0.00845]  Epoch 466: Train Loss = 0.009999035857617855\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=342, train_loss_step=0.00788, train_loss_epoch=0.010]Epoch 467: Train Loss = 0.007876564748585224\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=342, train_loss_step=0.00975, train_loss_epoch=0.00788]Epoch 468: Train Loss = 0.009746295399963856\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=342, train_loss_step=0.014, train_loss_epoch=0.00975]  Epoch 469: Train Loss = 0.013989279977977276\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=342, train_loss_step=0.0171, train_loss_epoch=0.014] Epoch 470: Train Loss = 0.01705743558704853\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=342, train_loss_step=0.0118, train_loss_epoch=0.0171]Epoch 471: Train Loss = 0.01179653313010931\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=342, train_loss_step=0.00998, train_loss_epoch=0.0118]Epoch 472: Train Loss = 0.009975478984415531\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=342, train_loss_step=0.00857, train_loss_epoch=0.00998]Epoch 473: Train Loss = 0.008567987941205502\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=342, train_loss_step=0.010, train_loss_epoch=0.00857]  Epoch 474: Train Loss = 0.010006996802985668\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.010] Epoch 475: Train Loss = 0.010666819289326668\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=342, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 476: Train Loss = 0.011586768552660942\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=342, train_loss_step=0.0092, train_loss_epoch=0.0116]Epoch 477: Train Loss = 0.009199527092278004\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=342, train_loss_step=0.0108, train_loss_epoch=0.0092]Epoch 478: Train Loss = 0.010778694413602352\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=342, train_loss_step=0.0131, train_loss_epoch=0.0108]Epoch 479: Train Loss = 0.013063544407486916\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=342, train_loss_step=0.00887, train_loss_epoch=0.0131]Epoch 480: Train Loss = 0.008873476646840572\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=342, train_loss_step=0.0109, train_loss_epoch=0.00887] Epoch 481: Train Loss = 0.010875657200813293\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=342, train_loss_step=0.0108, train_loss_epoch=0.0109] Epoch 482: Train Loss = 0.0107977744191885\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=342, train_loss_step=0.00896, train_loss_epoch=0.0108]Epoch 483: Train Loss = 0.008963095024228096\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=342, train_loss_step=0.0101, train_loss_epoch=0.00896] Epoch 484: Train Loss = 0.010051636025309563\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, v_num=342, train_loss_step=0.00943, train_loss_epoch=0.0101]Epoch 485: Train Loss = 0.009428623132407665\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=342, train_loss_step=0.00829, train_loss_epoch=0.00943]Epoch 486: Train Loss = 0.008291349746286869\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=342, train_loss_step=0.0121, train_loss_epoch=0.00829] Epoch 487: Train Loss = 0.012089503929018974\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=342, train_loss_step=0.0104, train_loss_epoch=0.0121] Epoch 488: Train Loss = 0.010409780777990818\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=342, train_loss_step=0.00994, train_loss_epoch=0.0104]Epoch 489: Train Loss = 0.009937030263245106\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=342, train_loss_step=0.00935, train_loss_epoch=0.00994]Epoch 490: Train Loss = 0.009350740350782871\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=342, train_loss_step=0.00979, train_loss_epoch=0.00935]Epoch 491: Train Loss = 0.009791784919798374\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=342, train_loss_step=0.0135, train_loss_epoch=0.00979] Epoch 492: Train Loss = 0.013499169610440731\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=342, train_loss_step=0.0107, train_loss_epoch=0.0135] Epoch 493: Train Loss = 0.01072183158248663\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=342, train_loss_step=0.00879, train_loss_epoch=0.0107]Epoch 494: Train Loss = 0.008792402222752571\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=342, train_loss_step=0.00801, train_loss_epoch=0.00879]Epoch 495: Train Loss = 0.00801483541727066\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=342, train_loss_step=0.00968, train_loss_epoch=0.00801]Epoch 496: Train Loss = 0.009678044356405735\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=342, train_loss_step=0.00919, train_loss_epoch=0.00968]Epoch 497: Train Loss = 0.00918712466955185\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=342, train_loss_step=0.0168, train_loss_epoch=0.00919] Epoch 498: Train Loss = 0.016768205910921097\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=342, train_loss_step=0.00808, train_loss_epoch=0.0168]Epoch 499: Train Loss = 0.008081234991550446\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=342, train_loss_step=0.00808, train_loss_epoch=0.00808]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=342, train_loss_step=0.00808, train_loss_epoch=0.00808]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 7: from 2008-05-12 00:00:00 to 2022-08-29 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=346, train_loss_step=0.0226]Epoch 0: Train Loss = 0.02256535179913044\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=346, train_loss_step=0.0372, train_loss_epoch=0.0226]Epoch 1: Train Loss = 0.037236861884593964\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=346, train_loss_step=0.0298, train_loss_epoch=0.0372]Epoch 2: Train Loss = 0.02981150709092617\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=346, train_loss_step=0.021, train_loss_epoch=0.0298] Epoch 3: Train Loss = 0.021039774641394615\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=346, train_loss_step=0.0183, train_loss_epoch=0.021]Epoch 4: Train Loss = 0.01826658844947815\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=346, train_loss_step=0.0178, train_loss_epoch=0.0183]Epoch 5: Train Loss = 0.01781340315937996\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=346, train_loss_step=0.0149, train_loss_epoch=0.0178]Epoch 6: Train Loss = 0.014866096898913383\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=346, train_loss_step=0.017, train_loss_epoch=0.0149] Epoch 7: Train Loss = 0.017022186890244484\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=346, train_loss_step=0.0122, train_loss_epoch=0.017]Epoch 8: Train Loss = 0.012174959294497967\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.0122]Epoch 9: Train Loss = 0.011870522983372211\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=346, train_loss_step=0.0178, train_loss_epoch=0.0119]Epoch 10: Train Loss = 0.017752939835190773\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=346, train_loss_step=0.0172, train_loss_epoch=0.0178]Epoch 11: Train Loss = 0.017213638871908188\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=346, train_loss_step=0.014, train_loss_epoch=0.0172] Epoch 12: Train Loss = 0.014001847244799137\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=346, train_loss_step=0.0151, train_loss_epoch=0.014]Epoch 13: Train Loss = 0.015051969327032566\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=346, train_loss_step=0.0157, train_loss_epoch=0.0151]Epoch 14: Train Loss = 0.0156985092908144\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=346, train_loss_step=0.0138, train_loss_epoch=0.0157]Epoch 15: Train Loss = 0.013768070377409458\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=346, train_loss_step=0.0147, train_loss_epoch=0.0138]Epoch 16: Train Loss = 0.014657342806458473\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=346, train_loss_step=0.0135, train_loss_epoch=0.0147]Epoch 17: Train Loss = 0.013472937978804111\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=346, train_loss_step=0.0106, train_loss_epoch=0.0135]Epoch 18: Train Loss = 0.010604603216052055\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=346, train_loss_step=0.0137, train_loss_epoch=0.0106]Epoch 19: Train Loss = 0.013741927221417427\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=346, train_loss_step=0.0125, train_loss_epoch=0.0137]Epoch 20: Train Loss = 0.012451539747416973\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=346, train_loss_step=0.011, train_loss_epoch=0.0125] Epoch 21: Train Loss = 0.010972624644637108\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=346, train_loss_step=0.00945, train_loss_epoch=0.011]Epoch 22: Train Loss = 0.009454997256398201\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=346, train_loss_step=0.00916, train_loss_epoch=0.00945]Epoch 23: Train Loss = 0.009156247600913048\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=346, train_loss_step=0.0156, train_loss_epoch=0.00916] Epoch 24: Train Loss = 0.015619069337844849\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=346, train_loss_step=0.0129, train_loss_epoch=0.0156] Epoch 25: Train Loss = 0.012912898324429989\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=346, train_loss_step=0.0149, train_loss_epoch=0.0129]Epoch 26: Train Loss = 0.014925112016499043\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=346, train_loss_step=0.00985, train_loss_epoch=0.0149]Epoch 27: Train Loss = 0.009850578382611275\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=346, train_loss_step=0.0143, train_loss_epoch=0.00985] Epoch 28: Train Loss = 0.014320045709609985\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.0143] Epoch 29: Train Loss = 0.010544353164732456\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=346, train_loss_step=0.0138, train_loss_epoch=0.0105]Epoch 30: Train Loss = 0.013780900277197361\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=346, train_loss_step=0.0153, train_loss_epoch=0.0138]Epoch 31: Train Loss = 0.015301934443414211\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=346, train_loss_step=0.0177, train_loss_epoch=0.0153]Epoch 32: Train Loss = 0.017671827226877213\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=346, train_loss_step=0.00931, train_loss_epoch=0.0177]Epoch 33: Train Loss = 0.009310522116720676\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=346, train_loss_step=0.012, train_loss_epoch=0.00931]  Epoch 34: Train Loss = 0.012043646536767483\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=346, train_loss_step=0.0134, train_loss_epoch=0.012] Epoch 35: Train Loss = 0.013388504274189472\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=346, train_loss_step=0.0133, train_loss_epoch=0.0134]Epoch 36: Train Loss = 0.013342722319066525\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=346, train_loss_step=0.0164, train_loss_epoch=0.0133]Epoch 37: Train Loss = 0.01639016903936863\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=346, train_loss_step=0.0131, train_loss_epoch=0.0164]Epoch 38: Train Loss = 0.013092530891299248\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=346, train_loss_step=0.0118, train_loss_epoch=0.0131]Epoch 39: Train Loss = 0.011813042685389519\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=346, train_loss_step=0.00982, train_loss_epoch=0.0118]Epoch 40: Train Loss = 0.009820552542805672\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=346, train_loss_step=0.016, train_loss_epoch=0.00982]  Epoch 41: Train Loss = 0.01601899228990078\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=346, train_loss_step=0.0121, train_loss_epoch=0.016] Epoch 42: Train Loss = 0.012116883881390095\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=346, train_loss_step=0.0128, train_loss_epoch=0.0121]Epoch 43: Train Loss = 0.012813687324523926\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.0128]Epoch 44: Train Loss = 0.011202218011021614\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s, v_num=346, train_loss_step=0.0108, train_loss_epoch=0.0112]Epoch 45: Train Loss = 0.010791188105940819\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=346, train_loss_step=0.0131, train_loss_epoch=0.0108]Epoch 46: Train Loss = 0.013096417300403118\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=346, train_loss_step=0.011, train_loss_epoch=0.0131] Epoch 47: Train Loss = 0.010962603613734245\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=346, train_loss_step=0.00941, train_loss_epoch=0.011]Epoch 48: Train Loss = 0.00941359531134367\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.00941] Epoch 49: Train Loss = 0.01188809983432293\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=346, train_loss_step=0.0125, train_loss_epoch=0.0119] Epoch 50: Train Loss = 0.012455688789486885\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=346, train_loss_step=0.00965, train_loss_epoch=0.0125]Epoch 51: Train Loss = 0.009648849256336689\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=346, train_loss_step=0.0118, train_loss_epoch=0.00965] Epoch 52: Train Loss = 0.011824612505733967\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=346, train_loss_step=0.0164, train_loss_epoch=0.0118] Epoch 53: Train Loss = 0.016354987397789955\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.0164]Epoch 54: Train Loss = 0.01131987851113081\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=346, train_loss_step=0.0108, train_loss_epoch=0.0113]Epoch 55: Train Loss = 0.010785115882754326\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.0108]Epoch 56: Train Loss = 0.010933957062661648\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=346, train_loss_step=0.0137, train_loss_epoch=0.0109]Epoch 57: Train Loss = 0.013694862835109234\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0137]Epoch 58: Train Loss = 0.011073342524468899\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=346, train_loss_step=0.014, train_loss_epoch=0.0111] Epoch 59: Train Loss = 0.013952253386378288\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=346, train_loss_step=0.0128, train_loss_epoch=0.014]Epoch 60: Train Loss = 0.012845054268836975\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=346, train_loss_step=0.013, train_loss_epoch=0.0128] Epoch 61: Train Loss = 0.013039528392255306\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.013]Epoch 62: Train Loss = 0.010181008838117123\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=346, train_loss_step=0.0133, train_loss_epoch=0.0102]Epoch 63: Train Loss = 0.013304409570991993\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=346, train_loss_step=0.0106, train_loss_epoch=0.0133]Epoch 64: Train Loss = 0.010620654560625553\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=346, train_loss_step=0.0153, train_loss_epoch=0.0106]Epoch 65: Train Loss = 0.01532535906881094\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=346, train_loss_step=0.0117, train_loss_epoch=0.0153]Epoch 66: Train Loss = 0.011727574281394482\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=346, train_loss_step=0.0162, train_loss_epoch=0.0117]Epoch 67: Train Loss = 0.01623891294002533\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=346, train_loss_step=0.014, train_loss_epoch=0.0162] Epoch 68: Train Loss = 0.014001728966832161\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=346, train_loss_step=0.0138, train_loss_epoch=0.014]Epoch 69: Train Loss = 0.013764680363237858\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=346, train_loss_step=0.0125, train_loss_epoch=0.0138]Epoch 70: Train Loss = 0.012476283125579357\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 11.60it/s, v_num=346, train_loss_step=0.0149, train_loss_epoch=0.0125]Epoch 71: Train Loss = 0.014922401867806911\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=346, train_loss_step=0.0167, train_loss_epoch=0.0149]Epoch 72: Train Loss = 0.016650471836328506\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=346, train_loss_step=0.012, train_loss_epoch=0.0167] Epoch 73: Train Loss = 0.011985689401626587\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.012]Epoch 74: Train Loss = 0.010228656232357025\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=346, train_loss_step=0.0121, train_loss_epoch=0.0102]Epoch 75: Train Loss = 0.012127644382417202\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=346, train_loss_step=0.0131, train_loss_epoch=0.0121]Epoch 76: Train Loss = 0.013091656379401684\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=346, train_loss_step=0.0104, train_loss_epoch=0.0131]Epoch 77: Train Loss = 0.01041353214532137\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=346, train_loss_step=0.0126, train_loss_epoch=0.0104]Epoch 78: Train Loss = 0.012577085755765438\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0126]Epoch 79: Train Loss = 0.011058859527111053\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.0111]Epoch 80: Train Loss = 0.010235922411084175\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=346, train_loss_step=0.0132, train_loss_epoch=0.0102]Epoch 81: Train Loss = 0.013197666965425014\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=346, train_loss_step=0.0136, train_loss_epoch=0.0132]Epoch 82: Train Loss = 0.013591962866485119\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0136]Epoch 83: Train Loss = 0.01114459615200758\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=346, train_loss_step=0.0146, train_loss_epoch=0.0111]Epoch 84: Train Loss = 0.014648597687482834\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=346, train_loss_step=0.0124, train_loss_epoch=0.0146]Epoch 85: Train Loss = 0.012444986961781979\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=346, train_loss_step=0.0137, train_loss_epoch=0.0124]Epoch 86: Train Loss = 0.0136802289634943\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=346, train_loss_step=0.0121, train_loss_epoch=0.0137]Epoch 87: Train Loss = 0.012085286900401115\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=346, train_loss_step=0.0116, train_loss_epoch=0.0121]Epoch 88: Train Loss = 0.011624768376350403\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=346, train_loss_step=0.0144, train_loss_epoch=0.0116]Epoch 89: Train Loss = 0.01438270416110754\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=346, train_loss_step=0.0132, train_loss_epoch=0.0144]Epoch 90: Train Loss = 0.013211525045335293\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=346, train_loss_step=0.0145, train_loss_epoch=0.0132]Epoch 91: Train Loss = 0.014479124918580055\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.0145]Epoch 92: Train Loss = 0.011288964189589024\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=346, train_loss_step=0.0146, train_loss_epoch=0.0113]Epoch 93: Train Loss = 0.014641731046140194\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=346, train_loss_step=0.0139, train_loss_epoch=0.0146]Epoch 94: Train Loss = 0.013946117833256721\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=346, train_loss_step=0.015, train_loss_epoch=0.0139] Epoch 95: Train Loss = 0.015030705370008945\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=346, train_loss_step=0.0114, train_loss_epoch=0.015]Epoch 96: Train Loss = 0.011436204425990582\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=346, train_loss_step=0.0174, train_loss_epoch=0.0114]Epoch 97: Train Loss = 0.017365189269185066\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=346, train_loss_step=0.0139, train_loss_epoch=0.0174]Epoch 98: Train Loss = 0.013888994231820107\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=346, train_loss_step=0.0125, train_loss_epoch=0.0139]Epoch 99: Train Loss = 0.012463887222111225\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=346, train_loss_step=0.0169, train_loss_epoch=0.0125]Epoch 100: Train Loss = 0.01692342758178711\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=346, train_loss_step=0.0123, train_loss_epoch=0.0169]Epoch 101: Train Loss = 0.012318840250372887\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=346, train_loss_step=0.0125, train_loss_epoch=0.0123]Epoch 102: Train Loss = 0.01249045692384243\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=346, train_loss_step=0.013, train_loss_epoch=0.0125] Epoch 103: Train Loss = 0.01304186787456274\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=346, train_loss_step=0.00939, train_loss_epoch=0.013]Epoch 104: Train Loss = 0.009394926950335503\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.00939] Epoch 105: Train Loss = 0.010921997018158436\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=346, train_loss_step=0.0107, train_loss_epoch=0.0109] Epoch 106: Train Loss = 0.010686767287552357\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=346, train_loss_step=0.0108, train_loss_epoch=0.0107]Epoch 107: Train Loss = 0.010781941935420036\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=346, train_loss_step=0.012, train_loss_epoch=0.0108] Epoch 108: Train Loss = 0.012042855843901634\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=346, train_loss_step=0.0155, train_loss_epoch=0.012]Epoch 109: Train Loss = 0.015469620004296303\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=346, train_loss_step=0.0097, train_loss_epoch=0.0155]Epoch 110: Train Loss = 0.009695521555840969\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=346, train_loss_step=0.0117, train_loss_epoch=0.0097]Epoch 111: Train Loss = 0.011703847907483578\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=346, train_loss_step=0.0121, train_loss_epoch=0.0117]Epoch 112: Train Loss = 0.012080247513949871\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=346, train_loss_step=0.0137, train_loss_epoch=0.0121]Epoch 113: Train Loss = 0.0136607950553298\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.0137]Epoch 114: Train Loss = 0.011935843154788017\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s, v_num=346, train_loss_step=0.0106, train_loss_epoch=0.0119]Epoch 115: Train Loss = 0.010610423050820827\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=346, train_loss_step=0.0129, train_loss_epoch=0.0106]Epoch 116: Train Loss = 0.012852422893047333\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=346, train_loss_step=0.00964, train_loss_epoch=0.0129]Epoch 117: Train Loss = 0.009641927666962147\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=346, train_loss_step=0.011, train_loss_epoch=0.00964]  Epoch 118: Train Loss = 0.010956652462482452\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 10.94it/s, v_num=346, train_loss_step=0.0156, train_loss_epoch=0.011] Epoch 119: Train Loss = 0.015597800724208355\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=346, train_loss_step=0.00927, train_loss_epoch=0.0156]Epoch 120: Train Loss = 0.009269737638533115\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=346, train_loss_step=0.0122, train_loss_epoch=0.00927] Epoch 121: Train Loss = 0.01218326110392809\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=346, train_loss_step=0.0098, train_loss_epoch=0.0122] Epoch 122: Train Loss = 0.009797470644116402\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=346, train_loss_step=0.011, train_loss_epoch=0.0098] Epoch 123: Train Loss = 0.011000245809555054\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=346, train_loss_step=0.0142, train_loss_epoch=0.011]Epoch 124: Train Loss = 0.01424481812864542\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.0142]Epoch 125: Train Loss = 0.010453261435031891\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=346, train_loss_step=0.00949, train_loss_epoch=0.0105]Epoch 126: Train Loss = 0.009485788643360138\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=346, train_loss_step=0.00946, train_loss_epoch=0.00949]Epoch 127: Train Loss = 0.00945507176220417\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 10.74it/s, v_num=346, train_loss_step=0.0118, train_loss_epoch=0.00946] Epoch 128: Train Loss = 0.011787488125264645\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0118] Epoch 129: Train Loss = 0.011085412465035915\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=346, train_loss_step=0.0106, train_loss_epoch=0.0111]Epoch 130: Train Loss = 0.01055473554879427\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.0106]Epoch 131: Train Loss = 0.011863130144774914\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.0119]Epoch 132: Train Loss = 0.011218198575079441\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=346, train_loss_step=0.00946, train_loss_epoch=0.0112]Epoch 133: Train Loss = 0.009458327665925026\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.00946] Epoch 134: Train Loss = 0.011171618476510048\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=346, train_loss_step=0.0141, train_loss_epoch=0.0112] Epoch 135: Train Loss = 0.014059324748814106\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=346, train_loss_step=0.00924, train_loss_epoch=0.0141]Epoch 136: Train Loss = 0.00923915859311819\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=346, train_loss_step=0.00938, train_loss_epoch=0.00924]Epoch 137: Train Loss = 0.009378637187182903\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=346, train_loss_step=0.0117, train_loss_epoch=0.00938] Epoch 138: Train Loss = 0.011717945337295532\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=346, train_loss_step=0.00919, train_loss_epoch=0.0117]Epoch 139: Train Loss = 0.009187763556838036\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.00919] Epoch 140: Train Loss = 0.010244590230286121\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=346, train_loss_step=0.00887, train_loss_epoch=0.0102]Epoch 141: Train Loss = 0.008871742524206638\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=346, train_loss_step=0.0103, train_loss_epoch=0.00887] Epoch 142: Train Loss = 0.010285177268087864\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=346, train_loss_step=0.00842, train_loss_epoch=0.0103]Epoch 143: Train Loss = 0.00841908622533083\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=346, train_loss_step=0.00812, train_loss_epoch=0.00842]Epoch 144: Train Loss = 0.008124571293592453\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=346, train_loss_step=0.00797, train_loss_epoch=0.00812]Epoch 145: Train Loss = 0.007972716353833675\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=346, train_loss_step=0.00692, train_loss_epoch=0.00797]Epoch 146: Train Loss = 0.006920475047081709\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=346, train_loss_step=0.0136, train_loss_epoch=0.00692] Epoch 147: Train Loss = 0.013585871085524559\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=346, train_loss_step=0.0117, train_loss_epoch=0.0136] Epoch 148: Train Loss = 0.011709245853126049\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.0117]Epoch 149: Train Loss = 0.011268464848399162\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.0113]Epoch 150: Train Loss = 0.01087123155593872\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 12.46it/s, v_num=346, train_loss_step=0.00898, train_loss_epoch=0.0109]Epoch 151: Train Loss = 0.008984515443444252\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=346, train_loss_step=0.0108, train_loss_epoch=0.00898] Epoch 152: Train Loss = 0.0107555678114295\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.0108] Epoch 153: Train Loss = 0.011243208311498165\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0112]Epoch 154: Train Loss = 0.011094929650425911\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=346, train_loss_step=0.0144, train_loss_epoch=0.0111]Epoch 155: Train Loss = 0.014401243068277836\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=346, train_loss_step=0.0107, train_loss_epoch=0.0144]Epoch 156: Train Loss = 0.010664002038538456\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=346, train_loss_step=0.0139, train_loss_epoch=0.0107]Epoch 157: Train Loss = 0.013933886773884296\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=346, train_loss_step=0.0117, train_loss_epoch=0.0139]Epoch 158: Train Loss = 0.011707725934684277\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=346, train_loss_step=0.0136, train_loss_epoch=0.0117]Epoch 159: Train Loss = 0.013594834133982658\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.0136]Epoch 160: Train Loss = 0.010124506428837776\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=346, train_loss_step=0.00785, train_loss_epoch=0.0101]Epoch 161: Train Loss = 0.007852306589484215\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=346, train_loss_step=0.00765, train_loss_epoch=0.00785]Epoch 162: Train Loss = 0.007648735772818327\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.00765] Epoch 163: Train Loss = 0.011177701875567436\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.0112] Epoch 164: Train Loss = 0.01045744214206934\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=346, train_loss_step=0.00951, train_loss_epoch=0.0105]Epoch 165: Train Loss = 0.009513035416603088\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=346, train_loss_step=0.0123, train_loss_epoch=0.00951] Epoch 166: Train Loss = 0.012329435907304287\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.0123] Epoch 167: Train Loss = 0.01086043007671833\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=346, train_loss_step=0.0134, train_loss_epoch=0.0109]Epoch 168: Train Loss = 0.013367587700486183\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.0134]Epoch 169: Train Loss = 0.01119150873273611\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=346, train_loss_step=0.0106, train_loss_epoch=0.0112]Epoch 170: Train Loss = 0.010611267760396004\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.0106]Epoch 171: Train Loss = 0.010549614205956459\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.0105]Epoch 172: Train Loss = 0.01188723836094141\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=346, train_loss_step=0.0118, train_loss_epoch=0.0119]Epoch 173: Train Loss = 0.011823617853224277\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=346, train_loss_step=0.010, train_loss_epoch=0.0118] Epoch 174: Train Loss = 0.010038895532488823\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=346, train_loss_step=0.0131, train_loss_epoch=0.010]Epoch 175: Train Loss = 0.01310145016759634\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=346, train_loss_step=0.00939, train_loss_epoch=0.0131]Epoch 176: Train Loss = 0.0093928137794137\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=346, train_loss_step=0.0128, train_loss_epoch=0.00939] Epoch 177: Train Loss = 0.012845488265156746\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=346, train_loss_step=0.00962, train_loss_epoch=0.0128]Epoch 178: Train Loss = 0.009624321945011616\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=346, train_loss_step=0.00996, train_loss_epoch=0.00962]Epoch 179: Train Loss = 0.009960434399545193\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=346, train_loss_step=0.00941, train_loss_epoch=0.00996]Epoch 180: Train Loss = 0.009406841360032558\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.00941] Epoch 181: Train Loss = 0.010918975807726383\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=346, train_loss_step=0.015, train_loss_epoch=0.0109]  Epoch 182: Train Loss = 0.015035748481750488\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=346, train_loss_step=0.0122, train_loss_epoch=0.015]Epoch 183: Train Loss = 0.012219270691275597\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.0122]Epoch 184: Train Loss = 0.011920730583369732\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=346, train_loss_step=0.00876, train_loss_epoch=0.0119]Epoch 185: Train Loss = 0.008758792653679848\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=346, train_loss_step=0.00934, train_loss_epoch=0.00876]Epoch 186: Train Loss = 0.009340832941234112\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=346, train_loss_step=0.0114, train_loss_epoch=0.00934] Epoch 187: Train Loss = 0.011432101018726826\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, v_num=346, train_loss_step=0.0153, train_loss_epoch=0.0114] Epoch 188: Train Loss = 0.01528841257095337\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=346, train_loss_step=0.00873, train_loss_epoch=0.0153]Epoch 189: Train Loss = 0.008732804097235203\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=346, train_loss_step=0.013, train_loss_epoch=0.00873]  Epoch 190: Train Loss = 0.013015261851251125\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=346, train_loss_step=0.013, train_loss_epoch=0.013]  Epoch 191: Train Loss = 0.012990355491638184\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=346, train_loss_step=0.00793, train_loss_epoch=0.013]Epoch 192: Train Loss = 0.007928423583507538\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s, v_num=346, train_loss_step=0.0133, train_loss_epoch=0.00793] Epoch 193: Train Loss = 0.013264956884086132\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.0133] Epoch 194: Train Loss = 0.01046675443649292\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=346, train_loss_step=0.0127, train_loss_epoch=0.0105]Epoch 195: Train Loss = 0.012693585827946663\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.0127]Epoch 196: Train Loss = 0.010228211991488934\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.0102]Epoch 197: Train Loss = 0.011861932463943958\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=346, train_loss_step=0.0114, train_loss_epoch=0.0119]Epoch 198: Train Loss = 0.011421210132539272\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0114]Epoch 199: Train Loss = 0.011097646318376064\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=346, train_loss_step=0.0107, train_loss_epoch=0.0111]Epoch 200: Train Loss = 0.01066659577190876\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s, v_num=346, train_loss_step=0.0106, train_loss_epoch=0.0107]Epoch 201: Train Loss = 0.010623499751091003\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=346, train_loss_step=0.00984, train_loss_epoch=0.0106]Epoch 202: Train Loss = 0.009844996966421604\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=346, train_loss_step=0.0162, train_loss_epoch=0.00984] Epoch 203: Train Loss = 0.016167286783456802\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=346, train_loss_step=0.0128, train_loss_epoch=0.0162] Epoch 204: Train Loss = 0.012768579646945\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=346, train_loss_step=0.00752, train_loss_epoch=0.0128]Epoch 205: Train Loss = 0.007516565266996622\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=346, train_loss_step=0.0089, train_loss_epoch=0.00752] Epoch 206: Train Loss = 0.008898784406483173\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=346, train_loss_step=0.00975, train_loss_epoch=0.0089]Epoch 207: Train Loss = 0.009751777164638042\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=346, train_loss_step=0.00888, train_loss_epoch=0.00975]Epoch 208: Train Loss = 0.00888079684227705\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=346, train_loss_step=0.00934, train_loss_epoch=0.00888]Epoch 209: Train Loss = 0.009335211478173733\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=346, train_loss_step=0.00861, train_loss_epoch=0.00934]Epoch 210: Train Loss = 0.008611775003373623\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=346, train_loss_step=0.00941, train_loss_epoch=0.00861]Epoch 211: Train Loss = 0.00940501969307661\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=346, train_loss_step=0.0104, train_loss_epoch=0.00941] Epoch 212: Train Loss = 0.010375337675213814\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=346, train_loss_step=0.0103, train_loss_epoch=0.0104] Epoch 213: Train Loss = 0.010266659781336784\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=346, train_loss_step=0.00786, train_loss_epoch=0.0103]Epoch 214: Train Loss = 0.007860681973397732\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=346, train_loss_step=0.0181, train_loss_epoch=0.00786] Epoch 215: Train Loss = 0.018070803955197334\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=346, train_loss_step=0.0104, train_loss_epoch=0.0181] Epoch 216: Train Loss = 0.01035919226706028\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.0104]Epoch 217: Train Loss = 0.010138370096683502\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=346, train_loss_step=0.0116, train_loss_epoch=0.0101]Epoch 218: Train Loss = 0.011565241031348705\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=346, train_loss_step=0.00947, train_loss_epoch=0.0116]Epoch 219: Train Loss = 0.009469469077885151\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.00947] Epoch 220: Train Loss = 0.010483280755579472\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=346, train_loss_step=0.00914, train_loss_epoch=0.0105]Epoch 221: Train Loss = 0.009136216714978218\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=346, train_loss_step=0.00884, train_loss_epoch=0.00914]Epoch 222: Train Loss = 0.008843488059937954\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.00884] Epoch 223: Train Loss = 0.011296967975795269\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=346, train_loss_step=0.00994, train_loss_epoch=0.0113]Epoch 224: Train Loss = 0.00993629265576601\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=346, train_loss_step=0.00923, train_loss_epoch=0.00994]Epoch 225: Train Loss = 0.009227761067450047\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=346, train_loss_step=0.00933, train_loss_epoch=0.00923]Epoch 226: Train Loss = 0.009333238936960697\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=346, train_loss_step=0.00888, train_loss_epoch=0.00933]Epoch 227: Train Loss = 0.008875378407537937\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=346, train_loss_step=0.00892, train_loss_epoch=0.00888]Epoch 228: Train Loss = 0.0089165223762393\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=346, train_loss_step=0.00995, train_loss_epoch=0.00892]Epoch 229: Train Loss = 0.009948590770363808\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.00995] Epoch 230: Train Loss = 0.01023678295314312\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=346, train_loss_step=0.00889, train_loss_epoch=0.0102]Epoch 231: Train Loss = 0.008888009004294872\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=346, train_loss_step=0.0121, train_loss_epoch=0.00889] Epoch 232: Train Loss = 0.012059586122632027\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=346, train_loss_step=0.0118, train_loss_epoch=0.0121] Epoch 233: Train Loss = 0.01182763371616602\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=346, train_loss_step=0.0159, train_loss_epoch=0.0118]Epoch 234: Train Loss = 0.015852730721235275\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=346, train_loss_step=0.0124, train_loss_epoch=0.0159]Epoch 235: Train Loss = 0.012364162132143974\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=346, train_loss_step=0.0115, train_loss_epoch=0.0124]Epoch 236: Train Loss = 0.011517965234816074\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=346, train_loss_step=0.00908, train_loss_epoch=0.0115]Epoch 237: Train Loss = 0.009075348265469074\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.00908] Epoch 238: Train Loss = 0.010947218164801598\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=346, train_loss_step=0.012, train_loss_epoch=0.0109]  Epoch 239: Train Loss = 0.011960936710238457\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.012]Epoch 240: Train Loss = 0.010469120927155018\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=346, train_loss_step=0.0143, train_loss_epoch=0.0105]Epoch 241: Train Loss = 0.014325574971735477\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0143]Epoch 242: Train Loss = 0.011056400835514069\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=346, train_loss_step=0.00949, train_loss_epoch=0.0111]Epoch 243: Train Loss = 0.009488158859312534\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=346, train_loss_step=0.0115, train_loss_epoch=0.00949] Epoch 244: Train Loss = 0.011538462713360786\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=346, train_loss_step=0.00892, train_loss_epoch=0.0115]Epoch 245: Train Loss = 0.008915684185922146\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=346, train_loss_step=0.0108, train_loss_epoch=0.00892] Epoch 246: Train Loss = 0.010769379325211048\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.0108] Epoch 247: Train Loss = 0.010061925277113914\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.0101]Epoch 248: Train Loss = 0.010113994590938091\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=346, train_loss_step=0.0103, train_loss_epoch=0.0101]Epoch 249: Train Loss = 0.010301253758370876\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=346, train_loss_step=0.0124, train_loss_epoch=0.0103]Epoch 250: Train Loss = 0.012402120046317577\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=346, train_loss_step=0.0118, train_loss_epoch=0.0124]Epoch 251: Train Loss = 0.011754698120057583\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=346, train_loss_step=0.0106, train_loss_epoch=0.0118]Epoch 252: Train Loss = 0.010627740994095802\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=346, train_loss_step=0.0118, train_loss_epoch=0.0106]Epoch 253: Train Loss = 0.011782532557845116\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=346, train_loss_step=0.011, train_loss_epoch=0.0118] Epoch 254: Train Loss = 0.01099178846925497\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.011]Epoch 255: Train Loss = 0.010896661318838596\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=346, train_loss_step=0.0116, train_loss_epoch=0.0109]Epoch 256: Train Loss = 0.011635116301476955\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=346, train_loss_step=0.00903, train_loss_epoch=0.0116]Epoch 257: Train Loss = 0.009029554203152657\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=346, train_loss_step=0.013, train_loss_epoch=0.00903]  Epoch 258: Train Loss = 0.013003182597458363\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.013] Epoch 259: Train Loss = 0.010235984809696674\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=346, train_loss_step=0.0114, train_loss_epoch=0.0102]Epoch 260: Train Loss = 0.011445184238255024\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0114]Epoch 261: Train Loss = 0.011121989227831364\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=346, train_loss_step=0.0124, train_loss_epoch=0.0111]Epoch 262: Train Loss = 0.012361043132841587\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=346, train_loss_step=0.00983, train_loss_epoch=0.0124]Epoch 263: Train Loss = 0.009830550290644169\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=346, train_loss_step=0.012, train_loss_epoch=0.00983]  Epoch 264: Train Loss = 0.01204781886190176\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=346, train_loss_step=0.00938, train_loss_epoch=0.012]Epoch 265: Train Loss = 0.009379678405821323\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=346, train_loss_step=0.00897, train_loss_epoch=0.00938]Epoch 266: Train Loss = 0.00897005945444107\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=346, train_loss_step=0.00754, train_loss_epoch=0.00897]Epoch 267: Train Loss = 0.0075429705902934074\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=346, train_loss_step=0.00847, train_loss_epoch=0.00754]Epoch 268: Train Loss = 0.008468670770525932\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.00847] Epoch 269: Train Loss = 0.01020975410938263\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=346, train_loss_step=0.00973, train_loss_epoch=0.0102]Epoch 270: Train Loss = 0.009729589335620403\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.00973] Epoch 271: Train Loss = 0.010523577220737934\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, v_num=346, train_loss_step=0.0121, train_loss_epoch=0.0105] Epoch 272: Train Loss = 0.012121395207941532\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.0121]Epoch 273: Train Loss = 0.011250310577452183\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=346, train_loss_step=0.00864, train_loss_epoch=0.0113]Epoch 274: Train Loss = 0.008635844103991985\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=346, train_loss_step=0.0108, train_loss_epoch=0.00864] Epoch 275: Train Loss = 0.01077545527368784\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=346, train_loss_step=0.0104, train_loss_epoch=0.0108] Epoch 276: Train Loss = 0.010372817516326904\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.0104]Epoch 277: Train Loss = 0.01131090335547924\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=346, train_loss_step=0.0122, train_loss_epoch=0.0113]Epoch 278: Train Loss = 0.012225963175296783\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=346, train_loss_step=0.00741, train_loss_epoch=0.0122]Epoch 279: Train Loss = 0.0074095940217375755\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=346, train_loss_step=0.0121, train_loss_epoch=0.00741] Epoch 280: Train Loss = 0.012130329385399818\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=346, train_loss_step=0.010, train_loss_epoch=0.0121]  Epoch 281: Train Loss = 0.010039537213742733\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=346, train_loss_step=0.0124, train_loss_epoch=0.010]Epoch 282: Train Loss = 0.012352699413895607\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=346, train_loss_step=0.0124, train_loss_epoch=0.0124]Epoch 283: Train Loss = 0.01243724673986435\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=346, train_loss_step=0.0108, train_loss_epoch=0.0124]Epoch 284: Train Loss = 0.01076569501310587\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.0108]Epoch 285: Train Loss = 0.010907085612416267\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=346, train_loss_step=0.0118, train_loss_epoch=0.0109]Epoch 286: Train Loss = 0.011762507259845734\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=346, train_loss_step=0.00986, train_loss_epoch=0.0118]Epoch 287: Train Loss = 0.009858758188784122\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=346, train_loss_step=0.00739, train_loss_epoch=0.00986]Epoch 288: Train Loss = 0.0073876031674444675\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=346, train_loss_step=0.0084, train_loss_epoch=0.00739] Epoch 289: Train Loss = 0.008404863998293877\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=346, train_loss_step=0.0081, train_loss_epoch=0.0084] Epoch 290: Train Loss = 0.008098078891634941\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=346, train_loss_step=0.00992, train_loss_epoch=0.0081]Epoch 291: Train Loss = 0.009916397742927074\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=346, train_loss_step=0.00786, train_loss_epoch=0.00992]Epoch 292: Train Loss = 0.007862919010221958\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=346, train_loss_step=0.0122, train_loss_epoch=0.00786] Epoch 293: Train Loss = 0.012188350781798363\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=346, train_loss_step=0.00861, train_loss_epoch=0.0122]Epoch 294: Train Loss = 0.008611631579697132\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, v_num=346, train_loss_step=0.00899, train_loss_epoch=0.00861]Epoch 295: Train Loss = 0.008994405157864094\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=346, train_loss_step=0.014, train_loss_epoch=0.00899]  Epoch 296: Train Loss = 0.013972504064440727\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=346, train_loss_step=0.00783, train_loss_epoch=0.014]Epoch 297: Train Loss = 0.007829065434634686\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=346, train_loss_step=0.0107, train_loss_epoch=0.00783] Epoch 298: Train Loss = 0.010653846897184849\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=346, train_loss_step=0.0131, train_loss_epoch=0.0107] Epoch 299: Train Loss = 0.013098751194775105\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.0131]Epoch 300: Train Loss = 0.010079949162900448\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=346, train_loss_step=0.0099, train_loss_epoch=0.0101]Epoch 301: Train Loss = 0.00990401953458786\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.0099]Epoch 302: Train Loss = 0.011152750812470913\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=346, train_loss_step=0.00835, train_loss_epoch=0.0112]Epoch 303: Train Loss = 0.00834548007696867\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 11.20it/s, v_num=346, train_loss_step=0.0115, train_loss_epoch=0.00835] Epoch 304: Train Loss = 0.011536503210663795\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0115] Epoch 305: Train Loss = 0.0111192362383008\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=346, train_loss_step=0.0141, train_loss_epoch=0.0111]Epoch 306: Train Loss = 0.014143570326268673\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=346, train_loss_step=0.00997, train_loss_epoch=0.0141]Epoch 307: Train Loss = 0.009974335320293903\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=346, train_loss_step=0.00808, train_loss_epoch=0.00997]Epoch 308: Train Loss = 0.008076305501163006\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.00808] Epoch 309: Train Loss = 0.011098056100308895\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=346, train_loss_step=0.00939, train_loss_epoch=0.0111]Epoch 310: Train Loss = 0.009387378580868244\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=346, train_loss_step=0.00849, train_loss_epoch=0.00939]Epoch 311: Train Loss = 0.00849076732993126\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=346, train_loss_step=0.00932, train_loss_epoch=0.00849]Epoch 312: Train Loss = 0.009317387826740742\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=346, train_loss_step=0.00829, train_loss_epoch=0.00932]Epoch 313: Train Loss = 0.008287173695862293\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.00829] Epoch 314: Train Loss = 0.010903100483119488\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.0109] Epoch 315: Train Loss = 0.010214785113930702\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=346, train_loss_step=0.0133, train_loss_epoch=0.0102]Epoch 316: Train Loss = 0.013343073427677155\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.0133]Epoch 317: Train Loss = 0.011253771372139454\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.0113]Epoch 318: Train Loss = 0.010914919897913933\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=346, train_loss_step=0.00932, train_loss_epoch=0.0109]Epoch 319: Train Loss = 0.009318944998085499\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.00932] Epoch 320: Train Loss = 0.011946926824748516\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.0119] Epoch 321: Train Loss = 0.011917589232325554\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=346, train_loss_step=0.00686, train_loss_epoch=0.0119]Epoch 322: Train Loss = 0.006861515808850527\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=346, train_loss_step=0.0108, train_loss_epoch=0.00686] Epoch 323: Train Loss = 0.010777940042316914\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=346, train_loss_step=0.0121, train_loss_epoch=0.0108] Epoch 324: Train Loss = 0.012112622149288654\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.0121]Epoch 325: Train Loss = 0.010936946608126163\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=346, train_loss_step=0.00932, train_loss_epoch=0.0109]Epoch 326: Train Loss = 0.00932381022721529\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.00932] Epoch 327: Train Loss = 0.010115458630025387\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=346, train_loss_step=0.010, train_loss_epoch=0.0101]  Epoch 328: Train Loss = 0.009999225847423077\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=346, train_loss_step=0.00932, train_loss_epoch=0.010]Epoch 329: Train Loss = 0.009315681643784046\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=346, train_loss_step=0.0124, train_loss_epoch=0.00932] Epoch 330: Train Loss = 0.012429624795913696\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=346, train_loss_step=0.00682, train_loss_epoch=0.0124]Epoch 331: Train Loss = 0.006815562956035137\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=346, train_loss_step=0.00782, train_loss_epoch=0.00682]Epoch 332: Train Loss = 0.00782007072120905\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=346, train_loss_step=0.0108, train_loss_epoch=0.00782] Epoch 333: Train Loss = 0.010754487477242947\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=346, train_loss_step=0.00816, train_loss_epoch=0.0108]Epoch 334: Train Loss = 0.00816358719021082\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=346, train_loss_step=0.0107, train_loss_epoch=0.00816] Epoch 335: Train Loss = 0.010687077417969704\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=346, train_loss_step=0.011, train_loss_epoch=0.0107]  Epoch 336: Train Loss = 0.0109932292252779\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=346, train_loss_step=0.00982, train_loss_epoch=0.011]Epoch 337: Train Loss = 0.009816018864512444\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=346, train_loss_step=0.0103, train_loss_epoch=0.00982] Epoch 338: Train Loss = 0.010316893458366394\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=346, train_loss_step=0.0143, train_loss_epoch=0.0103] Epoch 339: Train Loss = 0.014275598339736462\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=346, train_loss_step=0.00937, train_loss_epoch=0.0143]Epoch 340: Train Loss = 0.00936770997941494\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, v_num=346, train_loss_step=0.00903, train_loss_epoch=0.00937]Epoch 341: Train Loss = 0.009027650579810143\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=346, train_loss_step=0.00987, train_loss_epoch=0.00903]Epoch 342: Train Loss = 0.009870282374322414\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=346, train_loss_step=0.0143, train_loss_epoch=0.00987] Epoch 343: Train Loss = 0.014316683635115623\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=346, train_loss_step=0.00929, train_loss_epoch=0.0143]Epoch 344: Train Loss = 0.009292826056480408\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=346, train_loss_step=0.00888, train_loss_epoch=0.00929]Epoch 345: Train Loss = 0.008881660178303719\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 12.27it/s, v_num=346, train_loss_step=0.00736, train_loss_epoch=0.00888]Epoch 346: Train Loss = 0.007357836700975895\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 12.25it/s, v_num=346, train_loss_step=0.00836, train_loss_epoch=0.00736]Epoch 347: Train Loss = 0.008361900225281715\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=346, train_loss_step=0.00752, train_loss_epoch=0.00836]Epoch 348: Train Loss = 0.007518515456467867\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 11.40it/s, v_num=346, train_loss_step=0.00821, train_loss_epoch=0.00752]Epoch 349: Train Loss = 0.008211459033191204\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=346, train_loss_step=0.009, train_loss_epoch=0.00821]  Epoch 350: Train Loss = 0.008995258249342442\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=346, train_loss_step=0.00883, train_loss_epoch=0.009]Epoch 351: Train Loss = 0.00882929190993309\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.00883] Epoch 352: Train Loss = 0.010210416279733181\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=346, train_loss_step=0.0152, train_loss_epoch=0.0102] Epoch 353: Train Loss = 0.015190035104751587\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=346, train_loss_step=0.00974, train_loss_epoch=0.0152]Epoch 354: Train Loss = 0.009741303510963917\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=346, train_loss_step=0.00778, train_loss_epoch=0.00974]Epoch 355: Train Loss = 0.007778169121593237\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.00778] Epoch 356: Train Loss = 0.010216589085757732\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=346, train_loss_step=0.0104, train_loss_epoch=0.0102] Epoch 357: Train Loss = 0.010422791354358196\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=346, train_loss_step=0.00859, train_loss_epoch=0.0104]Epoch 358: Train Loss = 0.008590997196733952\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=346, train_loss_step=0.0136, train_loss_epoch=0.00859] Epoch 359: Train Loss = 0.013607935979962349\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=346, train_loss_step=0.00814, train_loss_epoch=0.0136]Epoch 360: Train Loss = 0.008143763989210129\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=346, train_loss_step=0.00702, train_loss_epoch=0.00814]Epoch 361: Train Loss = 0.007018078584223986\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.00702] Epoch 362: Train Loss = 0.01111478079110384\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=346, train_loss_step=0.0149, train_loss_epoch=0.0111] Epoch 363: Train Loss = 0.014937365427613258\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=346, train_loss_step=0.00911, train_loss_epoch=0.0149]Epoch 364: Train Loss = 0.009106184355914593\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.00911] Epoch 365: Train Loss = 0.010154654271900654\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=346, train_loss_step=0.00943, train_loss_epoch=0.0102]Epoch 366: Train Loss = 0.009433737024664879\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=346, train_loss_step=0.0093, train_loss_epoch=0.00943] Epoch 367: Train Loss = 0.009302088990807533\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=346, train_loss_step=0.0152, train_loss_epoch=0.0093] Epoch 368: Train Loss = 0.015241576358675957\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=346, train_loss_step=0.00833, train_loss_epoch=0.0152]Epoch 369: Train Loss = 0.008333178237080574\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=346, train_loss_step=0.0063, train_loss_epoch=0.00833] Epoch 370: Train Loss = 0.0063043939881026745\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 10.67it/s, v_num=346, train_loss_step=0.0104, train_loss_epoch=0.0063] Epoch 371: Train Loss = 0.010438146069645882\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=346, train_loss_step=0.00924, train_loss_epoch=0.0104]Epoch 372: Train Loss = 0.009243900887668133\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=346, train_loss_step=0.00896, train_loss_epoch=0.00924]Epoch 373: Train Loss = 0.008961633779108524\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=346, train_loss_step=0.0123, train_loss_epoch=0.00896] Epoch 374: Train Loss = 0.012250274419784546\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=346, train_loss_step=0.00936, train_loss_epoch=0.0123]Epoch 375: Train Loss = 0.009361418895423412\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=346, train_loss_step=0.00856, train_loss_epoch=0.00936]Epoch 376: Train Loss = 0.008556661196053028\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.00856] Epoch 377: Train Loss = 0.011307147331535816\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=346, train_loss_step=0.0134, train_loss_epoch=0.0113] Epoch 378: Train Loss = 0.013426287099719048\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=346, train_loss_step=0.00984, train_loss_epoch=0.0134]Epoch 379: Train Loss = 0.009838858619332314\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=346, train_loss_step=0.00967, train_loss_epoch=0.00984]Epoch 380: Train Loss = 0.00967053510248661\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=346, train_loss_step=0.0106, train_loss_epoch=0.00967] Epoch 381: Train Loss = 0.010561920702457428\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=346, train_loss_step=0.013, train_loss_epoch=0.0106]  Epoch 382: Train Loss = 0.012967908754944801\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=346, train_loss_step=0.0103, train_loss_epoch=0.013]Epoch 383: Train Loss = 0.010347945615649223\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=346, train_loss_step=0.0153, train_loss_epoch=0.0103]Epoch 384: Train Loss = 0.015257250517606735\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=346, train_loss_step=0.00896, train_loss_epoch=0.0153]Epoch 385: Train Loss = 0.008960181847214699\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=346, train_loss_step=0.00869, train_loss_epoch=0.00896]Epoch 386: Train Loss = 0.008687855675816536\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=346, train_loss_step=0.00829, train_loss_epoch=0.00869]Epoch 387: Train Loss = 0.008286467753350735\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.00829] Epoch 388: Train Loss = 0.01123394351452589\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=346, train_loss_step=0.00775, train_loss_epoch=0.0112]Epoch 389: Train Loss = 0.00775145972147584\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=346, train_loss_step=0.00888, train_loss_epoch=0.00775]Epoch 390: Train Loss = 0.008882849477231503\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.00888] Epoch 391: Train Loss = 0.011190238408744335\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=346, train_loss_step=0.012, train_loss_epoch=0.0112]  Epoch 392: Train Loss = 0.011970557272434235\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=346, train_loss_step=0.0106, train_loss_epoch=0.012]Epoch 393: Train Loss = 0.01060962863266468\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=346, train_loss_step=0.00906, train_loss_epoch=0.0106]Epoch 394: Train Loss = 0.009057210758328438\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s, v_num=346, train_loss_step=0.00945, train_loss_epoch=0.00906]Epoch 395: Train Loss = 0.009450907818973064\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=346, train_loss_step=0.00733, train_loss_epoch=0.00945]Epoch 396: Train Loss = 0.007327369414269924\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=346, train_loss_step=0.0096, train_loss_epoch=0.00733] Epoch 397: Train Loss = 0.009603766724467278\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.0096] Epoch 398: Train Loss = 0.010482448153197765\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=346, train_loss_step=0.0122, train_loss_epoch=0.0105]Epoch 399: Train Loss = 0.012233265675604343\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=346, train_loss_step=0.0117, train_loss_epoch=0.0122]Epoch 400: Train Loss = 0.011712678708136082\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.0117]Epoch 401: Train Loss = 0.010068200528621674\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=346, train_loss_step=0.00905, train_loss_epoch=0.0101]Epoch 402: Train Loss = 0.009052477777004242\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.00905] Epoch 403: Train Loss = 0.010147386230528355\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=346, train_loss_step=0.00972, train_loss_epoch=0.0101]Epoch 404: Train Loss = 0.009721703827381134\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=346, train_loss_step=0.00974, train_loss_epoch=0.00972]Epoch 405: Train Loss = 0.009736412204802036\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=346, train_loss_step=0.0084, train_loss_epoch=0.00974] Epoch 406: Train Loss = 0.008398378267884254\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=346, train_loss_step=0.00977, train_loss_epoch=0.0084]Epoch 407: Train Loss = 0.009768890216946602\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=346, train_loss_step=0.00964, train_loss_epoch=0.00977]Epoch 408: Train Loss = 0.009641440585255623\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.00964] Epoch 409: Train Loss = 0.010211825370788574\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=346, train_loss_step=0.0107, train_loss_epoch=0.0102] Epoch 410: Train Loss = 0.010656075552105904\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=346, train_loss_step=0.0103, train_loss_epoch=0.0107]Epoch 411: Train Loss = 0.01032725814729929\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.0103]Epoch 412: Train Loss = 0.011296572163701057\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=346, train_loss_step=0.00913, train_loss_epoch=0.0113]Epoch 413: Train Loss = 0.009128452278673649\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=346, train_loss_step=0.0117, train_loss_epoch=0.00913] Epoch 414: Train Loss = 0.01165751088410616\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=346, train_loss_step=0.0128, train_loss_epoch=0.0117] Epoch 415: Train Loss = 0.012821300886571407\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.0128]Epoch 416: Train Loss = 0.011250229552388191\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=346, train_loss_step=0.00835, train_loss_epoch=0.0113]Epoch 417: Train Loss = 0.008349867537617683\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=346, train_loss_step=0.00879, train_loss_epoch=0.00835]Epoch 418: Train Loss = 0.008791663683950901\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=346, train_loss_step=0.00784, train_loss_epoch=0.00879]Epoch 419: Train Loss = 0.007844929583370686\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=346, train_loss_step=0.00906, train_loss_epoch=0.00784]Epoch 420: Train Loss = 0.009063701145350933\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=346, train_loss_step=0.0116, train_loss_epoch=0.00906] Epoch 421: Train Loss = 0.011574672535061836\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=346, train_loss_step=0.00858, train_loss_epoch=0.0116]Epoch 422: Train Loss = 0.00857741292566061\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=346, train_loss_step=0.0106, train_loss_epoch=0.00858] Epoch 423: Train Loss = 0.010628931224346161\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=346, train_loss_step=0.0133, train_loss_epoch=0.0106] Epoch 424: Train Loss = 0.013297690078616142\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.0133]Epoch 425: Train Loss = 0.010179595090448856\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=346, train_loss_step=0.00865, train_loss_epoch=0.0102]Epoch 426: Train Loss = 0.008646245114505291\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=346, train_loss_step=0.0128, train_loss_epoch=0.00865] Epoch 427: Train Loss = 0.012822414748370647\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=346, train_loss_step=0.00916, train_loss_epoch=0.0128]Epoch 428: Train Loss = 0.009161912836134434\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=346, train_loss_step=0.00995, train_loss_epoch=0.00916]Epoch 429: Train Loss = 0.009946301579475403\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.00995] Epoch 430: Train Loss = 0.010181664489209652\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=346, train_loss_step=0.00962, train_loss_epoch=0.0102]Epoch 431: Train Loss = 0.009622539393603802\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=346, train_loss_step=0.0097, train_loss_epoch=0.00962] Epoch 432: Train Loss = 0.009704457595944405\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=346, train_loss_step=0.0118, train_loss_epoch=0.0097] Epoch 433: Train Loss = 0.0118342200294137\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=346, train_loss_step=0.0102, train_loss_epoch=0.0118]Epoch 434: Train Loss = 0.010164007544517517\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=346, train_loss_step=0.0104, train_loss_epoch=0.0102]Epoch 435: Train Loss = 0.01039364468306303\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=346, train_loss_step=0.00799, train_loss_epoch=0.0104]Epoch 436: Train Loss = 0.007990005426108837\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=346, train_loss_step=0.00852, train_loss_epoch=0.00799]Epoch 437: Train Loss = 0.008518394082784653\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.00852] Epoch 438: Train Loss = 0.010461906902492046\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=346, train_loss_step=0.00998, train_loss_epoch=0.0105]Epoch 439: Train Loss = 0.009976096451282501\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.00998] Epoch 440: Train Loss = 0.011080670170485973\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.0111] Epoch 441: Train Loss = 0.011880079284310341\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0119]Epoch 442: Train Loss = 0.011087888851761818\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=346, train_loss_step=0.010, train_loss_epoch=0.0111] Epoch 443: Train Loss = 0.010025197640061378\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=346, train_loss_step=0.0104, train_loss_epoch=0.010]Epoch 444: Train Loss = 0.010390679351985455\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=346, train_loss_step=0.00986, train_loss_epoch=0.0104]Epoch 445: Train Loss = 0.009855308569967747\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.00986] Epoch 446: Train Loss = 0.011163459159433842\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=346, train_loss_step=0.0115, train_loss_epoch=0.0112] Epoch 447: Train Loss = 0.011496083810925484\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=346, train_loss_step=0.0103, train_loss_epoch=0.0115]Epoch 448: Train Loss = 0.010271118022501469\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=346, train_loss_step=0.0125, train_loss_epoch=0.0103]Epoch 449: Train Loss = 0.012461679056286812\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=346, train_loss_step=0.00962, train_loss_epoch=0.0125]Epoch 450: Train Loss = 0.009623722173273563\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=346, train_loss_step=0.00944, train_loss_epoch=0.00962]Epoch 451: Train Loss = 0.009438907727599144\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=346, train_loss_step=0.0108, train_loss_epoch=0.00944] Epoch 452: Train Loss = 0.01081026066094637\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=346, train_loss_step=0.0095, train_loss_epoch=0.0108] Epoch 453: Train Loss = 0.009504280053079128\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=346, train_loss_step=0.0115, train_loss_epoch=0.0095]Epoch 454: Train Loss = 0.011542296968400478\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=346, train_loss_step=0.0111, train_loss_epoch=0.0115]Epoch 455: Train Loss = 0.011149764992296696\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=346, train_loss_step=0.0114, train_loss_epoch=0.0111]Epoch 456: Train Loss = 0.011365227401256561\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=346, train_loss_step=0.00839, train_loss_epoch=0.0114]Epoch 457: Train Loss = 0.008391658775508404\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=346, train_loss_step=0.00791, train_loss_epoch=0.00839]Epoch 458: Train Loss = 0.007909915409982204\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=346, train_loss_step=0.00941, train_loss_epoch=0.00791]Epoch 459: Train Loss = 0.009410341270267963\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=346, train_loss_step=0.00963, train_loss_epoch=0.00941]Epoch 460: Train Loss = 0.009630012325942516\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=346, train_loss_step=0.0097, train_loss_epoch=0.00963] Epoch 461: Train Loss = 0.009702594950795174\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=346, train_loss_step=0.00773, train_loss_epoch=0.0097]Epoch 462: Train Loss = 0.007734379731118679\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=346, train_loss_step=0.00961, train_loss_epoch=0.00773]Epoch 463: Train Loss = 0.00960987526923418\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=346, train_loss_step=0.0069, train_loss_epoch=0.00961] Epoch 464: Train Loss = 0.0068995957262814045\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=346, train_loss_step=0.00894, train_loss_epoch=0.0069]Epoch 465: Train Loss = 0.008942713961005211\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=346, train_loss_step=0.00881, train_loss_epoch=0.00894]Epoch 466: Train Loss = 0.008813919499516487\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=346, train_loss_step=0.0103, train_loss_epoch=0.00881] Epoch 467: Train Loss = 0.010259151458740234\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=346, train_loss_step=0.00987, train_loss_epoch=0.0103]Epoch 468: Train Loss = 0.009872844442725182\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=346, train_loss_step=0.00998, train_loss_epoch=0.00987]Epoch 469: Train Loss = 0.00997752882540226\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=346, train_loss_step=0.00858, train_loss_epoch=0.00998]Epoch 470: Train Loss = 0.008583185262978077\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=346, train_loss_step=0.0107, train_loss_epoch=0.00858] Epoch 471: Train Loss = 0.010735024698078632\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=346, train_loss_step=0.00951, train_loss_epoch=0.0107]Epoch 472: Train Loss = 0.009512513875961304\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.00951] Epoch 473: Train Loss = 0.0111589590087533\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.0112] Epoch 474: Train Loss = 0.010073416866362095\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=346, train_loss_step=0.00988, train_loss_epoch=0.0101]Epoch 475: Train Loss = 0.00987898837774992\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=346, train_loss_step=0.0121, train_loss_epoch=0.00988] Epoch 476: Train Loss = 0.012051683850586414\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=346, train_loss_step=0.0133, train_loss_epoch=0.0121] Epoch 477: Train Loss = 0.013295693323016167\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=346, train_loss_step=0.0128, train_loss_epoch=0.0133]Epoch 478: Train Loss = 0.012750172056257725\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s, v_num=346, train_loss_step=0.0105, train_loss_epoch=0.0128]Epoch 479: Train Loss = 0.010538813658058643\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=346, train_loss_step=0.00851, train_loss_epoch=0.0105]Epoch 480: Train Loss = 0.008514451794326305\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=346, train_loss_step=0.0119, train_loss_epoch=0.00851] Epoch 481: Train Loss = 0.011914469301700592\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=346, train_loss_step=0.0121, train_loss_epoch=0.0119] Epoch 482: Train Loss = 0.01214913371950388\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=346, train_loss_step=0.0109, train_loss_epoch=0.0121]Epoch 483: Train Loss = 0.010911085642874241\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=346, train_loss_step=0.0123, train_loss_epoch=0.0109]Epoch 484: Train Loss = 0.012346379458904266\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=346, train_loss_step=0.00799, train_loss_epoch=0.0123]Epoch 485: Train Loss = 0.007990009151399136\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=346, train_loss_step=0.0137, train_loss_epoch=0.00799] Epoch 486: Train Loss = 0.01371047180145979\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=346, train_loss_step=0.00828, train_loss_epoch=0.0137]Epoch 487: Train Loss = 0.008282942697405815\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=346, train_loss_step=0.00823, train_loss_epoch=0.00828]Epoch 488: Train Loss = 0.00822500791400671\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.00823] Epoch 489: Train Loss = 0.010129268281161785\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=346, train_loss_step=0.0112, train_loss_epoch=0.0101] Epoch 490: Train Loss = 0.011156288906931877\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=346, train_loss_step=0.00953, train_loss_epoch=0.0112]Epoch 491: Train Loss = 0.009530921466648579\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=346, train_loss_step=0.00925, train_loss_epoch=0.00953]Epoch 492: Train Loss = 0.009247980080544949\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=346, train_loss_step=0.0147, train_loss_epoch=0.00925] Epoch 493: Train Loss = 0.014654035679996014\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=346, train_loss_step=0.0114, train_loss_epoch=0.0147] Epoch 494: Train Loss = 0.011438222602009773\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=346, train_loss_step=0.0103, train_loss_epoch=0.0114]Epoch 495: Train Loss = 0.010347074829041958\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=346, train_loss_step=0.0101, train_loss_epoch=0.0103]Epoch 496: Train Loss = 0.010051115415990353\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 11.37it/s, v_num=346, train_loss_step=0.00905, train_loss_epoch=0.0101]Epoch 497: Train Loss = 0.009050469845533371\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=346, train_loss_step=0.00824, train_loss_epoch=0.00905]Epoch 498: Train Loss = 0.008238410577178001\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.00824] Epoch 499: Train Loss = 0.01129781175404787\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.0113] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=346, train_loss_step=0.0113, train_loss_epoch=0.0113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 39.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 8: from 2008-05-12 00:00:00 to 2022-09-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=350, train_loss_step=0.0231]Epoch 0: Train Loss = 0.023086529225111008\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=350, train_loss_step=0.030, train_loss_epoch=0.0231] Epoch 1: Train Loss = 0.03002237342298031\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=350, train_loss_step=0.0276, train_loss_epoch=0.030]Epoch 2: Train Loss = 0.027607819065451622\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=350, train_loss_step=0.026, train_loss_epoch=0.0276] Epoch 3: Train Loss = 0.026037218049168587\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=350, train_loss_step=0.0211, train_loss_epoch=0.026]Epoch 4: Train Loss = 0.021107947453856468\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=350, train_loss_step=0.0159, train_loss_epoch=0.0211]Epoch 5: Train Loss = 0.015856238082051277\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=350, train_loss_step=0.0147, train_loss_epoch=0.0159]Epoch 6: Train Loss = 0.014704734086990356\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=350, train_loss_step=0.0185, train_loss_epoch=0.0147]Epoch 7: Train Loss = 0.01850268989801407\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=350, train_loss_step=0.0122, train_loss_epoch=0.0185]Epoch 8: Train Loss = 0.012230666354298592\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.0122]Epoch 9: Train Loss = 0.012135319411754608\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s, v_num=350, train_loss_step=0.0142, train_loss_epoch=0.0121]Epoch 10: Train Loss = 0.014190243557095528\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.0142]Epoch 11: Train Loss = 0.01256564725190401\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=350, train_loss_step=0.0145, train_loss_epoch=0.0126]Epoch 12: Train Loss = 0.014467321336269379\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.0145]Epoch 13: Train Loss = 0.012570283375680447\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=350, train_loss_step=0.0139, train_loss_epoch=0.0126]Epoch 14: Train Loss = 0.013935761526226997\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=350, train_loss_step=0.013, train_loss_epoch=0.0139] Epoch 15: Train Loss = 0.012960976921021938\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.013]Epoch 16: Train Loss = 0.012647734954953194\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=350, train_loss_step=0.0131, train_loss_epoch=0.0126]Epoch 17: Train Loss = 0.01305621862411499\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=350, train_loss_step=0.00926, train_loss_epoch=0.0131]Epoch 18: Train Loss = 0.009263135492801666\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.00926] Epoch 19: Train Loss = 0.010747415944933891\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=350, train_loss_step=0.0133, train_loss_epoch=0.0107] Epoch 20: Train Loss = 0.013316109776496887\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=350, train_loss_step=0.0144, train_loss_epoch=0.0133]Epoch 21: Train Loss = 0.014414757490158081\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=350, train_loss_step=0.0108, train_loss_epoch=0.0144]Epoch 22: Train Loss = 0.010757846757769585\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=350, train_loss_step=0.0151, train_loss_epoch=0.0108]Epoch 23: Train Loss = 0.015095827169716358\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=350, train_loss_step=0.00942, train_loss_epoch=0.0151]Epoch 24: Train Loss = 0.009417028166353703\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=350, train_loss_step=0.0104, train_loss_epoch=0.00942] Epoch 25: Train Loss = 0.01042326632887125\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=350, train_loss_step=0.0157, train_loss_epoch=0.0104] Epoch 26: Train Loss = 0.015722690150141716\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=350, train_loss_step=0.0155, train_loss_epoch=0.0157]Epoch 27: Train Loss = 0.01554105244576931\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=350, train_loss_step=0.0163, train_loss_epoch=0.0155]Epoch 28: Train Loss = 0.016341129317879677\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=350, train_loss_step=0.0145, train_loss_epoch=0.0163]Epoch 29: Train Loss = 0.014532667584717274\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=350, train_loss_step=0.0176, train_loss_epoch=0.0145]Epoch 30: Train Loss = 0.01757747307419777\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=350, train_loss_step=0.00952, train_loss_epoch=0.0176]Epoch 31: Train Loss = 0.009516984224319458\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=350, train_loss_step=0.0133, train_loss_epoch=0.00952] Epoch 32: Train Loss = 0.01333118136972189\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=350, train_loss_step=0.00942, train_loss_epoch=0.0133]Epoch 33: Train Loss = 0.009424303658306599\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=350, train_loss_step=0.0101, train_loss_epoch=0.00942] Epoch 34: Train Loss = 0.010084898211061954\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.0101]  Epoch 35: Train Loss = 0.011007355526089668\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=350, train_loss_step=0.0117, train_loss_epoch=0.011]Epoch 36: Train Loss = 0.011736981570720673\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=350, train_loss_step=0.0104, train_loss_epoch=0.0117]Epoch 37: Train Loss = 0.010417448356747627\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=350, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 38: Train Loss = 0.011484036222100258\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=350, train_loss_step=0.0098, train_loss_epoch=0.0115]Epoch 39: Train Loss = 0.00979689322412014\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=350, train_loss_step=0.012, train_loss_epoch=0.0098] Epoch 40: Train Loss = 0.01202663779258728\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.012]Epoch 41: Train Loss = 0.01256799791008234\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=350, train_loss_step=0.00999, train_loss_epoch=0.0126]Epoch 42: Train Loss = 0.009985472075641155\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=350, train_loss_step=0.010, train_loss_epoch=0.00999]  Epoch 43: Train Loss = 0.010047020390629768\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=350, train_loss_step=0.00938, train_loss_epoch=0.010]Epoch 44: Train Loss = 0.009383350610733032\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.00938] Epoch 45: Train Loss = 0.01261808443814516\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.0126]  Epoch 46: Train Loss = 0.01099135261029005\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=350, train_loss_step=0.0103, train_loss_epoch=0.011]Epoch 47: Train Loss = 0.010275810025632381\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=350, train_loss_step=0.0112, train_loss_epoch=0.0103]Epoch 48: Train Loss = 0.011158551089465618\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=350, train_loss_step=0.0113, train_loss_epoch=0.0112]Epoch 49: Train Loss = 0.01133813988417387\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=350, train_loss_step=0.0118, train_loss_epoch=0.0113]Epoch 50: Train Loss = 0.011785008013248444\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=350, train_loss_step=0.0114, train_loss_epoch=0.0118]Epoch 51: Train Loss = 0.011418355628848076\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 11.08it/s, v_num=350, train_loss_step=0.0131, train_loss_epoch=0.0114]Epoch 52: Train Loss = 0.013073298148810863\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=350, train_loss_step=0.00843, train_loss_epoch=0.0131]Epoch 53: Train Loss = 0.00843237154185772\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=350, train_loss_step=0.0102, train_loss_epoch=0.00843] Epoch 54: Train Loss = 0.01017423439770937\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=350, train_loss_step=0.0118, train_loss_epoch=0.0102] Epoch 55: Train Loss = 0.011798433028161526\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=350, train_loss_step=0.0147, train_loss_epoch=0.0118]Epoch 56: Train Loss = 0.014744515530765057\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0147]Epoch 57: Train Loss = 0.010506263934075832\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=350, train_loss_step=0.0097, train_loss_epoch=0.0105]Epoch 58: Train Loss = 0.009704380296170712\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.0097]Epoch 59: Train Loss = 0.012075801379978657\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=350, train_loss_step=0.0146, train_loss_epoch=0.0121]Epoch 60: Train Loss = 0.014629803597927094\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0146]Epoch 61: Train Loss = 0.010522247292101383\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=350, train_loss_step=0.0114, train_loss_epoch=0.0105]Epoch 62: Train Loss = 0.011429039761424065\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.0114]Epoch 63: Train Loss = 0.011060894466936588\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=350, train_loss_step=0.0132, train_loss_epoch=0.0111]Epoch 64: Train Loss = 0.01315427478402853\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=350, train_loss_step=0.0134, train_loss_epoch=0.0132]Epoch 65: Train Loss = 0.013437735848128796\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.0134]Epoch 66: Train Loss = 0.012573310174047947\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=350, train_loss_step=0.0139, train_loss_epoch=0.0126]Epoch 67: Train Loss = 0.013876263983547688\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=350, train_loss_step=0.00929, train_loss_epoch=0.0139]Epoch 68: Train Loss = 0.009286357089877129\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=350, train_loss_step=0.0116, train_loss_epoch=0.00929] Epoch 69: Train Loss = 0.011591264046728611\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=350, train_loss_step=0.00927, train_loss_epoch=0.0116]Epoch 70: Train Loss = 0.009273998439311981\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=350, train_loss_step=0.0108, train_loss_epoch=0.00927] Epoch 71: Train Loss = 0.010840154252946377\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=350, train_loss_step=0.015, train_loss_epoch=0.0108]  Epoch 72: Train Loss = 0.015021324157714844\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=350, train_loss_step=0.00928, train_loss_epoch=0.015]Epoch 73: Train Loss = 0.009282651357352734\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=350, train_loss_step=0.00975, train_loss_epoch=0.00928]Epoch 74: Train Loss = 0.009754424914717674\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.00975]  Epoch 75: Train Loss = 0.010991678573191166\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=350, train_loss_step=0.013, train_loss_epoch=0.011]  Epoch 76: Train Loss = 0.013034296222031116\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.013]Epoch 77: Train Loss = 0.010619862005114555\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=350, train_loss_step=0.0103, train_loss_epoch=0.0106]Epoch 78: Train Loss = 0.010272045619785786\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=350, train_loss_step=0.00912, train_loss_epoch=0.0103]Epoch 79: Train Loss = 0.009119986556470394\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=350, train_loss_step=0.0135, train_loss_epoch=0.00912] Epoch 80: Train Loss = 0.013480594381690025\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=350, train_loss_step=0.00877, train_loss_epoch=0.0135]Epoch 81: Train Loss = 0.00876828283071518\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=350, train_loss_step=0.00958, train_loss_epoch=0.00877]Epoch 82: Train Loss = 0.009575881063938141\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=350, train_loss_step=0.0109, train_loss_epoch=0.00958] Epoch 83: Train Loss = 0.010895037092268467\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=350, train_loss_step=0.0122, train_loss_epoch=0.0109] Epoch 84: Train Loss = 0.012187330052256584\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=350, train_loss_step=0.0113, train_loss_epoch=0.0122]Epoch 85: Train Loss = 0.011281929910182953\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=350, train_loss_step=0.00819, train_loss_epoch=0.0113]Epoch 86: Train Loss = 0.008193916641175747\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=350, train_loss_step=0.0113, train_loss_epoch=0.00819] Epoch 87: Train Loss = 0.011267847381532192\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.0113] Epoch 88: Train Loss = 0.012610850855708122\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=350, train_loss_step=0.00866, train_loss_epoch=0.0126]Epoch 89: Train Loss = 0.008661163039505482\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=350, train_loss_step=0.0174, train_loss_epoch=0.00866] Epoch 90: Train Loss = 0.017365602776408195\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=350, train_loss_step=0.0114, train_loss_epoch=0.0174] Epoch 91: Train Loss = 0.011396640911698341\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=350, train_loss_step=0.0102, train_loss_epoch=0.0114]Epoch 92: Train Loss = 0.010170269757509232\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=350, train_loss_step=0.00962, train_loss_epoch=0.0102]Epoch 93: Train Loss = 0.00962102971971035\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.00962]  Epoch 94: Train Loss = 0.011048716492950916\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=350, train_loss_step=0.013, train_loss_epoch=0.011]  Epoch 95: Train Loss = 0.013026664964854717\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=350, train_loss_step=0.0128, train_loss_epoch=0.013]Epoch 96: Train Loss = 0.012803501449525356\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=350, train_loss_step=0.00917, train_loss_epoch=0.0128]Epoch 97: Train Loss = 0.009172982536256313\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.00917] Epoch 98: Train Loss = 0.010628198273479939\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.0106] Epoch 99: Train Loss = 0.011100130155682564\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=350, train_loss_step=0.00883, train_loss_epoch=0.0111]Epoch 100: Train Loss = 0.008830402977764606\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.00883] Epoch 101: Train Loss = 0.011060385033488274\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=350, train_loss_step=0.00979, train_loss_epoch=0.0111]Epoch 102: Train Loss = 0.00979497842490673\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.00979] Epoch 103: Train Loss = 0.01259615272283554\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=350, train_loss_step=0.0159, train_loss_epoch=0.0126] Epoch 104: Train Loss = 0.01589282788336277\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=350, train_loss_step=0.00961, train_loss_epoch=0.0159]Epoch 105: Train Loss = 0.009605923667550087\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=350, train_loss_step=0.0133, train_loss_epoch=0.00961] Epoch 106: Train Loss = 0.01325845718383789\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=350, train_loss_step=0.00968, train_loss_epoch=0.0133]Epoch 107: Train Loss = 0.009680410847067833\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.00968] Epoch 108: Train Loss = 0.010585593059659004\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0106] Epoch 109: Train Loss = 0.010488377884030342\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=350, train_loss_step=0.0108, train_loss_epoch=0.0105]Epoch 110: Train Loss = 0.010750931687653065\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=350, train_loss_step=0.0159, train_loss_epoch=0.0108]Epoch 111: Train Loss = 0.015924276784062386\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=350, train_loss_step=0.0132, train_loss_epoch=0.0159]Epoch 112: Train Loss = 0.013178388588130474\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=350, train_loss_step=0.00828, train_loss_epoch=0.0132]Epoch 113: Train Loss = 0.00828167051076889\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.00828]  Epoch 114: Train Loss = 0.010955547913908958\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=350, train_loss_step=0.0104, train_loss_epoch=0.011] Epoch 115: Train Loss = 0.010406272485852242\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=350, train_loss_step=0.0139, train_loss_epoch=0.0104]Epoch 116: Train Loss = 0.013912484049797058\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=350, train_loss_step=0.0143, train_loss_epoch=0.0139]Epoch 117: Train Loss = 0.014293225482106209\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=350, train_loss_step=0.0142, train_loss_epoch=0.0143]Epoch 118: Train Loss = 0.014196062460541725\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=350, train_loss_step=0.0137, train_loss_epoch=0.0142]Epoch 119: Train Loss = 0.01372013334184885\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=350, train_loss_step=0.0123, train_loss_epoch=0.0137]Epoch 120: Train Loss = 0.012309818528592587\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.0123]Epoch 121: Train Loss = 0.011072337627410889\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=350, train_loss_step=0.010, train_loss_epoch=0.0111] Epoch 122: Train Loss = 0.01003529317677021\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=350, train_loss_step=0.00789, train_loss_epoch=0.010]Epoch 123: Train Loss = 0.007887137122452259\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=350, train_loss_step=0.0129, train_loss_epoch=0.00789] Epoch 124: Train Loss = 0.012886260636150837\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=350, train_loss_step=0.0146, train_loss_epoch=0.0129] Epoch 125: Train Loss = 0.014625434763729572\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.0146]Epoch 126: Train Loss = 0.011106559075415134\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=350, train_loss_step=0.015, train_loss_epoch=0.0111] Epoch 127: Train Loss = 0.014965815469622612\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=350, train_loss_step=0.0142, train_loss_epoch=0.015]Epoch 128: Train Loss = 0.014186258427798748\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=350, train_loss_step=0.00947, train_loss_epoch=0.0142]Epoch 129: Train Loss = 0.009474285878241062\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=350, train_loss_step=0.00861, train_loss_epoch=0.00947]Epoch 130: Train Loss = 0.008610636927187443\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=350, train_loss_step=0.00804, train_loss_epoch=0.00861]Epoch 131: Train Loss = 0.008038138039410114\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=350, train_loss_step=0.016, train_loss_epoch=0.00804]  Epoch 132: Train Loss = 0.01602136716246605\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=350, train_loss_step=0.0138, train_loss_epoch=0.016] Epoch 133: Train Loss = 0.013782289810478687\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=350, train_loss_step=0.00825, train_loss_epoch=0.0138]Epoch 134: Train Loss = 0.008249616250395775\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=350, train_loss_step=0.00885, train_loss_epoch=0.00825]Epoch 135: Train Loss = 0.008849228732287884\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=350, train_loss_step=0.00979, train_loss_epoch=0.00885]Epoch 136: Train Loss = 0.009787669405341148\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=350, train_loss_step=0.012, train_loss_epoch=0.00979]  Epoch 137: Train Loss = 0.011964314617216587\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=350, train_loss_step=0.00841, train_loss_epoch=0.012]Epoch 138: Train Loss = 0.008414938114583492\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=350, train_loss_step=0.0096, train_loss_epoch=0.00841] Epoch 139: Train Loss = 0.009596011601388454\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.0096] Epoch 140: Train Loss = 0.010551954619586468\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=350, train_loss_step=0.0167, train_loss_epoch=0.0106]Epoch 141: Train Loss = 0.016727427020668983\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=350, train_loss_step=0.0136, train_loss_epoch=0.0167]Epoch 142: Train Loss = 0.013576927594840527\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=350, train_loss_step=0.00879, train_loss_epoch=0.0136]Epoch 143: Train Loss = 0.008787079714238644\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s, v_num=350, train_loss_step=0.0109, train_loss_epoch=0.00879] Epoch 144: Train Loss = 0.01088558230549097\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=350, train_loss_step=0.00978, train_loss_epoch=0.0109]Epoch 145: Train Loss = 0.009783374145627022\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=350, train_loss_step=0.00886, train_loss_epoch=0.00978]Epoch 146: Train Loss = 0.008858861401677132\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.00886] Epoch 147: Train Loss = 0.011087334714829922\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0111] Epoch 148: Train Loss = 0.01045242790132761\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=350, train_loss_step=0.0104, train_loss_epoch=0.0105]Epoch 149: Train Loss = 0.010428470559418201\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=350, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 150: Train Loss = 0.011512729339301586\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.0115]Epoch 151: Train Loss = 0.012075130827724934\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=350, train_loss_step=0.0101, train_loss_epoch=0.0121]Epoch 152: Train Loss = 0.010060446336865425\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=350, train_loss_step=0.00842, train_loss_epoch=0.0101]Epoch 153: Train Loss = 0.00842293817549944\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.00842] Epoch 154: Train Loss = 0.011090753600001335\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=350, train_loss_step=0.0122, train_loss_epoch=0.0111] Epoch 155: Train Loss = 0.01223174948245287\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=350, train_loss_step=0.009, train_loss_epoch=0.0122] Epoch 156: Train Loss = 0.00900300033390522\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.009]Epoch 157: Train Loss = 0.012573802843689919\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=350, train_loss_step=0.0084, train_loss_epoch=0.0126]Epoch 158: Train Loss = 0.008400177583098412\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=350, train_loss_step=0.00958, train_loss_epoch=0.0084]Epoch 159: Train Loss = 0.009578950703144073\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 12.33it/s, v_num=350, train_loss_step=0.0132, train_loss_epoch=0.00958] Epoch 160: Train Loss = 0.013210820965468884\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0132] Epoch 161: Train Loss = 0.010498705320060253\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=350, train_loss_step=0.0088, train_loss_epoch=0.0105]Epoch 162: Train Loss = 0.008802263997495174\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=350, train_loss_step=0.0098, train_loss_epoch=0.0088]Epoch 163: Train Loss = 0.009800991974771023\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=350, train_loss_step=0.00851, train_loss_epoch=0.0098]Epoch 164: Train Loss = 0.008512289263308048\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=350, train_loss_step=0.00768, train_loss_epoch=0.00851]Epoch 165: Train Loss = 0.007681138813495636\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.00768] Epoch 166: Train Loss = 0.010518277995288372\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.0105] Epoch 167: Train Loss = 0.010560535825788975\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s, v_num=350, train_loss_step=0.0098, train_loss_epoch=0.0106]Epoch 168: Train Loss = 0.009800536558032036\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.0098]Epoch 169: Train Loss = 0.010667943395674229\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=350, train_loss_step=0.0136, train_loss_epoch=0.0107]Epoch 170: Train Loss = 0.013585384003818035\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=350, train_loss_step=0.0118, train_loss_epoch=0.0136]Epoch 171: Train Loss = 0.011833387427031994\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=350, train_loss_step=0.00815, train_loss_epoch=0.0118]Epoch 172: Train Loss = 0.008148973807692528\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=350, train_loss_step=0.0108, train_loss_epoch=0.00815] Epoch 173: Train Loss = 0.010756644420325756\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.0108] Epoch 174: Train Loss = 0.010666323825716972\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=350, train_loss_step=0.0165, train_loss_epoch=0.0107]Epoch 175: Train Loss = 0.016524197533726692\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=350, train_loss_step=0.00908, train_loss_epoch=0.0165]Epoch 176: Train Loss = 0.009080549702048302\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=350, train_loss_step=0.00899, train_loss_epoch=0.00908]Epoch 177: Train Loss = 0.008986353874206543\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=350, train_loss_step=0.0113, train_loss_epoch=0.00899] Epoch 178: Train Loss = 0.011299126781523228\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=350, train_loss_step=0.0122, train_loss_epoch=0.0113] Epoch 179: Train Loss = 0.012186015024781227\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=350, train_loss_step=0.00858, train_loss_epoch=0.0122]Epoch 180: Train Loss = 0.008579054847359657\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=350, train_loss_step=0.0116, train_loss_epoch=0.00858] Epoch 181: Train Loss = 0.011609264649450779\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0116] Epoch 182: Train Loss = 0.010503963567316532\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=350, train_loss_step=0.0104, train_loss_epoch=0.0105]Epoch 183: Train Loss = 0.010447422042489052\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=350, train_loss_step=0.00851, train_loss_epoch=0.0104]Epoch 184: Train Loss = 0.008511954918503761\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=350, train_loss_step=0.0134, train_loss_epoch=0.00851] Epoch 185: Train Loss = 0.013428879901766777\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=350, train_loss_step=0.00972, train_loss_epoch=0.0134]Epoch 186: Train Loss = 0.009723511524498463\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=350, train_loss_step=0.00983, train_loss_epoch=0.00972]Epoch 187: Train Loss = 0.009826292283833027\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=350, train_loss_step=0.012, train_loss_epoch=0.00983]  Epoch 188: Train Loss = 0.012031764723360538\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=350, train_loss_step=0.014, train_loss_epoch=0.012]  Epoch 189: Train Loss = 0.013962281867861748\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=350, train_loss_step=0.0123, train_loss_epoch=0.014]Epoch 190: Train Loss = 0.012324681505560875\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=350, train_loss_step=0.0116, train_loss_epoch=0.0123]Epoch 191: Train Loss = 0.011647126637399197\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=350, train_loss_step=0.0135, train_loss_epoch=0.0116]Epoch 192: Train Loss = 0.013490130193531513\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=350, train_loss_step=0.0135, train_loss_epoch=0.0135]Epoch 193: Train Loss = 0.013456875458359718\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=350, train_loss_step=0.00825, train_loss_epoch=0.0135]Epoch 194: Train Loss = 0.008254637010395527\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=350, train_loss_step=0.00988, train_loss_epoch=0.00825]Epoch 195: Train Loss = 0.009883099235594273\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=350, train_loss_step=0.00977, train_loss_epoch=0.00988]Epoch 196: Train Loss = 0.009771858341991901\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=350, train_loss_step=0.0115, train_loss_epoch=0.00977] Epoch 197: Train Loss = 0.011529658921062946\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=350, train_loss_step=0.0113, train_loss_epoch=0.0115] Epoch 198: Train Loss = 0.011284480802714825\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=350, train_loss_step=0.00986, train_loss_epoch=0.0113]Epoch 199: Train Loss = 0.00985950417816639\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=350, train_loss_step=0.00854, train_loss_epoch=0.00986]Epoch 200: Train Loss = 0.008535684086382389\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=350, train_loss_step=0.010, train_loss_epoch=0.00854]  Epoch 201: Train Loss = 0.010039767250418663\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.010] Epoch 202: Train Loss = 0.012064307928085327\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=350, train_loss_step=0.00924, train_loss_epoch=0.0121]Epoch 203: Train Loss = 0.009235440753400326\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=350, train_loss_step=0.010, train_loss_epoch=0.00924]  Epoch 204: Train Loss = 0.010011055506765842\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=350, train_loss_step=0.0153, train_loss_epoch=0.010] Epoch 205: Train Loss = 0.015330256894230843\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 10.71it/s, v_num=350, train_loss_step=0.0128, train_loss_epoch=0.0153]Epoch 206: Train Loss = 0.012815053574740887\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=350, train_loss_step=0.0134, train_loss_epoch=0.0128]Epoch 207: Train Loss = 0.013360117562115192\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=350, train_loss_step=0.00872, train_loss_epoch=0.0134]Epoch 208: Train Loss = 0.00872411672025919\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=350, train_loss_step=0.00947, train_loss_epoch=0.00872]Epoch 209: Train Loss = 0.009467286989092827\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=350, train_loss_step=0.0131, train_loss_epoch=0.00947] Epoch 210: Train Loss = 0.013067497871816158\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=350, train_loss_step=0.0135, train_loss_epoch=0.0131] Epoch 211: Train Loss = 0.01346193440258503\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=350, train_loss_step=0.0117, train_loss_epoch=0.0135]Epoch 212: Train Loss = 0.011691602878272533\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.0117]Epoch 213: Train Loss = 0.010662158951163292\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=350, train_loss_step=0.00826, train_loss_epoch=0.0107]Epoch 214: Train Loss = 0.00826228130608797\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=350, train_loss_step=0.00847, train_loss_epoch=0.00826]Epoch 215: Train Loss = 0.008469185791909695\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=350, train_loss_step=0.00863, train_loss_epoch=0.00847]Epoch 216: Train Loss = 0.008632499724626541\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=350, train_loss_step=0.0117, train_loss_epoch=0.00863] Epoch 217: Train Loss = 0.011724451556801796\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=350, train_loss_step=0.0123, train_loss_epoch=0.0117] Epoch 218: Train Loss = 0.012252896092832088\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.0123]Epoch 219: Train Loss = 0.01260362472385168\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=350, train_loss_step=0.0102, train_loss_epoch=0.0126]Epoch 220: Train Loss = 0.010150459595024586\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=350, train_loss_step=0.0097, train_loss_epoch=0.0102]Epoch 221: Train Loss = 0.009703083895146847\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=350, train_loss_step=0.00804, train_loss_epoch=0.0097]Epoch 222: Train Loss = 0.008036008104681969\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=350, train_loss_step=0.0108, train_loss_epoch=0.00804] Epoch 223: Train Loss = 0.010795640759170055\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=350, train_loss_step=0.0122, train_loss_epoch=0.0108] Epoch 224: Train Loss = 0.012153148651123047\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=350, train_loss_step=0.0118, train_loss_epoch=0.0122]Epoch 225: Train Loss = 0.011796021834015846\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=350, train_loss_step=0.0088, train_loss_epoch=0.0118]Epoch 226: Train Loss = 0.008802852593362331\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0088]Epoch 227: Train Loss = 0.010531431064009666\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=350, train_loss_step=0.0103, train_loss_epoch=0.0105]Epoch 228: Train Loss = 0.010349040850996971\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.0103]Epoch 229: Train Loss = 0.012100226245820522\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=350, train_loss_step=0.00865, train_loss_epoch=0.0121]Epoch 230: Train Loss = 0.0086538540199399\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=350, train_loss_step=0.00982, train_loss_epoch=0.00865]Epoch 231: Train Loss = 0.009822048246860504\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=350, train_loss_step=0.0115, train_loss_epoch=0.00982] Epoch 232: Train Loss = 0.011486811563372612\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=350, train_loss_step=0.0125, train_loss_epoch=0.0115] Epoch 233: Train Loss = 0.012490009889006615\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=350, train_loss_step=0.00996, train_loss_epoch=0.0125]Epoch 234: Train Loss = 0.009963934309780598\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.00996] Epoch 235: Train Loss = 0.010744789615273476\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=350, train_loss_step=0.0138, train_loss_epoch=0.0107] Epoch 236: Train Loss = 0.01377935241907835\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=350, train_loss_step=0.00972, train_loss_epoch=0.0138]Epoch 237: Train Loss = 0.00971651915460825\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.00972] Epoch 238: Train Loss = 0.0106575358659029\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s, v_num=350, train_loss_step=0.00849, train_loss_epoch=0.0107]Epoch 239: Train Loss = 0.008491475135087967\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=350, train_loss_step=0.00986, train_loss_epoch=0.00849]Epoch 240: Train Loss = 0.009864941239356995\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=350, train_loss_step=0.0091, train_loss_epoch=0.00986] Epoch 241: Train Loss = 0.009104123339056969\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=350, train_loss_step=0.0115, train_loss_epoch=0.0091] Epoch 242: Train Loss = 0.011496387422084808\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=350, train_loss_step=0.0132, train_loss_epoch=0.0115]Epoch 243: Train Loss = 0.013186666183173656\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s, v_num=350, train_loss_step=0.00957, train_loss_epoch=0.0132]Epoch 244: Train Loss = 0.009568469598889351\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=350, train_loss_step=0.0101, train_loss_epoch=0.00957] Epoch 245: Train Loss = 0.010117226280272007\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=350, train_loss_step=0.0101, train_loss_epoch=0.0101] Epoch 246: Train Loss = 0.010065002366900444\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=350, train_loss_step=0.0131, train_loss_epoch=0.0101]Epoch 247: Train Loss = 0.013134753331542015\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=350, train_loss_step=0.0123, train_loss_epoch=0.0131]Epoch 248: Train Loss = 0.012295042164623737\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=350, train_loss_step=0.0132, train_loss_epoch=0.0123]Epoch 249: Train Loss = 0.013206301257014275\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s, v_num=350, train_loss_step=0.0152, train_loss_epoch=0.0132]Epoch 250: Train Loss = 0.015186632983386517\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=350, train_loss_step=0.0133, train_loss_epoch=0.0152]Epoch 251: Train Loss = 0.013250126503407955\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=350, train_loss_step=0.0159, train_loss_epoch=0.0133]Epoch 252: Train Loss = 0.01592753455042839\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=350, train_loss_step=0.0116, train_loss_epoch=0.0159]Epoch 253: Train Loss = 0.011574852280318737\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.0116]Epoch 254: Train Loss = 0.012062051333487034\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=350, train_loss_step=0.0138, train_loss_epoch=0.0121]Epoch 255: Train Loss = 0.013803929090499878\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=350, train_loss_step=0.0114, train_loss_epoch=0.0138]Epoch 256: Train Loss = 0.011404375545680523\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=350, train_loss_step=0.0124, train_loss_epoch=0.0114]Epoch 257: Train Loss = 0.012364544905722141\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=350, train_loss_step=0.012, train_loss_epoch=0.0124] Epoch 258: Train Loss = 0.011964776553213596\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.012] Epoch 259: Train Loss = 0.011022263206541538\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=350, train_loss_step=0.0103, train_loss_epoch=0.011]Epoch 260: Train Loss = 0.010279173031449318\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=350, train_loss_step=0.0143, train_loss_epoch=0.0103]Epoch 261: Train Loss = 0.014288862235844135\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.0143]Epoch 262: Train Loss = 0.01214692648500204\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=350, train_loss_step=0.0115, train_loss_epoch=0.0121]Epoch 263: Train Loss = 0.011467965319752693\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0115]Epoch 264: Train Loss = 0.010468202643096447\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=350, train_loss_step=0.0142, train_loss_epoch=0.0105]Epoch 265: Train Loss = 0.014223656617105007\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.0142]Epoch 266: Train Loss = 0.012065981514751911\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=350, train_loss_step=0.0117, train_loss_epoch=0.0121]Epoch 267: Train Loss = 0.011688043363392353\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=350, train_loss_step=0.0125, train_loss_epoch=0.0117]Epoch 268: Train Loss = 0.012463025748729706\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=350, train_loss_step=0.0101, train_loss_epoch=0.0125]Epoch 269: Train Loss = 0.010115234181284904\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=350, train_loss_step=0.0144, train_loss_epoch=0.0101]Epoch 270: Train Loss = 0.014371822588145733\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=350, train_loss_step=0.013, train_loss_epoch=0.0144] Epoch 271: Train Loss = 0.013043400831520557\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=350, train_loss_step=0.0117, train_loss_epoch=0.013]Epoch 272: Train Loss = 0.011652247980237007\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=350, train_loss_step=0.0139, train_loss_epoch=0.0117]Epoch 273: Train Loss = 0.01394562516361475\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=350, train_loss_step=0.017, train_loss_epoch=0.0139] Epoch 274: Train Loss = 0.017025170847773552\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=350, train_loss_step=0.0116, train_loss_epoch=0.017]Epoch 275: Train Loss = 0.011601204052567482\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=350, train_loss_step=0.00827, train_loss_epoch=0.0116]Epoch 276: Train Loss = 0.008267694152891636\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=350, train_loss_step=0.014, train_loss_epoch=0.00827]  Epoch 277: Train Loss = 0.013992035761475563\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.014] Epoch 278: Train Loss = 0.010544983670115471\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=350, train_loss_step=0.0083, train_loss_epoch=0.0105]Epoch 279: Train Loss = 0.00829821266233921\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=350, train_loss_step=0.00935, train_loss_epoch=0.0083]Epoch 280: Train Loss = 0.00934953335672617\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=350, train_loss_step=0.00869, train_loss_epoch=0.00935]Epoch 281: Train Loss = 0.008688965812325478\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=350, train_loss_step=0.0117, train_loss_epoch=0.00869] Epoch 282: Train Loss = 0.011678427457809448\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=350, train_loss_step=0.0112, train_loss_epoch=0.0117] Epoch 283: Train Loss = 0.01119909156113863\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=350, train_loss_step=0.00889, train_loss_epoch=0.0112]Epoch 284: Train Loss = 0.008887410163879395\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=350, train_loss_step=0.0096, train_loss_epoch=0.00889] Epoch 285: Train Loss = 0.00959616620093584\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=350, train_loss_step=0.0101, train_loss_epoch=0.0096] Epoch 286: Train Loss = 0.010128254070878029\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.0101]Epoch 287: Train Loss = 0.010670073330402374\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=350, train_loss_step=0.0108, train_loss_epoch=0.0107]Epoch 288: Train Loss = 0.010848511941730976\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.0108]Epoch 289: Train Loss = 0.010646163485944271\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=350, train_loss_step=0.00748, train_loss_epoch=0.0106]Epoch 290: Train Loss = 0.00747740687802434\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.00748] Epoch 291: Train Loss = 0.011133179068565369\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=350, train_loss_step=0.00851, train_loss_epoch=0.0111]Epoch 292: Train Loss = 0.00850686151534319\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=350, train_loss_step=0.00868, train_loss_epoch=0.00851]Epoch 293: Train Loss = 0.008676772937178612\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=350, train_loss_step=0.00862, train_loss_epoch=0.00868]Epoch 294: Train Loss = 0.00862235389649868\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=350, train_loss_step=0.0108, train_loss_epoch=0.00862] Epoch 295: Train Loss = 0.010799980722367764\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=350, train_loss_step=0.00966, train_loss_epoch=0.0108]Epoch 296: Train Loss = 0.009660293348133564\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=350, train_loss_step=0.00965, train_loss_epoch=0.00966]Epoch 297: Train Loss = 0.009646529331803322\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=350, train_loss_step=0.00959, train_loss_epoch=0.00965]Epoch 298: Train Loss = 0.009589655324816704\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.00959]  Epoch 299: Train Loss = 0.011015333235263824\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=350, train_loss_step=0.00795, train_loss_epoch=0.011]Epoch 300: Train Loss = 0.007954499684274197\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=350, train_loss_step=0.00909, train_loss_epoch=0.00795]Epoch 301: Train Loss = 0.009092756547033787\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=350, train_loss_step=0.00988, train_loss_epoch=0.00909]Epoch 302: Train Loss = 0.009876254014670849\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=350, train_loss_step=0.0128, train_loss_epoch=0.00988] Epoch 303: Train Loss = 0.01284017413854599\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=350, train_loss_step=0.00909, train_loss_epoch=0.0128]Epoch 304: Train Loss = 0.009093733504414558\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.00909] Epoch 305: Train Loss = 0.012132793664932251\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=350, train_loss_step=0.00733, train_loss_epoch=0.0121]Epoch 306: Train Loss = 0.007326506543904543\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=350, train_loss_step=0.0133, train_loss_epoch=0.00733] Epoch 307: Train Loss = 0.013313507661223412\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=350, train_loss_step=0.00929, train_loss_epoch=0.0133]Epoch 308: Train Loss = 0.00928934570401907\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=350, train_loss_step=0.0129, train_loss_epoch=0.00929] Epoch 309: Train Loss = 0.012946022674441338\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s, v_num=350, train_loss_step=0.00905, train_loss_epoch=0.0129]Epoch 310: Train Loss = 0.009049655869603157\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=350, train_loss_step=0.00984, train_loss_epoch=0.00905]Epoch 311: Train Loss = 0.009841318242251873\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=350, train_loss_step=0.00919, train_loss_epoch=0.00984]Epoch 312: Train Loss = 0.009187954477965832\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.00919]  Epoch 313: Train Loss = 0.010974189266562462\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=350, train_loss_step=0.0104, train_loss_epoch=0.011] Epoch 314: Train Loss = 0.010367871262133121\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=350, train_loss_step=0.0144, train_loss_epoch=0.0104]Epoch 315: Train Loss = 0.014356051571667194\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=350, train_loss_step=0.00708, train_loss_epoch=0.0144]Epoch 316: Train Loss = 0.007076857145875692\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=350, train_loss_step=0.00952, train_loss_epoch=0.00708]Epoch 317: Train Loss = 0.009521991945803165\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=350, train_loss_step=0.0103, train_loss_epoch=0.00952] Epoch 318: Train Loss = 0.010286545380949974\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=350, train_loss_step=0.0129, train_loss_epoch=0.0103] Epoch 319: Train Loss = 0.012928643263876438\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=350, train_loss_step=0.0112, train_loss_epoch=0.0129]Epoch 320: Train Loss = 0.01119519304484129\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=350, train_loss_step=0.0109, train_loss_epoch=0.0112]Epoch 321: Train Loss = 0.010936672799289227\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=350, train_loss_step=0.00956, train_loss_epoch=0.0109]Epoch 322: Train Loss = 0.009560927748680115\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=350, train_loss_step=0.0102, train_loss_epoch=0.00956] Epoch 323: Train Loss = 0.010247684083878994\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=350, train_loss_step=0.0109, train_loss_epoch=0.0102] Epoch 324: Train Loss = 0.010947393253445625\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=350, train_loss_step=0.00937, train_loss_epoch=0.0109]Epoch 325: Train Loss = 0.00937272422015667\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.00937] Epoch 326: Train Loss = 0.010586308315396309\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=350, train_loss_step=0.0125, train_loss_epoch=0.0106] Epoch 327: Train Loss = 0.012457659468054771\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=350, train_loss_step=0.0066, train_loss_epoch=0.0125]Epoch 328: Train Loss = 0.006598293781280518\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s, v_num=350, train_loss_step=0.00955, train_loss_epoch=0.0066]Epoch 329: Train Loss = 0.009550750255584717\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=350, train_loss_step=0.00798, train_loss_epoch=0.00955]Epoch 330: Train Loss = 0.00797981210052967\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=350, train_loss_step=0.00954, train_loss_epoch=0.00798]Epoch 331: Train Loss = 0.009537898935377598\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=350, train_loss_step=0.00854, train_loss_epoch=0.00954]Epoch 332: Train Loss = 0.00853566825389862\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=350, train_loss_step=0.00915, train_loss_epoch=0.00854]Epoch 333: Train Loss = 0.009149601683020592\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=350, train_loss_step=0.0102, train_loss_epoch=0.00915] Epoch 334: Train Loss = 0.010189658962190151\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=350, train_loss_step=0.0112, train_loss_epoch=0.0102] Epoch 335: Train Loss = 0.011226995848119259\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=350, train_loss_step=0.0117, train_loss_epoch=0.0112]Epoch 336: Train Loss = 0.011700903996825218\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=350, train_loss_step=0.0122, train_loss_epoch=0.0117]Epoch 337: Train Loss = 0.012229740619659424\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.0122]Epoch 338: Train Loss = 0.010601041838526726\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=350, train_loss_step=0.00944, train_loss_epoch=0.0106]Epoch 339: Train Loss = 0.00944492407143116\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=350, train_loss_step=0.0109, train_loss_epoch=0.00944] Epoch 340: Train Loss = 0.010903679765760899\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=350, train_loss_step=0.0091, train_loss_epoch=0.0109] Epoch 341: Train Loss = 0.009102870710194111\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=350, train_loss_step=0.00901, train_loss_epoch=0.0091]Epoch 342: Train Loss = 0.009007520973682404\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=350, train_loss_step=0.00914, train_loss_epoch=0.00901]Epoch 343: Train Loss = 0.00914364866912365\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=350, train_loss_step=0.0116, train_loss_epoch=0.00914] Epoch 344: Train Loss = 0.011556290090084076\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=350, train_loss_step=0.00973, train_loss_epoch=0.0116]Epoch 345: Train Loss = 0.009728929027915001\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=350, train_loss_step=0.00697, train_loss_epoch=0.00973]Epoch 346: Train Loss = 0.006969365756958723\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 10.18it/s, v_num=350, train_loss_step=0.015, train_loss_epoch=0.00697]  Epoch 347: Train Loss = 0.015020185150206089\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.015] Epoch 348: Train Loss = 0.010563545860350132\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=350, train_loss_step=0.00815, train_loss_epoch=0.0106]Epoch 349: Train Loss = 0.008145824074745178\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=350, train_loss_step=0.00947, train_loss_epoch=0.00815]Epoch 350: Train Loss = 0.009472248144447803\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=350, train_loss_step=0.00945, train_loss_epoch=0.00947]Epoch 351: Train Loss = 0.00944532174617052\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=350, train_loss_step=0.00956, train_loss_epoch=0.00945]Epoch 352: Train Loss = 0.00956292450428009\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=350, train_loss_step=0.0108, train_loss_epoch=0.00956] Epoch 353: Train Loss = 0.01080142892897129\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=350, train_loss_step=0.0101, train_loss_epoch=0.0108] Epoch 354: Train Loss = 0.010055235587060452\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=350, train_loss_step=0.0102, train_loss_epoch=0.0101]Epoch 355: Train Loss = 0.010170349851250648\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.0102]Epoch 356: Train Loss = 0.012138215824961662\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=350, train_loss_step=0.00888, train_loss_epoch=0.0121]Epoch 357: Train Loss = 0.008877747692167759\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=350, train_loss_step=0.0119, train_loss_epoch=0.00888] Epoch 358: Train Loss = 0.011875888332724571\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=350, train_loss_step=0.0125, train_loss_epoch=0.0119] Epoch 359: Train Loss = 0.012537333182990551\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=350, train_loss_step=0.00832, train_loss_epoch=0.0125]Epoch 360: Train Loss = 0.008321604691445827\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.00832] Epoch 361: Train Loss = 0.01062061544507742\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0106] Epoch 362: Train Loss = 0.010473140515387058\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=350, train_loss_step=0.00796, train_loss_epoch=0.0105]Epoch 363: Train Loss = 0.007964140735566616\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s, v_num=350, train_loss_step=0.0106, train_loss_epoch=0.00796] Epoch 364: Train Loss = 0.010613543912768364\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=350, train_loss_step=0.0089, train_loss_epoch=0.0106] Epoch 365: Train Loss = 0.008901654742658138\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.0089]Epoch 366: Train Loss = 0.010735544376075268\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=350, train_loss_step=0.0127, train_loss_epoch=0.0107]Epoch 367: Train Loss = 0.012683751992881298\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=350, train_loss_step=0.0144, train_loss_epoch=0.0127]Epoch 368: Train Loss = 0.014352417550981045\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=350, train_loss_step=0.00948, train_loss_epoch=0.0144]Epoch 369: Train Loss = 0.009481397457420826\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=350, train_loss_step=0.00997, train_loss_epoch=0.00948]Epoch 370: Train Loss = 0.0099661098793149\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=350, train_loss_step=0.00987, train_loss_epoch=0.00997]Epoch 371: Train Loss = 0.009869856759905815\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=350, train_loss_step=0.00847, train_loss_epoch=0.00987]Epoch 372: Train Loss = 0.008469545282423496\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=350, train_loss_step=0.00753, train_loss_epoch=0.00847]Epoch 373: Train Loss = 0.007529359310865402\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=350, train_loss_step=0.00763, train_loss_epoch=0.00753]Epoch 374: Train Loss = 0.007630011532455683\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=350, train_loss_step=0.00862, train_loss_epoch=0.00763]Epoch 375: Train Loss = 0.008615578524768353\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.00862] Epoch 376: Train Loss = 0.010655899532139301\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=350, train_loss_step=0.0104, train_loss_epoch=0.0107] Epoch 377: Train Loss = 0.010374902747571468\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=350, train_loss_step=0.0124, train_loss_epoch=0.0104]Epoch 378: Train Loss = 0.012413513846695423\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=350, train_loss_step=0.0104, train_loss_epoch=0.0124]Epoch 379: Train Loss = 0.010362955741584301\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=350, train_loss_step=0.0103, train_loss_epoch=0.0104]Epoch 380: Train Loss = 0.010306411422789097\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=350, train_loss_step=0.0117, train_loss_epoch=0.0103]Epoch 381: Train Loss = 0.011681773699820042\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=350, train_loss_step=0.0109, train_loss_epoch=0.0117]Epoch 382: Train Loss = 0.010893288068473339\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.0109]Epoch 383: Train Loss = 0.012112175114452839\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.0121]Epoch 384: Train Loss = 0.011103063821792603\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=350, train_loss_step=0.00968, train_loss_epoch=0.0111]Epoch 385: Train Loss = 0.009679576382040977\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=350, train_loss_step=0.0117, train_loss_epoch=0.00968] Epoch 386: Train Loss = 0.011695703491568565\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s, v_num=350, train_loss_step=0.0179, train_loss_epoch=0.0117] Epoch 387: Train Loss = 0.017913175746798515\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.0179] Epoch 388: Train Loss = 0.011015036143362522\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=350, train_loss_step=0.0139, train_loss_epoch=0.011]Epoch 389: Train Loss = 0.013850961811840534\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=350, train_loss_step=0.0115, train_loss_epoch=0.0139]Epoch 390: Train Loss = 0.011478275060653687\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=350, train_loss_step=0.014, train_loss_epoch=0.0115] Epoch 391: Train Loss = 0.01401674933731556\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=350, train_loss_step=0.0146, train_loss_epoch=0.014]Epoch 392: Train Loss = 0.01464874017983675\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=350, train_loss_step=0.013, train_loss_epoch=0.0146] Epoch 393: Train Loss = 0.013016419485211372\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=350, train_loss_step=0.0109, train_loss_epoch=0.013]Epoch 394: Train Loss = 0.010901713743805885\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=350, train_loss_step=0.0122, train_loss_epoch=0.0109]Epoch 395: Train Loss = 0.012160152196884155\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=350, train_loss_step=0.0119, train_loss_epoch=0.0122]Epoch 396: Train Loss = 0.01186505425721407\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=350, train_loss_step=0.0121, train_loss_epoch=0.0119]Epoch 397: Train Loss = 0.012084408663213253\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=350, train_loss_step=0.0145, train_loss_epoch=0.0121]Epoch 398: Train Loss = 0.014499195851385593\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.0145] Epoch 399: Train Loss = 0.01104178000241518\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=350, train_loss_step=0.0108, train_loss_epoch=0.011]Epoch 400: Train Loss = 0.010828335769474506\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=350, train_loss_step=0.0123, train_loss_epoch=0.0108]Epoch 401: Train Loss = 0.0122813256457448\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=350, train_loss_step=0.0198, train_loss_epoch=0.0123]Epoch 402: Train Loss = 0.0197924692183733\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=350, train_loss_step=0.0113, train_loss_epoch=0.0198]Epoch 403: Train Loss = 0.011253253556787968\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.0113]Epoch 404: Train Loss = 0.010730830021202564\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=350, train_loss_step=0.00866, train_loss_epoch=0.0107]Epoch 405: Train Loss = 0.00866201426833868\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 10.18it/s, v_num=350, train_loss_step=0.00998, train_loss_epoch=0.00866]Epoch 406: Train Loss = 0.009981903247535229\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=350, train_loss_step=0.013, train_loss_epoch=0.00998]  Epoch 407: Train Loss = 0.01304831076413393\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=350, train_loss_step=0.00917, train_loss_epoch=0.013]Epoch 408: Train Loss = 0.009170816279947758\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=350, train_loss_step=0.00925, train_loss_epoch=0.00917]Epoch 409: Train Loss = 0.009250200353562832\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=350, train_loss_step=0.0102, train_loss_epoch=0.00925] Epoch 410: Train Loss = 0.01016341894865036\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=350, train_loss_step=0.0161, train_loss_epoch=0.0102] Epoch 411: Train Loss = 0.016095351427793503\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=350, train_loss_step=0.0134, train_loss_epoch=0.0161]Epoch 412: Train Loss = 0.01343090645968914\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=350, train_loss_step=0.0101, train_loss_epoch=0.0134]Epoch 413: Train Loss = 0.0101199671626091\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=350, train_loss_step=0.0107, train_loss_epoch=0.0101]Epoch 414: Train Loss = 0.01070664543658495\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=350, train_loss_step=0.0138, train_loss_epoch=0.0107]Epoch 415: Train Loss = 0.013789447024464607\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=350, train_loss_step=0.00962, train_loss_epoch=0.0138]Epoch 416: Train Loss = 0.009620944038033485\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s, v_num=350, train_loss_step=0.00948, train_loss_epoch=0.00962]Epoch 417: Train Loss = 0.00948400143533945\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=350, train_loss_step=0.00957, train_loss_epoch=0.00948]Epoch 418: Train Loss = 0.009565138258039951\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=350, train_loss_step=0.012, train_loss_epoch=0.00957]  Epoch 419: Train Loss = 0.012027722783386707\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=350, train_loss_step=0.00827, train_loss_epoch=0.012]Epoch 420: Train Loss = 0.008271174505352974\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=350, train_loss_step=0.00927, train_loss_epoch=0.00827]Epoch 421: Train Loss = 0.009270727634429932\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=350, train_loss_step=0.0095, train_loss_epoch=0.00927] Epoch 422: Train Loss = 0.009504479356110096\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=350, train_loss_step=0.00875, train_loss_epoch=0.0095]Epoch 423: Train Loss = 0.008754602633416653\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=350, train_loss_step=0.00698, train_loss_epoch=0.00875]Epoch 424: Train Loss = 0.006981003563851118\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=350, train_loss_step=0.00952, train_loss_epoch=0.00698]Epoch 425: Train Loss = 0.009524545632302761\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=350, train_loss_step=0.0115, train_loss_epoch=0.00952] Epoch 426: Train Loss = 0.011521673761308193\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=350, train_loss_step=0.0118, train_loss_epoch=0.0115] Epoch 427: Train Loss = 0.011830161325633526\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=350, train_loss_step=0.0095, train_loss_epoch=0.0118]Epoch 428: Train Loss = 0.009500502608716488\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=350, train_loss_step=0.00825, train_loss_epoch=0.0095]Epoch 429: Train Loss = 0.008253800682723522\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=350, train_loss_step=0.00885, train_loss_epoch=0.00825]Epoch 430: Train Loss = 0.008848058059811592\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.00885] Epoch 431: Train Loss = 0.011051066219806671\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=350, train_loss_step=0.0124, train_loss_epoch=0.0111] Epoch 432: Train Loss = 0.012374338693916798\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=350, train_loss_step=0.0122, train_loss_epoch=0.0124]Epoch 433: Train Loss = 0.012218230403959751\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0122]Epoch 434: Train Loss = 0.010475772432982922\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=350, train_loss_step=0.0115, train_loss_epoch=0.0105]Epoch 435: Train Loss = 0.011478736065328121\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=350, train_loss_step=0.0119, train_loss_epoch=0.0115]Epoch 436: Train Loss = 0.011873660609126091\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=350, train_loss_step=0.00935, train_loss_epoch=0.0119]Epoch 437: Train Loss = 0.009354195557534695\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=350, train_loss_step=0.00894, train_loss_epoch=0.00935]Epoch 438: Train Loss = 0.008939708583056927\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=350, train_loss_step=0.00942, train_loss_epoch=0.00894]Epoch 439: Train Loss = 0.009418386034667492\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=350, train_loss_step=0.0104, train_loss_epoch=0.00942] Epoch 440: Train Loss = 0.010384698398411274\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=350, train_loss_step=0.00898, train_loss_epoch=0.0104]Epoch 441: Train Loss = 0.008978062309324741\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=350, train_loss_step=0.00908, train_loss_epoch=0.00898]Epoch 442: Train Loss = 0.009082181379199028\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=350, train_loss_step=0.00845, train_loss_epoch=0.00908]Epoch 443: Train Loss = 0.008448929525911808\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=350, train_loss_step=0.00907, train_loss_epoch=0.00845]Epoch 444: Train Loss = 0.009072242304682732\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=350, train_loss_step=0.0086, train_loss_epoch=0.00907] Epoch 445: Train Loss = 0.008602234534919262\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=350, train_loss_step=0.0157, train_loss_epoch=0.0086] Epoch 446: Train Loss = 0.015706120058894157\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.0157]Epoch 447: Train Loss = 0.010466702282428741\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=350, train_loss_step=0.00863, train_loss_epoch=0.0105]Epoch 448: Train Loss = 0.008630706928670406\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=350, train_loss_step=0.010, train_loss_epoch=0.00863]  Epoch 449: Train Loss = 0.010021339170634747\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.010] Epoch 450: Train Loss = 0.01109228003770113\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=350, train_loss_step=0.00926, train_loss_epoch=0.0111]Epoch 451: Train Loss = 0.009261203929781914\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=350, train_loss_step=0.0105, train_loss_epoch=0.00926] Epoch 452: Train Loss = 0.010537185706198215\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=350, train_loss_step=0.0119, train_loss_epoch=0.0105] Epoch 453: Train Loss = 0.011902539059519768\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=350, train_loss_step=0.009, train_loss_epoch=0.0119] Epoch 454: Train Loss = 0.009002670645713806\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=350, train_loss_step=0.0116, train_loss_epoch=0.009]Epoch 455: Train Loss = 0.011568978428840637\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=350, train_loss_step=0.008, train_loss_epoch=0.0116] Epoch 456: Train Loss = 0.007995869033038616\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=350, train_loss_step=0.00676, train_loss_epoch=0.008]Epoch 457: Train Loss = 0.006764527410268784\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=350, train_loss_step=0.0125, train_loss_epoch=0.00676] Epoch 458: Train Loss = 0.012488259002566338\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=350, train_loss_step=0.0129, train_loss_epoch=0.0125] Epoch 459: Train Loss = 0.012914587743580341\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=350, train_loss_step=0.00983, train_loss_epoch=0.0129]Epoch 460: Train Loss = 0.009831412695348263\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.00983]  Epoch 461: Train Loss = 0.010991111397743225\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=350, train_loss_step=0.012, train_loss_epoch=0.011]  Epoch 462: Train Loss = 0.012018196284770966\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=350, train_loss_step=0.00981, train_loss_epoch=0.012]Epoch 463: Train Loss = 0.0098114637658\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.00981] Epoch 464: Train Loss = 0.011094910092651844\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s, v_num=350, train_loss_step=0.0134, train_loss_epoch=0.0111] Epoch 465: Train Loss = 0.013413273729383945\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=350, train_loss_step=0.00883, train_loss_epoch=0.0134]Epoch 466: Train Loss = 0.00882966723293066\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=350, train_loss_step=0.00858, train_loss_epoch=0.00883]Epoch 467: Train Loss = 0.008580999448895454\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=350, train_loss_step=0.00991, train_loss_epoch=0.00858]Epoch 468: Train Loss = 0.009914548136293888\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=350, train_loss_step=0.0114, train_loss_epoch=0.00991] Epoch 469: Train Loss = 0.011370937339961529\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=350, train_loss_step=0.0129, train_loss_epoch=0.0114] Epoch 470: Train Loss = 0.012896555475890636\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=350, train_loss_step=0.0118, train_loss_epoch=0.0129]Epoch 471: Train Loss = 0.01178551372140646\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=350, train_loss_step=0.0091, train_loss_epoch=0.0118]Epoch 472: Train Loss = 0.009099218063056469\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=350, train_loss_step=0.015, train_loss_epoch=0.0091] Epoch 473: Train Loss = 0.015000530518591404\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=350, train_loss_step=0.00928, train_loss_epoch=0.015]Epoch 474: Train Loss = 0.009281092323362827\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=350, train_loss_step=0.00873, train_loss_epoch=0.00928]Epoch 475: Train Loss = 0.008731290698051453\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=350, train_loss_step=0.0114, train_loss_epoch=0.00873] Epoch 476: Train Loss = 0.011444851756095886\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=350, train_loss_step=0.00941, train_loss_epoch=0.0114]Epoch 477: Train Loss = 0.009408197365701199\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s, v_num=350, train_loss_step=0.0112, train_loss_epoch=0.00941] Epoch 478: Train Loss = 0.011229322291910648\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=350, train_loss_step=0.0167, train_loss_epoch=0.0112] Epoch 479: Train Loss = 0.016650982201099396\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=350, train_loss_step=0.0112, train_loss_epoch=0.0167]Epoch 480: Train Loss = 0.011160734109580517\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=350, train_loss_step=0.0113, train_loss_epoch=0.0112]Epoch 481: Train Loss = 0.01132440846413374\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=350, train_loss_step=0.0114, train_loss_epoch=0.0113]Epoch 482: Train Loss = 0.011428875848650932\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=350, train_loss_step=0.00814, train_loss_epoch=0.0114]Epoch 483: Train Loss = 0.008140446618199348\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=350, train_loss_step=0.0109, train_loss_epoch=0.00814] Epoch 484: Train Loss = 0.010881387628614902\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s, v_num=350, train_loss_step=0.014, train_loss_epoch=0.0109]  Epoch 485: Train Loss = 0.014025649055838585\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=350, train_loss_step=0.0101, train_loss_epoch=0.014]Epoch 486: Train Loss = 0.01008386816829443\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=350, train_loss_step=0.0126, train_loss_epoch=0.0101]Epoch 487: Train Loss = 0.012577091343700886\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=350, train_loss_step=0.00821, train_loss_epoch=0.0126]Epoch 488: Train Loss = 0.008210335858166218\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=350, train_loss_step=0.0112, train_loss_epoch=0.00821] Epoch 489: Train Loss = 0.01124058198183775\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=350, train_loss_step=0.00982, train_loss_epoch=0.0112]Epoch 490: Train Loss = 0.009818540886044502\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=350, train_loss_step=0.00933, train_loss_epoch=0.00982]Epoch 491: Train Loss = 0.009328976273536682\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=350, train_loss_step=0.0111, train_loss_epoch=0.00933] Epoch 492: Train Loss = 0.011081342585384846\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=350, train_loss_step=0.00889, train_loss_epoch=0.0111]Epoch 493: Train Loss = 0.008885257877409458\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=350, train_loss_step=0.0119, train_loss_epoch=0.00889] Epoch 494: Train Loss = 0.011850029230117798\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=350, train_loss_step=0.00962, train_loss_epoch=0.0119]Epoch 495: Train Loss = 0.009621195495128632\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=350, train_loss_step=0.00982, train_loss_epoch=0.00962]Epoch 496: Train Loss = 0.0098176384344697\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s, v_num=350, train_loss_step=0.011, train_loss_epoch=0.00982]  Epoch 497: Train Loss = 0.010998822748661041\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=350, train_loss_step=0.0122, train_loss_epoch=0.011] Epoch 498: Train Loss = 0.01215451117604971\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=350, train_loss_step=0.00914, train_loss_epoch=0.0122]Epoch 499: Train Loss = 0.009138726629316807\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=350, train_loss_step=0.00914, train_loss_epoch=0.00914]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=350, train_loss_step=0.00914, train_loss_epoch=0.00914]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 9: from 2008-05-12 00:00:00 to 2022-09-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=354, train_loss_step=0.0236]Epoch 0: Train Loss = 0.023623337969183922\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=354, train_loss_step=0.036, train_loss_epoch=0.0236] Epoch 1: Train Loss = 0.03602468967437744\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=354, train_loss_step=0.0263, train_loss_epoch=0.036]Epoch 2: Train Loss = 0.026320546865463257\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=354, train_loss_step=0.0205, train_loss_epoch=0.0263]Epoch 3: Train Loss = 0.02050970494747162\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 11.14it/s, v_num=354, train_loss_step=0.0157, train_loss_epoch=0.0205]Epoch 4: Train Loss = 0.015708809718489647\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=354, train_loss_step=0.0162, train_loss_epoch=0.0157]Epoch 5: Train Loss = 0.016157224774360657\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=354, train_loss_step=0.0143, train_loss_epoch=0.0162]Epoch 6: Train Loss = 0.014252126216888428\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=354, train_loss_step=0.0183, train_loss_epoch=0.0143]Epoch 7: Train Loss = 0.018281294032931328\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=354, train_loss_step=0.0154, train_loss_epoch=0.0183]Epoch 8: Train Loss = 0.015388729982078075\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.0154]Epoch 9: Train Loss = 0.010851715691387653\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=354, train_loss_step=0.0145, train_loss_epoch=0.0109]Epoch 10: Train Loss = 0.014515938237309456\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=354, train_loss_step=0.013, train_loss_epoch=0.0145] Epoch 11: Train Loss = 0.013031304813921452\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=354, train_loss_step=0.0131, train_loss_epoch=0.013]Epoch 12: Train Loss = 0.013104302808642387\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=354, train_loss_step=0.0118, train_loss_epoch=0.0131]Epoch 13: Train Loss = 0.011779137887060642\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=354, train_loss_step=0.0129, train_loss_epoch=0.0118]Epoch 14: Train Loss = 0.01293384563177824\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=354, train_loss_step=0.0138, train_loss_epoch=0.0129]Epoch 15: Train Loss = 0.013805332593619823\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=354, train_loss_step=0.0163, train_loss_epoch=0.0138]Epoch 16: Train Loss = 0.01625872030854225\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=354, train_loss_step=0.0114, train_loss_epoch=0.0163]Epoch 17: Train Loss = 0.011402899399399757\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=354, train_loss_step=0.0167, train_loss_epoch=0.0114]Epoch 18: Train Loss = 0.016714273020625114\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=354, train_loss_step=0.0133, train_loss_epoch=0.0167]Epoch 19: Train Loss = 0.013255206868052483\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=354, train_loss_step=0.0167, train_loss_epoch=0.0133]Epoch 20: Train Loss = 0.01671506278216839\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 12.64it/s, v_num=354, train_loss_step=0.0116, train_loss_epoch=0.0167]Epoch 21: Train Loss = 0.01161603070795536\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=354, train_loss_step=0.0129, train_loss_epoch=0.0116]Epoch 22: Train Loss = 0.012922060675919056\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=354, train_loss_step=0.015, train_loss_epoch=0.0129] Epoch 23: Train Loss = 0.014962770976126194\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=354, train_loss_step=0.0168, train_loss_epoch=0.015]Epoch 24: Train Loss = 0.016824152320623398\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=354, train_loss_step=0.0141, train_loss_epoch=0.0168]Epoch 25: Train Loss = 0.014100681059062481\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=354, train_loss_step=0.0142, train_loss_epoch=0.0141]Epoch 26: Train Loss = 0.014243797399103642\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=354, train_loss_step=0.0127, train_loss_epoch=0.0142]Epoch 27: Train Loss = 0.012737827375531197\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=354, train_loss_step=0.0164, train_loss_epoch=0.0127]Epoch 28: Train Loss = 0.016415143385529518\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=354, train_loss_step=0.0134, train_loss_epoch=0.0164]Epoch 29: Train Loss = 0.013394775800406933\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=354, train_loss_step=0.0167, train_loss_epoch=0.0134]Epoch 30: Train Loss = 0.01666189357638359\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=354, train_loss_step=0.0132, train_loss_epoch=0.0167]Epoch 31: Train Loss = 0.013217860832810402\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=354, train_loss_step=0.0153, train_loss_epoch=0.0132]Epoch 32: Train Loss = 0.015330218710005283\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=354, train_loss_step=0.0175, train_loss_epoch=0.0153]Epoch 33: Train Loss = 0.01748052053153515\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0175]Epoch 34: Train Loss = 0.010191231966018677\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=354, train_loss_step=0.0115, train_loss_epoch=0.0102]Epoch 35: Train Loss = 0.011532104574143887\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=354, train_loss_step=0.0135, train_loss_epoch=0.0115]Epoch 36: Train Loss = 0.013450218364596367\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=354, train_loss_step=0.0165, train_loss_epoch=0.0135]Epoch 37: Train Loss = 0.016497774049639702\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s, v_num=354, train_loss_step=0.0162, train_loss_epoch=0.0165]Epoch 38: Train Loss = 0.016197295859456062\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=354, train_loss_step=0.014, train_loss_epoch=0.0162] Epoch 39: Train Loss = 0.014021887443959713\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=354, train_loss_step=0.0119, train_loss_epoch=0.014]Epoch 40: Train Loss = 0.011919297277927399\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=354, train_loss_step=0.0125, train_loss_epoch=0.0119]Epoch 41: Train Loss = 0.012489200569689274\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=354, train_loss_step=0.013, train_loss_epoch=0.0125] Epoch 42: Train Loss = 0.012955830432474613\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=354, train_loss_step=0.012, train_loss_epoch=0.013] Epoch 43: Train Loss = 0.011965165846049786\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.012]Epoch 44: Train Loss = 0.010650052689015865\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0107]Epoch 45: Train Loss = 0.01222639437764883\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=354, train_loss_step=0.0115, train_loss_epoch=0.0122]Epoch 46: Train Loss = 0.01151538547128439\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=354, train_loss_step=0.00985, train_loss_epoch=0.0115]Epoch 47: Train Loss = 0.009853174909949303\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 10.49it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.00985] Epoch 48: Train Loss = 0.010928817093372345\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=354, train_loss_step=0.00933, train_loss_epoch=0.0109]Epoch 49: Train Loss = 0.009334353730082512\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=354, train_loss_step=0.0137, train_loss_epoch=0.00933] Epoch 50: Train Loss = 0.013672475703060627\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.0137] Epoch 51: Train Loss = 0.010689427144825459\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=354, train_loss_step=0.0136, train_loss_epoch=0.0107]Epoch 52: Train Loss = 0.01355332974344492\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=354, train_loss_step=0.0114, train_loss_epoch=0.0136]Epoch 53: Train Loss = 0.01135524082928896\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=354, train_loss_step=0.0127, train_loss_epoch=0.0114]Epoch 54: Train Loss = 0.01272024866193533\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=354, train_loss_step=0.0112, train_loss_epoch=0.0127]Epoch 55: Train Loss = 0.011163630522787571\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=354, train_loss_step=0.0135, train_loss_epoch=0.0112]Epoch 56: Train Loss = 0.01354068610817194\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=354, train_loss_step=0.0147, train_loss_epoch=0.0135]Epoch 57: Train Loss = 0.014701894484460354\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0147]Epoch 58: Train Loss = 0.012246728874742985\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=354, train_loss_step=0.0119, train_loss_epoch=0.0122]Epoch 59: Train Loss = 0.011863017454743385\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=354, train_loss_step=0.0133, train_loss_epoch=0.0119]Epoch 60: Train Loss = 0.013329601846635342\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=354, train_loss_step=0.0136, train_loss_epoch=0.0133]Epoch 61: Train Loss = 0.01361821684986353\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=354, train_loss_step=0.0118, train_loss_epoch=0.0136]Epoch 62: Train Loss = 0.01182451844215393\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 11.55it/s, v_num=354, train_loss_step=0.0114, train_loss_epoch=0.0118]Epoch 63: Train Loss = 0.01142088882625103\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=354, train_loss_step=0.013, train_loss_epoch=0.0114] Epoch 64: Train Loss = 0.013038819655776024\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=354, train_loss_step=0.0143, train_loss_epoch=0.013]Epoch 65: Train Loss = 0.014280488714575768\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=354, train_loss_step=0.0137, train_loss_epoch=0.0143]Epoch 66: Train Loss = 0.013684287667274475\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=354, train_loss_step=0.0145, train_loss_epoch=0.0137]Epoch 67: Train Loss = 0.014528533443808556\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.0145]Epoch 68: Train Loss = 0.010597841814160347\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=354, train_loss_step=0.0144, train_loss_epoch=0.0106]Epoch 69: Train Loss = 0.014428195543587208\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.0144]Epoch 70: Train Loss = 0.010825107805430889\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=354, train_loss_step=0.0124, train_loss_epoch=0.0108]Epoch 71: Train Loss = 0.012401155196130276\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.0124] Epoch 72: Train Loss = 0.0110234459862113\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.011]Epoch 73: Train Loss = 0.010747975669801235\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=354, train_loss_step=0.00947, train_loss_epoch=0.0107]Epoch 74: Train Loss = 0.009470907971262932\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=354, train_loss_step=0.0135, train_loss_epoch=0.00947] Epoch 75: Train Loss = 0.013495148159563541\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=354, train_loss_step=0.0147, train_loss_epoch=0.0135] Epoch 76: Train Loss = 0.014689662493765354\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=354, train_loss_step=0.0113, train_loss_epoch=0.0147]Epoch 77: Train Loss = 0.011299601756036282\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=354, train_loss_step=0.0168, train_loss_epoch=0.0113]Epoch 78: Train Loss = 0.0167720727622509\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=354, train_loss_step=0.0136, train_loss_epoch=0.0168]Epoch 79: Train Loss = 0.013584095053374767\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=354, train_loss_step=0.00947, train_loss_epoch=0.0136]Epoch 80: Train Loss = 0.009470253251492977\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=354, train_loss_step=0.0098, train_loss_epoch=0.00947] Epoch 81: Train Loss = 0.00980071909725666\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.0098] Epoch 82: Train Loss = 0.0105763990432024\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=354, train_loss_step=0.0153, train_loss_epoch=0.0106]Epoch 83: Train Loss = 0.015254635363817215\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.0153] Epoch 84: Train Loss = 0.010996279306709766\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=354, train_loss_step=0.00914, train_loss_epoch=0.011]Epoch 85: Train Loss = 0.009140295907855034\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=354, train_loss_step=0.0123, train_loss_epoch=0.00914] Epoch 86: Train Loss = 0.012299439869821072\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s, v_num=354, train_loss_step=0.0105, train_loss_epoch=0.0123] Epoch 87: Train Loss = 0.010526456870138645\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=354, train_loss_step=0.00871, train_loss_epoch=0.0105]Epoch 88: Train Loss = 0.008714715018868446\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=354, train_loss_step=0.0113, train_loss_epoch=0.00871] Epoch 89: Train Loss = 0.011343219317495823\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=354, train_loss_step=0.0146, train_loss_epoch=0.0113] Epoch 90: Train Loss = 0.014550400897860527\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=354, train_loss_step=0.0111, train_loss_epoch=0.0146]Epoch 91: Train Loss = 0.011131709441542625\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=354, train_loss_step=0.0098, train_loss_epoch=0.0111]Epoch 92: Train Loss = 0.00979676190763712\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=354, train_loss_step=0.0141, train_loss_epoch=0.0098]Epoch 93: Train Loss = 0.014055101200938225\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=354, train_loss_step=0.010, train_loss_epoch=0.0141] Epoch 94: Train Loss = 0.010038601234555244\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=354, train_loss_step=0.0111, train_loss_epoch=0.010]Epoch 95: Train Loss = 0.01113983429968357\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=354, train_loss_step=0.0127, train_loss_epoch=0.0111]Epoch 96: Train Loss = 0.012695357203483582\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=354, train_loss_step=0.0121, train_loss_epoch=0.0127]Epoch 97: Train Loss = 0.012120025232434273\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=354, train_loss_step=0.00892, train_loss_epoch=0.0121]Epoch 98: Train Loss = 0.008918721228837967\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.00892] Epoch 99: Train Loss = 0.010622038505971432\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.0106]Epoch 100: Train Loss = 0.010639704763889313\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=354, train_loss_step=0.0115, train_loss_epoch=0.0106]Epoch 101: Train Loss = 0.01147980336099863\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=354, train_loss_step=0.010, train_loss_epoch=0.0115] Epoch 102: Train Loss = 0.01003375742584467\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.010]Epoch 103: Train Loss = 0.010585064999759197\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0106]Epoch 104: Train Loss = 0.010165037587285042\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=354, train_loss_step=0.00961, train_loss_epoch=0.0102]Epoch 105: Train Loss = 0.009608308784663677\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=354, train_loss_step=0.0134, train_loss_epoch=0.00961] Epoch 106: Train Loss = 0.013374270871281624\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=354, train_loss_step=0.0091, train_loss_epoch=0.0134] Epoch 107: Train Loss = 0.00910102017223835\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=354, train_loss_step=0.0162, train_loss_epoch=0.0091]Epoch 108: Train Loss = 0.016226544976234436\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=354, train_loss_step=0.0117, train_loss_epoch=0.0162]Epoch 109: Train Loss = 0.011711145751178265\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.0117]Epoch 110: Train Loss = 0.01094627846032381\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.0109] Epoch 111: Train Loss = 0.010966360569000244\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=354, train_loss_step=0.0119, train_loss_epoch=0.011]Epoch 112: Train Loss = 0.011866726912558079\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=354, train_loss_step=0.0104, train_loss_epoch=0.0119]Epoch 113: Train Loss = 0.0103761600330472\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=354, train_loss_step=0.0138, train_loss_epoch=0.0104]Epoch 114: Train Loss = 0.013802756555378437\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=354, train_loss_step=0.0139, train_loss_epoch=0.0138]Epoch 115: Train Loss = 0.013852721080183983\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=354, train_loss_step=0.0159, train_loss_epoch=0.0139]Epoch 116: Train Loss = 0.015906209126114845\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=354, train_loss_step=0.0145, train_loss_epoch=0.0159]Epoch 117: Train Loss = 0.014488260261714458\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s, v_num=354, train_loss_step=0.0121, train_loss_epoch=0.0145]Epoch 118: Train Loss = 0.012088723480701447\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=354, train_loss_step=0.00975, train_loss_epoch=0.0121]Epoch 119: Train Loss = 0.009747656062245369\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 11.28it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.00975]  Epoch 120: Train Loss = 0.010964088141918182\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=354, train_loss_step=0.0124, train_loss_epoch=0.011] Epoch 121: Train Loss = 0.01237149816006422\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=354, train_loss_step=0.015, train_loss_epoch=0.0124] Epoch 122: Train Loss = 0.014973289333283901\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=354, train_loss_step=0.012, train_loss_epoch=0.015] Epoch 123: Train Loss = 0.011958888731896877\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=354, train_loss_step=0.0154, train_loss_epoch=0.012]Epoch 124: Train Loss = 0.015443718992173672\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=354, train_loss_step=0.0177, train_loss_epoch=0.0154]Epoch 125: Train Loss = 0.017719393596053123\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=354, train_loss_step=0.00968, train_loss_epoch=0.0177]Epoch 126: Train Loss = 0.009679586626589298\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=354, train_loss_step=0.0165, train_loss_epoch=0.00968] Epoch 127: Train Loss = 0.01651371456682682\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.0165] Epoch 128: Train Loss = 0.01031480822712183\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=354, train_loss_step=0.014, train_loss_epoch=0.0103] Epoch 129: Train Loss = 0.01403721421957016\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=354, train_loss_step=0.0136, train_loss_epoch=0.014]Epoch 130: Train Loss = 0.013601226732134819\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.0136] Epoch 131: Train Loss = 0.010950794443488121\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=354, train_loss_step=0.0118, train_loss_epoch=0.011]Epoch 132: Train Loss = 0.011842461302876472\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=354, train_loss_step=0.00969, train_loss_epoch=0.0118]Epoch 133: Train Loss = 0.009687726385891438\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s, v_num=354, train_loss_step=0.0113, train_loss_epoch=0.00969] Epoch 134: Train Loss = 0.011267466470599174\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=354, train_loss_step=0.0104, train_loss_epoch=0.0113] Epoch 135: Train Loss = 0.010435190983116627\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s, v_num=354, train_loss_step=0.0126, train_loss_epoch=0.0104]Epoch 136: Train Loss = 0.012588419020175934\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=354, train_loss_step=0.0105, train_loss_epoch=0.0126]Epoch 137: Train Loss = 0.010459532961249352\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0105]Epoch 138: Train Loss = 0.010239162482321262\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.0102]Epoch 139: Train Loss = 0.010935397818684578\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=354, train_loss_step=0.0135, train_loss_epoch=0.0109]Epoch 140: Train Loss = 0.013496465981006622\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=354, train_loss_step=0.00974, train_loss_epoch=0.0135]Epoch 141: Train Loss = 0.009741785004734993\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.00974] Epoch 142: Train Loss = 0.010568545199930668\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=354, train_loss_step=0.0128, train_loss_epoch=0.0106] Epoch 143: Train Loss = 0.01280463207513094\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=354, train_loss_step=0.0125, train_loss_epoch=0.0128]Epoch 144: Train Loss = 0.012525754980742931\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=354, train_loss_step=0.0123, train_loss_epoch=0.0125]Epoch 145: Train Loss = 0.012253633700311184\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=354, train_loss_step=0.0112, train_loss_epoch=0.0123]Epoch 146: Train Loss = 0.011202865280210972\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=354, train_loss_step=0.00729, train_loss_epoch=0.0112]Epoch 147: Train Loss = 0.007293249014765024\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=354, train_loss_step=0.0123, train_loss_epoch=0.00729] Epoch 148: Train Loss = 0.012310191988945007\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=354, train_loss_step=0.00836, train_loss_epoch=0.0123]Epoch 149: Train Loss = 0.008361500687897205\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.00836] Epoch 150: Train Loss = 0.010077707469463348\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=354, train_loss_step=0.00975, train_loss_epoch=0.0101]Epoch 151: Train Loss = 0.009749142453074455\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=354, train_loss_step=0.0105, train_loss_epoch=0.00975] Epoch 152: Train Loss = 0.010477102361619473\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=354, train_loss_step=0.00821, train_loss_epoch=0.0105]Epoch 153: Train Loss = 0.008206932805478573\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=354, train_loss_step=0.00929, train_loss_epoch=0.00821]Epoch 154: Train Loss = 0.00928527396172285\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=354, train_loss_step=0.00815, train_loss_epoch=0.00929]Epoch 155: Train Loss = 0.008145957253873348\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=354, train_loss_step=0.0112, train_loss_epoch=0.00815] Epoch 156: Train Loss = 0.011209473013877869\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s, v_num=354, train_loss_step=0.0125, train_loss_epoch=0.0112] Epoch 157: Train Loss = 0.01251279003918171\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=354, train_loss_step=0.00947, train_loss_epoch=0.0125]Epoch 158: Train Loss = 0.009465137496590614\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=354, train_loss_step=0.0131, train_loss_epoch=0.00947] Epoch 159: Train Loss = 0.01305871456861496\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=354, train_loss_step=0.0172, train_loss_epoch=0.0131] Epoch 160: Train Loss = 0.017186375334858894\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=354, train_loss_step=0.0118, train_loss_epoch=0.0172]Epoch 161: Train Loss = 0.01180666871368885\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=354, train_loss_step=0.0125, train_loss_epoch=0.0118]Epoch 162: Train Loss = 0.012498943135142326\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=354, train_loss_step=0.0112, train_loss_epoch=0.0125]Epoch 163: Train Loss = 0.011222245171666145\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.0112]Epoch 164: Train Loss = 0.010782046243548393\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=354, train_loss_step=0.00861, train_loss_epoch=0.0108]Epoch 165: Train Loss = 0.008610987104475498\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=354, train_loss_step=0.0116, train_loss_epoch=0.00861] Epoch 166: Train Loss = 0.011631323024630547\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=354, train_loss_step=0.0117, train_loss_epoch=0.0116] Epoch 167: Train Loss = 0.01168739888817072\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.0117]Epoch 168: Train Loss = 0.0107852378860116\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0108]Epoch 169: Train Loss = 0.010212554596364498\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.0102]Epoch 170: Train Loss = 0.010859462432563305\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=354, train_loss_step=0.012, train_loss_epoch=0.0109] Epoch 171: Train Loss = 0.01198017317801714\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=354, train_loss_step=0.00975, train_loss_epoch=0.012]Epoch 172: Train Loss = 0.009749880991876125\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=354, train_loss_step=0.0124, train_loss_epoch=0.00975] Epoch 173: Train Loss = 0.012352638877928257\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=354, train_loss_step=0.0064, train_loss_epoch=0.0124] Epoch 174: Train Loss = 0.006398409605026245\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=354, train_loss_step=0.010, train_loss_epoch=0.0064] Epoch 175: Train Loss = 0.01004034373909235\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=354, train_loss_step=0.0152, train_loss_epoch=0.010]Epoch 176: Train Loss = 0.015157429501414299\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=354, train_loss_step=0.00836, train_loss_epoch=0.0152]Epoch 177: Train Loss = 0.008358184248209\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=354, train_loss_step=0.0113, train_loss_epoch=0.00836] Epoch 178: Train Loss = 0.011337625794112682\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=354, train_loss_step=0.0121, train_loss_epoch=0.0113] Epoch 179: Train Loss = 0.012148143723607063\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=354, train_loss_step=0.0144, train_loss_epoch=0.0121]Epoch 180: Train Loss = 0.014416110701858997\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.0144]Epoch 181: Train Loss = 0.010733271948993206\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 11.60it/s, v_num=354, train_loss_step=0.012, train_loss_epoch=0.0107] Epoch 182: Train Loss = 0.011982126161456108\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=354, train_loss_step=0.0111, train_loss_epoch=0.012]Epoch 183: Train Loss = 0.011096619069576263\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=354, train_loss_step=0.0119, train_loss_epoch=0.0111]Epoch 184: Train Loss = 0.011867399327456951\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.0119]Epoch 185: Train Loss = 0.010786250233650208\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=354, train_loss_step=0.0137, train_loss_epoch=0.0108]Epoch 186: Train Loss = 0.013709904626011848\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=354, train_loss_step=0.00903, train_loss_epoch=0.0137]Epoch 187: Train Loss = 0.00902662705630064\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=354, train_loss_step=0.00938, train_loss_epoch=0.00903]Epoch 188: Train Loss = 0.009382553398609161\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.00938] Epoch 189: Train Loss = 0.01066883746534586\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=354, train_loss_step=0.00806, train_loss_epoch=0.0107]Epoch 190: Train Loss = 0.008064765483140945\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=354, train_loss_step=0.0113, train_loss_epoch=0.00806] Epoch 191: Train Loss = 0.011339143849909306\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=354, train_loss_step=0.0159, train_loss_epoch=0.0113] Epoch 192: Train Loss = 0.015893753618001938\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=354, train_loss_step=0.0118, train_loss_epoch=0.0159]Epoch 193: Train Loss = 0.01177889108657837\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=354, train_loss_step=0.00901, train_loss_epoch=0.0118]Epoch 194: Train Loss = 0.009014308452606201\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.00901] Epoch 195: Train Loss = 0.010809384286403656\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=354, train_loss_step=0.0112, train_loss_epoch=0.0108] Epoch 196: Train Loss = 0.011182514019310474\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0112]Epoch 197: Train Loss = 0.010236029513180256\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=354, train_loss_step=0.0118, train_loss_epoch=0.0102]Epoch 198: Train Loss = 0.01180716510862112\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=354, train_loss_step=0.00875, train_loss_epoch=0.0118]Epoch 199: Train Loss = 0.008747446350753307\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=354, train_loss_step=0.0137, train_loss_epoch=0.00875] Epoch 200: Train Loss = 0.013657673262059689\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=354, train_loss_step=0.0155, train_loss_epoch=0.0137] Epoch 201: Train Loss = 0.015535930171608925\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.0155]Epoch 202: Train Loss = 0.010099821723997593\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=354, train_loss_step=0.0105, train_loss_epoch=0.0101]Epoch 203: Train Loss = 0.010545040480792522\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=354, train_loss_step=0.009, train_loss_epoch=0.0105] Epoch 204: Train Loss = 0.00899824220687151\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=354, train_loss_step=0.00896, train_loss_epoch=0.009]Epoch 205: Train Loss = 0.008956159465014935\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.00896] Epoch 206: Train Loss = 0.010570267215371132\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.0106] Epoch 207: Train Loss = 0.010252604261040688\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=354, train_loss_step=0.00978, train_loss_epoch=0.0103]Epoch 208: Train Loss = 0.009775517508387566\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=354, train_loss_step=0.0119, train_loss_epoch=0.00978] Epoch 209: Train Loss = 0.011933325789868832\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, v_num=354, train_loss_step=0.0117, train_loss_epoch=0.0119] Epoch 210: Train Loss = 0.011661243624985218\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=354, train_loss_step=0.0116, train_loss_epoch=0.0117]Epoch 211: Train Loss = 0.011571504175662994\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.0116] Epoch 212: Train Loss = 0.011018069460988045\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.011]Epoch 213: Train Loss = 0.010129536502063274\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=354, train_loss_step=0.0119, train_loss_epoch=0.0101]Epoch 214: Train Loss = 0.01187306921929121\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=354, train_loss_step=0.0137, train_loss_epoch=0.0119]Epoch 215: Train Loss = 0.013734621927142143\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=354, train_loss_step=0.0114, train_loss_epoch=0.0137]Epoch 216: Train Loss = 0.011436675675213337\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=354, train_loss_step=0.0117, train_loss_epoch=0.0114]Epoch 217: Train Loss = 0.011663763783872128\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=354, train_loss_step=0.0113, train_loss_epoch=0.0117]Epoch 218: Train Loss = 0.01131593156605959\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=354, train_loss_step=0.0105, train_loss_epoch=0.0113]Epoch 219: Train Loss = 0.010482534766197205\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0105]Epoch 220: Train Loss = 0.010218949988484383\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=354, train_loss_step=0.0167, train_loss_epoch=0.0102]Epoch 221: Train Loss = 0.01671832986176014\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=354, train_loss_step=0.0078, train_loss_epoch=0.0167]Epoch 222: Train Loss = 0.0077984207309782505\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=354, train_loss_step=0.0159, train_loss_epoch=0.0078]Epoch 223: Train Loss = 0.015918735414743423\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=354, train_loss_step=0.0123, train_loss_epoch=0.0159]Epoch 224: Train Loss = 0.012266560457646847\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=354, train_loss_step=0.00919, train_loss_epoch=0.0123]Epoch 225: Train Loss = 0.00919440109282732\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=354, train_loss_step=0.00875, train_loss_epoch=0.00919]Epoch 226: Train Loss = 0.008752875030040741\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.00875]  Epoch 227: Train Loss = 0.01098729483783245\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.011] Epoch 228: Train Loss = 0.012151011265814304\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=354, train_loss_step=0.00925, train_loss_epoch=0.0122]Epoch 229: Train Loss = 0.009251223877072334\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=354, train_loss_step=0.00911, train_loss_epoch=0.00925]Epoch 230: Train Loss = 0.009114635176956654\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=354, train_loss_step=0.0135, train_loss_epoch=0.00911] Epoch 231: Train Loss = 0.013549565337598324\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0135] Epoch 232: Train Loss = 0.012184715829789639\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.0122]Epoch 233: Train Loss = 0.010810726322233677\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=354, train_loss_step=0.0123, train_loss_epoch=0.0108]Epoch 234: Train Loss = 0.012257336638867855\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=354, train_loss_step=0.00914, train_loss_epoch=0.0123]Epoch 235: Train Loss = 0.00913873128592968\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=354, train_loss_step=0.00673, train_loss_epoch=0.00914]Epoch 236: Train Loss = 0.006729639135301113\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.00673] Epoch 237: Train Loss = 0.01010102778673172\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.0101] Epoch 238: Train Loss = 0.010295835323631763\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=354, train_loss_step=0.0104, train_loss_epoch=0.0103]Epoch 239: Train Loss = 0.010364217683672905\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=354, train_loss_step=0.0129, train_loss_epoch=0.0104]Epoch 240: Train Loss = 0.01288935448974371\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.0129]Epoch 241: Train Loss = 0.010653291828930378\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=354, train_loss_step=0.0136, train_loss_epoch=0.0107]Epoch 242: Train Loss = 0.01357400231063366\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.0136]Epoch 243: Train Loss = 0.010566051118075848\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=354, train_loss_step=0.00919, train_loss_epoch=0.0106]Epoch 244: Train Loss = 0.009185337461531162\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=354, train_loss_step=0.010, train_loss_epoch=0.00919]  Epoch 245: Train Loss = 0.01003231666982174\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=354, train_loss_step=0.0116, train_loss_epoch=0.010] Epoch 246: Train Loss = 0.011570572853088379\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.0116]Epoch 247: Train Loss = 0.010879327543079853\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=354, train_loss_step=0.00896, train_loss_epoch=0.0109]Epoch 248: Train Loss = 0.008955461904406548\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=354, train_loss_step=0.0104, train_loss_epoch=0.00896] Epoch 249: Train Loss = 0.010359987616539001\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=354, train_loss_step=0.0151, train_loss_epoch=0.0104] Epoch 250: Train Loss = 0.015094535425305367\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=354, train_loss_step=0.0114, train_loss_epoch=0.0151]Epoch 251: Train Loss = 0.01142137311398983\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=354, train_loss_step=0.0098, train_loss_epoch=0.0114]Epoch 252: Train Loss = 0.009801371954381466\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=354, train_loss_step=0.00941, train_loss_epoch=0.0098]Epoch 253: Train Loss = 0.009407132863998413\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.00941] Epoch 254: Train Loss = 0.010931176133453846\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.0109] Epoch 255: Train Loss = 0.010149837471544743\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=354, train_loss_step=0.0105, train_loss_epoch=0.0101]Epoch 256: Train Loss = 0.010508420877158642\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.0105]Epoch 257: Train Loss = 0.010294722393155098\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0103]Epoch 258: Train Loss = 0.010209721513092518\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=354, train_loss_step=0.0128, train_loss_epoch=0.0102]Epoch 259: Train Loss = 0.012797706760466099\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=354, train_loss_step=0.0119, train_loss_epoch=0.0128]Epoch 260: Train Loss = 0.011918564327061176\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0119]Epoch 261: Train Loss = 0.010157028213143349\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=354, train_loss_step=0.0111, train_loss_epoch=0.0102]Epoch 262: Train Loss = 0.011093932203948498\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=354, train_loss_step=0.0124, train_loss_epoch=0.0111]Epoch 263: Train Loss = 0.012361087836325169\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=354, train_loss_step=0.0104, train_loss_epoch=0.0124]Epoch 264: Train Loss = 0.010385622270405293\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=354, train_loss_step=0.00964, train_loss_epoch=0.0104]Epoch 265: Train Loss = 0.009640314616262913\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=354, train_loss_step=0.012, train_loss_epoch=0.00964]  Epoch 266: Train Loss = 0.01201565656810999\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=354, train_loss_step=0.0145, train_loss_epoch=0.012] Epoch 267: Train Loss = 0.014497061260044575\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=354, train_loss_step=0.0118, train_loss_epoch=0.0145]Epoch 268: Train Loss = 0.011763808317482471\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.0118]Epoch 269: Train Loss = 0.010839256457984447\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=354, train_loss_step=0.0119, train_loss_epoch=0.0108]Epoch 270: Train Loss = 0.011870987713336945\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=354, train_loss_step=0.0105, train_loss_epoch=0.0119]Epoch 271: Train Loss = 0.010464338585734367\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.0105] Epoch 272: Train Loss = 0.011002452112734318\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=354, train_loss_step=0.0099, train_loss_epoch=0.011]Epoch 273: Train Loss = 0.009901373647153378\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=354, train_loss_step=0.00957, train_loss_epoch=0.0099]Epoch 274: Train Loss = 0.009565578773617744\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.00957] Epoch 275: Train Loss = 0.010816961526870728\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.0108] Epoch 276: Train Loss = 0.01083048339933157\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=354, train_loss_step=0.00938, train_loss_epoch=0.0108]Epoch 277: Train Loss = 0.009382948279380798\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=354, train_loss_step=0.0112, train_loss_epoch=0.00938] Epoch 278: Train Loss = 0.01121644675731659\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=354, train_loss_step=0.00901, train_loss_epoch=0.0112]Epoch 279: Train Loss = 0.009011832065880299\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=354, train_loss_step=0.0137, train_loss_epoch=0.00901] Epoch 280: Train Loss = 0.013732708990573883\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=354, train_loss_step=0.00966, train_loss_epoch=0.0137]Epoch 281: Train Loss = 0.009663219563663006\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=354, train_loss_step=0.00879, train_loss_epoch=0.00966]Epoch 282: Train Loss = 0.008793659508228302\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=354, train_loss_step=0.0116, train_loss_epoch=0.00879] Epoch 283: Train Loss = 0.011605724692344666\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=354, train_loss_step=0.00974, train_loss_epoch=0.0116]Epoch 284: Train Loss = 0.00973574910312891\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=354, train_loss_step=0.015, train_loss_epoch=0.00974]  Epoch 285: Train Loss = 0.014977850951254368\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=354, train_loss_step=0.0112, train_loss_epoch=0.015] Epoch 286: Train Loss = 0.011206633411347866\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=354, train_loss_step=0.0126, train_loss_epoch=0.0112]Epoch 287: Train Loss = 0.012591434642672539\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0126]Epoch 288: Train Loss = 0.012182447127997875\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=354, train_loss_step=0.0105, train_loss_epoch=0.0122]Epoch 289: Train Loss = 0.010492200031876564\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=354, train_loss_step=0.00884, train_loss_epoch=0.0105]Epoch 290: Train Loss = 0.008838136680424213\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=354, train_loss_step=0.00966, train_loss_epoch=0.00884]Epoch 291: Train Loss = 0.009656229056417942\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.00966] Epoch 292: Train Loss = 0.010684407316148281\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=354, train_loss_step=0.0132, train_loss_epoch=0.0107] Epoch 293: Train Loss = 0.013205461204051971\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.0132]Epoch 294: Train Loss = 0.010659337043762207\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0107]Epoch 295: Train Loss = 0.010210007429122925\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=354, train_loss_step=0.00808, train_loss_epoch=0.0102]Epoch 296: Train Loss = 0.008082153275609016\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=354, train_loss_step=0.0128, train_loss_epoch=0.00808] Epoch 297: Train Loss = 0.012788950465619564\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=354, train_loss_step=0.00907, train_loss_epoch=0.0128]Epoch 298: Train Loss = 0.009070320054888725\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=354, train_loss_step=0.0135, train_loss_epoch=0.00907] Epoch 299: Train Loss = 0.013506404124200344\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=354, train_loss_step=0.0134, train_loss_epoch=0.0135] Epoch 300: Train Loss = 0.013354352675378323\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=354, train_loss_step=0.0091, train_loss_epoch=0.0134]Epoch 301: Train Loss = 0.009095053188502789\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.0091]Epoch 302: Train Loss = 0.010903159156441689\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0109]Epoch 303: Train Loss = 0.012243571691215038\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=354, train_loss_step=0.00914, train_loss_epoch=0.0122]Epoch 304: Train Loss = 0.009139329195022583\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=354, train_loss_step=0.0111, train_loss_epoch=0.00914] Epoch 305: Train Loss = 0.011098981834948063\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=354, train_loss_step=0.00796, train_loss_epoch=0.0111]Epoch 306: Train Loss = 0.007958889938890934\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=354, train_loss_step=0.00917, train_loss_epoch=0.00796]Epoch 307: Train Loss = 0.009172140620648861\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=354, train_loss_step=0.013, train_loss_epoch=0.00917]  Epoch 308: Train Loss = 0.012962548062205315\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=354, train_loss_step=0.00786, train_loss_epoch=0.013]Epoch 309: Train Loss = 0.007858925499022007\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=354, train_loss_step=0.0121, train_loss_epoch=0.00786] Epoch 310: Train Loss = 0.01209710631519556\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=354, train_loss_step=0.012, train_loss_epoch=0.0121]  Epoch 311: Train Loss = 0.01199591625481844\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.012]Epoch 312: Train Loss = 0.01011017244309187\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=354, train_loss_step=0.0104, train_loss_epoch=0.0101]Epoch 313: Train Loss = 0.010395217686891556\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=354, train_loss_step=0.00912, train_loss_epoch=0.0104]Epoch 314: Train Loss = 0.009124966338276863\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.00912] Epoch 315: Train Loss = 0.012226955033838749\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0122] Epoch 316: Train Loss = 0.010156214237213135\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.0102]Epoch 317: Train Loss = 0.01031060516834259\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=354, train_loss_step=0.00956, train_loss_epoch=0.0103]Epoch 318: Train Loss = 0.009555325843393803\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=354, train_loss_step=0.00754, train_loss_epoch=0.00956]Epoch 319: Train Loss = 0.007537637371569872\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=354, train_loss_step=0.00978, train_loss_epoch=0.00754]Epoch 320: Train Loss = 0.009778562001883984\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s, v_num=354, train_loss_step=0.00829, train_loss_epoch=0.00978]Epoch 321: Train Loss = 0.0082866121083498\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=354, train_loss_step=0.00961, train_loss_epoch=0.00829]Epoch 322: Train Loss = 0.009606809355318546\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=354, train_loss_step=0.00754, train_loss_epoch=0.00961]Epoch 323: Train Loss = 0.007539821323007345\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=354, train_loss_step=0.00988, train_loss_epoch=0.00754]Epoch 324: Train Loss = 0.009880260564386845\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=354, train_loss_step=0.0128, train_loss_epoch=0.00988] Epoch 325: Train Loss = 0.012757127173244953\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, v_num=354, train_loss_step=0.00862, train_loss_epoch=0.0128]Epoch 326: Train Loss = 0.008623000234365463\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=354, train_loss_step=0.00944, train_loss_epoch=0.00862]Epoch 327: Train Loss = 0.009435310959815979\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.00944] Epoch 328: Train Loss = 0.010319049470126629\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=354, train_loss_step=0.0121, train_loss_epoch=0.0103] Epoch 329: Train Loss = 0.012097981758415699\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=354, train_loss_step=0.0128, train_loss_epoch=0.0121]Epoch 330: Train Loss = 0.01282534096390009\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=354, train_loss_step=0.00837, train_loss_epoch=0.0128]Epoch 331: Train Loss = 0.00837346725165844\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=354, train_loss_step=0.012, train_loss_epoch=0.00837]  Epoch 332: Train Loss = 0.011958223767578602\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.012] Epoch 333: Train Loss = 0.010770520195364952\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=354, train_loss_step=0.0126, train_loss_epoch=0.0108]Epoch 334: Train Loss = 0.01264885626733303\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 10.67it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0126]Epoch 335: Train Loss = 0.01224022451788187\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=354, train_loss_step=0.00928, train_loss_epoch=0.0122]Epoch 336: Train Loss = 0.009275701828300953\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.00928] Epoch 337: Train Loss = 0.010851363651454449\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=354, train_loss_step=0.00865, train_loss_epoch=0.0109]Epoch 338: Train Loss = 0.008653284050524235\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=354, train_loss_step=0.00948, train_loss_epoch=0.00865]Epoch 339: Train Loss = 0.009481005370616913\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=354, train_loss_step=0.0097, train_loss_epoch=0.00948] Epoch 340: Train Loss = 0.009704222902655602\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.0097]  Epoch 341: Train Loss = 0.0109565956518054\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.011]Epoch 342: Train Loss = 0.010309484787285328\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=354, train_loss_step=0.00859, train_loss_epoch=0.0103]Epoch 343: Train Loss = 0.00859079509973526\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=354, train_loss_step=0.00907, train_loss_epoch=0.00859]Epoch 344: Train Loss = 0.009069772437214851\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=354, train_loss_step=0.0121, train_loss_epoch=0.00907] Epoch 345: Train Loss = 0.012124885804951191\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=354, train_loss_step=0.00733, train_loss_epoch=0.0121]Epoch 346: Train Loss = 0.007334969937801361\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s, v_num=354, train_loss_step=0.010, train_loss_epoch=0.00733]  Epoch 347: Train Loss = 0.010021107271313667\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=354, train_loss_step=0.00892, train_loss_epoch=0.010]Epoch 348: Train Loss = 0.008920518681406975\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.00892] Epoch 349: Train Loss = 0.01023384090512991\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=354, train_loss_step=0.0124, train_loss_epoch=0.0102] Epoch 350: Train Loss = 0.012414275668561459\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=354, train_loss_step=0.00962, train_loss_epoch=0.0124]Epoch 351: Train Loss = 0.009620481170713902\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=354, train_loss_step=0.00972, train_loss_epoch=0.00962]Epoch 352: Train Loss = 0.009716907516121864\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=354, train_loss_step=0.0126, train_loss_epoch=0.00972] Epoch 353: Train Loss = 0.012555084191262722\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.0126] Epoch 354: Train Loss = 0.010310808196663857\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=354, train_loss_step=0.00921, train_loss_epoch=0.0103]Epoch 355: Train Loss = 0.00920773297548294\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=354, train_loss_step=0.00897, train_loss_epoch=0.00921]Epoch 356: Train Loss = 0.008971278555691242\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=354, train_loss_step=0.00956, train_loss_epoch=0.00897]Epoch 357: Train Loss = 0.009558443911373615\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=354, train_loss_step=0.00865, train_loss_epoch=0.00956]Epoch 358: Train Loss = 0.008646083064377308\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=354, train_loss_step=0.0121, train_loss_epoch=0.00865] Epoch 359: Train Loss = 0.012089923955500126\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.0121] Epoch 360: Train Loss = 0.010186740197241306\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=354, train_loss_step=0.00968, train_loss_epoch=0.0102]Epoch 361: Train Loss = 0.009681732393801212\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.00968] Epoch 362: Train Loss = 0.01224091462790966\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0122] Epoch 363: Train Loss = 0.01217363215982914\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=354, train_loss_step=0.0112, train_loss_epoch=0.0122]Epoch 364: Train Loss = 0.011235247366130352\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=354, train_loss_step=0.00973, train_loss_epoch=0.0112]Epoch 365: Train Loss = 0.009727603755891323\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.00973] Epoch 366: Train Loss = 0.01060563139617443\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.0106] Epoch 367: Train Loss = 0.010593382641673088\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=354, train_loss_step=0.013, train_loss_epoch=0.0106] Epoch 368: Train Loss = 0.012957533821463585\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=354, train_loss_step=0.0111, train_loss_epoch=0.013]Epoch 369: Train Loss = 0.011123090982437134\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=354, train_loss_step=0.0113, train_loss_epoch=0.0111]Epoch 370: Train Loss = 0.011318732984364033\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=354, train_loss_step=0.0104, train_loss_epoch=0.0113]Epoch 371: Train Loss = 0.010393953882157803\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=354, train_loss_step=0.0132, train_loss_epoch=0.0104]Epoch 372: Train Loss = 0.013210021890699863\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.0132]Epoch 373: Train Loss = 0.010069838725030422\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=354, train_loss_step=0.0089, train_loss_epoch=0.0101]Epoch 374: Train Loss = 0.008897879160940647\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=354, train_loss_step=0.00933, train_loss_epoch=0.0089]Epoch 375: Train Loss = 0.009334527887403965\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=354, train_loss_step=0.00937, train_loss_epoch=0.00933]Epoch 376: Train Loss = 0.009374863468110561\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=354, train_loss_step=0.00954, train_loss_epoch=0.00937]Epoch 377: Train Loss = 0.0095436442643404\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=354, train_loss_step=0.00869, train_loss_epoch=0.00954]Epoch 378: Train Loss = 0.008690419606864452\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=354, train_loss_step=0.0134, train_loss_epoch=0.00869] Epoch 379: Train Loss = 0.013445919379591942\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=354, train_loss_step=0.0123, train_loss_epoch=0.0134] Epoch 380: Train Loss = 0.012277618050575256\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.0123]Epoch 381: Train Loss = 0.010660069063305855\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=354, train_loss_step=0.00934, train_loss_epoch=0.0107]Epoch 382: Train Loss = 0.009340011514723301\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=354, train_loss_step=0.0133, train_loss_epoch=0.00934] Epoch 383: Train Loss = 0.013252777978777885\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=354, train_loss_step=0.00971, train_loss_epoch=0.0133]Epoch 384: Train Loss = 0.00970844179391861\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=354, train_loss_step=0.0136, train_loss_epoch=0.00971] Epoch 385: Train Loss = 0.013572371564805508\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=354, train_loss_step=0.0142, train_loss_epoch=0.0136] Epoch 386: Train Loss = 0.014209297485649586\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=354, train_loss_step=0.00855, train_loss_epoch=0.0142]Epoch 387: Train Loss = 0.00855038221925497\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=354, train_loss_step=0.0124, train_loss_epoch=0.00855] Epoch 388: Train Loss = 0.012413169257342815\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=354, train_loss_step=0.0137, train_loss_epoch=0.0124] Epoch 389: Train Loss = 0.013672985136508942\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, v_num=354, train_loss_step=0.00912, train_loss_epoch=0.0137]Epoch 390: Train Loss = 0.009120325557887554\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 10.94it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.00912] Epoch 391: Train Loss = 0.010562221519649029\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s, v_num=354, train_loss_step=0.0092, train_loss_epoch=0.0106] Epoch 392: Train Loss = 0.009203748777508736\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.0092]Epoch 393: Train Loss = 0.010826215147972107\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=354, train_loss_step=0.00823, train_loss_epoch=0.0108]Epoch 394: Train Loss = 0.00822522770613432\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=354, train_loss_step=0.00718, train_loss_epoch=0.00823]Epoch 395: Train Loss = 0.0071809133514761925\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=354, train_loss_step=0.00822, train_loss_epoch=0.00718]Epoch 396: Train Loss = 0.008223197422921658\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.00822] Epoch 397: Train Loss = 0.010852262377738953\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=354, train_loss_step=0.0064, train_loss_epoch=0.0109] Epoch 398: Train Loss = 0.006403119768947363\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=354, train_loss_step=0.0152, train_loss_epoch=0.0064]Epoch 399: Train Loss = 0.015175516717135906\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.0152]Epoch 400: Train Loss = 0.010058104991912842\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=354, train_loss_step=0.00823, train_loss_epoch=0.0101]Epoch 401: Train Loss = 0.008231679908931255\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.00823] Epoch 402: Train Loss = 0.010229394771158695\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=354, train_loss_step=0.0092, train_loss_epoch=0.0102] Epoch 403: Train Loss = 0.009195812977850437\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.0092]Epoch 404: Train Loss = 0.010276553221046925\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.0103]Epoch 405: Train Loss = 0.010287770070135593\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=354, train_loss_step=0.012, train_loss_epoch=0.0103] Epoch 406: Train Loss = 0.012046500109136105\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=354, train_loss_step=0.00988, train_loss_epoch=0.012]Epoch 407: Train Loss = 0.0098768575116992\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=354, train_loss_step=0.0113, train_loss_epoch=0.00988] Epoch 408: Train Loss = 0.011309294030070305\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=354, train_loss_step=0.00913, train_loss_epoch=0.0113]Epoch 409: Train Loss = 0.00912682618945837\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.00913] Epoch 410: Train Loss = 0.012175087817013264\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=354, train_loss_step=0.0131, train_loss_epoch=0.0122] Epoch 411: Train Loss = 0.013058394193649292\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.0131]Epoch 412: Train Loss = 0.010719910264015198\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=354, train_loss_step=0.00807, train_loss_epoch=0.0107]Epoch 413: Train Loss = 0.008068467490375042\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s, v_num=354, train_loss_step=0.0124, train_loss_epoch=0.00807] Epoch 414: Train Loss = 0.012403375469148159\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=354, train_loss_step=0.0132, train_loss_epoch=0.0124] Epoch 415: Train Loss = 0.013211456127464771\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=354, train_loss_step=0.0138, train_loss_epoch=0.0132]Epoch 416: Train Loss = 0.013775182887911797\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.0138]Epoch 417: Train Loss = 0.010134260170161724\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=354, train_loss_step=0.0131, train_loss_epoch=0.0101]Epoch 418: Train Loss = 0.013071880675852299\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=354, train_loss_step=0.00829, train_loss_epoch=0.0131]Epoch 419: Train Loss = 0.008292538113892078\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=354, train_loss_step=0.0118, train_loss_epoch=0.00829] Epoch 420: Train Loss = 0.011817735619843006\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=354, train_loss_step=0.00878, train_loss_epoch=0.0118]Epoch 421: Train Loss = 0.008775632828474045\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=354, train_loss_step=0.00859, train_loss_epoch=0.00878]Epoch 422: Train Loss = 0.008587787859141827\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.00859] Epoch 423: Train Loss = 0.010626330971717834\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=354, train_loss_step=0.012, train_loss_epoch=0.0106]  Epoch 424: Train Loss = 0.012012938968837261\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=354, train_loss_step=0.0085, train_loss_epoch=0.012]Epoch 425: Train Loss = 0.008502354845404625\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=354, train_loss_step=0.0143, train_loss_epoch=0.0085]Epoch 426: Train Loss = 0.014276674948632717\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=354, train_loss_step=0.00821, train_loss_epoch=0.0143]Epoch 427: Train Loss = 0.008209948427975178\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=354, train_loss_step=0.00984, train_loss_epoch=0.00821]Epoch 428: Train Loss = 0.009838844649493694\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.00984] Epoch 429: Train Loss = 0.010068529285490513\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=354, train_loss_step=0.00989, train_loss_epoch=0.0101]Epoch 430: Train Loss = 0.009889119304716587\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=354, train_loss_step=0.0102, train_loss_epoch=0.00989] Epoch 431: Train Loss = 0.01019161194562912\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=354, train_loss_step=0.00983, train_loss_epoch=0.0102]Epoch 432: Train Loss = 0.009831421077251434\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=354, train_loss_step=0.00888, train_loss_epoch=0.00983]Epoch 433: Train Loss = 0.008878989145159721\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=354, train_loss_step=0.0113, train_loss_epoch=0.00888] Epoch 434: Train Loss = 0.011336837895214558\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=354, train_loss_step=0.0115, train_loss_epoch=0.0113] Epoch 435: Train Loss = 0.011537830345332623\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=354, train_loss_step=0.008, train_loss_epoch=0.0115] Epoch 436: Train Loss = 0.007998940534889698\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=354, train_loss_step=0.0103, train_loss_epoch=0.008]Epoch 437: Train Loss = 0.010325858369469643\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=354, train_loss_step=0.0099, train_loss_epoch=0.0103]Epoch 438: Train Loss = 0.00990376342087984\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=354, train_loss_step=0.00987, train_loss_epoch=0.0099]Epoch 439: Train Loss = 0.00987476110458374\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=354, train_loss_step=0.0104, train_loss_epoch=0.00987] Epoch 440: Train Loss = 0.010360285639762878\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=354, train_loss_step=0.00819, train_loss_epoch=0.0104]Epoch 441: Train Loss = 0.008186498656868935\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=354, train_loss_step=0.0115, train_loss_epoch=0.00819] Epoch 442: Train Loss = 0.01147835049778223\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.0115] Epoch 443: Train Loss = 0.010769879445433617\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=354, train_loss_step=0.0114, train_loss_epoch=0.0108]Epoch 444: Train Loss = 0.01138498354703188\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s, v_num=354, train_loss_step=0.0156, train_loss_epoch=0.0114]Epoch 445: Train Loss = 0.015555075369775295\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s, v_num=354, train_loss_step=0.00794, train_loss_epoch=0.0156]Epoch 446: Train Loss = 0.007937404327094555\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.00794]  Epoch 447: Train Loss = 0.01104566641151905\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 11.21it/s, v_num=354, train_loss_step=0.00983, train_loss_epoch=0.011]Epoch 448: Train Loss = 0.009833982214331627\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=354, train_loss_step=0.0109, train_loss_epoch=0.00983] Epoch 449: Train Loss = 0.010882740840315819\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=354, train_loss_step=0.0111, train_loss_epoch=0.0109] Epoch 450: Train Loss = 0.011147231794893742\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=354, train_loss_step=0.012, train_loss_epoch=0.0111] Epoch 451: Train Loss = 0.011959942057728767\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=354, train_loss_step=0.00931, train_loss_epoch=0.012]Epoch 452: Train Loss = 0.009313344024121761\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=354, train_loss_step=0.0104, train_loss_epoch=0.00931] Epoch 453: Train Loss = 0.010394175536930561\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=354, train_loss_step=0.0106, train_loss_epoch=0.0104] Epoch 454: Train Loss = 0.010603342205286026\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=354, train_loss_step=0.011, train_loss_epoch=0.0106] Epoch 455: Train Loss = 0.010993723757565022\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=354, train_loss_step=0.00936, train_loss_epoch=0.011]Epoch 456: Train Loss = 0.009360072202980518\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=354, train_loss_step=0.00913, train_loss_epoch=0.00936]Epoch 457: Train Loss = 0.009133996441960335\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=354, train_loss_step=0.0118, train_loss_epoch=0.00913] Epoch 458: Train Loss = 0.011754789389669895\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=354, train_loss_step=0.0125, train_loss_epoch=0.0118] Epoch 459: Train Loss = 0.01246968749910593\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0125]Epoch 460: Train Loss = 0.01215412188321352\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=354, train_loss_step=0.0112, train_loss_epoch=0.0122]Epoch 461: Train Loss = 0.011227436363697052\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=354, train_loss_step=0.00991, train_loss_epoch=0.0112]Epoch 462: Train Loss = 0.00990885216742754\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=354, train_loss_step=0.0115, train_loss_epoch=0.00991] Epoch 463: Train Loss = 0.011503727175295353\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=354, train_loss_step=0.0119, train_loss_epoch=0.0115] Epoch 464: Train Loss = 0.011890843510627747\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=354, train_loss_step=0.0152, train_loss_epoch=0.0119]Epoch 465: Train Loss = 0.01524930726736784\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.0152]Epoch 466: Train Loss = 0.010707603767514229\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=354, train_loss_step=0.00969, train_loss_epoch=0.0107]Epoch 467: Train Loss = 0.009690621867775917\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=354, train_loss_step=0.00982, train_loss_epoch=0.00969]Epoch 468: Train Loss = 0.009823227301239967\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=354, train_loss_step=0.00961, train_loss_epoch=0.00982]Epoch 469: Train Loss = 0.009605209343135357\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=354, train_loss_step=0.00899, train_loss_epoch=0.00961]Epoch 470: Train Loss = 0.008987365290522575\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.00899] Epoch 471: Train Loss = 0.010074488818645477\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=354, train_loss_step=0.00965, train_loss_epoch=0.0101]Epoch 472: Train Loss = 0.009651401080191135\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=354, train_loss_step=0.00788, train_loss_epoch=0.00965]Epoch 473: Train Loss = 0.007880869321525097\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=354, train_loss_step=0.0127, train_loss_epoch=0.00788] Epoch 474: Train Loss = 0.012688396498560905\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=354, train_loss_step=0.0115, train_loss_epoch=0.0127] Epoch 475: Train Loss = 0.01150503195822239\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=354, train_loss_step=0.0121, train_loss_epoch=0.0115]Epoch 476: Train Loss = 0.012078708037734032\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=354, train_loss_step=0.00979, train_loss_epoch=0.0121]Epoch 477: Train Loss = 0.009790182113647461\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.00979] Epoch 478: Train Loss = 0.010794115252792835\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=354, train_loss_step=0.0111, train_loss_epoch=0.0108] Epoch 479: Train Loss = 0.011117200367152691\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=354, train_loss_step=0.00788, train_loss_epoch=0.0111]Epoch 480: Train Loss = 0.007883253507316113\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, v_num=354, train_loss_step=0.00955, train_loss_epoch=0.00788]Epoch 481: Train Loss = 0.009553493931889534\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=354, train_loss_step=0.00997, train_loss_epoch=0.00955]Epoch 482: Train Loss = 0.009965813718736172\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=354, train_loss_step=0.00967, train_loss_epoch=0.00997]Epoch 483: Train Loss = 0.009667092934250832\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=354, train_loss_step=0.0115, train_loss_epoch=0.00967] Epoch 484: Train Loss = 0.01145007461309433\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0115] Epoch 485: Train Loss = 0.012164690531790257\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=354, train_loss_step=0.0107, train_loss_epoch=0.0122]Epoch 486: Train Loss = 0.010732792317867279\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=354, train_loss_step=0.0137, train_loss_epoch=0.0107]Epoch 487: Train Loss = 0.01371911633759737\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=354, train_loss_step=0.0136, train_loss_epoch=0.0137]Epoch 488: Train Loss = 0.013627974316477776\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=354, train_loss_step=0.0123, train_loss_epoch=0.0136]Epoch 489: Train Loss = 0.01232130080461502\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=354, train_loss_step=0.0101, train_loss_epoch=0.0123]Epoch 490: Train Loss = 0.010109933093190193\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=354, train_loss_step=0.00925, train_loss_epoch=0.0101]Epoch 491: Train Loss = 0.009246760979294777\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=354, train_loss_step=0.00909, train_loss_epoch=0.00925]Epoch 492: Train Loss = 0.009087043814361095\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=354, train_loss_step=0.0121, train_loss_epoch=0.00909] Epoch 493: Train Loss = 0.012132006697356701\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=354, train_loss_step=0.0111, train_loss_epoch=0.0121] Epoch 494: Train Loss = 0.011076697148382664\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=354, train_loss_step=0.00964, train_loss_epoch=0.0111]Epoch 495: Train Loss = 0.00963539071381092\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=354, train_loss_step=0.0123, train_loss_epoch=0.00964] Epoch 496: Train Loss = 0.012342744506895542\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=354, train_loss_step=0.0108, train_loss_epoch=0.0123] Epoch 497: Train Loss = 0.01077059656381607\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=354, train_loss_step=0.0104, train_loss_epoch=0.0108]Epoch 498: Train Loss = 0.010367662645876408\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0104]Epoch 499: Train Loss = 0.01220307219773531\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0122]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=354, train_loss_step=0.0122, train_loss_epoch=0.0122]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 28.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 10: from 2008-05-12 00:00:00 to 2022-09-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=358, train_loss_step=0.0209]Epoch 0: Train Loss = 0.020936641842126846\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=358, train_loss_step=0.0397, train_loss_epoch=0.0209]Epoch 1: Train Loss = 0.03967178612947464\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=358, train_loss_step=0.0368, train_loss_epoch=0.0397]Epoch 2: Train Loss = 0.036837298423051834\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=358, train_loss_step=0.0169, train_loss_epoch=0.0368]Epoch 3: Train Loss = 0.016872210428118706\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=358, train_loss_step=0.0158, train_loss_epoch=0.0169]Epoch 4: Train Loss = 0.015782907605171204\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=358, train_loss_step=0.0131, train_loss_epoch=0.0158]Epoch 5: Train Loss = 0.013130471110343933\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=358, train_loss_step=0.0141, train_loss_epoch=0.0131]Epoch 6: Train Loss = 0.014066440984606743\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=358, train_loss_step=0.0155, train_loss_epoch=0.0141]Epoch 7: Train Loss = 0.015502160415053368\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=358, train_loss_step=0.0121, train_loss_epoch=0.0155]Epoch 8: Train Loss = 0.012118672952055931\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.0121]Epoch 9: Train Loss = 0.010466796346008778\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=358, train_loss_step=0.0158, train_loss_epoch=0.0105]Epoch 10: Train Loss = 0.015775883570313454\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=358, train_loss_step=0.0142, train_loss_epoch=0.0158]Epoch 11: Train Loss = 0.014188106171786785\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=358, train_loss_step=0.0116, train_loss_epoch=0.0142]Epoch 12: Train Loss = 0.011605414561927319\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=358, train_loss_step=0.0154, train_loss_epoch=0.0116]Epoch 13: Train Loss = 0.015433751046657562\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=358, train_loss_step=0.0173, train_loss_epoch=0.0154]Epoch 14: Train Loss = 0.017301537096500397\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=358, train_loss_step=0.0174, train_loss_epoch=0.0173]Epoch 15: Train Loss = 0.01735679805278778\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.0174]Epoch 16: Train Loss = 0.010455755516886711\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=358, train_loss_step=0.0167, train_loss_epoch=0.0105]Epoch 17: Train Loss = 0.016677675768733025\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=358, train_loss_step=0.0138, train_loss_epoch=0.0167]Epoch 18: Train Loss = 0.013760334812104702\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=358, train_loss_step=0.0163, train_loss_epoch=0.0138]Epoch 19: Train Loss = 0.016252512112259865\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.0163]Epoch 20: Train Loss = 0.011365889571607113\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=358, train_loss_step=0.0163, train_loss_epoch=0.0114]Epoch 21: Train Loss = 0.016255663707852364\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=358, train_loss_step=0.0149, train_loss_epoch=0.0163]Epoch 22: Train Loss = 0.01491097453981638\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=358, train_loss_step=0.0121, train_loss_epoch=0.0149]Epoch 23: Train Loss = 0.012064697220921516\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.0121]Epoch 24: Train Loss = 0.01139870099723339\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=358, train_loss_step=0.0117, train_loss_epoch=0.0114]Epoch 25: Train Loss = 0.011726298369467258\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=358, train_loss_step=0.0112, train_loss_epoch=0.0117]Epoch 26: Train Loss = 0.01121160015463829\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=358, train_loss_step=0.012, train_loss_epoch=0.0112] Epoch 27: Train Loss = 0.012027489021420479\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=358, train_loss_step=0.012, train_loss_epoch=0.012] Epoch 28: Train Loss = 0.012011713348329067\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=358, train_loss_step=0.0131, train_loss_epoch=0.012]Epoch 29: Train Loss = 0.013125047087669373\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=358, train_loss_step=0.0127, train_loss_epoch=0.0131]Epoch 30: Train Loss = 0.012675867415964603\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=358, train_loss_step=0.0125, train_loss_epoch=0.0127]Epoch 31: Train Loss = 0.012455851770937443\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=358, train_loss_step=0.0161, train_loss_epoch=0.0125]Epoch 32: Train Loss = 0.01606198213994503\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=358, train_loss_step=0.0162, train_loss_epoch=0.0161]Epoch 33: Train Loss = 0.016165046021342278\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=358, train_loss_step=0.0125, train_loss_epoch=0.0162]Epoch 34: Train Loss = 0.012455357238650322\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=358, train_loss_step=0.016, train_loss_epoch=0.0125] Epoch 35: Train Loss = 0.016004623845219612\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=358, train_loss_step=0.0121, train_loss_epoch=0.016]Epoch 36: Train Loss = 0.012065835297107697\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=358, train_loss_step=0.0133, train_loss_epoch=0.0121]Epoch 37: Train Loss = 0.013301105238497257\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=358, train_loss_step=0.0187, train_loss_epoch=0.0133]Epoch 38: Train Loss = 0.01869315467774868\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=358, train_loss_step=0.0119, train_loss_epoch=0.0187]Epoch 39: Train Loss = 0.011913622729480267\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=358, train_loss_step=0.0118, train_loss_epoch=0.0119]Epoch 40: Train Loss = 0.011774475686252117\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=358, train_loss_step=0.00847, train_loss_epoch=0.0118]Epoch 41: Train Loss = 0.008474165573716164\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.00847] Epoch 42: Train Loss = 0.010532652959227562\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=358, train_loss_step=0.0127, train_loss_epoch=0.0105] Epoch 43: Train Loss = 0.012732105329632759\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=358, train_loss_step=0.00934, train_loss_epoch=0.0127]Epoch 44: Train Loss = 0.009341365657746792\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.00934] Epoch 45: Train Loss = 0.010893077589571476\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=358, train_loss_step=0.00967, train_loss_epoch=0.0109]Epoch 46: Train Loss = 0.009670962579548359\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=358, train_loss_step=0.0107, train_loss_epoch=0.00967] Epoch 47: Train Loss = 0.010708498768508434\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=358, train_loss_step=0.0142, train_loss_epoch=0.0107] Epoch 48: Train Loss = 0.014209478162229061\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=358, train_loss_step=0.00932, train_loss_epoch=0.0142]Epoch 49: Train Loss = 0.009320585057139397\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=358, train_loss_step=0.0103, train_loss_epoch=0.00932] Epoch 50: Train Loss = 0.01027520652860403\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=358, train_loss_step=0.0111, train_loss_epoch=0.0103] Epoch 51: Train Loss = 0.011091123335063457\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=358, train_loss_step=0.0121, train_loss_epoch=0.0111]Epoch 52: Train Loss = 0.012107446789741516\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.0121]Epoch 53: Train Loss = 0.011399892158806324\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=358, train_loss_step=0.0131, train_loss_epoch=0.0114]Epoch 54: Train Loss = 0.013109909370541573\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=358, train_loss_step=0.0157, train_loss_epoch=0.0131]Epoch 55: Train Loss = 0.015675095841288567\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=358, train_loss_step=0.0118, train_loss_epoch=0.0157]Epoch 56: Train Loss = 0.0117659205570817\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=358, train_loss_step=0.00935, train_loss_epoch=0.0118]Epoch 57: Train Loss = 0.00934928935021162\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=358, train_loss_step=0.0102, train_loss_epoch=0.00935] Epoch 58: Train Loss = 0.010150684043765068\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.0102] Epoch 59: Train Loss = 0.010487673804163933\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=358, train_loss_step=0.0153, train_loss_epoch=0.0105]Epoch 60: Train Loss = 0.015316230244934559\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.0153]Epoch 61: Train Loss = 0.010854429565370083\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=358, train_loss_step=0.00897, train_loss_epoch=0.0109]Epoch 62: Train Loss = 0.00896607805043459\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=358, train_loss_step=0.012, train_loss_epoch=0.00897]  Epoch 63: Train Loss = 0.011995463632047176\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=358, train_loss_step=0.0112, train_loss_epoch=0.012] Epoch 64: Train Loss = 0.011183381080627441\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=358, train_loss_step=0.00943, train_loss_epoch=0.0112]Epoch 65: Train Loss = 0.009432941675186157\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=358, train_loss_step=0.00863, train_loss_epoch=0.00943]Epoch 66: Train Loss = 0.008634679950773716\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.00863] Epoch 67: Train Loss = 0.010429225862026215\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=358, train_loss_step=0.00923, train_loss_epoch=0.0104]Epoch 68: Train Loss = 0.009231488220393658\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=358, train_loss_step=0.00948, train_loss_epoch=0.00923]Epoch 69: Train Loss = 0.009482079185545444\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=358, train_loss_step=0.0142, train_loss_epoch=0.00948] Epoch 70: Train Loss = 0.014244349673390388\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=358, train_loss_step=0.0145, train_loss_epoch=0.0142] Epoch 71: Train Loss = 0.01452734787017107\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=358, train_loss_step=0.00872, train_loss_epoch=0.0145]Epoch 72: Train Loss = 0.008721687830984592\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=358, train_loss_step=0.00971, train_loss_epoch=0.00872]Epoch 73: Train Loss = 0.009714691899716854\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=358, train_loss_step=0.00837, train_loss_epoch=0.00971]Epoch 74: Train Loss = 0.008365730755031109\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=358, train_loss_step=0.0133, train_loss_epoch=0.00837] Epoch 75: Train Loss = 0.013288314454257488\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=358, train_loss_step=0.011, train_loss_epoch=0.0133]  Epoch 76: Train Loss = 0.010977321304380894\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=358, train_loss_step=0.013, train_loss_epoch=0.011] Epoch 77: Train Loss = 0.01299190428107977\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.013]Epoch 78: Train Loss = 0.010397237725555897\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=358, train_loss_step=0.0165, train_loss_epoch=0.0104]Epoch 79: Train Loss = 0.016542477533221245\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s, v_num=358, train_loss_step=0.0171, train_loss_epoch=0.0165]Epoch 80: Train Loss = 0.017094284296035767\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=358, train_loss_step=0.0089, train_loss_epoch=0.0171]Epoch 81: Train Loss = 0.008904307149350643\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=358, train_loss_step=0.013, train_loss_epoch=0.0089] Epoch 82: Train Loss = 0.012964273802936077\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=358, train_loss_step=0.00813, train_loss_epoch=0.013]Epoch 83: Train Loss = 0.008125253953039646\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=358, train_loss_step=0.0101, train_loss_epoch=0.00813] Epoch 84: Train Loss = 0.010116561315953732\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=358, train_loss_step=0.0124, train_loss_epoch=0.0101] Epoch 85: Train Loss = 0.012350396253168583\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=358, train_loss_step=0.0148, train_loss_epoch=0.0124]Epoch 86: Train Loss = 0.014816947281360626\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=358, train_loss_step=0.00976, train_loss_epoch=0.0148]Epoch 87: Train Loss = 0.00976384524255991\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=358, train_loss_step=0.0154, train_loss_epoch=0.00976] Epoch 88: Train Loss = 0.015357869677245617\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=358, train_loss_step=0.00869, train_loss_epoch=0.0154]Epoch 89: Train Loss = 0.008691571652889252\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=358, train_loss_step=0.00941, train_loss_epoch=0.00869]Epoch 90: Train Loss = 0.009405759163200855\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=358, train_loss_step=0.00907, train_loss_epoch=0.00941]Epoch 91: Train Loss = 0.009068502113223076\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=358, train_loss_step=0.0139, train_loss_epoch=0.00907] Epoch 92: Train Loss = 0.013861888088285923\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=358, train_loss_step=0.0125, train_loss_epoch=0.0139] Epoch 93: Train Loss = 0.012497542425990105\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=358, train_loss_step=0.00963, train_loss_epoch=0.0125]Epoch 94: Train Loss = 0.0096252067014575\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=358, train_loss_step=0.0135, train_loss_epoch=0.00963] Epoch 95: Train Loss = 0.013453193940222263\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=358, train_loss_step=0.00995, train_loss_epoch=0.0135]Epoch 96: Train Loss = 0.00995142012834549\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=358, train_loss_step=0.0147, train_loss_epoch=0.00995] Epoch 97: Train Loss = 0.01466304063796997\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=358, train_loss_step=0.00984, train_loss_epoch=0.0147]Epoch 98: Train Loss = 0.009840154089033604\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=358, train_loss_step=0.014, train_loss_epoch=0.00984]  Epoch 99: Train Loss = 0.014039682224392891\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=358, train_loss_step=0.011, train_loss_epoch=0.014] Epoch 100: Train Loss = 0.01100309006869793\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=358, train_loss_step=0.0136, train_loss_epoch=0.011]Epoch 101: Train Loss = 0.013590192422270775\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=358, train_loss_step=0.0103, train_loss_epoch=0.0136]Epoch 102: Train Loss = 0.010344053618609905\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=358, train_loss_step=0.00992, train_loss_epoch=0.0103]Epoch 103: Train Loss = 0.009917705319821835\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=358, train_loss_step=0.0133, train_loss_epoch=0.00992] Epoch 104: Train Loss = 0.013264866545796394\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=358, train_loss_step=0.00994, train_loss_epoch=0.0133]Epoch 105: Train Loss = 0.009940305724740028\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=358, train_loss_step=0.0128, train_loss_epoch=0.00994] Epoch 106: Train Loss = 0.012773755006492138\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=358, train_loss_step=0.0124, train_loss_epoch=0.0128] Epoch 107: Train Loss = 0.012358644977211952\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=358, train_loss_step=0.0115, train_loss_epoch=0.0124]Epoch 108: Train Loss = 0.011462175287306309\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=358, train_loss_step=0.0111, train_loss_epoch=0.0115]Epoch 109: Train Loss = 0.011081283912062645\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=358, train_loss_step=0.00984, train_loss_epoch=0.0111]Epoch 110: Train Loss = 0.009843590669333935\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=358, train_loss_step=0.0117, train_loss_epoch=0.00984] Epoch 111: Train Loss = 0.011730154976248741\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=358, train_loss_step=0.013, train_loss_epoch=0.0117]  Epoch 112: Train Loss = 0.012959702871739864\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=358, train_loss_step=0.0126, train_loss_epoch=0.013]Epoch 113: Train Loss = 0.012594424188137054\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=358, train_loss_step=0.0112, train_loss_epoch=0.0126]Epoch 114: Train Loss = 0.011205843649804592\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=358, train_loss_step=0.0115, train_loss_epoch=0.0112]Epoch 115: Train Loss = 0.0115122701972723\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=358, train_loss_step=0.0118, train_loss_epoch=0.0115]Epoch 116: Train Loss = 0.011799296364188194\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=358, train_loss_step=0.0134, train_loss_epoch=0.0118]Epoch 117: Train Loss = 0.013445048592984676\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=358, train_loss_step=0.0108, train_loss_epoch=0.0134]Epoch 118: Train Loss = 0.01079530082643032\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s, v_num=358, train_loss_step=0.00918, train_loss_epoch=0.0108]Epoch 119: Train Loss = 0.00918466318398714\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=358, train_loss_step=0.00946, train_loss_epoch=0.00918]Epoch 120: Train Loss = 0.00945574976503849\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.00946] Epoch 121: Train Loss = 0.010523522272706032\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=358, train_loss_step=0.0118, train_loss_epoch=0.0105] Epoch 122: Train Loss = 0.01180251780897379\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.0118]Epoch 123: Train Loss = 0.010639755986630917\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=358, train_loss_step=0.0138, train_loss_epoch=0.0106]Epoch 124: Train Loss = 0.01384474616497755\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=358, train_loss_step=0.00955, train_loss_epoch=0.0138]Epoch 125: Train Loss = 0.009554512798786163\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=358, train_loss_step=0.011, train_loss_epoch=0.00955]  Epoch 126: Train Loss = 0.010973108001053333\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=358, train_loss_step=0.0145, train_loss_epoch=0.011] Epoch 127: Train Loss = 0.014537186361849308\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=358, train_loss_step=0.0115, train_loss_epoch=0.0145]Epoch 128: Train Loss = 0.01150018535554409\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=358, train_loss_step=0.0116, train_loss_epoch=0.0115]Epoch 129: Train Loss = 0.011642081663012505\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=358, train_loss_step=0.012, train_loss_epoch=0.0116] Epoch 130: Train Loss = 0.012013928033411503\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=358, train_loss_step=0.0141, train_loss_epoch=0.012]Epoch 131: Train Loss = 0.014093390665948391\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=358, train_loss_step=0.0101, train_loss_epoch=0.0141]Epoch 132: Train Loss = 0.010073738172650337\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=358, train_loss_step=0.0116, train_loss_epoch=0.0101]Epoch 133: Train Loss = 0.011602790094912052\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=358, train_loss_step=0.0124, train_loss_epoch=0.0116]Epoch 134: Train Loss = 0.012399681843817234\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.0124]Epoch 135: Train Loss = 0.010446359403431416\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=358, train_loss_step=0.0125, train_loss_epoch=0.0104]Epoch 136: Train Loss = 0.012510182335972786\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=358, train_loss_step=0.0101, train_loss_epoch=0.0125]Epoch 137: Train Loss = 0.010127668268978596\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.0101]Epoch 138: Train Loss = 0.010886630043387413\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=358, train_loss_step=0.0187, train_loss_epoch=0.0109]Epoch 139: Train Loss = 0.018682314082980156\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=358, train_loss_step=0.0139, train_loss_epoch=0.0187]Epoch 140: Train Loss = 0.013851816765964031\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=358, train_loss_step=0.0118, train_loss_epoch=0.0139]Epoch 141: Train Loss = 0.011818893253803253\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=358, train_loss_step=0.00962, train_loss_epoch=0.0118]Epoch 142: Train Loss = 0.009622761979699135\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=358, train_loss_step=0.00955, train_loss_epoch=0.00962]Epoch 143: Train Loss = 0.009552190080285072\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=358, train_loss_step=0.0121, train_loss_epoch=0.00955] Epoch 144: Train Loss = 0.012096770107746124\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=358, train_loss_step=0.0112, train_loss_epoch=0.0121] Epoch 145: Train Loss = 0.01117683108896017\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=358, train_loss_step=0.0116, train_loss_epoch=0.0112]Epoch 146: Train Loss = 0.011589271016418934\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 10.79it/s, v_num=358, train_loss_step=0.00994, train_loss_epoch=0.0116]Epoch 147: Train Loss = 0.009940320625901222\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=358, train_loss_step=0.0162, train_loss_epoch=0.00994] Epoch 148: Train Loss = 0.016204433515667915\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=358, train_loss_step=0.010, train_loss_epoch=0.0162]  Epoch 149: Train Loss = 0.010045508854091167\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=358, train_loss_step=0.0127, train_loss_epoch=0.010]Epoch 150: Train Loss = 0.012650398537516594\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=358, train_loss_step=0.0089, train_loss_epoch=0.0127]Epoch 151: Train Loss = 0.00889830756932497\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=358, train_loss_step=0.0129, train_loss_epoch=0.0089]Epoch 152: Train Loss = 0.012882495298981667\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=358, train_loss_step=0.00821, train_loss_epoch=0.0129]Epoch 153: Train Loss = 0.008213570341467857\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=358, train_loss_step=0.012, train_loss_epoch=0.00821]  Epoch 154: Train Loss = 0.011953192763030529\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=358, train_loss_step=0.00797, train_loss_epoch=0.012]Epoch 155: Train Loss = 0.007970644161105156\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=358, train_loss_step=0.00937, train_loss_epoch=0.00797]Epoch 156: Train Loss = 0.009368800558149815\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=358, train_loss_step=0.00976, train_loss_epoch=0.00937]Epoch 157: Train Loss = 0.009761371649801731\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=358, train_loss_step=0.00909, train_loss_epoch=0.00976]Epoch 158: Train Loss = 0.009086132980883121\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.00909] Epoch 159: Train Loss = 0.01144465897232294\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  3.38it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.0114] Epoch 160: Train Loss = 0.0103946253657341\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=358, train_loss_step=0.0116, train_loss_epoch=0.0104]Epoch 161: Train Loss = 0.011613495647907257\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=358, train_loss_step=0.0129, train_loss_epoch=0.0116]Epoch 162: Train Loss = 0.012854652479290962\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=358, train_loss_step=0.010, train_loss_epoch=0.0129] Epoch 163: Train Loss = 0.010007903911173344\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.010]Epoch 164: Train Loss = 0.010402972809970379\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=358, train_loss_step=0.00938, train_loss_epoch=0.0104]Epoch 165: Train Loss = 0.009381034411489964\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=358, train_loss_step=0.0083, train_loss_epoch=0.00938] Epoch 166: Train Loss = 0.008304149843752384\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=358, train_loss_step=0.00907, train_loss_epoch=0.0083]Epoch 167: Train Loss = 0.009072842076420784\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=358, train_loss_step=0.0098, train_loss_epoch=0.00907] Epoch 168: Train Loss = 0.009798750281333923\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.0098] Epoch 169: Train Loss = 0.010935642756521702\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s, v_num=358, train_loss_step=0.0115, train_loss_epoch=0.0109]Epoch 170: Train Loss = 0.011539235711097717\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=358, train_loss_step=0.0096, train_loss_epoch=0.0115]Epoch 171: Train Loss = 0.009598842822015285\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=358, train_loss_step=0.0095, train_loss_epoch=0.0096]Epoch 172: Train Loss = 0.009504328481853008\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=358, train_loss_step=0.00823, train_loss_epoch=0.0095]Epoch 173: Train Loss = 0.00823068805038929\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.00823] Epoch 174: Train Loss = 0.010418045334517956\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=358, train_loss_step=0.0139, train_loss_epoch=0.0104] Epoch 175: Train Loss = 0.013873076997697353\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=358, train_loss_step=0.00927, train_loss_epoch=0.0139]Epoch 176: Train Loss = 0.009273812174797058\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=358, train_loss_step=0.00961, train_loss_epoch=0.00927]Epoch 177: Train Loss = 0.009608777239918709\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=358, train_loss_step=0.00972, train_loss_epoch=0.00961]Epoch 178: Train Loss = 0.009723575785756111\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=358, train_loss_step=0.011, train_loss_epoch=0.00972]  Epoch 179: Train Loss = 0.010976462624967098\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=358, train_loss_step=0.0135, train_loss_epoch=0.011] Epoch 180: Train Loss = 0.013513362966477871\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=358, train_loss_step=0.00723, train_loss_epoch=0.0135]Epoch 181: Train Loss = 0.007226760033518076\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=358, train_loss_step=0.0132, train_loss_epoch=0.00723] Epoch 182: Train Loss = 0.01319656241685152\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=358, train_loss_step=0.0101, train_loss_epoch=0.0132] Epoch 183: Train Loss = 0.010102130472660065\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=358, train_loss_step=0.0124, train_loss_epoch=0.0101]Epoch 184: Train Loss = 0.012370945885777473\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=358, train_loss_step=0.0111, train_loss_epoch=0.0124]Epoch 185: Train Loss = 0.011090540327131748\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=358, train_loss_step=0.0103, train_loss_epoch=0.0111]Epoch 186: Train Loss = 0.010290867649018764\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=358, train_loss_step=0.0135, train_loss_epoch=0.0103]Epoch 187: Train Loss = 0.013493412174284458\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=358, train_loss_step=0.0144, train_loss_epoch=0.0135]Epoch 188: Train Loss = 0.014392863027751446\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=358, train_loss_step=0.0157, train_loss_epoch=0.0144]Epoch 189: Train Loss = 0.015735160559415817\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=358, train_loss_step=0.0133, train_loss_epoch=0.0157]Epoch 190: Train Loss = 0.013308107852935791\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=358, train_loss_step=0.0159, train_loss_epoch=0.0133]Epoch 191: Train Loss = 0.015874799340963364\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=358, train_loss_step=0.0112, train_loss_epoch=0.0159]Epoch 192: Train Loss = 0.011192024685442448\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=358, train_loss_step=0.0123, train_loss_epoch=0.0112]Epoch 193: Train Loss = 0.012327681295573711\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=358, train_loss_step=0.0137, train_loss_epoch=0.0123]Epoch 194: Train Loss = 0.013740882277488708\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=358, train_loss_step=0.0115, train_loss_epoch=0.0137]Epoch 195: Train Loss = 0.011509492993354797\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=358, train_loss_step=0.0153, train_loss_epoch=0.0115]Epoch 196: Train Loss = 0.01525688637048006\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.0153]Epoch 197: Train Loss = 0.01090902741998434\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.0109]Epoch 198: Train Loss = 0.011447953060269356\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, v_num=358, train_loss_step=0.0121, train_loss_epoch=0.0114]Epoch 199: Train Loss = 0.01206367276608944\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.0121]Epoch 200: Train Loss = 0.010432601906359196\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=358, train_loss_step=0.0107, train_loss_epoch=0.0104]Epoch 201: Train Loss = 0.01067535113543272\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=358, train_loss_step=0.0118, train_loss_epoch=0.0107]Epoch 202: Train Loss = 0.011751350946724415\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=358, train_loss_step=0.0139, train_loss_epoch=0.0118]Epoch 203: Train Loss = 0.013885709457099438\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=358, train_loss_step=0.0101, train_loss_epoch=0.0139]Epoch 204: Train Loss = 0.010125473141670227\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=358, train_loss_step=0.00969, train_loss_epoch=0.0101]Epoch 205: Train Loss = 0.009688740596175194\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=358, train_loss_step=0.0149, train_loss_epoch=0.00969] Epoch 206: Train Loss = 0.014913857914507389\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=358, train_loss_step=0.00855, train_loss_epoch=0.0149]Epoch 207: Train Loss = 0.008552159182727337\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=358, train_loss_step=0.013, train_loss_epoch=0.00855]  Epoch 208: Train Loss = 0.012973114848136902\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s, v_num=358, train_loss_step=0.00941, train_loss_epoch=0.013]Epoch 209: Train Loss = 0.009408614598214626\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=358, train_loss_step=0.0145, train_loss_epoch=0.00941] Epoch 210: Train Loss = 0.014485536143183708\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=358, train_loss_step=0.00913, train_loss_epoch=0.0145]Epoch 211: Train Loss = 0.009133105166256428\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=358, train_loss_step=0.00865, train_loss_epoch=0.00913]Epoch 212: Train Loss = 0.008646308444440365\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=358, train_loss_step=0.0115, train_loss_epoch=0.00865] Epoch 213: Train Loss = 0.01149547565728426\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=358, train_loss_step=0.0149, train_loss_epoch=0.0115] Epoch 214: Train Loss = 0.014920905232429504\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s, v_num=358, train_loss_step=0.010, train_loss_epoch=0.0149] Epoch 215: Train Loss = 0.01004011370241642\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=358, train_loss_step=0.0165, train_loss_epoch=0.010]Epoch 216: Train Loss = 0.01647150330245495\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=358, train_loss_step=0.0112, train_loss_epoch=0.0165]Epoch 217: Train Loss = 0.011248734779655933\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=358, train_loss_step=0.0126, train_loss_epoch=0.0112]Epoch 218: Train Loss = 0.012591837905347347\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.0126]Epoch 219: Train Loss = 0.01139347068965435\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=358, train_loss_step=0.00998, train_loss_epoch=0.0114]Epoch 220: Train Loss = 0.009975316934287548\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=358, train_loss_step=0.0115, train_loss_epoch=0.00998] Epoch 221: Train Loss = 0.011482447385787964\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.0115] Epoch 222: Train Loss = 0.01142591517418623\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=358, train_loss_step=0.00871, train_loss_epoch=0.0114]Epoch 223: Train Loss = 0.008711283095180988\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=358, train_loss_step=0.00949, train_loss_epoch=0.00871]Epoch 224: Train Loss = 0.009492285549640656\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=358, train_loss_step=0.00902, train_loss_epoch=0.00949]Epoch 225: Train Loss = 0.009022661484777927\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=358, train_loss_step=0.0112, train_loss_epoch=0.00902] Epoch 226: Train Loss = 0.011225023306906223\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=358, train_loss_step=0.00723, train_loss_epoch=0.0112]Epoch 227: Train Loss = 0.007230340037494898\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=358, train_loss_step=0.00992, train_loss_epoch=0.00723]Epoch 228: Train Loss = 0.009923397563397884\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=358, train_loss_step=0.011, train_loss_epoch=0.00992]  Epoch 229: Train Loss = 0.01095525175333023\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=358, train_loss_step=0.0133, train_loss_epoch=0.011] Epoch 230: Train Loss = 0.013296176679432392\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=358, train_loss_step=0.015, train_loss_epoch=0.0133] Epoch 231: Train Loss = 0.014980347827076912\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=358, train_loss_step=0.0132, train_loss_epoch=0.015]Epoch 232: Train Loss = 0.013246065005660057\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=358, train_loss_step=0.00918, train_loss_epoch=0.0132]Epoch 233: Train Loss = 0.009183562360703945\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=358, train_loss_step=0.0116, train_loss_epoch=0.00918] Epoch 234: Train Loss = 0.011636837385594845\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=358, train_loss_step=0.0131, train_loss_epoch=0.0116] Epoch 235: Train Loss = 0.013071690686047077\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.0131]Epoch 236: Train Loss = 0.010891118086874485\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=358, train_loss_step=0.0129, train_loss_epoch=0.0109]Epoch 237: Train Loss = 0.012888496741652489\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=358, train_loss_step=0.00963, train_loss_epoch=0.0129]Epoch 238: Train Loss = 0.00962741207331419\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=358, train_loss_step=0.0133, train_loss_epoch=0.00963] Epoch 239: Train Loss = 0.013317614793777466\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=358, train_loss_step=0.0119, train_loss_epoch=0.0133] Epoch 240: Train Loss = 0.011869876645505428\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=358, train_loss_step=0.00855, train_loss_epoch=0.0119]Epoch 241: Train Loss = 0.008551317267119884\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s, v_num=358, train_loss_step=0.0107, train_loss_epoch=0.00855] Epoch 242: Train Loss = 0.01072882954031229\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.0107] Epoch 243: Train Loss = 0.010599086061120033\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=358, train_loss_step=0.012, train_loss_epoch=0.0106] Epoch 244: Train Loss = 0.011970056220889091\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=358, train_loss_step=0.00958, train_loss_epoch=0.012]Epoch 245: Train Loss = 0.009575393982231617\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=358, train_loss_step=0.0121, train_loss_epoch=0.00958] Epoch 246: Train Loss = 0.012071826495230198\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=358, train_loss_step=0.0108, train_loss_epoch=0.0121] Epoch 247: Train Loss = 0.010805954225361347\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=358, train_loss_step=0.0131, train_loss_epoch=0.0108]Epoch 248: Train Loss = 0.013139301910996437\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=358, train_loss_step=0.00962, train_loss_epoch=0.0131]Epoch 249: Train Loss = 0.009617350995540619\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=358, train_loss_step=0.0133, train_loss_epoch=0.00962] Epoch 250: Train Loss = 0.01325977686792612\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=358, train_loss_step=0.00877, train_loss_epoch=0.0133]Epoch 251: Train Loss = 0.008768978528678417\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=358, train_loss_step=0.00757, train_loss_epoch=0.00877]Epoch 252: Train Loss = 0.007571022491902113\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=358, train_loss_step=0.0131, train_loss_epoch=0.00757] Epoch 253: Train Loss = 0.013110232539474964\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=358, train_loss_step=0.00917, train_loss_epoch=0.0131]Epoch 254: Train Loss = 0.009174265898764133\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.00917] Epoch 255: Train Loss = 0.011353901587426662\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=358, train_loss_step=0.00969, train_loss_epoch=0.0114]Epoch 256: Train Loss = 0.009690351784229279\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=358, train_loss_step=0.00843, train_loss_epoch=0.00969]Epoch 257: Train Loss = 0.008429036475718021\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=358, train_loss_step=0.014, train_loss_epoch=0.00843]  Epoch 258: Train Loss = 0.014049107208848\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=358, train_loss_step=0.00988, train_loss_epoch=0.014]Epoch 259: Train Loss = 0.009880222380161285\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=358, train_loss_step=0.00845, train_loss_epoch=0.00988]Epoch 260: Train Loss = 0.008452152833342552\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=358, train_loss_step=0.00975, train_loss_epoch=0.00845]Epoch 261: Train Loss = 0.009745989926159382\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=358, train_loss_step=0.00852, train_loss_epoch=0.00975]Epoch 262: Train Loss = 0.008521643467247486\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=358, train_loss_step=0.00863, train_loss_epoch=0.00852]Epoch 263: Train Loss = 0.008626792579889297\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.00863] Epoch 264: Train Loss = 0.010883498005568981\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=358, train_loss_step=0.011, train_loss_epoch=0.0109]  Epoch 265: Train Loss = 0.010986581444740295\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=358, train_loss_step=0.0119, train_loss_epoch=0.011]Epoch 266: Train Loss = 0.011944742873311043\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=358, train_loss_step=0.0107, train_loss_epoch=0.0119]Epoch 267: Train Loss = 0.010722318664193153\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=358, train_loss_step=0.00823, train_loss_epoch=0.0107]Epoch 268: Train Loss = 0.008230309933423996\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=358, train_loss_step=0.00921, train_loss_epoch=0.00823]Epoch 269: Train Loss = 0.009207173250615597\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=358, train_loss_step=0.0088, train_loss_epoch=0.00921] Epoch 270: Train Loss = 0.008801464922726154\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.0088] Epoch 271: Train Loss = 0.010373606346547604\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=358, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 272: Train Loss = 0.01148519478738308\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.0115]Epoch 273: Train Loss = 0.010442463681101799\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=358, train_loss_step=0.0122, train_loss_epoch=0.0104]Epoch 274: Train Loss = 0.012167909182608128\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=358, train_loss_step=0.00953, train_loss_epoch=0.0122]Epoch 275: Train Loss = 0.009527730755507946\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=358, train_loss_step=0.0123, train_loss_epoch=0.00953] Epoch 276: Train Loss = 0.012311927042901516\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=358, train_loss_step=0.00767, train_loss_epoch=0.0123]Epoch 277: Train Loss = 0.0076672411523759365\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=358, train_loss_step=0.0102, train_loss_epoch=0.00767] Epoch 278: Train Loss = 0.010221730917692184\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=358, train_loss_step=0.0088, train_loss_epoch=0.0102] Epoch 279: Train Loss = 0.008803215809166431\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 10.18it/s, v_num=358, train_loss_step=0.0108, train_loss_epoch=0.0088]Epoch 280: Train Loss = 0.010767298750579357\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=358, train_loss_step=0.0113, train_loss_epoch=0.0108]Epoch 281: Train Loss = 0.011293577961623669\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=358, train_loss_step=0.00999, train_loss_epoch=0.0113]Epoch 282: Train Loss = 0.009987150318920612\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=358, train_loss_step=0.013, train_loss_epoch=0.00999]  Epoch 283: Train Loss = 0.013034592382609844\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=358, train_loss_step=0.0079, train_loss_epoch=0.013] Epoch 284: Train Loss = 0.007897628471255302\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=358, train_loss_step=0.00955, train_loss_epoch=0.0079]Epoch 285: Train Loss = 0.009545565582811832\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.00955] Epoch 286: Train Loss = 0.01089499332010746\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=358, train_loss_step=0.0118, train_loss_epoch=0.0109] Epoch 287: Train Loss = 0.011805757880210876\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.0118]Epoch 288: Train Loss = 0.010587331838905811\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.0106]Epoch 289: Train Loss = 0.010871308855712414\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=358, train_loss_step=0.0111, train_loss_epoch=0.0109]Epoch 290: Train Loss = 0.011098898947238922\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.0111]Epoch 291: Train Loss = 0.010937085375189781\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=358, train_loss_step=0.0136, train_loss_epoch=0.0109]Epoch 292: Train Loss = 0.013646206818521023\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=358, train_loss_step=0.0127, train_loss_epoch=0.0136]Epoch 293: Train Loss = 0.012729592621326447\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.0127]Epoch 294: Train Loss = 0.010542620904743671\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=358, train_loss_step=0.0113, train_loss_epoch=0.0105]Epoch 295: Train Loss = 0.011253840290009975\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=358, train_loss_step=0.0124, train_loss_epoch=0.0113]Epoch 296: Train Loss = 0.01242335606366396\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=358, train_loss_step=0.0138, train_loss_epoch=0.0124]Epoch 297: Train Loss = 0.013773374259471893\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=358, train_loss_step=0.0124, train_loss_epoch=0.0138]Epoch 298: Train Loss = 0.012362965382635593\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=358, train_loss_step=0.0103, train_loss_epoch=0.0124]Epoch 299: Train Loss = 0.01027054525911808\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=358, train_loss_step=0.0102, train_loss_epoch=0.0103]Epoch 300: Train Loss = 0.010213649831712246\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 11.26it/s, v_num=358, train_loss_step=0.0148, train_loss_epoch=0.0102]Epoch 301: Train Loss = 0.01480669155716896\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=358, train_loss_step=0.013, train_loss_epoch=0.0148] Epoch 302: Train Loss = 0.013024801388382912\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.013]Epoch 303: Train Loss = 0.011388465762138367\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=358, train_loss_step=0.0098, train_loss_epoch=0.0114]Epoch 304: Train Loss = 0.009795091114938259\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=358, train_loss_step=0.00776, train_loss_epoch=0.0098]Epoch 305: Train Loss = 0.007763729430735111\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.00776] Epoch 306: Train Loss = 0.010587869212031364\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=358, train_loss_step=0.00956, train_loss_epoch=0.0106]Epoch 307: Train Loss = 0.00955773051828146\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=358, train_loss_step=0.0137, train_loss_epoch=0.00956] Epoch 308: Train Loss = 0.013709823600947857\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=358, train_loss_step=0.0138, train_loss_epoch=0.0137] Epoch 309: Train Loss = 0.013788915239274502\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.0138]Epoch 310: Train Loss = 0.011428465135395527\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.0114]Epoch 311: Train Loss = 0.010372118093073368\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=358, train_loss_step=0.0107, train_loss_epoch=0.0104]Epoch 312: Train Loss = 0.010655088350176811\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=358, train_loss_step=0.012, train_loss_epoch=0.0107] Epoch 313: Train Loss = 0.01196354627609253\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=358, train_loss_step=0.0153, train_loss_epoch=0.012]Epoch 314: Train Loss = 0.015341942198574543\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=358, train_loss_step=0.0123, train_loss_epoch=0.0153]Epoch 315: Train Loss = 0.012291471473872662\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=358, train_loss_step=0.00938, train_loss_epoch=0.0123]Epoch 316: Train Loss = 0.009384595789015293\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=358, train_loss_step=0.013, train_loss_epoch=0.00938]  Epoch 317: Train Loss = 0.012963990680873394\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=358, train_loss_step=0.0134, train_loss_epoch=0.013] Epoch 318: Train Loss = 0.013394350185990334\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=358, train_loss_step=0.0125, train_loss_epoch=0.0134]Epoch 319: Train Loss = 0.012540385127067566\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=358, train_loss_step=0.0115, train_loss_epoch=0.0125]Epoch 320: Train Loss = 0.011476450599730015\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=358, train_loss_step=0.00946, train_loss_epoch=0.0115]Epoch 321: Train Loss = 0.009463791735470295\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=358, train_loss_step=0.00839, train_loss_epoch=0.00946]Epoch 322: Train Loss = 0.008388563059270382\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.00839] Epoch 323: Train Loss = 0.010599399916827679\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=358, train_loss_step=0.00949, train_loss_epoch=0.0106]Epoch 324: Train Loss = 0.009489579126238823\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=358, train_loss_step=0.0112, train_loss_epoch=0.00949] Epoch 325: Train Loss = 0.011162427254021168\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=358, train_loss_step=0.0108, train_loss_epoch=0.0112] Epoch 326: Train Loss = 0.010838361456990242\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=358, train_loss_step=0.0122, train_loss_epoch=0.0108]Epoch 327: Train Loss = 0.0121569549664855\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=358, train_loss_step=0.0127, train_loss_epoch=0.0122]Epoch 328: Train Loss = 0.012725948356091976\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=358, train_loss_step=0.00996, train_loss_epoch=0.0127]Epoch 329: Train Loss = 0.009960921481251717\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=358, train_loss_step=0.00834, train_loss_epoch=0.00996]Epoch 330: Train Loss = 0.008341200649738312\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=358, train_loss_step=0.00898, train_loss_epoch=0.00834]Epoch 331: Train Loss = 0.00898031983524561\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=358, train_loss_step=0.00953, train_loss_epoch=0.00898]Epoch 332: Train Loss = 0.009530697949230671\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s, v_num=358, train_loss_step=0.00937, train_loss_epoch=0.00953]Epoch 333: Train Loss = 0.009367123246192932\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=358, train_loss_step=0.0124, train_loss_epoch=0.00937] Epoch 334: Train Loss = 0.0123745771124959\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=358, train_loss_step=0.0119, train_loss_epoch=0.0124] Epoch 335: Train Loss = 0.01194754708558321\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=358, train_loss_step=0.0103, train_loss_epoch=0.0119]Epoch 336: Train Loss = 0.0102505162358284\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s, v_num=358, train_loss_step=0.0116, train_loss_epoch=0.0103]Epoch 337: Train Loss = 0.011645701713860035\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=358, train_loss_step=0.011, train_loss_epoch=0.0116] Epoch 338: Train Loss = 0.011037363670766354\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=358, train_loss_step=0.0091, train_loss_epoch=0.011]Epoch 339: Train Loss = 0.00910207536071539\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=358, train_loss_step=0.012, train_loss_epoch=0.0091] Epoch 340: Train Loss = 0.012013109400868416\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=358, train_loss_step=0.0132, train_loss_epoch=0.012]Epoch 341: Train Loss = 0.013227706775069237\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 12.40it/s, v_num=358, train_loss_step=0.011, train_loss_epoch=0.0132] Epoch 342: Train Loss = 0.011042741127312183\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=358, train_loss_step=0.0137, train_loss_epoch=0.011]Epoch 343: Train Loss = 0.013675949536263943\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=358, train_loss_step=0.0162, train_loss_epoch=0.0137]Epoch 344: Train Loss = 0.016165921464562416\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=358, train_loss_step=0.0149, train_loss_epoch=0.0162]Epoch 345: Train Loss = 0.014937594532966614\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=358, train_loss_step=0.00826, train_loss_epoch=0.0149]Epoch 346: Train Loss = 0.00825631432235241\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=358, train_loss_step=0.0135, train_loss_epoch=0.00826] Epoch 347: Train Loss = 0.013512303121387959\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=358, train_loss_step=0.0085, train_loss_epoch=0.0135] Epoch 348: Train Loss = 0.008501756004989147\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, v_num=358, train_loss_step=0.00967, train_loss_epoch=0.0085]Epoch 349: Train Loss = 0.009665140882134438\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=358, train_loss_step=0.0101, train_loss_epoch=0.00967] Epoch 350: Train Loss = 0.010142339393496513\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=358, train_loss_step=0.0124, train_loss_epoch=0.0101] Epoch 351: Train Loss = 0.012371267192065716\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=358, train_loss_step=0.0126, train_loss_epoch=0.0124]Epoch 352: Train Loss = 0.012619680725038052\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=358, train_loss_step=0.0099, train_loss_epoch=0.0126]Epoch 353: Train Loss = 0.00989566557109356\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=358, train_loss_step=0.00952, train_loss_epoch=0.0099]Epoch 354: Train Loss = 0.009518399834632874\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=358, train_loss_step=0.00962, train_loss_epoch=0.00952]Epoch 355: Train Loss = 0.009624423459172249\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=358, train_loss_step=0.0101, train_loss_epoch=0.00962] Epoch 356: Train Loss = 0.010123327374458313\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.0101] Epoch 357: Train Loss = 0.010563666932284832\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=358, train_loss_step=0.0135, train_loss_epoch=0.0106]Epoch 358: Train Loss = 0.013500520028173923\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=358, train_loss_step=0.00947, train_loss_epoch=0.0135]Epoch 359: Train Loss = 0.009470125660300255\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=358, train_loss_step=0.0134, train_loss_epoch=0.00947] Epoch 360: Train Loss = 0.013392056338489056\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.0134] Epoch 361: Train Loss = 0.011377052403986454\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=358, train_loss_step=0.00738, train_loss_epoch=0.0114]Epoch 362: Train Loss = 0.007380629424005747\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=358, train_loss_step=0.0126, train_loss_epoch=0.00738] Epoch 363: Train Loss = 0.012636005878448486\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=358, train_loss_step=0.00997, train_loss_epoch=0.0126]Epoch 364: Train Loss = 0.00997434463351965\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.00997] Epoch 365: Train Loss = 0.01136111468076706\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=358, train_loss_step=0.00997, train_loss_epoch=0.0114]Epoch 366: Train Loss = 0.009972699917852879\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=358, train_loss_step=0.0119, train_loss_epoch=0.00997] Epoch 367: Train Loss = 0.011878645978868008\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=358, train_loss_step=0.0125, train_loss_epoch=0.0119] Epoch 368: Train Loss = 0.012462727725505829\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=358, train_loss_step=0.00992, train_loss_epoch=0.0125]Epoch 369: Train Loss = 0.009917871095240116\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=358, train_loss_step=0.0139, train_loss_epoch=0.00992] Epoch 370: Train Loss = 0.013949142768979073\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=358, train_loss_step=0.0124, train_loss_epoch=0.0139] Epoch 371: Train Loss = 0.0123602245002985\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=358, train_loss_step=0.00716, train_loss_epoch=0.0124]Epoch 372: Train Loss = 0.007164389826357365\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=358, train_loss_step=0.00967, train_loss_epoch=0.00716]Epoch 373: Train Loss = 0.009665587916970253\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=358, train_loss_step=0.0113, train_loss_epoch=0.00967] Epoch 374: Train Loss = 0.011300918646156788\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=358, train_loss_step=0.0103, train_loss_epoch=0.0113] Epoch 375: Train Loss = 0.010276754386723042\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=358, train_loss_step=0.00901, train_loss_epoch=0.0103]Epoch 376: Train Loss = 0.009011661633849144\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=358, train_loss_step=0.0102, train_loss_epoch=0.00901] Epoch 377: Train Loss = 0.0102090360596776\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.0102] Epoch 378: Train Loss = 0.01061241328716278\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=358, train_loss_step=0.00891, train_loss_epoch=0.0106]Epoch 379: Train Loss = 0.008914360776543617\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=358, train_loss_step=0.0118, train_loss_epoch=0.00891] Epoch 380: Train Loss = 0.01180566381663084\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=358, train_loss_step=0.0143, train_loss_epoch=0.0118] Epoch 381: Train Loss = 0.014347773976624012\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=358, train_loss_step=0.014, train_loss_epoch=0.0143] Epoch 382: Train Loss = 0.01397246215492487\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=358, train_loss_step=0.00974, train_loss_epoch=0.014]Epoch 383: Train Loss = 0.009737047366797924\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=358, train_loss_step=0.0113, train_loss_epoch=0.00974] Epoch 384: Train Loss = 0.011346870101988316\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=358, train_loss_step=0.00813, train_loss_epoch=0.0113]Epoch 385: Train Loss = 0.00812974851578474\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.00813] Epoch 386: Train Loss = 0.010521058924496174\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=358, train_loss_step=0.00931, train_loss_epoch=0.0105]Epoch 387: Train Loss = 0.00931358989328146\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=358, train_loss_step=0.00923, train_loss_epoch=0.00931]Epoch 388: Train Loss = 0.009232585318386555\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=358, train_loss_step=0.00857, train_loss_epoch=0.00923]Epoch 389: Train Loss = 0.008569859899580479\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=358, train_loss_step=0.0118, train_loss_epoch=0.00857] Epoch 390: Train Loss = 0.011833744123578072\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=358, train_loss_step=0.00914, train_loss_epoch=0.0118]Epoch 391: Train Loss = 0.009139343164861202\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.00914] Epoch 392: Train Loss = 0.010503202676773071\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=358, train_loss_step=0.0119, train_loss_epoch=0.0105] Epoch 393: Train Loss = 0.011949374340474606\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=358, train_loss_step=0.0102, train_loss_epoch=0.0119]Epoch 394: Train Loss = 0.010160592384636402\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 10.22it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.0102]Epoch 395: Train Loss = 0.011389468796551228\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=358, train_loss_step=0.00967, train_loss_epoch=0.0114]Epoch 396: Train Loss = 0.009672313928604126\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.00967] Epoch 397: Train Loss = 0.010601353831589222\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=358, train_loss_step=0.00925, train_loss_epoch=0.0106]Epoch 398: Train Loss = 0.009247838519513607\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.00925] Epoch 399: Train Loss = 0.011436653323471546\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=358, train_loss_step=0.0082, train_loss_epoch=0.0114] Epoch 400: Train Loss = 0.00820490438491106\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.0082]Epoch 401: Train Loss = 0.01089426875114441\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=358, train_loss_step=0.0115, train_loss_epoch=0.0109]Epoch 402: Train Loss = 0.011457577347755432\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=358, train_loss_step=0.00996, train_loss_epoch=0.0115]Epoch 403: Train Loss = 0.009964647702872753\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=358, train_loss_step=0.00996, train_loss_epoch=0.00996]Epoch 404: Train Loss = 0.00996492337435484\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=358, train_loss_step=0.00896, train_loss_epoch=0.00996]Epoch 405: Train Loss = 0.008961481042206287\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=358, train_loss_step=0.00999, train_loss_epoch=0.00896]Epoch 406: Train Loss = 0.009988016448915005\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=358, train_loss_step=0.00825, train_loss_epoch=0.00999]Epoch 407: Train Loss = 0.008246124722063541\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.00825] Epoch 408: Train Loss = 0.0103896614164114\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=358, train_loss_step=0.0123, train_loss_epoch=0.0104] Epoch 409: Train Loss = 0.012312392704188824\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=358, train_loss_step=0.00901, train_loss_epoch=0.0123]Epoch 410: Train Loss = 0.009011571295559406\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=358, train_loss_step=0.00961, train_loss_epoch=0.00901]Epoch 411: Train Loss = 0.009608988650143147\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=358, train_loss_step=0.0091, train_loss_epoch=0.00961] Epoch 412: Train Loss = 0.009102332405745983\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=358, train_loss_step=0.00743, train_loss_epoch=0.0091]Epoch 413: Train Loss = 0.0074340528808534145\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.00743] Epoch 414: Train Loss = 0.011353007517755032\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=358, train_loss_step=0.00689, train_loss_epoch=0.0114]Epoch 415: Train Loss = 0.006889874581247568\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.00689] Epoch 416: Train Loss = 0.01091469544917345\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.0109] Epoch 417: Train Loss = 0.010610927827656269\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=358, train_loss_step=0.00931, train_loss_epoch=0.0106]Epoch 418: Train Loss = 0.00931489747017622\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=358, train_loss_step=0.013, train_loss_epoch=0.00931]  Epoch 419: Train Loss = 0.013011159375309944\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=358, train_loss_step=0.0133, train_loss_epoch=0.013] Epoch 420: Train Loss = 0.013299592770636082\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=358, train_loss_step=0.00804, train_loss_epoch=0.0133]Epoch 421: Train Loss = 0.008043800480663776\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=358, train_loss_step=0.0112, train_loss_epoch=0.00804] Epoch 422: Train Loss = 0.011162358336150646\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=358, train_loss_step=0.00774, train_loss_epoch=0.0112]Epoch 423: Train Loss = 0.0077374884858727455\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=358, train_loss_step=0.0127, train_loss_epoch=0.00774] Epoch 424: Train Loss = 0.012727634981274605\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.0127] Epoch 425: Train Loss = 0.010914956219494343\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=358, train_loss_step=0.011, train_loss_epoch=0.0109] Epoch 426: Train Loss = 0.01097383163869381\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=358, train_loss_step=0.00953, train_loss_epoch=0.011]Epoch 427: Train Loss = 0.00953128281980753\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s, v_num=358, train_loss_step=0.00973, train_loss_epoch=0.00953]Epoch 428: Train Loss = 0.009728295728564262\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=358, train_loss_step=0.00874, train_loss_epoch=0.00973]Epoch 429: Train Loss = 0.008736510761082172\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=358, train_loss_step=0.0108, train_loss_epoch=0.00874] Epoch 430: Train Loss = 0.010806898586452007\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=358, train_loss_step=0.00966, train_loss_epoch=0.0108]Epoch 431: Train Loss = 0.009656200185418129\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=358, train_loss_step=0.0122, train_loss_epoch=0.00966] Epoch 432: Train Loss = 0.012206369079649448\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.0122] Epoch 433: Train Loss = 0.010568593628704548\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=358, train_loss_step=0.00756, train_loss_epoch=0.0106]Epoch 434: Train Loss = 0.00756134232506156\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=358, train_loss_step=0.00836, train_loss_epoch=0.00756]Epoch 435: Train Loss = 0.008355253376066685\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 11.64it/s, v_num=358, train_loss_step=0.00815, train_loss_epoch=0.00836]Epoch 436: Train Loss = 0.008145256899297237\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=358, train_loss_step=0.00868, train_loss_epoch=0.00815]Epoch 437: Train Loss = 0.008680825121700764\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=358, train_loss_step=0.00912, train_loss_epoch=0.00868]Epoch 438: Train Loss = 0.009120358154177666\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=358, train_loss_step=0.0106, train_loss_epoch=0.00912] Epoch 439: Train Loss = 0.010573625564575195\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=358, train_loss_step=0.0107, train_loss_epoch=0.0106] Epoch 440: Train Loss = 0.010705078020691872\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=358, train_loss_step=0.0122, train_loss_epoch=0.0107]Epoch 441: Train Loss = 0.012156191281974316\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=358, train_loss_step=0.00949, train_loss_epoch=0.0122]Epoch 442: Train Loss = 0.009486908093094826\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=358, train_loss_step=0.0122, train_loss_epoch=0.00949] Epoch 443: Train Loss = 0.012198156677186489\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=358, train_loss_step=0.0126, train_loss_epoch=0.0122] Epoch 444: Train Loss = 0.012641937471926212\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s, v_num=358, train_loss_step=0.00952, train_loss_epoch=0.0126]Epoch 445: Train Loss = 0.009523897431790829\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=358, train_loss_step=0.00738, train_loss_epoch=0.00952]Epoch 446: Train Loss = 0.00737961707636714\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=358, train_loss_step=0.00893, train_loss_epoch=0.00738]Epoch 447: Train Loss = 0.008934217505156994\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=358, train_loss_step=0.0108, train_loss_epoch=0.00893] Epoch 448: Train Loss = 0.010756240226328373\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=358, train_loss_step=0.00898, train_loss_epoch=0.0108]Epoch 449: Train Loss = 0.008979059755802155\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=358, train_loss_step=0.00871, train_loss_epoch=0.00898]Epoch 450: Train Loss = 0.008708243258297443\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=358, train_loss_step=0.010, train_loss_epoch=0.00871]  Epoch 451: Train Loss = 0.009996377862989902\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=358, train_loss_step=0.012, train_loss_epoch=0.010]  Epoch 452: Train Loss = 0.011984815821051598\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=358, train_loss_step=0.0132, train_loss_epoch=0.012]Epoch 453: Train Loss = 0.01321654673665762\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=358, train_loss_step=0.0145, train_loss_epoch=0.0132]Epoch 454: Train Loss = 0.014461284503340721\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=358, train_loss_step=0.0126, train_loss_epoch=0.0145]Epoch 455: Train Loss = 0.0126018226146698\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.0126]Epoch 456: Train Loss = 0.01139947958290577\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.0114]Epoch 457: Train Loss = 0.01048271544277668\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=358, train_loss_step=0.0112, train_loss_epoch=0.0105]Epoch 458: Train Loss = 0.011213227175176144\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 10.28it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.0112]Epoch 459: Train Loss = 0.010874925181269646\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=358, train_loss_step=0.00859, train_loss_epoch=0.0109]Epoch 460: Train Loss = 0.008594841696321964\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.00859] Epoch 461: Train Loss = 0.010491023771464825\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=358, train_loss_step=0.00845, train_loss_epoch=0.0105]Epoch 462: Train Loss = 0.00845388974994421\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=358, train_loss_step=0.0133, train_loss_epoch=0.00845] Epoch 463: Train Loss = 0.013307901099324226\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=358, train_loss_step=0.0117, train_loss_epoch=0.0133] Epoch 464: Train Loss = 0.011681245639920235\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=358, train_loss_step=0.011, train_loss_epoch=0.0117] Epoch 465: Train Loss = 0.011007624678313732\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=358, train_loss_step=0.0087, train_loss_epoch=0.011]Epoch 466: Train Loss = 0.008699535392224789\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=358, train_loss_step=0.0119, train_loss_epoch=0.0087]Epoch 467: Train Loss = 0.011927662417292595\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=358, train_loss_step=0.00888, train_loss_epoch=0.0119]Epoch 468: Train Loss = 0.008877667598426342\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=358, train_loss_step=0.0102, train_loss_epoch=0.00888] Epoch 469: Train Loss = 0.010224987752735615\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=358, train_loss_step=0.00946, train_loss_epoch=0.0102]Epoch 470: Train Loss = 0.00946339312940836\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=358, train_loss_step=0.0129, train_loss_epoch=0.00946] Epoch 471: Train Loss = 0.012905837036669254\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=358, train_loss_step=0.00725, train_loss_epoch=0.0129]Epoch 472: Train Loss = 0.007245327811688185\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.00725] Epoch 473: Train Loss = 0.01042164210230112\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=358, train_loss_step=0.0122, train_loss_epoch=0.0104] Epoch 474: Train Loss = 0.01221474353224039\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=358, train_loss_step=0.0117, train_loss_epoch=0.0122]Epoch 475: Train Loss = 0.011658640578389168\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=358, train_loss_step=0.0103, train_loss_epoch=0.0117]Epoch 476: Train Loss = 0.010309743694961071\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=358, train_loss_step=0.0108, train_loss_epoch=0.0103]Epoch 477: Train Loss = 0.01076370570808649\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=358, train_loss_step=0.00981, train_loss_epoch=0.0108]Epoch 478: Train Loss = 0.009812605567276478\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=358, train_loss_step=0.00986, train_loss_epoch=0.00981]Epoch 479: Train Loss = 0.009860144928097725\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=358, train_loss_step=0.0109, train_loss_epoch=0.00986] Epoch 480: Train Loss = 0.010887215845286846\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=358, train_loss_step=0.012, train_loss_epoch=0.0109]  Epoch 481: Train Loss = 0.012026038952171803\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=358, train_loss_step=0.0118, train_loss_epoch=0.012]Epoch 482: Train Loss = 0.011771084740757942\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=358, train_loss_step=0.00723, train_loss_epoch=0.0118]Epoch 483: Train Loss = 0.007231865543872118\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=358, train_loss_step=0.00948, train_loss_epoch=0.00723]Epoch 484: Train Loss = 0.009483654983341694\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=358, train_loss_step=0.00917, train_loss_epoch=0.00948]Epoch 485: Train Loss = 0.009168686345219612\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=358, train_loss_step=0.0114, train_loss_epoch=0.00917] Epoch 486: Train Loss = 0.011355219408869743\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=358, train_loss_step=0.00934, train_loss_epoch=0.0114]Epoch 487: Train Loss = 0.009336784482002258\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=358, train_loss_step=0.0102, train_loss_epoch=0.00934] Epoch 488: Train Loss = 0.010226542130112648\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=358, train_loss_step=0.0147, train_loss_epoch=0.0102] Epoch 489: Train Loss = 0.014706759713590145\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=358, train_loss_step=0.00929, train_loss_epoch=0.0147]Epoch 490: Train Loss = 0.00929008424282074\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s, v_num=358, train_loss_step=0.0104, train_loss_epoch=0.00929] Epoch 491: Train Loss = 0.010358503088355064\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=358, train_loss_step=0.0103, train_loss_epoch=0.0104] Epoch 492: Train Loss = 0.010326465591788292\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=358, train_loss_step=0.0127, train_loss_epoch=0.0103]Epoch 493: Train Loss = 0.012668771669268608\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=358, train_loss_step=0.0105, train_loss_epoch=0.0127]Epoch 494: Train Loss = 0.010478958487510681\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=358, train_loss_step=0.00819, train_loss_epoch=0.0105]Epoch 495: Train Loss = 0.008191509172320366\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=358, train_loss_step=0.00942, train_loss_epoch=0.00819]Epoch 496: Train Loss = 0.009415834210813046\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=358, train_loss_step=0.0108, train_loss_epoch=0.00942] Epoch 497: Train Loss = 0.010838878341019154\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=358, train_loss_step=0.0123, train_loss_epoch=0.0108] Epoch 498: Train Loss = 0.012300734408199787\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=358, train_loss_step=0.00834, train_loss_epoch=0.0123]Epoch 499: Train Loss = 0.008337507024407387\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=358, train_loss_step=0.00834, train_loss_epoch=0.00834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=358, train_loss_step=0.00834, train_loss_epoch=0.00834]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 30.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 11: from 2008-05-12 00:00:00 to 2022-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=362, train_loss_step=0.0241]Epoch 0: Train Loss = 0.024145279079675674\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=362, train_loss_step=0.0368, train_loss_epoch=0.0241]Epoch 1: Train Loss = 0.03678528219461441\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=362, train_loss_step=0.0236, train_loss_epoch=0.0368]Epoch 2: Train Loss = 0.023623529821634293\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=362, train_loss_step=0.0326, train_loss_epoch=0.0236]Epoch 3: Train Loss = 0.032645080238580704\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=362, train_loss_step=0.0203, train_loss_epoch=0.0326]Epoch 4: Train Loss = 0.02025490626692772\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=362, train_loss_step=0.0113, train_loss_epoch=0.0203]Epoch 5: Train Loss = 0.011340194381773472\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=362, train_loss_step=0.0136, train_loss_epoch=0.0113]Epoch 6: Train Loss = 0.013587922789156437\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=362, train_loss_step=0.0136, train_loss_epoch=0.0136]Epoch 7: Train Loss = 0.013629334978759289\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=362, train_loss_step=0.0133, train_loss_epoch=0.0136]Epoch 8: Train Loss = 0.013337761163711548\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=362, train_loss_step=0.0125, train_loss_epoch=0.0133]Epoch 9: Train Loss = 0.012491944245994091\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.0125]Epoch 10: Train Loss = 0.0108179384842515\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=362, train_loss_step=0.0149, train_loss_epoch=0.0108]Epoch 11: Train Loss = 0.014868098311126232\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=362, train_loss_step=0.0116, train_loss_epoch=0.0149]Epoch 12: Train Loss = 0.011559808626770973\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.0116]Epoch 13: Train Loss = 0.010224328376352787\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=362, train_loss_step=0.0139, train_loss_epoch=0.0102]Epoch 14: Train Loss = 0.013860119506716728\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=362, train_loss_step=0.0122, train_loss_epoch=0.0139]Epoch 15: Train Loss = 0.012248239479959011\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=362, train_loss_step=0.013, train_loss_epoch=0.0122] Epoch 16: Train Loss = 0.01300672348588705\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=362, train_loss_step=0.0118, train_loss_epoch=0.013]Epoch 17: Train Loss = 0.011800924316048622\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=362, train_loss_step=0.017, train_loss_epoch=0.0118] Epoch 18: Train Loss = 0.017015602439641953\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=362, train_loss_step=0.0122, train_loss_epoch=0.017]Epoch 19: Train Loss = 0.012225975282490253\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=362, train_loss_step=0.0116, train_loss_epoch=0.0122]Epoch 20: Train Loss = 0.011550848372280598\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=362, train_loss_step=0.0145, train_loss_epoch=0.0116]Epoch 21: Train Loss = 0.014521373435854912\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=362, train_loss_step=0.0118, train_loss_epoch=0.0145]Epoch 22: Train Loss = 0.011757641099393368\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 10.45it/s, v_num=362, train_loss_step=0.0117, train_loss_epoch=0.0118]Epoch 23: Train Loss = 0.011682165786623955\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=362, train_loss_step=0.0145, train_loss_epoch=0.0117]Epoch 24: Train Loss = 0.014476323500275612\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=362, train_loss_step=0.0127, train_loss_epoch=0.0145]Epoch 25: Train Loss = 0.012717695906758308\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0127]Epoch 26: Train Loss = 0.01234012097120285\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=362, train_loss_step=0.0124, train_loss_epoch=0.0123]Epoch 27: Train Loss = 0.012432479299604893\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=362, train_loss_step=0.0117, train_loss_epoch=0.0124]Epoch 28: Train Loss = 0.011667913757264614\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s, v_num=362, train_loss_step=0.0178, train_loss_epoch=0.0117]Epoch 29: Train Loss = 0.017768939957022667\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=362, train_loss_step=0.0107, train_loss_epoch=0.0178]Epoch 30: Train Loss = 0.010746235959231853\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=362, train_loss_step=0.0171, train_loss_epoch=0.0107]Epoch 31: Train Loss = 0.017100682482123375\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=362, train_loss_step=0.0115, train_loss_epoch=0.0171]Epoch 32: Train Loss = 0.011537499725818634\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=362, train_loss_step=0.00971, train_loss_epoch=0.0115]Epoch 33: Train Loss = 0.009710912592709064\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=362, train_loss_step=0.00965, train_loss_epoch=0.00971]Epoch 34: Train Loss = 0.009654013440012932\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=362, train_loss_step=0.0117, train_loss_epoch=0.00965] Epoch 35: Train Loss = 0.011720091104507446\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0117] Epoch 36: Train Loss = 0.012277832254767418\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=362, train_loss_step=0.0107, train_loss_epoch=0.0123]Epoch 37: Train Loss = 0.010701483115553856\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0107]Epoch 38: Train Loss = 0.010549282655119896\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=362, train_loss_step=0.0116, train_loss_epoch=0.0105]Epoch 39: Train Loss = 0.011584888212382793\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.0116]Epoch 40: Train Loss = 0.010828324593603611\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=362, train_loss_step=0.00944, train_loss_epoch=0.0108]Epoch 41: Train Loss = 0.009443520568311214\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=362, train_loss_step=0.0119, train_loss_epoch=0.00944] Epoch 42: Train Loss = 0.011908967979252338\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=362, train_loss_step=0.00869, train_loss_epoch=0.0119]Epoch 43: Train Loss = 0.008689283393323421\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=362, train_loss_step=0.00912, train_loss_epoch=0.00869]Epoch 44: Train Loss = 0.009120090864598751\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.00912] Epoch 45: Train Loss = 0.012088371440768242\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=362, train_loss_step=0.0111, train_loss_epoch=0.0121] Epoch 46: Train Loss = 0.011129251681268215\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=362, train_loss_step=0.0135, train_loss_epoch=0.0111]Epoch 47: Train Loss = 0.013496882282197475\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=362, train_loss_step=0.0125, train_loss_epoch=0.0135]Epoch 48: Train Loss = 0.012525981292128563\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.0125] Epoch 49: Train Loss = 0.010002397000789642\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=362, train_loss_step=0.00975, train_loss_epoch=0.010]Epoch 50: Train Loss = 0.009745900519192219\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=362, train_loss_step=0.00817, train_loss_epoch=0.00975]Epoch 51: Train Loss = 0.008170063607394695\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=362, train_loss_step=0.00895, train_loss_epoch=0.00817]Epoch 52: Train Loss = 0.008952080272138119\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=362, train_loss_step=0.0106, train_loss_epoch=0.00895] Epoch 53: Train Loss = 0.01057893130928278\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.0106] Epoch 54: Train Loss = 0.010774741880595684\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=362, train_loss_step=0.0111, train_loss_epoch=0.0108]Epoch 55: Train Loss = 0.011137501336634159\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=362, train_loss_step=0.0111, train_loss_epoch=0.0111]Epoch 56: Train Loss = 0.011114746332168579\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=362, train_loss_step=0.00874, train_loss_epoch=0.0111]Epoch 57: Train Loss = 0.008740771561861038\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=362, train_loss_step=0.0111, train_loss_epoch=0.00874] Epoch 58: Train Loss = 0.011074586771428585\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=362, train_loss_step=0.00951, train_loss_epoch=0.0111]Epoch 59: Train Loss = 0.009508312679827213\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s, v_num=362, train_loss_step=0.0158, train_loss_epoch=0.00951] Epoch 60: Train Loss = 0.01580183021724224\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=362, train_loss_step=0.00974, train_loss_epoch=0.0158]Epoch 61: Train Loss = 0.009735352359712124\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=362, train_loss_step=0.0104, train_loss_epoch=0.00974] Epoch 62: Train Loss = 0.010396384634077549\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 11.46it/s, v_num=362, train_loss_step=0.00932, train_loss_epoch=0.0104]Epoch 63: Train Loss = 0.009316434152424335\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=362, train_loss_step=0.00996, train_loss_epoch=0.00932]Epoch 64: Train Loss = 0.009958460927009583\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=362, train_loss_step=0.00932, train_loss_epoch=0.00996]Epoch 65: Train Loss = 0.009315671399235725\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.00932]  Epoch 66: Train Loss = 0.010042120702564716\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=362, train_loss_step=0.0124, train_loss_epoch=0.010] Epoch 67: Train Loss = 0.012402655556797981\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=362, train_loss_step=0.00956, train_loss_epoch=0.0124]Epoch 68: Train Loss = 0.009559767320752144\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=362, train_loss_step=0.00816, train_loss_epoch=0.00956]Epoch 69: Train Loss = 0.008162228390574455\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=362, train_loss_step=0.0126, train_loss_epoch=0.00816] Epoch 70: Train Loss = 0.012586407363414764\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=362, train_loss_step=0.00948, train_loss_epoch=0.0126]Epoch 71: Train Loss = 0.009478612802922726\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=362, train_loss_step=0.0125, train_loss_epoch=0.00948] Epoch 72: Train Loss = 0.012503264471888542\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=362, train_loss_step=0.0107, train_loss_epoch=0.0125] Epoch 73: Train Loss = 0.010749484412372112\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 10.49it/s, v_num=362, train_loss_step=0.0092, train_loss_epoch=0.0107]Epoch 74: Train Loss = 0.009198935702443123\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 12.40it/s, v_num=362, train_loss_step=0.00914, train_loss_epoch=0.0092]Epoch 75: Train Loss = 0.009136485867202282\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=362, train_loss_step=0.00982, train_loss_epoch=0.00914]Epoch 76: Train Loss = 0.00981671642512083\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=362, train_loss_step=0.0114, train_loss_epoch=0.00982] Epoch 77: Train Loss = 0.01139173936098814\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 10.71it/s, v_num=362, train_loss_step=0.00962, train_loss_epoch=0.0114]Epoch 78: Train Loss = 0.009616171009838581\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=362, train_loss_step=0.00879, train_loss_epoch=0.00962]Epoch 79: Train Loss = 0.00878687109798193\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=362, train_loss_step=0.0097, train_loss_epoch=0.00879] Epoch 80: Train Loss = 0.009700106456875801\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=362, train_loss_step=0.0137, train_loss_epoch=0.0097] Epoch 81: Train Loss = 0.013716233894228935\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=362, train_loss_step=0.00917, train_loss_epoch=0.0137]Epoch 82: Train Loss = 0.009169583208858967\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=362, train_loss_step=0.0139, train_loss_epoch=0.00917] Epoch 83: Train Loss = 0.01385373156517744\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=362, train_loss_step=0.0122, train_loss_epoch=0.0139] Epoch 84: Train Loss = 0.012207484804093838\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.0122]Epoch 85: Train Loss = 0.010259070433676243\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=362, train_loss_step=0.00956, train_loss_epoch=0.0103]Epoch 86: Train Loss = 0.009557873010635376\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.00956] Epoch 87: Train Loss = 0.012067755684256554\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0121] Epoch 88: Train Loss = 0.010541136376559734\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=362, train_loss_step=0.0125, train_loss_epoch=0.0105]Epoch 89: Train Loss = 0.012463243678212166\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.0125]Epoch 90: Train Loss = 0.010806074365973473\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=362, train_loss_step=0.0122, train_loss_epoch=0.0108]Epoch 91: Train Loss = 0.012198644690215588\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, v_num=362, train_loss_step=0.0139, train_loss_epoch=0.0122]Epoch 92: Train Loss = 0.01392441987991333\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=362, train_loss_step=0.0128, train_loss_epoch=0.0139]Epoch 93: Train Loss = 0.012848054990172386\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s, v_num=362, train_loss_step=0.0111, train_loss_epoch=0.0128]Epoch 94: Train Loss = 0.01109685841947794\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=362, train_loss_step=0.0119, train_loss_epoch=0.0111]Epoch 95: Train Loss = 0.01188348326832056\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.0119]Epoch 96: Train Loss = 0.010286228731274605\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=362, train_loss_step=0.0109, train_loss_epoch=0.0103]Epoch 97: Train Loss = 0.010933900251984596\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=362, train_loss_step=0.0167, train_loss_epoch=0.0109]Epoch 98: Train Loss = 0.01667163521051407\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=362, train_loss_step=0.0112, train_loss_epoch=0.0167]Epoch 99: Train Loss = 0.011239109560847282\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=362, train_loss_step=0.00845, train_loss_epoch=0.0112]Epoch 100: Train Loss = 0.008450446650385857\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=362, train_loss_step=0.00941, train_loss_epoch=0.00845]Epoch 101: Train Loss = 0.009413248859345913\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.00941]  Epoch 102: Train Loss = 0.010011911392211914\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=362, train_loss_step=0.0126, train_loss_epoch=0.010] Epoch 103: Train Loss = 0.01264506857842207\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=362, train_loss_step=0.0107, train_loss_epoch=0.0126]Epoch 104: Train Loss = 0.010683711618185043\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 12.09it/s, v_num=362, train_loss_step=0.016, train_loss_epoch=0.0107] Epoch 105: Train Loss = 0.01600133813917637\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=362, train_loss_step=0.00895, train_loss_epoch=0.016]Epoch 106: Train Loss = 0.008952987380325794\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=362, train_loss_step=0.0113, train_loss_epoch=0.00895] Epoch 107: Train Loss = 0.011301391758024693\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=362, train_loss_step=0.00801, train_loss_epoch=0.0113]Epoch 108: Train Loss = 0.008006198331713676\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=362, train_loss_step=0.0141, train_loss_epoch=0.00801] Epoch 109: Train Loss = 0.014063782058656216\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=362, train_loss_step=0.0119, train_loss_epoch=0.0141] Epoch 110: Train Loss = 0.01191078033298254\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=362, train_loss_step=0.00986, train_loss_epoch=0.0119]Epoch 111: Train Loss = 0.009857354685664177\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=362, train_loss_step=0.011, train_loss_epoch=0.00986]  Epoch 112: Train Loss = 0.010983888991177082\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 11.34it/s, v_num=362, train_loss_step=0.012, train_loss_epoch=0.011]  Epoch 113: Train Loss = 0.01197992917150259\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.012]Epoch 114: Train Loss = 0.012310312129557133\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=362, train_loss_step=0.00872, train_loss_epoch=0.0123]Epoch 115: Train Loss = 0.008717415854334831\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=362, train_loss_step=0.0141, train_loss_epoch=0.00872] Epoch 116: Train Loss = 0.014091060496866703\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=362, train_loss_step=0.0124, train_loss_epoch=0.0141] Epoch 117: Train Loss = 0.012388566508889198\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=362, train_loss_step=0.0147, train_loss_epoch=0.0124]Epoch 118: Train Loss = 0.01467538345605135\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=362, train_loss_step=0.0095, train_loss_epoch=0.0147]Epoch 119: Train Loss = 0.009502643719315529\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=362, train_loss_step=0.00872, train_loss_epoch=0.0095]Epoch 120: Train Loss = 0.008716078475117683\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.00872] Epoch 121: Train Loss = 0.012272195890545845\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=362, train_loss_step=0.0139, train_loss_epoch=0.0123] Epoch 122: Train Loss = 0.013891400769352913\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=362, train_loss_step=0.0141, train_loss_epoch=0.0139]Epoch 123: Train Loss = 0.014078058302402496\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.0141]Epoch 124: Train Loss = 0.01020241342484951\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=362, train_loss_step=0.0129, train_loss_epoch=0.0102]Epoch 125: Train Loss = 0.012903032824397087\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=362, train_loss_step=0.0106, train_loss_epoch=0.0129]Epoch 126: Train Loss = 0.010638887993991375\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0106]Epoch 127: Train Loss = 0.010458702221512794\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.0105]Epoch 128: Train Loss = 0.01026215311139822\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=362, train_loss_step=0.0126, train_loss_epoch=0.0103]Epoch 129: Train Loss = 0.01260547898709774\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.0126]Epoch 130: Train Loss = 0.010320614092051983\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=362, train_loss_step=0.00996, train_loss_epoch=0.0103]Epoch 131: Train Loss = 0.009959396906197071\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=362, train_loss_step=0.0112, train_loss_epoch=0.00996] Epoch 132: Train Loss = 0.01116927620023489\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0112] Epoch 133: Train Loss = 0.012260223738849163\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=362, train_loss_step=0.0119, train_loss_epoch=0.0123]Epoch 134: Train Loss = 0.011864500120282173\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=362, train_loss_step=0.00982, train_loss_epoch=0.0119]Epoch 135: Train Loss = 0.00981973297894001\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=362, train_loss_step=0.0109, train_loss_epoch=0.00982] Epoch 136: Train Loss = 0.01091959048062563\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=362, train_loss_step=0.0104, train_loss_epoch=0.0109] Epoch 137: Train Loss = 0.010407495312392712\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=362, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 138: Train Loss = 0.011548934504389763\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.0115]Epoch 139: Train Loss = 0.012140401639044285\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s, v_num=362, train_loss_step=0.0118, train_loss_epoch=0.0121]Epoch 140: Train Loss = 0.01184052973985672\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=362, train_loss_step=0.00956, train_loss_epoch=0.0118]Epoch 141: Train Loss = 0.009562479332089424\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=362, train_loss_step=0.00983, train_loss_epoch=0.00956]Epoch 142: Train Loss = 0.00982869602739811\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 10.67it/s, v_num=362, train_loss_step=0.0089, train_loss_epoch=0.00983] Epoch 143: Train Loss = 0.008896826766431332\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=362, train_loss_step=0.0104, train_loss_epoch=0.0089] Epoch 144: Train Loss = 0.01035026740282774\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=362, train_loss_step=0.0126, train_loss_epoch=0.0104]Epoch 145: Train Loss = 0.012602110393345356\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=362, train_loss_step=0.0147, train_loss_epoch=0.0126]Epoch 146: Train Loss = 0.014687742106616497\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=362, train_loss_step=0.0143, train_loss_epoch=0.0147]Epoch 147: Train Loss = 0.014260969124734402\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=362, train_loss_step=0.0104, train_loss_epoch=0.0143]Epoch 148: Train Loss = 0.01040587853640318\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=362, train_loss_step=0.0104, train_loss_epoch=0.0104]Epoch 149: Train Loss = 0.010393488220870495\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.0104]Epoch 150: Train Loss = 0.012109673582017422\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=362, train_loss_step=0.0152, train_loss_epoch=0.0121]Epoch 151: Train Loss = 0.015178070403635502\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=362, train_loss_step=0.0089, train_loss_epoch=0.0152]Epoch 152: Train Loss = 0.008902489207684994\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=362, train_loss_step=0.0135, train_loss_epoch=0.0089]Epoch 153: Train Loss = 0.013542423956096172\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=362, train_loss_step=0.0156, train_loss_epoch=0.0135]Epoch 154: Train Loss = 0.01558635849505663\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=362, train_loss_step=0.0115, train_loss_epoch=0.0156]Epoch 155: Train Loss = 0.01152706891298294\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=362, train_loss_step=0.0133, train_loss_epoch=0.0115]Epoch 156: Train Loss = 0.013315275311470032\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=362, train_loss_step=0.0112, train_loss_epoch=0.0133]Epoch 157: Train Loss = 0.011157608591020107\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=362, train_loss_step=0.0116, train_loss_epoch=0.0112]Epoch 158: Train Loss = 0.011607304215431213\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=362, train_loss_step=0.0122, train_loss_epoch=0.0116]Epoch 159: Train Loss = 0.012176541611552238\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.0122]Epoch 160: Train Loss = 0.010206061415374279\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=362, train_loss_step=0.0146, train_loss_epoch=0.0102]Epoch 161: Train Loss = 0.014625294134020805\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=362, train_loss_step=0.0107, train_loss_epoch=0.0146]Epoch 162: Train Loss = 0.010705581866204739\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=362, train_loss_step=0.0127, train_loss_epoch=0.0107]Epoch 163: Train Loss = 0.012677550315856934\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=362, train_loss_step=0.00862, train_loss_epoch=0.0127]Epoch 164: Train Loss = 0.008623750880360603\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=362, train_loss_step=0.00932, train_loss_epoch=0.00862]Epoch 165: Train Loss = 0.009316012263298035\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=362, train_loss_step=0.0124, train_loss_epoch=0.00932] Epoch 166: Train Loss = 0.012380076572299004\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=362, train_loss_step=0.0145, train_loss_epoch=0.0124] Epoch 167: Train Loss = 0.014509889297187328\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=362, train_loss_step=0.0127, train_loss_epoch=0.0145]Epoch 168: Train Loss = 0.012681975029408932\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=362, train_loss_step=0.0128, train_loss_epoch=0.0127]Epoch 169: Train Loss = 0.012818233110010624\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=362, train_loss_step=0.0109, train_loss_epoch=0.0128]Epoch 170: Train Loss = 0.010942305438220501\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=362, train_loss_step=0.0131, train_loss_epoch=0.0109]Epoch 171: Train Loss = 0.013071437366306782\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=362, train_loss_step=0.0128, train_loss_epoch=0.0131]Epoch 172: Train Loss = 0.012845213524997234\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=362, train_loss_step=0.00945, train_loss_epoch=0.0128]Epoch 173: Train Loss = 0.009445645846426487\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.00945] Epoch 174: Train Loss = 0.010165204294025898\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=362, train_loss_step=0.0141, train_loss_epoch=0.0102] Epoch 175: Train Loss = 0.014125069603323936\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=362, train_loss_step=0.0126, train_loss_epoch=0.0141]Epoch 176: Train Loss = 0.01263689436018467\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.0126]Epoch 177: Train Loss = 0.010844503529369831\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.0108]Epoch 178: Train Loss = 0.010177670046687126\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=362, train_loss_step=0.00827, train_loss_epoch=0.0102]Epoch 179: Train Loss = 0.008272475562989712\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.00827] Epoch 180: Train Loss = 0.0107884481549263\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=362, train_loss_step=0.0149, train_loss_epoch=0.0108] Epoch 181: Train Loss = 0.014850026927888393\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=362, train_loss_step=0.0118, train_loss_epoch=0.0149]Epoch 182: Train Loss = 0.011826934292912483\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0118]Epoch 183: Train Loss = 0.010516597889363766\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.0105]Epoch 184: Train Loss = 0.010284650139510632\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.0103]Epoch 185: Train Loss = 0.010182109661400318\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=362, train_loss_step=0.0107, train_loss_epoch=0.0102]Epoch 186: Train Loss = 0.01068310160189867\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=362, train_loss_step=0.00887, train_loss_epoch=0.0107]Epoch 187: Train Loss = 0.008869277313351631\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=362, train_loss_step=0.0088, train_loss_epoch=0.00887] Epoch 188: Train Loss = 0.008802228607237339\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=362, train_loss_step=0.0131, train_loss_epoch=0.0088] Epoch 189: Train Loss = 0.01314040832221508\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=362, train_loss_step=0.0146, train_loss_epoch=0.0131]Epoch 190: Train Loss = 0.014551835134625435\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=362, train_loss_step=0.0104, train_loss_epoch=0.0146]Epoch 191: Train Loss = 0.010359937325119972\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=362, train_loss_step=0.0101, train_loss_epoch=0.0104]Epoch 192: Train Loss = 0.010138658806681633\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.0101]Epoch 193: Train Loss = 0.012111741118133068\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s, v_num=362, train_loss_step=0.0118, train_loss_epoch=0.0121]Epoch 194: Train Loss = 0.011849747970700264\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=362, train_loss_step=0.00979, train_loss_epoch=0.0118]Epoch 195: Train Loss = 0.009788439609110355\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=362, train_loss_step=0.0142, train_loss_epoch=0.00979] Epoch 196: Train Loss = 0.014245995320379734\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=362, train_loss_step=0.0107, train_loss_epoch=0.0142] Epoch 197: Train Loss = 0.010655811987817287\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=362, train_loss_step=0.0156, train_loss_epoch=0.0107]Epoch 198: Train Loss = 0.015557696111500263\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=362, train_loss_step=0.0115, train_loss_epoch=0.0156]Epoch 199: Train Loss = 0.011501695029437542\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0115]Epoch 200: Train Loss = 0.010538160800933838\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=362, train_loss_step=0.0112, train_loss_epoch=0.0105]Epoch 201: Train Loss = 0.011180155910551548\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=362, train_loss_step=0.0114, train_loss_epoch=0.0112]Epoch 202: Train Loss = 0.011425691656768322\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.0114] Epoch 203: Train Loss = 0.010008624754846096\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=362, train_loss_step=0.0125, train_loss_epoch=0.010]Epoch 204: Train Loss = 0.012456919066607952\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=362, train_loss_step=0.00881, train_loss_epoch=0.0125]Epoch 205: Train Loss = 0.008805678226053715\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=362, train_loss_step=0.0115, train_loss_epoch=0.00881] Epoch 206: Train Loss = 0.011450588703155518\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=362, train_loss_step=0.0143, train_loss_epoch=0.0115] Epoch 207: Train Loss = 0.01431369874626398\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=362, train_loss_step=0.00786, train_loss_epoch=0.0143]Epoch 208: Train Loss = 0.007858983241021633\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s, v_num=362, train_loss_step=0.00933, train_loss_epoch=0.00786]Epoch 209: Train Loss = 0.009330627508461475\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=362, train_loss_step=0.00948, train_loss_epoch=0.00933]Epoch 210: Train Loss = 0.009478083811700344\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=362, train_loss_step=0.0126, train_loss_epoch=0.00948] Epoch 211: Train Loss = 0.012605362571775913\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=362, train_loss_step=0.0115, train_loss_epoch=0.0126] Epoch 212: Train Loss = 0.011456524021923542\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.0115]Epoch 213: Train Loss = 0.010191707871854305\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=362, train_loss_step=0.013, train_loss_epoch=0.0102] Epoch 214: Train Loss = 0.013040287420153618\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=362, train_loss_step=0.0128, train_loss_epoch=0.013]Epoch 215: Train Loss = 0.012804917059838772\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.0128]Epoch 216: Train Loss = 0.012067468836903572\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0121]Epoch 217: Train Loss = 0.01229932066053152\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=362, train_loss_step=0.0101, train_loss_epoch=0.0123]Epoch 218: Train Loss = 0.010050525888800621\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=362, train_loss_step=0.00873, train_loss_epoch=0.0101]Epoch 219: Train Loss = 0.00872705690562725\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=362, train_loss_step=0.013, train_loss_epoch=0.00873]  Epoch 220: Train Loss = 0.012977796606719494\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.013] Epoch 221: Train Loss = 0.010521781630814075\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0105]Epoch 222: Train Loss = 0.010465300641953945\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.0105]Epoch 223: Train Loss = 0.012074166908860207\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=362, train_loss_step=0.0131, train_loss_epoch=0.0121]Epoch 224: Train Loss = 0.013073146343231201\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=362, train_loss_step=0.0111, train_loss_epoch=0.0131]Epoch 225: Train Loss = 0.011066789738833904\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=362, train_loss_step=0.0163, train_loss_epoch=0.0111]Epoch 226: Train Loss = 0.01628519967198372\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=362, train_loss_step=0.0125, train_loss_epoch=0.0163]Epoch 227: Train Loss = 0.012474131770431995\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s, v_num=362, train_loss_step=0.0145, train_loss_epoch=0.0125]Epoch 228: Train Loss = 0.014486351981759071\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=362, train_loss_step=0.0127, train_loss_epoch=0.0145]Epoch 229: Train Loss = 0.012736650183796883\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.0127] Epoch 230: Train Loss = 0.010032623074948788\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s, v_num=362, train_loss_step=0.00897, train_loss_epoch=0.010]Epoch 231: Train Loss = 0.008967885747551918\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=362, train_loss_step=0.0116, train_loss_epoch=0.00897] Epoch 232: Train Loss = 0.01163694728165865\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0116] Epoch 233: Train Loss = 0.01232320349663496\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0123]Epoch 234: Train Loss = 0.012299785390496254\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=362, train_loss_step=0.00964, train_loss_epoch=0.0123]Epoch 235: Train Loss = 0.009642437100410461\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=362, train_loss_step=0.0128, train_loss_epoch=0.00964] Epoch 236: Train Loss = 0.01282937079668045\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=362, train_loss_step=0.0101, train_loss_epoch=0.0128] Epoch 237: Train Loss = 0.010110782459378242\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=362, train_loss_step=0.0114, train_loss_epoch=0.0101]Epoch 238: Train Loss = 0.011445875279605389\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.0114]Epoch 239: Train Loss = 0.012126682326197624\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=362, train_loss_step=0.0119, train_loss_epoch=0.0121]Epoch 240: Train Loss = 0.011892227455973625\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=362, train_loss_step=0.00849, train_loss_epoch=0.0119]Epoch 241: Train Loss = 0.008491717278957367\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.00849] Epoch 242: Train Loss = 0.010196051560342312\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=362, train_loss_step=0.0106, train_loss_epoch=0.0102] Epoch 243: Train Loss = 0.0106055261567235\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=362, train_loss_step=0.00916, train_loss_epoch=0.0106]Epoch 244: Train Loss = 0.009160219691693783\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=362, train_loss_step=0.0106, train_loss_epoch=0.00916] Epoch 245: Train Loss = 0.010640842840075493\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=362, train_loss_step=0.0116, train_loss_epoch=0.0106] Epoch 246: Train Loss = 0.011566475965082645\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.0116] Epoch 247: Train Loss = 0.010017240419983864\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=362, train_loss_step=0.0161, train_loss_epoch=0.010]Epoch 248: Train Loss = 0.016065388917922974\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=362, train_loss_step=0.0106, train_loss_epoch=0.0161]Epoch 249: Train Loss = 0.01059103012084961\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=362, train_loss_step=0.00977, train_loss_epoch=0.0106]Epoch 250: Train Loss = 0.009765836410224438\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=362, train_loss_step=0.00796, train_loss_epoch=0.00977]Epoch 251: Train Loss = 0.007957044057548046\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=362, train_loss_step=0.00966, train_loss_epoch=0.00796]Epoch 252: Train Loss = 0.009656998328864574\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=362, train_loss_step=0.00899, train_loss_epoch=0.00966]Epoch 253: Train Loss = 0.008991611190140247\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s, v_num=362, train_loss_step=0.00905, train_loss_epoch=0.00899]Epoch 254: Train Loss = 0.009049096144735813\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=362, train_loss_step=0.00896, train_loss_epoch=0.00905]Epoch 255: Train Loss = 0.00896462518721819\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=362, train_loss_step=0.0135, train_loss_epoch=0.00896] Epoch 256: Train Loss = 0.013538213446736336\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=362, train_loss_step=0.0084, train_loss_epoch=0.0135] Epoch 257: Train Loss = 0.008395345881581306\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.0084]Epoch 258: Train Loss = 0.010339869186282158\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=362, train_loss_step=0.0127, train_loss_epoch=0.0103]Epoch 259: Train Loss = 0.012713725678622723\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=362, train_loss_step=0.0099, train_loss_epoch=0.0127]Epoch 260: Train Loss = 0.00989586766809225\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=362, train_loss_step=0.0104, train_loss_epoch=0.0099]Epoch 261: Train Loss = 0.010441211983561516\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=362, train_loss_step=0.00886, train_loss_epoch=0.0104]Epoch 262: Train Loss = 0.008858396671712399\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.00886]  Epoch 263: Train Loss = 0.01003127358853817\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=362, train_loss_step=0.00858, train_loss_epoch=0.010]Epoch 264: Train Loss = 0.008578391745686531\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.00858] Epoch 265: Train Loss = 0.01021425612270832\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=362, train_loss_step=0.00989, train_loss_epoch=0.0102]Epoch 266: Train Loss = 0.009888921864330769\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=362, train_loss_step=0.0091, train_loss_epoch=0.00989] Epoch 267: Train Loss = 0.009098018519580364\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0091] Epoch 268: Train Loss = 0.010488144122064114\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.0105]Epoch 269: Train Loss = 0.010331319645047188\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s, v_num=362, train_loss_step=0.00905, train_loss_epoch=0.0103]Epoch 270: Train Loss = 0.009051848202943802\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.00905] Epoch 271: Train Loss = 0.010300585068762302\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=362, train_loss_step=0.0109, train_loss_epoch=0.0103] Epoch 272: Train Loss = 0.010854527354240417\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=362, train_loss_step=0.00801, train_loss_epoch=0.0109]Epoch 273: Train Loss = 0.008014253340661526\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=362, train_loss_step=0.013, train_loss_epoch=0.00801]  Epoch 274: Train Loss = 0.013028492219746113\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=362, train_loss_step=0.0131, train_loss_epoch=0.013] Epoch 275: Train Loss = 0.01308248657733202\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=362, train_loss_step=0.0141, train_loss_epoch=0.0131]Epoch 276: Train Loss = 0.0140685448423028\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0141]Epoch 277: Train Loss = 0.010453151538968086\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=362, train_loss_step=0.0109, train_loss_epoch=0.0105]Epoch 278: Train Loss = 0.010859591886401176\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=362, train_loss_step=0.00949, train_loss_epoch=0.0109]Epoch 279: Train Loss = 0.009489940479397774\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=362, train_loss_step=0.00788, train_loss_epoch=0.00949]Epoch 280: Train Loss = 0.00788103323429823\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=362, train_loss_step=0.0134, train_loss_epoch=0.00788] Epoch 281: Train Loss = 0.013372302986681461\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=362, train_loss_step=0.00741, train_loss_epoch=0.0134]Epoch 282: Train Loss = 0.007408709730952978\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=362, train_loss_step=0.00908, train_loss_epoch=0.00741]Epoch 283: Train Loss = 0.009076081216335297\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.00908] Epoch 284: Train Loss = 0.010262246243655682\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=362, train_loss_step=0.00894, train_loss_epoch=0.0103]Epoch 285: Train Loss = 0.008943532593548298\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=362, train_loss_step=0.0128, train_loss_epoch=0.00894] Epoch 286: Train Loss = 0.01284147147089243\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=362, train_loss_step=0.00898, train_loss_epoch=0.0128]Epoch 287: Train Loss = 0.008980317041277885\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=362, train_loss_step=0.013, train_loss_epoch=0.00898]  Epoch 288: Train Loss = 0.013045142404735088\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 11.60it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.013] Epoch 289: Train Loss = 0.010265091434121132\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=362, train_loss_step=0.0144, train_loss_epoch=0.0103]Epoch 290: Train Loss = 0.01442124042659998\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=362, train_loss_step=0.00987, train_loss_epoch=0.0144]Epoch 291: Train Loss = 0.009865372441709042\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.00987] Epoch 292: Train Loss = 0.010272189043462276\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 10.94it/s, v_num=362, train_loss_step=0.012, train_loss_epoch=0.0103]  Epoch 293: Train Loss = 0.01203013677150011\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=362, train_loss_step=0.0122, train_loss_epoch=0.012]Epoch 294: Train Loss = 0.012244945392012596\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=362, train_loss_step=0.0145, train_loss_epoch=0.0122]Epoch 295: Train Loss = 0.01454472541809082\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=362, train_loss_step=0.0114, train_loss_epoch=0.0145]Epoch 296: Train Loss = 0.01137003768235445\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0114]Epoch 297: Train Loss = 0.01227563712745905\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=362, train_loss_step=0.0112, train_loss_epoch=0.0123]Epoch 298: Train Loss = 0.011176020838320255\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=362, train_loss_step=0.0117, train_loss_epoch=0.0112]Epoch 299: Train Loss = 0.01172755565494299\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=362, train_loss_step=0.0106, train_loss_epoch=0.0117]Epoch 300: Train Loss = 0.01062068622559309\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=362, train_loss_step=0.016, train_loss_epoch=0.0106] Epoch 301: Train Loss = 0.015983032062649727\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=362, train_loss_step=0.0144, train_loss_epoch=0.016]Epoch 302: Train Loss = 0.014442646875977516\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=362, train_loss_step=0.0134, train_loss_epoch=0.0144]Epoch 303: Train Loss = 0.013395899906754494\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=362, train_loss_step=0.012, train_loss_epoch=0.0134] Epoch 304: Train Loss = 0.012004243209958076\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=362, train_loss_step=0.0138, train_loss_epoch=0.012]Epoch 305: Train Loss = 0.013849549926817417\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=362, train_loss_step=0.0158, train_loss_epoch=0.0138]Epoch 306: Train Loss = 0.015810856595635414\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=362, train_loss_step=0.0136, train_loss_epoch=0.0158]Epoch 307: Train Loss = 0.013565847650170326\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=362, train_loss_step=0.0143, train_loss_epoch=0.0136]Epoch 308: Train Loss = 0.014348565600812435\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.0143]Epoch 309: Train Loss = 0.010160433128476143\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=362, train_loss_step=0.0106, train_loss_epoch=0.0102]Epoch 310: Train Loss = 0.010570022277534008\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.0106]Epoch 311: Train Loss = 0.010154908522963524\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=362, train_loss_step=0.011, train_loss_epoch=0.0102] Epoch 312: Train Loss = 0.010993754491209984\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=362, train_loss_step=0.0122, train_loss_epoch=0.011]Epoch 313: Train Loss = 0.012202640995383263\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=362, train_loss_step=0.0122, train_loss_epoch=0.0122]Epoch 314: Train Loss = 0.012210226617753506\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.0122]Epoch 315: Train Loss = 0.012128378264605999\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=362, train_loss_step=0.0112, train_loss_epoch=0.0121]Epoch 316: Train Loss = 0.011180958710610867\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=362, train_loss_step=0.0138, train_loss_epoch=0.0112]Epoch 317: Train Loss = 0.013759310357272625\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=362, train_loss_step=0.0134, train_loss_epoch=0.0138]Epoch 318: Train Loss = 0.0134135065600276\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=362, train_loss_step=0.0115, train_loss_epoch=0.0134]Epoch 319: Train Loss = 0.011511518619954586\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s, v_num=362, train_loss_step=0.0111, train_loss_epoch=0.0115]Epoch 320: Train Loss = 0.01113202702254057\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=362, train_loss_step=0.0127, train_loss_epoch=0.0111]Epoch 321: Train Loss = 0.012688434682786465\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=362, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 322: Train Loss = 0.011965797282755375\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.012]Epoch 323: Train Loss = 0.01205191109329462\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=362, train_loss_step=0.0154, train_loss_epoch=0.0121]Epoch 324: Train Loss = 0.015424266457557678\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=362, train_loss_step=0.0113, train_loss_epoch=0.0154]Epoch 325: Train Loss = 0.011269758455455303\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s, v_num=362, train_loss_step=0.00884, train_loss_epoch=0.0113]Epoch 326: Train Loss = 0.008839898742735386\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 12.87it/s, v_num=362, train_loss_step=0.0107, train_loss_epoch=0.00884] Epoch 327: Train Loss = 0.010712533257901669\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 12.51it/s, v_num=362, train_loss_step=0.011, train_loss_epoch=0.0107]  Epoch 328: Train Loss = 0.010955557227134705\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=362, train_loss_step=0.0128, train_loss_epoch=0.011]Epoch 329: Train Loss = 0.012755672447383404\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.0128]Epoch 330: Train Loss = 0.010236667469143867\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=362, train_loss_step=0.00956, train_loss_epoch=0.0102]Epoch 331: Train Loss = 0.00956100132316351\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=362, train_loss_step=0.013, train_loss_epoch=0.00956]  Epoch 332: Train Loss = 0.01303496491163969\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=362, train_loss_step=0.0138, train_loss_epoch=0.013] Epoch 333: Train Loss = 0.013787084259092808\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=362, train_loss_step=0.0113, train_loss_epoch=0.0138]Epoch 334: Train Loss = 0.011277980171144009\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=362, train_loss_step=0.0118, train_loss_epoch=0.0113]Epoch 335: Train Loss = 0.011816747486591339\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=362, train_loss_step=0.00846, train_loss_epoch=0.0118]Epoch 336: Train Loss = 0.008460328914225101\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=362, train_loss_step=0.00976, train_loss_epoch=0.00846]Epoch 337: Train Loss = 0.009757003746926785\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=362, train_loss_step=0.013, train_loss_epoch=0.00976]  Epoch 338: Train Loss = 0.013006198219954967\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=362, train_loss_step=0.0137, train_loss_epoch=0.013] Epoch 339: Train Loss = 0.013686585240066051\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=362, train_loss_step=0.00801, train_loss_epoch=0.0137]Epoch 340: Train Loss = 0.008008827455341816\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=362, train_loss_step=0.013, train_loss_epoch=0.00801]  Epoch 341: Train Loss = 0.012992442585527897\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=362, train_loss_step=0.0112, train_loss_epoch=0.013] Epoch 342: Train Loss = 0.011190653778612614\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0112]Epoch 343: Train Loss = 0.010498465038836002\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=362, train_loss_step=0.0136, train_loss_epoch=0.0105]Epoch 344: Train Loss = 0.013647696003317833\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.0136] Epoch 345: Train Loss = 0.010026578791439533\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.010] Epoch 346: Train Loss = 0.01004245039075613\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.010]Epoch 347: Train Loss = 0.010527530685067177\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=362, train_loss_step=0.0153, train_loss_epoch=0.0105]Epoch 348: Train Loss = 0.015289311297237873\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.0153]Epoch 349: Train Loss = 0.0107872998341918\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=362, train_loss_step=0.00976, train_loss_epoch=0.0108]Epoch 350: Train Loss = 0.009761663153767586\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=362, train_loss_step=0.0132, train_loss_epoch=0.00976] Epoch 351: Train Loss = 0.01320728100836277\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=362, train_loss_step=0.0127, train_loss_epoch=0.0132] Epoch 352: Train Loss = 0.012687929905951023\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=362, train_loss_step=0.0128, train_loss_epoch=0.0127]Epoch 353: Train Loss = 0.012757955119013786\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s, v_num=362, train_loss_step=0.0128, train_loss_epoch=0.0128]Epoch 354: Train Loss = 0.01276142057031393\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=362, train_loss_step=0.0101, train_loss_epoch=0.0128]Epoch 355: Train Loss = 0.0100856339558959\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=362, train_loss_step=0.00983, train_loss_epoch=0.0101]Epoch 356: Train Loss = 0.009827854111790657\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=362, train_loss_step=0.0106, train_loss_epoch=0.00983] Epoch 357: Train Loss = 0.01058761216700077\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.0106] Epoch 358: Train Loss = 0.010778733529150486\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s, v_num=362, train_loss_step=0.0112, train_loss_epoch=0.0108]Epoch 359: Train Loss = 0.011165840551257133\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s, v_num=362, train_loss_step=0.0133, train_loss_epoch=0.0112]Epoch 360: Train Loss = 0.013336625881493092\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0133]Epoch 361: Train Loss = 0.010498089715838432\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=362, train_loss_step=0.0106, train_loss_epoch=0.0105]Epoch 362: Train Loss = 0.010559783317148685\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=362, train_loss_step=0.0109, train_loss_epoch=0.0106]Epoch 363: Train Loss = 0.010882646776735783\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=362, train_loss_step=0.0107, train_loss_epoch=0.0109]Epoch 364: Train Loss = 0.010713598690927029\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=362, train_loss_step=0.0146, train_loss_epoch=0.0107]Epoch 365: Train Loss = 0.014558962546288967\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=362, train_loss_step=0.0162, train_loss_epoch=0.0146]Epoch 366: Train Loss = 0.016160080209374428\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=362, train_loss_step=0.0104, train_loss_epoch=0.0162]Epoch 367: Train Loss = 0.010430417954921722\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=362, train_loss_step=0.0113, train_loss_epoch=0.0104]Epoch 368: Train Loss = 0.011322326958179474\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=362, train_loss_step=0.0122, train_loss_epoch=0.0113]Epoch 369: Train Loss = 0.012230195105075836\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0122]Epoch 370: Train Loss = 0.012275404296815395\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=362, train_loss_step=0.0132, train_loss_epoch=0.0123]Epoch 371: Train Loss = 0.01316206343472004\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=362, train_loss_step=0.0129, train_loss_epoch=0.0132]Epoch 372: Train Loss = 0.012851865962147713\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=362, train_loss_step=0.0101, train_loss_epoch=0.0129]Epoch 373: Train Loss = 0.010116840712726116\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=362, train_loss_step=0.0161, train_loss_epoch=0.0101]Epoch 374: Train Loss = 0.016105258837342262\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=362, train_loss_step=0.0132, train_loss_epoch=0.0161]Epoch 375: Train Loss = 0.013199456967413425\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=362, train_loss_step=0.0124, train_loss_epoch=0.0132]Epoch 376: Train Loss = 0.01244161557406187\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 13.02it/s, v_num=362, train_loss_step=0.00854, train_loss_epoch=0.0124]Epoch 377: Train Loss = 0.008542299270629883\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=362, train_loss_step=0.00776, train_loss_epoch=0.00854]Epoch 378: Train Loss = 0.007757850456982851\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=362, train_loss_step=0.00904, train_loss_epoch=0.00776]Epoch 379: Train Loss = 0.009043054655194283\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s, v_num=362, train_loss_step=0.00969, train_loss_epoch=0.00904]Epoch 380: Train Loss = 0.00969227310270071\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.00969] Epoch 381: Train Loss = 0.010215030051767826\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=362, train_loss_step=0.0119, train_loss_epoch=0.0102] Epoch 382: Train Loss = 0.011931924149394035\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.0119]Epoch 383: Train Loss = 0.010759594850242138\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.0108] Epoch 384: Train Loss = 0.010031742975115776\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=362, train_loss_step=0.00969, train_loss_epoch=0.010]Epoch 385: Train Loss = 0.009686016477644444\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=362, train_loss_step=0.00954, train_loss_epoch=0.00969]Epoch 386: Train Loss = 0.009540206752717495\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.00954] Epoch 387: Train Loss = 0.01050305925309658\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=362, train_loss_step=0.0117, train_loss_epoch=0.0105] Epoch 388: Train Loss = 0.011713320389389992\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=362, train_loss_step=0.00922, train_loss_epoch=0.0117]Epoch 389: Train Loss = 0.009216676466166973\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 13.40it/s, v_num=362, train_loss_step=0.00908, train_loss_epoch=0.00922]Epoch 390: Train Loss = 0.009077618829905987\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=362, train_loss_step=0.0117, train_loss_epoch=0.00908] Epoch 391: Train Loss = 0.011680823750793934\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=362, train_loss_step=0.00993, train_loss_epoch=0.0117]Epoch 392: Train Loss = 0.009932481683790684\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=362, train_loss_step=0.0095, train_loss_epoch=0.00993] Epoch 393: Train Loss = 0.009496867656707764\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=362, train_loss_step=0.0101, train_loss_epoch=0.0095] Epoch 394: Train Loss = 0.01008257269859314\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=362, train_loss_step=0.011, train_loss_epoch=0.0101] Epoch 395: Train Loss = 0.010975738056004047\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=362, train_loss_step=0.00925, train_loss_epoch=0.011]Epoch 396: Train Loss = 0.009254478849470615\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=362, train_loss_step=0.0082, train_loss_epoch=0.00925] Epoch 397: Train Loss = 0.008195075206458569\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=362, train_loss_step=0.0094, train_loss_epoch=0.0082] Epoch 398: Train Loss = 0.009397364221513271\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, v_num=362, train_loss_step=0.00911, train_loss_epoch=0.0094]Epoch 399: Train Loss = 0.00910587515681982\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=362, train_loss_step=0.00891, train_loss_epoch=0.00911]Epoch 400: Train Loss = 0.008912057615816593\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.00891]  Epoch 401: Train Loss = 0.010036760941147804\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=362, train_loss_step=0.00893, train_loss_epoch=0.010]Epoch 402: Train Loss = 0.008929683826863766\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=362, train_loss_step=0.00967, train_loss_epoch=0.00893]Epoch 403: Train Loss = 0.009666243568062782\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=362, train_loss_step=0.0134, train_loss_epoch=0.00967] Epoch 404: Train Loss = 0.013448107056319714\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s, v_num=362, train_loss_step=0.00989, train_loss_epoch=0.0134]Epoch 405: Train Loss = 0.009889987297356129\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.00989] Epoch 406: Train Loss = 0.010179691947996616\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=362, train_loss_step=0.0134, train_loss_epoch=0.0102] Epoch 407: Train Loss = 0.013404123485088348\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=362, train_loss_step=0.0159, train_loss_epoch=0.0134]Epoch 408: Train Loss = 0.015886902809143066\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=362, train_loss_step=0.0138, train_loss_epoch=0.0159]Epoch 409: Train Loss = 0.013813825324177742\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=362, train_loss_step=0.0115, train_loss_epoch=0.0138]Epoch 410: Train Loss = 0.01146162860095501\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=362, train_loss_step=0.0137, train_loss_epoch=0.0115]Epoch 411: Train Loss = 0.013675415888428688\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0137]Epoch 412: Train Loss = 0.012327750213444233\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=362, train_loss_step=0.0112, train_loss_epoch=0.0123]Epoch 413: Train Loss = 0.01120405551046133\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=362, train_loss_step=0.0125, train_loss_epoch=0.0112]Epoch 414: Train Loss = 0.012499767355620861\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=362, train_loss_step=0.0134, train_loss_epoch=0.0125]Epoch 415: Train Loss = 0.01336245983839035\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=362, train_loss_step=0.00893, train_loss_epoch=0.0134]Epoch 416: Train Loss = 0.008931545540690422\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=362, train_loss_step=0.00869, train_loss_epoch=0.00893]Epoch 417: Train Loss = 0.00869249552488327\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=362, train_loss_step=0.0103, train_loss_epoch=0.00869] Epoch 418: Train Loss = 0.010278850793838501\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0103] Epoch 419: Train Loss = 0.012346858158707619\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0123]Epoch 420: Train Loss = 0.010474338196218014\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=362, train_loss_step=0.0117, train_loss_epoch=0.0105]Epoch 421: Train Loss = 0.011744816787540913\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=362, train_loss_step=0.0114, train_loss_epoch=0.0117]Epoch 422: Train Loss = 0.011408403515815735\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=362, train_loss_step=0.0122, train_loss_epoch=0.0114]Epoch 423: Train Loss = 0.012203233316540718\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=362, train_loss_step=0.0142, train_loss_epoch=0.0122]Epoch 424: Train Loss = 0.014182129874825478\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=362, train_loss_step=0.0121, train_loss_epoch=0.0142]Epoch 425: Train Loss = 0.012085328809916973\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=362, train_loss_step=0.010, train_loss_epoch=0.0121] Epoch 426: Train Loss = 0.010020014829933643\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=362, train_loss_step=0.0138, train_loss_epoch=0.010]Epoch 427: Train Loss = 0.013778090476989746\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=362, train_loss_step=0.00938, train_loss_epoch=0.0138]Epoch 428: Train Loss = 0.009379087015986443\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=362, train_loss_step=0.0098, train_loss_epoch=0.00938] Epoch 429: Train Loss = 0.0097953574731946\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=362, train_loss_step=0.0169, train_loss_epoch=0.0098] Epoch 430: Train Loss = 0.016931632533669472\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=362, train_loss_step=0.00904, train_loss_epoch=0.0169]Epoch 431: Train Loss = 0.009041651152074337\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=362, train_loss_step=0.0101, train_loss_epoch=0.00904] Epoch 432: Train Loss = 0.010084264911711216\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=362, train_loss_step=0.00785, train_loss_epoch=0.0101]Epoch 433: Train Loss = 0.007849028334021568\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=362, train_loss_step=0.00844, train_loss_epoch=0.00785]Epoch 434: Train Loss = 0.008435795083642006\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=362, train_loss_step=0.0115, train_loss_epoch=0.00844] Epoch 435: Train Loss = 0.01154195237904787\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s, v_num=362, train_loss_step=0.00818, train_loss_epoch=0.0115]Epoch 436: Train Loss = 0.008183098398149014\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=362, train_loss_step=0.011, train_loss_epoch=0.00818]  Epoch 437: Train Loss = 0.01104604173451662\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=362, train_loss_step=0.0153, train_loss_epoch=0.011] Epoch 438: Train Loss = 0.01531099434942007\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=362, train_loss_step=0.0134, train_loss_epoch=0.0153]Epoch 439: Train Loss = 0.013449160382151604\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 13.75it/s, v_num=362, train_loss_step=0.0136, train_loss_epoch=0.0134]Epoch 440: Train Loss = 0.01358374860137701\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=362, train_loss_step=0.00941, train_loss_epoch=0.0136]Epoch 441: Train Loss = 0.009414833970367908\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=362, train_loss_step=0.00919, train_loss_epoch=0.00941]Epoch 442: Train Loss = 0.00919076893478632\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=362, train_loss_step=0.0093, train_loss_epoch=0.00919] Epoch 443: Train Loss = 0.009295018389821053\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=362, train_loss_step=0.011, train_loss_epoch=0.0093]  Epoch 444: Train Loss = 0.011034195311367512\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=362, train_loss_step=0.0112, train_loss_epoch=0.011]Epoch 445: Train Loss = 0.011245066300034523\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=362, train_loss_step=0.0133, train_loss_epoch=0.0112]Epoch 446: Train Loss = 0.013268674723803997\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.0133]Epoch 447: Train Loss = 0.010819937102496624\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=362, train_loss_step=0.00765, train_loss_epoch=0.0108]Epoch 448: Train Loss = 0.007649466395378113\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=362, train_loss_step=0.00899, train_loss_epoch=0.00765]Epoch 449: Train Loss = 0.00898518692702055\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=362, train_loss_step=0.0104, train_loss_epoch=0.00899] Epoch 450: Train Loss = 0.010431312955915928\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=362, train_loss_step=0.011, train_loss_epoch=0.0104]  Epoch 451: Train Loss = 0.010998270474374294\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=362, train_loss_step=0.0129, train_loss_epoch=0.011]Epoch 452: Train Loss = 0.012905893847346306\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=362, train_loss_step=0.00967, train_loss_epoch=0.0129]Epoch 453: Train Loss = 0.00967391300946474\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=362, train_loss_step=0.00801, train_loss_epoch=0.00967]Epoch 454: Train Loss = 0.008012277074158192\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=362, train_loss_step=0.00807, train_loss_epoch=0.00801]Epoch 455: Train Loss = 0.008071057498455048\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=362, train_loss_step=0.0094, train_loss_epoch=0.00807] Epoch 456: Train Loss = 0.009395545348525047\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=362, train_loss_step=0.0105, train_loss_epoch=0.0094] Epoch 457: Train Loss = 0.010485806502401829\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=362, train_loss_step=0.011, train_loss_epoch=0.0105] Epoch 458: Train Loss = 0.011045568622648716\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s, v_num=362, train_loss_step=0.0151, train_loss_epoch=0.011]Epoch 459: Train Loss = 0.01511993259191513\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=362, train_loss_step=0.00937, train_loss_epoch=0.0151]Epoch 460: Train Loss = 0.009366804733872414\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 12.37it/s, v_num=362, train_loss_step=0.00778, train_loss_epoch=0.00937]Epoch 461: Train Loss = 0.007777226623147726\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 12.63it/s, v_num=362, train_loss_step=0.00862, train_loss_epoch=0.00778]Epoch 462: Train Loss = 0.008621028624475002\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=362, train_loss_step=0.0107, train_loss_epoch=0.00862] Epoch 463: Train Loss = 0.010666376911103725\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=362, train_loss_step=0.00988, train_loss_epoch=0.0107]Epoch 464: Train Loss = 0.009877076372504234\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=362, train_loss_step=0.00841, train_loss_epoch=0.00988]Epoch 465: Train Loss = 0.008411196060478687\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=362, train_loss_step=0.0117, train_loss_epoch=0.00841] Epoch 466: Train Loss = 0.011733315885066986\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=362, train_loss_step=0.0109, train_loss_epoch=0.0117] Epoch 467: Train Loss = 0.010855140164494514\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=362, train_loss_step=0.00666, train_loss_epoch=0.0109]Epoch 468: Train Loss = 0.006658910773694515\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=362, train_loss_step=0.0115, train_loss_epoch=0.00666] Epoch 469: Train Loss = 0.011486874893307686\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=362, train_loss_step=0.0127, train_loss_epoch=0.0115] Epoch 470: Train Loss = 0.012716640718281269\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=362, train_loss_step=0.0125, train_loss_epoch=0.0127]Epoch 471: Train Loss = 0.01248970814049244\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=362, train_loss_step=0.00884, train_loss_epoch=0.0125]Epoch 472: Train Loss = 0.008844896219670773\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.00884] Epoch 473: Train Loss = 0.010214172303676605\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=362, train_loss_step=0.0171, train_loss_epoch=0.0102] Epoch 474: Train Loss = 0.017118481919169426\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=362, train_loss_step=0.0117, train_loss_epoch=0.0171]Epoch 475: Train Loss = 0.011718629859387875\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=362, train_loss_step=0.0091, train_loss_epoch=0.0117]Epoch 476: Train Loss = 0.009102755226194859\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=362, train_loss_step=0.0098, train_loss_epoch=0.0091]Epoch 477: Train Loss = 0.009803318418562412\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=362, train_loss_step=0.0101, train_loss_epoch=0.0098]Epoch 478: Train Loss = 0.010144032537937164\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=362, train_loss_step=0.0102, train_loss_epoch=0.0101]Epoch 479: Train Loss = 0.010234727524220943\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=362, train_loss_step=0.00992, train_loss_epoch=0.0102]Epoch 480: Train Loss = 0.009915834292769432\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=362, train_loss_step=0.0076, train_loss_epoch=0.00992] Epoch 481: Train Loss = 0.007603011559695005\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=362, train_loss_step=0.00922, train_loss_epoch=0.0076]Epoch 482: Train Loss = 0.009222251363098621\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=362, train_loss_step=0.00801, train_loss_epoch=0.00922]Epoch 483: Train Loss = 0.008012128062546253\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=362, train_loss_step=0.0108, train_loss_epoch=0.00801] Epoch 484: Train Loss = 0.010761827230453491\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 13.44it/s, v_num=362, train_loss_step=0.0123, train_loss_epoch=0.0108] Epoch 485: Train Loss = 0.012326317839324474\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=362, train_loss_step=0.0113, train_loss_epoch=0.0123]Epoch 486: Train Loss = 0.011286916211247444\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=362, train_loss_step=0.0125, train_loss_epoch=0.0113]Epoch 487: Train Loss = 0.01253626961261034\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=362, train_loss_step=0.00812, train_loss_epoch=0.0125]Epoch 488: Train Loss = 0.008116284385323524\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=362, train_loss_step=0.0119, train_loss_epoch=0.00812] Epoch 489: Train Loss = 0.011877484619617462\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=362, train_loss_step=0.00968, train_loss_epoch=0.0119]Epoch 490: Train Loss = 0.009682574309408665\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=362, train_loss_step=0.0106, train_loss_epoch=0.00968] Epoch 491: Train Loss = 0.010563620366156101\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=362, train_loss_step=0.00659, train_loss_epoch=0.0106]Epoch 492: Train Loss = 0.006588856689631939\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 13.56it/s, v_num=362, train_loss_step=0.00994, train_loss_epoch=0.00659]Epoch 493: Train Loss = 0.009938416071236134\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=362, train_loss_step=0.00824, train_loss_epoch=0.00994]Epoch 494: Train Loss = 0.008242943324148655\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=362, train_loss_step=0.0143, train_loss_epoch=0.00824] Epoch 495: Train Loss = 0.014272675849497318\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=362, train_loss_step=0.00951, train_loss_epoch=0.0143]Epoch 496: Train Loss = 0.0095055578276515\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=362, train_loss_step=0.00764, train_loss_epoch=0.00951]Epoch 497: Train Loss = 0.00763748912140727\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=362, train_loss_step=0.00963, train_loss_epoch=0.00764]Epoch 498: Train Loss = 0.009629243984818459\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=362, train_loss_step=0.00755, train_loss_epoch=0.00963]Epoch 499: Train Loss = 0.007549212779849768\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=362, train_loss_step=0.00755, train_loss_epoch=0.00755]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.09it/s, v_num=362, train_loss_step=0.00755, train_loss_epoch=0.00755]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 12: from 2008-05-12 00:00:00 to 2022-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=365, train_loss_step=0.0245]Epoch 0: Train Loss = 0.024456774815917015\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=365, train_loss_step=0.0383, train_loss_epoch=0.0245]Epoch 1: Train Loss = 0.038270365446805954\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=365, train_loss_step=0.027, train_loss_epoch=0.0383] Epoch 2: Train Loss = 0.026990598067641258\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=365, train_loss_step=0.0183, train_loss_epoch=0.027]Epoch 3: Train Loss = 0.018275324255228043\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=365, train_loss_step=0.0189, train_loss_epoch=0.0183]Epoch 4: Train Loss = 0.018888870254158974\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=365, train_loss_step=0.0151, train_loss_epoch=0.0189]Epoch 5: Train Loss = 0.015148313716053963\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=365, train_loss_step=0.0165, train_loss_epoch=0.0151]Epoch 6: Train Loss = 0.016478318721055984\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=365, train_loss_step=0.0153, train_loss_epoch=0.0165]Epoch 7: Train Loss = 0.015342195518314838\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=365, train_loss_step=0.0154, train_loss_epoch=0.0153]Epoch 8: Train Loss = 0.015417917631566525\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=365, train_loss_step=0.0145, train_loss_epoch=0.0154]Epoch 9: Train Loss = 0.014511389657855034\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=365, train_loss_step=0.0131, train_loss_epoch=0.0145]Epoch 10: Train Loss = 0.013125714845955372\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=365, train_loss_step=0.0119, train_loss_epoch=0.0131]Epoch 11: Train Loss = 0.011938628740608692\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=365, train_loss_step=0.011, train_loss_epoch=0.0119] Epoch 12: Train Loss = 0.011021009646356106\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=365, train_loss_step=0.0126, train_loss_epoch=0.011]Epoch 13: Train Loss = 0.012648041360080242\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=365, train_loss_step=0.0111, train_loss_epoch=0.0126]Epoch 14: Train Loss = 0.011096314527094364\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=365, train_loss_step=0.0132, train_loss_epoch=0.0111]Epoch 15: Train Loss = 0.013154292479157448\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=365, train_loss_step=0.013, train_loss_epoch=0.0132] Epoch 16: Train Loss = 0.013024912215769291\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=365, train_loss_step=0.0133, train_loss_epoch=0.013]Epoch 17: Train Loss = 0.013347310945391655\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=365, train_loss_step=0.0143, train_loss_epoch=0.0133]Epoch 18: Train Loss = 0.01432075072079897\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=365, train_loss_step=0.014, train_loss_epoch=0.0143] Epoch 19: Train Loss = 0.01401718519628048\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=365, train_loss_step=0.0101, train_loss_epoch=0.014]Epoch 20: Train Loss = 0.010091700591146946\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=365, train_loss_step=0.0125, train_loss_epoch=0.0101]Epoch 21: Train Loss = 0.012522521428763866\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.0125]Epoch 22: Train Loss = 0.011290439404547215\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=365, train_loss_step=0.0125, train_loss_epoch=0.0113]Epoch 23: Train Loss = 0.01248952653259039\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=365, train_loss_step=0.016, train_loss_epoch=0.0125] Epoch 24: Train Loss = 0.015961848199367523\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=365, train_loss_step=0.00985, train_loss_epoch=0.016]Epoch 25: Train Loss = 0.009850856848061085\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=365, train_loss_step=0.00939, train_loss_epoch=0.00985]Epoch 26: Train Loss = 0.009389066137373447\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=365, train_loss_step=0.0115, train_loss_epoch=0.00939] Epoch 27: Train Loss = 0.011515812017023563\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=365, train_loss_step=0.0183, train_loss_epoch=0.0115] Epoch 28: Train Loss = 0.018269876018166542\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=365, train_loss_step=0.0128, train_loss_epoch=0.0183]Epoch 29: Train Loss = 0.012832230888307095\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=365, train_loss_step=0.0121, train_loss_epoch=0.0128]Epoch 30: Train Loss = 0.012069557793438435\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=365, train_loss_step=0.0109, train_loss_epoch=0.0121]Epoch 31: Train Loss = 0.01087570283561945\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=365, train_loss_step=0.0152, train_loss_epoch=0.0109]Epoch 32: Train Loss = 0.015232344157993793\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=365, train_loss_step=0.0147, train_loss_epoch=0.0152]Epoch 33: Train Loss = 0.014714940451085567\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=365, train_loss_step=0.0093, train_loss_epoch=0.0147]Epoch 34: Train Loss = 0.009295736439526081\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.0093]Epoch 35: Train Loss = 0.010777713730931282\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=365, train_loss_step=0.0137, train_loss_epoch=0.0108]Epoch 36: Train Loss = 0.01373108197003603\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=365, train_loss_step=0.0136, train_loss_epoch=0.0137]Epoch 37: Train Loss = 0.013620304875075817\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=365, train_loss_step=0.0135, train_loss_epoch=0.0136]Epoch 38: Train Loss = 0.013450943864881992\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=365, train_loss_step=0.0144, train_loss_epoch=0.0135]Epoch 39: Train Loss = 0.014407913200557232\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=365, train_loss_step=0.013, train_loss_epoch=0.0144] Epoch 40: Train Loss = 0.01298717875033617\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=365, train_loss_step=0.0168, train_loss_epoch=0.013]Epoch 41: Train Loss = 0.016836782917380333\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=365, train_loss_step=0.0133, train_loss_epoch=0.0168]Epoch 42: Train Loss = 0.013317517936229706\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=365, train_loss_step=0.0141, train_loss_epoch=0.0133]Epoch 43: Train Loss = 0.014064031653106213\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=365, train_loss_step=0.0121, train_loss_epoch=0.0141]Epoch 44: Train Loss = 0.012141131795942783\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=365, train_loss_step=0.00988, train_loss_epoch=0.0121]Epoch 45: Train Loss = 0.009875255636870861\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=365, train_loss_step=0.014, train_loss_epoch=0.00988]  Epoch 46: Train Loss = 0.014003142714500427\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=365, train_loss_step=0.0128, train_loss_epoch=0.014] Epoch 47: Train Loss = 0.012787743471562862\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=365, train_loss_step=0.011, train_loss_epoch=0.0128] Epoch 48: Train Loss = 0.011011498980224133\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=365, train_loss_step=0.00866, train_loss_epoch=0.011]Epoch 49: Train Loss = 0.008663441054522991\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.00866] Epoch 50: Train Loss = 0.010762353427708149\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=365, train_loss_step=0.0128, train_loss_epoch=0.0108] Epoch 51: Train Loss = 0.012842295691370964\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.0128]Epoch 52: Train Loss = 0.011279397644102573\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=365, train_loss_step=0.0136, train_loss_epoch=0.0113]Epoch 53: Train Loss = 0.013580895960330963\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=365, train_loss_step=0.0121, train_loss_epoch=0.0136]Epoch 54: Train Loss = 0.012116529978811741\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.0121]Epoch 55: Train Loss = 0.010444669052958488\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=365, train_loss_step=0.0133, train_loss_epoch=0.0104]Epoch 56: Train Loss = 0.013316221535205841\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=365, train_loss_step=0.0101, train_loss_epoch=0.0133]Epoch 57: Train Loss = 0.010090283118188381\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=365, train_loss_step=0.0093, train_loss_epoch=0.0101]Epoch 58: Train Loss = 0.009295676834881306\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=365, train_loss_step=0.0099, train_loss_epoch=0.0093]Epoch 59: Train Loss = 0.009902089834213257\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 13.21it/s, v_num=365, train_loss_step=0.0114, train_loss_epoch=0.0099]Epoch 60: Train Loss = 0.01137042697519064\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=365, train_loss_step=0.0115, train_loss_epoch=0.0114]Epoch 61: Train Loss = 0.011521922424435616\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=365, train_loss_step=0.011, train_loss_epoch=0.0115] Epoch 62: Train Loss = 0.01098676584661007\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=365, train_loss_step=0.0137, train_loss_epoch=0.011]Epoch 63: Train Loss = 0.013670564629137516\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=365, train_loss_step=0.0117, train_loss_epoch=0.0137]Epoch 64: Train Loss = 0.011728594079613686\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=365, train_loss_step=0.0147, train_loss_epoch=0.0117]Epoch 65: Train Loss = 0.014696439728140831\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=365, train_loss_step=0.0118, train_loss_epoch=0.0147]Epoch 66: Train Loss = 0.011803935281932354\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=365, train_loss_step=0.00961, train_loss_epoch=0.0118]Epoch 67: Train Loss = 0.009610101580619812\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=365, train_loss_step=0.0119, train_loss_epoch=0.00961] Epoch 68: Train Loss = 0.011907695792615414\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=365, train_loss_step=0.0111, train_loss_epoch=0.0119] Epoch 69: Train Loss = 0.011062885634601116\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=365, train_loss_step=0.0129, train_loss_epoch=0.0111]Epoch 70: Train Loss = 0.012857143767178059\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.0129]Epoch 71: Train Loss = 0.011250033043324947\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=365, train_loss_step=0.012, train_loss_epoch=0.0113] Epoch 72: Train Loss = 0.012002261355519295\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=365, train_loss_step=0.0115, train_loss_epoch=0.012]Epoch 73: Train Loss = 0.011498868465423584\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.0115]Epoch 74: Train Loss = 0.010392717085778713\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=365, train_loss_step=0.0117, train_loss_epoch=0.0104]Epoch 75: Train Loss = 0.011685416102409363\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=365, train_loss_step=0.0115, train_loss_epoch=0.0117]Epoch 76: Train Loss = 0.011526052840054035\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=365, train_loss_step=0.0137, train_loss_epoch=0.0115]Epoch 77: Train Loss = 0.013676827773451805\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=365, train_loss_step=0.0147, train_loss_epoch=0.0137]Epoch 78: Train Loss = 0.014718644320964813\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=365, train_loss_step=0.012, train_loss_epoch=0.0147] Epoch 79: Train Loss = 0.011984743177890778\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=365, train_loss_step=0.0124, train_loss_epoch=0.012]Epoch 80: Train Loss = 0.012373958714306355\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=365, train_loss_step=0.0123, train_loss_epoch=0.0124]Epoch 81: Train Loss = 0.012342959642410278\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=365, train_loss_step=0.00978, train_loss_epoch=0.0123]Epoch 82: Train Loss = 0.009777849540114403\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.00978] Epoch 83: Train Loss = 0.010350094176828861\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.0104] Epoch 84: Train Loss = 0.011284440755844116\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.0113]Epoch 85: Train Loss = 0.010832704603672028\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=365, train_loss_step=0.0112, train_loss_epoch=0.0108]Epoch 86: Train Loss = 0.011225187219679356\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.0112]Epoch 87: Train Loss = 0.010840006172657013\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=365, train_loss_step=0.0116, train_loss_epoch=0.0108]Epoch 88: Train Loss = 0.011632425710558891\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=365, train_loss_step=0.00929, train_loss_epoch=0.0116]Epoch 89: Train Loss = 0.009290273301303387\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=365, train_loss_step=0.0131, train_loss_epoch=0.00929] Epoch 90: Train Loss = 0.0131274638697505\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 10.68it/s, v_num=365, train_loss_step=0.0114, train_loss_epoch=0.0131] Epoch 91: Train Loss = 0.011390662752091885\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=365, train_loss_step=0.0114, train_loss_epoch=0.0114]Epoch 92: Train Loss = 0.011371849104762077\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=365, train_loss_step=0.011, train_loss_epoch=0.0114] Epoch 93: Train Loss = 0.011021372862160206\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=365, train_loss_step=0.00938, train_loss_epoch=0.011]Epoch 94: Train Loss = 0.009383433498442173\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=365, train_loss_step=0.0165, train_loss_epoch=0.00938] Epoch 95: Train Loss = 0.01652034930884838\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 14.11it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.0165] Epoch 96: Train Loss = 0.010797304101288319\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=365, train_loss_step=0.0136, train_loss_epoch=0.0108]Epoch 97: Train Loss = 0.013611389324069023\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=365, train_loss_step=0.010, train_loss_epoch=0.0136] Epoch 98: Train Loss = 0.010045675560832024\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 12.87it/s, v_num=365, train_loss_step=0.00781, train_loss_epoch=0.010]Epoch 99: Train Loss = 0.007806036155670881\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=365, train_loss_step=0.00891, train_loss_epoch=0.00781]Epoch 100: Train Loss = 0.008908201940357685\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=365, train_loss_step=0.00993, train_loss_epoch=0.00891]Epoch 101: Train Loss = 0.009928002022206783\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=365, train_loss_step=0.00689, train_loss_epoch=0.00993]Epoch 102: Train Loss = 0.006892398465424776\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=365, train_loss_step=0.0116, train_loss_epoch=0.00689] Epoch 103: Train Loss = 0.011555898003280163\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 13.05it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.0116] Epoch 104: Train Loss = 0.011303734965622425\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.0113]Epoch 105: Train Loss = 0.010372156277298927\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=365, train_loss_step=0.0127, train_loss_epoch=0.0104]Epoch 106: Train Loss = 0.012704857625067234\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=365, train_loss_step=0.00869, train_loss_epoch=0.0127]Epoch 107: Train Loss = 0.008694174699485302\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=365, train_loss_step=0.00817, train_loss_epoch=0.00869]Epoch 108: Train Loss = 0.008172483183443546\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=365, train_loss_step=0.00941, train_loss_epoch=0.00817]Epoch 109: Train Loss = 0.0094055300578475\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=365, train_loss_step=0.00997, train_loss_epoch=0.00941]Epoch 110: Train Loss = 0.009973722510039806\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=365, train_loss_step=0.00946, train_loss_epoch=0.00997]Epoch 111: Train Loss = 0.009455288760364056\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=365, train_loss_step=0.0107, train_loss_epoch=0.00946] Epoch 112: Train Loss = 0.01069930661469698\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=365, train_loss_step=0.00914, train_loss_epoch=0.0107]Epoch 113: Train Loss = 0.009135114960372448\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=365, train_loss_step=0.0088, train_loss_epoch=0.00914] Epoch 114: Train Loss = 0.008803149685263634\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=365, train_loss_step=0.00853, train_loss_epoch=0.0088]Epoch 115: Train Loss = 0.008534439839422703\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=365, train_loss_step=0.0101, train_loss_epoch=0.00853] Epoch 116: Train Loss = 0.010098546743392944\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s, v_num=365, train_loss_step=0.00809, train_loss_epoch=0.0101]Epoch 117: Train Loss = 0.00808657705783844\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=365, train_loss_step=0.0138, train_loss_epoch=0.00809] Epoch 118: Train Loss = 0.013818600215017796\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=365, train_loss_step=0.00912, train_loss_epoch=0.0138]Epoch 119: Train Loss = 0.00911658350378275\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=365, train_loss_step=0.0116, train_loss_epoch=0.00912] Epoch 120: Train Loss = 0.011550642549991608\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=365, train_loss_step=0.0111, train_loss_epoch=0.0116] Epoch 121: Train Loss = 0.011111577041447163\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=365, train_loss_step=0.0102, train_loss_epoch=0.0111]Epoch 122: Train Loss = 0.010198644362390041\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=365, train_loss_step=0.00965, train_loss_epoch=0.0102]Epoch 123: Train Loss = 0.009646245278418064\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=365, train_loss_step=0.0095, train_loss_epoch=0.00965] Epoch 124: Train Loss = 0.00950457900762558\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=365, train_loss_step=0.00877, train_loss_epoch=0.0095]Epoch 125: Train Loss = 0.008774672634899616\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=365, train_loss_step=0.00731, train_loss_epoch=0.00877]Epoch 126: Train Loss = 0.007310480810701847\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=365, train_loss_step=0.00708, train_loss_epoch=0.00731]Epoch 127: Train Loss = 0.007078242022544146\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=365, train_loss_step=0.0098, train_loss_epoch=0.00708] Epoch 128: Train Loss = 0.00980090256780386\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=365, train_loss_step=0.0076, train_loss_epoch=0.0098] Epoch 129: Train Loss = 0.007601168472319841\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=365, train_loss_step=0.011, train_loss_epoch=0.0076] Epoch 130: Train Loss = 0.011006781831383705\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=365, train_loss_step=0.0083, train_loss_epoch=0.011]Epoch 131: Train Loss = 0.008303488604724407\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=365, train_loss_step=0.0135, train_loss_epoch=0.0083]Epoch 132: Train Loss = 0.013549341820180416\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=365, train_loss_step=0.00997, train_loss_epoch=0.0135]Epoch 133: Train Loss = 0.009971565566956997\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=365, train_loss_step=0.00886, train_loss_epoch=0.00997]Epoch 134: Train Loss = 0.008860099129378796\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.00886] Epoch 135: Train Loss = 0.01083823386579752\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=365, train_loss_step=0.00946, train_loss_epoch=0.0108]Epoch 136: Train Loss = 0.009464007802307606\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=365, train_loss_step=0.0111, train_loss_epoch=0.00946] Epoch 137: Train Loss = 0.011132963001728058\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=365, train_loss_step=0.00944, train_loss_epoch=0.0111]Epoch 138: Train Loss = 0.009442674927413464\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=365, train_loss_step=0.00887, train_loss_epoch=0.00944]Epoch 139: Train Loss = 0.00887143425643444\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=365, train_loss_step=0.0107, train_loss_epoch=0.00887] Epoch 140: Train Loss = 0.010692300274968147\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=365, train_loss_step=0.0111, train_loss_epoch=0.0107] Epoch 141: Train Loss = 0.011136569082736969\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=365, train_loss_step=0.00818, train_loss_epoch=0.0111]Epoch 142: Train Loss = 0.008184144273400307\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 12.94it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.00818] Epoch 143: Train Loss = 0.010400878265500069\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=365, train_loss_step=0.0119, train_loss_epoch=0.0104] Epoch 144: Train Loss = 0.011927535757422447\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=365, train_loss_step=0.00953, train_loss_epoch=0.0119]Epoch 145: Train Loss = 0.009526652283966541\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=365, train_loss_step=0.00937, train_loss_epoch=0.00953]Epoch 146: Train Loss = 0.009371601976454258\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=365, train_loss_step=0.0146, train_loss_epoch=0.00937] Epoch 147: Train Loss = 0.014596047811210155\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=365, train_loss_step=0.00973, train_loss_epoch=0.0146]Epoch 148: Train Loss = 0.009725180454552174\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=365, train_loss_step=0.0125, train_loss_epoch=0.00973] Epoch 149: Train Loss = 0.012452907860279083\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=365, train_loss_step=0.0111, train_loss_epoch=0.0125] Epoch 150: Train Loss = 0.011092069558799267\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=365, train_loss_step=0.0133, train_loss_epoch=0.0111]Epoch 151: Train Loss = 0.01325852982699871\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=365, train_loss_step=0.0149, train_loss_epoch=0.0133]Epoch 152: Train Loss = 0.014865964651107788\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=365, train_loss_step=0.0123, train_loss_epoch=0.0149]Epoch 153: Train Loss = 0.01234059501439333\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=365, train_loss_step=0.0127, train_loss_epoch=0.0123]Epoch 154: Train Loss = 0.012742766179144382\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=365, train_loss_step=0.0114, train_loss_epoch=0.0127]Epoch 155: Train Loss = 0.011384064331650734\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=365, train_loss_step=0.0111, train_loss_epoch=0.0114]Epoch 156: Train Loss = 0.011082124896347523\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=365, train_loss_step=0.00972, train_loss_epoch=0.0111]Epoch 157: Train Loss = 0.009721525013446808\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=365, train_loss_step=0.0129, train_loss_epoch=0.00972] Epoch 158: Train Loss = 0.012927784584462643\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 13.54it/s, v_num=365, train_loss_step=0.0116, train_loss_epoch=0.0129] Epoch 159: Train Loss = 0.011635832488536835\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=365, train_loss_step=0.010, train_loss_epoch=0.0116] Epoch 160: Train Loss = 0.010019390843808651\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=365, train_loss_step=0.0126, train_loss_epoch=0.010]Epoch 161: Train Loss = 0.01260180864483118\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=365, train_loss_step=0.00974, train_loss_epoch=0.0126]Epoch 162: Train Loss = 0.009741641581058502\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=365, train_loss_step=0.00927, train_loss_epoch=0.00974]Epoch 163: Train Loss = 0.009267990477383137\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=365, train_loss_step=0.0132, train_loss_epoch=0.00927] Epoch 164: Train Loss = 0.01318617444485426\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=365, train_loss_step=0.0097, train_loss_epoch=0.0132] Epoch 165: Train Loss = 0.009699579328298569\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=365, train_loss_step=0.0106, train_loss_epoch=0.0097]Epoch 166: Train Loss = 0.010582970455288887\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=365, train_loss_step=0.00993, train_loss_epoch=0.0106]Epoch 167: Train Loss = 0.00993422418832779\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=365, train_loss_step=0.00908, train_loss_epoch=0.00993]Epoch 168: Train Loss = 0.009078102186322212\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=365, train_loss_step=0.0098, train_loss_epoch=0.00908] Epoch 169: Train Loss = 0.009799926541745663\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=365, train_loss_step=0.00858, train_loss_epoch=0.0098]Epoch 170: Train Loss = 0.008584421128034592\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=365, train_loss_step=0.0109, train_loss_epoch=0.00858] Epoch 171: Train Loss = 0.010948581621050835\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=365, train_loss_step=0.00948, train_loss_epoch=0.0109]Epoch 172: Train Loss = 0.00948337558656931\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=365, train_loss_step=0.0129, train_loss_epoch=0.00948] Epoch 173: Train Loss = 0.01287554670125246\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=365, train_loss_step=0.0117, train_loss_epoch=0.0129] Epoch 174: Train Loss = 0.011667660437524319\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=365, train_loss_step=0.0105, train_loss_epoch=0.0117]Epoch 175: Train Loss = 0.010548054240643978\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=365, train_loss_step=0.00975, train_loss_epoch=0.0105]Epoch 176: Train Loss = 0.009754342958331108\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, v_num=365, train_loss_step=0.00916, train_loss_epoch=0.00975]Epoch 177: Train Loss = 0.009157995693385601\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=365, train_loss_step=0.011, train_loss_epoch=0.00916]  Epoch 178: Train Loss = 0.01103175338357687\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=365, train_loss_step=0.0114, train_loss_epoch=0.011] Epoch 179: Train Loss = 0.01135658472776413\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=365, train_loss_step=0.0138, train_loss_epoch=0.0114]Epoch 180: Train Loss = 0.013782111927866936\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=365, train_loss_step=0.0128, train_loss_epoch=0.0138]Epoch 181: Train Loss = 0.01279205922037363\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=365, train_loss_step=0.0131, train_loss_epoch=0.0128]Epoch 182: Train Loss = 0.013141567818820477\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=365, train_loss_step=0.0123, train_loss_epoch=0.0131]Epoch 183: Train Loss = 0.012279406189918518\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=365, train_loss_step=0.0126, train_loss_epoch=0.0123]Epoch 184: Train Loss = 0.012646977789700031\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=365, train_loss_step=0.0126, train_loss_epoch=0.0126]Epoch 185: Train Loss = 0.012631908990442753\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=365, train_loss_step=0.00955, train_loss_epoch=0.0126]Epoch 186: Train Loss = 0.009546936489641666\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=365, train_loss_step=0.00989, train_loss_epoch=0.00955]Epoch 187: Train Loss = 0.009892729111015797\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 13.34it/s, v_num=365, train_loss_step=0.0128, train_loss_epoch=0.00989] Epoch 188: Train Loss = 0.012803792022168636\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=365, train_loss_step=0.0114, train_loss_epoch=0.0128] Epoch 189: Train Loss = 0.011438915506005287\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=365, train_loss_step=0.0103, train_loss_epoch=0.0114]Epoch 190: Train Loss = 0.010348731651902199\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=365, train_loss_step=0.0142, train_loss_epoch=0.0103]Epoch 191: Train Loss = 0.01418284885585308\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.0142]Epoch 192: Train Loss = 0.010368868708610535\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=365, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 193: Train Loss = 0.011507362127304077\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.0115]Epoch 194: Train Loss = 0.01129991002380848\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 12.64it/s, v_num=365, train_loss_step=0.0118, train_loss_epoch=0.0113]Epoch 195: Train Loss = 0.01176855992525816\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=365, train_loss_step=0.0116, train_loss_epoch=0.0118]Epoch 196: Train Loss = 0.011554700322449207\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=365, train_loss_step=0.0134, train_loss_epoch=0.0116]Epoch 197: Train Loss = 0.013405169360339642\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=365, train_loss_step=0.0106, train_loss_epoch=0.0134]Epoch 198: Train Loss = 0.010606491006910801\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=365, train_loss_step=0.0128, train_loss_epoch=0.0106]Epoch 199: Train Loss = 0.012844452634453773\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=365, train_loss_step=0.00846, train_loss_epoch=0.0128]Epoch 200: Train Loss = 0.008459975011646748\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 16.14it/s, v_num=365, train_loss_step=0.0115, train_loss_epoch=0.00846] Epoch 201: Train Loss = 0.011477142572402954\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s, v_num=365, train_loss_step=0.011, train_loss_epoch=0.0115]  Epoch 202: Train Loss = 0.01097734272480011\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=365, train_loss_step=0.0182, train_loss_epoch=0.011]Epoch 203: Train Loss = 0.018167246133089066\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=365, train_loss_step=0.012, train_loss_epoch=0.0182] Epoch 204: Train Loss = 0.012027866207063198\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=365, train_loss_step=0.0132, train_loss_epoch=0.012]Epoch 205: Train Loss = 0.013210857287049294\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=365, train_loss_step=0.00957, train_loss_epoch=0.0132]Epoch 206: Train Loss = 0.009569172747433186\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.00957] Epoch 207: Train Loss = 0.010360890999436378\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=365, train_loss_step=0.0107, train_loss_epoch=0.0104] Epoch 208: Train Loss = 0.01070356648415327\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=365, train_loss_step=0.00935, train_loss_epoch=0.0107]Epoch 209: Train Loss = 0.009345440194010735\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=365, train_loss_step=0.00898, train_loss_epoch=0.00935]Epoch 210: Train Loss = 0.008979626931250095\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=365, train_loss_step=0.00986, train_loss_epoch=0.00898]Epoch 211: Train Loss = 0.00986019242554903\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=365, train_loss_step=0.0141, train_loss_epoch=0.00986] Epoch 212: Train Loss = 0.01410801149904728\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=365, train_loss_step=0.00961, train_loss_epoch=0.0141]Epoch 213: Train Loss = 0.009612980298697948\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=365, train_loss_step=0.00959, train_loss_epoch=0.00961]Epoch 214: Train Loss = 0.009594673290848732\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=365, train_loss_step=0.00991, train_loss_epoch=0.00959]Epoch 215: Train Loss = 0.009914957918226719\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.00991] Epoch 216: Train Loss = 0.010435759089887142\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=365, train_loss_step=0.00923, train_loss_epoch=0.0104]Epoch 217: Train Loss = 0.009228781796991825\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=365, train_loss_step=0.00922, train_loss_epoch=0.00923]Epoch 218: Train Loss = 0.009223022498190403\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=365, train_loss_step=0.0121, train_loss_epoch=0.00922] Epoch 219: Train Loss = 0.0120594697073102\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=365, train_loss_step=0.00836, train_loss_epoch=0.0121]Epoch 220: Train Loss = 0.008357921615242958\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=365, train_loss_step=0.0142, train_loss_epoch=0.00836] Epoch 221: Train Loss = 0.014225861988961697\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=365, train_loss_step=0.0143, train_loss_epoch=0.0142] Epoch 222: Train Loss = 0.01433944795280695\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=365, train_loss_step=0.00938, train_loss_epoch=0.0143]Epoch 223: Train Loss = 0.009382246062159538\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=365, train_loss_step=0.00785, train_loss_epoch=0.00938]Epoch 224: Train Loss = 0.007853124290704727\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.00785] Epoch 225: Train Loss = 0.010407415218651295\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=365, train_loss_step=0.00976, train_loss_epoch=0.0104]Epoch 226: Train Loss = 0.009755543433129787\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=365, train_loss_step=0.0093, train_loss_epoch=0.00976] Epoch 227: Train Loss = 0.009296943433582783\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=365, train_loss_step=0.00968, train_loss_epoch=0.0093]Epoch 228: Train Loss = 0.009678871370851994\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=365, train_loss_step=0.0127, train_loss_epoch=0.00968] Epoch 229: Train Loss = 0.012669314630329609\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=365, train_loss_step=0.0102, train_loss_epoch=0.0127] Epoch 230: Train Loss = 0.010184803046286106\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=365, train_loss_step=0.0136, train_loss_epoch=0.0102]Epoch 231: Train Loss = 0.013607158325612545\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=365, train_loss_step=0.0103, train_loss_epoch=0.0136]Epoch 232: Train Loss = 0.010337910614907742\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=365, train_loss_step=0.0107, train_loss_epoch=0.0103]Epoch 233: Train Loss = 0.010714597068727016\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=365, train_loss_step=0.0119, train_loss_epoch=0.0107]Epoch 234: Train Loss = 0.01187938917428255\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=365, train_loss_step=0.00964, train_loss_epoch=0.0119]Epoch 235: Train Loss = 0.00964427925646305\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=365, train_loss_step=0.00959, train_loss_epoch=0.00964]Epoch 236: Train Loss = 0.009587062522768974\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=365, train_loss_step=0.00934, train_loss_epoch=0.00959]Epoch 237: Train Loss = 0.009337997995316982\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s, v_num=365, train_loss_step=0.00908, train_loss_epoch=0.00934]Epoch 238: Train Loss = 0.009075545705854893\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=365, train_loss_step=0.0109, train_loss_epoch=0.00908] Epoch 239: Train Loss = 0.010921657085418701\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=365, train_loss_step=0.00829, train_loss_epoch=0.0109]Epoch 240: Train Loss = 0.008292511105537415\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=365, train_loss_step=0.012, train_loss_epoch=0.00829]  Epoch 241: Train Loss = 0.012030094861984253\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s, v_num=365, train_loss_step=0.0083, train_loss_epoch=0.012] Epoch 242: Train Loss = 0.008297459222376347\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=365, train_loss_step=0.012, train_loss_epoch=0.0083] Epoch 243: Train Loss = 0.01199278049170971\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=365, train_loss_step=0.010, train_loss_epoch=0.012] Epoch 244: Train Loss = 0.010044366121292114\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.010]Epoch 245: Train Loss = 0.010840276256203651\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=365, train_loss_step=0.00974, train_loss_epoch=0.0108]Epoch 246: Train Loss = 0.009739505127072334\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=365, train_loss_step=0.013, train_loss_epoch=0.00974]  Epoch 247: Train Loss = 0.01295006088912487\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.013] Epoch 248: Train Loss = 0.011316545307636261\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=365, train_loss_step=0.00888, train_loss_epoch=0.0113]Epoch 249: Train Loss = 0.008882865309715271\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=365, train_loss_step=0.0146, train_loss_epoch=0.00888] Epoch 250: Train Loss = 0.014623123221099377\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=365, train_loss_step=0.0107, train_loss_epoch=0.0146] Epoch 251: Train Loss = 0.010742178186774254\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=365, train_loss_step=0.0101, train_loss_epoch=0.0107]Epoch 252: Train Loss = 0.010146361775696278\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=365, train_loss_step=0.00668, train_loss_epoch=0.0101]Epoch 253: Train Loss = 0.006682385224848986\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=365, train_loss_step=0.0121, train_loss_epoch=0.00668] Epoch 254: Train Loss = 0.012121316976845264\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=365, train_loss_step=0.012, train_loss_epoch=0.0121]  Epoch 255: Train Loss = 0.012014148756861687\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=365, train_loss_step=0.00857, train_loss_epoch=0.012]Epoch 256: Train Loss = 0.008567308075726032\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=365, train_loss_step=0.00884, train_loss_epoch=0.00857]Epoch 257: Train Loss = 0.00884194951504469\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=365, train_loss_step=0.011, train_loss_epoch=0.00884]  Epoch 258: Train Loss = 0.011025208048522472\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=365, train_loss_step=0.0138, train_loss_epoch=0.011] Epoch 259: Train Loss = 0.01378700416535139\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=365, train_loss_step=0.00852, train_loss_epoch=0.0138]Epoch 260: Train Loss = 0.008524461649358273\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 14.17it/s, v_num=365, train_loss_step=0.00998, train_loss_epoch=0.00852]Epoch 261: Train Loss = 0.00997870322316885\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=365, train_loss_step=0.0095, train_loss_epoch=0.00998] Epoch 262: Train Loss = 0.009502251632511616\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=365, train_loss_step=0.00956, train_loss_epoch=0.0095]Epoch 263: Train Loss = 0.00955939944833517\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=365, train_loss_step=0.0131, train_loss_epoch=0.00956] Epoch 264: Train Loss = 0.013116640038788319\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=365, train_loss_step=0.0135, train_loss_epoch=0.0131] Epoch 265: Train Loss = 0.013494597747921944\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=365, train_loss_step=0.00996, train_loss_epoch=0.0135]Epoch 266: Train Loss = 0.00995737873017788\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=365, train_loss_step=0.0152, train_loss_epoch=0.00996] Epoch 267: Train Loss = 0.015188184566795826\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=365, train_loss_step=0.00855, train_loss_epoch=0.0152]Epoch 268: Train Loss = 0.008552097715437412\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=365, train_loss_step=0.0145, train_loss_epoch=0.00855] Epoch 269: Train Loss = 0.014467855915427208\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 13.34it/s, v_num=365, train_loss_step=0.0125, train_loss_epoch=0.0145] Epoch 270: Train Loss = 0.012549336068332195\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=365, train_loss_step=0.0114, train_loss_epoch=0.0125]Epoch 271: Train Loss = 0.0114129688590765\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=365, train_loss_step=0.0103, train_loss_epoch=0.0114]Epoch 272: Train Loss = 0.01030209194868803\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=365, train_loss_step=0.0122, train_loss_epoch=0.0103]Epoch 273: Train Loss = 0.012189364992082119\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s, v_num=365, train_loss_step=0.0124, train_loss_epoch=0.0122]Epoch 274: Train Loss = 0.012405745685100555\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=365, train_loss_step=0.00871, train_loss_epoch=0.0124]Epoch 275: Train Loss = 0.00871098879724741\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=365, train_loss_step=0.0095, train_loss_epoch=0.00871] Epoch 276: Train Loss = 0.009504267014563084\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=365, train_loss_step=0.0106, train_loss_epoch=0.0095] Epoch 277: Train Loss = 0.01056104339659214\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=365, train_loss_step=0.014, train_loss_epoch=0.0106] Epoch 278: Train Loss = 0.014020407572388649\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.014]Epoch 279: Train Loss = 0.010421106591820717\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 11.34it/s, v_num=365, train_loss_step=0.012, train_loss_epoch=0.0104] Epoch 280: Train Loss = 0.012044720351696014\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=365, train_loss_step=0.00871, train_loss_epoch=0.012]Epoch 281: Train Loss = 0.008705215528607368\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 13.91it/s, v_num=365, train_loss_step=0.00983, train_loss_epoch=0.00871]Epoch 282: Train Loss = 0.00982879102230072\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.00983] Epoch 283: Train Loss = 0.010428695939481258\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=365, train_loss_step=0.00838, train_loss_epoch=0.0104]Epoch 284: Train Loss = 0.008384177461266518\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=365, train_loss_step=0.00665, train_loss_epoch=0.00838]Epoch 285: Train Loss = 0.006649774964898825\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=365, train_loss_step=0.00841, train_loss_epoch=0.00665]Epoch 286: Train Loss = 0.00841315183788538\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=365, train_loss_step=0.0117, train_loss_epoch=0.00841] Epoch 287: Train Loss = 0.011726371012628078\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=365, train_loss_step=0.00809, train_loss_epoch=0.0117]Epoch 288: Train Loss = 0.008089015260338783\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=365, train_loss_step=0.00803, train_loss_epoch=0.00809]Epoch 289: Train Loss = 0.008033107034862041\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=365, train_loss_step=0.00803, train_loss_epoch=0.00803]Epoch 290: Train Loss = 0.008031661622226238\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=365, train_loss_step=0.0105, train_loss_epoch=0.00803] Epoch 291: Train Loss = 0.010543720796704292\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=365, train_loss_step=0.0101, train_loss_epoch=0.0105] Epoch 292: Train Loss = 0.010139750316739082\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=365, train_loss_step=0.0101, train_loss_epoch=0.0101]Epoch 293: Train Loss = 0.010071669705212116\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=365, train_loss_step=0.00988, train_loss_epoch=0.0101]Epoch 294: Train Loss = 0.009881076402962208\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=365, train_loss_step=0.00962, train_loss_epoch=0.00988]Epoch 295: Train Loss = 0.009620835073292255\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=365, train_loss_step=0.0105, train_loss_epoch=0.00962] Epoch 296: Train Loss = 0.010509454645216465\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=365, train_loss_step=0.0107, train_loss_epoch=0.0105] Epoch 297: Train Loss = 0.010719947516918182\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 12.64it/s, v_num=365, train_loss_step=0.00876, train_loss_epoch=0.0107]Epoch 298: Train Loss = 0.008764333091676235\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s, v_num=365, train_loss_step=0.00879, train_loss_epoch=0.00876]Epoch 299: Train Loss = 0.008791415952146053\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s, v_num=365, train_loss_step=0.0102, train_loss_epoch=0.00879] Epoch 300: Train Loss = 0.010187149047851562\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=365, train_loss_step=0.0103, train_loss_epoch=0.0102] Epoch 301: Train Loss = 0.010310746729373932\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=365, train_loss_step=0.00936, train_loss_epoch=0.0103]Epoch 302: Train Loss = 0.009363159537315369\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=365, train_loss_step=0.0078, train_loss_epoch=0.00936] Epoch 303: Train Loss = 0.007803397718816996\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=365, train_loss_step=0.0088, train_loss_epoch=0.0078] Epoch 304: Train Loss = 0.00880326610058546\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=365, train_loss_step=0.00966, train_loss_epoch=0.0088]Epoch 305: Train Loss = 0.009659175761044025\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=365, train_loss_step=0.00944, train_loss_epoch=0.00966]Epoch 306: Train Loss = 0.009439625777304173\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.00944] Epoch 307: Train Loss = 0.010789823718369007\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=365, train_loss_step=0.00869, train_loss_epoch=0.0108]Epoch 308: Train Loss = 0.008688918314874172\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=365, train_loss_step=0.0125, train_loss_epoch=0.00869] Epoch 309: Train Loss = 0.012457192875444889\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=365, train_loss_step=0.00987, train_loss_epoch=0.0125]Epoch 310: Train Loss = 0.009869963862001896\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=365, train_loss_step=0.00874, train_loss_epoch=0.00987]Epoch 311: Train Loss = 0.008739427663385868\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=365, train_loss_step=0.0074, train_loss_epoch=0.00874] Epoch 312: Train Loss = 0.007397151552140713\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=365, train_loss_step=0.0112, train_loss_epoch=0.0074] Epoch 313: Train Loss = 0.011248297989368439\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=365, train_loss_step=0.0131, train_loss_epoch=0.0112]Epoch 314: Train Loss = 0.013082141987979412\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=365, train_loss_step=0.00999, train_loss_epoch=0.0131]Epoch 315: Train Loss = 0.009991014376282692\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=365, train_loss_step=0.0109, train_loss_epoch=0.00999] Epoch 316: Train Loss = 0.010911687277257442\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 13.68it/s, v_num=365, train_loss_step=0.0109, train_loss_epoch=0.0109] Epoch 317: Train Loss = 0.010902070440351963\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=365, train_loss_step=0.00747, train_loss_epoch=0.0109]Epoch 318: Train Loss = 0.007465002592653036\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=365, train_loss_step=0.009, train_loss_epoch=0.00747]  Epoch 319: Train Loss = 0.00899612344801426\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.009] Epoch 320: Train Loss = 0.010432985611259937\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=365, train_loss_step=0.00987, train_loss_epoch=0.0104]Epoch 321: Train Loss = 0.009869699366390705\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=365, train_loss_step=0.00936, train_loss_epoch=0.00987]Epoch 322: Train Loss = 0.009363099932670593\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 13.32it/s, v_num=365, train_loss_step=0.00796, train_loss_epoch=0.00936]Epoch 323: Train Loss = 0.00795824360102415\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.00796] Epoch 324: Train Loss = 0.011266930028796196\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=365, train_loss_step=0.00794, train_loss_epoch=0.0113]Epoch 325: Train Loss = 0.00794361811131239\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=365, train_loss_step=0.00801, train_loss_epoch=0.00794]Epoch 326: Train Loss = 0.008010285906493664\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=365, train_loss_step=0.0109, train_loss_epoch=0.00801] Epoch 327: Train Loss = 0.010935841128230095\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.0109] Epoch 328: Train Loss = 0.01082070916891098\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=365, train_loss_step=0.00894, train_loss_epoch=0.0108]Epoch 329: Train Loss = 0.008938501589000225\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=365, train_loss_step=0.0121, train_loss_epoch=0.00894] Epoch 330: Train Loss = 0.012133089825510979\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 12.75it/s, v_num=365, train_loss_step=0.0102, train_loss_epoch=0.0121] Epoch 331: Train Loss = 0.010204934515058994\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=365, train_loss_step=0.00827, train_loss_epoch=0.0102]Epoch 332: Train Loss = 0.00826908741146326\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.00827] Epoch 333: Train Loss = 0.010815160349011421\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=365, train_loss_step=0.0099, train_loss_epoch=0.0108] Epoch 334: Train Loss = 0.00990262906998396\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=365, train_loss_step=0.00872, train_loss_epoch=0.0099]Epoch 335: Train Loss = 0.008719510398805141\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=365, train_loss_step=0.012, train_loss_epoch=0.00872]  Epoch 336: Train Loss = 0.011976518668234348\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=365, train_loss_step=0.0123, train_loss_epoch=0.012] Epoch 337: Train Loss = 0.01234977412968874\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=365, train_loss_step=0.011, train_loss_epoch=0.0123] Epoch 338: Train Loss = 0.01102748978883028\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=365, train_loss_step=0.0121, train_loss_epoch=0.011]Epoch 339: Train Loss = 0.012102882377803326\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=365, train_loss_step=0.0168, train_loss_epoch=0.0121]Epoch 340: Train Loss = 0.0167985986918211\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=365, train_loss_step=0.0128, train_loss_epoch=0.0168]Epoch 341: Train Loss = 0.012754089199006557\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=365, train_loss_step=0.00992, train_loss_epoch=0.0128]Epoch 342: Train Loss = 0.009922238066792488\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=365, train_loss_step=0.0191, train_loss_epoch=0.00992] Epoch 343: Train Loss = 0.019075116142630577\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=365, train_loss_step=0.0107, train_loss_epoch=0.0191] Epoch 344: Train Loss = 0.01069142110645771\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=365, train_loss_step=0.00892, train_loss_epoch=0.0107]Epoch 345: Train Loss = 0.008916296064853668\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=365, train_loss_step=0.00921, train_loss_epoch=0.00892]Epoch 346: Train Loss = 0.00920803565531969\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 13.13it/s, v_num=365, train_loss_step=0.0126, train_loss_epoch=0.00921] Epoch 347: Train Loss = 0.012563280761241913\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=365, train_loss_step=0.0117, train_loss_epoch=0.0126] Epoch 348: Train Loss = 0.011666868813335896\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=365, train_loss_step=0.010, train_loss_epoch=0.0117] Epoch 349: Train Loss = 0.010011985898017883\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=365, train_loss_step=0.0123, train_loss_epoch=0.010]Epoch 350: Train Loss = 0.012303375639021397\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=365, train_loss_step=0.0146, train_loss_epoch=0.0123]Epoch 351: Train Loss = 0.014557762071490288\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=365, train_loss_step=0.014, train_loss_epoch=0.0146] Epoch 352: Train Loss = 0.014031327329576015\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=365, train_loss_step=0.0122, train_loss_epoch=0.014]Epoch 353: Train Loss = 0.01224223431199789\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=365, train_loss_step=0.00978, train_loss_epoch=0.0122]Epoch 354: Train Loss = 0.009783723391592503\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 13.64it/s, v_num=365, train_loss_step=0.0106, train_loss_epoch=0.00978] Epoch 355: Train Loss = 0.01062949188053608\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 11.21it/s, v_num=365, train_loss_step=0.0114, train_loss_epoch=0.0106] Epoch 356: Train Loss = 0.011396155692636967\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=365, train_loss_step=0.00827, train_loss_epoch=0.0114]Epoch 357: Train Loss = 0.00827272329479456\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=365, train_loss_step=0.0132, train_loss_epoch=0.00827] Epoch 358: Train Loss = 0.013189931400120258\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=365, train_loss_step=0.0102, train_loss_epoch=0.0132] Epoch 359: Train Loss = 0.010248963721096516\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 13.81it/s, v_num=365, train_loss_step=0.0081, train_loss_epoch=0.0102]Epoch 360: Train Loss = 0.008100727573037148\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=365, train_loss_step=0.0128, train_loss_epoch=0.0081]Epoch 361: Train Loss = 0.01284727267920971\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=365, train_loss_step=0.012, train_loss_epoch=0.0128] Epoch 362: Train Loss = 0.011960886418819427\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=365, train_loss_step=0.0075, train_loss_epoch=0.012]Epoch 363: Train Loss = 0.007504552137106657\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=365, train_loss_step=0.0148, train_loss_epoch=0.0075]Epoch 364: Train Loss = 0.014841662719845772\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=365, train_loss_step=0.0123, train_loss_epoch=0.0148]Epoch 365: Train Loss = 0.012284763157367706\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=365, train_loss_step=0.00895, train_loss_epoch=0.0123]Epoch 366: Train Loss = 0.008948354050517082\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=365, train_loss_step=0.0117, train_loss_epoch=0.00895] Epoch 367: Train Loss = 0.011684508994221687\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=365, train_loss_step=0.0147, train_loss_epoch=0.0117] Epoch 368: Train Loss = 0.014651315286755562\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=365, train_loss_step=0.0112, train_loss_epoch=0.0147]Epoch 369: Train Loss = 0.011163955554366112\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=365, train_loss_step=0.00775, train_loss_epoch=0.0112]Epoch 370: Train Loss = 0.00774910394102335\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=365, train_loss_step=0.0127, train_loss_epoch=0.00775] Epoch 371: Train Loss = 0.012672677636146545\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=365, train_loss_step=0.00953, train_loss_epoch=0.0127]Epoch 372: Train Loss = 0.009529618546366692\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=365, train_loss_step=0.00996, train_loss_epoch=0.00953]Epoch 373: Train Loss = 0.009962216019630432\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, v_num=365, train_loss_step=0.0106, train_loss_epoch=0.00996] Epoch 374: Train Loss = 0.010589621029794216\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=365, train_loss_step=0.0106, train_loss_epoch=0.0106] Epoch 375: Train Loss = 0.01062639057636261\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=365, train_loss_step=0.00824, train_loss_epoch=0.0106]Epoch 376: Train Loss = 0.00824365671724081\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=365, train_loss_step=0.00893, train_loss_epoch=0.00824]Epoch 377: Train Loss = 0.0089321443811059\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.00893] Epoch 378: Train Loss = 0.01126872282475233\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=365, train_loss_step=0.0101, train_loss_epoch=0.0113] Epoch 379: Train Loss = 0.010091928765177727\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=365, train_loss_step=0.0134, train_loss_epoch=0.0101]Epoch 380: Train Loss = 0.013378282077610493\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=365, train_loss_step=0.00822, train_loss_epoch=0.0134]Epoch 381: Train Loss = 0.008223154582083225\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 10.17it/s, v_num=365, train_loss_step=0.0119, train_loss_epoch=0.00822] Epoch 382: Train Loss = 0.011883826926350594\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=365, train_loss_step=0.015, train_loss_epoch=0.0119]  Epoch 383: Train Loss = 0.014998676255345345\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=365, train_loss_step=0.00888, train_loss_epoch=0.015]Epoch 384: Train Loss = 0.008878263644874096\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=365, train_loss_step=0.00954, train_loss_epoch=0.00888]Epoch 385: Train Loss = 0.00954306311905384\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=365, train_loss_step=0.00992, train_loss_epoch=0.00954]Epoch 386: Train Loss = 0.00992398988455534\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=365, train_loss_step=0.00944, train_loss_epoch=0.00992]Epoch 387: Train Loss = 0.009438564069569111\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=365, train_loss_step=0.0117, train_loss_epoch=0.00944] Epoch 388: Train Loss = 0.011719130910933018\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=365, train_loss_step=0.00846, train_loss_epoch=0.0117]Epoch 389: Train Loss = 0.008459800854325294\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=365, train_loss_step=0.00903, train_loss_epoch=0.00846]Epoch 390: Train Loss = 0.009033137001097202\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=365, train_loss_step=0.00856, train_loss_epoch=0.00903]Epoch 391: Train Loss = 0.008558625355362892\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=365, train_loss_step=0.0105, train_loss_epoch=0.00856] Epoch 392: Train Loss = 0.010464757680892944\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 13.01it/s, v_num=365, train_loss_step=0.00957, train_loss_epoch=0.0105]Epoch 393: Train Loss = 0.009570921771228313\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=365, train_loss_step=0.0111, train_loss_epoch=0.00957] Epoch 394: Train Loss = 0.01110411249101162\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.0111] Epoch 395: Train Loss = 0.010394466109573841\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=365, train_loss_step=0.00992, train_loss_epoch=0.0104]Epoch 396: Train Loss = 0.009921540506184101\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=365, train_loss_step=0.00857, train_loss_epoch=0.00992]Epoch 397: Train Loss = 0.008570789359509945\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=365, train_loss_step=0.0103, train_loss_epoch=0.00857] Epoch 398: Train Loss = 0.01027270220220089\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, v_num=365, train_loss_step=0.00874, train_loss_epoch=0.0103]Epoch 399: Train Loss = 0.008738257922232151\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.00874] Epoch 400: Train Loss = 0.01128356996923685\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=365, train_loss_step=0.0084, train_loss_epoch=0.0113] Epoch 401: Train Loss = 0.008403794839978218\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 14.17it/s, v_num=365, train_loss_step=0.0103, train_loss_epoch=0.0084]Epoch 402: Train Loss = 0.010264317505061626\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=365, train_loss_step=0.010, train_loss_epoch=0.0103] Epoch 403: Train Loss = 0.00999951921403408\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=365, train_loss_step=0.00852, train_loss_epoch=0.010]Epoch 404: Train Loss = 0.008517367765307426\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=365, train_loss_step=0.00767, train_loss_epoch=0.00852]Epoch 405: Train Loss = 0.007672685664147139\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=365, train_loss_step=0.0113, train_loss_epoch=0.00767] Epoch 406: Train Loss = 0.011286904104053974\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=365, train_loss_step=0.0103, train_loss_epoch=0.0113] Epoch 407: Train Loss = 0.010273623280227184\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=365, train_loss_step=0.00773, train_loss_epoch=0.0103]Epoch 408: Train Loss = 0.007730033714324236\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=365, train_loss_step=0.00823, train_loss_epoch=0.00773]Epoch 409: Train Loss = 0.008229573257267475\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=365, train_loss_step=0.0123, train_loss_epoch=0.00823] Epoch 410: Train Loss = 0.012338842265307903\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=365, train_loss_step=0.00985, train_loss_epoch=0.0123]Epoch 411: Train Loss = 0.00985388271510601\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=365, train_loss_step=0.00975, train_loss_epoch=0.00985]Epoch 412: Train Loss = 0.009751405566930771\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=365, train_loss_step=0.0103, train_loss_epoch=0.00975] Epoch 413: Train Loss = 0.010286236181855202\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=365, train_loss_step=0.00673, train_loss_epoch=0.0103]Epoch 414: Train Loss = 0.006730408873409033\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=365, train_loss_step=0.0125, train_loss_epoch=0.00673] Epoch 415: Train Loss = 0.012460927478969097\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=365, train_loss_step=0.00964, train_loss_epoch=0.0125]Epoch 416: Train Loss = 0.009638414718210697\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=365, train_loss_step=0.00887, train_loss_epoch=0.00964]Epoch 417: Train Loss = 0.0088694142177701\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=365, train_loss_step=0.0106, train_loss_epoch=0.00887] Epoch 418: Train Loss = 0.010553570464253426\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=365, train_loss_step=0.00956, train_loss_epoch=0.0106]Epoch 419: Train Loss = 0.009558333083987236\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=365, train_loss_step=0.00896, train_loss_epoch=0.00956]Epoch 420: Train Loss = 0.008963893167674541\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 12.97it/s, v_num=365, train_loss_step=0.0115, train_loss_epoch=0.00896] Epoch 421: Train Loss = 0.01145503856241703\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=365, train_loss_step=0.00936, train_loss_epoch=0.0115]Epoch 422: Train Loss = 0.009355383925139904\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=365, train_loss_step=0.00881, train_loss_epoch=0.00936]Epoch 423: Train Loss = 0.008812721818685532\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=365, train_loss_step=0.00947, train_loss_epoch=0.00881]Epoch 424: Train Loss = 0.009470045566558838\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=365, train_loss_step=0.00997, train_loss_epoch=0.00947]Epoch 425: Train Loss = 0.009967079386115074\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=365, train_loss_step=0.00924, train_loss_epoch=0.00997]Epoch 426: Train Loss = 0.009236699901521206\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=365, train_loss_step=0.00949, train_loss_epoch=0.00924]Epoch 427: Train Loss = 0.009487936273217201\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=365, train_loss_step=0.0101, train_loss_epoch=0.00949] Epoch 428: Train Loss = 0.01014233659952879\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=365, train_loss_step=0.00789, train_loss_epoch=0.0101]Epoch 429: Train Loss = 0.007893283851444721\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=365, train_loss_step=0.0109, train_loss_epoch=0.00789] Epoch 430: Train Loss = 0.010883950628340244\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=365, train_loss_step=0.00992, train_loss_epoch=0.0109]Epoch 431: Train Loss = 0.00992459338158369\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=365, train_loss_step=0.0116, train_loss_epoch=0.00992] Epoch 432: Train Loss = 0.011598517186939716\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=365, train_loss_step=0.0119, train_loss_epoch=0.0116] Epoch 433: Train Loss = 0.011867284774780273\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s, v_num=365, train_loss_step=0.00954, train_loss_epoch=0.0119]Epoch 434: Train Loss = 0.009537448175251484\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s, v_num=365, train_loss_step=0.0116, train_loss_epoch=0.00954] Epoch 435: Train Loss = 0.01161638181656599\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.0116] Epoch 436: Train Loss = 0.010389811359345913\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=365, train_loss_step=0.0118, train_loss_epoch=0.0104]Epoch 437: Train Loss = 0.011830835603177547\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=365, train_loss_step=0.00881, train_loss_epoch=0.0118]Epoch 438: Train Loss = 0.00881196465343237\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=365, train_loss_step=0.00778, train_loss_epoch=0.00881]Epoch 439: Train Loss = 0.007778320927172899\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=365, train_loss_step=0.00817, train_loss_epoch=0.00778]Epoch 440: Train Loss = 0.008174799382686615\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=365, train_loss_step=0.0107, train_loss_epoch=0.00817] Epoch 441: Train Loss = 0.010740610770881176\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=365, train_loss_step=0.00938, train_loss_epoch=0.0107]Epoch 442: Train Loss = 0.009381371550261974\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=365, train_loss_step=0.00912, train_loss_epoch=0.00938]Epoch 443: Train Loss = 0.0091154919937253\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=365, train_loss_step=0.00749, train_loss_epoch=0.00912]Epoch 444: Train Loss = 0.007487253751605749\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=365, train_loss_step=0.0103, train_loss_epoch=0.00749] Epoch 445: Train Loss = 0.010312181897461414\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.0103] Epoch 446: Train Loss = 0.010377430357038975\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=365, train_loss_step=0.0116, train_loss_epoch=0.0104]Epoch 447: Train Loss = 0.011595457792282104\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=365, train_loss_step=0.00773, train_loss_epoch=0.0116]Epoch 448: Train Loss = 0.007725171744823456\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=365, train_loss_step=0.00895, train_loss_epoch=0.00773]Epoch 449: Train Loss = 0.00895213894546032\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=365, train_loss_step=0.0084, train_loss_epoch=0.00895] Epoch 450: Train Loss = 0.008395343087613583\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=365, train_loss_step=0.00828, train_loss_epoch=0.0084]Epoch 451: Train Loss = 0.008283029310405254\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=365, train_loss_step=0.00871, train_loss_epoch=0.00828]Epoch 452: Train Loss = 0.008708428591489792\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=365, train_loss_step=0.00849, train_loss_epoch=0.00871]Epoch 453: Train Loss = 0.00849497877061367\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=365, train_loss_step=0.0129, train_loss_epoch=0.00849] Epoch 454: Train Loss = 0.012908175587654114\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=365, train_loss_step=0.00999, train_loss_epoch=0.0129]Epoch 455: Train Loss = 0.009990150108933449\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=365, train_loss_step=0.010, train_loss_epoch=0.00999]  Epoch 456: Train Loss = 0.010021519847214222\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=365, train_loss_step=0.00812, train_loss_epoch=0.010]Epoch 457: Train Loss = 0.008118787780404091\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=365, train_loss_step=0.0121, train_loss_epoch=0.00812] Epoch 458: Train Loss = 0.012077271938323975\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=365, train_loss_step=0.0101, train_loss_epoch=0.0121] Epoch 459: Train Loss = 0.010075296275317669\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=365, train_loss_step=0.00975, train_loss_epoch=0.0101]Epoch 460: Train Loss = 0.009751135483384132\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=365, train_loss_step=0.012, train_loss_epoch=0.00975]  Epoch 461: Train Loss = 0.011955276131629944\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=365, train_loss_step=0.0089, train_loss_epoch=0.012] Epoch 462: Train Loss = 0.008902515284717083\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=365, train_loss_step=0.00883, train_loss_epoch=0.0089]Epoch 463: Train Loss = 0.008833224885165691\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=365, train_loss_step=0.00945, train_loss_epoch=0.00883]Epoch 464: Train Loss = 0.00944518018513918\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=365, train_loss_step=0.011, train_loss_epoch=0.00945]  Epoch 465: Train Loss = 0.011027387343347073\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s, v_num=365, train_loss_step=0.00886, train_loss_epoch=0.011]Epoch 466: Train Loss = 0.008856290020048618\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=365, train_loss_step=0.0079, train_loss_epoch=0.00886] Epoch 467: Train Loss = 0.007902839221060276\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=365, train_loss_step=0.0109, train_loss_epoch=0.0079] Epoch 468: Train Loss = 0.010919996537268162\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=365, train_loss_step=0.0107, train_loss_epoch=0.0109]Epoch 469: Train Loss = 0.010687695816159248\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=365, train_loss_step=0.00891, train_loss_epoch=0.0107]Epoch 470: Train Loss = 0.008913733996450901\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=365, train_loss_step=0.00812, train_loss_epoch=0.00891]Epoch 471: Train Loss = 0.008122715167701244\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=365, train_loss_step=0.0128, train_loss_epoch=0.00812] Epoch 472: Train Loss = 0.012835514731705189\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=365, train_loss_step=0.00884, train_loss_epoch=0.0128]Epoch 473: Train Loss = 0.008840912953019142\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=365, train_loss_step=0.0087, train_loss_epoch=0.00884] Epoch 474: Train Loss = 0.008698707446455956\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=365, train_loss_step=0.00979, train_loss_epoch=0.0087]Epoch 475: Train Loss = 0.00978979654610157\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=365, train_loss_step=0.00821, train_loss_epoch=0.00979]Epoch 476: Train Loss = 0.00821191631257534\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=365, train_loss_step=0.00791, train_loss_epoch=0.00821]Epoch 477: Train Loss = 0.007912536151707172\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=365, train_loss_step=0.0133, train_loss_epoch=0.00791] Epoch 478: Train Loss = 0.01334576215595007\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=365, train_loss_step=0.00903, train_loss_epoch=0.0133]Epoch 479: Train Loss = 0.009029467590153217\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=365, train_loss_step=0.0144, train_loss_epoch=0.00903] Epoch 480: Train Loss = 0.014371528290212154\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=365, train_loss_step=0.0116, train_loss_epoch=0.0144] Epoch 481: Train Loss = 0.011558971367776394\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=365, train_loss_step=0.0107, train_loss_epoch=0.0116]Epoch 482: Train Loss = 0.010719651356339455\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=365, train_loss_step=0.0118, train_loss_epoch=0.0107]Epoch 483: Train Loss = 0.01180586963891983\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.0118]Epoch 484: Train Loss = 0.01077971886843443\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=365, train_loss_step=0.0158, train_loss_epoch=0.0108]Epoch 485: Train Loss = 0.015773525461554527\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=365, train_loss_step=0.0115, train_loss_epoch=0.0158]Epoch 486: Train Loss = 0.011478139087557793\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=365, train_loss_step=0.0101, train_loss_epoch=0.0115]Epoch 487: Train Loss = 0.010082715190947056\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=365, train_loss_step=0.013, train_loss_epoch=0.0101] Epoch 488: Train Loss = 0.012960156425833702\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, v_num=365, train_loss_step=0.0108, train_loss_epoch=0.013]Epoch 489: Train Loss = 0.010785664431750774\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 13.64it/s, v_num=365, train_loss_step=0.00779, train_loss_epoch=0.0108]Epoch 490: Train Loss = 0.007790873292833567\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=365, train_loss_step=0.00973, train_loss_epoch=0.00779]Epoch 491: Train Loss = 0.009733003564178944\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=365, train_loss_step=0.0083, train_loss_epoch=0.00973] Epoch 492: Train Loss = 0.008299528621137142\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=365, train_loss_step=0.0093, train_loss_epoch=0.0083] Epoch 493: Train Loss = 0.009300194680690765\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=365, train_loss_step=0.0104, train_loss_epoch=0.0093]Epoch 494: Train Loss = 0.010397173464298248\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=365, train_loss_step=0.0114, train_loss_epoch=0.0104]Epoch 495: Train Loss = 0.011372086592018604\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=365, train_loss_step=0.00929, train_loss_epoch=0.0114]Epoch 496: Train Loss = 0.009294116869568825\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=365, train_loss_step=0.00894, train_loss_epoch=0.00929]Epoch 497: Train Loss = 0.008939486928284168\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=365, train_loss_step=0.00923, train_loss_epoch=0.00894]Epoch 498: Train Loss = 0.009233906865119934\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.52it/s, v_num=365, train_loss_step=0.0129, train_loss_epoch=0.00923] Epoch 499: Train Loss = 0.012860586866736412\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.25it/s, v_num=365, train_loss_step=0.0129, train_loss_epoch=0.0129] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=365, train_loss_step=0.0129, train_loss_epoch=0.0129]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 13: from 2008-05-12 00:00:00 to 2022-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=367, train_loss_step=0.0237]Epoch 0: Train Loss = 0.023700585588812828\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=367, train_loss_step=0.0414, train_loss_epoch=0.0237]Epoch 1: Train Loss = 0.04141861945390701\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=367, train_loss_step=0.0236, train_loss_epoch=0.0414]Epoch 2: Train Loss = 0.02363378182053566\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=367, train_loss_step=0.0207, train_loss_epoch=0.0236]Epoch 3: Train Loss = 0.02066180109977722\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, v_num=367, train_loss_step=0.0186, train_loss_epoch=0.0207]Epoch 4: Train Loss = 0.01862763985991478\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 11.78it/s, v_num=367, train_loss_step=0.017, train_loss_epoch=0.0186] Epoch 5: Train Loss = 0.017011897638440132\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=367, train_loss_step=0.0139, train_loss_epoch=0.017]Epoch 6: Train Loss = 0.01392353791743517\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=367, train_loss_step=0.0167, train_loss_epoch=0.0139]Epoch 7: Train Loss = 0.016659028828144073\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=367, train_loss_step=0.022, train_loss_epoch=0.0167] Epoch 8: Train Loss = 0.021988702937960625\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=367, train_loss_step=0.0132, train_loss_epoch=0.022]Epoch 9: Train Loss = 0.013153484091162682\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=367, train_loss_step=0.0213, train_loss_epoch=0.0132]Epoch 10: Train Loss = 0.021272407844662666\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=367, train_loss_step=0.0125, train_loss_epoch=0.0213]Epoch 11: Train Loss = 0.012463279999792576\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=367, train_loss_step=0.0158, train_loss_epoch=0.0125]Epoch 12: Train Loss = 0.0158365648239851\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=367, train_loss_step=0.0174, train_loss_epoch=0.0158]Epoch 13: Train Loss = 0.01738564483821392\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=367, train_loss_step=0.0146, train_loss_epoch=0.0174]Epoch 14: Train Loss = 0.014623920433223248\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=367, train_loss_step=0.0123, train_loss_epoch=0.0146]Epoch 15: Train Loss = 0.012299991212785244\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=367, train_loss_step=0.0115, train_loss_epoch=0.0123]Epoch 16: Train Loss = 0.011505745351314545\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=367, train_loss_step=0.0179, train_loss_epoch=0.0115]Epoch 17: Train Loss = 0.017916711047291756\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=367, train_loss_step=0.0143, train_loss_epoch=0.0179]Epoch 18: Train Loss = 0.014250100590288639\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.0143]Epoch 19: Train Loss = 0.010209957137703896\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=367, train_loss_step=0.0164, train_loss_epoch=0.0102]Epoch 20: Train Loss = 0.01639973558485508\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=367, train_loss_step=0.0178, train_loss_epoch=0.0164]Epoch 21: Train Loss = 0.017759989947080612\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=367, train_loss_step=0.0167, train_loss_epoch=0.0178]Epoch 22: Train Loss = 0.01672722026705742\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 15.92it/s, v_num=367, train_loss_step=0.0135, train_loss_epoch=0.0167]Epoch 23: Train Loss = 0.013479218818247318\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=367, train_loss_step=0.012, train_loss_epoch=0.0135] Epoch 24: Train Loss = 0.01202373392879963\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=367, train_loss_step=0.0181, train_loss_epoch=0.012]Epoch 25: Train Loss = 0.01808471605181694\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=367, train_loss_step=0.00864, train_loss_epoch=0.0181]Epoch 26: Train Loss = 0.008637296967208385\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=367, train_loss_step=0.00935, train_loss_epoch=0.00864]Epoch 27: Train Loss = 0.009348815307021141\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=367, train_loss_step=0.0118, train_loss_epoch=0.00935] Epoch 28: Train Loss = 0.011767561547458172\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=367, train_loss_step=0.0123, train_loss_epoch=0.0118] Epoch 29: Train Loss = 0.01232475321739912\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=367, train_loss_step=0.0131, train_loss_epoch=0.0123]Epoch 30: Train Loss = 0.013112069107592106\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=367, train_loss_step=0.0135, train_loss_epoch=0.0131]Epoch 31: Train Loss = 0.013522808440029621\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=367, train_loss_step=0.0131, train_loss_epoch=0.0135]Epoch 32: Train Loss = 0.013068556785583496\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=367, train_loss_step=0.0151, train_loss_epoch=0.0131]Epoch 33: Train Loss = 0.01510158646851778\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.0151]Epoch 34: Train Loss = 0.011155858635902405\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=367, train_loss_step=0.0149, train_loss_epoch=0.0112]Epoch 35: Train Loss = 0.014911605976521969\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=367, train_loss_step=0.00824, train_loss_epoch=0.0149]Epoch 36: Train Loss = 0.008235504850745201\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.00824] Epoch 37: Train Loss = 0.011631375178694725\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=367, train_loss_step=0.0146, train_loss_epoch=0.0116] Epoch 38: Train Loss = 0.014581860043108463\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.0146]Epoch 39: Train Loss = 0.010918019339442253\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=367, train_loss_step=0.0135, train_loss_epoch=0.0109]Epoch 40: Train Loss = 0.013533912599086761\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.0135]Epoch 41: Train Loss = 0.01163423527032137\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0116]Epoch 42: Train Loss = 0.010330713354051113\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=367, train_loss_step=0.0134, train_loss_epoch=0.0103]Epoch 43: Train Loss = 0.013418393209576607\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=367, train_loss_step=0.0101, train_loss_epoch=0.0134]Epoch 44: Train Loss = 0.010144485160708427\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=367, train_loss_step=0.0121, train_loss_epoch=0.0101]Epoch 45: Train Loss = 0.01212973054498434\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=367, train_loss_step=0.0153, train_loss_epoch=0.0121]Epoch 46: Train Loss = 0.01534788217395544\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=367, train_loss_step=0.0124, train_loss_epoch=0.0153]Epoch 47: Train Loss = 0.01238947082310915\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=367, train_loss_step=0.0123, train_loss_epoch=0.0124]Epoch 48: Train Loss = 0.012304889038205147\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.0123]Epoch 49: Train Loss = 0.010881039313971996\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=367, train_loss_step=0.012, train_loss_epoch=0.0109] Epoch 50: Train Loss = 0.012007803656160831\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.012]Epoch 51: Train Loss = 0.010225391015410423\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=367, train_loss_step=0.0125, train_loss_epoch=0.0102]Epoch 52: Train Loss = 0.012525626458227634\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=367, train_loss_step=0.0104, train_loss_epoch=0.0125]Epoch 53: Train Loss = 0.01041218638420105\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=367, train_loss_step=0.0119, train_loss_epoch=0.0104]Epoch 54: Train Loss = 0.011894584633409977\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=367, train_loss_step=0.0127, train_loss_epoch=0.0119]Epoch 55: Train Loss = 0.01274105068296194\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s, v_num=367, train_loss_step=0.0132, train_loss_epoch=0.0127]Epoch 56: Train Loss = 0.013171962462365627\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=367, train_loss_step=0.0134, train_loss_epoch=0.0132]Epoch 57: Train Loss = 0.013412965461611748\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=367, train_loss_step=0.00795, train_loss_epoch=0.0134]Epoch 58: Train Loss = 0.007948005571961403\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=367, train_loss_step=0.0113, train_loss_epoch=0.00795] Epoch 59: Train Loss = 0.011287353001534939\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.0113] Epoch 60: Train Loss = 0.011167236603796482\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=367, train_loss_step=0.016, train_loss_epoch=0.0112] Epoch 61: Train Loss = 0.015981677919626236\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.016]Epoch 62: Train Loss = 0.010308601893484592\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.0103]Epoch 63: Train Loss = 0.010560251772403717\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.0106]Epoch 64: Train Loss = 0.010927380062639713\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=367, train_loss_step=0.0118, train_loss_epoch=0.0109]Epoch 65: Train Loss = 0.011830911040306091\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=367, train_loss_step=0.0107, train_loss_epoch=0.0118]Epoch 66: Train Loss = 0.010704576969146729\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=367, train_loss_step=0.00932, train_loss_epoch=0.0107]Epoch 67: Train Loss = 0.009317298419773579\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=367, train_loss_step=0.0113, train_loss_epoch=0.00932] Epoch 68: Train Loss = 0.011301257647573948\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=367, train_loss_step=0.00878, train_loss_epoch=0.0113]Epoch 69: Train Loss = 0.00878269225358963\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=367, train_loss_step=0.0127, train_loss_epoch=0.00878] Epoch 70: Train Loss = 0.012739353813230991\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=367, train_loss_step=0.0111, train_loss_epoch=0.0127] Epoch 71: Train Loss = 0.011080904863774776\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.0111]Epoch 72: Train Loss = 0.011563314124941826\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.0116]Epoch 73: Train Loss = 0.010861089453101158\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=367, train_loss_step=0.0104, train_loss_epoch=0.0109]Epoch 74: Train Loss = 0.010428463108837605\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=367, train_loss_step=0.00926, train_loss_epoch=0.0104]Epoch 75: Train Loss = 0.009256897494196892\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=367, train_loss_step=0.0132, train_loss_epoch=0.00926] Epoch 76: Train Loss = 0.013161166571080685\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=367, train_loss_step=0.0134, train_loss_epoch=0.0132] Epoch 77: Train Loss = 0.013449907302856445\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.0134]Epoch 78: Train Loss = 0.010770927183330059\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=367, train_loss_step=0.0142, train_loss_epoch=0.0108]Epoch 79: Train Loss = 0.014239104464650154\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=367, train_loss_step=0.0096, train_loss_epoch=0.0142]Epoch 80: Train Loss = 0.009600897319614887\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=367, train_loss_step=0.0129, train_loss_epoch=0.0096]Epoch 81: Train Loss = 0.012894711457192898\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.0129]Epoch 82: Train Loss = 0.010166297666728497\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=367, train_loss_step=0.00946, train_loss_epoch=0.0102]Epoch 83: Train Loss = 0.009463494643568993\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, v_num=367, train_loss_step=0.00997, train_loss_epoch=0.00946]Epoch 84: Train Loss = 0.009973320178687572\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=367, train_loss_step=0.00924, train_loss_epoch=0.00997]Epoch 85: Train Loss = 0.009241596795618534\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=367, train_loss_step=0.0101, train_loss_epoch=0.00924] Epoch 86: Train Loss = 0.010147273540496826\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=367, train_loss_step=0.0113, train_loss_epoch=0.0101] Epoch 87: Train Loss = 0.011324203573167324\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=367, train_loss_step=0.00937, train_loss_epoch=0.0113]Epoch 88: Train Loss = 0.009367810562252998\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=367, train_loss_step=0.016, train_loss_epoch=0.00937]  Epoch 89: Train Loss = 0.015965091064572334\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=367, train_loss_step=0.00791, train_loss_epoch=0.016]Epoch 90: Train Loss = 0.00791056826710701\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=367, train_loss_step=0.013, train_loss_epoch=0.00791]  Epoch 91: Train Loss = 0.012962442822754383\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=367, train_loss_step=0.0136, train_loss_epoch=0.013] Epoch 92: Train Loss = 0.013618473894894123\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=367, train_loss_step=0.0119, train_loss_epoch=0.0136]Epoch 93: Train Loss = 0.011934429407119751\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=367, train_loss_step=0.0136, train_loss_epoch=0.0119]Epoch 94: Train Loss = 0.013627558946609497\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=367, train_loss_step=0.0125, train_loss_epoch=0.0136]Epoch 95: Train Loss = 0.01248918753117323\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.0125]Epoch 96: Train Loss = 0.011616389267146587\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.0116]Epoch 97: Train Loss = 0.010632497258484364\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0106]Epoch 98: Train Loss = 0.010311129502952099\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 13.46it/s, v_num=367, train_loss_step=0.0125, train_loss_epoch=0.0103]Epoch 99: Train Loss = 0.012453007511794567\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=367, train_loss_step=0.00905, train_loss_epoch=0.0125]Epoch 100: Train Loss = 0.009053416550159454\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=367, train_loss_step=0.0126, train_loss_epoch=0.00905] Epoch 101: Train Loss = 0.012562514282763004\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=367, train_loss_step=0.00967, train_loss_epoch=0.0126]Epoch 102: Train Loss = 0.00966787151992321\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, v_num=367, train_loss_step=0.0123, train_loss_epoch=0.00967] Epoch 103: Train Loss = 0.012260017916560173\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=367, train_loss_step=0.00918, train_loss_epoch=0.0123]Epoch 104: Train Loss = 0.009183340705931187\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=367, train_loss_step=0.012, train_loss_epoch=0.00918]  Epoch 105: Train Loss = 0.012023353949189186\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=367, train_loss_step=0.00995, train_loss_epoch=0.012]Epoch 106: Train Loss = 0.009951191022992134\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=367, train_loss_step=0.0104, train_loss_epoch=0.00995] Epoch 107: Train Loss = 0.010443159379065037\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=367, train_loss_step=0.0117, train_loss_epoch=0.0104] Epoch 108: Train Loss = 0.011737811379134655\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=367, train_loss_step=0.0121, train_loss_epoch=0.0117]Epoch 109: Train Loss = 0.012053134851157665\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=367, train_loss_step=0.00951, train_loss_epoch=0.0121]Epoch 110: Train Loss = 0.009508490562438965\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 16.02it/s, v_num=367, train_loss_step=0.0113, train_loss_epoch=0.00951] Epoch 111: Train Loss = 0.011322653852403164\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 12.81it/s, v_num=367, train_loss_step=0.0123, train_loss_epoch=0.0113] Epoch 112: Train Loss = 0.012347748503088951\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=367, train_loss_step=0.0114, train_loss_epoch=0.0123]Epoch 113: Train Loss = 0.011366360820829868\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.0114]Epoch 114: Train Loss = 0.011165753938257694\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=367, train_loss_step=0.00958, train_loss_epoch=0.0112]Epoch 115: Train Loss = 0.009581648744642735\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=367, train_loss_step=0.0107, train_loss_epoch=0.00958] Epoch 116: Train Loss = 0.010742264799773693\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=367, train_loss_step=0.00868, train_loss_epoch=0.0107]Epoch 117: Train Loss = 0.008684779517352581\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=367, train_loss_step=0.0119, train_loss_epoch=0.00868] Epoch 118: Train Loss = 0.011879302561283112\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=367, train_loss_step=0.013, train_loss_epoch=0.0119]  Epoch 119: Train Loss = 0.013029743917286396\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.013]Epoch 120: Train Loss = 0.010638542473316193\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=367, train_loss_step=0.0157, train_loss_epoch=0.0106]Epoch 121: Train Loss = 0.015684764832258224\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=367, train_loss_step=0.0121, train_loss_epoch=0.0157]Epoch 122: Train Loss = 0.012113692238926888\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=367, train_loss_step=0.0168, train_loss_epoch=0.0121]Epoch 123: Train Loss = 0.01679244637489319\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.0168]Epoch 124: Train Loss = 0.010200255550444126\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=367, train_loss_step=0.0129, train_loss_epoch=0.0102]Epoch 125: Train Loss = 0.012876739725470543\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.0129]Epoch 126: Train Loss = 0.011556603945791721\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=367, train_loss_step=0.0114, train_loss_epoch=0.0116]Epoch 127: Train Loss = 0.011411215178668499\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0114]Epoch 128: Train Loss = 0.01026047021150589\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=367, train_loss_step=0.0179, train_loss_epoch=0.0103]Epoch 129: Train Loss = 0.017945345491170883\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.0179]Epoch 130: Train Loss = 0.010877220891416073\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=367, train_loss_step=0.00982, train_loss_epoch=0.0109]Epoch 131: Train Loss = 0.009819856844842434\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=367, train_loss_step=0.00972, train_loss_epoch=0.00982]Epoch 132: Train Loss = 0.009724823758006096\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.00972] Epoch 133: Train Loss = 0.010310584679245949\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=367, train_loss_step=0.0113, train_loss_epoch=0.0103] Epoch 134: Train Loss = 0.011315284296870232\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=367, train_loss_step=0.0124, train_loss_epoch=0.0113]Epoch 135: Train Loss = 0.012381012551486492\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=367, train_loss_step=0.00956, train_loss_epoch=0.0124]Epoch 136: Train Loss = 0.009557957760989666\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=367, train_loss_step=0.011, train_loss_epoch=0.00956]  Epoch 137: Train Loss = 0.010999763384461403\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 13.20it/s, v_num=367, train_loss_step=0.0084, train_loss_epoch=0.011] Epoch 138: Train Loss = 0.008395854383707047\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=367, train_loss_step=0.00961, train_loss_epoch=0.0084]Epoch 139: Train Loss = 0.00961321871727705\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=367, train_loss_step=0.0158, train_loss_epoch=0.00961] Epoch 140: Train Loss = 0.015788646414875984\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=367, train_loss_step=0.00804, train_loss_epoch=0.0158]Epoch 141: Train Loss = 0.00803566537797451\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=367, train_loss_step=0.0118, train_loss_epoch=0.00804] Epoch 142: Train Loss = 0.011816534213721752\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=367, train_loss_step=0.0123, train_loss_epoch=0.0118] Epoch 143: Train Loss = 0.01225134264677763\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=367, train_loss_step=0.00978, train_loss_epoch=0.0123]Epoch 144: Train Loss = 0.009780414402484894\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=367, train_loss_step=0.0135, train_loss_epoch=0.00978] Epoch 145: Train Loss = 0.013508849777281284\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=367, train_loss_step=0.0111, train_loss_epoch=0.0135] Epoch 146: Train Loss = 0.011058169417083263\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=367, train_loss_step=0.0123, train_loss_epoch=0.0111]Epoch 147: Train Loss = 0.012289712205529213\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=367, train_loss_step=0.0126, train_loss_epoch=0.0123]Epoch 148: Train Loss = 0.012558761052787304\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.0126]Epoch 149: Train Loss = 0.010554194450378418\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=367, train_loss_step=0.00959, train_loss_epoch=0.0106]Epoch 150: Train Loss = 0.00959315337240696\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.00959] Epoch 151: Train Loss = 0.011156107299029827\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=367, train_loss_step=0.00992, train_loss_epoch=0.0112]Epoch 152: Train Loss = 0.00991833209991455\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=367, train_loss_step=0.0105, train_loss_epoch=0.00992] Epoch 153: Train Loss = 0.010493452660739422\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s, v_num=367, train_loss_step=0.00866, train_loss_epoch=0.0105]Epoch 154: Train Loss = 0.008659137412905693\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=367, train_loss_step=0.0128, train_loss_epoch=0.00866] Epoch 155: Train Loss = 0.01276377122849226\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=367, train_loss_step=0.0104, train_loss_epoch=0.0128] Epoch 156: Train Loss = 0.010421690531075\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=367, train_loss_step=0.00895, train_loss_epoch=0.0104]Epoch 157: Train Loss = 0.008952146396040916\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.00895] Epoch 158: Train Loss = 0.011582909151911736\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=367, train_loss_step=0.00969, train_loss_epoch=0.0116]Epoch 159: Train Loss = 0.009694426320493221\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=367, train_loss_step=0.0115, train_loss_epoch=0.00969] Epoch 160: Train Loss = 0.011521779000759125\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=367, train_loss_step=0.0124, train_loss_epoch=0.0115] Epoch 161: Train Loss = 0.012425823137164116\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=367, train_loss_step=0.0129, train_loss_epoch=0.0124]Epoch 162: Train Loss = 0.012918157503008842\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=367, train_loss_step=0.00986, train_loss_epoch=0.0129]Epoch 163: Train Loss = 0.009862625040113926\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=367, train_loss_step=0.013, train_loss_epoch=0.00986]  Epoch 164: Train Loss = 0.012978852726519108\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.013] Epoch 165: Train Loss = 0.01092755887657404\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=367, train_loss_step=0.0113, train_loss_epoch=0.0109]Epoch 166: Train Loss = 0.011328564025461674\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0113]Epoch 167: Train Loss = 0.010316084139049053\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=367, train_loss_step=0.0118, train_loss_epoch=0.0103]Epoch 168: Train Loss = 0.01180571410804987\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=367, train_loss_step=0.0107, train_loss_epoch=0.0118]Epoch 169: Train Loss = 0.01074462290853262\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 170: Train Loss = 0.011579449288547039\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.0116]Epoch 171: Train Loss = 0.011161880567669868\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.0112]Epoch 172: Train Loss = 0.010226071812212467\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=367, train_loss_step=0.0118, train_loss_epoch=0.0102]Epoch 173: Train Loss = 0.011843741871416569\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=367, train_loss_step=0.0125, train_loss_epoch=0.0118]Epoch 174: Train Loss = 0.012483751401305199\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=367, train_loss_step=0.00998, train_loss_epoch=0.0125]Epoch 175: Train Loss = 0.0099782794713974\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=367, train_loss_step=0.0151, train_loss_epoch=0.00998] Epoch 176: Train Loss = 0.015129795297980309\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=367, train_loss_step=0.0121, train_loss_epoch=0.0151] Epoch 177: Train Loss = 0.012111972086131573\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.0121]Epoch 178: Train Loss = 0.010238348506391048\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.0102]Epoch 179: Train Loss = 0.011241590604186058\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.0112]Epoch 180: Train Loss = 0.01075685489922762\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.0108]Epoch 181: Train Loss = 0.010583172552287579\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, v_num=367, train_loss_step=0.0115, train_loss_epoch=0.0106]Epoch 182: Train Loss = 0.01152773853391409\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=367, train_loss_step=0.00986, train_loss_epoch=0.0115]Epoch 183: Train Loss = 0.009860016405582428\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, v_num=367, train_loss_step=0.00943, train_loss_epoch=0.00986]Epoch 184: Train Loss = 0.00943013932555914\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.00943] Epoch 185: Train Loss = 0.010831452906131744\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=367, train_loss_step=0.00845, train_loss_epoch=0.0108]Epoch 186: Train Loss = 0.008447728119790554\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=367, train_loss_step=0.00949, train_loss_epoch=0.00845]Epoch 187: Train Loss = 0.009486238472163677\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=367, train_loss_step=0.010, train_loss_epoch=0.00949]  Epoch 188: Train Loss = 0.009996595792472363\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=367, train_loss_step=0.00856, train_loss_epoch=0.010]Epoch 189: Train Loss = 0.008557927794754505\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=367, train_loss_step=0.00938, train_loss_epoch=0.00856]Epoch 190: Train Loss = 0.009381462819874287\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=367, train_loss_step=0.00952, train_loss_epoch=0.00938]Epoch 191: Train Loss = 0.009518141858279705\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=367, train_loss_step=0.010, train_loss_epoch=0.00952]  Epoch 192: Train Loss = 0.010002831928431988\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.010] Epoch 193: Train Loss = 0.010637626983225346\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=367, train_loss_step=0.0114, train_loss_epoch=0.0106]Epoch 194: Train Loss = 0.011423831805586815\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.0114]Epoch 195: Train Loss = 0.011241174302995205\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=367, train_loss_step=0.00861, train_loss_epoch=0.0112]Epoch 196: Train Loss = 0.008606186136603355\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=367, train_loss_step=0.0104, train_loss_epoch=0.00861] Epoch 197: Train Loss = 0.010359854437410831\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 16.11it/s, v_num=367, train_loss_step=0.00938, train_loss_epoch=0.0104]Epoch 198: Train Loss = 0.00937812589108944\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s, v_num=367, train_loss_step=0.00936, train_loss_epoch=0.00938]Epoch 199: Train Loss = 0.009358595125377178\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=367, train_loss_step=0.0125, train_loss_epoch=0.00936] Epoch 200: Train Loss = 0.012507572770118713\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0125] Epoch 201: Train Loss = 0.010259720496833324\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.0103]Epoch 202: Train Loss = 0.010929325595498085\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.0109]Epoch 203: Train Loss = 0.011243210174143314\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.0112]Epoch 204: Train Loss = 0.010862060822546482\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=367, train_loss_step=0.00973, train_loss_epoch=0.0109]Epoch 205: Train Loss = 0.00973060168325901\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.00973] Epoch 206: Train Loss = 0.010846537537872791\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=367, train_loss_step=0.0122, train_loss_epoch=0.0108] Epoch 207: Train Loss = 0.012195813469588757\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=367, train_loss_step=0.00992, train_loss_epoch=0.0122]Epoch 208: Train Loss = 0.009915282018482685\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=367, train_loss_step=0.0104, train_loss_epoch=0.00992] Epoch 209: Train Loss = 0.010439092293381691\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=367, train_loss_step=0.011, train_loss_epoch=0.0104]  Epoch 210: Train Loss = 0.010992227122187614\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=367, train_loss_step=0.00954, train_loss_epoch=0.011]Epoch 211: Train Loss = 0.009540855884552002\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=367, train_loss_step=0.0148, train_loss_epoch=0.00954] Epoch 212: Train Loss = 0.014791719615459442\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 11.71it/s, v_num=367, train_loss_step=0.00974, train_loss_epoch=0.0148]Epoch 213: Train Loss = 0.00973673164844513\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=367, train_loss_step=0.00788, train_loss_epoch=0.00974]Epoch 214: Train Loss = 0.00787719152867794\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=367, train_loss_step=0.0124, train_loss_epoch=0.00788] Epoch 215: Train Loss = 0.012393069453537464\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=367, train_loss_step=0.00671, train_loss_epoch=0.0124]Epoch 216: Train Loss = 0.006712544243782759\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=367, train_loss_step=0.011, train_loss_epoch=0.00671]  Epoch 217: Train Loss = 0.011025716550648212\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=367, train_loss_step=0.0101, train_loss_epoch=0.011] Epoch 218: Train Loss = 0.010144590400159359\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0101]Epoch 219: Train Loss = 0.010340110398828983\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0103]Epoch 220: Train Loss = 0.0103351641446352\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=367, train_loss_step=0.00691, train_loss_epoch=0.0103]Epoch 221: Train Loss = 0.00690604280680418\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=367, train_loss_step=0.00917, train_loss_epoch=0.00691]Epoch 222: Train Loss = 0.009170121513307095\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=367, train_loss_step=0.0105, train_loss_epoch=0.00917] Epoch 223: Train Loss = 0.010548927821218967\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0105] Epoch 224: Train Loss = 0.010311683639883995\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=367, train_loss_step=0.0138, train_loss_epoch=0.0103]Epoch 225: Train Loss = 0.01383836567401886\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=367, train_loss_step=0.00808, train_loss_epoch=0.0138]Epoch 226: Train Loss = 0.008077569305896759\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=367, train_loss_step=0.00978, train_loss_epoch=0.00808]Epoch 227: Train Loss = 0.009777535684406757\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=367, train_loss_step=0.00982, train_loss_epoch=0.00978]Epoch 228: Train Loss = 0.009821715764701366\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=367, train_loss_step=0.0138, train_loss_epoch=0.00982] Epoch 229: Train Loss = 0.013775201514363289\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.0138] Epoch 230: Train Loss = 0.011563616804778576\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=367, train_loss_step=0.00657, train_loss_epoch=0.0116]Epoch 231: Train Loss = 0.006570348981767893\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=367, train_loss_step=0.0151, train_loss_epoch=0.00657] Epoch 232: Train Loss = 0.01505821943283081\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=367, train_loss_step=0.0123, train_loss_epoch=0.0151] Epoch 233: Train Loss = 0.0122894998639822\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.0123]Epoch 234: Train Loss = 0.010854397900402546\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.0109]Epoch 235: Train Loss = 0.010754120536148548\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=367, train_loss_step=0.0181, train_loss_epoch=0.0108]Epoch 236: Train Loss = 0.018063833937048912\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=367, train_loss_step=0.0119, train_loss_epoch=0.0181]Epoch 237: Train Loss = 0.01192733459174633\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=367, train_loss_step=0.00893, train_loss_epoch=0.0119]Epoch 238: Train Loss = 0.008925511501729488\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.00893] Epoch 239: Train Loss = 0.010837137699127197\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=367, train_loss_step=0.015, train_loss_epoch=0.0108]  Epoch 240: Train Loss = 0.014993155375123024\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=367, train_loss_step=0.00981, train_loss_epoch=0.015]Epoch 241: Train Loss = 0.009809807874262333\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=367, train_loss_step=0.014, train_loss_epoch=0.00981]  Epoch 242: Train Loss = 0.013963170349597931\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=367, train_loss_step=0.0138, train_loss_epoch=0.014] Epoch 243: Train Loss = 0.01383951585739851\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=367, train_loss_step=0.0128, train_loss_epoch=0.0138]Epoch 244: Train Loss = 0.012836788780987263\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=367, train_loss_step=0.0117, train_loss_epoch=0.0128]Epoch 245: Train Loss = 0.011728237383067608\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.0117]Epoch 246: Train Loss = 0.011580219492316246\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.0116]Epoch 247: Train Loss = 0.011207274161279202\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.0112]Epoch 248: Train Loss = 0.011151701211929321\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=367, train_loss_step=0.0122, train_loss_epoch=0.0112]Epoch 249: Train Loss = 0.012178353033959866\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0122]Epoch 250: Train Loss = 0.010258843190968037\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=367, train_loss_step=0.0174, train_loss_epoch=0.0103]Epoch 251: Train Loss = 0.017436476424336433\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=367, train_loss_step=0.00954, train_loss_epoch=0.0174]Epoch 252: Train Loss = 0.009536954574286938\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=367, train_loss_step=0.00904, train_loss_epoch=0.00954]Epoch 253: Train Loss = 0.009044737555086613\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=367, train_loss_step=0.00852, train_loss_epoch=0.00904]Epoch 254: Train Loss = 0.008523206226527691\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=367, train_loss_step=0.00875, train_loss_epoch=0.00852]Epoch 255: Train Loss = 0.00875309482216835\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 13.76it/s, v_num=367, train_loss_step=0.00881, train_loss_epoch=0.00875]Epoch 256: Train Loss = 0.008809349499642849\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.00881] Epoch 257: Train Loss = 0.010315538384020329\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=367, train_loss_step=0.0126, train_loss_epoch=0.0103] Epoch 258: Train Loss = 0.012589299120008945\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=367, train_loss_step=0.00816, train_loss_epoch=0.0126]Epoch 259: Train Loss = 0.008157415315508842\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=367, train_loss_step=0.00989, train_loss_epoch=0.00816]Epoch 260: Train Loss = 0.009892674162983894\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=367, train_loss_step=0.0165, train_loss_epoch=0.00989] Epoch 261: Train Loss = 0.016464153304696083\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=367, train_loss_step=0.00973, train_loss_epoch=0.0165]Epoch 262: Train Loss = 0.009730135090649128\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=367, train_loss_step=0.011, train_loss_epoch=0.00973]  Epoch 263: Train Loss = 0.01100949663668871\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=367, train_loss_step=0.00874, train_loss_epoch=0.011]Epoch 264: Train Loss = 0.008735106326639652\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=367, train_loss_step=0.00847, train_loss_epoch=0.00874]Epoch 265: Train Loss = 0.008471894077956676\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=367, train_loss_step=0.0119, train_loss_epoch=0.00847] Epoch 266: Train Loss = 0.01190592348575592\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=367, train_loss_step=0.0127, train_loss_epoch=0.0119] Epoch 267: Train Loss = 0.012692958116531372\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=367, train_loss_step=0.00968, train_loss_epoch=0.0127]Epoch 268: Train Loss = 0.009679668582975864\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=367, train_loss_step=0.0104, train_loss_epoch=0.00968] Epoch 269: Train Loss = 0.010419981554150581\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0104] Epoch 270: Train Loss = 0.010297439061105251\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=367, train_loss_step=0.0104, train_loss_epoch=0.0103]Epoch 271: Train Loss = 0.010402525775134563\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=367, train_loss_step=0.0117, train_loss_epoch=0.0104]Epoch 272: Train Loss = 0.011653700843453407\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=367, train_loss_step=0.00938, train_loss_epoch=0.0117]Epoch 273: Train Loss = 0.009379162453114986\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=367, train_loss_step=0.0101, train_loss_epoch=0.00938] Epoch 274: Train Loss = 0.010116497986018658\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0101] Epoch 275: Train Loss = 0.010265452787280083\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=367, train_loss_step=0.00995, train_loss_epoch=0.0103]Epoch 276: Train Loss = 0.009952557273209095\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=367, train_loss_step=0.011, train_loss_epoch=0.00995]  Epoch 277: Train Loss = 0.011037816293537617\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=367, train_loss_step=0.00799, train_loss_epoch=0.011]Epoch 278: Train Loss = 0.007994824089109898\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=367, train_loss_step=0.0139, train_loss_epoch=0.00799] Epoch 279: Train Loss = 0.013891910202801228\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.0139] Epoch 280: Train Loss = 0.010195189155638218\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=367, train_loss_step=0.0147, train_loss_epoch=0.0102]Epoch 281: Train Loss = 0.014657916501164436\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=367, train_loss_step=0.0135, train_loss_epoch=0.0147]Epoch 282: Train Loss = 0.01349911279976368\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=367, train_loss_step=0.0122, train_loss_epoch=0.0135]Epoch 283: Train Loss = 0.012221992015838623\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=367, train_loss_step=0.00965, train_loss_epoch=0.0122]Epoch 284: Train Loss = 0.009653903543949127\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.00965] Epoch 285: Train Loss = 0.010239632800221443\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=367, train_loss_step=0.0126, train_loss_epoch=0.0102] Epoch 286: Train Loss = 0.012564676813781261\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0126]Epoch 287: Train Loss = 0.010309182107448578\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=367, train_loss_step=0.00844, train_loss_epoch=0.0103]Epoch 288: Train Loss = 0.008439278230071068\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 13.02it/s, v_num=367, train_loss_step=0.00958, train_loss_epoch=0.00844]Epoch 289: Train Loss = 0.00957523100078106\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=367, train_loss_step=0.0137, train_loss_epoch=0.00958] Epoch 290: Train Loss = 0.013677856884896755\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=367, train_loss_step=0.00927, train_loss_epoch=0.0137]Epoch 291: Train Loss = 0.009265443310141563\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=367, train_loss_step=0.0151, train_loss_epoch=0.00927] Epoch 292: Train Loss = 0.015077630989253521\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=367, train_loss_step=0.00894, train_loss_epoch=0.0151]Epoch 293: Train Loss = 0.008942780084908009\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=367, train_loss_step=0.010, train_loss_epoch=0.00894]  Epoch 294: Train Loss = 0.010034632869064808\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s, v_num=367, train_loss_step=0.0115, train_loss_epoch=0.010] Epoch 295: Train Loss = 0.011485113762319088\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=367, train_loss_step=0.014, train_loss_epoch=0.0115] Epoch 296: Train Loss = 0.013964134268462658\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=367, train_loss_step=0.00929, train_loss_epoch=0.014]Epoch 297: Train Loss = 0.009286927990615368\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=367, train_loss_step=0.0126, train_loss_epoch=0.00929] Epoch 298: Train Loss = 0.012620777823030949\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, v_num=367, train_loss_step=0.00923, train_loss_epoch=0.0126]Epoch 299: Train Loss = 0.009230554103851318\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=367, train_loss_step=0.00797, train_loss_epoch=0.00923]Epoch 300: Train Loss = 0.007970595732331276\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.00797] Epoch 301: Train Loss = 0.01123198214918375\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=367, train_loss_step=0.0133, train_loss_epoch=0.0112] Epoch 302: Train Loss = 0.013268723152577877\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=367, train_loss_step=0.00807, train_loss_epoch=0.0133]Epoch 303: Train Loss = 0.008071561343967915\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=367, train_loss_step=0.0127, train_loss_epoch=0.00807] Epoch 304: Train Loss = 0.01273607462644577\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.0127] Epoch 305: Train Loss = 0.011182403191924095\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=367, train_loss_step=0.00974, train_loss_epoch=0.0112]Epoch 306: Train Loss = 0.009739224798977375\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=367, train_loss_step=0.00937, train_loss_epoch=0.00974]Epoch 307: Train Loss = 0.009374941699206829\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=367, train_loss_step=0.0141, train_loss_epoch=0.00937] Epoch 308: Train Loss = 0.014097161591053009\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=367, train_loss_step=0.0101, train_loss_epoch=0.0141] Epoch 309: Train Loss = 0.010053105652332306\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=367, train_loss_step=0.014, train_loss_epoch=0.0101] Epoch 310: Train Loss = 0.013974695466458797\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=367, train_loss_step=0.0101, train_loss_epoch=0.014]Epoch 311: Train Loss = 0.010111459530889988\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.0101]Epoch 312: Train Loss = 0.010756910778582096\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.0108]Epoch 313: Train Loss = 0.01060452964156866\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=367, train_loss_step=0.00883, train_loss_epoch=0.0106]Epoch 314: Train Loss = 0.00883292406797409\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=367, train_loss_step=0.012, train_loss_epoch=0.00883]  Epoch 315: Train Loss = 0.011966065503656864\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 12.97it/s, v_num=367, train_loss_step=0.00928, train_loss_epoch=0.012]Epoch 316: Train Loss = 0.00928454753011465\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=367, train_loss_step=0.0115, train_loss_epoch=0.00928] Epoch 317: Train Loss = 0.01147326361387968\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=367, train_loss_step=0.0114, train_loss_epoch=0.0115] Epoch 318: Train Loss = 0.011361015029251575\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=367, train_loss_step=0.0089, train_loss_epoch=0.0114]Epoch 319: Train Loss = 0.008899925276637077\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=367, train_loss_step=0.00992, train_loss_epoch=0.0089]Epoch 320: Train Loss = 0.009921668097376823\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=367, train_loss_step=0.00869, train_loss_epoch=0.00992]Epoch 321: Train Loss = 0.008685342036187649\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=367, train_loss_step=0.0104, train_loss_epoch=0.00869] Epoch 322: Train Loss = 0.010397642850875854\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=367, train_loss_step=0.014, train_loss_epoch=0.0104]  Epoch 323: Train Loss = 0.013970927335321903\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=367, train_loss_step=0.0107, train_loss_epoch=0.014]Epoch 324: Train Loss = 0.010680682957172394\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=367, train_loss_step=0.010, train_loss_epoch=0.0107] Epoch 325: Train Loss = 0.010030694305896759\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.010]Epoch 326: Train Loss = 0.010246464982628822\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=367, train_loss_step=0.0105, train_loss_epoch=0.0102]Epoch 327: Train Loss = 0.010480659082531929\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, v_num=367, train_loss_step=0.013, train_loss_epoch=0.0105] Epoch 328: Train Loss = 0.013027074746787548\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=367, train_loss_step=0.00979, train_loss_epoch=0.013]Epoch 329: Train Loss = 0.009789297357201576\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=367, train_loss_step=0.0114, train_loss_epoch=0.00979] Epoch 330: Train Loss = 0.011390320025384426\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s, v_num=367, train_loss_step=0.00861, train_loss_epoch=0.0114]Epoch 331: Train Loss = 0.008610345423221588\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=367, train_loss_step=0.0133, train_loss_epoch=0.00861] Epoch 332: Train Loss = 0.013287733308970928\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=367, train_loss_step=0.0101, train_loss_epoch=0.0133] Epoch 333: Train Loss = 0.010130182839930058\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=367, train_loss_step=0.011, train_loss_epoch=0.0101] Epoch 334: Train Loss = 0.011048773303627968\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=367, train_loss_step=0.0087, train_loss_epoch=0.011]Epoch 335: Train Loss = 0.008702671155333519\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=367, train_loss_step=0.0135, train_loss_epoch=0.0087]Epoch 336: Train Loss = 0.013479507528245449\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=367, train_loss_step=0.00806, train_loss_epoch=0.0135]Epoch 337: Train Loss = 0.008057830855250359\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=367, train_loss_step=0.0176, train_loss_epoch=0.00806] Epoch 338: Train Loss = 0.017564022913575172\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.0176] Epoch 339: Train Loss = 0.01077780220657587\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=367, train_loss_step=0.0125, train_loss_epoch=0.0108]Epoch 340: Train Loss = 0.012493284419178963\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s, v_num=367, train_loss_step=0.0135, train_loss_epoch=0.0125]Epoch 341: Train Loss = 0.013474559411406517\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s, v_num=367, train_loss_step=0.011, train_loss_epoch=0.0135] Epoch 342: Train Loss = 0.011019020341336727\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=367, train_loss_step=0.011, train_loss_epoch=0.011] Epoch 343: Train Loss = 0.011044873856008053\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=367, train_loss_step=0.0111, train_loss_epoch=0.011]Epoch 344: Train Loss = 0.011071247979998589\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.0111]Epoch 345: Train Loss = 0.010245569050312042\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=367, train_loss_step=0.0114, train_loss_epoch=0.0102]Epoch 346: Train Loss = 0.011382922530174255\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=367, train_loss_step=0.00937, train_loss_epoch=0.0114]Epoch 347: Train Loss = 0.00936813559383154\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.00937] Epoch 348: Train Loss = 0.010268173180520535\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.0103] Epoch 349: Train Loss = 0.010555459186434746\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=367, train_loss_step=0.0127, train_loss_epoch=0.0106]Epoch 350: Train Loss = 0.012697802856564522\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.0127]Epoch 351: Train Loss = 0.010582643561065197\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=367, train_loss_step=0.00789, train_loss_epoch=0.0106]Epoch 352: Train Loss = 0.007892477326095104\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.00789] Epoch 353: Train Loss = 0.010219295509159565\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=367, train_loss_step=0.00834, train_loss_epoch=0.0102]Epoch 354: Train Loss = 0.008336855098605156\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=367, train_loss_step=0.0104, train_loss_epoch=0.00834] Epoch 355: Train Loss = 0.010415911674499512\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=367, train_loss_step=0.00936, train_loss_epoch=0.0104]Epoch 356: Train Loss = 0.009359650313854218\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=367, train_loss_step=0.0107, train_loss_epoch=0.00936] Epoch 357: Train Loss = 0.010678461752831936\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=367, train_loss_step=0.00969, train_loss_epoch=0.0107]Epoch 358: Train Loss = 0.009689873084425926\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.00969] Epoch 359: Train Loss = 0.01031527854502201\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=367, train_loss_step=0.00946, train_loss_epoch=0.0103]Epoch 360: Train Loss = 0.009460918605327606\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.00946] Epoch 361: Train Loss = 0.010347829200327396\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=367, train_loss_step=0.00844, train_loss_epoch=0.0103]Epoch 362: Train Loss = 0.008440947160124779\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.00844] Epoch 363: Train Loss = 0.010799798183143139\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.0108] Epoch 364: Train Loss = 0.010909787379205227\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0109]Epoch 365: Train Loss = 0.010254078544676304\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=367, train_loss_step=0.0129, train_loss_epoch=0.0103]Epoch 366: Train Loss = 0.012890574522316456\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=367, train_loss_step=0.0124, train_loss_epoch=0.0129]Epoch 367: Train Loss = 0.012448607943952084\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=367, train_loss_step=0.0124, train_loss_epoch=0.0124]Epoch 368: Train Loss = 0.012359189800918102\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=367, train_loss_step=0.0111, train_loss_epoch=0.0124]Epoch 369: Train Loss = 0.011145844124257565\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=367, train_loss_step=0.0127, train_loss_epoch=0.0111]Epoch 370: Train Loss = 0.012657702900469303\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 13.59it/s, v_num=367, train_loss_step=0.0118, train_loss_epoch=0.0127]Epoch 371: Train Loss = 0.011804744601249695\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=367, train_loss_step=0.00926, train_loss_epoch=0.0118]Epoch 372: Train Loss = 0.009262689389288425\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=367, train_loss_step=0.00963, train_loss_epoch=0.00926]Epoch 373: Train Loss = 0.009629412554204464\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=367, train_loss_step=0.00967, train_loss_epoch=0.00963]Epoch 374: Train Loss = 0.00967446994036436\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 10.57it/s, v_num=367, train_loss_step=0.00926, train_loss_epoch=0.00967]Epoch 375: Train Loss = 0.00926055759191513\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s, v_num=367, train_loss_step=0.0146, train_loss_epoch=0.00926] Epoch 376: Train Loss = 0.014610350131988525\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=367, train_loss_step=0.00965, train_loss_epoch=0.0146]Epoch 377: Train Loss = 0.009647165425121784\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=367, train_loss_step=0.00923, train_loss_epoch=0.00965]Epoch 378: Train Loss = 0.009229189716279507\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=367, train_loss_step=0.0114, train_loss_epoch=0.00923] Epoch 379: Train Loss = 0.011418389156460762\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=367, train_loss_step=0.0117, train_loss_epoch=0.0114] Epoch 380: Train Loss = 0.011664507910609245\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=367, train_loss_step=0.0079, train_loss_epoch=0.0117]Epoch 381: Train Loss = 0.007897862233221531\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=367, train_loss_step=0.0131, train_loss_epoch=0.0079]Epoch 382: Train Loss = 0.013108358718454838\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=367, train_loss_step=0.00953, train_loss_epoch=0.0131]Epoch 383: Train Loss = 0.009530370123684406\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=367, train_loss_step=0.0111, train_loss_epoch=0.00953] Epoch 384: Train Loss = 0.01107659749686718\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=367, train_loss_step=0.00847, train_loss_epoch=0.0111]Epoch 385: Train Loss = 0.008469194173812866\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=367, train_loss_step=0.00836, train_loss_epoch=0.00847]Epoch 386: Train Loss = 0.00835630763322115\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=367, train_loss_step=0.0121, train_loss_epoch=0.00836] Epoch 387: Train Loss = 0.01205405779182911\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=367, train_loss_step=0.00944, train_loss_epoch=0.0121]Epoch 388: Train Loss = 0.009440564550459385\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=367, train_loss_step=0.00803, train_loss_epoch=0.00944]Epoch 389: Train Loss = 0.008029757998883724\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=367, train_loss_step=0.0113, train_loss_epoch=0.00803] Epoch 390: Train Loss = 0.011326193809509277\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.0113] Epoch 391: Train Loss = 0.01083379052579403\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=367, train_loss_step=0.0131, train_loss_epoch=0.0108]Epoch 392: Train Loss = 0.013118565082550049\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=367, train_loss_step=0.0115, train_loss_epoch=0.0131]Epoch 393: Train Loss = 0.011470509693026543\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.0115]Epoch 394: Train Loss = 0.010183489881455898\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=367, train_loss_step=0.0087, train_loss_epoch=0.0102]Epoch 395: Train Loss = 0.008704003877937794\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=367, train_loss_step=0.010, train_loss_epoch=0.0087] Epoch 396: Train Loss = 0.010012807324528694\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=367, train_loss_step=0.0132, train_loss_epoch=0.010]Epoch 397: Train Loss = 0.013182408176362514\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=367, train_loss_step=0.00937, train_loss_epoch=0.0132]Epoch 398: Train Loss = 0.009370722807943821\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.00937] Epoch 399: Train Loss = 0.010574053041636944\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=367, train_loss_step=0.0111, train_loss_epoch=0.0106] Epoch 400: Train Loss = 0.011098329909145832\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.0111]Epoch 401: Train Loss = 0.010639088228344917\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=367, train_loss_step=0.00932, train_loss_epoch=0.0106]Epoch 402: Train Loss = 0.009320227429270744\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, v_num=367, train_loss_step=0.0118, train_loss_epoch=0.00932] Epoch 403: Train Loss = 0.011780289001762867\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=367, train_loss_step=0.0119, train_loss_epoch=0.0118] Epoch 404: Train Loss = 0.01186566986143589\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=367, train_loss_step=0.00938, train_loss_epoch=0.0119]Epoch 405: Train Loss = 0.009381239302456379\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=367, train_loss_step=0.0112, train_loss_epoch=0.00938] Epoch 406: Train Loss = 0.011194444261491299\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, v_num=367, train_loss_step=0.0144, train_loss_epoch=0.0112] Epoch 407: Train Loss = 0.014392699114978313\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=367, train_loss_step=0.012, train_loss_epoch=0.0144] Epoch 408: Train Loss = 0.012049040757119656\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=367, train_loss_step=0.0105, train_loss_epoch=0.012]Epoch 409: Train Loss = 0.010456454940140247\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=367, train_loss_step=0.00895, train_loss_epoch=0.0105]Epoch 410: Train Loss = 0.008949719369411469\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.00895] Epoch 411: Train Loss = 0.01025825273245573\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=367, train_loss_step=0.00968, train_loss_epoch=0.0103]Epoch 412: Train Loss = 0.009679079987108707\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=367, train_loss_step=0.0115, train_loss_epoch=0.00968] Epoch 413: Train Loss = 0.011458350345492363\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=367, train_loss_step=0.0137, train_loss_epoch=0.0115] Epoch 414: Train Loss = 0.013737543486058712\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=367, train_loss_step=0.0103, train_loss_epoch=0.0137]Epoch 415: Train Loss = 0.010284478776156902\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=367, train_loss_step=0.00881, train_loss_epoch=0.0103]Epoch 416: Train Loss = 0.008813388645648956\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=367, train_loss_step=0.0134, train_loss_epoch=0.00881] Epoch 417: Train Loss = 0.013413356617093086\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s, v_num=367, train_loss_step=0.0114, train_loss_epoch=0.0134] Epoch 418: Train Loss = 0.011433967389166355\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s, v_num=367, train_loss_step=0.0169, train_loss_epoch=0.0114]Epoch 419: Train Loss = 0.01692156307399273\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=367, train_loss_step=0.011, train_loss_epoch=0.0169] Epoch 420: Train Loss = 0.010976918041706085\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=367, train_loss_step=0.0129, train_loss_epoch=0.011]Epoch 421: Train Loss = 0.012905329465866089\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=367, train_loss_step=0.0105, train_loss_epoch=0.0129]Epoch 422: Train Loss = 0.010476094670593739\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=367, train_loss_step=0.00898, train_loss_epoch=0.0105]Epoch 423: Train Loss = 0.008978554047644138\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=367, train_loss_step=0.0105, train_loss_epoch=0.00898] Epoch 424: Train Loss = 0.010502106510102749\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=367, train_loss_step=0.0125, train_loss_epoch=0.0105] Epoch 425: Train Loss = 0.012534028850495815\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=367, train_loss_step=0.0129, train_loss_epoch=0.0125]Epoch 426: Train Loss = 0.012909303419291973\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.0129]Epoch 427: Train Loss = 0.010249419137835503\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=367, train_loss_step=0.00841, train_loss_epoch=0.0102]Epoch 428: Train Loss = 0.008410646580159664\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=367, train_loss_step=0.0124, train_loss_epoch=0.00841] Epoch 429: Train Loss = 0.012413492426276207\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=367, train_loss_step=0.0125, train_loss_epoch=0.0124] Epoch 430: Train Loss = 0.012500403448939323\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=367, train_loss_step=0.0098, train_loss_epoch=0.0125]Epoch 431: Train Loss = 0.00980368535965681\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=367, train_loss_step=0.0126, train_loss_epoch=0.0098]Epoch 432: Train Loss = 0.012553229928016663\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=367, train_loss_step=0.0119, train_loss_epoch=0.0126]Epoch 433: Train Loss = 0.01187082938849926\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=367, train_loss_step=0.00974, train_loss_epoch=0.0119]Epoch 434: Train Loss = 0.00973762571811676\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=367, train_loss_step=0.0105, train_loss_epoch=0.00974] Epoch 435: Train Loss = 0.010459923185408115\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=367, train_loss_step=0.0141, train_loss_epoch=0.0105] Epoch 436: Train Loss = 0.014072751626372337\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=367, train_loss_step=0.0105, train_loss_epoch=0.0141]Epoch 437: Train Loss = 0.0104728564620018\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=367, train_loss_step=0.00989, train_loss_epoch=0.0105]Epoch 438: Train Loss = 0.00989097636193037\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=367, train_loss_step=0.00714, train_loss_epoch=0.00989]Epoch 439: Train Loss = 0.007137902081012726\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=367, train_loss_step=0.0117, train_loss_epoch=0.00714] Epoch 440: Train Loss = 0.011747808195650578\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=367, train_loss_step=0.00915, train_loss_epoch=0.0117]Epoch 441: Train Loss = 0.00915439147502184\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 13.03it/s, v_num=367, train_loss_step=0.00885, train_loss_epoch=0.00915]Epoch 442: Train Loss = 0.008851698599755764\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=367, train_loss_step=0.00785, train_loss_epoch=0.00885]Epoch 443: Train Loss = 0.007850989699363708\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 10.36it/s, v_num=367, train_loss_step=0.00933, train_loss_epoch=0.00785]Epoch 444: Train Loss = 0.009327315725386143\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=367, train_loss_step=0.0121, train_loss_epoch=0.00933] Epoch 445: Train Loss = 0.012090279720723629\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=367, train_loss_step=0.014, train_loss_epoch=0.0121]  Epoch 446: Train Loss = 0.013958240859210491\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=367, train_loss_step=0.00804, train_loss_epoch=0.014]Epoch 447: Train Loss = 0.00804451759904623\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=367, train_loss_step=0.00912, train_loss_epoch=0.00804]Epoch 448: Train Loss = 0.00912120658904314\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=367, train_loss_step=0.00995, train_loss_epoch=0.00912]Epoch 449: Train Loss = 0.00994893442839384\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=367, train_loss_step=0.00854, train_loss_epoch=0.00995]Epoch 450: Train Loss = 0.008535182103514671\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=367, train_loss_step=0.00878, train_loss_epoch=0.00854]Epoch 451: Train Loss = 0.008782756514847279\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=367, train_loss_step=0.00833, train_loss_epoch=0.00878]Epoch 452: Train Loss = 0.008327662944793701\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=367, train_loss_step=0.00863, train_loss_epoch=0.00833]Epoch 453: Train Loss = 0.008632131852209568\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=367, train_loss_step=0.0128, train_loss_epoch=0.00863] Epoch 454: Train Loss = 0.012780659832060337\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=367, train_loss_step=0.00975, train_loss_epoch=0.0128]Epoch 455: Train Loss = 0.009751790203154087\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.00975] Epoch 456: Train Loss = 0.010604528710246086\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=367, train_loss_step=0.0107, train_loss_epoch=0.0106] Epoch 457: Train Loss = 0.010705268941819668\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 458: Train Loss = 0.011605741456151009\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=367, train_loss_step=0.00914, train_loss_epoch=0.0116]Epoch 459: Train Loss = 0.009139358066022396\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=367, train_loss_step=0.0101, train_loss_epoch=0.00914] Epoch 460: Train Loss = 0.010107502341270447\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=367, train_loss_step=0.00883, train_loss_epoch=0.0101]Epoch 461: Train Loss = 0.008833406493067741\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=367, train_loss_step=0.012, train_loss_epoch=0.00883]  Epoch 462: Train Loss = 0.0119705218821764\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=367, train_loss_step=0.00957, train_loss_epoch=0.012]Epoch 463: Train Loss = 0.009568549692630768\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=367, train_loss_step=0.0116, train_loss_epoch=0.00957] Epoch 464: Train Loss = 0.011615155264735222\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 13.68it/s, v_num=367, train_loss_step=0.0109, train_loss_epoch=0.0116] Epoch 465: Train Loss = 0.010916572995483875\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s, v_num=367, train_loss_step=0.011, train_loss_epoch=0.0109] Epoch 466: Train Loss = 0.011026114225387573\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=367, train_loss_step=0.012, train_loss_epoch=0.011] Epoch 467: Train Loss = 0.012011195532977581\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=367, train_loss_step=0.0117, train_loss_epoch=0.012]Epoch 468: Train Loss = 0.011710941791534424\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=367, train_loss_step=0.00852, train_loss_epoch=0.0117]Epoch 469: Train Loss = 0.008522630669176579\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 13.00it/s, v_num=367, train_loss_step=0.0082, train_loss_epoch=0.00852] Epoch 470: Train Loss = 0.008200815878808498\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=367, train_loss_step=0.00899, train_loss_epoch=0.0082]Epoch 471: Train Loss = 0.008993486873805523\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=367, train_loss_step=0.0102, train_loss_epoch=0.00899] Epoch 472: Train Loss = 0.010199861600995064\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=367, train_loss_step=0.0119, train_loss_epoch=0.0102] Epoch 473: Train Loss = 0.01185554824769497\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=367, train_loss_step=0.00969, train_loss_epoch=0.0119]Epoch 474: Train Loss = 0.009686559438705444\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=367, train_loss_step=0.00846, train_loss_epoch=0.00969]Epoch 475: Train Loss = 0.008462239988148212\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=367, train_loss_step=0.0099, train_loss_epoch=0.00846] Epoch 476: Train Loss = 0.009902364574372768\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=367, train_loss_step=0.0101, train_loss_epoch=0.0099] Epoch 477: Train Loss = 0.010061523877084255\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=367, train_loss_step=0.00876, train_loss_epoch=0.0101]Epoch 478: Train Loss = 0.008761398494243622\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=367, train_loss_step=0.00938, train_loss_epoch=0.00876]Epoch 479: Train Loss = 0.009376506321132183\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=367, train_loss_step=0.00933, train_loss_epoch=0.00938]Epoch 480: Train Loss = 0.00933451671153307\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=367, train_loss_step=0.00838, train_loss_epoch=0.00933]Epoch 481: Train Loss = 0.008382420055568218\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=367, train_loss_step=0.0121, train_loss_epoch=0.00838] Epoch 482: Train Loss = 0.01213652640581131\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 13.65it/s, v_num=367, train_loss_step=0.0105, train_loss_epoch=0.0121] Epoch 483: Train Loss = 0.010514804162085056\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=367, train_loss_step=0.0101, train_loss_epoch=0.0105]Epoch 484: Train Loss = 0.010089529678225517\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=367, train_loss_step=0.0106, train_loss_epoch=0.0101]Epoch 485: Train Loss = 0.01063531544059515\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=367, train_loss_step=0.00971, train_loss_epoch=0.0106]Epoch 486: Train Loss = 0.009712984785437584\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=367, train_loss_step=0.00769, train_loss_epoch=0.00971]Epoch 487: Train Loss = 0.007689462509006262\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=367, train_loss_step=0.0114, train_loss_epoch=0.00769] Epoch 488: Train Loss = 0.01143593993037939\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=367, train_loss_step=0.00906, train_loss_epoch=0.0114]Epoch 489: Train Loss = 0.009059862233698368\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=367, train_loss_step=0.00943, train_loss_epoch=0.00906]Epoch 490: Train Loss = 0.00943477638065815\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=367, train_loss_step=0.0117, train_loss_epoch=0.00943] Epoch 491: Train Loss = 0.01172006968408823\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=367, train_loss_step=0.00954, train_loss_epoch=0.0117]Epoch 492: Train Loss = 0.009542041458189487\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 13.20it/s, v_num=367, train_loss_step=0.0108, train_loss_epoch=0.00954] Epoch 493: Train Loss = 0.010799855925142765\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=367, train_loss_step=0.0105, train_loss_epoch=0.0108] Epoch 494: Train Loss = 0.010481107048690319\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s, v_num=367, train_loss_step=0.0142, train_loss_epoch=0.0105]Epoch 495: Train Loss = 0.014193032868206501\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=367, train_loss_step=0.00931, train_loss_epoch=0.0142]Epoch 496: Train Loss = 0.00930861383676529\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s, v_num=367, train_loss_step=0.013, train_loss_epoch=0.00931]  Epoch 497: Train Loss = 0.012977522797882557\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=367, train_loss_step=0.00972, train_loss_epoch=0.013]Epoch 498: Train Loss = 0.009721631184220314\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=367, train_loss_step=0.00826, train_loss_epoch=0.00972]Epoch 499: Train Loss = 0.008261253125965595\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s, v_num=367, train_loss_step=0.00826, train_loss_epoch=0.00826]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, v_num=367, train_loss_step=0.00826, train_loss_epoch=0.00826]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 14: from 2008-05-12 00:00:00 to 2022-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s, v_num=369, train_loss_step=0.0289]Epoch 0: Train Loss = 0.028860734775662422\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=369, train_loss_step=0.0492, train_loss_epoch=0.0289]Epoch 1: Train Loss = 0.04918285086750984\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=369, train_loss_step=0.0262, train_loss_epoch=0.0492]Epoch 2: Train Loss = 0.026179715991020203\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=369, train_loss_step=0.0202, train_loss_epoch=0.0262]Epoch 3: Train Loss = 0.02018834464251995\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=369, train_loss_step=0.0146, train_loss_epoch=0.0202]Epoch 4: Train Loss = 0.014646315015852451\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=369, train_loss_step=0.015, train_loss_epoch=0.0146] Epoch 5: Train Loss = 0.014955122955143452\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=369, train_loss_step=0.0155, train_loss_epoch=0.015]Epoch 6: Train Loss = 0.01545612420886755\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=369, train_loss_step=0.0129, train_loss_epoch=0.0155]Epoch 7: Train Loss = 0.012921475805342197\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s, v_num=369, train_loss_step=0.0131, train_loss_epoch=0.0129]Epoch 8: Train Loss = 0.013118451461195946\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=369, train_loss_step=0.0144, train_loss_epoch=0.0131]Epoch 9: Train Loss = 0.014396156184375286\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.0144]Epoch 10: Train Loss = 0.011627268977463245\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=369, train_loss_step=0.0136, train_loss_epoch=0.0116]Epoch 11: Train Loss = 0.013637981377542019\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=369, train_loss_step=0.0138, train_loss_epoch=0.0136]Epoch 12: Train Loss = 0.013814078643918037\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=369, train_loss_step=0.013, train_loss_epoch=0.0138] Epoch 13: Train Loss = 0.01297736819833517\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=369, train_loss_step=0.0167, train_loss_epoch=0.013]Epoch 14: Train Loss = 0.016728850081562996\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=369, train_loss_step=0.0138, train_loss_epoch=0.0167]Epoch 15: Train Loss = 0.013762061484158039\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=369, train_loss_step=0.0131, train_loss_epoch=0.0138]Epoch 16: Train Loss = 0.013102282769978046\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=369, train_loss_step=0.0126, train_loss_epoch=0.0131]Epoch 17: Train Loss = 0.012560740113258362\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=369, train_loss_step=0.0113, train_loss_epoch=0.0126]Epoch 18: Train Loss = 0.011341514065861702\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=369, train_loss_step=0.0122, train_loss_epoch=0.0113]Epoch 19: Train Loss = 0.012160837650299072\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=369, train_loss_step=0.0138, train_loss_epoch=0.0122]Epoch 20: Train Loss = 0.013795973733067513\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.0138]Epoch 21: Train Loss = 0.011723166331648827\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=369, train_loss_step=0.013, train_loss_epoch=0.0117] Epoch 22: Train Loss = 0.012968415394425392\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 16.55it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.013]Epoch 23: Train Loss = 0.013186912052333355\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=369, train_loss_step=0.0131, train_loss_epoch=0.0132]Epoch 24: Train Loss = 0.01312132179737091\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=369, train_loss_step=0.0126, train_loss_epoch=0.0131]Epoch 25: Train Loss = 0.012615324929356575\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=369, train_loss_step=0.0105, train_loss_epoch=0.0126]Epoch 26: Train Loss = 0.010468232445418835\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=369, train_loss_step=0.00995, train_loss_epoch=0.0105]Epoch 27: Train Loss = 0.009948955848813057\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=369, train_loss_step=0.0139, train_loss_epoch=0.00995] Epoch 28: Train Loss = 0.013873795978724957\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=369, train_loss_step=0.0119, train_loss_epoch=0.0139] Epoch 29: Train Loss = 0.011938522569835186\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=369, train_loss_step=0.0119, train_loss_epoch=0.0119]Epoch 30: Train Loss = 0.011871985159814358\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=369, train_loss_step=0.0127, train_loss_epoch=0.0119]Epoch 31: Train Loss = 0.012742732651531696\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=369, train_loss_step=0.0164, train_loss_epoch=0.0127]Epoch 32: Train Loss = 0.016381345689296722\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=369, train_loss_step=0.017, train_loss_epoch=0.0164] Epoch 33: Train Loss = 0.01695532537996769\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=369, train_loss_step=0.0109, train_loss_epoch=0.017]Epoch 34: Train Loss = 0.0108542051166296\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=369, train_loss_step=0.0119, train_loss_epoch=0.0109]Epoch 35: Train Loss = 0.011867822147905827\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=369, train_loss_step=0.00987, train_loss_epoch=0.0119]Epoch 36: Train Loss = 0.009872057475149632\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=369, train_loss_step=0.0114, train_loss_epoch=0.00987] Epoch 37: Train Loss = 0.011395945213735104\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, v_num=369, train_loss_step=0.0109, train_loss_epoch=0.0114] Epoch 38: Train Loss = 0.010850084945559502\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=369, train_loss_step=0.00974, train_loss_epoch=0.0109]Epoch 39: Train Loss = 0.00973872933536768\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=369, train_loss_step=0.015, train_loss_epoch=0.00974]  Epoch 40: Train Loss = 0.015011477284133434\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=369, train_loss_step=0.0114, train_loss_epoch=0.015] Epoch 41: Train Loss = 0.011392051354050636\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0114]Epoch 42: Train Loss = 0.01152439322322607\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=369, train_loss_step=0.00861, train_loss_epoch=0.0115]Epoch 43: Train Loss = 0.008613587357103825\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=369, train_loss_step=0.00948, train_loss_epoch=0.00861]Epoch 44: Train Loss = 0.009481029585003853\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=369, train_loss_step=0.0137, train_loss_epoch=0.00948] Epoch 45: Train Loss = 0.013696097768843174\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=369, train_loss_step=0.012, train_loss_epoch=0.0137]  Epoch 46: Train Loss = 0.012016774155199528\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=369, train_loss_step=0.0104, train_loss_epoch=0.012]Epoch 47: Train Loss = 0.010391279123723507\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=369, train_loss_step=0.00985, train_loss_epoch=0.0104]Epoch 48: Train Loss = 0.009854727424681187\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=369, train_loss_step=0.0098, train_loss_epoch=0.00985] Epoch 49: Train Loss = 0.009796388447284698\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=369, train_loss_step=0.00876, train_loss_epoch=0.0098]Epoch 50: Train Loss = 0.008756742812693119\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=369, train_loss_step=0.010, train_loss_epoch=0.00876]  Epoch 51: Train Loss = 0.01004305761307478\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=369, train_loss_step=0.00949, train_loss_epoch=0.010]Epoch 52: Train Loss = 0.009487172588706017\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 16.79it/s, v_num=369, train_loss_step=0.0108, train_loss_epoch=0.00949] Epoch 53: Train Loss = 0.010793457739055157\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.0108] Epoch 54: Train Loss = 0.011176856234669685\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.0112]Epoch 55: Train Loss = 0.013176056556403637\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=369, train_loss_step=0.0129, train_loss_epoch=0.0132]Epoch 56: Train Loss = 0.01287098415195942\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=369, train_loss_step=0.0108, train_loss_epoch=0.0129]Epoch 57: Train Loss = 0.010816963389515877\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=369, train_loss_step=0.00986, train_loss_epoch=0.0108]Epoch 58: Train Loss = 0.009859239682555199\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=369, train_loss_step=0.0105, train_loss_epoch=0.00986] Epoch 59: Train Loss = 0.010545781813561916\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0105] Epoch 60: Train Loss = 0.011515147052705288\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=369, train_loss_step=0.0104, train_loss_epoch=0.0115]Epoch 61: Train Loss = 0.010446920059621334\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=369, train_loss_step=0.0105, train_loss_epoch=0.0104]Epoch 62: Train Loss = 0.010450923815369606\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=369, train_loss_step=0.012, train_loss_epoch=0.0105] Epoch 63: Train Loss = 0.011976785026490688\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=369, train_loss_step=0.00985, train_loss_epoch=0.012]Epoch 64: Train Loss = 0.009849642403423786\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=369, train_loss_step=0.0134, train_loss_epoch=0.00985] Epoch 65: Train Loss = 0.01341981254518032\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=369, train_loss_step=0.0124, train_loss_epoch=0.0134] Epoch 66: Train Loss = 0.01238004770129919\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=369, train_loss_step=0.0171, train_loss_epoch=0.0124]Epoch 67: Train Loss = 0.01711721159517765\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=369, train_loss_step=0.0141, train_loss_epoch=0.0171]Epoch 68: Train Loss = 0.014145811088383198\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.0141]Epoch 69: Train Loss = 0.011589781381189823\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=369, train_loss_step=0.00976, train_loss_epoch=0.0116]Epoch 70: Train Loss = 0.009760365821421146\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 16.40it/s, v_num=369, train_loss_step=0.0127, train_loss_epoch=0.00976] Epoch 71: Train Loss = 0.012706952169537544\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=369, train_loss_step=0.0153, train_loss_epoch=0.0127] Epoch 72: Train Loss = 0.015307484194636345\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=369, train_loss_step=0.0109, train_loss_epoch=0.0153]Epoch 73: Train Loss = 0.010895968414843082\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=369, train_loss_step=0.0103, train_loss_epoch=0.0109]Epoch 74: Train Loss = 0.010259537026286125\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=369, train_loss_step=0.0127, train_loss_epoch=0.0103]Epoch 75: Train Loss = 0.012654886581003666\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=369, train_loss_step=0.0137, train_loss_epoch=0.0127]Epoch 76: Train Loss = 0.013704684562981129\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.0137]Epoch 77: Train Loss = 0.011610796675086021\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=369, train_loss_step=0.00995, train_loss_epoch=0.0116]Epoch 78: Train Loss = 0.009946995414793491\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.00995] Epoch 79: Train Loss = 0.011220596730709076\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=369, train_loss_step=0.016, train_loss_epoch=0.0112]  Epoch 80: Train Loss = 0.016044480726122856\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, v_num=369, train_loss_step=0.0118, train_loss_epoch=0.016]Epoch 81: Train Loss = 0.011802331544458866\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=369, train_loss_step=0.0158, train_loss_epoch=0.0118]Epoch 82: Train Loss = 0.015809299424290657\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=369, train_loss_step=0.00923, train_loss_epoch=0.0158]Epoch 83: Train Loss = 0.00922642182558775\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.00923] Epoch 84: Train Loss = 0.011197342537343502\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=369, train_loss_step=0.00984, train_loss_epoch=0.0112]Epoch 85: Train Loss = 0.009842566214501858\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=369, train_loss_step=0.0162, train_loss_epoch=0.00984] Epoch 86: Train Loss = 0.016220111399888992\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=369, train_loss_step=0.0127, train_loss_epoch=0.0162] Epoch 87: Train Loss = 0.012733778916299343\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=369, train_loss_step=0.0168, train_loss_epoch=0.0127]Epoch 88: Train Loss = 0.016756486147642136\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=369, train_loss_step=0.00902, train_loss_epoch=0.0168]Epoch 89: Train Loss = 0.009018382988870144\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s, v_num=369, train_loss_step=0.0128, train_loss_epoch=0.00902] Epoch 90: Train Loss = 0.012838071212172508\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=369, train_loss_step=0.0148, train_loss_epoch=0.0128] Epoch 91: Train Loss = 0.014811568893492222\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=369, train_loss_step=0.00949, train_loss_epoch=0.0148]Epoch 92: Train Loss = 0.009487217292189598\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=369, train_loss_step=0.0104, train_loss_epoch=0.00949] Epoch 93: Train Loss = 0.01044966746121645\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s, v_num=369, train_loss_step=0.0147, train_loss_epoch=0.0104] Epoch 94: Train Loss = 0.014651129953563213\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0147]Epoch 95: Train Loss = 0.011493881233036518\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=369, train_loss_step=0.0121, train_loss_epoch=0.0115]Epoch 96: Train Loss = 0.012148511596024036\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=369, train_loss_step=0.00853, train_loss_epoch=0.0121]Epoch 97: Train Loss = 0.008533472195267677\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=369, train_loss_step=0.012, train_loss_epoch=0.00853]  Epoch 98: Train Loss = 0.01197474543005228\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=369, train_loss_step=0.00927, train_loss_epoch=0.012]Epoch 99: Train Loss = 0.00926557183265686\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.00927] Epoch 100: Train Loss = 0.01147517655044794\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=369, train_loss_step=0.00959, train_loss_epoch=0.0115]Epoch 101: Train Loss = 0.00958594772964716\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=369, train_loss_step=0.0128, train_loss_epoch=0.00959] Epoch 102: Train Loss = 0.012842873111367226\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0128]  Epoch 103: Train Loss = 0.01095955353230238\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=369, train_loss_step=0.00951, train_loss_epoch=0.011]Epoch 104: Train Loss = 0.009505118243396282\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.00951] Epoch 105: Train Loss = 0.011239588260650635\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.0112] Epoch 106: Train Loss = 0.01169670931994915\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=369, train_loss_step=0.0122, train_loss_epoch=0.0117]Epoch 107: Train Loss = 0.01223684661090374\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=369, train_loss_step=0.0104, train_loss_epoch=0.0122]Epoch 108: Train Loss = 0.010398032143712044\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0104]Epoch 109: Train Loss = 0.010669012553989887\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=369, train_loss_step=0.0103, train_loss_epoch=0.0107]Epoch 110: Train Loss = 0.010284511372447014\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=369, train_loss_step=0.0124, train_loss_epoch=0.0103]Epoch 111: Train Loss = 0.012383484281599522\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.0124]Epoch 112: Train Loss = 0.011736184358596802\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0117] Epoch 113: Train Loss = 0.0109759122133255\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=369, train_loss_step=0.0099, train_loss_epoch=0.011]Epoch 114: Train Loss = 0.009903335012495518\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=369, train_loss_step=0.00954, train_loss_epoch=0.0099]Epoch 115: Train Loss = 0.009538768790662289\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=369, train_loss_step=0.0109, train_loss_epoch=0.00954] Epoch 116: Train Loss = 0.01093369536101818\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 13.54it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0109] Epoch 117: Train Loss = 0.010746806859970093\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 10.51it/s, v_num=369, train_loss_step=0.00989, train_loss_epoch=0.0107]Epoch 118: Train Loss = 0.009889990091323853\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=369, train_loss_step=0.00813, train_loss_epoch=0.00989]Epoch 119: Train Loss = 0.008125723339617252\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.00813] Epoch 120: Train Loss = 0.011233526282012463\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 16.47it/s, v_num=369, train_loss_step=0.00909, train_loss_epoch=0.0112]Epoch 121: Train Loss = 0.009093833155930042\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=369, train_loss_step=0.0129, train_loss_epoch=0.00909] Epoch 122: Train Loss = 0.012862786650657654\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0129] Epoch 123: Train Loss = 0.011533543467521667\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=369, train_loss_step=0.0118, train_loss_epoch=0.0115]Epoch 124: Train Loss = 0.011803247965872288\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=369, train_loss_step=0.00996, train_loss_epoch=0.0118]Epoch 125: Train Loss = 0.00996464304625988\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=369, train_loss_step=0.00879, train_loss_epoch=0.00996]Epoch 126: Train Loss = 0.008790944702923298\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=369, train_loss_step=0.0127, train_loss_epoch=0.00879] Epoch 127: Train Loss = 0.01271766982972622\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=369, train_loss_step=0.0127, train_loss_epoch=0.0127] Epoch 128: Train Loss = 0.01265204418450594\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=369, train_loss_step=0.0109, train_loss_epoch=0.0127]Epoch 129: Train Loss = 0.010898415930569172\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=369, train_loss_step=0.0114, train_loss_epoch=0.0109]Epoch 130: Train Loss = 0.01141752302646637\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s, v_num=369, train_loss_step=0.0113, train_loss_epoch=0.0114]Epoch 131: Train Loss = 0.011326124891638756\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=369, train_loss_step=0.015, train_loss_epoch=0.0113] Epoch 132: Train Loss = 0.015040287747979164\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s, v_num=369, train_loss_step=0.0106, train_loss_epoch=0.015]Epoch 133: Train Loss = 0.010564297437667847\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=369, train_loss_step=0.0121, train_loss_epoch=0.0106]Epoch 134: Train Loss = 0.012109460309147835\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=369, train_loss_step=0.00966, train_loss_epoch=0.0121]Epoch 135: Train Loss = 0.00965618435293436\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=369, train_loss_step=0.0135, train_loss_epoch=0.00966] Epoch 136: Train Loss = 0.013502941466867924\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.0135] Epoch 137: Train Loss = 0.01122348289936781\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=369, train_loss_step=0.0101, train_loss_epoch=0.0112]Epoch 138: Train Loss = 0.010106489062309265\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=369, train_loss_step=0.0111, train_loss_epoch=0.0101]Epoch 139: Train Loss = 0.011066042818129063\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=369, train_loss_step=0.00988, train_loss_epoch=0.0111]Epoch 140: Train Loss = 0.009878645651042461\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=369, train_loss_step=0.0152, train_loss_epoch=0.00988] Epoch 141: Train Loss = 0.01522890292108059\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, v_num=369, train_loss_step=0.00995, train_loss_epoch=0.0152]Epoch 142: Train Loss = 0.009952702559530735\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s, v_num=369, train_loss_step=0.0124, train_loss_epoch=0.00995] Epoch 143: Train Loss = 0.012442784383893013\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s, v_num=369, train_loss_step=0.0124, train_loss_epoch=0.0124] Epoch 144: Train Loss = 0.01244612131267786\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=369, train_loss_step=0.0152, train_loss_epoch=0.0124]Epoch 145: Train Loss = 0.015239630825817585\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.0152]Epoch 146: Train Loss = 0.013239217922091484\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=369, train_loss_step=0.0123, train_loss_epoch=0.0132]Epoch 147: Train Loss = 0.012291883118450642\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=369, train_loss_step=0.0136, train_loss_epoch=0.0123]Epoch 148: Train Loss = 0.013590154238045216\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.0136]Epoch 149: Train Loss = 0.011624456383287907\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=369, train_loss_step=0.0155, train_loss_epoch=0.0116]Epoch 150: Train Loss = 0.015488809905946255\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=369, train_loss_step=0.0111, train_loss_epoch=0.0155]Epoch 151: Train Loss = 0.011099806986749172\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=369, train_loss_step=0.012, train_loss_epoch=0.0111] Epoch 152: Train Loss = 0.012010694481432438\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.012]Epoch 153: Train Loss = 0.010708891786634922\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=369, train_loss_step=0.00998, train_loss_epoch=0.0107]Epoch 154: Train Loss = 0.00997836608439684\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=369, train_loss_step=0.0113, train_loss_epoch=0.00998] Epoch 155: Train Loss = 0.01129948627203703\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=369, train_loss_step=0.00982, train_loss_epoch=0.0113]Epoch 156: Train Loss = 0.009822266176342964\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s, v_num=369, train_loss_step=0.00936, train_loss_epoch=0.00982]Epoch 157: Train Loss = 0.00936278235167265\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=369, train_loss_step=0.0122, train_loss_epoch=0.00936] Epoch 158: Train Loss = 0.012240439653396606\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0122] Epoch 159: Train Loss = 0.010710653848946095\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=369, train_loss_step=0.0149, train_loss_epoch=0.0107]Epoch 160: Train Loss = 0.014919825829565525\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=369, train_loss_step=0.0123, train_loss_epoch=0.0149]Epoch 161: Train Loss = 0.012321216985583305\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s, v_num=369, train_loss_step=0.0101, train_loss_epoch=0.0123]Epoch 162: Train Loss = 0.01007718127220869\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=369, train_loss_step=0.0113, train_loss_epoch=0.0101]Epoch 163: Train Loss = 0.011268223635852337\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=369, train_loss_step=0.0124, train_loss_epoch=0.0113]Epoch 164: Train Loss = 0.012441364116966724\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=369, train_loss_step=0.0128, train_loss_epoch=0.0124]Epoch 165: Train Loss = 0.012778458185493946\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=369, train_loss_step=0.0141, train_loss_epoch=0.0128]Epoch 166: Train Loss = 0.014089870266616344\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=369, train_loss_step=0.008, train_loss_epoch=0.0141] Epoch 167: Train Loss = 0.008000091649591923\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=369, train_loss_step=0.010, train_loss_epoch=0.008] Epoch 168: Train Loss = 0.010036625899374485\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=369, train_loss_step=0.00927, train_loss_epoch=0.010]Epoch 169: Train Loss = 0.009274491108953953\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=369, train_loss_step=0.0119, train_loss_epoch=0.00927] Epoch 170: Train Loss = 0.011898777447640896\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=369, train_loss_step=0.0131, train_loss_epoch=0.0119] Epoch 171: Train Loss = 0.013111969456076622\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=369, train_loss_step=0.0091, train_loss_epoch=0.0131]Epoch 172: Train Loss = 0.009095092304050922\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=369, train_loss_step=0.0118, train_loss_epoch=0.0091]Epoch 173: Train Loss = 0.011762944050133228\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=369, train_loss_step=0.00962, train_loss_epoch=0.0118]Epoch 174: Train Loss = 0.009624546393752098\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=369, train_loss_step=0.00982, train_loss_epoch=0.00962]Epoch 175: Train Loss = 0.009820378385484219\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=369, train_loss_step=0.0105, train_loss_epoch=0.00982] Epoch 176: Train Loss = 0.010477696545422077\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.0105] Epoch 177: Train Loss = 0.011242381297051907\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=369, train_loss_step=0.0118, train_loss_epoch=0.0112]Epoch 178: Train Loss = 0.011835424229502678\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=369, train_loss_step=0.0105, train_loss_epoch=0.0118]Epoch 179: Train Loss = 0.010499090887606144\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0105]Epoch 180: Train Loss = 0.010669267736375332\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=369, train_loss_step=0.00952, train_loss_epoch=0.0107]Epoch 181: Train Loss = 0.009517272934317589\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=369, train_loss_step=0.00774, train_loss_epoch=0.00952]Epoch 182: Train Loss = 0.007739732973277569\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=369, train_loss_step=0.0124, train_loss_epoch=0.00774] Epoch 183: Train Loss = 0.012352054007351398\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=369, train_loss_step=0.013, train_loss_epoch=0.0124]  Epoch 184: Train Loss = 0.013041073456406593\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=369, train_loss_step=0.00862, train_loss_epoch=0.013]Epoch 185: Train Loss = 0.008616050705313683\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=369, train_loss_step=0.0113, train_loss_epoch=0.00862] Epoch 186: Train Loss = 0.01125400047749281\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 13.68it/s, v_num=369, train_loss_step=0.010, train_loss_epoch=0.0113]  Epoch 187: Train Loss = 0.010031193494796753\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s, v_num=369, train_loss_step=0.00975, train_loss_epoch=0.010]Epoch 188: Train Loss = 0.009754158556461334\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=369, train_loss_step=0.012, train_loss_epoch=0.00975]  Epoch 189: Train Loss = 0.011965842917561531\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=369, train_loss_step=0.0134, train_loss_epoch=0.012] Epoch 190: Train Loss = 0.013387748040258884\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0134]Epoch 191: Train Loss = 0.010711929760873318\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=369, train_loss_step=0.0103, train_loss_epoch=0.0107]Epoch 192: Train Loss = 0.010258287191390991\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=369, train_loss_step=0.00839, train_loss_epoch=0.0103]Epoch 193: Train Loss = 0.008394522592425346\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=369, train_loss_step=0.00956, train_loss_epoch=0.00839]Epoch 194: Train Loss = 0.009558198973536491\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=369, train_loss_step=0.00918, train_loss_epoch=0.00956]Epoch 195: Train Loss = 0.00917709432542324\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=369, train_loss_step=0.0125, train_loss_epoch=0.00918] Epoch 196: Train Loss = 0.012547786347568035\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=369, train_loss_step=0.00879, train_loss_epoch=0.0125]Epoch 197: Train Loss = 0.008794699795544147\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=369, train_loss_step=0.0137, train_loss_epoch=0.00879] Epoch 198: Train Loss = 0.013713150285184383\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=369, train_loss_step=0.00841, train_loss_epoch=0.0137]Epoch 199: Train Loss = 0.008409184403717518\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=369, train_loss_step=0.014, train_loss_epoch=0.00841]  Epoch 200: Train Loss = 0.013993360102176666\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.014] Epoch 201: Train Loss = 0.01317340973764658\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=369, train_loss_step=0.00725, train_loss_epoch=0.0132]Epoch 202: Train Loss = 0.007246498949825764\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=369, train_loss_step=0.00833, train_loss_epoch=0.00725]Epoch 203: Train Loss = 0.008329009637236595\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=369, train_loss_step=0.0102, train_loss_epoch=0.00833] Epoch 204: Train Loss = 0.010245271027088165\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=369, train_loss_step=0.008, train_loss_epoch=0.0102]  Epoch 205: Train Loss = 0.008001339621841908\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=369, train_loss_step=0.0106, train_loss_epoch=0.008]Epoch 206: Train Loss = 0.010582965798676014\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, v_num=369, train_loss_step=0.00993, train_loss_epoch=0.0106]Epoch 207: Train Loss = 0.009933719411492348\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=369, train_loss_step=0.0133, train_loss_epoch=0.00993] Epoch 208: Train Loss = 0.013284523971378803\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.0133] Epoch 209: Train Loss = 0.01324806921184063\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=369, train_loss_step=0.0128, train_loss_epoch=0.0132]Epoch 210: Train Loss = 0.012827938422560692\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0128] Epoch 211: Train Loss = 0.010967067442834377\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=369, train_loss_step=0.00987, train_loss_epoch=0.011]Epoch 212: Train Loss = 0.009871003217995167\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=369, train_loss_step=0.0121, train_loss_epoch=0.00987] Epoch 213: Train Loss = 0.012089387513697147\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=369, train_loss_step=0.0122, train_loss_epoch=0.0121] Epoch 214: Train Loss = 0.012168831191956997\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=369, train_loss_step=0.00878, train_loss_epoch=0.0122]Epoch 215: Train Loss = 0.008777567185461521\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=369, train_loss_step=0.00998, train_loss_epoch=0.00878]Epoch 216: Train Loss = 0.009982526302337646\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=369, train_loss_step=0.00831, train_loss_epoch=0.00998]Epoch 217: Train Loss = 0.008312377147376537\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=369, train_loss_step=0.0101, train_loss_epoch=0.00831] Epoch 218: Train Loss = 0.010149652138352394\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.0101] Epoch 219: Train Loss = 0.01318658608943224\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=369, train_loss_step=0.0128, train_loss_epoch=0.0132]Epoch 220: Train Loss = 0.01277671568095684\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=369, train_loss_step=0.0143, train_loss_epoch=0.0128]Epoch 221: Train Loss = 0.014281952753663063\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.0143]Epoch 222: Train Loss = 0.01160470675677061\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=369, train_loss_step=0.0138, train_loss_epoch=0.0116]Epoch 223: Train Loss = 0.013754828833043575\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 13.65it/s, v_num=369, train_loss_step=0.0137, train_loss_epoch=0.0138]Epoch 224: Train Loss = 0.01370270736515522\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 12.90it/s, v_num=369, train_loss_step=0.0102, train_loss_epoch=0.0137]Epoch 225: Train Loss = 0.010150632821023464\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=369, train_loss_step=0.0162, train_loss_epoch=0.0102]Epoch 226: Train Loss = 0.016166256740689278\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.0162]Epoch 227: Train Loss = 0.01166670210659504\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.0117]Epoch 228: Train Loss = 0.01168915443122387\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=369, train_loss_step=0.0165, train_loss_epoch=0.0117]Epoch 229: Train Loss = 0.01647229492664337\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0165] Epoch 230: Train Loss = 0.010962364263832569\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=369, train_loss_step=0.0175, train_loss_epoch=0.011]Epoch 231: Train Loss = 0.017519550397992134\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=369, train_loss_step=0.0161, train_loss_epoch=0.0175]Epoch 232: Train Loss = 0.01610296219587326\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=369, train_loss_step=0.0138, train_loss_epoch=0.0161]Epoch 233: Train Loss = 0.013756834901869297\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, v_num=369, train_loss_step=0.020, train_loss_epoch=0.0138] Epoch 234: Train Loss = 0.02000616118311882\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.020]Epoch 235: Train Loss = 0.011501261964440346\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.0115]Epoch 236: Train Loss = 0.011656432412564754\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.0117]Epoch 237: Train Loss = 0.011735956184566021\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=369, train_loss_step=0.013, train_loss_epoch=0.0117] Epoch 238: Train Loss = 0.013029394671320915\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=369, train_loss_step=0.0184, train_loss_epoch=0.013]Epoch 239: Train Loss = 0.018449364230036736\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 16.06it/s, v_num=369, train_loss_step=0.0153, train_loss_epoch=0.0184]Epoch 240: Train Loss = 0.01528930477797985\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.0153]Epoch 241: Train Loss = 0.013162828050553799\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=369, train_loss_step=0.0122, train_loss_epoch=0.0132]Epoch 242: Train Loss = 0.0121985524892807\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 13.32it/s, v_num=369, train_loss_step=0.00998, train_loss_epoch=0.0122]Epoch 243: Train Loss = 0.009975208900868893\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=369, train_loss_step=0.00932, train_loss_epoch=0.00998]Epoch 244: Train Loss = 0.009319824166595936\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.00932] Epoch 245: Train Loss = 0.011738045141100883\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=369, train_loss_step=0.0163, train_loss_epoch=0.0117] Epoch 246: Train Loss = 0.016274357214570045\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.0163]Epoch 247: Train Loss = 0.01122343447059393\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=369, train_loss_step=0.0105, train_loss_epoch=0.0112]Epoch 248: Train Loss = 0.0105404919013381\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=369, train_loss_step=0.013, train_loss_epoch=0.0105] Epoch 249: Train Loss = 0.013028654269874096\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=369, train_loss_step=0.0124, train_loss_epoch=0.013]Epoch 250: Train Loss = 0.012404347769916058\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=369, train_loss_step=0.0105, train_loss_epoch=0.0124]Epoch 251: Train Loss = 0.010497360490262508\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.0105]Epoch 252: Train Loss = 0.011676141060888767\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0117]Epoch 253: Train Loss = 0.010709090158343315\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=369, train_loss_step=0.0118, train_loss_epoch=0.0107]Epoch 254: Train Loss = 0.011824256740510464\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.0118]Epoch 255: Train Loss = 0.01324886828660965\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=369, train_loss_step=0.0138, train_loss_epoch=0.0132]Epoch 256: Train Loss = 0.013849414885044098\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0138]Epoch 257: Train Loss = 0.011531786993145943\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=369, train_loss_step=0.0102, train_loss_epoch=0.0115]Epoch 258: Train Loss = 0.010228590108454227\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=369, train_loss_step=0.0104, train_loss_epoch=0.0102]Epoch 259: Train Loss = 0.01044800691306591\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 260: Train Loss = 0.011500502936542034\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=369, train_loss_step=0.0131, train_loss_epoch=0.0115]Epoch 261: Train Loss = 0.01312676165252924\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=369, train_loss_step=0.00984, train_loss_epoch=0.0131]Epoch 262: Train Loss = 0.009839787147939205\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=369, train_loss_step=0.0138, train_loss_epoch=0.00984] Epoch 263: Train Loss = 0.013837724924087524\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=369, train_loss_step=0.00971, train_loss_epoch=0.0138]Epoch 264: Train Loss = 0.009705739095807076\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.00971] Epoch 265: Train Loss = 0.011551253497600555\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=369, train_loss_step=0.0089, train_loss_epoch=0.0116] Epoch 266: Train Loss = 0.008902854286134243\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0089] Epoch 267: Train Loss = 0.011020434089004993\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=369, train_loss_step=0.012, train_loss_epoch=0.011] Epoch 268: Train Loss = 0.01196922268718481\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=369, train_loss_step=0.0152, train_loss_epoch=0.012]Epoch 269: Train Loss = 0.015239892527461052\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=369, train_loss_step=0.0104, train_loss_epoch=0.0152]Epoch 270: Train Loss = 0.01039134245365858\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 271: Train Loss = 0.011450624093413353\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0115] Epoch 272: Train Loss = 0.01104381587356329\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.011]Epoch 273: Train Loss = 0.01169058121740818\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=369, train_loss_step=0.00855, train_loss_epoch=0.0117]Epoch 274: Train Loss = 0.008551965467631817\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=369, train_loss_step=0.0134, train_loss_epoch=0.00855] Epoch 275: Train Loss = 0.013378972187638283\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, v_num=369, train_loss_step=0.0102, train_loss_epoch=0.0134] Epoch 276: Train Loss = 0.01016564667224884\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=369, train_loss_step=0.0121, train_loss_epoch=0.0102]Epoch 277: Train Loss = 0.012130169197916985\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s, v_num=369, train_loss_step=0.00976, train_loss_epoch=0.0121]Epoch 278: Train Loss = 0.009756422601640224\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, v_num=369, train_loss_step=0.0102, train_loss_epoch=0.00976] Epoch 279: Train Loss = 0.010192119516432285\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0102]  Epoch 280: Train Loss = 0.011042130179703236\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.011]Epoch 281: Train Loss = 0.010714421980082989\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=369, train_loss_step=0.00975, train_loss_epoch=0.0107]Epoch 282: Train Loss = 0.009746404364705086\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.00975] Epoch 283: Train Loss = 0.013174678198993206\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=369, train_loss_step=0.0105, train_loss_epoch=0.0132] Epoch 284: Train Loss = 0.010489625856280327\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=369, train_loss_step=0.0122, train_loss_epoch=0.0105]Epoch 285: Train Loss = 0.012157604098320007\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=369, train_loss_step=0.0097, train_loss_epoch=0.0122]Epoch 286: Train Loss = 0.009703705087304115\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=369, train_loss_step=0.0105, train_loss_epoch=0.0097]Epoch 287: Train Loss = 0.010480646975338459\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=369, train_loss_step=0.00885, train_loss_epoch=0.0105]Epoch 288: Train Loss = 0.00885265413671732\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=369, train_loss_step=0.0126, train_loss_epoch=0.00885] Epoch 289: Train Loss = 0.012610835023224354\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 13.77it/s, v_num=369, train_loss_step=0.00924, train_loss_epoch=0.0126]Epoch 290: Train Loss = 0.009240476414561272\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=369, train_loss_step=0.0102, train_loss_epoch=0.00924] Epoch 291: Train Loss = 0.010220184922218323\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=369, train_loss_step=0.0076, train_loss_epoch=0.0102] Epoch 292: Train Loss = 0.007597174495458603\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=369, train_loss_step=0.010, train_loss_epoch=0.0076] Epoch 293: Train Loss = 0.01004713587462902\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 16.65it/s, v_num=369, train_loss_step=0.0121, train_loss_epoch=0.010]Epoch 294: Train Loss = 0.012054815888404846\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=369, train_loss_step=0.0104, train_loss_epoch=0.0121]Epoch 295: Train Loss = 0.010431205853819847\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, v_num=369, train_loss_step=0.0126, train_loss_epoch=0.0104]Epoch 296: Train Loss = 0.012569738551974297\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s, v_num=369, train_loss_step=0.0104, train_loss_epoch=0.0126]Epoch 297: Train Loss = 0.010351949371397495\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=369, train_loss_step=0.0124, train_loss_epoch=0.0104]Epoch 298: Train Loss = 0.012363606132566929\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=369, train_loss_step=0.00919, train_loss_epoch=0.0124]Epoch 299: Train Loss = 0.009192579425871372\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=369, train_loss_step=0.0111, train_loss_epoch=0.00919] Epoch 300: Train Loss = 0.011080318130552769\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=369, train_loss_step=0.00925, train_loss_epoch=0.0111]Epoch 301: Train Loss = 0.009254413656890392\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s, v_num=369, train_loss_step=0.00882, train_loss_epoch=0.00925]Epoch 302: Train Loss = 0.008824879303574562\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 12.26it/s, v_num=369, train_loss_step=0.0125, train_loss_epoch=0.00882] Epoch 303: Train Loss = 0.012527870945632458\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 12.27it/s, v_num=369, train_loss_step=0.0108, train_loss_epoch=0.0125] Epoch 304: Train Loss = 0.010780195705592632\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=369, train_loss_step=0.00794, train_loss_epoch=0.0108]Epoch 305: Train Loss = 0.007937178015708923\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=369, train_loss_step=0.0108, train_loss_epoch=0.00794] Epoch 306: Train Loss = 0.010818888433277607\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, v_num=369, train_loss_step=0.00936, train_loss_epoch=0.0108]Epoch 307: Train Loss = 0.009356905706226826\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=369, train_loss_step=0.00966, train_loss_epoch=0.00936]Epoch 308: Train Loss = 0.00965678971260786\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=369, train_loss_step=0.0113, train_loss_epoch=0.00966] Epoch 309: Train Loss = 0.01133216917514801\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=369, train_loss_step=0.0136, train_loss_epoch=0.0113] Epoch 310: Train Loss = 0.01357191801071167\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0136]Epoch 311: Train Loss = 0.01067025400698185\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=369, train_loss_step=0.00981, train_loss_epoch=0.0107]Epoch 312: Train Loss = 0.009810219518840313\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=369, train_loss_step=0.00935, train_loss_epoch=0.00981]Epoch 313: Train Loss = 0.009347173385322094\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.00935] Epoch 314: Train Loss = 0.011744056828320026\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=369, train_loss_step=0.00901, train_loss_epoch=0.0117]Epoch 315: Train Loss = 0.009009309113025665\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=369, train_loss_step=0.00943, train_loss_epoch=0.00901]Epoch 316: Train Loss = 0.009429676458239555\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=369, train_loss_step=0.00879, train_loss_epoch=0.00943]Epoch 317: Train Loss = 0.008794349618256092\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.00879] Epoch 318: Train Loss = 0.011199386790394783\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.0112] Epoch 319: Train Loss = 0.01115952804684639\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=369, train_loss_step=0.0106, train_loss_epoch=0.0112]Epoch 320: Train Loss = 0.010635257698595524\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=369, train_loss_step=0.0113, train_loss_epoch=0.0106]Epoch 321: Train Loss = 0.011298537254333496\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=369, train_loss_step=0.0109, train_loss_epoch=0.0113]Epoch 322: Train Loss = 0.010902189649641514\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=369, train_loss_step=0.0119, train_loss_epoch=0.0109]Epoch 323: Train Loss = 0.011850380338728428\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0119]Epoch 324: Train Loss = 0.010712862946093082\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=369, train_loss_step=0.00949, train_loss_epoch=0.0107]Epoch 325: Train Loss = 0.009493702091276646\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=369, train_loss_step=0.0127, train_loss_epoch=0.00949] Epoch 326: Train Loss = 0.0127427252009511\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=369, train_loss_step=0.0121, train_loss_epoch=0.0127] Epoch 327: Train Loss = 0.012136955745518208\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=369, train_loss_step=0.0111, train_loss_epoch=0.0121]Epoch 328: Train Loss = 0.011059040203690529\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.0111]Epoch 329: Train Loss = 0.011163076385855675\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 12.98it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0112]Epoch 330: Train Loss = 0.011482876725494862\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=369, train_loss_step=0.00906, train_loss_epoch=0.0115]Epoch 331: Train Loss = 0.009059806354343891\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=369, train_loss_step=0.00928, train_loss_epoch=0.00906]Epoch 332: Train Loss = 0.009284630417823792\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=369, train_loss_step=0.0125, train_loss_epoch=0.00928] Epoch 333: Train Loss = 0.012533202767372131\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=369, train_loss_step=0.0114, train_loss_epoch=0.0125] Epoch 334: Train Loss = 0.01137964241206646\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=369, train_loss_step=0.0114, train_loss_epoch=0.0114]Epoch 335: Train Loss = 0.01135583221912384\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=369, train_loss_step=0.00962, train_loss_epoch=0.0114]Epoch 336: Train Loss = 0.009622477926313877\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.00962] Epoch 337: Train Loss = 0.013174978084862232\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=369, train_loss_step=0.0103, train_loss_epoch=0.0132] Epoch 338: Train Loss = 0.010256011970341206\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s, v_num=369, train_loss_step=0.00936, train_loss_epoch=0.0103]Epoch 339: Train Loss = 0.009361999109387398\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=369, train_loss_step=0.015, train_loss_epoch=0.00936]  Epoch 340: Train Loss = 0.01501349825412035\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=369, train_loss_step=0.0088, train_loss_epoch=0.015] Epoch 341: Train Loss = 0.008802407421171665\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=369, train_loss_step=0.00993, train_loss_epoch=0.0088]Epoch 342: Train Loss = 0.009928089566528797\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=369, train_loss_step=0.00999, train_loss_epoch=0.00993]Epoch 343: Train Loss = 0.009994766674935818\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=369, train_loss_step=0.00763, train_loss_epoch=0.00999]Epoch 344: Train Loss = 0.007626824080944061\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=369, train_loss_step=0.00944, train_loss_epoch=0.00763]Epoch 345: Train Loss = 0.00943566020578146\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=369, train_loss_step=0.00983, train_loss_epoch=0.00944]Epoch 346: Train Loss = 0.009829173795878887\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=369, train_loss_step=0.00689, train_loss_epoch=0.00983]Epoch 347: Train Loss = 0.006894991267472506\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, v_num=369, train_loss_step=0.0111, train_loss_epoch=0.00689] Epoch 348: Train Loss = 0.011066973209381104\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=369, train_loss_step=0.00951, train_loss_epoch=0.0111]Epoch 349: Train Loss = 0.009507449343800545\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=369, train_loss_step=0.0101, train_loss_epoch=0.00951] Epoch 350: Train Loss = 0.010123089887201786\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0101]  Epoch 351: Train Loss = 0.010958795435726643\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=369, train_loss_step=0.0123, train_loss_epoch=0.011]Epoch 352: Train Loss = 0.012315258383750916\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=369, train_loss_step=0.013, train_loss_epoch=0.0123] Epoch 353: Train Loss = 0.013022429309785366\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, v_num=369, train_loss_step=0.0144, train_loss_epoch=0.013]Epoch 354: Train Loss = 0.014445117674767971\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=369, train_loss_step=0.0131, train_loss_epoch=0.0144]Epoch 355: Train Loss = 0.01307153794914484\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=369, train_loss_step=0.0138, train_loss_epoch=0.0131]Epoch 356: Train Loss = 0.013753308914601803\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 13.09it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0138]Epoch 357: Train Loss = 0.010706761851906776\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=369, train_loss_step=0.0134, train_loss_epoch=0.0107]Epoch 358: Train Loss = 0.013390185311436653\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0134] Epoch 359: Train Loss = 0.011026185937225819\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=369, train_loss_step=0.00912, train_loss_epoch=0.011]Epoch 360: Train Loss = 0.009124447591602802\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=369, train_loss_step=0.00841, train_loss_epoch=0.00912]Epoch 361: Train Loss = 0.00841126125305891\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=369, train_loss_step=0.00978, train_loss_epoch=0.00841]Epoch 362: Train Loss = 0.009775021113455296\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=369, train_loss_step=0.0109, train_loss_epoch=0.00978] Epoch 363: Train Loss = 0.010863902047276497\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=369, train_loss_step=0.00965, train_loss_epoch=0.0109]Epoch 364: Train Loss = 0.009646257385611534\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=369, train_loss_step=0.00958, train_loss_epoch=0.00965]Epoch 365: Train Loss = 0.009583958424627781\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.00958] Epoch 366: Train Loss = 0.011570055969059467\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=369, train_loss_step=0.0072, train_loss_epoch=0.0116] Epoch 367: Train Loss = 0.00719773443415761\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=369, train_loss_step=0.0122, train_loss_epoch=0.0072]Epoch 368: Train Loss = 0.01224242988973856\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=369, train_loss_step=0.0098, train_loss_epoch=0.0122]Epoch 369: Train Loss = 0.009795364923775196\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=369, train_loss_step=0.00867, train_loss_epoch=0.0098]Epoch 370: Train Loss = 0.00867019034922123\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=369, train_loss_step=0.00952, train_loss_epoch=0.00867]Epoch 371: Train Loss = 0.009520858526229858\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.00952] Epoch 372: Train Loss = 0.01164566446095705\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=369, train_loss_step=0.00856, train_loss_epoch=0.0116]Epoch 373: Train Loss = 0.008556428365409374\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=369, train_loss_step=0.0128, train_loss_epoch=0.00856] Epoch 374: Train Loss = 0.012774506583809853\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=369, train_loss_step=0.0098, train_loss_epoch=0.0128] Epoch 375: Train Loss = 0.00980089046061039\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=369, train_loss_step=0.00982, train_loss_epoch=0.0098]Epoch 376: Train Loss = 0.009816152043640614\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.00982] Epoch 377: Train Loss = 0.011726458556950092\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 13.50it/s, v_num=369, train_loss_step=0.014, train_loss_epoch=0.0117]  Epoch 378: Train Loss = 0.013961179181933403\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=369, train_loss_step=0.00788, train_loss_epoch=0.014]Epoch 379: Train Loss = 0.00788117852061987\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=369, train_loss_step=0.00885, train_loss_epoch=0.00788]Epoch 380: Train Loss = 0.008846457116305828\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=369, train_loss_step=0.00876, train_loss_epoch=0.00885]Epoch 381: Train Loss = 0.008758286945521832\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=369, train_loss_step=0.013, train_loss_epoch=0.00876]  Epoch 382: Train Loss = 0.013013690710067749\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 14.17it/s, v_num=369, train_loss_step=0.00787, train_loss_epoch=0.013]Epoch 383: Train Loss = 0.007865744642913342\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=369, train_loss_step=0.012, train_loss_epoch=0.00787]  Epoch 384: Train Loss = 0.011956985108554363\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=369, train_loss_step=0.00847, train_loss_epoch=0.012]Epoch 385: Train Loss = 0.008473220281302929\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=369, train_loss_step=0.012, train_loss_epoch=0.00847]  Epoch 386: Train Loss = 0.011982964351773262\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=369, train_loss_step=0.0114, train_loss_epoch=0.012] Epoch 387: Train Loss = 0.011404437944293022\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=369, train_loss_step=0.0084, train_loss_epoch=0.0114]Epoch 388: Train Loss = 0.008397342637181282\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=369, train_loss_step=0.0113, train_loss_epoch=0.0084]Epoch 389: Train Loss = 0.011268631555140018\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=369, train_loss_step=0.0114, train_loss_epoch=0.0113]Epoch 390: Train Loss = 0.01137508638203144\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=369, train_loss_step=0.00897, train_loss_epoch=0.0114]Epoch 391: Train Loss = 0.008969403803348541\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=369, train_loss_step=0.0117, train_loss_epoch=0.00897] Epoch 392: Train Loss = 0.011681011877954006\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=369, train_loss_step=0.0118, train_loss_epoch=0.0117] Epoch 393: Train Loss = 0.011848824098706245\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=369, train_loss_step=0.0101, train_loss_epoch=0.0118]Epoch 394: Train Loss = 0.010054861195385456\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0101] Epoch 395: Train Loss = 0.01102371048182249\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=369, train_loss_step=0.00723, train_loss_epoch=0.011]Epoch 396: Train Loss = 0.007232938427478075\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=369, train_loss_step=0.0122, train_loss_epoch=0.00723] Epoch 397: Train Loss = 0.012154524214565754\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=369, train_loss_step=0.00771, train_loss_epoch=0.0122]Epoch 398: Train Loss = 0.007707240525633097\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=369, train_loss_step=0.0111, train_loss_epoch=0.00771] Epoch 399: Train Loss = 0.011058039031922817\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=369, train_loss_step=0.00943, train_loss_epoch=0.0111]Epoch 400: Train Loss = 0.009428904391825199\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=369, train_loss_step=0.0125, train_loss_epoch=0.00943] Epoch 401: Train Loss = 0.012486478313803673\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=369, train_loss_step=0.0139, train_loss_epoch=0.0125] Epoch 402: Train Loss = 0.013926250860095024\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=369, train_loss_step=0.00922, train_loss_epoch=0.0139]Epoch 403: Train Loss = 0.00921595748513937\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=369, train_loss_step=0.0109, train_loss_epoch=0.00922] Epoch 404: Train Loss = 0.010872723534703255\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=369, train_loss_step=0.014, train_loss_epoch=0.0109]  Epoch 405: Train Loss = 0.013982617296278477\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=369, train_loss_step=0.0108, train_loss_epoch=0.014]Epoch 406: Train Loss = 0.010763113386929035\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=369, train_loss_step=0.0143, train_loss_epoch=0.0108]Epoch 407: Train Loss = 0.014349629171192646\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=369, train_loss_step=0.0111, train_loss_epoch=0.0143]Epoch 408: Train Loss = 0.011108978651463985\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=369, train_loss_step=0.0109, train_loss_epoch=0.0111]Epoch 409: Train Loss = 0.01090331468731165\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=369, train_loss_step=0.00876, train_loss_epoch=0.0109]Epoch 410: Train Loss = 0.008763951249420643\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.00876] Epoch 411: Train Loss = 0.01156432181596756\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=369, train_loss_step=0.00831, train_loss_epoch=0.0116]Epoch 412: Train Loss = 0.008306469768285751\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=369, train_loss_step=0.00967, train_loss_epoch=0.00831]Epoch 413: Train Loss = 0.009670885279774666\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=369, train_loss_step=0.0087, train_loss_epoch=0.00967] Epoch 414: Train Loss = 0.008698671124875546\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=369, train_loss_step=0.013, train_loss_epoch=0.0087]  Epoch 415: Train Loss = 0.012962273322045803\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=369, train_loss_step=0.00965, train_loss_epoch=0.013]Epoch 416: Train Loss = 0.009646319784224033\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 12.45it/s, v_num=369, train_loss_step=0.00815, train_loss_epoch=0.00965]Epoch 417: Train Loss = 0.008147632703185081\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s, v_num=369, train_loss_step=0.0122, train_loss_epoch=0.00815] Epoch 418: Train Loss = 0.01218525879085064\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=369, train_loss_step=0.0134, train_loss_epoch=0.0122] Epoch 419: Train Loss = 0.013419726863503456\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, v_num=369, train_loss_step=0.00975, train_loss_epoch=0.0134]Epoch 420: Train Loss = 0.009754030965268612\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=369, train_loss_step=0.00879, train_loss_epoch=0.00975]Epoch 421: Train Loss = 0.008792146109044552\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=369, train_loss_step=0.0104, train_loss_epoch=0.00879] Epoch 422: Train Loss = 0.010405570268630981\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=369, train_loss_step=0.00975, train_loss_epoch=0.0104]Epoch 423: Train Loss = 0.009747189469635487\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=369, train_loss_step=0.0127, train_loss_epoch=0.00975] Epoch 424: Train Loss = 0.012670238502323627\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=369, train_loss_step=0.00963, train_loss_epoch=0.0127]Epoch 425: Train Loss = 0.009634493850171566\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, v_num=369, train_loss_step=0.0132, train_loss_epoch=0.00963] Epoch 426: Train Loss = 0.013152087107300758\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=369, train_loss_step=0.013, train_loss_epoch=0.0132]  Epoch 427: Train Loss = 0.013029927387833595\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=369, train_loss_step=0.0083, train_loss_epoch=0.013]Epoch 428: Train Loss = 0.00829852744936943\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=369, train_loss_step=0.00964, train_loss_epoch=0.0083]Epoch 429: Train Loss = 0.009643102996051311\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=369, train_loss_step=0.0146, train_loss_epoch=0.00964] Epoch 430: Train Loss = 0.014603808522224426\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=369, train_loss_step=0.00917, train_loss_epoch=0.0146]Epoch 431: Train Loss = 0.009174655191600323\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=369, train_loss_step=0.0097, train_loss_epoch=0.00917] Epoch 432: Train Loss = 0.00969916582107544\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=369, train_loss_step=0.0104, train_loss_epoch=0.0097] Epoch 433: Train Loss = 0.010428337380290031\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=369, train_loss_step=0.0119, train_loss_epoch=0.0104]Epoch 434: Train Loss = 0.011897155083715916\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=369, train_loss_step=0.00895, train_loss_epoch=0.0119]Epoch 435: Train Loss = 0.008945520035922527\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=369, train_loss_step=0.0122, train_loss_epoch=0.00895] Epoch 436: Train Loss = 0.012184707447886467\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=369, train_loss_step=0.0102, train_loss_epoch=0.0122] Epoch 437: Train Loss = 0.010236990638077259\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, v_num=369, train_loss_step=0.0092, train_loss_epoch=0.0102]Epoch 438: Train Loss = 0.009196564555168152\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=369, train_loss_step=0.0124, train_loss_epoch=0.0092]Epoch 439: Train Loss = 0.012364553287625313\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 13.93it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0124]Epoch 440: Train Loss = 0.010746386833488941\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=369, train_loss_step=0.0103, train_loss_epoch=0.0107]Epoch 441: Train Loss = 0.01031588762998581\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=369, train_loss_step=0.0108, train_loss_epoch=0.0103]Epoch 442: Train Loss = 0.010823381133377552\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=369, train_loss_step=0.00985, train_loss_epoch=0.0108]Epoch 443: Train Loss = 0.009846637956798077\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.00985] Epoch 444: Train Loss = 0.010670305229723454\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=369, train_loss_step=0.00968, train_loss_epoch=0.0107]Epoch 445: Train Loss = 0.00968163926154375\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 16.50it/s, v_num=369, train_loss_step=0.00889, train_loss_epoch=0.00968]Epoch 446: Train Loss = 0.00889297854155302\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=369, train_loss_step=0.0113, train_loss_epoch=0.00889] Epoch 447: Train Loss = 0.011302659288048744\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=369, train_loss_step=0.0114, train_loss_epoch=0.0113] Epoch 448: Train Loss = 0.01137382723391056\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.0114]Epoch 449: Train Loss = 0.01118982769548893\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=369, train_loss_step=0.0088, train_loss_epoch=0.0112]Epoch 450: Train Loss = 0.008801472373306751\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=369, train_loss_step=0.00856, train_loss_epoch=0.0088]Epoch 451: Train Loss = 0.008560163900256157\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.00856] Epoch 452: Train Loss = 0.011184788309037685\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=369, train_loss_step=0.00848, train_loss_epoch=0.0112]Epoch 453: Train Loss = 0.008476406335830688\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=369, train_loss_step=0.0119, train_loss_epoch=0.00848] Epoch 454: Train Loss = 0.01186003815382719\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, v_num=369, train_loss_step=0.0129, train_loss_epoch=0.0119] Epoch 455: Train Loss = 0.012858985923230648\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 12.72it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0129]Epoch 456: Train Loss = 0.011477376334369183\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=369, train_loss_step=0.00814, train_loss_epoch=0.0115]Epoch 457: Train Loss = 0.008139451965689659\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 12.65it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.00814]  Epoch 458: Train Loss = 0.011008343659341335\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=369, train_loss_step=0.0108, train_loss_epoch=0.011] Epoch 459: Train Loss = 0.010770836845040321\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=369, train_loss_step=0.0109, train_loss_epoch=0.0108]Epoch 460: Train Loss = 0.010862722992897034\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=369, train_loss_step=0.00914, train_loss_epoch=0.0109]Epoch 461: Train Loss = 0.00913845282047987\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=369, train_loss_step=0.00996, train_loss_epoch=0.00914]Epoch 462: Train Loss = 0.009964197874069214\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=369, train_loss_step=0.0108, train_loss_epoch=0.00996] Epoch 463: Train Loss = 0.010773537680506706\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=369, train_loss_step=0.0108, train_loss_epoch=0.0108] Epoch 464: Train Loss = 0.010831892490386963\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=369, train_loss_step=0.0096, train_loss_epoch=0.0108]Epoch 465: Train Loss = 0.009604706428945065\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.0096]Epoch 466: Train Loss = 0.011602314189076424\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=369, train_loss_step=0.0105, train_loss_epoch=0.0116]Epoch 467: Train Loss = 0.010466189123690128\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=369, train_loss_step=0.00889, train_loss_epoch=0.0105]Epoch 468: Train Loss = 0.008887999691069126\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=369, train_loss_step=0.00954, train_loss_epoch=0.00889]Epoch 469: Train Loss = 0.009537403471767902\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=369, train_loss_step=0.00845, train_loss_epoch=0.00954]Epoch 470: Train Loss = 0.008450754918158054\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=369, train_loss_step=0.0124, train_loss_epoch=0.00845] Epoch 471: Train Loss = 0.012371579185128212\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=369, train_loss_step=0.0204, train_loss_epoch=0.0124] Epoch 472: Train Loss = 0.02040812000632286\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=369, train_loss_step=0.0116, train_loss_epoch=0.0204]Epoch 473: Train Loss = 0.011590253561735153\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=369, train_loss_step=0.0148, train_loss_epoch=0.0116]Epoch 474: Train Loss = 0.014838390052318573\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.0148]Epoch 475: Train Loss = 0.011247986927628517\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 12.60it/s, v_num=369, train_loss_step=0.0107, train_loss_epoch=0.0112]Epoch 476: Train Loss = 0.010662613436579704\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=369, train_loss_step=0.00878, train_loss_epoch=0.0107]Epoch 477: Train Loss = 0.00878498237580061\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=369, train_loss_step=0.0119, train_loss_epoch=0.00878] Epoch 478: Train Loss = 0.011897861026227474\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=369, train_loss_step=0.00817, train_loss_epoch=0.0119]Epoch 479: Train Loss = 0.008165252394974232\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=369, train_loss_step=0.0112, train_loss_epoch=0.00817] Epoch 480: Train Loss = 0.011224218644201756\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=369, train_loss_step=0.00921, train_loss_epoch=0.0112]Epoch 481: Train Loss = 0.009210528805851936\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 12.67it/s, v_num=369, train_loss_step=0.0106, train_loss_epoch=0.00921] Epoch 482: Train Loss = 0.010622972622513771\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=369, train_loss_step=0.00994, train_loss_epoch=0.0106]Epoch 483: Train Loss = 0.009937924332916737\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=369, train_loss_step=0.00922, train_loss_epoch=0.00994]Epoch 484: Train Loss = 0.009220035746693611\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=369, train_loss_step=0.00895, train_loss_epoch=0.00922]Epoch 485: Train Loss = 0.008950111456215382\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=369, train_loss_step=0.00944, train_loss_epoch=0.00895]Epoch 486: Train Loss = 0.009444855153560638\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=369, train_loss_step=0.0108, train_loss_epoch=0.00944] Epoch 487: Train Loss = 0.010834810324013233\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=369, train_loss_step=0.0126, train_loss_epoch=0.0108] Epoch 488: Train Loss = 0.012560458853840828\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=369, train_loss_step=0.011, train_loss_epoch=0.0126] Epoch 489: Train Loss = 0.010979040525853634\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=369, train_loss_step=0.0103, train_loss_epoch=0.011]Epoch 490: Train Loss = 0.01025135163217783\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=369, train_loss_step=0.00767, train_loss_epoch=0.0103]Epoch 491: Train Loss = 0.007670480292290449\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=369, train_loss_step=0.00833, train_loss_epoch=0.00767]Epoch 492: Train Loss = 0.00832534208893776\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s, v_num=369, train_loss_step=0.00967, train_loss_epoch=0.00833]Epoch 493: Train Loss = 0.009672267362475395\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=369, train_loss_step=0.010, train_loss_epoch=0.00967]  Epoch 494: Train Loss = 0.010000182315707207\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=369, train_loss_step=0.00879, train_loss_epoch=0.010]Epoch 495: Train Loss = 0.008794908411800861\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=369, train_loss_step=0.0111, train_loss_epoch=0.00879] Epoch 496: Train Loss = 0.011116236448287964\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0111] Epoch 497: Train Loss = 0.011535972356796265\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 12.91it/s, v_num=369, train_loss_step=0.00943, train_loss_epoch=0.0115]Epoch 498: Train Loss = 0.009433518163859844\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.00943] Epoch 499: Train Loss = 0.011466899886727333\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0115] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s, v_num=369, train_loss_step=0.0115, train_loss_epoch=0.0115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 15: from 2008-05-12 00:00:00 to 2022-11-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=371, train_loss_step=0.0183]Epoch 0: Train Loss = 0.018326465040445328\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.65it/s, v_num=371, train_loss_step=0.0426, train_loss_epoch=0.0183]Epoch 1: Train Loss = 0.042638637125492096\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.22it/s, v_num=371, train_loss_step=0.0256, train_loss_epoch=0.0426]Epoch 2: Train Loss = 0.02561313845217228\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=371, train_loss_step=0.0172, train_loss_epoch=0.0256]Epoch 3: Train Loss = 0.017205238342285156\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=371, train_loss_step=0.0163, train_loss_epoch=0.0172]Epoch 4: Train Loss = 0.016346724703907967\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=371, train_loss_step=0.0205, train_loss_epoch=0.0163]Epoch 5: Train Loss = 0.02049309015274048\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=371, train_loss_step=0.0179, train_loss_epoch=0.0205]Epoch 6: Train Loss = 0.017866671085357666\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=371, train_loss_step=0.0175, train_loss_epoch=0.0179]Epoch 7: Train Loss = 0.017473813146352768\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s, v_num=371, train_loss_step=0.0119, train_loss_epoch=0.0175]Epoch 8: Train Loss = 0.011864209547638893\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=371, train_loss_step=0.0128, train_loss_epoch=0.0119]Epoch 9: Train Loss = 0.01280425488948822\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=371, train_loss_step=0.0129, train_loss_epoch=0.0128]Epoch 10: Train Loss = 0.012906184419989586\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=371, train_loss_step=0.0155, train_loss_epoch=0.0129]Epoch 11: Train Loss = 0.0154948141425848\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=371, train_loss_step=0.0124, train_loss_epoch=0.0155]Epoch 12: Train Loss = 0.01239230576902628\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=371, train_loss_step=0.0152, train_loss_epoch=0.0124]Epoch 13: Train Loss = 0.015222241170704365\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=371, train_loss_step=0.0144, train_loss_epoch=0.0152]Epoch 14: Train Loss = 0.014436786994338036\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=371, train_loss_step=0.0159, train_loss_epoch=0.0144]Epoch 15: Train Loss = 0.015938453376293182\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.0159]Epoch 16: Train Loss = 0.011451998725533485\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=371, train_loss_step=0.00895, train_loss_epoch=0.0115]Epoch 17: Train Loss = 0.008950884453952312\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=371, train_loss_step=0.0127, train_loss_epoch=0.00895] Epoch 18: Train Loss = 0.01273306179791689\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=371, train_loss_step=0.0124, train_loss_epoch=0.0127] Epoch 19: Train Loss = 0.01237951684743166\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=371, train_loss_step=0.0148, train_loss_epoch=0.0124]Epoch 20: Train Loss = 0.014772601425647736\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=371, train_loss_step=0.0132, train_loss_epoch=0.0148]Epoch 21: Train Loss = 0.013177954591810703\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=371, train_loss_step=0.012, train_loss_epoch=0.0132] Epoch 22: Train Loss = 0.011952751316130161\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.012]Epoch 23: Train Loss = 0.010601403191685677\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=371, train_loss_step=0.00991, train_loss_epoch=0.0106]Epoch 24: Train Loss = 0.009909813292324543\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=371, train_loss_step=0.0107, train_loss_epoch=0.00991] Epoch 25: Train Loss = 0.010718784295022488\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=371, train_loss_step=0.0147, train_loss_epoch=0.0107] Epoch 26: Train Loss = 0.014660967513918877\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=371, train_loss_step=0.0142, train_loss_epoch=0.0147]Epoch 27: Train Loss = 0.014167482033371925\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=371, train_loss_step=0.0127, train_loss_epoch=0.0142]Epoch 28: Train Loss = 0.012714487500488758\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=371, train_loss_step=0.0129, train_loss_epoch=0.0127]Epoch 29: Train Loss = 0.01287276390939951\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=371, train_loss_step=0.011, train_loss_epoch=0.0129] Epoch 30: Train Loss = 0.010981598868966103\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 16.28it/s, v_num=371, train_loss_step=0.0144, train_loss_epoch=0.011]Epoch 31: Train Loss = 0.014421803876757622\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=371, train_loss_step=0.0122, train_loss_epoch=0.0144]Epoch 32: Train Loss = 0.012212089262902737\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=371, train_loss_step=0.0122, train_loss_epoch=0.0122]Epoch 33: Train Loss = 0.012160778045654297\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=371, train_loss_step=0.0132, train_loss_epoch=0.0122]Epoch 34: Train Loss = 0.013154692947864532\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=371, train_loss_step=0.00755, train_loss_epoch=0.0132]Epoch 35: Train Loss = 0.007552646566182375\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, v_num=371, train_loss_step=0.0109, train_loss_epoch=0.00755] Epoch 36: Train Loss = 0.010876834392547607\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=371, train_loss_step=0.0141, train_loss_epoch=0.0109] Epoch 37: Train Loss = 0.014055674895644188\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.0141]Epoch 38: Train Loss = 0.011504233814775944\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.0115]Epoch 39: Train Loss = 0.011387371458113194\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=371, train_loss_step=0.0164, train_loss_epoch=0.0114]Epoch 40: Train Loss = 0.016414225101470947\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=371, train_loss_step=0.0133, train_loss_epoch=0.0164]Epoch 41: Train Loss = 0.013294733129441738\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=371, train_loss_step=0.0113, train_loss_epoch=0.0133]Epoch 42: Train Loss = 0.011271767318248749\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=371, train_loss_step=0.00935, train_loss_epoch=0.0113]Epoch 43: Train Loss = 0.009353489615023136\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s, v_num=371, train_loss_step=0.014, train_loss_epoch=0.00935]  Epoch 44: Train Loss = 0.01397944986820221\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=371, train_loss_step=0.0117, train_loss_epoch=0.014] Epoch 45: Train Loss = 0.011671648360788822\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.0117]Epoch 46: Train Loss = 0.010406159795820713\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=371, train_loss_step=0.0132, train_loss_epoch=0.0104]Epoch 47: Train Loss = 0.013182028196752071\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=371, train_loss_step=0.0133, train_loss_epoch=0.0132]Epoch 48: Train Loss = 0.013336620293557644\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=371, train_loss_step=0.0162, train_loss_epoch=0.0133]Epoch 49: Train Loss = 0.01621399261057377\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=371, train_loss_step=0.0126, train_loss_epoch=0.0162]Epoch 50: Train Loss = 0.012578739784657955\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=371, train_loss_step=0.0127, train_loss_epoch=0.0126]Epoch 51: Train Loss = 0.012747412547469139\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=371, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 52: Train Loss = 0.011950998567044735\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=371, train_loss_step=0.00941, train_loss_epoch=0.012]Epoch 53: Train Loss = 0.009409775957465172\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.00941] Epoch 54: Train Loss = 0.010621903464198112\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.0106] Epoch 55: Train Loss = 0.011420262977480888\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=371, train_loss_step=0.00982, train_loss_epoch=0.0114]Epoch 56: Train Loss = 0.009824148379266262\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=371, train_loss_step=0.0137, train_loss_epoch=0.00982] Epoch 57: Train Loss = 0.013671406544744968\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=371, train_loss_step=0.0137, train_loss_epoch=0.0137] Epoch 58: Train Loss = 0.013742205686867237\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.0137]Epoch 59: Train Loss = 0.011113488115370274\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=371, train_loss_step=0.00992, train_loss_epoch=0.0111]Epoch 60: Train Loss = 0.00991973839700222\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.00992] Epoch 61: Train Loss = 0.01044908631592989\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, v_num=371, train_loss_step=0.0125, train_loss_epoch=0.0104] Epoch 62: Train Loss = 0.01250547170639038\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=371, train_loss_step=0.00944, train_loss_epoch=0.0125]Epoch 63: Train Loss = 0.009438665583729744\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=371, train_loss_step=0.00841, train_loss_epoch=0.00944]Epoch 64: Train Loss = 0.008407310582697392\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.00841] Epoch 65: Train Loss = 0.010323395021259785\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, v_num=371, train_loss_step=0.00913, train_loss_epoch=0.0103]Epoch 66: Train Loss = 0.009133418090641499\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=371, train_loss_step=0.00696, train_loss_epoch=0.00913]Epoch 67: Train Loss = 0.006961473263800144\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=371, train_loss_step=0.0125, train_loss_epoch=0.00696] Epoch 68: Train Loss = 0.01252610981464386\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=371, train_loss_step=0.0102, train_loss_epoch=0.0125] Epoch 69: Train Loss = 0.010224439203739166\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=371, train_loss_step=0.00974, train_loss_epoch=0.0102]Epoch 70: Train Loss = 0.00974427629262209\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=371, train_loss_step=0.00972, train_loss_epoch=0.00974]Epoch 71: Train Loss = 0.009718277491629124\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=371, train_loss_step=0.0102, train_loss_epoch=0.00972] Epoch 72: Train Loss = 0.010211065411567688\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.0102] Epoch 73: Train Loss = 0.011546848341822624\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=371, train_loss_step=0.0084, train_loss_epoch=0.0115]Epoch 74: Train Loss = 0.008400498889386654\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=371, train_loss_step=0.0194, train_loss_epoch=0.0084]Epoch 75: Train Loss = 0.019420994445681572\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 16.10it/s, v_num=371, train_loss_step=0.0119, train_loss_epoch=0.0194]Epoch 76: Train Loss = 0.01192493736743927\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=371, train_loss_step=0.0138, train_loss_epoch=0.0119]Epoch 77: Train Loss = 0.013821696862578392\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.0138]Epoch 78: Train Loss = 0.011200065724551678\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 16.26it/s, v_num=371, train_loss_step=0.0107, train_loss_epoch=0.0112]Epoch 79: Train Loss = 0.010738782584667206\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=371, train_loss_step=0.0124, train_loss_epoch=0.0107]Epoch 80: Train Loss = 0.01243301946669817\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=371, train_loss_step=0.0102, train_loss_epoch=0.0124]Epoch 81: Train Loss = 0.010177663527429104\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.0102]Epoch 82: Train Loss = 0.01105708722025156\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.0111]Epoch 83: Train Loss = 0.011546315625309944\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=371, train_loss_step=0.0144, train_loss_epoch=0.0115]Epoch 84: Train Loss = 0.014445039443671703\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=371, train_loss_step=0.0131, train_loss_epoch=0.0144]Epoch 85: Train Loss = 0.013137665577232838\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=371, train_loss_step=0.00962, train_loss_epoch=0.0131]Epoch 86: Train Loss = 0.009615907445549965\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=371, train_loss_step=0.00809, train_loss_epoch=0.00962]Epoch 87: Train Loss = 0.008088367059826851\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=371, train_loss_step=0.0117, train_loss_epoch=0.00809] Epoch 88: Train Loss = 0.011737396009266376\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=371, train_loss_step=0.00941, train_loss_epoch=0.0117]Epoch 89: Train Loss = 0.009407694451510906\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=371, train_loss_step=0.0132, train_loss_epoch=0.00941] Epoch 90: Train Loss = 0.013244792819023132\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=371, train_loss_step=0.0129, train_loss_epoch=0.0132] Epoch 91: Train Loss = 0.012854248285293579\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=371, train_loss_step=0.0128, train_loss_epoch=0.0129]Epoch 92: Train Loss = 0.012800464406609535\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 11.47it/s, v_num=371, train_loss_step=0.0108, train_loss_epoch=0.0128]Epoch 93: Train Loss = 0.010835324414074421\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.0108]Epoch 94: Train Loss = 0.011441553942859173\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=371, train_loss_step=0.0136, train_loss_epoch=0.0114]Epoch 95: Train Loss = 0.013566275127232075\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=371, train_loss_step=0.0134, train_loss_epoch=0.0136]Epoch 96: Train Loss = 0.01340582687407732\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=371, train_loss_step=0.0142, train_loss_epoch=0.0134]Epoch 97: Train Loss = 0.014226557686924934\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=371, train_loss_step=0.012, train_loss_epoch=0.0142] Epoch 98: Train Loss = 0.011985077522695065\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=371, train_loss_step=0.0102, train_loss_epoch=0.012]Epoch 99: Train Loss = 0.010189409367740154\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=371, train_loss_step=0.0094, train_loss_epoch=0.0102]Epoch 100: Train Loss = 0.009401223622262478\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.0094]Epoch 101: Train Loss = 0.010648505762219429\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=371, train_loss_step=0.0128, train_loss_epoch=0.0106]Epoch 102: Train Loss = 0.012792815454304218\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.0128]Epoch 103: Train Loss = 0.010320009663701057\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=371, train_loss_step=0.0098, train_loss_epoch=0.0103]Epoch 104: Train Loss = 0.009802139364182949\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=371, train_loss_step=0.0096, train_loss_epoch=0.0098]Epoch 105: Train Loss = 0.009602213278412819\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=371, train_loss_step=0.00928, train_loss_epoch=0.0096]Epoch 106: Train Loss = 0.009281442500650883\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s, v_num=371, train_loss_step=0.0125, train_loss_epoch=0.00928] Epoch 107: Train Loss = 0.012510712258517742\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=371, train_loss_step=0.00767, train_loss_epoch=0.0125]Epoch 108: Train Loss = 0.00767436483874917\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=371, train_loss_step=0.00933, train_loss_epoch=0.00767]Epoch 109: Train Loss = 0.00932870153337717\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=371, train_loss_step=0.00975, train_loss_epoch=0.00933]Epoch 110: Train Loss = 0.009746259078383446\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=371, train_loss_step=0.00835, train_loss_epoch=0.00975]Epoch 111: Train Loss = 0.008350467309355736\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=371, train_loss_step=0.00911, train_loss_epoch=0.00835]Epoch 112: Train Loss = 0.009108932688832283\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.00911] Epoch 113: Train Loss = 0.010364175774157047\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=371, train_loss_step=0.0091, train_loss_epoch=0.0104] Epoch 114: Train Loss = 0.009103749878704548\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.0091]Epoch 115: Train Loss = 0.011377336457371712\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s, v_num=371, train_loss_step=0.012, train_loss_epoch=0.0114] Epoch 116: Train Loss = 0.012011194601655006\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s, v_num=371, train_loss_step=0.014, train_loss_epoch=0.012] Epoch 117: Train Loss = 0.013950193300843239\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.014]Epoch 118: Train Loss = 0.011358638294041157\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, v_num=371, train_loss_step=0.021, train_loss_epoch=0.0114] Epoch 119: Train Loss = 0.021033313125371933\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=371, train_loss_step=0.0116, train_loss_epoch=0.021]Epoch 120: Train Loss = 0.011605004779994488\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=371, train_loss_step=0.0133, train_loss_epoch=0.0116]Epoch 121: Train Loss = 0.013346725143492222\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=371, train_loss_step=0.0108, train_loss_epoch=0.0133]Epoch 122: Train Loss = 0.010795289650559425\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.0108]Epoch 123: Train Loss = 0.0104113994166255\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=371, train_loss_step=0.0122, train_loss_epoch=0.0104]Epoch 124: Train Loss = 0.012157821096479893\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=371, train_loss_step=0.00974, train_loss_epoch=0.0122]Epoch 125: Train Loss = 0.009740973822772503\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=371, train_loss_step=0.00804, train_loss_epoch=0.00974]Epoch 126: Train Loss = 0.008036377839744091\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=371, train_loss_step=0.014, train_loss_epoch=0.00804]  Epoch 127: Train Loss = 0.014024310745298862\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.014] Epoch 128: Train Loss = 0.011057062074542046\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=371, train_loss_step=0.0121, train_loss_epoch=0.0111]Epoch 129: Train Loss = 0.01214614324271679\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=371, train_loss_step=0.0122, train_loss_epoch=0.0121]Epoch 130: Train Loss = 0.012235830537974834\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=371, train_loss_step=0.0107, train_loss_epoch=0.0122]Epoch 131: Train Loss = 0.010652703233063221\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=371, train_loss_step=0.00999, train_loss_epoch=0.0107]Epoch 132: Train Loss = 0.009993081912398338\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.00999] Epoch 133: Train Loss = 0.011195600032806396\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=371, train_loss_step=0.0127, train_loss_epoch=0.0112] Epoch 134: Train Loss = 0.012660881504416466\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 13.60it/s, v_num=371, train_loss_step=0.0122, train_loss_epoch=0.0127]Epoch 135: Train Loss = 0.012216593138873577\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 13.61it/s, v_num=371, train_loss_step=0.00825, train_loss_epoch=0.0122]Epoch 136: Train Loss = 0.008247298188507557\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=371, train_loss_step=0.0125, train_loss_epoch=0.00825] Epoch 137: Train Loss = 0.01250919047743082\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, v_num=371, train_loss_step=0.0108, train_loss_epoch=0.0125] Epoch 138: Train Loss = 0.010764554142951965\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=371, train_loss_step=0.0132, train_loss_epoch=0.0108]Epoch 139: Train Loss = 0.013226785697042942\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.0132]Epoch 140: Train Loss = 0.011527977883815765\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=371, train_loss_step=0.00962, train_loss_epoch=0.0115]Epoch 141: Train Loss = 0.009621412493288517\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=371, train_loss_step=0.00904, train_loss_epoch=0.00962]Epoch 142: Train Loss = 0.00904409121721983\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=371, train_loss_step=0.0116, train_loss_epoch=0.00904] Epoch 143: Train Loss = 0.011554577387869358\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=371, train_loss_step=0.00906, train_loss_epoch=0.0116]Epoch 144: Train Loss = 0.009064284153282642\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=371, train_loss_step=0.0119, train_loss_epoch=0.00906] Epoch 145: Train Loss = 0.011928446590900421\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.0119] Epoch 146: Train Loss = 0.01011314895004034\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=371, train_loss_step=0.0118, train_loss_epoch=0.0101]Epoch 147: Train Loss = 0.011764108203351498\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.0118]Epoch 148: Train Loss = 0.010622058995068073\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=371, train_loss_step=0.0151, train_loss_epoch=0.0106]Epoch 149: Train Loss = 0.015110963024199009\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=371, train_loss_step=0.0122, train_loss_epoch=0.0151]Epoch 150: Train Loss = 0.012201513163745403\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.0122]Epoch 151: Train Loss = 0.01011462789028883\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=371, train_loss_step=0.0132, train_loss_epoch=0.0101]Epoch 152: Train Loss = 0.013225020840764046\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=371, train_loss_step=0.0167, train_loss_epoch=0.0132]Epoch 153: Train Loss = 0.01668342761695385\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.0167]Epoch 154: Train Loss = 0.01032271422445774\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=371, train_loss_step=0.00905, train_loss_epoch=0.0103]Epoch 155: Train Loss = 0.009054998867213726\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.00905] Epoch 156: Train Loss = 0.011093070730566978\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 13.50it/s, v_num=371, train_loss_step=0.0193, train_loss_epoch=0.0111] Epoch 157: Train Loss = 0.019276658073067665\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=371, train_loss_step=0.0159, train_loss_epoch=0.0193]Epoch 158: Train Loss = 0.015863126143813133\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=371, train_loss_step=0.0123, train_loss_epoch=0.0159]Epoch 159: Train Loss = 0.012327054515480995\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=371, train_loss_step=0.00837, train_loss_epoch=0.0123]Epoch 160: Train Loss = 0.008371352218091488\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, v_num=371, train_loss_step=0.0091, train_loss_epoch=0.00837] Epoch 161: Train Loss = 0.009103002957999706\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=371, train_loss_step=0.00939, train_loss_epoch=0.0091]Epoch 162: Train Loss = 0.009394178166985512\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=371, train_loss_step=0.011, train_loss_epoch=0.00939]  Epoch 163: Train Loss = 0.011048541404306889\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=371, train_loss_step=0.0109, train_loss_epoch=0.011] Epoch 164: Train Loss = 0.010893923230469227\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=371, train_loss_step=0.00858, train_loss_epoch=0.0109]Epoch 165: Train Loss = 0.008583277463912964\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.00858] Epoch 166: Train Loss = 0.011407369747757912\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=371, train_loss_step=0.0141, train_loss_epoch=0.0114] Epoch 167: Train Loss = 0.014145812951028347\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=371, train_loss_step=0.00932, train_loss_epoch=0.0141]Epoch 168: Train Loss = 0.00931880809366703\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=371, train_loss_step=0.00912, train_loss_epoch=0.00932]Epoch 169: Train Loss = 0.009116807952523232\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=371, train_loss_step=0.00936, train_loss_epoch=0.00912]Epoch 170: Train Loss = 0.009358441457152367\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=371, train_loss_step=0.014, train_loss_epoch=0.00936]  Epoch 171: Train Loss = 0.01398517470806837\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=371, train_loss_step=0.0182, train_loss_epoch=0.014] Epoch 172: Train Loss = 0.01817556843161583\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=371, train_loss_step=0.0152, train_loss_epoch=0.0182]Epoch 173: Train Loss = 0.015171410515904427\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=371, train_loss_step=0.0088, train_loss_epoch=0.0152]Epoch 174: Train Loss = 0.008800909854471684\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=371, train_loss_step=0.0105, train_loss_epoch=0.0088]Epoch 175: Train Loss = 0.010490350425243378\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, v_num=371, train_loss_step=0.0113, train_loss_epoch=0.0105]Epoch 176: Train Loss = 0.01126307062804699\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=371, train_loss_step=0.00948, train_loss_epoch=0.0113]Epoch 177: Train Loss = 0.009481891058385372\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, v_num=371, train_loss_step=0.0116, train_loss_epoch=0.00948] Epoch 178: Train Loss = 0.011564342305064201\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=371, train_loss_step=0.00908, train_loss_epoch=0.0116]Epoch 179: Train Loss = 0.009078358300030231\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=371, train_loss_step=0.00923, train_loss_epoch=0.00908]Epoch 180: Train Loss = 0.00922557432204485\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 17.43it/s, v_num=371, train_loss_step=0.0137, train_loss_epoch=0.00923] Epoch 181: Train Loss = 0.013666525483131409\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.0137] Epoch 182: Train Loss = 0.010611497797071934\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=371, train_loss_step=0.00743, train_loss_epoch=0.0106]Epoch 183: Train Loss = 0.007428978569805622\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=371, train_loss_step=0.00715, train_loss_epoch=0.00743]Epoch 184: Train Loss = 0.007153952028602362\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=371, train_loss_step=0.00774, train_loss_epoch=0.00715]Epoch 185: Train Loss = 0.007737009786069393\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=371, train_loss_step=0.00971, train_loss_epoch=0.00774]Epoch 186: Train Loss = 0.00971145462244749\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=371, train_loss_step=0.00838, train_loss_epoch=0.00971]Epoch 187: Train Loss = 0.008384368382394314\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=371, train_loss_step=0.00938, train_loss_epoch=0.00838]Epoch 188: Train Loss = 0.009384357370436192\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=371, train_loss_step=0.00929, train_loss_epoch=0.00938]Epoch 189: Train Loss = 0.00928554404526949\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=371, train_loss_step=0.0129, train_loss_epoch=0.00929] Epoch 190: Train Loss = 0.012867982499301434\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=371, train_loss_step=0.0118, train_loss_epoch=0.0129] Epoch 191: Train Loss = 0.011845535598695278\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=371, train_loss_step=0.0125, train_loss_epoch=0.0118]Epoch 192: Train Loss = 0.012462451122701168\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=371, train_loss_step=0.0113, train_loss_epoch=0.0125]Epoch 193: Train Loss = 0.011267864145338535\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=371, train_loss_step=0.013, train_loss_epoch=0.0113] Epoch 194: Train Loss = 0.012991560623049736\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=371, train_loss_step=0.0154, train_loss_epoch=0.013]Epoch 195: Train Loss = 0.015447859652340412\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.0154]Epoch 196: Train Loss = 0.011464131996035576\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.0115]Epoch 197: Train Loss = 0.010293214581906796\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s, v_num=371, train_loss_step=0.0105, train_loss_epoch=0.0103]Epoch 198: Train Loss = 0.010504232719540596\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 11.40it/s, v_num=371, train_loss_step=0.0113, train_loss_epoch=0.0105]Epoch 199: Train Loss = 0.01128039788454771\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=371, train_loss_step=0.0095, train_loss_epoch=0.0113]Epoch 200: Train Loss = 0.009504290297627449\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=371, train_loss_step=0.012, train_loss_epoch=0.0095] Epoch 201: Train Loss = 0.012008067220449448\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.012]Epoch 202: Train Loss = 0.010262057185173035\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, v_num=371, train_loss_step=0.00986, train_loss_epoch=0.0103]Epoch 203: Train Loss = 0.009861945174634457\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=371, train_loss_step=0.00997, train_loss_epoch=0.00986]Epoch 204: Train Loss = 0.009973841719329357\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=371, train_loss_step=0.00844, train_loss_epoch=0.00997]Epoch 205: Train Loss = 0.008443254046142101\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.00844] Epoch 206: Train Loss = 0.011052639223635197\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=371, train_loss_step=0.0108, train_loss_epoch=0.0111] Epoch 207: Train Loss = 0.010809834115207195\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=371, train_loss_step=0.011, train_loss_epoch=0.0108] Epoch 208: Train Loss = 0.010997439734637737\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=371, train_loss_step=0.00877, train_loss_epoch=0.011]Epoch 209: Train Loss = 0.008769079111516476\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=371, train_loss_step=0.00879, train_loss_epoch=0.00877]Epoch 210: Train Loss = 0.008794943802058697\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=371, train_loss_step=0.00698, train_loss_epoch=0.00879]Epoch 211: Train Loss = 0.006982035934925079\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=371, train_loss_step=0.0107, train_loss_epoch=0.00698] Epoch 212: Train Loss = 0.010684498585760593\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=371, train_loss_step=0.00867, train_loss_epoch=0.0107]Epoch 213: Train Loss = 0.008673573844134808\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=371, train_loss_step=0.00793, train_loss_epoch=0.00867]Epoch 214: Train Loss = 0.00793388020247221\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=371, train_loss_step=0.00908, train_loss_epoch=0.00793]Epoch 215: Train Loss = 0.009080715477466583\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=371, train_loss_step=0.00784, train_loss_epoch=0.00908]Epoch 216: Train Loss = 0.007837934419512749\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=371, train_loss_step=0.00819, train_loss_epoch=0.00784]Epoch 217: Train Loss = 0.008194295689463615\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=371, train_loss_step=0.0118, train_loss_epoch=0.00819] Epoch 218: Train Loss = 0.011811934411525726\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.0118] Epoch 219: Train Loss = 0.010426519438624382\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=371, train_loss_step=0.00909, train_loss_epoch=0.0104]Epoch 220: Train Loss = 0.009087997488677502\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=371, train_loss_step=0.0108, train_loss_epoch=0.00909] Epoch 221: Train Loss = 0.010770214721560478\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=371, train_loss_step=0.00921, train_loss_epoch=0.0108]Epoch 222: Train Loss = 0.00921015627682209\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 16.02it/s, v_num=371, train_loss_step=0.011, train_loss_epoch=0.00921]  Epoch 223: Train Loss = 0.010965004563331604\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=371, train_loss_step=0.0084, train_loss_epoch=0.011] Epoch 224: Train Loss = 0.00840231403708458\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=371, train_loss_step=0.00992, train_loss_epoch=0.0084]Epoch 225: Train Loss = 0.009918917901813984\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=371, train_loss_step=0.0116, train_loss_epoch=0.00992] Epoch 226: Train Loss = 0.011596573516726494\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=371, train_loss_step=0.0113, train_loss_epoch=0.0116] Epoch 227: Train Loss = 0.011341659352183342\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=371, train_loss_step=0.0135, train_loss_epoch=0.0113]Epoch 228: Train Loss = 0.013473039492964745\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=371, train_loss_step=0.0139, train_loss_epoch=0.0135]Epoch 229: Train Loss = 0.013910393230617046\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.0139]Epoch 230: Train Loss = 0.010273211635649204\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 13.77it/s, v_num=371, train_loss_step=0.0124, train_loss_epoch=0.0103]Epoch 231: Train Loss = 0.012443342246115208\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=371, train_loss_step=0.00931, train_loss_epoch=0.0124]Epoch 232: Train Loss = 0.009313183836638927\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=371, train_loss_step=0.0099, train_loss_epoch=0.00931] Epoch 233: Train Loss = 0.009900026023387909\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.0099] Epoch 234: Train Loss = 0.011466671712696552\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=371, train_loss_step=0.00919, train_loss_epoch=0.0115]Epoch 235: Train Loss = 0.009187187068164349\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=371, train_loss_step=0.00991, train_loss_epoch=0.00919]Epoch 236: Train Loss = 0.009905671700835228\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=371, train_loss_step=0.0121, train_loss_epoch=0.00991] Epoch 237: Train Loss = 0.012122676707804203\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=371, train_loss_step=0.00945, train_loss_epoch=0.0121]Epoch 238: Train Loss = 0.009446780197322369\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.00945] Epoch 239: Train Loss = 0.010337313637137413\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.0103] Epoch 240: Train Loss = 0.0101171238347888\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=371, train_loss_step=0.00875, train_loss_epoch=0.0101]Epoch 241: Train Loss = 0.008752236142754555\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=371, train_loss_step=0.00889, train_loss_epoch=0.00875]Epoch 242: Train Loss = 0.008885958231985569\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=371, train_loss_step=0.0127, train_loss_epoch=0.00889] Epoch 243: Train Loss = 0.012731046415865421\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=371, train_loss_step=0.00986, train_loss_epoch=0.0127]Epoch 244: Train Loss = 0.009863344952464104\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=371, train_loss_step=0.00916, train_loss_epoch=0.00986]Epoch 245: Train Loss = 0.00916301179677248\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=371, train_loss_step=0.00946, train_loss_epoch=0.00916]Epoch 246: Train Loss = 0.009460133500397205\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.00946] Epoch 247: Train Loss = 0.010418289341032505\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=371, train_loss_step=0.00808, train_loss_epoch=0.0104]Epoch 248: Train Loss = 0.008078576065599918\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.00808] Epoch 249: Train Loss = 0.011423669755458832\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=371, train_loss_step=0.00893, train_loss_epoch=0.0114]Epoch 250: Train Loss = 0.008925464004278183\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=371, train_loss_step=0.00876, train_loss_epoch=0.00893]Epoch 251: Train Loss = 0.008757732808589935\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=371, train_loss_step=0.0109, train_loss_epoch=0.00876] Epoch 252: Train Loss = 0.010889687575399876\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.0109] Epoch 253: Train Loss = 0.011445088312029839\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=371, train_loss_step=0.00986, train_loss_epoch=0.0114]Epoch 254: Train Loss = 0.009859303943812847\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=371, train_loss_step=0.0127, train_loss_epoch=0.00986] Epoch 255: Train Loss = 0.012662501074373722\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=371, train_loss_step=0.00815, train_loss_epoch=0.0127]Epoch 256: Train Loss = 0.008154056034982204\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s, v_num=371, train_loss_step=0.0122, train_loss_epoch=0.00815] Epoch 257: Train Loss = 0.01215885579586029\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.0122] Epoch 258: Train Loss = 0.011238383129239082\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=371, train_loss_step=0.00929, train_loss_epoch=0.0112]Epoch 259: Train Loss = 0.009287779219448566\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=371, train_loss_step=0.0113, train_loss_epoch=0.00929] Epoch 260: Train Loss = 0.011250516399741173\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=371, train_loss_step=0.00939, train_loss_epoch=0.0113]Epoch 261: Train Loss = 0.009385919198393822\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=371, train_loss_step=0.0121, train_loss_epoch=0.00939] Epoch 262: Train Loss = 0.012102169916033745\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.0121] Epoch 263: Train Loss = 0.011522349901497364\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.0115]Epoch 264: Train Loss = 0.010589123703539371\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=371, train_loss_step=0.00851, train_loss_epoch=0.0106]Epoch 265: Train Loss = 0.008509424515068531\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.00851] Epoch 266: Train Loss = 0.010093152523040771\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=371, train_loss_step=0.0131, train_loss_epoch=0.0101] Epoch 267: Train Loss = 0.013101114891469479\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=371, train_loss_step=0.010, train_loss_epoch=0.0131] Epoch 268: Train Loss = 0.010032596997916698\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, v_num=371, train_loss_step=0.00731, train_loss_epoch=0.010]Epoch 269: Train Loss = 0.007314740680158138\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=371, train_loss_step=0.0141, train_loss_epoch=0.00731] Epoch 270: Train Loss = 0.014146914705634117\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=371, train_loss_step=0.00837, train_loss_epoch=0.0141]Epoch 271: Train Loss = 0.008371335454285145\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=371, train_loss_step=0.0105, train_loss_epoch=0.00837] Epoch 272: Train Loss = 0.010469900444149971\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, v_num=371, train_loss_step=0.0124, train_loss_epoch=0.0105] Epoch 273: Train Loss = 0.012418306432664394\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=371, train_loss_step=0.0122, train_loss_epoch=0.0124]Epoch 274: Train Loss = 0.012210938148200512\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=371, train_loss_step=0.00884, train_loss_epoch=0.0122]Epoch 275: Train Loss = 0.008843431249260902\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=371, train_loss_step=0.0118, train_loss_epoch=0.00884] Epoch 276: Train Loss = 0.011771777644753456\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.0118] Epoch 277: Train Loss = 0.011180267669260502\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.0112]Epoch 278: Train Loss = 0.011211441829800606\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=371, train_loss_step=0.0113, train_loss_epoch=0.0112]Epoch 279: Train Loss = 0.011268903501331806\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=371, train_loss_step=0.00925, train_loss_epoch=0.0113]Epoch 280: Train Loss = 0.009250602684915066\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=371, train_loss_step=0.0113, train_loss_epoch=0.00925] Epoch 281: Train Loss = 0.01133774220943451\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=371, train_loss_step=0.0117, train_loss_epoch=0.0113] Epoch 282: Train Loss = 0.011724025011062622\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=371, train_loss_step=0.00833, train_loss_epoch=0.0117]Epoch 283: Train Loss = 0.008329465985298157\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=371, train_loss_step=0.0113, train_loss_epoch=0.00833] Epoch 284: Train Loss = 0.011346012353897095\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.0113] Epoch 285: Train Loss = 0.010649247094988823\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=371, train_loss_step=0.00948, train_loss_epoch=0.0106]Epoch 286: Train Loss = 0.009483152069151402\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=371, train_loss_step=0.00816, train_loss_epoch=0.00948]Epoch 287: Train Loss = 0.008163833059370518\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=371, train_loss_step=0.00909, train_loss_epoch=0.00816]Epoch 288: Train Loss = 0.00908621959388256\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=371, train_loss_step=0.0118, train_loss_epoch=0.00909] Epoch 289: Train Loss = 0.011836377903819084\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=371, train_loss_step=0.0116, train_loss_epoch=0.0118] Epoch 290: Train Loss = 0.01164613664150238\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=371, train_loss_step=0.00842, train_loss_epoch=0.0116]Epoch 291: Train Loss = 0.00842453446239233\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=371, train_loss_step=0.0109, train_loss_epoch=0.00842] Epoch 292: Train Loss = 0.01091221533715725\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=371, train_loss_step=0.00921, train_loss_epoch=0.0109]Epoch 293: Train Loss = 0.009213658981025219\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=371, train_loss_step=0.0117, train_loss_epoch=0.00921] Epoch 294: Train Loss = 0.011651886627078056\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=371, train_loss_step=0.00957, train_loss_epoch=0.0117]Epoch 295: Train Loss = 0.00956664327532053\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s, v_num=371, train_loss_step=0.009, train_loss_epoch=0.00957]  Epoch 296: Train Loss = 0.00899595208466053\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 11.12it/s, v_num=371, train_loss_step=0.0151, train_loss_epoch=0.009] Epoch 297: Train Loss = 0.015061818063259125\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.0151]Epoch 298: Train Loss = 0.010619605891406536\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 13.49it/s, v_num=371, train_loss_step=0.0128, train_loss_epoch=0.0106]Epoch 299: Train Loss = 0.012780800461769104\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 12.56it/s, v_num=371, train_loss_step=0.00896, train_loss_epoch=0.0128]Epoch 300: Train Loss = 0.008960078470408916\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=371, train_loss_step=0.00866, train_loss_epoch=0.00896]Epoch 301: Train Loss = 0.008664690889418125\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=371, train_loss_step=0.0118, train_loss_epoch=0.00866] Epoch 302: Train Loss = 0.011786079965531826\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.0118] Epoch 303: Train Loss = 0.011389392428100109\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=371, train_loss_step=0.0124, train_loss_epoch=0.0114]Epoch 304: Train Loss = 0.012378108687698841\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=371, train_loss_step=0.00911, train_loss_epoch=0.0124]Epoch 305: Train Loss = 0.009108343161642551\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=371, train_loss_step=0.00859, train_loss_epoch=0.00911]Epoch 306: Train Loss = 0.008589199744164944\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=371, train_loss_step=0.0123, train_loss_epoch=0.00859] Epoch 307: Train Loss = 0.01226266473531723\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.0123] Epoch 308: Train Loss = 0.010570058599114418\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=371, train_loss_step=0.0116, train_loss_epoch=0.0106]Epoch 309: Train Loss = 0.011619189754128456\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=371, train_loss_step=0.0116, train_loss_epoch=0.0116]Epoch 310: Train Loss = 0.011647047474980354\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=371, train_loss_step=0.00883, train_loss_epoch=0.0116]Epoch 311: Train Loss = 0.008830654434859753\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=371, train_loss_step=0.00934, train_loss_epoch=0.00883]Epoch 312: Train Loss = 0.009344273246824741\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=371, train_loss_step=0.0108, train_loss_epoch=0.00934] Epoch 313: Train Loss = 0.010779925622045994\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=371, train_loss_step=0.0128, train_loss_epoch=0.0108] Epoch 314: Train Loss = 0.012834032066166401\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=371, train_loss_step=0.0137, train_loss_epoch=0.0128]Epoch 315: Train Loss = 0.013686896301805973\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.0137]Epoch 316: Train Loss = 0.011059342883527279\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=371, train_loss_step=0.00974, train_loss_epoch=0.0111]Epoch 317: Train Loss = 0.009737388230860233\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=371, train_loss_step=0.00867, train_loss_epoch=0.00974]Epoch 318: Train Loss = 0.008668418042361736\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=371, train_loss_step=0.0122, train_loss_epoch=0.00867] Epoch 319: Train Loss = 0.012220611795783043\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.0122] Epoch 320: Train Loss = 0.011484409682452679\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=371, train_loss_step=0.00779, train_loss_epoch=0.0115]Epoch 321: Train Loss = 0.007792662363499403\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=371, train_loss_step=0.0134, train_loss_epoch=0.00779] Epoch 322: Train Loss = 0.01341278851032257\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=371, train_loss_step=0.0151, train_loss_epoch=0.0134] Epoch 323: Train Loss = 0.015094829723238945\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=371, train_loss_step=0.00966, train_loss_epoch=0.0151]Epoch 324: Train Loss = 0.00965550635010004\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=371, train_loss_step=0.00945, train_loss_epoch=0.00966]Epoch 325: Train Loss = 0.009452862665057182\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=371, train_loss_step=0.00921, train_loss_epoch=0.00945]Epoch 326: Train Loss = 0.00921088270843029\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.00921] Epoch 327: Train Loss = 0.01009656023234129\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.0101] Epoch 328: Train Loss = 0.010418054647743702\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=371, train_loss_step=0.0135, train_loss_epoch=0.0104]Epoch 329: Train Loss = 0.013531332835555077\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.0135]Epoch 330: Train Loss = 0.01116862427443266\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=371, train_loss_step=0.00872, train_loss_epoch=0.0112]Epoch 331: Train Loss = 0.008722682483494282\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.00872] Epoch 332: Train Loss = 0.010269568301737309\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=371, train_loss_step=0.00949, train_loss_epoch=0.0103]Epoch 333: Train Loss = 0.009492630138993263\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=371, train_loss_step=0.00857, train_loss_epoch=0.00949]Epoch 334: Train Loss = 0.00856989435851574\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=371, train_loss_step=0.00905, train_loss_epoch=0.00857]Epoch 335: Train Loss = 0.009048967622220516\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.00905] Epoch 336: Train Loss = 0.01116579957306385\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=371, train_loss_step=0.0092, train_loss_epoch=0.0112] Epoch 337: Train Loss = 0.009199804626405239\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=371, train_loss_step=0.00939, train_loss_epoch=0.0092]Epoch 338: Train Loss = 0.009387882426381111\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 13.76it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.00939] Epoch 339: Train Loss = 0.011185849085450172\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 11.21it/s, v_num=371, train_loss_step=0.00951, train_loss_epoch=0.0112]Epoch 340: Train Loss = 0.009508820250630379\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=371, train_loss_step=0.0127, train_loss_epoch=0.00951] Epoch 341: Train Loss = 0.012698674574494362\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=371, train_loss_step=0.00773, train_loss_epoch=0.0127]Epoch 342: Train Loss = 0.00773431034758687\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=371, train_loss_step=0.011, train_loss_epoch=0.00773]  Epoch 343: Train Loss = 0.010982834734022617\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=371, train_loss_step=0.0123, train_loss_epoch=0.011] Epoch 344: Train Loss = 0.012332295067608356\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=371, train_loss_step=0.00875, train_loss_epoch=0.0123]Epoch 345: Train Loss = 0.00874782633036375\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=371, train_loss_step=0.0146, train_loss_epoch=0.00875] Epoch 346: Train Loss = 0.01457955688238144\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=371, train_loss_step=0.0138, train_loss_epoch=0.0146] Epoch 347: Train Loss = 0.013830979354679585\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=371, train_loss_step=0.00998, train_loss_epoch=0.0138]Epoch 348: Train Loss = 0.009977123700082302\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.00998] Epoch 349: Train Loss = 0.011122511699795723\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=371, train_loss_step=0.0105, train_loss_epoch=0.0111] Epoch 350: Train Loss = 0.010471790097653866\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=371, train_loss_step=0.00973, train_loss_epoch=0.0105]Epoch 351: Train Loss = 0.009725905954837799\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s, v_num=371, train_loss_step=0.00985, train_loss_epoch=0.00973]Epoch 352: Train Loss = 0.009848472662270069\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.00985] Epoch 353: Train Loss = 0.010129292495548725\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=371, train_loss_step=0.00664, train_loss_epoch=0.0101]Epoch 354: Train Loss = 0.006639301776885986\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=371, train_loss_step=0.0081, train_loss_epoch=0.00664] Epoch 355: Train Loss = 0.008099670521914959\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=371, train_loss_step=0.00933, train_loss_epoch=0.0081]Epoch 356: Train Loss = 0.009327182546257973\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=371, train_loss_step=0.00964, train_loss_epoch=0.00933]Epoch 357: Train Loss = 0.009639029391109943\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=371, train_loss_step=0.00822, train_loss_epoch=0.00964]Epoch 358: Train Loss = 0.00822268333286047\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=371, train_loss_step=0.00997, train_loss_epoch=0.00822]Epoch 359: Train Loss = 0.00996539555490017\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=371, train_loss_step=0.00958, train_loss_epoch=0.00997]Epoch 360: Train Loss = 0.009577459655702114\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=371, train_loss_step=0.00856, train_loss_epoch=0.00958]Epoch 361: Train Loss = 0.008562463335692883\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=371, train_loss_step=0.00937, train_loss_epoch=0.00856]Epoch 362: Train Loss = 0.009368588216602802\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=371, train_loss_step=0.00917, train_loss_epoch=0.00937]Epoch 363: Train Loss = 0.00917138997465372\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s, v_num=371, train_loss_step=0.00946, train_loss_epoch=0.00917]Epoch 364: Train Loss = 0.009455603547394276\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=371, train_loss_step=0.00789, train_loss_epoch=0.00946]Epoch 365: Train Loss = 0.007891201414167881\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=371, train_loss_step=0.0119, train_loss_epoch=0.00789] Epoch 366: Train Loss = 0.011932737194001675\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.0119] Epoch 367: Train Loss = 0.011431770399212837\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.0114]Epoch 368: Train Loss = 0.011236650869250298\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.0112]Epoch 369: Train Loss = 0.011060436256229877\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, v_num=371, train_loss_step=0.00931, train_loss_epoch=0.0111]Epoch 370: Train Loss = 0.009311837144196033\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.00931] Epoch 371: Train Loss = 0.010439862497150898\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=371, train_loss_step=0.012, train_loss_epoch=0.0104]  Epoch 372: Train Loss = 0.01201576553285122\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.012]Epoch 373: Train Loss = 0.010394844226539135\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s, v_num=371, train_loss_step=0.0122, train_loss_epoch=0.0104]Epoch 374: Train Loss = 0.012224739417433739\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.0122]Epoch 375: Train Loss = 0.010394825600087643\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=371, train_loss_step=0.0133, train_loss_epoch=0.0104]Epoch 376: Train Loss = 0.013284226879477501\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=371, train_loss_step=0.0118, train_loss_epoch=0.0133]Epoch 377: Train Loss = 0.011830748990178108\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=371, train_loss_step=0.0107, train_loss_epoch=0.0118]Epoch 378: Train Loss = 0.010746309533715248\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=371, train_loss_step=0.00944, train_loss_epoch=0.0107]Epoch 379: Train Loss = 0.009439507499337196\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=371, train_loss_step=0.00826, train_loss_epoch=0.00944]Epoch 380: Train Loss = 0.00825542863458395\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.00826] Epoch 381: Train Loss = 0.010613923892378807\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.0106] Epoch 382: Train Loss = 0.011249822564423084\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=371, train_loss_step=0.0105, train_loss_epoch=0.0112]Epoch 383: Train Loss = 0.010476973839104176\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.0105]Epoch 384: Train Loss = 0.011421873234212399\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=371, train_loss_step=0.012, train_loss_epoch=0.0114] Epoch 385: Train Loss = 0.012034973129630089\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=371, train_loss_step=0.00901, train_loss_epoch=0.012]Epoch 386: Train Loss = 0.009014948271214962\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=371, train_loss_step=0.00823, train_loss_epoch=0.00901]Epoch 387: Train Loss = 0.008229414001107216\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.00823] Epoch 388: Train Loss = 0.0114694619551301\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=371, train_loss_step=0.0149, train_loss_epoch=0.0115] Epoch 389: Train Loss = 0.014922860078513622\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=371, train_loss_step=0.00853, train_loss_epoch=0.0149]Epoch 390: Train Loss = 0.008532985113561153\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=371, train_loss_step=0.00817, train_loss_epoch=0.00853]Epoch 391: Train Loss = 0.008172028698027134\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=371, train_loss_step=0.00965, train_loss_epoch=0.00817]Epoch 392: Train Loss = 0.009650020860135555\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, v_num=371, train_loss_step=0.00985, train_loss_epoch=0.00965]Epoch 393: Train Loss = 0.009854246862232685\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=371, train_loss_step=0.011, train_loss_epoch=0.00985]  Epoch 394: Train Loss = 0.01099074725061655\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=371, train_loss_step=0.0117, train_loss_epoch=0.011] Epoch 395: Train Loss = 0.011658730916678905\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 12.53it/s, v_num=371, train_loss_step=0.00871, train_loss_epoch=0.0117]Epoch 396: Train Loss = 0.00871377531439066\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=371, train_loss_step=0.00664, train_loss_epoch=0.00871]Epoch 397: Train Loss = 0.006635850761085749\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=371, train_loss_step=0.00873, train_loss_epoch=0.00664]Epoch 398: Train Loss = 0.008729984052479267\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 13.82it/s, v_num=371, train_loss_step=0.0106, train_loss_epoch=0.00873] Epoch 399: Train Loss = 0.010566708631813526\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=371, train_loss_step=0.0118, train_loss_epoch=0.0106] Epoch 400: Train Loss = 0.01182151585817337\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=371, train_loss_step=0.00947, train_loss_epoch=0.0118]Epoch 401: Train Loss = 0.009467505849897861\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.00947] Epoch 402: Train Loss = 0.010278692469000816\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=371, train_loss_step=0.00884, train_loss_epoch=0.0103]Epoch 403: Train Loss = 0.008835287764668465\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=371, train_loss_step=0.0098, train_loss_epoch=0.00884] Epoch 404: Train Loss = 0.00980040617287159\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=371, train_loss_step=0.0126, train_loss_epoch=0.0098] Epoch 405: Train Loss = 0.012622954323887825\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.0126]Epoch 406: Train Loss = 0.010270793922245502\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.0103]Epoch 407: Train Loss = 0.011422946117818356\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=371, train_loss_step=0.014, train_loss_epoch=0.0114] Epoch 408: Train Loss = 0.013989025726914406\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=371, train_loss_step=0.0156, train_loss_epoch=0.014]Epoch 409: Train Loss = 0.015645161271095276\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=371, train_loss_step=0.0102, train_loss_epoch=0.0156]Epoch 410: Train Loss = 0.010196603834629059\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=371, train_loss_step=0.011, train_loss_epoch=0.0102] Epoch 411: Train Loss = 0.010976570658385754\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=371, train_loss_step=0.0103, train_loss_epoch=0.011]Epoch 412: Train Loss = 0.010301575995981693\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.0103]Epoch 413: Train Loss = 0.010361420921981335\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.0104]Epoch 414: Train Loss = 0.010376697406172752\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=371, train_loss_step=0.00932, train_loss_epoch=0.0104]Epoch 415: Train Loss = 0.009320608340203762\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=371, train_loss_step=0.00803, train_loss_epoch=0.00932]Epoch 416: Train Loss = 0.008028961718082428\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.00803] Epoch 417: Train Loss = 0.011383481323719025\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=371, train_loss_step=0.0095, train_loss_epoch=0.0114] Epoch 418: Train Loss = 0.009496827609837055\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=371, train_loss_step=0.0089, train_loss_epoch=0.0095]Epoch 419: Train Loss = 0.008896170184016228\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.0089]Epoch 420: Train Loss = 0.010064438916742802\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=371, train_loss_step=0.00956, train_loss_epoch=0.0101]Epoch 421: Train Loss = 0.009556894190609455\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=371, train_loss_step=0.00918, train_loss_epoch=0.00956]Epoch 422: Train Loss = 0.009175284765660763\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s, v_num=371, train_loss_step=0.00946, train_loss_epoch=0.00918]Epoch 423: Train Loss = 0.009455927647650242\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=371, train_loss_step=0.00739, train_loss_epoch=0.00946]Epoch 424: Train Loss = 0.007385578006505966\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=371, train_loss_step=0.00982, train_loss_epoch=0.00739]Epoch 425: Train Loss = 0.009822397492825985\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=371, train_loss_step=0.00931, train_loss_epoch=0.00982]Epoch 426: Train Loss = 0.009313750080764294\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=371, train_loss_step=0.00874, train_loss_epoch=0.00931]Epoch 427: Train Loss = 0.008737565949559212\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.00874] Epoch 428: Train Loss = 0.01152824517339468\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.0115] Epoch 429: Train Loss = 0.010120675899088383\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 11.40it/s, v_num=371, train_loss_step=0.00895, train_loss_epoch=0.0101]Epoch 430: Train Loss = 0.008946050889790058\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=371, train_loss_step=0.00982, train_loss_epoch=0.00895]Epoch 431: Train Loss = 0.009817606769502163\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.00982] Epoch 432: Train Loss = 0.01151347067207098\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.0115] Epoch 433: Train Loss = 0.010120393708348274\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.0101]Epoch 434: Train Loss = 0.011189064010977745\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=371, train_loss_step=0.00965, train_loss_epoch=0.0112]Epoch 435: Train Loss = 0.009645621292293072\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=371, train_loss_step=0.00885, train_loss_epoch=0.00965]Epoch 436: Train Loss = 0.008854767307639122\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=371, train_loss_step=0.0117, train_loss_epoch=0.00885] Epoch 437: Train Loss = 0.011747902259230614\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.0117] Epoch 438: Train Loss = 0.0111371586099267\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.0111]Epoch 439: Train Loss = 0.011382527649402618\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=371, train_loss_step=0.00744, train_loss_epoch=0.0114]Epoch 440: Train Loss = 0.007443234324455261\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=371, train_loss_step=0.00791, train_loss_epoch=0.00744]Epoch 441: Train Loss = 0.007906084880232811\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=371, train_loss_step=0.00992, train_loss_epoch=0.00791]Epoch 442: Train Loss = 0.009918642230331898\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=371, train_loss_step=0.00767, train_loss_epoch=0.00992]Epoch 443: Train Loss = 0.007673888001590967\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=371, train_loss_step=0.0131, train_loss_epoch=0.00767] Epoch 444: Train Loss = 0.013108184561133385\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=371, train_loss_step=0.0095, train_loss_epoch=0.0131] Epoch 445: Train Loss = 0.00950397364795208\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=371, train_loss_step=0.0107, train_loss_epoch=0.0095]Epoch 446: Train Loss = 0.010688443668186665\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=371, train_loss_step=0.00857, train_loss_epoch=0.0107]Epoch 447: Train Loss = 0.008574821054935455\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=371, train_loss_step=0.00999, train_loss_epoch=0.00857]Epoch 448: Train Loss = 0.00998962577432394\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=371, train_loss_step=0.00914, train_loss_epoch=0.00999]Epoch 449: Train Loss = 0.009135567583143711\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.00914] Epoch 450: Train Loss = 0.011086775921285152\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=371, train_loss_step=0.00847, train_loss_epoch=0.0111]Epoch 451: Train Loss = 0.008473032154142857\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=371, train_loss_step=0.00884, train_loss_epoch=0.00847]Epoch 452: Train Loss = 0.008843575604259968\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.00884] Epoch 453: Train Loss = 0.010449833236634731\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=371, train_loss_step=0.0108, train_loss_epoch=0.0104] Epoch 454: Train Loss = 0.010831504128873348\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=371, train_loss_step=0.0112, train_loss_epoch=0.0108]Epoch 455: Train Loss = 0.011172080412507057\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=371, train_loss_step=0.0128, train_loss_epoch=0.0112]Epoch 456: Train Loss = 0.0127818388864398\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 12.63it/s, v_num=371, train_loss_step=0.00834, train_loss_epoch=0.0128]Epoch 457: Train Loss = 0.00834406353533268\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=371, train_loss_step=0.00929, train_loss_epoch=0.00834]Epoch 458: Train Loss = 0.009287779219448566\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=371, train_loss_step=0.00731, train_loss_epoch=0.00929]Epoch 459: Train Loss = 0.00730788754299283\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=371, train_loss_step=0.0121, train_loss_epoch=0.00731] Epoch 460: Train Loss = 0.012084556743502617\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.0121] Epoch 461: Train Loss = 0.010106879286468029\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=371, train_loss_step=0.00787, train_loss_epoch=0.0101]Epoch 462: Train Loss = 0.007868562825024128\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=371, train_loss_step=0.0123, train_loss_epoch=0.00787] Epoch 463: Train Loss = 0.012255050241947174\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=371, train_loss_step=0.0118, train_loss_epoch=0.0123] Epoch 464: Train Loss = 0.011795615777373314\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=371, train_loss_step=0.00884, train_loss_epoch=0.0118]Epoch 465: Train Loss = 0.008844071067869663\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=371, train_loss_step=0.00831, train_loss_epoch=0.00884]Epoch 466: Train Loss = 0.008311054669320583\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=371, train_loss_step=0.0108, train_loss_epoch=0.00831] Epoch 467: Train Loss = 0.010826420970261097\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=371, train_loss_step=0.012, train_loss_epoch=0.0108]  Epoch 468: Train Loss = 0.011993428692221642\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=371, train_loss_step=0.0129, train_loss_epoch=0.012]Epoch 469: Train Loss = 0.012904918752610683\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=371, train_loss_step=0.00931, train_loss_epoch=0.0129]Epoch 470: Train Loss = 0.009314442984759808\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=371, train_loss_step=0.00765, train_loss_epoch=0.00931]Epoch 471: Train Loss = 0.0076508051715791225\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=371, train_loss_step=0.00882, train_loss_epoch=0.00765]Epoch 472: Train Loss = 0.00882174726575613\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=371, train_loss_step=0.0107, train_loss_epoch=0.00882] Epoch 473: Train Loss = 0.010678513906896114\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=371, train_loss_step=0.00958, train_loss_epoch=0.0107]Epoch 474: Train Loss = 0.009577563963830471\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=371, train_loss_step=0.00803, train_loss_epoch=0.00958]Epoch 475: Train Loss = 0.008033044636249542\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=371, train_loss_step=0.0119, train_loss_epoch=0.00803] Epoch 476: Train Loss = 0.011915397830307484\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=371, train_loss_step=0.0101, train_loss_epoch=0.0119] Epoch 477: Train Loss = 0.010127030313014984\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=371, train_loss_step=0.00765, train_loss_epoch=0.0101]Epoch 478: Train Loss = 0.007653338368982077\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=371, train_loss_step=0.0121, train_loss_epoch=0.00765] Epoch 479: Train Loss = 0.012089400552213192\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=371, train_loss_step=0.0115, train_loss_epoch=0.0121] Epoch 480: Train Loss = 0.011522896587848663\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=371, train_loss_step=0.00927, train_loss_epoch=0.0115]Epoch 481: Train Loss = 0.009269134141504765\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=371, train_loss_step=0.00952, train_loss_epoch=0.00927]Epoch 482: Train Loss = 0.009517385624349117\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=371, train_loss_step=0.00984, train_loss_epoch=0.00952]Epoch 483: Train Loss = 0.009841561317443848\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=371, train_loss_step=0.0114, train_loss_epoch=0.00984] Epoch 484: Train Loss = 0.011394237168133259\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=371, train_loss_step=0.0113, train_loss_epoch=0.0114] Epoch 485: Train Loss = 0.011280796490609646\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, v_num=371, train_loss_step=0.0104, train_loss_epoch=0.0113]Epoch 486: Train Loss = 0.010398469865322113\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=371, train_loss_step=0.0133, train_loss_epoch=0.0104]Epoch 487: Train Loss = 0.0132762985303998\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=371, train_loss_step=0.00969, train_loss_epoch=0.0133]Epoch 488: Train Loss = 0.009689402766525745\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=371, train_loss_step=0.0111, train_loss_epoch=0.00969] Epoch 489: Train Loss = 0.01109341811388731\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=371, train_loss_step=0.00911, train_loss_epoch=0.0111]Epoch 490: Train Loss = 0.009108662605285645\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=371, train_loss_step=0.0079, train_loss_epoch=0.00911] Epoch 491: Train Loss = 0.007896690629422665\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 13.46it/s, v_num=371, train_loss_step=0.00936, train_loss_epoch=0.0079]Epoch 492: Train Loss = 0.009363561868667603\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=371, train_loss_step=0.0098, train_loss_epoch=0.00936] Epoch 493: Train Loss = 0.009799158200621605\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=371, train_loss_step=0.00866, train_loss_epoch=0.0098]Epoch 494: Train Loss = 0.008661762811243534\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=371, train_loss_step=0.0131, train_loss_epoch=0.00866] Epoch 495: Train Loss = 0.013104455545544624\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=371, train_loss_step=0.00848, train_loss_epoch=0.0131]Epoch 496: Train Loss = 0.008479933254420757\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=371, train_loss_step=0.00785, train_loss_epoch=0.00848]Epoch 497: Train Loss = 0.007850734516978264\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=371, train_loss_step=0.0118, train_loss_epoch=0.00785] Epoch 498: Train Loss = 0.011816112324595451\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=371, train_loss_step=0.00676, train_loss_epoch=0.0118]Epoch 499: Train Loss = 0.006757695693522692\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.59it/s, v_num=371, train_loss_step=0.00676, train_loss_epoch=0.00676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, v_num=371, train_loss_step=0.00676, train_loss_epoch=0.00676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 16: from 2008-05-12 00:00:00 to 2022-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s, v_num=373, train_loss_step=0.0304]Epoch 0: Train Loss = 0.030381614342331886\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=373, train_loss_step=0.0295, train_loss_epoch=0.0304]Epoch 1: Train Loss = 0.029450872913002968\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=373, train_loss_step=0.0237, train_loss_epoch=0.0295]Epoch 2: Train Loss = 0.02367374300956726\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 11.06it/s, v_num=373, train_loss_step=0.0272, train_loss_epoch=0.0237]Epoch 3: Train Loss = 0.027203325182199478\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=373, train_loss_step=0.0167, train_loss_epoch=0.0272]Epoch 4: Train Loss = 0.016664905473589897\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=373, train_loss_step=0.0231, train_loss_epoch=0.0167]Epoch 5: Train Loss = 0.023074224591255188\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=373, train_loss_step=0.0232, train_loss_epoch=0.0231]Epoch 6: Train Loss = 0.023213442414999008\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=373, train_loss_step=0.0185, train_loss_epoch=0.0232]Epoch 7: Train Loss = 0.018484603613615036\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=373, train_loss_step=0.0174, train_loss_epoch=0.0185]Epoch 8: Train Loss = 0.01740494929254055\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, v_num=373, train_loss_step=0.015, train_loss_epoch=0.0174] Epoch 9: Train Loss = 0.015041095204651356\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 12.67it/s, v_num=373, train_loss_step=0.0162, train_loss_epoch=0.015]Epoch 10: Train Loss = 0.01620377041399479\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=373, train_loss_step=0.0147, train_loss_epoch=0.0162]Epoch 11: Train Loss = 0.014711640775203705\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=373, train_loss_step=0.0212, train_loss_epoch=0.0147]Epoch 12: Train Loss = 0.021177293732762337\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=373, train_loss_step=0.0132, train_loss_epoch=0.0212]Epoch 13: Train Loss = 0.013182670809328556\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=373, train_loss_step=0.0124, train_loss_epoch=0.0132]Epoch 14: Train Loss = 0.012411719188094139\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0124]Epoch 15: Train Loss = 0.011734883300960064\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=373, train_loss_step=0.0143, train_loss_epoch=0.0117]Epoch 16: Train Loss = 0.014324774965643883\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=373, train_loss_step=0.013, train_loss_epoch=0.0143] Epoch 17: Train Loss = 0.013032674789428711\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=373, train_loss_step=0.0137, train_loss_epoch=0.013]Epoch 18: Train Loss = 0.01371114794164896\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=373, train_loss_step=0.0101, train_loss_epoch=0.0137]Epoch 19: Train Loss = 0.010126689448952675\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=373, train_loss_step=0.014, train_loss_epoch=0.0101] Epoch 20: Train Loss = 0.0140012102201581\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=373, train_loss_step=0.00989, train_loss_epoch=0.014]Epoch 21: Train Loss = 0.009889675304293633\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.00989] Epoch 22: Train Loss = 0.011781081557273865\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=373, train_loss_step=0.0121, train_loss_epoch=0.0118] Epoch 23: Train Loss = 0.012064672075212002\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=373, train_loss_step=0.0126, train_loss_epoch=0.0121]Epoch 24: Train Loss = 0.01256462000310421\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=373, train_loss_step=0.0139, train_loss_epoch=0.0126]Epoch 25: Train Loss = 0.013872933574020863\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.0139] Epoch 26: Train Loss = 0.011021233163774014\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=373, train_loss_step=0.0116, train_loss_epoch=0.011]Epoch 27: Train Loss = 0.011585511267185211\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=373, train_loss_step=0.0104, train_loss_epoch=0.0116]Epoch 28: Train Loss = 0.010366064496338367\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=373, train_loss_step=0.0135, train_loss_epoch=0.0104]Epoch 29: Train Loss = 0.013522573746740818\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.0135] Epoch 30: Train Loss = 0.011017720215022564\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 16.07it/s, v_num=373, train_loss_step=0.0138, train_loss_epoch=0.011]Epoch 31: Train Loss = 0.01379858423024416\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, v_num=373, train_loss_step=0.00872, train_loss_epoch=0.0138]Epoch 32: Train Loss = 0.00872248038649559\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 14.11it/s, v_num=373, train_loss_step=0.0156, train_loss_epoch=0.00872] Epoch 33: Train Loss = 0.015572150237858295\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=373, train_loss_step=0.0128, train_loss_epoch=0.0156] Epoch 34: Train Loss = 0.01281594205647707\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=373, train_loss_step=0.0134, train_loss_epoch=0.0128]Epoch 35: Train Loss = 0.013357585296034813\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=373, train_loss_step=0.00938, train_loss_epoch=0.0134]Epoch 36: Train Loss = 0.009382398799061775\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=373, train_loss_step=0.0115, train_loss_epoch=0.00938] Epoch 37: Train Loss = 0.011456131935119629\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=373, train_loss_step=0.0132, train_loss_epoch=0.0115] Epoch 38: Train Loss = 0.013202340342104435\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=373, train_loss_step=0.0116, train_loss_epoch=0.0132]Epoch 39: Train Loss = 0.011646087281405926\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=373, train_loss_step=0.0125, train_loss_epoch=0.0116]Epoch 40: Train Loss = 0.012497932650148869\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.0125]Epoch 41: Train Loss = 0.010847153142094612\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=373, train_loss_step=0.00875, train_loss_epoch=0.0108]Epoch 42: Train Loss = 0.008754661306738853\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=373, train_loss_step=0.00967, train_loss_epoch=0.00875]Epoch 43: Train Loss = 0.009672037325799465\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=373, train_loss_step=0.0122, train_loss_epoch=0.00967] Epoch 44: Train Loss = 0.012195049785077572\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=373, train_loss_step=0.0141, train_loss_epoch=0.0122] Epoch 45: Train Loss = 0.014072060585021973\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.0141]Epoch 46: Train Loss = 0.011800467036664486\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, v_num=373, train_loss_step=0.0113, train_loss_epoch=0.0118]Epoch 47: Train Loss = 0.011256023310124874\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=373, train_loss_step=0.0159, train_loss_epoch=0.0113]Epoch 48: Train Loss = 0.015879876911640167\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=373, train_loss_step=0.0136, train_loss_epoch=0.0159]Epoch 49: Train Loss = 0.013570182956755161\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=373, train_loss_step=0.0129, train_loss_epoch=0.0136]Epoch 50: Train Loss = 0.012905595824122429\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, v_num=373, train_loss_step=0.00941, train_loss_epoch=0.0129]Epoch 51: Train Loss = 0.00940967071801424\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s, v_num=373, train_loss_step=0.013, train_loss_epoch=0.00941]  Epoch 52: Train Loss = 0.012962410226464272\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=373, train_loss_step=0.00678, train_loss_epoch=0.013]Epoch 53: Train Loss = 0.006775486283004284\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.00678]  Epoch 54: Train Loss = 0.010997544042766094\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=373, train_loss_step=0.014, train_loss_epoch=0.011]  Epoch 55: Train Loss = 0.014026420190930367\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=373, train_loss_step=0.0183, train_loss_epoch=0.014]Epoch 56: Train Loss = 0.01827709749341011\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.0183] Epoch 57: Train Loss = 0.010970627889037132\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=373, train_loss_step=0.0101, train_loss_epoch=0.011]Epoch 58: Train Loss = 0.010117572732269764\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=373, train_loss_step=0.0135, train_loss_epoch=0.0101]Epoch 59: Train Loss = 0.013458356261253357\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=373, train_loss_step=0.0147, train_loss_epoch=0.0135]Epoch 60: Train Loss = 0.014713136479258537\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=373, train_loss_step=0.0142, train_loss_epoch=0.0147]Epoch 61: Train Loss = 0.01417144201695919\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.0142]Epoch 62: Train Loss = 0.010941393673419952\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=373, train_loss_step=0.012, train_loss_epoch=0.0109] Epoch 63: Train Loss = 0.011995567940175533\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=373, train_loss_step=0.0152, train_loss_epoch=0.012]Epoch 64: Train Loss = 0.015244228765368462\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=373, train_loss_step=0.0125, train_loss_epoch=0.0152]Epoch 65: Train Loss = 0.012540261261165142\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=373, train_loss_step=0.0145, train_loss_epoch=0.0125]Epoch 66: Train Loss = 0.01448250375688076\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=373, train_loss_step=0.0143, train_loss_epoch=0.0145]Epoch 67: Train Loss = 0.01431822869926691\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=373, train_loss_step=0.0121, train_loss_epoch=0.0143]Epoch 68: Train Loss = 0.012108098715543747\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=373, train_loss_step=0.0106, train_loss_epoch=0.0121]Epoch 69: Train Loss = 0.01063407864421606\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=373, train_loss_step=0.0113, train_loss_epoch=0.0106]Epoch 70: Train Loss = 0.01126991305500269\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=373, train_loss_step=0.0111, train_loss_epoch=0.0113]Epoch 71: Train Loss = 0.011095911264419556\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=373, train_loss_step=0.0115, train_loss_epoch=0.0111]Epoch 72: Train Loss = 0.011499123647809029\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=373, train_loss_step=0.012, train_loss_epoch=0.0115] Epoch 73: Train Loss = 0.011967546306550503\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.012]Epoch 74: Train Loss = 0.01076133269816637\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=373, train_loss_step=0.0113, train_loss_epoch=0.0108]Epoch 75: Train Loss = 0.01128604356199503\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=373, train_loss_step=0.0145, train_loss_epoch=0.0113]Epoch 76: Train Loss = 0.01446150429546833\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=373, train_loss_step=0.0142, train_loss_epoch=0.0145]Epoch 77: Train Loss = 0.014182253740727901\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=373, train_loss_step=0.0083, train_loss_epoch=0.0142]Epoch 78: Train Loss = 0.008297066204249859\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=373, train_loss_step=0.0134, train_loss_epoch=0.0083]Epoch 79: Train Loss = 0.01342862006276846\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=373, train_loss_step=0.00928, train_loss_epoch=0.0134]Epoch 80: Train Loss = 0.009282829239964485\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.00928] Epoch 81: Train Loss = 0.010756373405456543\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=373, train_loss_step=0.0106, train_loss_epoch=0.0108] Epoch 82: Train Loss = 0.010642648674547672\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=373, train_loss_step=0.0123, train_loss_epoch=0.0106]Epoch 83: Train Loss = 0.01232747919857502\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=373, train_loss_step=0.0122, train_loss_epoch=0.0123]Epoch 84: Train Loss = 0.012162057682871819\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=373, train_loss_step=0.0112, train_loss_epoch=0.0122]Epoch 85: Train Loss = 0.011190411634743214\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=373, train_loss_step=0.0125, train_loss_epoch=0.0112]Epoch 86: Train Loss = 0.012510448694229126\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=373, train_loss_step=0.0145, train_loss_epoch=0.0125]Epoch 87: Train Loss = 0.014546729624271393\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=373, train_loss_step=0.0128, train_loss_epoch=0.0145]Epoch 88: Train Loss = 0.012788480147719383\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s, v_num=373, train_loss_step=0.014, train_loss_epoch=0.0128] Epoch 89: Train Loss = 0.014012737199664116\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.014]Epoch 90: Train Loss = 0.011753999628126621\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=373, train_loss_step=0.00938, train_loss_epoch=0.0118]Epoch 91: Train Loss = 0.009378246031701565\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=373, train_loss_step=0.0132, train_loss_epoch=0.00938] Epoch 92: Train Loss = 0.013239705935120583\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=373, train_loss_step=0.00924, train_loss_epoch=0.0132]Epoch 93: Train Loss = 0.009239530190825462\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=373, train_loss_step=0.0131, train_loss_epoch=0.00924] Epoch 94: Train Loss = 0.01310930959880352\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=373, train_loss_step=0.00811, train_loss_epoch=0.0131]Epoch 95: Train Loss = 0.008113515563309193\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=373, train_loss_step=0.0103, train_loss_epoch=0.00811] Epoch 96: Train Loss = 0.010334803722798824\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=373, train_loss_step=0.0116, train_loss_epoch=0.0103] Epoch 97: Train Loss = 0.011573128402233124\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=373, train_loss_step=0.00918, train_loss_epoch=0.0116]Epoch 98: Train Loss = 0.0091781597584486\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=373, train_loss_step=0.00892, train_loss_epoch=0.00918]Epoch 99: Train Loss = 0.008919082581996918\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=373, train_loss_step=0.0105, train_loss_epoch=0.00892] Epoch 100: Train Loss = 0.010515328496694565\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=373, train_loss_step=0.00984, train_loss_epoch=0.0105]Epoch 101: Train Loss = 0.00983815174549818\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 15.92it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.00984] Epoch 102: Train Loss = 0.011737152002751827\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 16.10it/s, v_num=373, train_loss_step=0.0128, train_loss_epoch=0.0117] Epoch 103: Train Loss = 0.012790367938578129\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=373, train_loss_step=0.00964, train_loss_epoch=0.0128]Epoch 104: Train Loss = 0.009644084610044956\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=373, train_loss_step=0.0096, train_loss_epoch=0.00964] Epoch 105: Train Loss = 0.009599616751074791\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 16.04it/s, v_num=373, train_loss_step=0.0096, train_loss_epoch=0.0096] Epoch 106: Train Loss = 0.009603274054825306\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=373, train_loss_step=0.00926, train_loss_epoch=0.0096]Epoch 107: Train Loss = 0.009260895662009716\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=373, train_loss_step=0.0124, train_loss_epoch=0.00926] Epoch 108: Train Loss = 0.012381656095385551\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=373, train_loss_step=0.0115, train_loss_epoch=0.0124] Epoch 109: Train Loss = 0.011493131518363953\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=373, train_loss_step=0.0124, train_loss_epoch=0.0115]Epoch 110: Train Loss = 0.012413651682436466\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=373, train_loss_step=0.0145, train_loss_epoch=0.0124]Epoch 111: Train Loss = 0.014467360451817513\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=373, train_loss_step=0.0134, train_loss_epoch=0.0145]Epoch 112: Train Loss = 0.01344319712370634\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=373, train_loss_step=0.0129, train_loss_epoch=0.0134]Epoch 113: Train Loss = 0.012945621274411678\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=373, train_loss_step=0.0133, train_loss_epoch=0.0129]Epoch 114: Train Loss = 0.013346031308174133\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=373, train_loss_step=0.0128, train_loss_epoch=0.0133]Epoch 115: Train Loss = 0.012798832729458809\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=373, train_loss_step=0.00916, train_loss_epoch=0.0128]Epoch 116: Train Loss = 0.009156978689134121\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.00916] Epoch 117: Train Loss = 0.011768989264965057\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=373, train_loss_step=0.0144, train_loss_epoch=0.0118] Epoch 118: Train Loss = 0.014404256828129292\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 13.22it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0144]Epoch 119: Train Loss = 0.011949732899665833\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=373, train_loss_step=0.0138, train_loss_epoch=0.0119]Epoch 120: Train Loss = 0.013828447088599205\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=373, train_loss_step=0.015, train_loss_epoch=0.0138] Epoch 121: Train Loss = 0.015039258636534214\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=373, train_loss_step=0.0186, train_loss_epoch=0.015]Epoch 122: Train Loss = 0.01856067404150963\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=373, train_loss_step=0.0144, train_loss_epoch=0.0186]Epoch 123: Train Loss = 0.01439560204744339\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=373, train_loss_step=0.0157, train_loss_epoch=0.0144]Epoch 124: Train Loss = 0.01573668234050274\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=373, train_loss_step=0.0137, train_loss_epoch=0.0157]Epoch 125: Train Loss = 0.01369516085833311\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0137]Epoch 126: Train Loss = 0.011937467381358147\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=373, train_loss_step=0.0127, train_loss_epoch=0.0119]Epoch 127: Train Loss = 0.012706694193184376\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=373, train_loss_step=0.00926, train_loss_epoch=0.0127]Epoch 128: Train Loss = 0.009259740822017193\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=373, train_loss_step=0.0137, train_loss_epoch=0.00926] Epoch 129: Train Loss = 0.01365321408957243\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.0137] Epoch 130: Train Loss = 0.01074154581874609\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=373, train_loss_step=0.0112, train_loss_epoch=0.0107]Epoch 131: Train Loss = 0.011159077286720276\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=373, train_loss_step=0.00955, train_loss_epoch=0.0112]Epoch 132: Train Loss = 0.009547567926347256\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=373, train_loss_step=0.015, train_loss_epoch=0.00955]  Epoch 133: Train Loss = 0.015043376944959164\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=373, train_loss_step=0.0149, train_loss_epoch=0.015] Epoch 134: Train Loss = 0.014921500347554684\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.0149] Epoch 135: Train Loss = 0.010995052754878998\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=373, train_loss_step=0.0137, train_loss_epoch=0.011]Epoch 136: Train Loss = 0.013678106479346752\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.0137]Epoch 137: Train Loss = 0.010762886144220829\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=373, train_loss_step=0.0116, train_loss_epoch=0.0108]Epoch 138: Train Loss = 0.011597542092204094\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s, v_num=373, train_loss_step=0.0143, train_loss_epoch=0.0116]Epoch 139: Train Loss = 0.01426644902676344\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s, v_num=373, train_loss_step=0.0121, train_loss_epoch=0.0143]Epoch 140: Train Loss = 0.012124551460146904\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=373, train_loss_step=0.0135, train_loss_epoch=0.0121]Epoch 141: Train Loss = 0.013530625961720943\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=373, train_loss_step=0.0171, train_loss_epoch=0.0135]Epoch 142: Train Loss = 0.01713622733950615\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=373, train_loss_step=0.0135, train_loss_epoch=0.0171]Epoch 143: Train Loss = 0.013536587357521057\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=373, train_loss_step=0.010, train_loss_epoch=0.0135] Epoch 144: Train Loss = 0.010015917010605335\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=373, train_loss_step=0.0113, train_loss_epoch=0.010]Epoch 145: Train Loss = 0.01134198997169733\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=373, train_loss_step=0.0125, train_loss_epoch=0.0113]Epoch 146: Train Loss = 0.012494432739913464\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=373, train_loss_step=0.0145, train_loss_epoch=0.0125]Epoch 147: Train Loss = 0.01453979592770338\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0145]Epoch 148: Train Loss = 0.011896266601979733\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=373, train_loss_step=0.0132, train_loss_epoch=0.0119]Epoch 149: Train Loss = 0.013226131908595562\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=373, train_loss_step=0.0129, train_loss_epoch=0.0132]Epoch 150: Train Loss = 0.012885610572993755\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=373, train_loss_step=0.00952, train_loss_epoch=0.0129]Epoch 151: Train Loss = 0.009523102082312107\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=373, train_loss_step=0.00878, train_loss_epoch=0.00952]Epoch 152: Train Loss = 0.008782426826655865\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=373, train_loss_step=0.0111, train_loss_epoch=0.00878] Epoch 153: Train Loss = 0.011080464348196983\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s, v_num=373, train_loss_step=0.0147, train_loss_epoch=0.0111] Epoch 154: Train Loss = 0.014733994379639626\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.0147]Epoch 155: Train Loss = 0.010933555662631989\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0109]Epoch 156: Train Loss = 0.011905292980372906\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=373, train_loss_step=0.0124, train_loss_epoch=0.0119]Epoch 157: Train Loss = 0.01237856037914753\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=373, train_loss_step=0.0115, train_loss_epoch=0.0124]Epoch 158: Train Loss = 0.011532442644238472\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=373, train_loss_step=0.0111, train_loss_epoch=0.0115]Epoch 159: Train Loss = 0.011137271299958229\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=373, train_loss_step=0.0102, train_loss_epoch=0.0111]Epoch 160: Train Loss = 0.010184593498706818\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=373, train_loss_step=0.0125, train_loss_epoch=0.0102]Epoch 161: Train Loss = 0.012523450888693333\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=373, train_loss_step=0.00925, train_loss_epoch=0.0125]Epoch 162: Train Loss = 0.009251861833035946\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.00925] Epoch 163: Train Loss = 0.010775511153042316\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=373, train_loss_step=0.00911, train_loss_epoch=0.0108]Epoch 164: Train Loss = 0.00910626444965601\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=373, train_loss_step=0.00883, train_loss_epoch=0.00911]Epoch 165: Train Loss = 0.008826643228530884\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=373, train_loss_step=0.00979, train_loss_epoch=0.00883]Epoch 166: Train Loss = 0.009785215370357037\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.00979] Epoch 167: Train Loss = 0.011699238792061806\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=373, train_loss_step=0.00848, train_loss_epoch=0.0117]Epoch 168: Train Loss = 0.008482120931148529\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=373, train_loss_step=0.0103, train_loss_epoch=0.00848] Epoch 169: Train Loss = 0.01034641545265913\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=373, train_loss_step=0.0123, train_loss_epoch=0.0103] Epoch 170: Train Loss = 0.012349367141723633\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=373, train_loss_step=0.0148, train_loss_epoch=0.0123]Epoch 171: Train Loss = 0.014838919043540955\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=373, train_loss_step=0.0101, train_loss_epoch=0.0148]Epoch 172: Train Loss = 0.01010194979608059\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=373, train_loss_step=0.0105, train_loss_epoch=0.0101]Epoch 173: Train Loss = 0.01053374819457531\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.0105]Epoch 174: Train Loss = 0.01175015326589346\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=373, train_loss_step=0.0106, train_loss_epoch=0.0118]Epoch 175: Train Loss = 0.010573213919997215\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=373, train_loss_step=0.00848, train_loss_epoch=0.0106]Epoch 176: Train Loss = 0.008482391946017742\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.00848] Epoch 177: Train Loss = 0.010933725163340569\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.0109] Epoch 178: Train Loss = 0.01071187760680914\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=373, train_loss_step=0.0125, train_loss_epoch=0.0107]Epoch 179: Train Loss = 0.012467090971767902\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.0125]Epoch 180: Train Loss = 0.010939809493720531\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=373, train_loss_step=0.0151, train_loss_epoch=0.0109]Epoch 181: Train Loss = 0.015134491957724094\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=373, train_loss_step=0.00843, train_loss_epoch=0.0151]Epoch 182: Train Loss = 0.008432741276919842\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.00843] Epoch 183: Train Loss = 0.01190500520169735\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 14.12it/s, v_num=373, train_loss_step=0.00944, train_loss_epoch=0.0119]Epoch 184: Train Loss = 0.009436880238354206\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=373, train_loss_step=0.0129, train_loss_epoch=0.00944] Epoch 185: Train Loss = 0.012858656235039234\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=373, train_loss_step=0.00913, train_loss_epoch=0.0129]Epoch 186: Train Loss = 0.009125581942498684\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=373, train_loss_step=0.00891, train_loss_epoch=0.00913]Epoch 187: Train Loss = 0.0089122848585248\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=373, train_loss_step=0.0101, train_loss_epoch=0.00891] Epoch 188: Train Loss = 0.010146397165954113\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0101] Epoch 189: Train Loss = 0.011910589411854744\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=373, train_loss_step=0.00882, train_loss_epoch=0.0119]Epoch 190: Train Loss = 0.008821855299174786\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=373, train_loss_step=0.00882, train_loss_epoch=0.00882]Epoch 191: Train Loss = 0.008818366564810276\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=373, train_loss_step=0.00876, train_loss_epoch=0.00882]Epoch 192: Train Loss = 0.008757890202105045\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=373, train_loss_step=0.0137, train_loss_epoch=0.00876] Epoch 193: Train Loss = 0.013703671284019947\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=373, train_loss_step=0.0088, train_loss_epoch=0.0137] Epoch 194: Train Loss = 0.008803450502455235\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=373, train_loss_step=0.00771, train_loss_epoch=0.0088]Epoch 195: Train Loss = 0.00771368807181716\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=373, train_loss_step=0.0124, train_loss_epoch=0.00771] Epoch 196: Train Loss = 0.01240047998726368\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=373, train_loss_step=0.0113, train_loss_epoch=0.0124] Epoch 197: Train Loss = 0.011287161149084568\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=373, train_loss_step=0.0105, train_loss_epoch=0.0113]Epoch 198: Train Loss = 0.010486212559044361\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 13.55it/s, v_num=373, train_loss_step=0.00829, train_loss_epoch=0.0105]Epoch 199: Train Loss = 0.008287889882922173\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=373, train_loss_step=0.0123, train_loss_epoch=0.00829] Epoch 200: Train Loss = 0.012328020296990871\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, v_num=373, train_loss_step=0.0114, train_loss_epoch=0.0123] Epoch 201: Train Loss = 0.011366584338247776\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=373, train_loss_step=0.0145, train_loss_epoch=0.0114]Epoch 202: Train Loss = 0.014498189091682434\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.0145]Epoch 203: Train Loss = 0.01181696355342865\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=373, train_loss_step=0.0132, train_loss_epoch=0.0118]Epoch 204: Train Loss = 0.01319988165050745\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=373, train_loss_step=0.0137, train_loss_epoch=0.0132]Epoch 205: Train Loss = 0.013709267601370811\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=373, train_loss_step=0.00866, train_loss_epoch=0.0137]Epoch 206: Train Loss = 0.00866117887198925\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=373, train_loss_step=0.00804, train_loss_epoch=0.00866]Epoch 207: Train Loss = 0.008044601418077946\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=373, train_loss_step=0.0112, train_loss_epoch=0.00804] Epoch 208: Train Loss = 0.011212055571377277\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=373, train_loss_step=0.0133, train_loss_epoch=0.0112] Epoch 209: Train Loss = 0.013345271348953247\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.0133]Epoch 210: Train Loss = 0.01074237935245037\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=373, train_loss_step=0.0104, train_loss_epoch=0.0107]Epoch 211: Train Loss = 0.010397503152489662\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=373, train_loss_step=0.0131, train_loss_epoch=0.0104]Epoch 212: Train Loss = 0.013125082477927208\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s, v_num=373, train_loss_step=0.0112, train_loss_epoch=0.0131]Epoch 213: Train Loss = 0.011160065419971943\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=373, train_loss_step=0.0127, train_loss_epoch=0.0112]Epoch 214: Train Loss = 0.012711385264992714\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.0127] Epoch 215: Train Loss = 0.011010210029780865\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=373, train_loss_step=0.0149, train_loss_epoch=0.011]Epoch 216: Train Loss = 0.014895682223141193\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=373, train_loss_step=0.00908, train_loss_epoch=0.0149]Epoch 217: Train Loss = 0.0090824319049716\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=373, train_loss_step=0.00841, train_loss_epoch=0.00908]Epoch 218: Train Loss = 0.008411356247961521\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=373, train_loss_step=0.0126, train_loss_epoch=0.00841] Epoch 219: Train Loss = 0.01257586944848299\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=373, train_loss_step=0.0138, train_loss_epoch=0.0126] Epoch 220: Train Loss = 0.01383886393159628\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0138]Epoch 221: Train Loss = 0.011700228787958622\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=373, train_loss_step=0.0111, train_loss_epoch=0.0117]Epoch 222: Train Loss = 0.011107857339084148\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=373, train_loss_step=0.0105, train_loss_epoch=0.0111]Epoch 223: Train Loss = 0.010468170046806335\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=373, train_loss_step=0.00991, train_loss_epoch=0.0105]Epoch 224: Train Loss = 0.009912571869790554\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=373, train_loss_step=0.0104, train_loss_epoch=0.00991] Epoch 225: Train Loss = 0.010441171005368233\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0104] Epoch 226: Train Loss = 0.011852583847939968\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0119]Epoch 227: Train Loss = 0.011919690296053886\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=373, train_loss_step=0.0114, train_loss_epoch=0.0119]Epoch 228: Train Loss = 0.011385753750801086\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=373, train_loss_step=0.0106, train_loss_epoch=0.0114]Epoch 229: Train Loss = 0.010648275725543499\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0106]Epoch 230: Train Loss = 0.011851140297949314\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 13.56it/s, v_num=373, train_loss_step=0.013, train_loss_epoch=0.0119] Epoch 231: Train Loss = 0.013020013459026814\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.013]Epoch 232: Train Loss = 0.011949107982218266\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=373, train_loss_step=0.014, train_loss_epoch=0.0119] Epoch 233: Train Loss = 0.014025011099874973\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.014]Epoch 234: Train Loss = 0.010863683186471462\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=373, train_loss_step=0.014, train_loss_epoch=0.0109] Epoch 235: Train Loss = 0.013998515903949738\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.014] Epoch 236: Train Loss = 0.011043420992791653\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=373, train_loss_step=0.0157, train_loss_epoch=0.011]Epoch 237: Train Loss = 0.015723636373877525\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0157]Epoch 238: Train Loss = 0.011930650100111961\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=373, train_loss_step=0.00986, train_loss_epoch=0.0119]Epoch 239: Train Loss = 0.009857804514467716\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=373, train_loss_step=0.0101, train_loss_epoch=0.00986] Epoch 240: Train Loss = 0.010123425163328648\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=373, train_loss_step=0.0121, train_loss_epoch=0.0101] Epoch 241: Train Loss = 0.012136256322264671\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=373, train_loss_step=0.016, train_loss_epoch=0.0121] Epoch 242: Train Loss = 0.015967288985848427\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=373, train_loss_step=0.0145, train_loss_epoch=0.016]Epoch 243: Train Loss = 0.014541380107402802\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=373, train_loss_step=0.0114, train_loss_epoch=0.0145]Epoch 244: Train Loss = 0.011417312547564507\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=373, train_loss_step=0.0124, train_loss_epoch=0.0114]Epoch 245: Train Loss = 0.012408340349793434\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0124]Epoch 246: Train Loss = 0.011684275232255459\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=373, train_loss_step=0.0101, train_loss_epoch=0.0117]Epoch 247: Train Loss = 0.010110174305737019\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 13.78it/s, v_num=373, train_loss_step=0.00865, train_loss_epoch=0.0101]Epoch 248: Train Loss = 0.008653822354972363\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=373, train_loss_step=0.00901, train_loss_epoch=0.00865]Epoch 249: Train Loss = 0.00900568813085556\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, v_num=373, train_loss_step=0.00947, train_loss_epoch=0.00901]Epoch 250: Train Loss = 0.009467949159443378\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=373, train_loss_step=0.0101, train_loss_epoch=0.00947] Epoch 251: Train Loss = 0.010097051970660686\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=373, train_loss_step=0.0106, train_loss_epoch=0.0101] Epoch 252: Train Loss = 0.010644554160535336\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=373, train_loss_step=0.0094, train_loss_epoch=0.0106]Epoch 253: Train Loss = 0.009403815492987633\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.0094]Epoch 254: Train Loss = 0.010940010659396648\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=373, train_loss_step=0.0128, train_loss_epoch=0.0109]Epoch 255: Train Loss = 0.012840846553444862\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=373, train_loss_step=0.0103, train_loss_epoch=0.0128]Epoch 256: Train Loss = 0.010275679640471935\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=373, train_loss_step=0.00722, train_loss_epoch=0.0103]Epoch 257: Train Loss = 0.007217724807560444\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=373, train_loss_step=0.0106, train_loss_epoch=0.00722] Epoch 258: Train Loss = 0.010639594867825508\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s, v_num=373, train_loss_step=0.00921, train_loss_epoch=0.0106]Epoch 259: Train Loss = 0.009205826558172703\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=373, train_loss_step=0.0121, train_loss_epoch=0.00921] Epoch 260: Train Loss = 0.012118798680603504\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=373, train_loss_step=0.0112, train_loss_epoch=0.0121] Epoch 261: Train Loss = 0.011169503442943096\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=373, train_loss_step=0.0146, train_loss_epoch=0.0112]Epoch 262: Train Loss = 0.014593482948839664\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=373, train_loss_step=0.0115, train_loss_epoch=0.0146]Epoch 263: Train Loss = 0.01145229022949934\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=373, train_loss_step=0.0131, train_loss_epoch=0.0115]Epoch 264: Train Loss = 0.013113378547132015\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=373, train_loss_step=0.0112, train_loss_epoch=0.0131]Epoch 265: Train Loss = 0.011178978718817234\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=373, train_loss_step=0.00999, train_loss_epoch=0.0112]Epoch 266: Train Loss = 0.009991993196308613\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=373, train_loss_step=0.0104, train_loss_epoch=0.00999] Epoch 267: Train Loss = 0.010391476564109325\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=373, train_loss_step=0.0145, train_loss_epoch=0.0104] Epoch 268: Train Loss = 0.014455556869506836\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.0145]Epoch 269: Train Loss = 0.010687879286706448\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=373, train_loss_step=0.0158, train_loss_epoch=0.0107]Epoch 270: Train Loss = 0.015828503295779228\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=373, train_loss_step=0.0114, train_loss_epoch=0.0158]Epoch 271: Train Loss = 0.011435248889029026\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=373, train_loss_step=0.0127, train_loss_epoch=0.0114]Epoch 272: Train Loss = 0.012684560380876064\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=373, train_loss_step=0.0124, train_loss_epoch=0.0127]Epoch 273: Train Loss = 0.012418740428984165\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.0124]Epoch 274: Train Loss = 0.010833660140633583\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=373, train_loss_step=0.00947, train_loss_epoch=0.0108]Epoch 275: Train Loss = 0.009468518197536469\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.00947] Epoch 276: Train Loss = 0.010778287425637245\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 11.43it/s, v_num=373, train_loss_step=0.00853, train_loss_epoch=0.0108]Epoch 277: Train Loss = 0.008534932509064674\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=373, train_loss_step=0.0114, train_loss_epoch=0.00853] Epoch 278: Train Loss = 0.011437656357884407\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=373, train_loss_step=0.0127, train_loss_epoch=0.0114] Epoch 279: Train Loss = 0.01267325971275568\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=373, train_loss_step=0.0113, train_loss_epoch=0.0127]Epoch 280: Train Loss = 0.01134627964347601\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.0113]Epoch 281: Train Loss = 0.010773255489766598\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=373, train_loss_step=0.00797, train_loss_epoch=0.0108]Epoch 282: Train Loss = 0.007969721220433712\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=373, train_loss_step=0.013, train_loss_epoch=0.00797]  Epoch 283: Train Loss = 0.013017439283430576\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=373, train_loss_step=0.0103, train_loss_epoch=0.013] Epoch 284: Train Loss = 0.010262511670589447\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=373, train_loss_step=0.0113, train_loss_epoch=0.0103]Epoch 285: Train Loss = 0.011286280117928982\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=373, train_loss_step=0.00818, train_loss_epoch=0.0113]Epoch 286: Train Loss = 0.00817539356648922\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=373, train_loss_step=0.0147, train_loss_epoch=0.00818] Epoch 287: Train Loss = 0.01472377497702837\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=373, train_loss_step=0.0111, train_loss_epoch=0.0147] Epoch 288: Train Loss = 0.011140160262584686\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0111]Epoch 289: Train Loss = 0.011739159934222698\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=373, train_loss_step=0.00957, train_loss_epoch=0.0117]Epoch 290: Train Loss = 0.009573198854923248\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=373, train_loss_step=0.00734, train_loss_epoch=0.00957]Epoch 291: Train Loss = 0.007336657494306564\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=373, train_loss_step=0.00907, train_loss_epoch=0.00734]Epoch 292: Train Loss = 0.009069734252989292\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=373, train_loss_step=0.00739, train_loss_epoch=0.00907]Epoch 293: Train Loss = 0.007388127036392689\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=373, train_loss_step=0.0104, train_loss_epoch=0.00739] Epoch 294: Train Loss = 0.010410708375275135\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=373, train_loss_step=0.00998, train_loss_epoch=0.0104]Epoch 295: Train Loss = 0.009975605644285679\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=373, train_loss_step=0.0122, train_loss_epoch=0.00998] Epoch 296: Train Loss = 0.012222598306834698\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=373, train_loss_step=0.00762, train_loss_epoch=0.0122]Epoch 297: Train Loss = 0.007615384180098772\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=373, train_loss_step=0.0115, train_loss_epoch=0.00762] Epoch 298: Train Loss = 0.011501866392791271\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=373, train_loss_step=0.00817, train_loss_epoch=0.0115]Epoch 299: Train Loss = 0.008172408677637577\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=373, train_loss_step=0.0114, train_loss_epoch=0.00817] Epoch 300: Train Loss = 0.01135985367000103\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 13.45it/s, v_num=373, train_loss_step=0.00991, train_loss_epoch=0.0114]Epoch 301: Train Loss = 0.009912415407598019\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.00991] Epoch 302: Train Loss = 0.010934236459434032\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=373, train_loss_step=0.0114, train_loss_epoch=0.0109] Epoch 303: Train Loss = 0.011372237466275692\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=373, train_loss_step=0.0126, train_loss_epoch=0.0114]Epoch 304: Train Loss = 0.012622741051018238\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=373, train_loss_step=0.0093, train_loss_epoch=0.0126]Epoch 305: Train Loss = 0.009299577213823795\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.0093] Epoch 306: Train Loss = 0.011038246564567089\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.011]Epoch 307: Train Loss = 0.010691880248486996\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=373, train_loss_step=0.00802, train_loss_epoch=0.0107]Epoch 308: Train Loss = 0.00802011787891388\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.00802]  Epoch 309: Train Loss = 0.010965416207909584\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=373, train_loss_step=0.0132, train_loss_epoch=0.011] Epoch 310: Train Loss = 0.01324546243995428\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.0132]Epoch 311: Train Loss = 0.010914790444076061\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=373, train_loss_step=0.00868, train_loss_epoch=0.0109]Epoch 312: Train Loss = 0.008679745718836784\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=373, train_loss_step=0.00894, train_loss_epoch=0.00868]Epoch 313: Train Loss = 0.008935722522437572\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=373, train_loss_step=0.00902, train_loss_epoch=0.00894]Epoch 314: Train Loss = 0.009022659622132778\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=373, train_loss_step=0.00775, train_loss_epoch=0.00902]Epoch 315: Train Loss = 0.007754612248390913\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=373, train_loss_step=0.0127, train_loss_epoch=0.00775] Epoch 316: Train Loss = 0.012656326405704021\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 16.55it/s, v_num=373, train_loss_step=0.0106, train_loss_epoch=0.0127] Epoch 317: Train Loss = 0.010606358759105206\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=373, train_loss_step=0.0116, train_loss_epoch=0.0106]Epoch 318: Train Loss = 0.011619864962995052\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=373, train_loss_step=0.00893, train_loss_epoch=0.0116]Epoch 319: Train Loss = 0.008932477794587612\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=373, train_loss_step=0.0098, train_loss_epoch=0.00893] Epoch 320: Train Loss = 0.009796413592994213\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=373, train_loss_step=0.0134, train_loss_epoch=0.0098] Epoch 321: Train Loss = 0.013363110832870007\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=373, train_loss_step=0.0133, train_loss_epoch=0.0134]Epoch 322: Train Loss = 0.013251186348497868\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=373, train_loss_step=0.0079, train_loss_epoch=0.0133]Epoch 323: Train Loss = 0.0078969094902277\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=373, train_loss_step=0.0121, train_loss_epoch=0.0079]Epoch 324: Train Loss = 0.012063107453286648\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=373, train_loss_step=0.0102, train_loss_epoch=0.0121]Epoch 325: Train Loss = 0.010223825462162495\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, v_num=373, train_loss_step=0.0104, train_loss_epoch=0.0102]Epoch 326: Train Loss = 0.010364181362092495\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=373, train_loss_step=0.00788, train_loss_epoch=0.0104]Epoch 327: Train Loss = 0.007876026444137096\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=373, train_loss_step=0.0115, train_loss_epoch=0.00788] Epoch 328: Train Loss = 0.011469759047031403\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=373, train_loss_step=0.0105, train_loss_epoch=0.0115] Epoch 329: Train Loss = 0.01047165784984827\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.0105]Epoch 330: Train Loss = 0.01090517919510603\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=373, train_loss_step=0.00922, train_loss_epoch=0.0109]Epoch 331: Train Loss = 0.009220033884048462\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=373, train_loss_step=0.0104, train_loss_epoch=0.00922] Epoch 332: Train Loss = 0.010421251878142357\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 13.82it/s, v_num=373, train_loss_step=0.0112, train_loss_epoch=0.0104] Epoch 333: Train Loss = 0.011209431104362011\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=373, train_loss_step=0.00916, train_loss_epoch=0.0112]Epoch 334: Train Loss = 0.009160585701465607\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=373, train_loss_step=0.00831, train_loss_epoch=0.00916]Epoch 335: Train Loss = 0.008310681208968163\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.00831] Epoch 336: Train Loss = 0.01194298267364502\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=373, train_loss_step=0.00888, train_loss_epoch=0.0119]Epoch 337: Train Loss = 0.00887519121170044\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=373, train_loss_step=0.00899, train_loss_epoch=0.00888]Epoch 338: Train Loss = 0.008989601396024227\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=373, train_loss_step=0.00847, train_loss_epoch=0.00899]Epoch 339: Train Loss = 0.008467220701277256\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=373, train_loss_step=0.00996, train_loss_epoch=0.00847]Epoch 340: Train Loss = 0.009964482858777046\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.00996] Epoch 341: Train Loss = 0.010718630626797676\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.0107]  Epoch 342: Train Loss = 0.010980194434523582\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=373, train_loss_step=0.0135, train_loss_epoch=0.011]Epoch 343: Train Loss = 0.013521519489586353\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0135]Epoch 344: Train Loss = 0.011897492222487926\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=373, train_loss_step=0.0131, train_loss_epoch=0.0119]Epoch 345: Train Loss = 0.013105257414281368\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.0131]Epoch 346: Train Loss = 0.010684020817279816\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=373, train_loss_step=0.0133, train_loss_epoch=0.0107]Epoch 347: Train Loss = 0.013305730186402798\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=373, train_loss_step=0.0142, train_loss_epoch=0.0133]Epoch 348: Train Loss = 0.014196121133863926\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=373, train_loss_step=0.014, train_loss_epoch=0.0142] Epoch 349: Train Loss = 0.01395074650645256\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=373, train_loss_step=0.0123, train_loss_epoch=0.014]Epoch 350: Train Loss = 0.012290837243199348\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0123]Epoch 351: Train Loss = 0.01171006727963686\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=373, train_loss_step=0.0111, train_loss_epoch=0.0117]Epoch 352: Train Loss = 0.011068610474467278\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=373, train_loss_step=0.0103, train_loss_epoch=0.0111]Epoch 353: Train Loss = 0.010306908749043941\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=373, train_loss_step=0.0129, train_loss_epoch=0.0103]Epoch 354: Train Loss = 0.012930521741509438\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0129]Epoch 355: Train Loss = 0.011685469187796116\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=373, train_loss_step=0.0122, train_loss_epoch=0.0117]Epoch 356: Train Loss = 0.0121763339266181\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0122]Epoch 357: Train Loss = 0.011945568956434727\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=373, train_loss_step=0.00981, train_loss_epoch=0.0119]Epoch 358: Train Loss = 0.009806938469409943\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=373, train_loss_step=0.0122, train_loss_epoch=0.00981] Epoch 359: Train Loss = 0.012230990454554558\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=373, train_loss_step=0.012, train_loss_epoch=0.0122]  Epoch 360: Train Loss = 0.012048442848026752\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=373, train_loss_step=0.0131, train_loss_epoch=0.012]Epoch 361: Train Loss = 0.013057426549494267\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 13.20it/s, v_num=373, train_loss_step=0.010, train_loss_epoch=0.0131] Epoch 362: Train Loss = 0.010036096908152103\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=373, train_loss_step=0.0155, train_loss_epoch=0.010]Epoch 363: Train Loss = 0.015467907302081585\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=373, train_loss_step=0.0116, train_loss_epoch=0.0155]Epoch 364: Train Loss = 0.011559046804904938\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=373, train_loss_step=0.00822, train_loss_epoch=0.0116]Epoch 365: Train Loss = 0.008223584853112698\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=373, train_loss_step=0.00895, train_loss_epoch=0.00822]Epoch 366: Train Loss = 0.0089491605758667\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.00895] Epoch 367: Train Loss = 0.01183722447603941\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=373, train_loss_step=0.00918, train_loss_epoch=0.0118]Epoch 368: Train Loss = 0.009181619621813297\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.00918] Epoch 369: Train Loss = 0.010851604864001274\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=373, train_loss_step=0.0122, train_loss_epoch=0.0109] Epoch 370: Train Loss = 0.012190715409815311\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0122]Epoch 371: Train Loss = 0.011689521372318268\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0117]Epoch 372: Train Loss = 0.011653229594230652\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 13.22it/s, v_num=373, train_loss_step=0.00582, train_loss_epoch=0.0117]Epoch 373: Train Loss = 0.00581553066149354\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=373, train_loss_step=0.0114, train_loss_epoch=0.00582] Epoch 374: Train Loss = 0.011398998089134693\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=373, train_loss_step=0.00924, train_loss_epoch=0.0114]Epoch 375: Train Loss = 0.009243735112249851\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.00924] Epoch 376: Train Loss = 0.010653789155185223\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=373, train_loss_step=0.00918, train_loss_epoch=0.0107]Epoch 377: Train Loss = 0.009180157445371151\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=373, train_loss_step=0.00966, train_loss_epoch=0.00918]Epoch 378: Train Loss = 0.009662836790084839\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=373, train_loss_step=0.00725, train_loss_epoch=0.00966]Epoch 379: Train Loss = 0.0072457739152014256\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=373, train_loss_step=0.00917, train_loss_epoch=0.00725]Epoch 380: Train Loss = 0.009173023514449596\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=373, train_loss_step=0.0102, train_loss_epoch=0.00917] Epoch 381: Train Loss = 0.01020065601915121\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0102] Epoch 382: Train Loss = 0.011739679612219334\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s, v_num=373, train_loss_step=0.00771, train_loss_epoch=0.0117]Epoch 383: Train Loss = 0.007707218173891306\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.00771] Epoch 384: Train Loss = 0.010874220170080662\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=373, train_loss_step=0.00977, train_loss_epoch=0.0109]Epoch 385: Train Loss = 0.009773582220077515\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=373, train_loss_step=0.0161, train_loss_epoch=0.00977] Epoch 386: Train Loss = 0.01612992212176323\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.0161] Epoch 387: Train Loss = 0.010811863467097282\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=373, train_loss_step=0.00943, train_loss_epoch=0.0108]Epoch 388: Train Loss = 0.00943310558795929\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.00943] Epoch 389: Train Loss = 0.010845491662621498\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=373, train_loss_step=0.00733, train_loss_epoch=0.0108]Epoch 390: Train Loss = 0.007328961510211229\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=373, train_loss_step=0.00849, train_loss_epoch=0.00733]Epoch 391: Train Loss = 0.008487758226692677\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=373, train_loss_step=0.00816, train_loss_epoch=0.00849]Epoch 392: Train Loss = 0.008156617172062397\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=373, train_loss_step=0.0134, train_loss_epoch=0.00816] Epoch 393: Train Loss = 0.013351837173104286\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=373, train_loss_step=0.00936, train_loss_epoch=0.0134]Epoch 394: Train Loss = 0.009362241253256798\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.00936] Epoch 395: Train Loss = 0.011802149936556816\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=373, train_loss_step=0.00834, train_loss_epoch=0.0118]Epoch 396: Train Loss = 0.008340060710906982\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=373, train_loss_step=0.0113, train_loss_epoch=0.00834] Epoch 397: Train Loss = 0.011342606507241726\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=373, train_loss_step=0.0114, train_loss_epoch=0.0113] Epoch 398: Train Loss = 0.011410712264478207\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 13.13it/s, v_num=373, train_loss_step=0.00827, train_loss_epoch=0.0114]Epoch 399: Train Loss = 0.008273548446595669\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=373, train_loss_step=0.010, train_loss_epoch=0.00827]  Epoch 400: Train Loss = 0.010043778456747532\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=373, train_loss_step=0.0103, train_loss_epoch=0.010] Epoch 401: Train Loss = 0.010312208905816078\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=373, train_loss_step=0.0144, train_loss_epoch=0.0103]Epoch 402: Train Loss = 0.01440370548516512\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=373, train_loss_step=0.0134, train_loss_epoch=0.0144]Epoch 403: Train Loss = 0.013442812487483025\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=373, train_loss_step=0.00818, train_loss_epoch=0.0134]Epoch 404: Train Loss = 0.008181004785001278\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=373, train_loss_step=0.0132, train_loss_epoch=0.00818] Epoch 405: Train Loss = 0.013204938732087612\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=373, train_loss_step=0.00918, train_loss_epoch=0.0132]Epoch 406: Train Loss = 0.009177296422421932\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=373, train_loss_step=0.0104, train_loss_epoch=0.00918] Epoch 407: Train Loss = 0.010423554107546806\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0104] Epoch 408: Train Loss = 0.011697926558554173\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=373, train_loss_step=0.00924, train_loss_epoch=0.0117]Epoch 409: Train Loss = 0.00923850666731596\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=373, train_loss_step=0.00896, train_loss_epoch=0.00924]Epoch 410: Train Loss = 0.00895729660987854\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=373, train_loss_step=0.0125, train_loss_epoch=0.00896] Epoch 411: Train Loss = 0.012481559999287128\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=373, train_loss_step=0.0102, train_loss_epoch=0.0125] Epoch 412: Train Loss = 0.010184700600802898\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=373, train_loss_step=0.00936, train_loss_epoch=0.0102]Epoch 413: Train Loss = 0.009355437941849232\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, v_num=373, train_loss_step=0.0128, train_loss_epoch=0.00936] Epoch 414: Train Loss = 0.012789747677743435\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, v_num=373, train_loss_step=0.0108, train_loss_epoch=0.0128] Epoch 415: Train Loss = 0.010835150256752968\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=373, train_loss_step=0.010, train_loss_epoch=0.0108] Epoch 416: Train Loss = 0.010035506449639797\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=373, train_loss_step=0.0121, train_loss_epoch=0.010]Epoch 417: Train Loss = 0.01207516435533762\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=373, train_loss_step=0.00856, train_loss_epoch=0.0121]Epoch 418: Train Loss = 0.008559438399970531\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=373, train_loss_step=0.0137, train_loss_epoch=0.00856] Epoch 419: Train Loss = 0.013689504005014896\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=373, train_loss_step=0.00857, train_loss_epoch=0.0137]Epoch 420: Train Loss = 0.00857155304402113\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=373, train_loss_step=0.0114, train_loss_epoch=0.00857] Epoch 421: Train Loss = 0.011354541406035423\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s, v_num=373, train_loss_step=0.00875, train_loss_epoch=0.0114]Epoch 422: Train Loss = 0.008752910420298576\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=373, train_loss_step=0.0101, train_loss_epoch=0.00875] Epoch 423: Train Loss = 0.010059608146548271\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.0101] Epoch 424: Train Loss = 0.010922267101705074\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=373, train_loss_step=0.00945, train_loss_epoch=0.0109]Epoch 425: Train Loss = 0.009446365758776665\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=373, train_loss_step=0.00957, train_loss_epoch=0.00945]Epoch 426: Train Loss = 0.009566417895257473\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=373, train_loss_step=0.0103, train_loss_epoch=0.00957] Epoch 427: Train Loss = 0.01028346549719572\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=373, train_loss_step=0.0105, train_loss_epoch=0.0103] Epoch 428: Train Loss = 0.010523729957640171\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=373, train_loss_step=0.0102, train_loss_epoch=0.0105]Epoch 429: Train Loss = 0.010209320113062859\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=373, train_loss_step=0.0148, train_loss_epoch=0.0102]Epoch 430: Train Loss = 0.014807699248194695\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.0148] Epoch 431: Train Loss = 0.011044720187783241\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=373, train_loss_step=0.00848, train_loss_epoch=0.011]Epoch 432: Train Loss = 0.008480050601065159\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=373, train_loss_step=0.00703, train_loss_epoch=0.00848]Epoch 433: Train Loss = 0.007028013002127409\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=373, train_loss_step=0.00855, train_loss_epoch=0.00703]Epoch 434: Train Loss = 0.008547415025532246\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s, v_num=373, train_loss_step=0.0112, train_loss_epoch=0.00855] Epoch 435: Train Loss = 0.011233551427721977\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=373, train_loss_step=0.0123, train_loss_epoch=0.0112] Epoch 436: Train Loss = 0.012341619469225407\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=373, train_loss_step=0.0116, train_loss_epoch=0.0123]Epoch 437: Train Loss = 0.01160187367349863\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.0116]Epoch 438: Train Loss = 0.010705361142754555\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.0107]Epoch 439: Train Loss = 0.01179627887904644\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.0118] Epoch 440: Train Loss = 0.011044333688914776\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=373, train_loss_step=0.0116, train_loss_epoch=0.011]Epoch 441: Train Loss = 0.011633838526904583\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=373, train_loss_step=0.00789, train_loss_epoch=0.0116]Epoch 442: Train Loss = 0.007890907116234303\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s, v_num=373, train_loss_step=0.00943, train_loss_epoch=0.00789]Epoch 443: Train Loss = 0.009426966309547424\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=373, train_loss_step=0.00889, train_loss_epoch=0.00943]Epoch 444: Train Loss = 0.008889653719961643\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=373, train_loss_step=0.0122, train_loss_epoch=0.00889] Epoch 445: Train Loss = 0.012180541642010212\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=373, train_loss_step=0.0131, train_loss_epoch=0.0122] Epoch 446: Train Loss = 0.013072377070784569\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.0131]Epoch 447: Train Loss = 0.010863745585083961\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=373, train_loss_step=0.00851, train_loss_epoch=0.0109]Epoch 448: Train Loss = 0.00851087924093008\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=373, train_loss_step=0.0105, train_loss_epoch=0.00851] Epoch 449: Train Loss = 0.010493375360965729\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=373, train_loss_step=0.00991, train_loss_epoch=0.0105]Epoch 450: Train Loss = 0.009909363463521004\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=373, train_loss_step=0.0105, train_loss_epoch=0.00991] Epoch 451: Train Loss = 0.010534273460507393\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=373, train_loss_step=0.0103, train_loss_epoch=0.0105] Epoch 452: Train Loss = 0.01030039880424738\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=373, train_loss_step=0.0128, train_loss_epoch=0.0103]Epoch 453: Train Loss = 0.012785964645445347\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=373, train_loss_step=0.00845, train_loss_epoch=0.0128]Epoch 454: Train Loss = 0.008447027765214443\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s, v_num=373, train_loss_step=0.00734, train_loss_epoch=0.00845]Epoch 455: Train Loss = 0.007336396723985672\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=373, train_loss_step=0.00897, train_loss_epoch=0.00734]Epoch 456: Train Loss = 0.008967923000454903\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=373, train_loss_step=0.011, train_loss_epoch=0.00897]  Epoch 457: Train Loss = 0.01098532136529684\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=373, train_loss_step=0.00937, train_loss_epoch=0.011]Epoch 458: Train Loss = 0.00937481690198183\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.00937] Epoch 459: Train Loss = 0.011758411303162575\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=373, train_loss_step=0.00891, train_loss_epoch=0.0118]Epoch 460: Train Loss = 0.008911756798624992\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 13.30it/s, v_num=373, train_loss_step=0.00808, train_loss_epoch=0.00891]Epoch 461: Train Loss = 0.00807748269289732\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=373, train_loss_step=0.00903, train_loss_epoch=0.00808]Epoch 462: Train Loss = 0.0090306606143713\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=373, train_loss_step=0.0121, train_loss_epoch=0.00903] Epoch 463: Train Loss = 0.012109167873859406\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=373, train_loss_step=0.00809, train_loss_epoch=0.0121]Epoch 464: Train Loss = 0.008089707233011723\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=373, train_loss_step=0.00923, train_loss_epoch=0.00809]Epoch 465: Train Loss = 0.009234420955181122\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=373, train_loss_step=0.00869, train_loss_epoch=0.00923]Epoch 466: Train Loss = 0.008685075677931309\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=373, train_loss_step=0.00903, train_loss_epoch=0.00869]Epoch 467: Train Loss = 0.009026801213622093\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.00903] Epoch 468: Train Loss = 0.010662056505680084\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=373, train_loss_step=0.0111, train_loss_epoch=0.0107] Epoch 469: Train Loss = 0.011053786613047123\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=373, train_loss_step=0.00975, train_loss_epoch=0.0111]Epoch 470: Train Loss = 0.009754134342074394\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=373, train_loss_step=0.0101, train_loss_epoch=0.00975] Epoch 471: Train Loss = 0.010109453462064266\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=373, train_loss_step=0.0107, train_loss_epoch=0.0101] Epoch 472: Train Loss = 0.010745497420430183\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=373, train_loss_step=0.00874, train_loss_epoch=0.0107]Epoch 473: Train Loss = 0.008742050267755985\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=373, train_loss_step=0.0136, train_loss_epoch=0.00874] Epoch 474: Train Loss = 0.013613404706120491\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=373, train_loss_step=0.0105, train_loss_epoch=0.0136] Epoch 475: Train Loss = 0.010471981950104237\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=373, train_loss_step=0.0109, train_loss_epoch=0.0105]Epoch 476: Train Loss = 0.010896728374063969\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=373, train_loss_step=0.0128, train_loss_epoch=0.0109]Epoch 477: Train Loss = 0.012844031676650047\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 12.90it/s, v_num=373, train_loss_step=0.00938, train_loss_epoch=0.0128]Epoch 478: Train Loss = 0.009382769465446472\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=373, train_loss_step=0.00969, train_loss_epoch=0.00938]Epoch 479: Train Loss = 0.00968897994607687\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=373, train_loss_step=0.0115, train_loss_epoch=0.00969] Epoch 480: Train Loss = 0.011482234112918377\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=373, train_loss_step=0.0119, train_loss_epoch=0.0115] Epoch 481: Train Loss = 0.011912090703845024\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=373, train_loss_step=0.00941, train_loss_epoch=0.0119]Epoch 482: Train Loss = 0.009411275386810303\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=373, train_loss_step=0.00781, train_loss_epoch=0.00941]Epoch 483: Train Loss = 0.007807212416082621\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=373, train_loss_step=0.0101, train_loss_epoch=0.00781] Epoch 484: Train Loss = 0.010098910890519619\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=373, train_loss_step=0.0118, train_loss_epoch=0.0101] Epoch 485: Train Loss = 0.011781767010688782\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=373, train_loss_step=0.0105, train_loss_epoch=0.0118]Epoch 486: Train Loss = 0.010529009625315666\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=373, train_loss_step=0.00835, train_loss_epoch=0.0105]Epoch 487: Train Loss = 0.008347591385245323\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=373, train_loss_step=0.00994, train_loss_epoch=0.00835]Epoch 488: Train Loss = 0.009936107322573662\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=373, train_loss_step=0.010, train_loss_epoch=0.00994]  Epoch 489: Train Loss = 0.010021314956247807\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s, v_num=373, train_loss_step=0.0146, train_loss_epoch=0.010] Epoch 490: Train Loss = 0.014575280249118805\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, v_num=373, train_loss_step=0.0116, train_loss_epoch=0.0146]Epoch 491: Train Loss = 0.011551210656762123\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=373, train_loss_step=0.0126, train_loss_epoch=0.0116]Epoch 492: Train Loss = 0.012570281513035297\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=373, train_loss_step=0.0111, train_loss_epoch=0.0126]Epoch 493: Train Loss = 0.011112972162663937\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 13.60it/s, v_num=373, train_loss_step=0.0102, train_loss_epoch=0.0111]Epoch 494: Train Loss = 0.010202338919043541\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 13.60it/s, v_num=373, train_loss_step=0.00949, train_loss_epoch=0.0102]Epoch 495: Train Loss = 0.009492666460573673\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 13.45it/s, v_num=373, train_loss_step=0.0104, train_loss_epoch=0.00949] Epoch 496: Train Loss = 0.010411662980914116\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=373, train_loss_step=0.0085, train_loss_epoch=0.0104] Epoch 497: Train Loss = 0.008498727343976498\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=373, train_loss_step=0.00904, train_loss_epoch=0.0085]Epoch 498: Train Loss = 0.00904124230146408\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.00904] Epoch 499: Train Loss = 0.01173254195600748\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0117] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s, v_num=373, train_loss_step=0.0117, train_loss_epoch=0.0117]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 17: from 2008-05-12 00:00:00 to 2022-12-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=375, train_loss_step=0.0177]Epoch 0: Train Loss = 0.017731260508298874\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=375, train_loss_step=0.0382, train_loss_epoch=0.0177]Epoch 1: Train Loss = 0.03818603605031967\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=375, train_loss_step=0.0282, train_loss_epoch=0.0382]Epoch 2: Train Loss = 0.02822360023856163\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=375, train_loss_step=0.0164, train_loss_epoch=0.0282]Epoch 3: Train Loss = 0.01637287251651287\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=375, train_loss_step=0.0231, train_loss_epoch=0.0164]Epoch 4: Train Loss = 0.023096146062016487\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=375, train_loss_step=0.0238, train_loss_epoch=0.0231]Epoch 5: Train Loss = 0.023750152438879013\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=375, train_loss_step=0.0206, train_loss_epoch=0.0238]Epoch 6: Train Loss = 0.020561987534165382\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=375, train_loss_step=0.0163, train_loss_epoch=0.0206]Epoch 7: Train Loss = 0.016267655417323112\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=375, train_loss_step=0.015, train_loss_epoch=0.0163] Epoch 8: Train Loss = 0.01500959787517786\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=375, train_loss_step=0.0136, train_loss_epoch=0.015]Epoch 9: Train Loss = 0.013608657754957676\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=375, train_loss_step=0.014, train_loss_epoch=0.0136] Epoch 10: Train Loss = 0.014019222930073738\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=375, train_loss_step=0.0141, train_loss_epoch=0.014]Epoch 11: Train Loss = 0.014136705547571182\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=375, train_loss_step=0.0134, train_loss_epoch=0.0141]Epoch 12: Train Loss = 0.013443776406347752\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=375, train_loss_step=0.0132, train_loss_epoch=0.0134]Epoch 13: Train Loss = 0.013164336793124676\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=375, train_loss_step=0.0126, train_loss_epoch=0.0132]Epoch 14: Train Loss = 0.01255644578486681\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.0126]Epoch 15: Train Loss = 0.012458008714020252\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=375, train_loss_step=0.0138, train_loss_epoch=0.0125]Epoch 16: Train Loss = 0.013825049623847008\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=375, train_loss_step=0.0151, train_loss_epoch=0.0138]Epoch 17: Train Loss = 0.01506863534450531\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=375, train_loss_step=0.0126, train_loss_epoch=0.0151]Epoch 18: Train Loss = 0.012588524259626865\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=375, train_loss_step=0.012, train_loss_epoch=0.0126] Epoch 19: Train Loss = 0.012016406282782555\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=375, train_loss_step=0.0126, train_loss_epoch=0.012]Epoch 20: Train Loss = 0.012552293948829174\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 16.60it/s, v_num=375, train_loss_step=0.0124, train_loss_epoch=0.0126]Epoch 21: Train Loss = 0.012439570389688015\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=375, train_loss_step=0.0155, train_loss_epoch=0.0124]Epoch 22: Train Loss = 0.015521843917667866\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=375, train_loss_step=0.011, train_loss_epoch=0.0155] Epoch 23: Train Loss = 0.011021710932254791\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=375, train_loss_step=0.00778, train_loss_epoch=0.011]Epoch 24: Train Loss = 0.0077845449559390545\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=375, train_loss_step=0.00959, train_loss_epoch=0.00778]Epoch 25: Train Loss = 0.009586241096258163\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, v_num=375, train_loss_step=0.0148, train_loss_epoch=0.00959] Epoch 26: Train Loss = 0.01479768194258213\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.0148] Epoch 27: Train Loss = 0.012521849013864994\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0125]Epoch 28: Train Loss = 0.010139320977032185\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 16.64it/s, v_num=375, train_loss_step=0.0151, train_loss_epoch=0.0101]Epoch 29: Train Loss = 0.015102805569767952\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=375, train_loss_step=0.0123, train_loss_epoch=0.0151]Epoch 30: Train Loss = 0.012344379909336567\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=375, train_loss_step=0.0129, train_loss_epoch=0.0123]Epoch 31: Train Loss = 0.012869035825133324\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=375, train_loss_step=0.0181, train_loss_epoch=0.0129]Epoch 32: Train Loss = 0.018146613612771034\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.0181]Epoch 33: Train Loss = 0.0108022540807724\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, v_num=375, train_loss_step=0.016, train_loss_epoch=0.0108] Epoch 34: Train Loss = 0.016012711450457573\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, v_num=375, train_loss_step=0.0105, train_loss_epoch=0.016]Epoch 35: Train Loss = 0.010467843152582645\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=375, train_loss_step=0.0111, train_loss_epoch=0.0105]Epoch 36: Train Loss = 0.011078749783337116\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=375, train_loss_step=0.0117, train_loss_epoch=0.0111]Epoch 37: Train Loss = 0.011656992137432098\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=375, train_loss_step=0.0124, train_loss_epoch=0.0117]Epoch 38: Train Loss = 0.012414397671818733\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=375, train_loss_step=0.0143, train_loss_epoch=0.0124]Epoch 39: Train Loss = 0.014261717908084393\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=375, train_loss_step=0.0129, train_loss_epoch=0.0143]Epoch 40: Train Loss = 0.012885856442153454\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=375, train_loss_step=0.0134, train_loss_epoch=0.0129]Epoch 41: Train Loss = 0.013433367945253849\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=375, train_loss_step=0.0105, train_loss_epoch=0.0134]Epoch 42: Train Loss = 0.01047959178686142\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.0105]Epoch 43: Train Loss = 0.01084944885224104\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=375, train_loss_step=0.011, train_loss_epoch=0.0108] Epoch 44: Train Loss = 0.01102251373231411\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 16.28it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.011]Epoch 45: Train Loss = 0.011525453068315983\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=375, train_loss_step=0.0119, train_loss_epoch=0.0115]Epoch 46: Train Loss = 0.011922351084649563\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=375, train_loss_step=0.00979, train_loss_epoch=0.0119]Epoch 47: Train Loss = 0.009785695001482964\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=375, train_loss_step=0.0154, train_loss_epoch=0.00979] Epoch 48: Train Loss = 0.015447051264345646\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.0154] Epoch 49: Train Loss = 0.012536321766674519\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=375, train_loss_step=0.016, train_loss_epoch=0.0125] Epoch 50: Train Loss = 0.015982093289494514\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 16.55it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.016]Epoch 51: Train Loss = 0.012495117262005806\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=375, train_loss_step=0.0146, train_loss_epoch=0.0125]Epoch 52: Train Loss = 0.0146168302744627\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=375, train_loss_step=0.0128, train_loss_epoch=0.0146]Epoch 53: Train Loss = 0.012815403752028942\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=375, train_loss_step=0.00993, train_loss_epoch=0.0128]Epoch 54: Train Loss = 0.009932426735758781\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=375, train_loss_step=0.0113, train_loss_epoch=0.00993] Epoch 55: Train Loss = 0.011309081688523293\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=375, train_loss_step=0.0123, train_loss_epoch=0.0113] Epoch 56: Train Loss = 0.012260696850717068\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=375, train_loss_step=0.0131, train_loss_epoch=0.0123]Epoch 57: Train Loss = 0.013075307011604309\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=375, train_loss_step=0.0122, train_loss_epoch=0.0131]Epoch 58: Train Loss = 0.012231739237904549\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=375, train_loss_step=0.0106, train_loss_epoch=0.0122]Epoch 59: Train Loss = 0.01058779377490282\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=375, train_loss_step=0.0155, train_loss_epoch=0.0106]Epoch 60: Train Loss = 0.015479760244488716\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=375, train_loss_step=0.0144, train_loss_epoch=0.0155]Epoch 61: Train Loss = 0.014407015405595303\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=375, train_loss_step=0.0107, train_loss_epoch=0.0144]Epoch 62: Train Loss = 0.010683340020477772\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=375, train_loss_step=0.0121, train_loss_epoch=0.0107]Epoch 63: Train Loss = 0.012117086909711361\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=375, train_loss_step=0.0102, train_loss_epoch=0.0121]Epoch 64: Train Loss = 0.010242914780974388\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=375, train_loss_step=0.0117, train_loss_epoch=0.0102]Epoch 65: Train Loss = 0.011673837900161743\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=375, train_loss_step=0.0124, train_loss_epoch=0.0117]Epoch 66: Train Loss = 0.01235357765108347\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.0124]Epoch 67: Train Loss = 0.012544750235974789\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=375, train_loss_step=0.0105, train_loss_epoch=0.0125]Epoch 68: Train Loss = 0.010509312152862549\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=375, train_loss_step=0.00879, train_loss_epoch=0.0105]Epoch 69: Train Loss = 0.008789615705609322\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=375, train_loss_step=0.0107, train_loss_epoch=0.00879] Epoch 70: Train Loss = 0.01071690022945404\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=375, train_loss_step=0.0142, train_loss_epoch=0.0107] Epoch 71: Train Loss = 0.014243057928979397\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=375, train_loss_step=0.0148, train_loss_epoch=0.0142]Epoch 72: Train Loss = 0.014813445508480072\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=375, train_loss_step=0.0121, train_loss_epoch=0.0148]Epoch 73: Train Loss = 0.012111491523683071\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=375, train_loss_step=0.0121, train_loss_epoch=0.0121]Epoch 74: Train Loss = 0.012128109112381935\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s, v_num=375, train_loss_step=0.0131, train_loss_epoch=0.0121]Epoch 75: Train Loss = 0.013139421120285988\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=375, train_loss_step=0.0102, train_loss_epoch=0.0131]Epoch 76: Train Loss = 0.01017389353364706\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=375, train_loss_step=0.0153, train_loss_epoch=0.0102]Epoch 77: Train Loss = 0.015310779213905334\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0153]Epoch 78: Train Loss = 0.01007886417210102\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=375, train_loss_step=0.0168, train_loss_epoch=0.0101]Epoch 79: Train Loss = 0.016790371388196945\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0168]Epoch 80: Train Loss = 0.010094192810356617\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 16.07it/s, v_num=375, train_loss_step=0.0106, train_loss_epoch=0.0101]Epoch 81: Train Loss = 0.010554416105151176\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.0106]Epoch 82: Train Loss = 0.01248218584805727\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 13.60it/s, v_num=375, train_loss_step=0.0124, train_loss_epoch=0.0125]Epoch 83: Train Loss = 0.012404980137944221\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=375, train_loss_step=0.00973, train_loss_epoch=0.0124]Epoch 84: Train Loss = 0.009727495722472668\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=375, train_loss_step=0.010, train_loss_epoch=0.00973]  Epoch 85: Train Loss = 0.010014556348323822\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=375, train_loss_step=0.0145, train_loss_epoch=0.010] Epoch 86: Train Loss = 0.014473632909357548\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.0145]Epoch 87: Train Loss = 0.01137391384691\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0114]Epoch 88: Train Loss = 0.011490766890347004\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=375, train_loss_step=0.0124, train_loss_epoch=0.0115]Epoch 89: Train Loss = 0.012350424192845821\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=375, train_loss_step=0.0123, train_loss_epoch=0.0124]Epoch 90: Train Loss = 0.01226653903722763\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=375, train_loss_step=0.00901, train_loss_epoch=0.0123]Epoch 91: Train Loss = 0.009008839726448059\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=375, train_loss_step=0.0138, train_loss_epoch=0.00901] Epoch 92: Train Loss = 0.013780609704554081\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=375, train_loss_step=0.0146, train_loss_epoch=0.0138] Epoch 93: Train Loss = 0.014599068090319633\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=375, train_loss_step=0.00792, train_loss_epoch=0.0146]Epoch 94: Train Loss = 0.007920843549072742\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=375, train_loss_step=0.0112, train_loss_epoch=0.00792] Epoch 95: Train Loss = 0.011205362156033516\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=375, train_loss_step=0.00882, train_loss_epoch=0.0112]Epoch 96: Train Loss = 0.008815334178507328\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=375, train_loss_step=0.00982, train_loss_epoch=0.00882]Epoch 97: Train Loss = 0.009823644533753395\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, v_num=375, train_loss_step=0.011, train_loss_epoch=0.00982]  Epoch 98: Train Loss = 0.010970862582325935\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.011] Epoch 99: Train Loss = 0.010853703133761883\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=375, train_loss_step=0.0112, train_loss_epoch=0.0109]Epoch 100: Train Loss = 0.011157914996147156\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=375, train_loss_step=0.0118, train_loss_epoch=0.0112]Epoch 101: Train Loss = 0.011754268780350685\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 16.02it/s, v_num=375, train_loss_step=0.0112, train_loss_epoch=0.0118]Epoch 102: Train Loss = 0.011221950873732567\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 16.64it/s, v_num=375, train_loss_step=0.0106, train_loss_epoch=0.0112]Epoch 103: Train Loss = 0.0106278071179986\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 17.36it/s, v_num=375, train_loss_step=0.0106, train_loss_epoch=0.0106]Epoch 104: Train Loss = 0.010605894960463047\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=375, train_loss_step=0.00885, train_loss_epoch=0.0106]Epoch 105: Train Loss = 0.008852479048073292\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=375, train_loss_step=0.0105, train_loss_epoch=0.00885] Epoch 106: Train Loss = 0.010469869710505009\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.0105] Epoch 107: Train Loss = 0.012664525769650936\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=375, train_loss_step=0.0111, train_loss_epoch=0.0127]Epoch 108: Train Loss = 0.011089389212429523\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=375, train_loss_step=0.0134, train_loss_epoch=0.0111]Epoch 109: Train Loss = 0.01339174248278141\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0134]Epoch 110: Train Loss = 0.01152742374688387\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=375, train_loss_step=0.00983, train_loss_epoch=0.0115]Epoch 111: Train Loss = 0.009834811091423035\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=375, train_loss_step=0.0141, train_loss_epoch=0.00983] Epoch 112: Train Loss = 0.014088227413594723\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.0141] Epoch 113: Train Loss = 0.01137740258127451\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.0114]Epoch 114: Train Loss = 0.012453888542950153\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.0125]Epoch 115: Train Loss = 0.010840498842298985\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=375, train_loss_step=0.0122, train_loss_epoch=0.0108]Epoch 116: Train Loss = 0.012224902398884296\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=375, train_loss_step=0.0151, train_loss_epoch=0.0122]Epoch 117: Train Loss = 0.015062903985381126\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=375, train_loss_step=0.0123, train_loss_epoch=0.0151]Epoch 118: Train Loss = 0.012268438003957272\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 16.92it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.0123]Epoch 119: Train Loss = 0.012664535082876682\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=375, train_loss_step=0.00996, train_loss_epoch=0.0127]Epoch 120: Train Loss = 0.009961159899830818\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 16.73it/s, v_num=375, train_loss_step=0.0103, train_loss_epoch=0.00996] Epoch 121: Train Loss = 0.010258923284709454\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=375, train_loss_step=0.013, train_loss_epoch=0.0103]  Epoch 122: Train Loss = 0.012983816675841808\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, v_num=375, train_loss_step=0.00883, train_loss_epoch=0.013]Epoch 123: Train Loss = 0.00882894080132246\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.00883] Epoch 124: Train Loss = 0.01091796439141035\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=375, train_loss_step=0.0119, train_loss_epoch=0.0109] Epoch 125: Train Loss = 0.011885815300047398\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=375, train_loss_step=0.0116, train_loss_epoch=0.0119]Epoch 126: Train Loss = 0.011631546542048454\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=375, train_loss_step=0.0112, train_loss_epoch=0.0116]Epoch 127: Train Loss = 0.011202218942344189\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=375, train_loss_step=0.0152, train_loss_epoch=0.0112]Epoch 128: Train Loss = 0.015154368244111538\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s, v_num=375, train_loss_step=0.0132, train_loss_epoch=0.0152]Epoch 129: Train Loss = 0.01321761030703783\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, v_num=375, train_loss_step=0.0116, train_loss_epoch=0.0132]Epoch 130: Train Loss = 0.01156389620155096\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=375, train_loss_step=0.0119, train_loss_epoch=0.0116]Epoch 131: Train Loss = 0.011878094635903835\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=375, train_loss_step=0.0121, train_loss_epoch=0.0119]Epoch 132: Train Loss = 0.012126488611102104\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=375, train_loss_step=0.0136, train_loss_epoch=0.0121]Epoch 133: Train Loss = 0.013598263263702393\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 13.91it/s, v_num=375, train_loss_step=0.0131, train_loss_epoch=0.0136]Epoch 134: Train Loss = 0.013093489222228527\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=375, train_loss_step=0.0131, train_loss_epoch=0.0131]Epoch 135: Train Loss = 0.013070746324956417\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=375, train_loss_step=0.0134, train_loss_epoch=0.0131]Epoch 136: Train Loss = 0.013396534137427807\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=375, train_loss_step=0.00871, train_loss_epoch=0.0134]Epoch 137: Train Loss = 0.008705325424671173\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=375, train_loss_step=0.013, train_loss_epoch=0.00871]  Epoch 138: Train Loss = 0.012999356724321842\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s, v_num=375, train_loss_step=0.0119, train_loss_epoch=0.013] Epoch 139: Train Loss = 0.0119226248934865\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.0119]Epoch 140: Train Loss = 0.01268796343356371\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=375, train_loss_step=0.0129, train_loss_epoch=0.0127]Epoch 141: Train Loss = 0.012857018038630486\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.0129]Epoch 142: Train Loss = 0.012704899534583092\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=375, train_loss_step=0.0158, train_loss_epoch=0.0127]Epoch 143: Train Loss = 0.015818962827324867\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s, v_num=375, train_loss_step=0.0139, train_loss_epoch=0.0158]Epoch 144: Train Loss = 0.013916583731770515\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=375, train_loss_step=0.0131, train_loss_epoch=0.0139]Epoch 145: Train Loss = 0.013126962818205357\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.0131]Epoch 146: Train Loss = 0.010921589098870754\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.0109]Epoch 147: Train Loss = 0.010837463662028313\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.0108]Epoch 148: Train Loss = 0.010791071690618992\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=375, train_loss_step=0.0164, train_loss_epoch=0.0108]Epoch 149: Train Loss = 0.016406672075390816\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.0164]Epoch 150: Train Loss = 0.01083125825971365\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=375, train_loss_step=0.0126, train_loss_epoch=0.0108]Epoch 151: Train Loss = 0.012612809427082539\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=375, train_loss_step=0.0134, train_loss_epoch=0.0126]Epoch 152: Train Loss = 0.013352771289646626\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=375, train_loss_step=0.0154, train_loss_epoch=0.0134]Epoch 153: Train Loss = 0.015409472398459911\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=375, train_loss_step=0.0133, train_loss_epoch=0.0154]Epoch 154: Train Loss = 0.013314381241798401\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, v_num=375, train_loss_step=0.0152, train_loss_epoch=0.0133]Epoch 155: Train Loss = 0.015170061960816383\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s, v_num=375, train_loss_step=0.00962, train_loss_epoch=0.0152]Epoch 156: Train Loss = 0.00961976032704115\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=375, train_loss_step=0.0132, train_loss_epoch=0.00962] Epoch 157: Train Loss = 0.013171084225177765\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=375, train_loss_step=0.0128, train_loss_epoch=0.0132] Epoch 158: Train Loss = 0.012805379927158356\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.0128]Epoch 159: Train Loss = 0.012480762787163258\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=375, train_loss_step=0.0122, train_loss_epoch=0.0125]Epoch 160: Train Loss = 0.012220076285302639\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 16.11it/s, v_num=375, train_loss_step=0.0168, train_loss_epoch=0.0122]Epoch 161: Train Loss = 0.01678290031850338\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=375, train_loss_step=0.0106, train_loss_epoch=0.0168]Epoch 162: Train Loss = 0.010606995783746243\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=375, train_loss_step=0.00836, train_loss_epoch=0.0106]Epoch 163: Train Loss = 0.00836022850126028\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=375, train_loss_step=0.00804, train_loss_epoch=0.00836]Epoch 164: Train Loss = 0.008040991611778736\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=375, train_loss_step=0.00945, train_loss_epoch=0.00804]Epoch 165: Train Loss = 0.009445603005588055\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=375, train_loss_step=0.0141, train_loss_epoch=0.00945] Epoch 166: Train Loss = 0.014082000590860844\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=375, train_loss_step=0.0113, train_loss_epoch=0.0141] Epoch 167: Train Loss = 0.011271885596215725\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=375, train_loss_step=0.00905, train_loss_epoch=0.0113]Epoch 168: Train Loss = 0.009045004844665527\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=375, train_loss_step=0.0118, train_loss_epoch=0.00905] Epoch 169: Train Loss = 0.011829463765025139\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=375, train_loss_step=0.00877, train_loss_epoch=0.0118]Epoch 170: Train Loss = 0.00876984279602766\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=375, train_loss_step=0.00907, train_loss_epoch=0.00877]Epoch 171: Train Loss = 0.00907242763787508\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=375, train_loss_step=0.0107, train_loss_epoch=0.00907] Epoch 172: Train Loss = 0.010654451325535774\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=375, train_loss_step=0.00855, train_loss_epoch=0.0107]Epoch 173: Train Loss = 0.008546425960958004\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=375, train_loss_step=0.0107, train_loss_epoch=0.00855] Epoch 174: Train Loss = 0.010678806342184544\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=375, train_loss_step=0.013, train_loss_epoch=0.0107]  Epoch 175: Train Loss = 0.01302326563745737\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=375, train_loss_step=0.0118, train_loss_epoch=0.013]Epoch 176: Train Loss = 0.011767787858843803\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=375, train_loss_step=0.00811, train_loss_epoch=0.0118]Epoch 177: Train Loss = 0.008110658265650272\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=375, train_loss_step=0.0113, train_loss_epoch=0.00811] Epoch 178: Train Loss = 0.011278592981398106\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=375, train_loss_step=0.011, train_loss_epoch=0.0113]  Epoch 179: Train Loss = 0.010970362462103367\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=375, train_loss_step=0.0097, train_loss_epoch=0.011]Epoch 180: Train Loss = 0.0096976887434721\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=375, train_loss_step=0.0116, train_loss_epoch=0.0097]Epoch 181: Train Loss = 0.011562689207494259\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=375, train_loss_step=0.00949, train_loss_epoch=0.0116]Epoch 182: Train Loss = 0.009492737241089344\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=375, train_loss_step=0.0103, train_loss_epoch=0.00949] Epoch 183: Train Loss = 0.010255811735987663\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=375, train_loss_step=0.0154, train_loss_epoch=0.0103] Epoch 184: Train Loss = 0.015442689880728722\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=375, train_loss_step=0.0103, train_loss_epoch=0.0154]Epoch 185: Train Loss = 0.01031860988587141\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s, v_num=375, train_loss_step=0.0118, train_loss_epoch=0.0103]Epoch 186: Train Loss = 0.011757980100810528\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=375, train_loss_step=0.0121, train_loss_epoch=0.0118]Epoch 187: Train Loss = 0.012113884091377258\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=375, train_loss_step=0.00901, train_loss_epoch=0.0121]Epoch 188: Train Loss = 0.009007183834910393\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.00901] Epoch 189: Train Loss = 0.01081803534179926\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=375, train_loss_step=0.0121, train_loss_epoch=0.0108] Epoch 190: Train Loss = 0.012125133536756039\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=375, train_loss_step=0.00869, train_loss_epoch=0.0121]Epoch 191: Train Loss = 0.008688731119036674\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=375, train_loss_step=0.00897, train_loss_epoch=0.00869]Epoch 192: Train Loss = 0.008973940275609493\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=375, train_loss_step=0.0167, train_loss_epoch=0.00897] Epoch 193: Train Loss = 0.01670343056321144\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=375, train_loss_step=0.00999, train_loss_epoch=0.0167]Epoch 194: Train Loss = 0.009989678859710693\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 13.88it/s, v_num=375, train_loss_step=0.014, train_loss_epoch=0.00999]  Epoch 195: Train Loss = 0.014002992771565914\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=375, train_loss_step=0.0103, train_loss_epoch=0.014] Epoch 196: Train Loss = 0.010325474664568901\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=375, train_loss_step=0.0106, train_loss_epoch=0.0103]Epoch 197: Train Loss = 0.010626948438584805\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s, v_num=375, train_loss_step=0.0144, train_loss_epoch=0.0106]Epoch 198: Train Loss = 0.014407818205654621\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=375, train_loss_step=0.00969, train_loss_epoch=0.0144]Epoch 199: Train Loss = 0.009686562232673168\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=375, train_loss_step=0.00789, train_loss_epoch=0.00969]Epoch 200: Train Loss = 0.007894732989370823\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=375, train_loss_step=0.00875, train_loss_epoch=0.00789]Epoch 201: Train Loss = 0.008747500367462635\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=375, train_loss_step=0.00949, train_loss_epoch=0.00875]Epoch 202: Train Loss = 0.009489739313721657\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=375, train_loss_step=0.00802, train_loss_epoch=0.00949]Epoch 203: Train Loss = 0.008023201487958431\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=375, train_loss_step=0.00775, train_loss_epoch=0.00802]Epoch 204: Train Loss = 0.007748883683234453\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=375, train_loss_step=0.00936, train_loss_epoch=0.00775]Epoch 205: Train Loss = 0.009355304762721062\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=375, train_loss_step=0.00984, train_loss_epoch=0.00936]Epoch 206: Train Loss = 0.009843758307397366\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.00984] Epoch 207: Train Loss = 0.010860445909202099\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=375, train_loss_step=0.0124, train_loss_epoch=0.0109] Epoch 208: Train Loss = 0.01241203211247921\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, v_num=375, train_loss_step=0.0103, train_loss_epoch=0.0124]Epoch 209: Train Loss = 0.010273146443068981\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=375, train_loss_step=0.00834, train_loss_epoch=0.0103]Epoch 210: Train Loss = 0.008344323374330997\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=375, train_loss_step=0.010, train_loss_epoch=0.00834]  Epoch 211: Train Loss = 0.010023212060332298\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=375, train_loss_step=0.00932, train_loss_epoch=0.010]Epoch 212: Train Loss = 0.009318741038441658\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=375, train_loss_step=0.012, train_loss_epoch=0.00932]  Epoch 213: Train Loss = 0.011985989287495613\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=375, train_loss_step=0.011, train_loss_epoch=0.012]  Epoch 214: Train Loss = 0.01095681730657816\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=375, train_loss_step=0.00996, train_loss_epoch=0.011]Epoch 215: Train Loss = 0.009963010437786579\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=375, train_loss_step=0.00902, train_loss_epoch=0.00996]Epoch 216: Train Loss = 0.009022889658808708\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=375, train_loss_step=0.00976, train_loss_epoch=0.00902]Epoch 217: Train Loss = 0.009764626622200012\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=375, train_loss_step=0.0102, train_loss_epoch=0.00976] Epoch 218: Train Loss = 0.010196560993790627\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.0102] Epoch 219: Train Loss = 0.01086057722568512\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.0109]Epoch 220: Train Loss = 0.01043095625936985\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=375, train_loss_step=0.00911, train_loss_epoch=0.0104]Epoch 221: Train Loss = 0.009109936654567719\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=375, train_loss_step=0.00923, train_loss_epoch=0.00911]Epoch 222: Train Loss = 0.009230253286659718\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.00923] Epoch 223: Train Loss = 0.012671103700995445\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=375, train_loss_step=0.0129, train_loss_epoch=0.0127] Epoch 224: Train Loss = 0.012892862781882286\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=375, train_loss_step=0.0121, train_loss_epoch=0.0129]Epoch 225: Train Loss = 0.012125213630497456\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s, v_num=375, train_loss_step=0.0111, train_loss_epoch=0.0121]Epoch 226: Train Loss = 0.011143828742206097\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 14.12it/s, v_num=375, train_loss_step=0.012, train_loss_epoch=0.0111] Epoch 227: Train Loss = 0.012029625475406647\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=375, train_loss_step=0.0103, train_loss_epoch=0.012]Epoch 228: Train Loss = 0.01031583547592163\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=375, train_loss_step=0.00926, train_loss_epoch=0.0103]Epoch 229: Train Loss = 0.009257672354578972\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=375, train_loss_step=0.0146, train_loss_epoch=0.00926] Epoch 230: Train Loss = 0.014632187783718109\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.0146] Epoch 231: Train Loss = 0.010810346342623234\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=375, train_loss_step=0.0138, train_loss_epoch=0.0108]Epoch 232: Train Loss = 0.013768204487860203\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.0138]Epoch 233: Train Loss = 0.012749127112329006\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=375, train_loss_step=0.0139, train_loss_epoch=0.0127]Epoch 234: Train Loss = 0.013884522020816803\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.0139]Epoch 235: Train Loss = 0.010377676226198673\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=375, train_loss_step=0.00839, train_loss_epoch=0.0104]Epoch 236: Train Loss = 0.008391288109123707\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=375, train_loss_step=0.00968, train_loss_epoch=0.00839]Epoch 237: Train Loss = 0.009683465585112572\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=375, train_loss_step=0.0154, train_loss_epoch=0.00968] Epoch 238: Train Loss = 0.015436510555446148\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=375, train_loss_step=0.00921, train_loss_epoch=0.0154]Epoch 239: Train Loss = 0.009206765331327915\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=375, train_loss_step=0.0102, train_loss_epoch=0.00921] Epoch 240: Train Loss = 0.0102164875715971\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=375, train_loss_step=0.00877, train_loss_epoch=0.0102]Epoch 241: Train Loss = 0.008771034888923168\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=375, train_loss_step=0.00799, train_loss_epoch=0.00877]Epoch 242: Train Loss = 0.007994601503014565\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=375, train_loss_step=0.0102, train_loss_epoch=0.00799] Epoch 243: Train Loss = 0.01016570907086134\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=375, train_loss_step=0.0107, train_loss_epoch=0.0102] Epoch 244: Train Loss = 0.010737642645835876\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=375, train_loss_step=0.0144, train_loss_epoch=0.0107]Epoch 245: Train Loss = 0.014388250187039375\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=375, train_loss_step=0.0105, train_loss_epoch=0.0144]Epoch 246: Train Loss = 0.010541395284235477\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=375, train_loss_step=0.0119, train_loss_epoch=0.0105]Epoch 247: Train Loss = 0.011868713423609734\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=375, train_loss_step=0.0106, train_loss_epoch=0.0119]Epoch 248: Train Loss = 0.010602323338389397\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=375, train_loss_step=0.00886, train_loss_epoch=0.0106]Epoch 249: Train Loss = 0.008857417851686478\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, v_num=375, train_loss_step=0.00998, train_loss_epoch=0.00886]Epoch 250: Train Loss = 0.009982910938560963\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=375, train_loss_step=0.0089, train_loss_epoch=0.00998] Epoch 251: Train Loss = 0.0089041693136096\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=375, train_loss_step=0.0074, train_loss_epoch=0.0089] Epoch 252: Train Loss = 0.007404773496091366\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.0074]Epoch 253: Train Loss = 0.010893880389630795\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=375, train_loss_step=0.012, train_loss_epoch=0.0109] Epoch 254: Train Loss = 0.012008109129965305\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=375, train_loss_step=0.0117, train_loss_epoch=0.012]Epoch 255: Train Loss = 0.011699186637997627\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=375, train_loss_step=0.0126, train_loss_epoch=0.0117]Epoch 256: Train Loss = 0.012645778246223927\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=375, train_loss_step=0.0162, train_loss_epoch=0.0126]Epoch 257: Train Loss = 0.016180705279111862\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=375, train_loss_step=0.0116, train_loss_epoch=0.0162]Epoch 258: Train Loss = 0.011624638922512531\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.0116]Epoch 259: Train Loss = 0.010936416685581207\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=375, train_loss_step=0.0162, train_loss_epoch=0.0109]Epoch 260: Train Loss = 0.01620417647063732\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=375, train_loss_step=0.011, train_loss_epoch=0.0162] Epoch 261: Train Loss = 0.011023201048374176\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=375, train_loss_step=0.0116, train_loss_epoch=0.011]Epoch 262: Train Loss = 0.011611961759626865\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0116]Epoch 263: Train Loss = 0.010130892507731915\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0101]Epoch 264: Train Loss = 0.011451641097664833\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=375, train_loss_step=0.0141, train_loss_epoch=0.0115]Epoch 265: Train Loss = 0.014098639599978924\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=375, train_loss_step=0.00901, train_loss_epoch=0.0141]Epoch 266: Train Loss = 0.00900948140770197\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.00901] Epoch 267: Train Loss = 0.011365287005901337\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 12.94it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.0114] Epoch 268: Train Loss = 0.010408462025225163\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0104]Epoch 269: Train Loss = 0.010108450427651405\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=375, train_loss_step=0.0112, train_loss_epoch=0.0101]Epoch 270: Train Loss = 0.011235808953642845\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.0112]Epoch 271: Train Loss = 0.011369839310646057\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=375, train_loss_step=0.00795, train_loss_epoch=0.0114]Epoch 272: Train Loss = 0.007948748767375946\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.00795] Epoch 273: Train Loss = 0.012467584572732449\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=375, train_loss_step=0.009, train_loss_epoch=0.0125]  Epoch 274: Train Loss = 0.008999119512736797\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.009]Epoch 275: Train Loss = 0.010429762303829193\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 276: Train Loss = 0.011464790441095829\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0115]Epoch 277: Train Loss = 0.011523962952196598\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=375, train_loss_step=0.0116, train_loss_epoch=0.0115]Epoch 278: Train Loss = 0.011614552699029446\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=375, train_loss_step=0.0096, train_loss_epoch=0.0116]Epoch 279: Train Loss = 0.009598062373697758\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=375, train_loss_step=0.00925, train_loss_epoch=0.0096]Epoch 280: Train Loss = 0.009250671602785587\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s, v_num=375, train_loss_step=0.00866, train_loss_epoch=0.00925]Epoch 281: Train Loss = 0.008657671511173248\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s, v_num=375, train_loss_step=0.00866, train_loss_epoch=0.00866]Epoch 282: Train Loss = 0.008661394938826561\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=375, train_loss_step=0.00852, train_loss_epoch=0.00866]Epoch 283: Train Loss = 0.008519218303263187\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.00852] Epoch 284: Train Loss = 0.010874046012759209\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.0109] Epoch 285: Train Loss = 0.012703077867627144\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=375, train_loss_step=0.00962, train_loss_epoch=0.0127]Epoch 286: Train Loss = 0.009618151001632214\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=375, train_loss_step=0.0118, train_loss_epoch=0.00962] Epoch 287: Train Loss = 0.01184337493032217\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=375, train_loss_step=0.00898, train_loss_epoch=0.0118]Epoch 288: Train Loss = 0.008976360782980919\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=375, train_loss_step=0.0118, train_loss_epoch=0.00898] Epoch 289: Train Loss = 0.011784828267991543\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0118] Epoch 290: Train Loss = 0.011480191722512245\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=375, train_loss_step=0.0133, train_loss_epoch=0.0115]Epoch 291: Train Loss = 0.01332247443497181\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=375, train_loss_step=0.00991, train_loss_epoch=0.0133]Epoch 292: Train Loss = 0.009909912943840027\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=375, train_loss_step=0.00984, train_loss_epoch=0.00991]Epoch 293: Train Loss = 0.009835953824222088\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=375, train_loss_step=0.0128, train_loss_epoch=0.00984] Epoch 294: Train Loss = 0.012843559496104717\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=375, train_loss_step=0.0102, train_loss_epoch=0.0128] Epoch 295: Train Loss = 0.010208326391875744\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=375, train_loss_step=0.0134, train_loss_epoch=0.0102]Epoch 296: Train Loss = 0.013363173231482506\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.0134]Epoch 297: Train Loss = 0.01265137828886509\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=375, train_loss_step=0.0139, train_loss_epoch=0.0127]Epoch 298: Train Loss = 0.013907784596085548\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=375, train_loss_step=0.0124, train_loss_epoch=0.0139]Epoch 299: Train Loss = 0.012354989536106586\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.0124]Epoch 300: Train Loss = 0.012745736166834831\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0127]Epoch 301: Train Loss = 0.010133365169167519\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=375, train_loss_step=0.0124, train_loss_epoch=0.0101]Epoch 302: Train Loss = 0.012365689501166344\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=375, train_loss_step=0.00962, train_loss_epoch=0.0124]Epoch 303: Train Loss = 0.009619568474590778\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=375, train_loss_step=0.00858, train_loss_epoch=0.00962]Epoch 304: Train Loss = 0.00857811514288187\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=375, train_loss_step=0.00958, train_loss_epoch=0.00858]Epoch 305: Train Loss = 0.00958286877721548\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.00958] Epoch 306: Train Loss = 0.011377600021660328\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=375, train_loss_step=0.00977, train_loss_epoch=0.0114]Epoch 307: Train Loss = 0.009765074588358402\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=375, train_loss_step=0.0113, train_loss_epoch=0.00977] Epoch 308: Train Loss = 0.011316209100186825\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0113] Epoch 309: Train Loss = 0.0100797014310956\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s, v_num=375, train_loss_step=0.0118, train_loss_epoch=0.0101]Epoch 310: Train Loss = 0.011831716634333134\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=375, train_loss_step=0.0126, train_loss_epoch=0.0118]Epoch 311: Train Loss = 0.012566640973091125\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, v_num=375, train_loss_step=0.0122, train_loss_epoch=0.0126]Epoch 312: Train Loss = 0.012246559374034405\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=375, train_loss_step=0.011, train_loss_epoch=0.0122] Epoch 313: Train Loss = 0.010956388898193836\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=375, train_loss_step=0.0102, train_loss_epoch=0.011]Epoch 314: Train Loss = 0.010220853611826897\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=375, train_loss_step=0.0151, train_loss_epoch=0.0102]Epoch 315: Train Loss = 0.015068159438669682\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=375, train_loss_step=0.00771, train_loss_epoch=0.0151]Epoch 316: Train Loss = 0.007714367471635342\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.00771] Epoch 317: Train Loss = 0.010802528820931911\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=375, train_loss_step=0.00971, train_loss_epoch=0.0108]Epoch 318: Train Loss = 0.009713462553918362\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=375, train_loss_step=0.00798, train_loss_epoch=0.00971]Epoch 319: Train Loss = 0.007980016991496086\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 16.28it/s, v_num=375, train_loss_step=0.0113, train_loss_epoch=0.00798] Epoch 320: Train Loss = 0.011325548402965069\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=375, train_loss_step=0.00748, train_loss_epoch=0.0113]Epoch 321: Train Loss = 0.007482473738491535\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.00748] Epoch 322: Train Loss = 0.010828845202922821\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=375, train_loss_step=0.0075, train_loss_epoch=0.0108] Epoch 323: Train Loss = 0.0075002103112638\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=375, train_loss_step=0.00951, train_loss_epoch=0.0075]Epoch 324: Train Loss = 0.00950569473206997\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.00951] Epoch 325: Train Loss = 0.010431813076138496\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=375, train_loss_step=0.0077, train_loss_epoch=0.0104] Epoch 326: Train Loss = 0.007703245151787996\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=375, train_loss_step=0.0138, train_loss_epoch=0.0077]Epoch 327: Train Loss = 0.013835204765200615\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=375, train_loss_step=0.00805, train_loss_epoch=0.0138]Epoch 328: Train Loss = 0.008045369759202003\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=375, train_loss_step=0.00894, train_loss_epoch=0.00805]Epoch 329: Train Loss = 0.008941500447690487\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=375, train_loss_step=0.00907, train_loss_epoch=0.00894]Epoch 330: Train Loss = 0.009073004126548767\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, v_num=375, train_loss_step=0.0119, train_loss_epoch=0.00907] Epoch 331: Train Loss = 0.011876165866851807\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=375, train_loss_step=0.0106, train_loss_epoch=0.0119] Epoch 332: Train Loss = 0.01060541532933712\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, v_num=375, train_loss_step=0.012, train_loss_epoch=0.0106] Epoch 333: Train Loss = 0.011988731101155281\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=375, train_loss_step=0.0123, train_loss_epoch=0.012]Epoch 334: Train Loss = 0.012257104739546776\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=375, train_loss_step=0.0118, train_loss_epoch=0.0123]Epoch 335: Train Loss = 0.011792453937232494\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=375, train_loss_step=0.00951, train_loss_epoch=0.0118]Epoch 336: Train Loss = 0.009506781585514545\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.00951] Epoch 337: Train Loss = 0.012656329199671745\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=375, train_loss_step=0.0103, train_loss_epoch=0.0127] Epoch 338: Train Loss = 0.010322121903300285\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=375, train_loss_step=0.0117, train_loss_epoch=0.0103]Epoch 339: Train Loss = 0.011673325672745705\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, v_num=375, train_loss_step=0.0093, train_loss_epoch=0.0117]Epoch 340: Train Loss = 0.009299674071371555\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=375, train_loss_step=0.0105, train_loss_epoch=0.0093]Epoch 341: Train Loss = 0.010539354756474495\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=375, train_loss_step=0.0132, train_loss_epoch=0.0105]Epoch 342: Train Loss = 0.013238003477454185\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=375, train_loss_step=0.0134, train_loss_epoch=0.0132]Epoch 343: Train Loss = 0.013362052850425243\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=375, train_loss_step=0.0134, train_loss_epoch=0.0134]Epoch 344: Train Loss = 0.013367312029004097\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=375, train_loss_step=0.0105, train_loss_epoch=0.0134]Epoch 345: Train Loss = 0.010474731214344501\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.0105]Epoch 346: Train Loss = 0.011426887474954128\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s, v_num=375, train_loss_step=0.0122, train_loss_epoch=0.0114]Epoch 347: Train Loss = 0.012224944308400154\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=375, train_loss_step=0.010, train_loss_epoch=0.0122] Epoch 348: Train Loss = 0.010032118298113346\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=375, train_loss_step=0.0124, train_loss_epoch=0.010]Epoch 349: Train Loss = 0.012388183735311031\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=375, train_loss_step=0.0138, train_loss_epoch=0.0124]Epoch 350: Train Loss = 0.013816451653838158\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=375, train_loss_step=0.00991, train_loss_epoch=0.0138]Epoch 351: Train Loss = 0.009914644062519073\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=375, train_loss_step=0.00928, train_loss_epoch=0.00991]Epoch 352: Train Loss = 0.009281395934522152\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=375, train_loss_step=0.00834, train_loss_epoch=0.00928]Epoch 353: Train Loss = 0.008336092345416546\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=375, train_loss_step=0.00888, train_loss_epoch=0.00834]Epoch 354: Train Loss = 0.008878948166966438\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 16.56it/s, v_num=375, train_loss_step=0.0116, train_loss_epoch=0.00888] Epoch 355: Train Loss = 0.01156601868569851\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=375, train_loss_step=0.00934, train_loss_epoch=0.0116]Epoch 356: Train Loss = 0.009342971257865429\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=375, train_loss_step=0.00815, train_loss_epoch=0.00934]Epoch 357: Train Loss = 0.008148513734340668\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=375, train_loss_step=0.00983, train_loss_epoch=0.00815]Epoch 358: Train Loss = 0.009827242232859135\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=375, train_loss_step=0.0121, train_loss_epoch=0.00983] Epoch 359: Train Loss = 0.012088289484381676\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=375, train_loss_step=0.0111, train_loss_epoch=0.0121] Epoch 360: Train Loss = 0.011054905131459236\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=375, train_loss_step=0.013, train_loss_epoch=0.0111] Epoch 361: Train Loss = 0.013029484078288078\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=375, train_loss_step=0.00881, train_loss_epoch=0.013]Epoch 362: Train Loss = 0.008811604231595993\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=375, train_loss_step=0.00944, train_loss_epoch=0.00881]Epoch 363: Train Loss = 0.00943573284894228\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=375, train_loss_step=0.00964, train_loss_epoch=0.00944]Epoch 364: Train Loss = 0.009641953743994236\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=375, train_loss_step=0.00941, train_loss_epoch=0.00964]Epoch 365: Train Loss = 0.009412608109414577\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=375, train_loss_step=0.0112, train_loss_epoch=0.00941] Epoch 366: Train Loss = 0.011197388172149658\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0112] Epoch 367: Train Loss = 0.010149987414479256\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.0101]Epoch 368: Train Loss = 0.010366122238337994\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=375, train_loss_step=0.0113, train_loss_epoch=0.0104]Epoch 369: Train Loss = 0.01127112377434969\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=375, train_loss_step=0.0113, train_loss_epoch=0.0113]Epoch 370: Train Loss = 0.011275433003902435\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 13.20it/s, v_num=375, train_loss_step=0.00821, train_loss_epoch=0.0113]Epoch 371: Train Loss = 0.008206077851355076\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=375, train_loss_step=0.0112, train_loss_epoch=0.00821] Epoch 372: Train Loss = 0.011223765090107918\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=375, train_loss_step=0.00825, train_loss_epoch=0.0112]Epoch 373: Train Loss = 0.008254531770944595\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.00825] Epoch 374: Train Loss = 0.010438740253448486\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=375, train_loss_step=0.0131, train_loss_epoch=0.0104] Epoch 375: Train Loss = 0.013122783042490482\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=375, train_loss_step=0.00913, train_loss_epoch=0.0131]Epoch 376: Train Loss = 0.009130324237048626\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s, v_num=375, train_loss_step=0.0137, train_loss_epoch=0.00913] Epoch 377: Train Loss = 0.01365767139941454\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=375, train_loss_step=0.009, train_loss_epoch=0.0137]  Epoch 378: Train Loss = 0.008996469900012016\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s, v_num=375, train_loss_step=0.0144, train_loss_epoch=0.009]Epoch 379: Train Loss = 0.014369103126227856\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 15.92it/s, v_num=375, train_loss_step=0.00977, train_loss_epoch=0.0144]Epoch 380: Train Loss = 0.009767336770892143\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.00977] Epoch 381: Train Loss = 0.010836675763130188\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=375, train_loss_step=0.00755, train_loss_epoch=0.0108]Epoch 382: Train Loss = 0.007553242612630129\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.00755] Epoch 383: Train Loss = 0.010867459699511528\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=375, train_loss_step=0.0116, train_loss_epoch=0.0109] Epoch 384: Train Loss = 0.011645232327282429\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 13.30it/s, v_num=375, train_loss_step=0.0136, train_loss_epoch=0.0116]Epoch 385: Train Loss = 0.013622254133224487\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=375, train_loss_step=0.00928, train_loss_epoch=0.0136]Epoch 386: Train Loss = 0.009279192425310612\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=375, train_loss_step=0.0075, train_loss_epoch=0.00928] Epoch 387: Train Loss = 0.00749773858115077\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=375, train_loss_step=0.0105, train_loss_epoch=0.0075] Epoch 388: Train Loss = 0.010473539121448994\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=375, train_loss_step=0.0102, train_loss_epoch=0.0105]Epoch 389: Train Loss = 0.01017257571220398\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=375, train_loss_step=0.0142, train_loss_epoch=0.0102]Epoch 390: Train Loss = 0.014174772426486015\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=375, train_loss_step=0.00793, train_loss_epoch=0.0142]Epoch 391: Train Loss = 0.007928836159408092\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 13.59it/s, v_num=375, train_loss_step=0.0122, train_loss_epoch=0.00793] Epoch 392: Train Loss = 0.012232432141900063\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=375, train_loss_step=0.0132, train_loss_epoch=0.0122] Epoch 393: Train Loss = 0.013154944404959679\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=375, train_loss_step=0.0096, train_loss_epoch=0.0132]Epoch 394: Train Loss = 0.009601302444934845\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.0096]Epoch 395: Train Loss = 0.011389398016035557\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=375, train_loss_step=0.00818, train_loss_epoch=0.0114]Epoch 396: Train Loss = 0.008175174705684185\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, v_num=375, train_loss_step=0.0135, train_loss_epoch=0.00818] Epoch 397: Train Loss = 0.01353580690920353\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=375, train_loss_step=0.0113, train_loss_epoch=0.0135] Epoch 398: Train Loss = 0.011322077363729477\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=375, train_loss_step=0.00915, train_loss_epoch=0.0113]Epoch 399: Train Loss = 0.00915045291185379\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.00915] Epoch 400: Train Loss = 0.010374669916927814\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=375, train_loss_step=0.00906, train_loss_epoch=0.0104]Epoch 401: Train Loss = 0.009060845710337162\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=375, train_loss_step=0.00847, train_loss_epoch=0.00906]Epoch 402: Train Loss = 0.008469149470329285\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=375, train_loss_step=0.00741, train_loss_epoch=0.00847]Epoch 403: Train Loss = 0.007405636366456747\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=375, train_loss_step=0.0099, train_loss_epoch=0.00741] Epoch 404: Train Loss = 0.00990306120365858\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.0099] Epoch 405: Train Loss = 0.01039028074592352\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=375, train_loss_step=0.0161, train_loss_epoch=0.0104]Epoch 406: Train Loss = 0.016136309131979942\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.0161]Epoch 407: Train Loss = 0.010401517152786255\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=375, train_loss_step=0.0103, train_loss_epoch=0.0104]Epoch 408: Train Loss = 0.010321760550141335\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=375, train_loss_step=0.00832, train_loss_epoch=0.0103]Epoch 409: Train Loss = 0.00832164753228426\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=375, train_loss_step=0.0106, train_loss_epoch=0.00832] Epoch 410: Train Loss = 0.010641534812748432\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=375, train_loss_step=0.00813, train_loss_epoch=0.0106]Epoch 411: Train Loss = 0.008133537136018276\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 13.93it/s, v_num=375, train_loss_step=0.0145, train_loss_epoch=0.00813] Epoch 412: Train Loss = 0.01452996488660574\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0145] Epoch 413: Train Loss = 0.011461992748081684\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=375, train_loss_step=0.0122, train_loss_epoch=0.0115]Epoch 414: Train Loss = 0.012246671132743359\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=375, train_loss_step=0.00962, train_loss_epoch=0.0122]Epoch 415: Train Loss = 0.00962276104837656\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.00962] Epoch 416: Train Loss = 0.011541636660695076\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=375, train_loss_step=0.011, train_loss_epoch=0.0115]  Epoch 417: Train Loss = 0.01096914242953062\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=375, train_loss_step=0.00812, train_loss_epoch=0.011]Epoch 418: Train Loss = 0.00811556912958622\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.00812] Epoch 419: Train Loss = 0.010111826471984386\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0101] Epoch 420: Train Loss = 0.010094535537064075\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=375, train_loss_step=0.0105, train_loss_epoch=0.0101]Epoch 421: Train Loss = 0.010493813082575798\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=375, train_loss_step=0.00858, train_loss_epoch=0.0105]Epoch 422: Train Loss = 0.008582359179854393\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=375, train_loss_step=0.0139, train_loss_epoch=0.00858] Epoch 423: Train Loss = 0.013921012170612812\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0139] Epoch 424: Train Loss = 0.011488758958876133\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=375, train_loss_step=0.0117, train_loss_epoch=0.0115]Epoch 425: Train Loss = 0.011733834631741047\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=375, train_loss_step=0.00903, train_loss_epoch=0.0117]Epoch 426: Train Loss = 0.00903275329619646\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=375, train_loss_step=0.0108, train_loss_epoch=0.00903] Epoch 427: Train Loss = 0.010753089562058449\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=375, train_loss_step=0.00857, train_loss_epoch=0.0108]Epoch 428: Train Loss = 0.008573166094720364\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, v_num=375, train_loss_step=0.00957, train_loss_epoch=0.00857]Epoch 429: Train Loss = 0.009565675631165504\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.00957] Epoch 430: Train Loss = 0.012462732382118702\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=375, train_loss_step=0.00959, train_loss_epoch=0.0125]Epoch 431: Train Loss = 0.009589576162397861\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=375, train_loss_step=0.0143, train_loss_epoch=0.00959] Epoch 432: Train Loss = 0.01429023128002882\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 13.22it/s, v_num=375, train_loss_step=0.00944, train_loss_epoch=0.0143]Epoch 433: Train Loss = 0.009435667656362057\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=375, train_loss_step=0.00871, train_loss_epoch=0.00944]Epoch 434: Train Loss = 0.008705304935574532\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=375, train_loss_step=0.0142, train_loss_epoch=0.00871] Epoch 435: Train Loss = 0.014153346419334412\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.0142] Epoch 436: Train Loss = 0.011351006105542183\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=375, train_loss_step=0.013, train_loss_epoch=0.0114] Epoch 437: Train Loss = 0.013042906299233437\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=375, train_loss_step=0.0096, train_loss_epoch=0.013]Epoch 438: Train Loss = 0.00960155762732029\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=375, train_loss_step=0.0083, train_loss_epoch=0.0096]Epoch 439: Train Loss = 0.00829575676470995\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0083]Epoch 440: Train Loss = 0.011501722037792206\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.0115]Epoch 441: Train Loss = 0.01250272337347269\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0125]Epoch 442: Train Loss = 0.011530322954058647\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0115]Epoch 443: Train Loss = 0.010100580751895905\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=375, train_loss_step=0.0122, train_loss_epoch=0.0101]Epoch 444: Train Loss = 0.012201843783259392\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.0122]Epoch 445: Train Loss = 0.012731075286865234\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=375, train_loss_step=0.0111, train_loss_epoch=0.0127]Epoch 446: Train Loss = 0.011072794906795025\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=375, train_loss_step=0.0111, train_loss_epoch=0.0111]Epoch 447: Train Loss = 0.011055917479097843\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=375, train_loss_step=0.0112, train_loss_epoch=0.0111]Epoch 448: Train Loss = 0.011224700137972832\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=375, train_loss_step=0.00819, train_loss_epoch=0.0112]Epoch 449: Train Loss = 0.008194220252335072\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.00819] Epoch 450: Train Loss = 0.010423434898257256\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=375, train_loss_step=0.00992, train_loss_epoch=0.0104]Epoch 451: Train Loss = 0.009917888790369034\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=375, train_loss_step=0.012, train_loss_epoch=0.00992]  Epoch 452: Train Loss = 0.01196560263633728\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=375, train_loss_step=0.0113, train_loss_epoch=0.012] Epoch 453: Train Loss = 0.01128500048071146\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=375, train_loss_step=0.0121, train_loss_epoch=0.0113]Epoch 454: Train Loss = 0.012063764035701752\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=375, train_loss_step=0.00953, train_loss_epoch=0.0121]Epoch 455: Train Loss = 0.009528840892016888\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=375, train_loss_step=0.0128, train_loss_epoch=0.00953] Epoch 456: Train Loss = 0.012788868509232998\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0128] Epoch 457: Train Loss = 0.01145272795110941\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=375, train_loss_step=0.00944, train_loss_epoch=0.0115]Epoch 458: Train Loss = 0.009438103064894676\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=375, train_loss_step=0.0128, train_loss_epoch=0.00944] Epoch 459: Train Loss = 0.012806884944438934\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=375, train_loss_step=0.00891, train_loss_epoch=0.0128]Epoch 460: Train Loss = 0.008910858072340488\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=375, train_loss_step=0.00994, train_loss_epoch=0.00891]Epoch 461: Train Loss = 0.009941949509084225\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=375, train_loss_step=0.0104, train_loss_epoch=0.00994] Epoch 462: Train Loss = 0.010417296551167965\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=375, train_loss_step=0.00882, train_loss_epoch=0.0104]Epoch 463: Train Loss = 0.00881890393793583\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=375, train_loss_step=0.0113, train_loss_epoch=0.00882] Epoch 464: Train Loss = 0.011323104612529278\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=375, train_loss_step=0.00857, train_loss_epoch=0.0113]Epoch 465: Train Loss = 0.00856871623545885\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=375, train_loss_step=0.00696, train_loss_epoch=0.00857]Epoch 466: Train Loss = 0.006958659738302231\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=375, train_loss_step=0.0098, train_loss_epoch=0.00696] Epoch 467: Train Loss = 0.009803232736885548\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=375, train_loss_step=0.0121, train_loss_epoch=0.0098] Epoch 468: Train Loss = 0.01208343356847763\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=375, train_loss_step=0.00992, train_loss_epoch=0.0121]Epoch 469: Train Loss = 0.009916870854794979\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.00992] Epoch 470: Train Loss = 0.010112464427947998\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=375, train_loss_step=0.0127, train_loss_epoch=0.0101] Epoch 471: Train Loss = 0.012670480646193027\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=375, train_loss_step=0.0159, train_loss_epoch=0.0127]Epoch 472: Train Loss = 0.015940042212605476\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=375, train_loss_step=0.00765, train_loss_epoch=0.0159]Epoch 473: Train Loss = 0.007649469189345837\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=375, train_loss_step=0.00961, train_loss_epoch=0.00765]Epoch 474: Train Loss = 0.009607719257473946\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=375, train_loss_step=0.00918, train_loss_epoch=0.00961]Epoch 475: Train Loss = 0.009177262894809246\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=375, train_loss_step=0.00982, train_loss_epoch=0.00918]Epoch 476: Train Loss = 0.009823922999203205\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=375, train_loss_step=0.0125, train_loss_epoch=0.00982] Epoch 477: Train Loss = 0.012463363818824291\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=375, train_loss_step=0.00805, train_loss_epoch=0.0125]Epoch 478: Train Loss = 0.008047875948250294\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=375, train_loss_step=0.0119, train_loss_epoch=0.00805] Epoch 479: Train Loss = 0.011888007633388042\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 16.10it/s, v_num=375, train_loss_step=0.0101, train_loss_epoch=0.0119] Epoch 480: Train Loss = 0.010091465897858143\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=375, train_loss_step=0.00873, train_loss_epoch=0.0101]Epoch 481: Train Loss = 0.008725136518478394\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.00873] Epoch 482: Train Loss = 0.011400642804801464\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=375, train_loss_step=0.0128, train_loss_epoch=0.0114] Epoch 483: Train Loss = 0.012848109938204288\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=375, train_loss_step=0.00991, train_loss_epoch=0.0128]Epoch 484: Train Loss = 0.009905688464641571\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.00991] Epoch 485: Train Loss = 0.010922626592218876\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=375, train_loss_step=0.00892, train_loss_epoch=0.0109]Epoch 486: Train Loss = 0.008921328000724316\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=375, train_loss_step=0.0102, train_loss_epoch=0.00892] Epoch 487: Train Loss = 0.010156191885471344\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, v_num=375, train_loss_step=0.00814, train_loss_epoch=0.0102]Epoch 488: Train Loss = 0.008142904378473759\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=375, train_loss_step=0.0105, train_loss_epoch=0.00814] Epoch 489: Train Loss = 0.010470814071595669\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 16.36it/s, v_num=375, train_loss_step=0.00924, train_loss_epoch=0.0105]Epoch 490: Train Loss = 0.009242639876902103\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=375, train_loss_step=0.00736, train_loss_epoch=0.00924]Epoch 491: Train Loss = 0.007361923810094595\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=375, train_loss_step=0.0109, train_loss_epoch=0.00736] Epoch 492: Train Loss = 0.010867366567254066\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0109] Epoch 493: Train Loss = 0.011530786752700806\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=375, train_loss_step=0.0117, train_loss_epoch=0.0115]Epoch 494: Train Loss = 0.01165411900728941\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=375, train_loss_step=0.0115, train_loss_epoch=0.0117]Epoch 495: Train Loss = 0.011505539529025555\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=375, train_loss_step=0.00784, train_loss_epoch=0.0115]Epoch 496: Train Loss = 0.007835407741367817\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=375, train_loss_step=0.00895, train_loss_epoch=0.00784]Epoch 497: Train Loss = 0.00895202811807394\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=375, train_loss_step=0.00938, train_loss_epoch=0.00895]Epoch 498: Train Loss = 0.009377216920256615\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.00938] Epoch 499: Train Loss = 0.011424499563872814\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.0114] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=375, train_loss_step=0.0114, train_loss_epoch=0.0114]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 18: from 2008-05-12 00:00:00 to 2022-12-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s, v_num=377, train_loss_step=0.0206]Epoch 0: Train Loss = 0.020640801638364792\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=377, train_loss_step=0.0443, train_loss_epoch=0.0206]Epoch 1: Train Loss = 0.04430338367819786\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=377, train_loss_step=0.0423, train_loss_epoch=0.0443]Epoch 2: Train Loss = 0.042301781475543976\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=377, train_loss_step=0.0189, train_loss_epoch=0.0423]Epoch 3: Train Loss = 0.018948925659060478\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=377, train_loss_step=0.0235, train_loss_epoch=0.0189]Epoch 4: Train Loss = 0.023486550897359848\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, v_num=377, train_loss_step=0.0145, train_loss_epoch=0.0235]Epoch 5: Train Loss = 0.014543007127940655\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=377, train_loss_step=0.0141, train_loss_epoch=0.0145]Epoch 6: Train Loss = 0.014061293564736843\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=377, train_loss_step=0.0161, train_loss_epoch=0.0141]Epoch 7: Train Loss = 0.016110800206661224\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=377, train_loss_step=0.015, train_loss_epoch=0.0161] Epoch 8: Train Loss = 0.015011805109679699\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=377, train_loss_step=0.0178, train_loss_epoch=0.015]Epoch 9: Train Loss = 0.017824627459049225\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=377, train_loss_step=0.0137, train_loss_epoch=0.0178]Epoch 10: Train Loss = 0.013683455064892769\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=377, train_loss_step=0.0137, train_loss_epoch=0.0137]Epoch 11: Train Loss = 0.013666994869709015\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=377, train_loss_step=0.0128, train_loss_epoch=0.0137]Epoch 12: Train Loss = 0.0127949183806777\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=377, train_loss_step=0.0141, train_loss_epoch=0.0128]Epoch 13: Train Loss = 0.014131687581539154\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=377, train_loss_step=0.0135, train_loss_epoch=0.0141]Epoch 14: Train Loss = 0.013547421433031559\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.0135]Epoch 15: Train Loss = 0.011371261440217495\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=377, train_loss_step=0.0201, train_loss_epoch=0.0114]Epoch 16: Train Loss = 0.02008540742099285\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=377, train_loss_step=0.0153, train_loss_epoch=0.0201]Epoch 17: Train Loss = 0.01534995622932911\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=377, train_loss_step=0.0131, train_loss_epoch=0.0153]Epoch 18: Train Loss = 0.013116279616951942\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=377, train_loss_step=0.0126, train_loss_epoch=0.0131]Epoch 19: Train Loss = 0.012636830098927021\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=377, train_loss_step=0.0105, train_loss_epoch=0.0126]Epoch 20: Train Loss = 0.010500838048756123\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=377, train_loss_step=0.0136, train_loss_epoch=0.0105]Epoch 21: Train Loss = 0.013564039953052998\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=377, train_loss_step=0.0151, train_loss_epoch=0.0136]Epoch 22: Train Loss = 0.015052573755383492\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=377, train_loss_step=0.0129, train_loss_epoch=0.0151]Epoch 23: Train Loss = 0.012900522910058498\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.0129]Epoch 24: Train Loss = 0.011364138685166836\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=377, train_loss_step=0.0141, train_loss_epoch=0.0114]Epoch 25: Train Loss = 0.014054698869585991\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=377, train_loss_step=0.011, train_loss_epoch=0.0141] Epoch 26: Train Loss = 0.011049559339880943\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, v_num=377, train_loss_step=0.0138, train_loss_epoch=0.011]Epoch 27: Train Loss = 0.013791472651064396\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=377, train_loss_step=0.0116, train_loss_epoch=0.0138]Epoch 28: Train Loss = 0.011595209129154682\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=377, train_loss_step=0.0144, train_loss_epoch=0.0116]Epoch 29: Train Loss = 0.01443447731435299\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=377, train_loss_step=0.0125, train_loss_epoch=0.0144]Epoch 30: Train Loss = 0.012516685761511326\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=377, train_loss_step=0.0144, train_loss_epoch=0.0125]Epoch 31: Train Loss = 0.014380798675119877\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=377, train_loss_step=0.0123, train_loss_epoch=0.0144]Epoch 32: Train Loss = 0.012258957140147686\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=377, train_loss_step=0.00947, train_loss_epoch=0.0123]Epoch 33: Train Loss = 0.009474711492657661\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=377, train_loss_step=0.00912, train_loss_epoch=0.00947]Epoch 34: Train Loss = 0.009123618714511395\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.00912] Epoch 35: Train Loss = 0.01018849853426218\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.0102] Epoch 36: Train Loss = 0.011204766109585762\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=377, train_loss_step=0.00986, train_loss_epoch=0.0112]Epoch 37: Train Loss = 0.009860838763415813\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=377, train_loss_step=0.0147, train_loss_epoch=0.00986] Epoch 38: Train Loss = 0.014679891988635063\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=377, train_loss_step=0.0111, train_loss_epoch=0.0147] Epoch 39: Train Loss = 0.01109311543405056\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=377, train_loss_step=0.0134, train_loss_epoch=0.0111]Epoch 40: Train Loss = 0.013360354118049145\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 13.75it/s, v_num=377, train_loss_step=0.0116, train_loss_epoch=0.0134]Epoch 41: Train Loss = 0.011593450792133808\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=377, train_loss_step=0.00881, train_loss_epoch=0.0116]Epoch 42: Train Loss = 0.008811436593532562\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=377, train_loss_step=0.0148, train_loss_epoch=0.00881] Epoch 43: Train Loss = 0.014769366942346096\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=377, train_loss_step=0.0129, train_loss_epoch=0.0148] Epoch 44: Train Loss = 0.012934135273098946\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=377, train_loss_step=0.00722, train_loss_epoch=0.0129]Epoch 45: Train Loss = 0.007221020758152008\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=377, train_loss_step=0.0103, train_loss_epoch=0.00722] Epoch 46: Train Loss = 0.010304206050932407\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=377, train_loss_step=0.0134, train_loss_epoch=0.0103] Epoch 47: Train Loss = 0.013363778591156006\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.0134]Epoch 48: Train Loss = 0.011377538554370403\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=377, train_loss_step=0.010, train_loss_epoch=0.0114] Epoch 49: Train Loss = 0.010006437078118324\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=377, train_loss_step=0.0125, train_loss_epoch=0.010]Epoch 50: Train Loss = 0.012502032332122326\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=377, train_loss_step=0.0133, train_loss_epoch=0.0125]Epoch 51: Train Loss = 0.013285188935697079\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=377, train_loss_step=0.0116, train_loss_epoch=0.0133]Epoch 52: Train Loss = 0.011551429517567158\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=377, train_loss_step=0.0135, train_loss_epoch=0.0116]Epoch 53: Train Loss = 0.013489625416696072\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=377, train_loss_step=0.0134, train_loss_epoch=0.0135]Epoch 54: Train Loss = 0.013397670350968838\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.0134]Epoch 55: Train Loss = 0.010129442438483238\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=377, train_loss_step=0.0118, train_loss_epoch=0.0101]Epoch 56: Train Loss = 0.011820616200566292\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=377, train_loss_step=0.00729, train_loss_epoch=0.0118]Epoch 57: Train Loss = 0.007286532316356897\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.00729] Epoch 58: Train Loss = 0.010094028897583485\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=377, train_loss_step=0.0132, train_loss_epoch=0.0101] Epoch 59: Train Loss = 0.01323021948337555\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.0132]Epoch 60: Train Loss = 0.012663228437304497\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=377, train_loss_step=0.0088, train_loss_epoch=0.0127]Epoch 61: Train Loss = 0.008804435841739178\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=377, train_loss_step=0.010, train_loss_epoch=0.0088] Epoch 62: Train Loss = 0.009996357373893261\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=377, train_loss_step=0.0129, train_loss_epoch=0.010]Epoch 63: Train Loss = 0.012903884053230286\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=377, train_loss_step=0.00917, train_loss_epoch=0.0129]Epoch 64: Train Loss = 0.009169241413474083\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.00917] Epoch 65: Train Loss = 0.011172492988407612\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=377, train_loss_step=0.0145, train_loss_epoch=0.0112] Epoch 66: Train Loss = 0.014507793821394444\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=377, train_loss_step=0.0164, train_loss_epoch=0.0145]Epoch 67: Train Loss = 0.016401633620262146\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.0164]Epoch 68: Train Loss = 0.01142888329923153\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.0114]Epoch 69: Train Loss = 0.010169491171836853\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=377, train_loss_step=0.0119, train_loss_epoch=0.0102]Epoch 70: Train Loss = 0.011927611194550991\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=377, train_loss_step=0.0128, train_loss_epoch=0.0119]Epoch 71: Train Loss = 0.012780675664544106\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.0128]Epoch 72: Train Loss = 0.010167415253818035\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.0102]Epoch 73: Train Loss = 0.010364539921283722\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=377, train_loss_step=0.0143, train_loss_epoch=0.0104]Epoch 74: Train Loss = 0.01433737762272358\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=377, train_loss_step=0.0109, train_loss_epoch=0.0143]Epoch 75: Train Loss = 0.01092192716896534\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.0109]Epoch 76: Train Loss = 0.010554388165473938\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=377, train_loss_step=0.0117, train_loss_epoch=0.0106]Epoch 77: Train Loss = 0.011720412410795689\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=377, train_loss_step=0.0116, train_loss_epoch=0.0117]Epoch 78: Train Loss = 0.011578359641134739\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=377, train_loss_step=0.0119, train_loss_epoch=0.0116]Epoch 79: Train Loss = 0.01189615298062563\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=377, train_loss_step=0.0198, train_loss_epoch=0.0119]Epoch 80: Train Loss = 0.019765665754675865\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=377, train_loss_step=0.0148, train_loss_epoch=0.0198]Epoch 81: Train Loss = 0.014752310700714588\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=377, train_loss_step=0.0118, train_loss_epoch=0.0148]Epoch 82: Train Loss = 0.01181724201887846\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=377, train_loss_step=0.0121, train_loss_epoch=0.0118]Epoch 83: Train Loss = 0.012073897756636143\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=377, train_loss_step=0.0134, train_loss_epoch=0.0121]Epoch 84: Train Loss = 0.013382134959101677\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=377, train_loss_step=0.0135, train_loss_epoch=0.0134]Epoch 85: Train Loss = 0.013465800322592258\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.0135]Epoch 86: Train Loss = 0.012728638015687466\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=377, train_loss_step=0.0155, train_loss_epoch=0.0127]Epoch 87: Train Loss = 0.015539862215518951\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=377, train_loss_step=0.0138, train_loss_epoch=0.0155]Epoch 88: Train Loss = 0.013840779662132263\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=377, train_loss_step=0.012, train_loss_epoch=0.0138] Epoch 89: Train Loss = 0.011992298997938633\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=377, train_loss_step=0.0116, train_loss_epoch=0.012]Epoch 90: Train Loss = 0.011588375084102154\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=377, train_loss_step=0.0156, train_loss_epoch=0.0116]Epoch 91: Train Loss = 0.015637703239917755\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=377, train_loss_step=0.0134, train_loss_epoch=0.0156]Epoch 92: Train Loss = 0.013449995778501034\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=377, train_loss_step=0.0131, train_loss_epoch=0.0134]Epoch 93: Train Loss = 0.013098130002617836\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=377, train_loss_step=0.00859, train_loss_epoch=0.0131]Epoch 94: Train Loss = 0.008590235374867916\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=377, train_loss_step=0.020, train_loss_epoch=0.00859]  Epoch 95: Train Loss = 0.020030977204442024\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=377, train_loss_step=0.0133, train_loss_epoch=0.020] Epoch 96: Train Loss = 0.013329665176570415\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=377, train_loss_step=0.0139, train_loss_epoch=0.0133]Epoch 97: Train Loss = 0.01386761013418436\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=377, train_loss_step=0.0162, train_loss_epoch=0.0139]Epoch 98: Train Loss = 0.01617935299873352\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=377, train_loss_step=0.0108, train_loss_epoch=0.0162]Epoch 99: Train Loss = 0.010787355713546276\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=377, train_loss_step=0.0131, train_loss_epoch=0.0108]Epoch 100: Train Loss = 0.013109427876770496\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=377, train_loss_step=0.0139, train_loss_epoch=0.0131]Epoch 101: Train Loss = 0.013894218020141125\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=377, train_loss_step=0.0167, train_loss_epoch=0.0139]Epoch 102: Train Loss = 0.016742262989282608\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=377, train_loss_step=0.0109, train_loss_epoch=0.0167]Epoch 103: Train Loss = 0.010926353745162487\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.0109]Epoch 104: Train Loss = 0.010553896427154541\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=377, train_loss_step=0.0111, train_loss_epoch=0.0106]Epoch 105: Train Loss = 0.011127789504826069\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=377, train_loss_step=0.0119, train_loss_epoch=0.0111]Epoch 106: Train Loss = 0.01185075007379055\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=377, train_loss_step=0.0107, train_loss_epoch=0.0119]Epoch 107: Train Loss = 0.010680929757654667\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=377, train_loss_step=0.010, train_loss_epoch=0.0107] Epoch 108: Train Loss = 0.00999546516686678\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=377, train_loss_step=0.0133, train_loss_epoch=0.010]Epoch 109: Train Loss = 0.013277278281748295\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.0133]Epoch 110: Train Loss = 0.011426805518567562\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=377, train_loss_step=0.0123, train_loss_epoch=0.0114]Epoch 111: Train Loss = 0.012336106039583683\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.0123]Epoch 112: Train Loss = 0.011244882829487324\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=377, train_loss_step=0.00852, train_loss_epoch=0.0112]Epoch 113: Train Loss = 0.008517836220562458\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=377, train_loss_step=0.00913, train_loss_epoch=0.00852]Epoch 114: Train Loss = 0.009128878824412823\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=377, train_loss_step=0.010, train_loss_epoch=0.00913]  Epoch 115: Train Loss = 0.010002614930272102\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=377, train_loss_step=0.0133, train_loss_epoch=0.010] Epoch 116: Train Loss = 0.013282549567520618\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.0133]Epoch 117: Train Loss = 0.012696323916316032\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=377, train_loss_step=0.00917, train_loss_epoch=0.0127]Epoch 118: Train Loss = 0.009173701517283916\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=377, train_loss_step=0.0129, train_loss_epoch=0.00917] Epoch 119: Train Loss = 0.012892057187855244\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=377, train_loss_step=0.0122, train_loss_epoch=0.0129] Epoch 120: Train Loss = 0.01224763784557581\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=377, train_loss_step=0.00923, train_loss_epoch=0.0122]Epoch 121: Train Loss = 0.009234164841473103\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=377, train_loss_step=0.0111, train_loss_epoch=0.00923] Epoch 122: Train Loss = 0.01113321352750063\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=377, train_loss_step=0.0137, train_loss_epoch=0.0111] Epoch 123: Train Loss = 0.013678355142474174\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=377, train_loss_step=0.0103, train_loss_epoch=0.0137]Epoch 124: Train Loss = 0.01028942596167326\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=377, train_loss_step=0.00892, train_loss_epoch=0.0103]Epoch 125: Train Loss = 0.008917178027331829\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=377, train_loss_step=0.0108, train_loss_epoch=0.00892] Epoch 126: Train Loss = 0.01078114379197359\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=377, train_loss_step=0.00923, train_loss_epoch=0.0108]Epoch 127: Train Loss = 0.00923159159719944\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, v_num=377, train_loss_step=0.0121, train_loss_epoch=0.00923] Epoch 128: Train Loss = 0.012082298286259174\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=377, train_loss_step=0.0123, train_loss_epoch=0.0121] Epoch 129: Train Loss = 0.01228391844779253\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=377, train_loss_step=0.0132, train_loss_epoch=0.0123]Epoch 130: Train Loss = 0.013243927620351315\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s, v_num=377, train_loss_step=0.0133, train_loss_epoch=0.0132]Epoch 131: Train Loss = 0.013326987624168396\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 11.08it/s, v_num=377, train_loss_step=0.0119, train_loss_epoch=0.0133]Epoch 132: Train Loss = 0.011863001622259617\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=377, train_loss_step=0.00965, train_loss_epoch=0.0119]Epoch 133: Train Loss = 0.00965184811502695\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.00965] Epoch 134: Train Loss = 0.01116614043712616\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=377, train_loss_step=0.0109, train_loss_epoch=0.0112] Epoch 135: Train Loss = 0.010913158766925335\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=377, train_loss_step=0.0109, train_loss_epoch=0.0109]Epoch 136: Train Loss = 0.0109212351962924\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=377, train_loss_step=0.0117, train_loss_epoch=0.0109]Epoch 137: Train Loss = 0.011743946000933647\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=377, train_loss_step=0.0122, train_loss_epoch=0.0117]Epoch 138: Train Loss = 0.012223386205732822\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=377, train_loss_step=0.0115, train_loss_epoch=0.0122]Epoch 139: Train Loss = 0.011532692238688469\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=377, train_loss_step=0.00793, train_loss_epoch=0.0115]Epoch 140: Train Loss = 0.00793159194290638\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=377, train_loss_step=0.00895, train_loss_epoch=0.00793]Epoch 141: Train Loss = 0.008953343145549297\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, v_num=377, train_loss_step=0.0081, train_loss_epoch=0.00895] Epoch 142: Train Loss = 0.008095971308648586\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=377, train_loss_step=0.00949, train_loss_epoch=0.0081]Epoch 143: Train Loss = 0.009494936093688011\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=377, train_loss_step=0.008, train_loss_epoch=0.00949]  Epoch 144: Train Loss = 0.00800060573965311\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=377, train_loss_step=0.00844, train_loss_epoch=0.008]Epoch 145: Train Loss = 0.008443848229944706\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=377, train_loss_step=0.0113, train_loss_epoch=0.00844] Epoch 146: Train Loss = 0.01129270251840353\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=377, train_loss_step=0.0103, train_loss_epoch=0.0113] Epoch 147: Train Loss = 0.010287007316946983\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=377, train_loss_step=0.0117, train_loss_epoch=0.0103]Epoch 148: Train Loss = 0.01167671475559473\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.0117]Epoch 149: Train Loss = 0.01061958260834217\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=377, train_loss_step=0.0113, train_loss_epoch=0.0106]Epoch 150: Train Loss = 0.011281643994152546\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.0113]Epoch 151: Train Loss = 0.01060765702277422\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=377, train_loss_step=0.0117, train_loss_epoch=0.0106]Epoch 152: Train Loss = 0.011746393516659737\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=377, train_loss_step=0.0121, train_loss_epoch=0.0117]Epoch 153: Train Loss = 0.012101220898330212\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.0121]Epoch 154: Train Loss = 0.010054499842226505\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.0101]Epoch 155: Train Loss = 0.01017728727310896\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=377, train_loss_step=0.00766, train_loss_epoch=0.0102]Epoch 156: Train Loss = 0.007662024814635515\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=377, train_loss_step=0.00943, train_loss_epoch=0.00766]Epoch 157: Train Loss = 0.009427293203771114\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=377, train_loss_step=0.00738, train_loss_epoch=0.00943]Epoch 158: Train Loss = 0.007383373100310564\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.00738] Epoch 159: Train Loss = 0.012728535570204258\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=377, train_loss_step=0.0116, train_loss_epoch=0.0127] Epoch 160: Train Loss = 0.01160565298050642\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=377, train_loss_step=0.014, train_loss_epoch=0.0116] Epoch 161: Train Loss = 0.013957176357507706\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.014]Epoch 162: Train Loss = 0.010406039655208588\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.0104]Epoch 163: Train Loss = 0.010374536737799644\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=377, train_loss_step=0.0128, train_loss_epoch=0.0104]Epoch 164: Train Loss = 0.012751861475408077\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=377, train_loss_step=0.015, train_loss_epoch=0.0128] Epoch 165: Train Loss = 0.015031605958938599\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=377, train_loss_step=0.0122, train_loss_epoch=0.015]Epoch 166: Train Loss = 0.012214227579534054\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=377, train_loss_step=0.0129, train_loss_epoch=0.0122]Epoch 167: Train Loss = 0.012905844487249851\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.0129]Epoch 168: Train Loss = 0.010156328789889812\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=377, train_loss_step=0.0143, train_loss_epoch=0.0102]Epoch 169: Train Loss = 0.014266927726566792\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.0143]Epoch 170: Train Loss = 0.010143297724425793\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=377, train_loss_step=0.00893, train_loss_epoch=0.0101]Epoch 171: Train Loss = 0.008930519223213196\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=377, train_loss_step=0.00862, train_loss_epoch=0.00893]Epoch 172: Train Loss = 0.0086210323497653\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=377, train_loss_step=0.00818, train_loss_epoch=0.00862]Epoch 173: Train Loss = 0.008181018754839897\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=377, train_loss_step=0.0108, train_loss_epoch=0.00818] Epoch 174: Train Loss = 0.010798238217830658\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=377, train_loss_step=0.0128, train_loss_epoch=0.0108] Epoch 175: Train Loss = 0.012785211205482483\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=377, train_loss_step=0.00986, train_loss_epoch=0.0128]Epoch 176: Train Loss = 0.009855414740741253\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=377, train_loss_step=0.00875, train_loss_epoch=0.00986]Epoch 177: Train Loss = 0.00874749943614006\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=377, train_loss_step=0.011, train_loss_epoch=0.00875]  Epoch 178: Train Loss = 0.010999180376529694\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=377, train_loss_step=0.00905, train_loss_epoch=0.011]Epoch 179: Train Loss = 0.009054673835635185\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=377, train_loss_step=0.0122, train_loss_epoch=0.00905] Epoch 180: Train Loss = 0.012177982367575169\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=377, train_loss_step=0.0148, train_loss_epoch=0.0122] Epoch 181: Train Loss = 0.014819919131696224\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=377, train_loss_step=0.0156, train_loss_epoch=0.0148]Epoch 182: Train Loss = 0.015647707507014275\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=377, train_loss_step=0.0131, train_loss_epoch=0.0156]Epoch 183: Train Loss = 0.0130744818598032\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.0131]Epoch 184: Train Loss = 0.010409193113446236\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, v_num=377, train_loss_step=0.00876, train_loss_epoch=0.0104]Epoch 185: Train Loss = 0.008757597766816616\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 11.33it/s, v_num=377, train_loss_step=0.00852, train_loss_epoch=0.00876]Epoch 186: Train Loss = 0.008517584763467312\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=377, train_loss_step=0.0131, train_loss_epoch=0.00852] Epoch 187: Train Loss = 0.013051888905465603\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.0131] Epoch 188: Train Loss = 0.011409936472773552\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=377, train_loss_step=0.00948, train_loss_epoch=0.0114]Epoch 189: Train Loss = 0.009475343860685825\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=377, train_loss_step=0.00991, train_loss_epoch=0.00948]Epoch 190: Train Loss = 0.009907648898661137\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=377, train_loss_step=0.0103, train_loss_epoch=0.00991] Epoch 191: Train Loss = 0.010326767340302467\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=377, train_loss_step=0.0139, train_loss_epoch=0.0103] Epoch 192: Train Loss = 0.013866390101611614\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=377, train_loss_step=0.011, train_loss_epoch=0.0139] Epoch 193: Train Loss = 0.010950981639325619\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.011]Epoch 194: Train Loss = 0.01123961340636015\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=377, train_loss_step=0.0095, train_loss_epoch=0.0112]Epoch 195: Train Loss = 0.009504021145403385\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=377, train_loss_step=0.00864, train_loss_epoch=0.0095]Epoch 196: Train Loss = 0.008638248778879642\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=377, train_loss_step=0.00996, train_loss_epoch=0.00864]Epoch 197: Train Loss = 0.009962039068341255\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=377, train_loss_step=0.0107, train_loss_epoch=0.00996] Epoch 198: Train Loss = 0.010680800303816795\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, v_num=377, train_loss_step=0.00921, train_loss_epoch=0.0107]Epoch 199: Train Loss = 0.009207378141582012\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=377, train_loss_step=0.011, train_loss_epoch=0.00921]  Epoch 200: Train Loss = 0.010975432582199574\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=377, train_loss_step=0.00813, train_loss_epoch=0.011]Epoch 201: Train Loss = 0.008131801150739193\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=377, train_loss_step=0.00894, train_loss_epoch=0.00813]Epoch 202: Train Loss = 0.008940726518630981\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=377, train_loss_step=0.00751, train_loss_epoch=0.00894]Epoch 203: Train Loss = 0.00751459551975131\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.00751] Epoch 204: Train Loss = 0.01039909664541483\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=377, train_loss_step=0.0111, train_loss_epoch=0.0104] Epoch 205: Train Loss = 0.01108627114444971\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=377, train_loss_step=0.0128, train_loss_epoch=0.0111]Epoch 206: Train Loss = 0.012793582864105701\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.0128]Epoch 207: Train Loss = 0.010063502006232738\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.0101]Epoch 208: Train Loss = 0.012656005099415779\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.0127]Epoch 209: Train Loss = 0.01269523799419403\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 13.41it/s, v_num=377, train_loss_step=0.00902, train_loss_epoch=0.0127]Epoch 210: Train Loss = 0.009017433039844036\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=377, train_loss_step=0.010, train_loss_epoch=0.00902]  Epoch 211: Train Loss = 0.0100396191701293\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=377, train_loss_step=0.00903, train_loss_epoch=0.010]Epoch 212: Train Loss = 0.009031367488205433\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, v_num=377, train_loss_step=0.00927, train_loss_epoch=0.00903]Epoch 213: Train Loss = 0.009272332303225994\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s, v_num=377, train_loss_step=0.0103, train_loss_epoch=0.00927] Epoch 214: Train Loss = 0.010287085548043251\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=377, train_loss_step=0.0128, train_loss_epoch=0.0103] Epoch 215: Train Loss = 0.012794489040970802\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=377, train_loss_step=0.0145, train_loss_epoch=0.0128]Epoch 216: Train Loss = 0.014483639039099216\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.0145]Epoch 217: Train Loss = 0.010395882651209831\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=377, train_loss_step=0.0134, train_loss_epoch=0.0104]Epoch 218: Train Loss = 0.013411021791398525\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=377, train_loss_step=0.0111, train_loss_epoch=0.0134]Epoch 219: Train Loss = 0.011071748100221157\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=377, train_loss_step=0.00766, train_loss_epoch=0.0111]Epoch 220: Train Loss = 0.00765768950805068\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.00766] Epoch 221: Train Loss = 0.010404922999441624\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=377, train_loss_step=0.00955, train_loss_epoch=0.0104]Epoch 222: Train Loss = 0.009550356306135654\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=377, train_loss_step=0.0128, train_loss_epoch=0.00955] Epoch 223: Train Loss = 0.012772412970662117\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=377, train_loss_step=0.00945, train_loss_epoch=0.0128]Epoch 224: Train Loss = 0.009448311291635036\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=377, train_loss_step=0.011, train_loss_epoch=0.00945]  Epoch 225: Train Loss = 0.011033470742404461\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=377, train_loss_step=0.0133, train_loss_epoch=0.011] Epoch 226: Train Loss = 0.01327150035649538\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=377, train_loss_step=0.0117, train_loss_epoch=0.0133]Epoch 227: Train Loss = 0.011691550724208355\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=377, train_loss_step=0.0109, train_loss_epoch=0.0117]Epoch 228: Train Loss = 0.010881046764552593\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 12.51it/s, v_num=377, train_loss_step=0.014, train_loss_epoch=0.0109] Epoch 229: Train Loss = 0.014044205658137798\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=377, train_loss_step=0.00985, train_loss_epoch=0.014]Epoch 230: Train Loss = 0.009847523644566536\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.00985] Epoch 231: Train Loss = 0.010622440837323666\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=377, train_loss_step=0.0138, train_loss_epoch=0.0106] Epoch 232: Train Loss = 0.01379026286303997\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=377, train_loss_step=0.0123, train_loss_epoch=0.0138]Epoch 233: Train Loss = 0.012298494577407837\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=377, train_loss_step=0.0133, train_loss_epoch=0.0123]Epoch 234: Train Loss = 0.013250237330794334\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=377, train_loss_step=0.0124, train_loss_epoch=0.0133]Epoch 235: Train Loss = 0.012364274822175503\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=377, train_loss_step=0.0158, train_loss_epoch=0.0124]Epoch 236: Train Loss = 0.015787288546562195\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 11.40it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.0158]Epoch 237: Train Loss = 0.010358864441514015\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=377, train_loss_step=0.0138, train_loss_epoch=0.0104]Epoch 238: Train Loss = 0.013849199749529362\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.0138]Epoch 239: Train Loss = 0.0106196915730834\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.0106]Epoch 240: Train Loss = 0.010394193232059479\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.0104]Epoch 241: Train Loss = 0.012749223038554192\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.0127]Epoch 242: Train Loss = 0.011228135786950588\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=377, train_loss_step=0.0123, train_loss_epoch=0.0112]Epoch 243: Train Loss = 0.012288765050470829\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.0123]Epoch 244: Train Loss = 0.011446059681475163\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=377, train_loss_step=0.0156, train_loss_epoch=0.0114]Epoch 245: Train Loss = 0.015583930537104607\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=377, train_loss_step=0.0215, train_loss_epoch=0.0156]Epoch 246: Train Loss = 0.021519958972930908\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=377, train_loss_step=0.0105, train_loss_epoch=0.0215]Epoch 247: Train Loss = 0.010530737228691578\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=377, train_loss_step=0.0125, train_loss_epoch=0.0105]Epoch 248: Train Loss = 0.012464714236557484\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=377, train_loss_step=0.0125, train_loss_epoch=0.0125]Epoch 249: Train Loss = 0.012497635558247566\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=377, train_loss_step=0.0168, train_loss_epoch=0.0125]Epoch 250: Train Loss = 0.01680057682096958\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.0168]Epoch 251: Train Loss = 0.011220237240195274\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=377, train_loss_step=0.00905, train_loss_epoch=0.0112]Epoch 252: Train Loss = 0.00904738251119852\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=377, train_loss_step=0.0134, train_loss_epoch=0.00905] Epoch 253: Train Loss = 0.013369061052799225\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=377, train_loss_step=0.0133, train_loss_epoch=0.0134] Epoch 254: Train Loss = 0.013341655023396015\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=377, train_loss_step=0.0111, train_loss_epoch=0.0133]Epoch 255: Train Loss = 0.01107075810432434\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=377, train_loss_step=0.0119, train_loss_epoch=0.0111]Epoch 256: Train Loss = 0.011883154511451721\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=377, train_loss_step=0.015, train_loss_epoch=0.0119] Epoch 257: Train Loss = 0.015042017214000225\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=377, train_loss_step=0.00986, train_loss_epoch=0.015]Epoch 258: Train Loss = 0.009860374964773655\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=377, train_loss_step=0.0116, train_loss_epoch=0.00986] Epoch 259: Train Loss = 0.01158121693879366\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=377, train_loss_step=0.0105, train_loss_epoch=0.0116] Epoch 260: Train Loss = 0.010456783697009087\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.0105]Epoch 261: Train Loss = 0.011153214611113071\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.0112]Epoch 262: Train Loss = 0.010100170038640499\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 13.54it/s, v_num=377, train_loss_step=0.0125, train_loss_epoch=0.0101]Epoch 263: Train Loss = 0.01254248432815075\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, v_num=377, train_loss_step=0.0132, train_loss_epoch=0.0125]Epoch 264: Train Loss = 0.013247912749648094\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=377, train_loss_step=0.0142, train_loss_epoch=0.0132]Epoch 265: Train Loss = 0.014216155745089054\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=377, train_loss_step=0.0125, train_loss_epoch=0.0142]Epoch 266: Train Loss = 0.012457658536732197\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=377, train_loss_step=0.00719, train_loss_epoch=0.0125]Epoch 267: Train Loss = 0.0071931867860257626\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=377, train_loss_step=0.0154, train_loss_epoch=0.00719] Epoch 268: Train Loss = 0.01535042840987444\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=377, train_loss_step=0.00918, train_loss_epoch=0.0154]Epoch 269: Train Loss = 0.009182959794998169\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=377, train_loss_step=0.0129, train_loss_epoch=0.00918] Epoch 270: Train Loss = 0.012864801101386547\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.0129] Epoch 271: Train Loss = 0.011152132414281368\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.0112]Epoch 272: Train Loss = 0.010637876577675343\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=377, train_loss_step=0.0111, train_loss_epoch=0.0106]Epoch 273: Train Loss = 0.01107572577893734\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=377, train_loss_step=0.0119, train_loss_epoch=0.0111]Epoch 274: Train Loss = 0.011876926757395267\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=377, train_loss_step=0.0121, train_loss_epoch=0.0119]Epoch 275: Train Loss = 0.012053685262799263\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=377, train_loss_step=0.0105, train_loss_epoch=0.0121]Epoch 276: Train Loss = 0.010496320202946663\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=377, train_loss_step=0.0103, train_loss_epoch=0.0105]Epoch 277: Train Loss = 0.010312199592590332\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=377, train_loss_step=0.00971, train_loss_epoch=0.0103]Epoch 278: Train Loss = 0.009709751233458519\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=377, train_loss_step=0.00821, train_loss_epoch=0.00971]Epoch 279: Train Loss = 0.008213999681174755\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=377, train_loss_step=0.00954, train_loss_epoch=0.00821]Epoch 280: Train Loss = 0.009538426995277405\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=377, train_loss_step=0.011, train_loss_epoch=0.00954]  Epoch 281: Train Loss = 0.010995270684361458\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=377, train_loss_step=0.0117, train_loss_epoch=0.011] Epoch 282: Train Loss = 0.01172944251447916\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=377, train_loss_step=0.0113, train_loss_epoch=0.0117]Epoch 283: Train Loss = 0.011284719221293926\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=377, train_loss_step=0.0109, train_loss_epoch=0.0113]Epoch 284: Train Loss = 0.01090782880783081\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 10.18it/s, v_num=377, train_loss_step=0.00951, train_loss_epoch=0.0109]Epoch 285: Train Loss = 0.009508049115538597\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=377, train_loss_step=0.0125, train_loss_epoch=0.00951] Epoch 286: Train Loss = 0.012510053813457489\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=377, train_loss_step=0.012, train_loss_epoch=0.0125]  Epoch 287: Train Loss = 0.011994747444987297\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=377, train_loss_step=0.00863, train_loss_epoch=0.012]Epoch 288: Train Loss = 0.008633981458842754\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=377, train_loss_step=0.0146, train_loss_epoch=0.00863] Epoch 289: Train Loss = 0.014575549401342869\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=377, train_loss_step=0.0133, train_loss_epoch=0.0146] Epoch 290: Train Loss = 0.013329803012311459\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=377, train_loss_step=0.00908, train_loss_epoch=0.0133]Epoch 291: Train Loss = 0.009075576439499855\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 13.05it/s, v_num=377, train_loss_step=0.0118, train_loss_epoch=0.00908] Epoch 292: Train Loss = 0.011835834011435509\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=377, train_loss_step=0.00821, train_loss_epoch=0.0118]Epoch 293: Train Loss = 0.008214364759624004\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=377, train_loss_step=0.0109, train_loss_epoch=0.00821] Epoch 294: Train Loss = 0.010924897156655788\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=377, train_loss_step=0.0122, train_loss_epoch=0.0109] Epoch 295: Train Loss = 0.012189014814794064\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.0122]Epoch 296: Train Loss = 0.011396527290344238\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=377, train_loss_step=0.0135, train_loss_epoch=0.0114]Epoch 297: Train Loss = 0.013535977341234684\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=377, train_loss_step=0.00934, train_loss_epoch=0.0135]Epoch 298: Train Loss = 0.009339040145277977\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=377, train_loss_step=0.0113, train_loss_epoch=0.00934] Epoch 299: Train Loss = 0.011266462504863739\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.0113] Epoch 300: Train Loss = 0.010241253301501274\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=377, train_loss_step=0.0108, train_loss_epoch=0.0102]Epoch 301: Train Loss = 0.010751299560070038\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=377, train_loss_step=0.0131, train_loss_epoch=0.0108]Epoch 302: Train Loss = 0.01307161245495081\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.0131]Epoch 303: Train Loss = 0.0126692159101367\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=377, train_loss_step=0.0121, train_loss_epoch=0.0127]Epoch 304: Train Loss = 0.012133250012993813\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.0121]Epoch 305: Train Loss = 0.01273171603679657\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=377, train_loss_step=0.0117, train_loss_epoch=0.0127]Epoch 306: Train Loss = 0.011710690334439278\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=377, train_loss_step=0.0105, train_loss_epoch=0.0117]Epoch 307: Train Loss = 0.01046688947826624\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.0105]Epoch 308: Train Loss = 0.010147660039365292\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.0101]Epoch 309: Train Loss = 0.010430008172988892\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=377, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 310: Train Loss = 0.011496196500957012\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.0115]Epoch 311: Train Loss = 0.010132725350558758\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=377, train_loss_step=0.00983, train_loss_epoch=0.0101]Epoch 312: Train Loss = 0.00982646457850933\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.00983] Epoch 313: Train Loss = 0.011241800151765347\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=377, train_loss_step=0.00874, train_loss_epoch=0.0112]Epoch 314: Train Loss = 0.008744541555643082\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.00874] Epoch 315: Train Loss = 0.012709125876426697\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=377, train_loss_step=0.012, train_loss_epoch=0.0127]  Epoch 316: Train Loss = 0.01203638780862093\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=377, train_loss_step=0.00951, train_loss_epoch=0.012]Epoch 317: Train Loss = 0.0095060458406806\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.00951] Epoch 318: Train Loss = 0.010249564424157143\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=377, train_loss_step=0.00918, train_loss_epoch=0.0102]Epoch 319: Train Loss = 0.009175145998597145\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.00918] Epoch 320: Train Loss = 0.011371160857379436\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=377, train_loss_step=0.0092, train_loss_epoch=0.0114] Epoch 321: Train Loss = 0.009196375496685505\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, v_num=377, train_loss_step=0.0103, train_loss_epoch=0.0092]Epoch 322: Train Loss = 0.010325117968022823\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=377, train_loss_step=0.0107, train_loss_epoch=0.0103]Epoch 323: Train Loss = 0.01072847843170166\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 13.22it/s, v_num=377, train_loss_step=0.00965, train_loss_epoch=0.0107]Epoch 324: Train Loss = 0.009646043181419373\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=377, train_loss_step=0.00949, train_loss_epoch=0.00965]Epoch 325: Train Loss = 0.009491004049777985\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=377, train_loss_step=0.0142, train_loss_epoch=0.00949] Epoch 326: Train Loss = 0.01418355293571949\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=377, train_loss_step=0.0107, train_loss_epoch=0.0142] Epoch 327: Train Loss = 0.010667198337614536\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 13.55it/s, v_num=377, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 328: Train Loss = 0.011599432677030563\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=377, train_loss_step=0.0079, train_loss_epoch=0.0116]Epoch 329: Train Loss = 0.007902299985289574\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=377, train_loss_step=0.0125, train_loss_epoch=0.0079]Epoch 330: Train Loss = 0.012489543296396732\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=377, train_loss_step=0.012, train_loss_epoch=0.0125] Epoch 331: Train Loss = 0.012049459852278233\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=377, train_loss_step=0.00777, train_loss_epoch=0.012]Epoch 332: Train Loss = 0.007766985800117254\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=377, train_loss_step=0.0122, train_loss_epoch=0.00777] Epoch 333: Train Loss = 0.012178266420960426\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=377, train_loss_step=0.00817, train_loss_epoch=0.0122]Epoch 334: Train Loss = 0.008170629851520061\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=377, train_loss_step=0.00712, train_loss_epoch=0.00817]Epoch 335: Train Loss = 0.007117662578821182\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=377, train_loss_step=0.0115, train_loss_epoch=0.00712] Epoch 336: Train Loss = 0.01151824276894331\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=377, train_loss_step=0.00898, train_loss_epoch=0.0115]Epoch 337: Train Loss = 0.00898213405162096\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=377, train_loss_step=0.0096, train_loss_epoch=0.00898] Epoch 338: Train Loss = 0.009602195583283901\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=377, train_loss_step=0.00953, train_loss_epoch=0.0096]Epoch 339: Train Loss = 0.009528756141662598\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, v_num=377, train_loss_step=0.0109, train_loss_epoch=0.00953] Epoch 340: Train Loss = 0.010864990763366222\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.0109] Epoch 341: Train Loss = 0.010194770060479641\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=377, train_loss_step=0.00858, train_loss_epoch=0.0102]Epoch 342: Train Loss = 0.008582601323723793\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=377, train_loss_step=0.0118, train_loss_epoch=0.00858] Epoch 343: Train Loss = 0.011802634224295616\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=377, train_loss_step=0.00856, train_loss_epoch=0.0118]Epoch 344: Train Loss = 0.008561605587601662\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=377, train_loss_step=0.00981, train_loss_epoch=0.00856]Epoch 345: Train Loss = 0.009808184579014778\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=377, train_loss_step=0.013, train_loss_epoch=0.00981]  Epoch 346: Train Loss = 0.012968005612492561\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.013] Epoch 347: Train Loss = 0.010617117397487164\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=377, train_loss_step=0.0127, train_loss_epoch=0.0106]Epoch 348: Train Loss = 0.012707501649856567\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=377, train_loss_step=0.00794, train_loss_epoch=0.0127]Epoch 349: Train Loss = 0.007939130999147892\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.00794] Epoch 350: Train Loss = 0.01035954337567091\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=377, train_loss_step=0.0103, train_loss_epoch=0.0104] Epoch 351: Train Loss = 0.010269294492900372\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=377, train_loss_step=0.0119, train_loss_epoch=0.0103]Epoch 352: Train Loss = 0.011881253682076931\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=377, train_loss_step=0.00847, train_loss_epoch=0.0119]Epoch 353: Train Loss = 0.008472221903502941\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=377, train_loss_step=0.00737, train_loss_epoch=0.00847]Epoch 354: Train Loss = 0.007372881751507521\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.00737] Epoch 355: Train Loss = 0.010636636056005955\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=377, train_loss_step=0.0115, train_loss_epoch=0.0106] Epoch 356: Train Loss = 0.011468520388007164\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=377, train_loss_step=0.0105, train_loss_epoch=0.0115]Epoch 357: Train Loss = 0.010482867248356342\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 12.77it/s, v_num=377, train_loss_step=0.0105, train_loss_epoch=0.0105]Epoch 358: Train Loss = 0.010496048256754875\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=377, train_loss_step=0.00997, train_loss_epoch=0.0105]Epoch 359: Train Loss = 0.009971650317311287\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.00997] Epoch 360: Train Loss = 0.010408217087388039\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, v_num=377, train_loss_step=0.00925, train_loss_epoch=0.0104]Epoch 361: Train Loss = 0.009248155169188976\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=377, train_loss_step=0.0084, train_loss_epoch=0.00925] Epoch 362: Train Loss = 0.00840388610959053\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, v_num=377, train_loss_step=0.00921, train_loss_epoch=0.0084]Epoch 363: Train Loss = 0.009212150238454342\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=377, train_loss_step=0.00826, train_loss_epoch=0.00921]Epoch 364: Train Loss = 0.008264514617621899\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=377, train_loss_step=0.00988, train_loss_epoch=0.00826]Epoch 365: Train Loss = 0.009876453317701817\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=377, train_loss_step=0.00938, train_loss_epoch=0.00988]Epoch 366: Train Loss = 0.009377611801028252\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=377, train_loss_step=0.00997, train_loss_epoch=0.00938]Epoch 367: Train Loss = 0.009971861727535725\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=377, train_loss_step=0.00873, train_loss_epoch=0.00997]Epoch 368: Train Loss = 0.008728419430553913\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.00873] Epoch 369: Train Loss = 0.011235679499804974\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=377, train_loss_step=0.00719, train_loss_epoch=0.0112]Epoch 370: Train Loss = 0.007193574216216803\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=377, train_loss_step=0.00932, train_loss_epoch=0.00719]Epoch 371: Train Loss = 0.00931649561971426\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.00932] Epoch 372: Train Loss = 0.010360175743699074\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=377, train_loss_step=0.00894, train_loss_epoch=0.0104]Epoch 373: Train Loss = 0.008937603794038296\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=377, train_loss_step=0.00779, train_loss_epoch=0.00894]Epoch 374: Train Loss = 0.007787502370774746\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=377, train_loss_step=0.00796, train_loss_epoch=0.00779]Epoch 375: Train Loss = 0.007957655005156994\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=377, train_loss_step=0.0128, train_loss_epoch=0.00796] Epoch 376: Train Loss = 0.012823815457522869\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.0128] Epoch 377: Train Loss = 0.011155168525874615\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=377, train_loss_step=0.011, train_loss_epoch=0.0112] Epoch 378: Train Loss = 0.011042105965316296\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.011]Epoch 379: Train Loss = 0.010146506130695343\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=377, train_loss_step=0.0111, train_loss_epoch=0.0101]Epoch 380: Train Loss = 0.011121316812932491\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=377, train_loss_step=0.00773, train_loss_epoch=0.0111]Epoch 381: Train Loss = 0.007733493112027645\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=377, train_loss_step=0.0123, train_loss_epoch=0.00773] Epoch 382: Train Loss = 0.012278649024665356\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=377, train_loss_step=0.00981, train_loss_epoch=0.0123]Epoch 383: Train Loss = 0.009805405512452126\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=377, train_loss_step=0.00947, train_loss_epoch=0.00981]Epoch 384: Train Loss = 0.009472169913351536\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=377, train_loss_step=0.00897, train_loss_epoch=0.00947]Epoch 385: Train Loss = 0.008966033346951008\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=377, train_loss_step=0.0118, train_loss_epoch=0.00897] Epoch 386: Train Loss = 0.011812356300652027\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.0118] Epoch 387: Train Loss = 0.010566933080554008\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=377, train_loss_step=0.00966, train_loss_epoch=0.0106]Epoch 388: Train Loss = 0.009664395824074745\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=377, train_loss_step=0.0134, train_loss_epoch=0.00966] Epoch 389: Train Loss = 0.013372081331908703\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.0134] Epoch 390: Train Loss = 0.010213484987616539\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.0102]Epoch 391: Train Loss = 0.010203099809587002\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=377, train_loss_step=0.00964, train_loss_epoch=0.0102]Epoch 392: Train Loss = 0.009642030112445354\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=377, train_loss_step=0.0103, train_loss_epoch=0.00964] Epoch 393: Train Loss = 0.010287346318364143\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=377, train_loss_step=0.00957, train_loss_epoch=0.0103]Epoch 394: Train Loss = 0.00957218836992979\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=377, train_loss_step=0.0103, train_loss_epoch=0.00957] Epoch 395: Train Loss = 0.010276006534695625\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, v_num=377, train_loss_step=0.0111, train_loss_epoch=0.0103] Epoch 396: Train Loss = 0.01106849405914545\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, v_num=377, train_loss_step=0.0123, train_loss_epoch=0.0111]Epoch 397: Train Loss = 0.012321194633841515\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.0123]Epoch 398: Train Loss = 0.011389883235096931\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=377, train_loss_step=0.00897, train_loss_epoch=0.0114]Epoch 399: Train Loss = 0.008969062007963657\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.00897] Epoch 400: Train Loss = 0.011163330636918545\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.0112] Epoch 401: Train Loss = 0.010355805978178978\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, v_num=377, train_loss_step=0.00801, train_loss_epoch=0.0104]Epoch 402: Train Loss = 0.008014797233045101\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=377, train_loss_step=0.0098, train_loss_epoch=0.00801] Epoch 403: Train Loss = 0.009796652011573315\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.0098] Epoch 404: Train Loss = 0.01143183559179306\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=377, train_loss_step=0.0097, train_loss_epoch=0.0114]Epoch 405: Train Loss = 0.00970438215881586\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=377, train_loss_step=0.0107, train_loss_epoch=0.0097]Epoch 406: Train Loss = 0.010683887638151646\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=377, train_loss_step=0.00856, train_loss_epoch=0.0107]Epoch 407: Train Loss = 0.008555153384804726\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.00856] Epoch 408: Train Loss = 0.010387924499809742\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=377, train_loss_step=0.0132, train_loss_epoch=0.0104] Epoch 409: Train Loss = 0.013184149749577045\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=377, train_loss_step=0.00985, train_loss_epoch=0.0132]Epoch 410: Train Loss = 0.009853988885879517\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.00985] Epoch 411: Train Loss = 0.010220031253993511\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=377, train_loss_step=0.0126, train_loss_epoch=0.0102] Epoch 412: Train Loss = 0.012566874735057354\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=377, train_loss_step=0.00894, train_loss_epoch=0.0126]Epoch 413: Train Loss = 0.008942465297877789\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=377, train_loss_step=0.00943, train_loss_epoch=0.00894]Epoch 414: Train Loss = 0.009433682076632977\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=377, train_loss_step=0.0113, train_loss_epoch=0.00943] Epoch 415: Train Loss = 0.011338566429913044\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=377, train_loss_step=0.0129, train_loss_epoch=0.0113] Epoch 416: Train Loss = 0.012878315523266792\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=377, train_loss_step=0.00839, train_loss_epoch=0.0129]Epoch 417: Train Loss = 0.008389183320105076\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=377, train_loss_step=0.0147, train_loss_epoch=0.00839] Epoch 418: Train Loss = 0.014708340167999268\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=377, train_loss_step=0.00843, train_loss_epoch=0.0147]Epoch 419: Train Loss = 0.00843134056776762\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=377, train_loss_step=0.00908, train_loss_epoch=0.00843]Epoch 420: Train Loss = 0.009075924754142761\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=377, train_loss_step=0.0119, train_loss_epoch=0.00908] Epoch 421: Train Loss = 0.011864796280860901\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=377, train_loss_step=0.00861, train_loss_epoch=0.0119]Epoch 422: Train Loss = 0.0086058983579278\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=377, train_loss_step=0.0117, train_loss_epoch=0.00861] Epoch 423: Train Loss = 0.011661342345178127\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=377, train_loss_step=0.00997, train_loss_epoch=0.0117]Epoch 424: Train Loss = 0.009974460117518902\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 12.32it/s, v_num=377, train_loss_step=0.00748, train_loss_epoch=0.00997]Epoch 425: Train Loss = 0.00747712654992938\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=377, train_loss_step=0.00954, train_loss_epoch=0.00748]Epoch 426: Train Loss = 0.009539213962852955\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.00954] Epoch 427: Train Loss = 0.010570064187049866\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s, v_num=377, train_loss_step=0.010, train_loss_epoch=0.0106]  Epoch 428: Train Loss = 0.010006291791796684\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.010]Epoch 429: Train Loss = 0.010131041519343853\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.0101]Epoch 430: Train Loss = 0.010207648389041424\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 13.19it/s, v_num=377, train_loss_step=0.0092, train_loss_epoch=0.0102]Epoch 431: Train Loss = 0.00919649749994278\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=377, train_loss_step=0.0142, train_loss_epoch=0.0092]Epoch 432: Train Loss = 0.01417631097137928\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=377, train_loss_step=0.0122, train_loss_epoch=0.0142]Epoch 433: Train Loss = 0.01223920751363039\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=377, train_loss_step=0.00926, train_loss_epoch=0.0122]Epoch 434: Train Loss = 0.009263044223189354\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=377, train_loss_step=0.00957, train_loss_epoch=0.00926]Epoch 435: Train Loss = 0.00956648588180542\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=377, train_loss_step=0.00991, train_loss_epoch=0.00957]Epoch 436: Train Loss = 0.009910483844578266\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=377, train_loss_step=0.0095, train_loss_epoch=0.00991] Epoch 437: Train Loss = 0.00949771236628294\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=377, train_loss_step=0.0111, train_loss_epoch=0.0095] Epoch 438: Train Loss = 0.011060512624680996\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=377, train_loss_step=0.00931, train_loss_epoch=0.0111]Epoch 439: Train Loss = 0.00930724199861288\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.00931] Epoch 440: Train Loss = 0.010211825370788574\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=377, train_loss_step=0.00917, train_loss_epoch=0.0102]Epoch 441: Train Loss = 0.009174966253340244\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=377, train_loss_step=0.0107, train_loss_epoch=0.00917] Epoch 442: Train Loss = 0.01065729558467865\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.0107] Epoch 443: Train Loss = 0.011231916025280952\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.0112]Epoch 444: Train Loss = 0.010449106805026531\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=377, train_loss_step=0.0136, train_loss_epoch=0.0104]Epoch 445: Train Loss = 0.013568500988185406\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=377, train_loss_step=0.0147, train_loss_epoch=0.0136]Epoch 446: Train Loss = 0.01473221741616726\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=377, train_loss_step=0.0134, train_loss_epoch=0.0147]Epoch 447: Train Loss = 0.013440864160656929\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=377, train_loss_step=0.00993, train_loss_epoch=0.0134]Epoch 448: Train Loss = 0.009933004155755043\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=377, train_loss_step=0.0136, train_loss_epoch=0.00993] Epoch 449: Train Loss = 0.013605333864688873\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s, v_num=377, train_loss_step=0.0128, train_loss_epoch=0.0136] Epoch 450: Train Loss = 0.012821531854569912\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=377, train_loss_step=0.00939, train_loss_epoch=0.0128]Epoch 451: Train Loss = 0.009394549764692783\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=377, train_loss_step=0.0096, train_loss_epoch=0.00939] Epoch 452: Train Loss = 0.009599989280104637\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=377, train_loss_step=0.013, train_loss_epoch=0.0096]  Epoch 453: Train Loss = 0.013013786636292934\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=377, train_loss_step=0.0126, train_loss_epoch=0.013]Epoch 454: Train Loss = 0.012614911422133446\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=377, train_loss_step=0.0112, train_loss_epoch=0.0126]Epoch 455: Train Loss = 0.011182275600731373\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=377, train_loss_step=0.0106, train_loss_epoch=0.0112]Epoch 456: Train Loss = 0.010609826073050499\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=377, train_loss_step=0.0142, train_loss_epoch=0.0106]Epoch 457: Train Loss = 0.014193999581038952\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=377, train_loss_step=0.00873, train_loss_epoch=0.0142]Epoch 458: Train Loss = 0.008727689273655415\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=377, train_loss_step=0.0104, train_loss_epoch=0.00873] Epoch 459: Train Loss = 0.010431991890072823\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=377, train_loss_step=0.0118, train_loss_epoch=0.0104] Epoch 460: Train Loss = 0.011822301894426346\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=377, train_loss_step=0.0148, train_loss_epoch=0.0118]Epoch 461: Train Loss = 0.01484147273004055\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, v_num=377, train_loss_step=0.00664, train_loss_epoch=0.0148]Epoch 462: Train Loss = 0.00663695577532053\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=377, train_loss_step=0.0117, train_loss_epoch=0.00664] Epoch 463: Train Loss = 0.011675717309117317\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=377, train_loss_step=0.0144, train_loss_epoch=0.0117] Epoch 464: Train Loss = 0.014427850022912025\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=377, train_loss_step=0.012, train_loss_epoch=0.0144] Epoch 465: Train Loss = 0.01198109146207571\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=377, train_loss_step=0.013, train_loss_epoch=0.012] Epoch 466: Train Loss = 0.013013591058552265\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=377, train_loss_step=0.00988, train_loss_epoch=0.013]Epoch 467: Train Loss = 0.00988346803933382\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, v_num=377, train_loss_step=0.0126, train_loss_epoch=0.00988] Epoch 468: Train Loss = 0.012551039457321167\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=377, train_loss_step=0.0119, train_loss_epoch=0.0126] Epoch 469: Train Loss = 0.011940190568566322\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=377, train_loss_step=0.00936, train_loss_epoch=0.0119]Epoch 470: Train Loss = 0.009364699013531208\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=377, train_loss_step=0.0114, train_loss_epoch=0.00936] Epoch 471: Train Loss = 0.011401643976569176\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=377, train_loss_step=0.0076, train_loss_epoch=0.0114] Epoch 472: Train Loss = 0.0075986310839653015\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=377, train_loss_step=0.00912, train_loss_epoch=0.0076]Epoch 473: Train Loss = 0.00912033673375845\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=377, train_loss_step=0.0107, train_loss_epoch=0.00912] Epoch 474: Train Loss = 0.010678314603865147\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=377, train_loss_step=0.0149, train_loss_epoch=0.0107] Epoch 475: Train Loss = 0.014852841384708881\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=377, train_loss_step=0.0131, train_loss_epoch=0.0149]Epoch 476: Train Loss = 0.013067581690847874\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=377, train_loss_step=0.012, train_loss_epoch=0.0131] Epoch 477: Train Loss = 0.012029305100440979\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=377, train_loss_step=0.010, train_loss_epoch=0.012] Epoch 478: Train Loss = 0.010047335177659988\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, v_num=377, train_loss_step=0.0101, train_loss_epoch=0.010]Epoch 479: Train Loss = 0.010148987174034119\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=377, train_loss_step=0.0117, train_loss_epoch=0.0101]Epoch 480: Train Loss = 0.011668525636196136\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=377, train_loss_step=0.0128, train_loss_epoch=0.0117]Epoch 481: Train Loss = 0.01281766127794981\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=377, train_loss_step=0.0102, train_loss_epoch=0.0128]Epoch 482: Train Loss = 0.010208352468907833\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=377, train_loss_step=0.0115, train_loss_epoch=0.0102]Epoch 483: Train Loss = 0.01150931604206562\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=377, train_loss_step=0.00889, train_loss_epoch=0.0115]Epoch 484: Train Loss = 0.00888548232614994\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=377, train_loss_step=0.00705, train_loss_epoch=0.00889]Epoch 485: Train Loss = 0.007046888116747141\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 13.49it/s, v_num=377, train_loss_step=0.0109, train_loss_epoch=0.00705] Epoch 486: Train Loss = 0.010857313871383667\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=377, train_loss_step=0.0122, train_loss_epoch=0.0109] Epoch 487: Train Loss = 0.012224161066114902\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=377, train_loss_step=0.00842, train_loss_epoch=0.0122]Epoch 488: Train Loss = 0.008415428921580315\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=377, train_loss_step=0.00963, train_loss_epoch=0.00842]Epoch 489: Train Loss = 0.009626834653317928\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=377, train_loss_step=0.00998, train_loss_epoch=0.00963]Epoch 490: Train Loss = 0.00997545849531889\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=377, train_loss_step=0.00932, train_loss_epoch=0.00998]Epoch 491: Train Loss = 0.009323573671281338\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=377, train_loss_step=0.00862, train_loss_epoch=0.00932]Epoch 492: Train Loss = 0.0086152208968997\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=377, train_loss_step=0.0107, train_loss_epoch=0.00862] Epoch 493: Train Loss = 0.010726260021328926\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=377, train_loss_step=0.0121, train_loss_epoch=0.0107] Epoch 494: Train Loss = 0.012116109021008015\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=377, train_loss_step=0.0115, train_loss_epoch=0.0121]Epoch 495: Train Loss = 0.01151724997907877\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=377, train_loss_step=0.00934, train_loss_epoch=0.0115]Epoch 496: Train Loss = 0.009339118376374245\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=377, train_loss_step=0.00906, train_loss_epoch=0.00934]Epoch 497: Train Loss = 0.009060033597052097\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=377, train_loss_step=0.0113, train_loss_epoch=0.00906] Epoch 498: Train Loss = 0.011283135041594505\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.09it/s, v_num=377, train_loss_step=0.010, train_loss_epoch=0.0113]  Epoch 499: Train Loss = 0.010015777312219143\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.81it/s, v_num=377, train_loss_step=0.010, train_loss_epoch=0.010] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.59it/s, v_num=377, train_loss_step=0.010, train_loss_epoch=0.010]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 19: from 2008-05-12 00:00:00 to 2022-12-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=379, train_loss_step=0.0253]Epoch 0: Train Loss = 0.025311456993222237\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=379, train_loss_step=0.0361, train_loss_epoch=0.0253]Epoch 1: Train Loss = 0.036133382469415665\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=379, train_loss_step=0.0268, train_loss_epoch=0.0361]Epoch 2: Train Loss = 0.026788726449012756\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=379, train_loss_step=0.0197, train_loss_epoch=0.0268]Epoch 3: Train Loss = 0.01968022808432579\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=379, train_loss_step=0.0202, train_loss_epoch=0.0197]Epoch 4: Train Loss = 0.0202138964086771\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=379, train_loss_step=0.0178, train_loss_epoch=0.0202]Epoch 5: Train Loss = 0.017750294879078865\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=379, train_loss_step=0.0122, train_loss_epoch=0.0178]Epoch 6: Train Loss = 0.012164239771664143\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=379, train_loss_step=0.0158, train_loss_epoch=0.0122]Epoch 7: Train Loss = 0.015789946541190147\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=379, train_loss_step=0.0132, train_loss_epoch=0.0158]Epoch 8: Train Loss = 0.01324026845395565\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=379, train_loss_step=0.0127, train_loss_epoch=0.0132]Epoch 9: Train Loss = 0.012712948024272919\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=379, train_loss_step=0.0174, train_loss_epoch=0.0127]Epoch 10: Train Loss = 0.01735960878431797\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=379, train_loss_step=0.0124, train_loss_epoch=0.0174]Epoch 11: Train Loss = 0.01238658931106329\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0124]Epoch 12: Train Loss = 0.0111697381362319\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=379, train_loss_step=0.0144, train_loss_epoch=0.0112]Epoch 13: Train Loss = 0.014377950690686703\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=379, train_loss_step=0.0139, train_loss_epoch=0.0144]Epoch 14: Train Loss = 0.013909376226365566\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=379, train_loss_step=0.0115, train_loss_epoch=0.0139]Epoch 15: Train Loss = 0.011495104059576988\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=379, train_loss_step=0.00894, train_loss_epoch=0.0115]Epoch 16: Train Loss = 0.008943097665905952\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=379, train_loss_step=0.0136, train_loss_epoch=0.00894] Epoch 17: Train Loss = 0.013572747819125652\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=379, train_loss_step=0.0129, train_loss_epoch=0.0136] Epoch 18: Train Loss = 0.012867498211562634\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=379, train_loss_step=0.0135, train_loss_epoch=0.0129]Epoch 19: Train Loss = 0.01347169280052185\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0135]Epoch 20: Train Loss = 0.01118201669305563\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=379, train_loss_step=0.0129, train_loss_epoch=0.0112]Epoch 21: Train Loss = 0.012878075242042542\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=379, train_loss_step=0.015, train_loss_epoch=0.0129] Epoch 22: Train Loss = 0.014990258030593395\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.015]Epoch 23: Train Loss = 0.01065026968717575\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=379, train_loss_step=0.0128, train_loss_epoch=0.0107]Epoch 24: Train Loss = 0.012777859345078468\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.0128]Epoch 25: Train Loss = 0.010666919872164726\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=379, train_loss_step=0.0127, train_loss_epoch=0.0107]Epoch 26: Train Loss = 0.012678646482527256\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=379, train_loss_step=0.0109, train_loss_epoch=0.0127]Epoch 27: Train Loss = 0.010855180211365223\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=379, train_loss_step=0.0105, train_loss_epoch=0.0109]Epoch 28: Train Loss = 0.010519132018089294\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=379, train_loss_step=0.0123, train_loss_epoch=0.0105]Epoch 29: Train Loss = 0.012267818674445152\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=379, train_loss_step=0.0117, train_loss_epoch=0.0123]Epoch 30: Train Loss = 0.01165684126317501\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=379, train_loss_step=0.0125, train_loss_epoch=0.0117]Epoch 31: Train Loss = 0.012477708049118519\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=379, train_loss_step=0.0156, train_loss_epoch=0.0125]Epoch 32: Train Loss = 0.015581157989799976\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=379, train_loss_step=0.012, train_loss_epoch=0.0156] Epoch 33: Train Loss = 0.011978967115283012\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.012]Epoch 34: Train Loss = 0.010256142355501652\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=379, train_loss_step=0.012, train_loss_epoch=0.0103] Epoch 35: Train Loss = 0.01196504570543766\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=379, train_loss_step=0.00985, train_loss_epoch=0.012]Epoch 36: Train Loss = 0.00985244382172823\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=379, train_loss_step=0.0129, train_loss_epoch=0.00985] Epoch 37: Train Loss = 0.012866265140473843\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=379, train_loss_step=0.0137, train_loss_epoch=0.0129] Epoch 38: Train Loss = 0.013735330663621426\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.0137]Epoch 39: Train Loss = 0.010171241126954556\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=379, train_loss_step=0.00999, train_loss_epoch=0.0102]Epoch 40: Train Loss = 0.009994983673095703\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=379, train_loss_step=0.0151, train_loss_epoch=0.00999] Epoch 41: Train Loss = 0.015077473595738411\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.0151] Epoch 42: Train Loss = 0.010721038095653057\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=379, train_loss_step=0.0125, train_loss_epoch=0.0107]Epoch 43: Train Loss = 0.012527743354439735\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.011, train_loss_epoch=0.0125] Epoch 44: Train Loss = 0.01103885006159544\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s, v_num=379, train_loss_step=0.0147, train_loss_epoch=0.011]Epoch 45: Train Loss = 0.014681599102914333\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=379, train_loss_step=0.0159, train_loss_epoch=0.0147]Epoch 46: Train Loss = 0.015937699005007744\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=379, train_loss_step=0.00954, train_loss_epoch=0.0159]Epoch 47: Train Loss = 0.009544816799461842\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=379, train_loss_step=0.00977, train_loss_epoch=0.00954]Epoch 48: Train Loss = 0.009769895114004612\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=379, train_loss_step=0.012, train_loss_epoch=0.00977]  Epoch 49: Train Loss = 0.012006259523332119\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=379, train_loss_step=0.00989, train_loss_epoch=0.012]Epoch 50: Train Loss = 0.009885027073323727\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.00989] Epoch 51: Train Loss = 0.01061108149588108\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.0106] Epoch 52: Train Loss = 0.010666392743587494\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.0107]Epoch 53: Train Loss = 0.010689795017242432\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 12.27it/s, v_num=379, train_loss_step=0.0122, train_loss_epoch=0.0107]Epoch 54: Train Loss = 0.012181871570646763\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0122]Epoch 55: Train Loss = 0.011182211339473724\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.0112]Epoch 56: Train Loss = 0.010411196388304234\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=379, train_loss_step=0.0159, train_loss_epoch=0.0104]Epoch 57: Train Loss = 0.015906047075986862\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=379, train_loss_step=0.0119, train_loss_epoch=0.0159]Epoch 58: Train Loss = 0.011884824372828007\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=379, train_loss_step=0.0119, train_loss_epoch=0.0119]Epoch 59: Train Loss = 0.0119468467310071\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0119]Epoch 60: Train Loss = 0.011213921941816807\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=379, train_loss_step=0.00866, train_loss_epoch=0.0112]Epoch 61: Train Loss = 0.008660007268190384\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=379, train_loss_step=0.00963, train_loss_epoch=0.00866]Epoch 62: Train Loss = 0.009627990424633026\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, v_num=379, train_loss_step=0.00968, train_loss_epoch=0.00963]Epoch 63: Train Loss = 0.00967964343726635\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, v_num=379, train_loss_step=0.00943, train_loss_epoch=0.00968]Epoch 64: Train Loss = 0.009425285272300243\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.00943] Epoch 65: Train Loss = 0.010230389423668385\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=379, train_loss_step=0.0111, train_loss_epoch=0.0102] Epoch 66: Train Loss = 0.011052499525249004\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=379, train_loss_step=0.012, train_loss_epoch=0.0111] Epoch 67: Train Loss = 0.011990197002887726\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.012]Epoch 68: Train Loss = 0.01034365314990282\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=379, train_loss_step=0.0145, train_loss_epoch=0.0103]Epoch 69: Train Loss = 0.014545053243637085\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=379, train_loss_step=0.0135, train_loss_epoch=0.0145]Epoch 70: Train Loss = 0.0135373305529356\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=379, train_loss_step=0.0131, train_loss_epoch=0.0135]Epoch 71: Train Loss = 0.013073792681097984\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=379, train_loss_step=0.0116, train_loss_epoch=0.0131]Epoch 72: Train Loss = 0.011571483686566353\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.0116]Epoch 73: Train Loss = 0.010638943873345852\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=379, train_loss_step=0.0124, train_loss_epoch=0.0106]Epoch 74: Train Loss = 0.012439161539077759\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=379, train_loss_step=0.00895, train_loss_epoch=0.0124]Epoch 75: Train Loss = 0.008947157301008701\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=379, train_loss_step=0.0154, train_loss_epoch=0.00895] Epoch 76: Train Loss = 0.015374427661299706\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, v_num=379, train_loss_step=0.0109, train_loss_epoch=0.0154] Epoch 77: Train Loss = 0.010865866206586361\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=379, train_loss_step=0.00893, train_loss_epoch=0.0109]Epoch 78: Train Loss = 0.008925458416342735\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=379, train_loss_step=0.0118, train_loss_epoch=0.00893] Epoch 79: Train Loss = 0.011817000806331635\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=379, train_loss_step=0.0133, train_loss_epoch=0.0118] Epoch 80: Train Loss = 0.013279304839670658\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=379, train_loss_step=0.0123, train_loss_epoch=0.0133]Epoch 81: Train Loss = 0.012291954830288887\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=379, train_loss_step=0.0126, train_loss_epoch=0.0123]Epoch 82: Train Loss = 0.012559658847749233\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.0126]Epoch 83: Train Loss = 0.010320141911506653\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=379, train_loss_step=0.0141, train_loss_epoch=0.0103]Epoch 84: Train Loss = 0.014090071432292461\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=379, train_loss_step=0.0143, train_loss_epoch=0.0141]Epoch 85: Train Loss = 0.014310894533991814\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=379, train_loss_step=0.00918, train_loss_epoch=0.0143]Epoch 86: Train Loss = 0.009183237329125404\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=379, train_loss_step=0.00842, train_loss_epoch=0.00918]Epoch 87: Train Loss = 0.008422615937888622\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=379, train_loss_step=0.0105, train_loss_epoch=0.00842] Epoch 88: Train Loss = 0.010544024407863617\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.0105] Epoch 89: Train Loss = 0.010081126354634762\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.0101]Epoch 90: Train Loss = 0.011423605494201183\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=379, train_loss_step=0.0127, train_loss_epoch=0.0114]Epoch 91: Train Loss = 0.012698827311396599\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=379, train_loss_step=0.0129, train_loss_epoch=0.0127]Epoch 92: Train Loss = 0.012905142270028591\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.0129]Epoch 93: Train Loss = 0.010237956419587135\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=379, train_loss_step=0.0108, train_loss_epoch=0.0102]Epoch 94: Train Loss = 0.010770891793072224\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.0108]Epoch 95: Train Loss = 0.010252454318106174\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=379, train_loss_step=0.0124, train_loss_epoch=0.0103]Epoch 96: Train Loss = 0.012429042719304562\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=379, train_loss_step=0.0128, train_loss_epoch=0.0124]Epoch 97: Train Loss = 0.012756750918924809\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=379, train_loss_step=0.0152, train_loss_epoch=0.0128]Epoch 98: Train Loss = 0.015244361944496632\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 13.44it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.0152]Epoch 99: Train Loss = 0.01020998414605856\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=379, train_loss_step=0.0109, train_loss_epoch=0.0102]Epoch 100: Train Loss = 0.010898604057729244\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=379, train_loss_step=0.0137, train_loss_epoch=0.0109]Epoch 101: Train Loss = 0.013650462031364441\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.0137]Epoch 102: Train Loss = 0.010333875194191933\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=379, train_loss_step=0.0121, train_loss_epoch=0.0103]Epoch 103: Train Loss = 0.012060980312526226\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=379, train_loss_step=0.0117, train_loss_epoch=0.0121]Epoch 104: Train Loss = 0.011664839461445808\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=379, train_loss_step=0.0141, train_loss_epoch=0.0117]Epoch 105: Train Loss = 0.014104612171649933\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=379, train_loss_step=0.0115, train_loss_epoch=0.0141]Epoch 106: Train Loss = 0.011543194763362408\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=379, train_loss_step=0.0109, train_loss_epoch=0.0115]Epoch 107: Train Loss = 0.010871192440390587\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=379, train_loss_step=0.011, train_loss_epoch=0.0109] Epoch 108: Train Loss = 0.01104793418198824\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.011]Epoch 109: Train Loss = 0.01037551462650299\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=379, train_loss_step=0.0098, train_loss_epoch=0.0104]Epoch 110: Train Loss = 0.009803597815334797\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=379, train_loss_step=0.0119, train_loss_epoch=0.0098]Epoch 111: Train Loss = 0.011904910206794739\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=379, train_loss_step=0.0092, train_loss_epoch=0.0119]Epoch 112: Train Loss = 0.009201417677104473\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=379, train_loss_step=0.0115, train_loss_epoch=0.0092]Epoch 113: Train Loss = 0.01151282899081707\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.0115]Epoch 114: Train Loss = 0.010396831668913364\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=379, train_loss_step=0.00722, train_loss_epoch=0.0104]Epoch 115: Train Loss = 0.007218756712973118\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=379, train_loss_step=0.0138, train_loss_epoch=0.00722] Epoch 116: Train Loss = 0.013778203167021275\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0138] Epoch 117: Train Loss = 0.01121843233704567\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=379, train_loss_step=0.0175, train_loss_epoch=0.0112]Epoch 118: Train Loss = 0.017522774636745453\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=379, train_loss_step=0.00885, train_loss_epoch=0.0175]Epoch 119: Train Loss = 0.008845928125083447\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=379, train_loss_step=0.0118, train_loss_epoch=0.00885] Epoch 120: Train Loss = 0.011788410134613514\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=379, train_loss_step=0.0128, train_loss_epoch=0.0118] Epoch 121: Train Loss = 0.012756399810314178\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=379, train_loss_step=0.014, train_loss_epoch=0.0128] Epoch 122: Train Loss = 0.014029606245458126\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.0151, train_loss_epoch=0.014]Epoch 123: Train Loss = 0.015077903866767883\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=379, train_loss_step=0.0136, train_loss_epoch=0.0151]Epoch 124: Train Loss = 0.013593836687505245\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=379, train_loss_step=0.00911, train_loss_epoch=0.0136]Epoch 125: Train Loss = 0.009111529216170311\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s, v_num=379, train_loss_step=0.0124, train_loss_epoch=0.00911] Epoch 126: Train Loss = 0.012439700774848461\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=379, train_loss_step=0.0126, train_loss_epoch=0.0124] Epoch 127: Train Loss = 0.012588165700435638\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=379, train_loss_step=0.00865, train_loss_epoch=0.0126]Epoch 128: Train Loss = 0.00865358579903841\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=379, train_loss_step=0.0105, train_loss_epoch=0.00865] Epoch 129: Train Loss = 0.010478079319000244\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=379, train_loss_step=0.0115, train_loss_epoch=0.0105] Epoch 130: Train Loss = 0.011451107449829578\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, v_num=379, train_loss_step=0.00985, train_loss_epoch=0.0115]Epoch 131: Train Loss = 0.009852970950305462\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=379, train_loss_step=0.013, train_loss_epoch=0.00985]  Epoch 132: Train Loss = 0.01303567923605442\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=379, train_loss_step=0.0108, train_loss_epoch=0.013] Epoch 133: Train Loss = 0.010794991627335548\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=379, train_loss_step=0.00955, train_loss_epoch=0.0108]Epoch 134: Train Loss = 0.009549583308398724\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=379, train_loss_step=0.00911, train_loss_epoch=0.00955]Epoch 135: Train Loss = 0.009105120785534382\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.00911] Epoch 136: Train Loss = 0.010068533942103386\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.0101] Epoch 137: Train Loss = 0.010317361913621426\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=379, train_loss_step=0.00728, train_loss_epoch=0.0103]Epoch 138: Train Loss = 0.007277057971805334\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=379, train_loss_step=0.0116, train_loss_epoch=0.00728] Epoch 139: Train Loss = 0.011570431292057037\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=379, train_loss_step=0.0116, train_loss_epoch=0.0116] Epoch 140: Train Loss = 0.011633417569100857\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.0116]Epoch 141: Train Loss = 0.01024505216628313\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.0102]Epoch 142: Train Loss = 0.010318519547581673\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=379, train_loss_step=0.00836, train_loss_epoch=0.0103]Epoch 143: Train Loss = 0.008355529047548771\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=379, train_loss_step=0.0108, train_loss_epoch=0.00836] Epoch 144: Train Loss = 0.01078113354742527\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=379, train_loss_step=0.0123, train_loss_epoch=0.0108] Epoch 145: Train Loss = 0.01225212961435318\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 12.86it/s, v_num=379, train_loss_step=0.0142, train_loss_epoch=0.0123]Epoch 146: Train Loss = 0.01422545313835144\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.0142]Epoch 147: Train Loss = 0.010687754489481449\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=379, train_loss_step=0.0125, train_loss_epoch=0.0107]Epoch 148: Train Loss = 0.012485682964324951\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=379, train_loss_step=0.0145, train_loss_epoch=0.0125]Epoch 149: Train Loss = 0.014541071839630604\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 16.04it/s, v_num=379, train_loss_step=0.00877, train_loss_epoch=0.0145]Epoch 150: Train Loss = 0.008772709406912327\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.00877] Epoch 151: Train Loss = 0.010670050978660583\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=379, train_loss_step=0.0141, train_loss_epoch=0.0107] Epoch 152: Train Loss = 0.014105388894677162\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=379, train_loss_step=0.0125, train_loss_epoch=0.0141]Epoch 153: Train Loss = 0.01246960461139679\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.0125]Epoch 154: Train Loss = 0.010596157982945442\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0106]Epoch 155: Train Loss = 0.011236180551350117\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.0112]Epoch 156: Train Loss = 0.010095094330608845\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.00969, train_loss_epoch=0.0101]Epoch 157: Train Loss = 0.009686256758868694\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.00969] Epoch 158: Train Loss = 0.01061898935586214\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=379, train_loss_step=0.00824, train_loss_epoch=0.0106]Epoch 159: Train Loss = 0.008240028284490108\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=379, train_loss_step=0.0118, train_loss_epoch=0.00824] Epoch 160: Train Loss = 0.011755572631955147\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=379, train_loss_step=0.010, train_loss_epoch=0.0118]  Epoch 161: Train Loss = 0.010045884177088737\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=379, train_loss_step=0.0129, train_loss_epoch=0.010]Epoch 162: Train Loss = 0.012856093235313892\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=379, train_loss_step=0.00941, train_loss_epoch=0.0129]Epoch 163: Train Loss = 0.009413016028702259\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=379, train_loss_step=0.013, train_loss_epoch=0.00941]  Epoch 164: Train Loss = 0.012993027456104755\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=379, train_loss_step=0.010, train_loss_epoch=0.013]  Epoch 165: Train Loss = 0.009996116161346436\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=379, train_loss_step=0.00999, train_loss_epoch=0.010]Epoch 166: Train Loss = 0.009988879784941673\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=379, train_loss_step=0.014, train_loss_epoch=0.00999]  Epoch 167: Train Loss = 0.013998609967529774\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=379, train_loss_step=0.0157, train_loss_epoch=0.014] Epoch 168: Train Loss = 0.015670139342546463\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=379, train_loss_step=0.0109, train_loss_epoch=0.0157]Epoch 169: Train Loss = 0.010927125811576843\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=379, train_loss_step=0.0121, train_loss_epoch=0.0109]Epoch 170: Train Loss = 0.012058811262249947\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.0121]Epoch 171: Train Loss = 0.010254970751702785\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s, v_num=379, train_loss_step=0.00892, train_loss_epoch=0.0103]Epoch 172: Train Loss = 0.008921111933887005\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=379, train_loss_step=0.0143, train_loss_epoch=0.00892] Epoch 173: Train Loss = 0.014320151880383492\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.0163, train_loss_epoch=0.0143] Epoch 174: Train Loss = 0.016250336542725563\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=379, train_loss_step=0.0162, train_loss_epoch=0.0163]Epoch 175: Train Loss = 0.016157984733581543\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=379, train_loss_step=0.0156, train_loss_epoch=0.0162]Epoch 176: Train Loss = 0.015584148466587067\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=379, train_loss_step=0.00957, train_loss_epoch=0.0156]Epoch 177: Train Loss = 0.009568088687956333\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=379, train_loss_step=0.0123, train_loss_epoch=0.00957] Epoch 178: Train Loss = 0.01226679515093565\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s, v_num=379, train_loss_step=0.0141, train_loss_epoch=0.0123] Epoch 179: Train Loss = 0.014084731228649616\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=379, train_loss_step=0.0123, train_loss_epoch=0.0141]Epoch 180: Train Loss = 0.012338795699179173\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=379, train_loss_step=0.0173, train_loss_epoch=0.0123]Epoch 181: Train Loss = 0.017285456880927086\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=379, train_loss_step=0.0135, train_loss_epoch=0.0173]Epoch 182: Train Loss = 0.013528287410736084\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=379, train_loss_step=0.0125, train_loss_epoch=0.0135]Epoch 183: Train Loss = 0.01248877588659525\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=379, train_loss_step=0.0152, train_loss_epoch=0.0125]Epoch 184: Train Loss = 0.015233227051794529\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=379, train_loss_step=0.012, train_loss_epoch=0.0152] Epoch 185: Train Loss = 0.011960135772824287\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=379, train_loss_step=0.0155, train_loss_epoch=0.012]Epoch 186: Train Loss = 0.015465104021131992\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=379, train_loss_step=0.0125, train_loss_epoch=0.0155]Epoch 187: Train Loss = 0.012473613023757935\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=379, train_loss_step=0.00957, train_loss_epoch=0.0125]Epoch 188: Train Loss = 0.009570728056132793\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=379, train_loss_step=0.012, train_loss_epoch=0.00957]  Epoch 189: Train Loss = 0.012001290917396545\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 16.06it/s, v_num=379, train_loss_step=0.0134, train_loss_epoch=0.012] Epoch 190: Train Loss = 0.013381173834204674\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=379, train_loss_step=0.00947, train_loss_epoch=0.0134]Epoch 191: Train Loss = 0.009474684484302998\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=379, train_loss_step=0.0126, train_loss_epoch=0.00947] Epoch 192: Train Loss = 0.012643816880881786\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 16.70it/s, v_num=379, train_loss_step=0.0121, train_loss_epoch=0.0126] Epoch 193: Train Loss = 0.012080426327884197\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 16.55it/s, v_num=379, train_loss_step=0.0116, train_loss_epoch=0.0121]Epoch 194: Train Loss = 0.011566671542823315\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.0116]Epoch 195: Train Loss = 0.011428468860685825\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=379, train_loss_step=0.0124, train_loss_epoch=0.0114]Epoch 196: Train Loss = 0.012359709478914738\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=379, train_loss_step=0.0117, train_loss_epoch=0.0124]Epoch 197: Train Loss = 0.011668269522488117\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=379, train_loss_step=0.0129, train_loss_epoch=0.0117]Epoch 198: Train Loss = 0.01290477067232132\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.0129]Epoch 199: Train Loss = 0.01143901888281107\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 12.75it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.0114]Epoch 200: Train Loss = 0.01138274185359478\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.0114]Epoch 201: Train Loss = 0.011434899643063545\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.0114]Epoch 202: Train Loss = 0.010079300962388515\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=379, train_loss_step=0.00961, train_loss_epoch=0.0101]Epoch 203: Train Loss = 0.00960561353713274\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=379, train_loss_step=0.010, train_loss_epoch=0.00961]  Epoch 204: Train Loss = 0.010008314624428749\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=379, train_loss_step=0.0121, train_loss_epoch=0.010] Epoch 205: Train Loss = 0.012076311744749546\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=379, train_loss_step=0.0123, train_loss_epoch=0.0121]Epoch 206: Train Loss = 0.012329448945820332\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=379, train_loss_step=0.0137, train_loss_epoch=0.0123]Epoch 207: Train Loss = 0.013703863136470318\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, v_num=379, train_loss_step=0.00878, train_loss_epoch=0.0137]Epoch 208: Train Loss = 0.008780025877058506\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 12.90it/s, v_num=379, train_loss_step=0.00899, train_loss_epoch=0.00878]Epoch 209: Train Loss = 0.008993775583803654\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=379, train_loss_step=0.0119, train_loss_epoch=0.00899] Epoch 210: Train Loss = 0.011912241578102112\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.0136, train_loss_epoch=0.0119] Epoch 211: Train Loss = 0.01362393144518137\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=379, train_loss_step=0.0127, train_loss_epoch=0.0136]Epoch 212: Train Loss = 0.012687728740274906\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=379, train_loss_step=0.0132, train_loss_epoch=0.0127]Epoch 213: Train Loss = 0.013184642419219017\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=379, train_loss_step=0.0135, train_loss_epoch=0.0132]Epoch 214: Train Loss = 0.013519559986889362\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=379, train_loss_step=0.00996, train_loss_epoch=0.0135]Epoch 215: Train Loss = 0.00996327679604292\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=379, train_loss_step=0.00988, train_loss_epoch=0.00996]Epoch 216: Train Loss = 0.0098836999386549\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.00988] Epoch 217: Train Loss = 0.010442298837006092\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=379, train_loss_step=0.0119, train_loss_epoch=0.0104] Epoch 218: Train Loss = 0.011893071234226227\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=379, train_loss_step=0.0141, train_loss_epoch=0.0119]Epoch 219: Train Loss = 0.014083193615078926\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 13.20it/s, v_num=379, train_loss_step=0.0108, train_loss_epoch=0.0141]Epoch 220: Train Loss = 0.010765832848846912\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=379, train_loss_step=0.0119, train_loss_epoch=0.0108]Epoch 221: Train Loss = 0.011918657459318638\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=379, train_loss_step=0.00896, train_loss_epoch=0.0119]Epoch 222: Train Loss = 0.008958762511610985\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=379, train_loss_step=0.00832, train_loss_epoch=0.00896]Epoch 223: Train Loss = 0.008320916444063187\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=379, train_loss_step=0.00841, train_loss_epoch=0.00832]Epoch 224: Train Loss = 0.0084081394597888\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=379, train_loss_step=0.0128, train_loss_epoch=0.00841] Epoch 225: Train Loss = 0.012803450226783752\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=379, train_loss_step=0.0119, train_loss_epoch=0.0128] Epoch 226: Train Loss = 0.01192441675812006\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=379, train_loss_step=0.00958, train_loss_epoch=0.0119]Epoch 227: Train Loss = 0.009583763778209686\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 13.13it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.00958] Epoch 228: Train Loss = 0.010666214860975742\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=379, train_loss_step=0.00829, train_loss_epoch=0.0107]Epoch 229: Train Loss = 0.008288889192044735\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=379, train_loss_step=0.00979, train_loss_epoch=0.00829]Epoch 230: Train Loss = 0.009785003028810024\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=379, train_loss_step=0.0108, train_loss_epoch=0.00979] Epoch 231: Train Loss = 0.010818426497280598\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=379, train_loss_step=0.00867, train_loss_epoch=0.0108]Epoch 232: Train Loss = 0.00866615679115057\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=379, train_loss_step=0.00795, train_loss_epoch=0.00867]Epoch 233: Train Loss = 0.007954567670822144\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=379, train_loss_step=0.00878, train_loss_epoch=0.00795]Epoch 234: Train Loss = 0.008781409822404385\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=379, train_loss_step=0.00845, train_loss_epoch=0.00878]Epoch 235: Train Loss = 0.0084459837526083\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=379, train_loss_step=0.00785, train_loss_epoch=0.00845]Epoch 236: Train Loss = 0.007853612303733826\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=379, train_loss_step=0.00856, train_loss_epoch=0.00785]Epoch 237: Train Loss = 0.008556627668440342\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=379, train_loss_step=0.0145, train_loss_epoch=0.00856] Epoch 238: Train Loss = 0.014495228417217731\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.0145] Epoch 239: Train Loss = 0.010063305497169495\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.0101]Epoch 240: Train Loss = 0.0101070711389184\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0101]Epoch 241: Train Loss = 0.011212043464183807\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=379, train_loss_step=0.0118, train_loss_epoch=0.0112]Epoch 242: Train Loss = 0.011815070174634457\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=379, train_loss_step=0.0105, train_loss_epoch=0.0118]Epoch 243: Train Loss = 0.010533333756029606\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=379, train_loss_step=0.00984, train_loss_epoch=0.0105]Epoch 244: Train Loss = 0.009841402992606163\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=379, train_loss_step=0.0115, train_loss_epoch=0.00984] Epoch 245: Train Loss = 0.01146361231803894\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=379, train_loss_step=0.00862, train_loss_epoch=0.0115]Epoch 246: Train Loss = 0.008620091713964939\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=379, train_loss_step=0.00898, train_loss_epoch=0.00862]Epoch 247: Train Loss = 0.008980811573565006\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.00898] Epoch 248: Train Loss = 0.011425105854868889\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=379, train_loss_step=0.013, train_loss_epoch=0.0114]  Epoch 249: Train Loss = 0.013014544732868671\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s, v_num=379, train_loss_step=0.00973, train_loss_epoch=0.013]Epoch 250: Train Loss = 0.00973199401050806\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.00973] Epoch 251: Train Loss = 0.010390954092144966\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=379, train_loss_step=0.0124, train_loss_epoch=0.0104] Epoch 252: Train Loss = 0.012438992038369179\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=379, train_loss_step=0.00956, train_loss_epoch=0.0124]Epoch 253: Train Loss = 0.009561018086969852\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=379, train_loss_step=0.00938, train_loss_epoch=0.00956]Epoch 254: Train Loss = 0.009376435540616512\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.00938] Epoch 255: Train Loss = 0.01057242788374424\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.0106] Epoch 256: Train Loss = 0.010344448499381542\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=379, train_loss_step=0.00844, train_loss_epoch=0.0103]Epoch 257: Train Loss = 0.008436759002506733\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=379, train_loss_step=0.00972, train_loss_epoch=0.00844]Epoch 258: Train Loss = 0.009722935035824776\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=379, train_loss_step=0.00767, train_loss_epoch=0.00972]Epoch 259: Train Loss = 0.007670200429856777\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=379, train_loss_step=0.0121, train_loss_epoch=0.00767] Epoch 260: Train Loss = 0.012062889523804188\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.0121] Epoch 261: Train Loss = 0.010700715705752373\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=379, train_loss_step=0.00954, train_loss_epoch=0.0107]Epoch 262: Train Loss = 0.009536920115351677\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=379, train_loss_step=0.00959, train_loss_epoch=0.00954]Epoch 263: Train Loss = 0.009591623209416866\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=379, train_loss_step=0.0149, train_loss_epoch=0.00959] Epoch 264: Train Loss = 0.014887147583067417\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=379, train_loss_step=0.010, train_loss_epoch=0.0149]  Epoch 265: Train Loss = 0.009998940862715244\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s, v_num=379, train_loss_step=0.00858, train_loss_epoch=0.010]Epoch 266: Train Loss = 0.008575333282351494\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 14.11it/s, v_num=379, train_loss_step=0.00938, train_loss_epoch=0.00858]Epoch 267: Train Loss = 0.009383357129991055\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=379, train_loss_step=0.00945, train_loss_epoch=0.00938]Epoch 268: Train Loss = 0.00945203471928835\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=379, train_loss_step=0.0108, train_loss_epoch=0.00945] Epoch 269: Train Loss = 0.010782568715512753\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=379, train_loss_step=0.00892, train_loss_epoch=0.0108]Epoch 270: Train Loss = 0.008917772211134434\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=379, train_loss_step=0.00783, train_loss_epoch=0.00892]Epoch 271: Train Loss = 0.007829729467630386\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=379, train_loss_step=0.0118, train_loss_epoch=0.00783] Epoch 272: Train Loss = 0.01181385014206171\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=379, train_loss_step=0.0129, train_loss_epoch=0.0118] Epoch 273: Train Loss = 0.012938299216330051\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=379, train_loss_step=0.00917, train_loss_epoch=0.0129]Epoch 274: Train Loss = 0.009165643714368343\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.00917] Epoch 275: Train Loss = 0.010243384167551994\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=379, train_loss_step=0.00935, train_loss_epoch=0.0102]Epoch 276: Train Loss = 0.00934705138206482\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=379, train_loss_step=0.00776, train_loss_epoch=0.00935]Epoch 277: Train Loss = 0.007759753614664078\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=379, train_loss_step=0.0122, train_loss_epoch=0.00776] Epoch 278: Train Loss = 0.012242441065609455\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=379, train_loss_step=0.0122, train_loss_epoch=0.0122] Epoch 279: Train Loss = 0.012225605547428131\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=379, train_loss_step=0.00972, train_loss_epoch=0.0122]Epoch 280: Train Loss = 0.00972378347069025\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=379, train_loss_step=0.00925, train_loss_epoch=0.00972]Epoch 281: Train Loss = 0.009246204979717731\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=379, train_loss_step=0.00968, train_loss_epoch=0.00925]Epoch 282: Train Loss = 0.00968489795923233\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=379, train_loss_step=0.013, train_loss_epoch=0.00968]  Epoch 283: Train Loss = 0.012974143959581852\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=379, train_loss_step=0.00931, train_loss_epoch=0.013]Epoch 284: Train Loss = 0.009313388727605343\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=379, train_loss_step=0.00921, train_loss_epoch=0.00931]Epoch 285: Train Loss = 0.009209221228957176\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=379, train_loss_step=0.0142, train_loss_epoch=0.00921] Epoch 286: Train Loss = 0.014169261790812016\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.0142] Epoch 287: Train Loss = 0.01019313931465149\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.0102]Epoch 288: Train Loss = 0.011373689398169518\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.0114]Epoch 289: Train Loss = 0.010432553477585316\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.0104]Epoch 290: Train Loss = 0.010555117391049862\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=379, train_loss_step=0.00992, train_loss_epoch=0.0106]Epoch 291: Train Loss = 0.009922785684466362\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=379, train_loss_step=0.00921, train_loss_epoch=0.00992]Epoch 292: Train Loss = 0.009209811687469482\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=379, train_loss_step=0.00956, train_loss_epoch=0.00921]Epoch 293: Train Loss = 0.009559914469718933\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.00956] Epoch 294: Train Loss = 0.010141851380467415\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.0101] Epoch 295: Train Loss = 0.010627910494804382\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=379, train_loss_step=0.0127, train_loss_epoch=0.0106]Epoch 296: Train Loss = 0.012679487466812134\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=379, train_loss_step=0.0116, train_loss_epoch=0.0127]Epoch 297: Train Loss = 0.011621398851275444\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=379, train_loss_step=0.00997, train_loss_epoch=0.0116]Epoch 298: Train Loss = 0.009966785088181496\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 12.63it/s, v_num=379, train_loss_step=0.00912, train_loss_epoch=0.00997]Epoch 299: Train Loss = 0.009119627997279167\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=379, train_loss_step=0.00892, train_loss_epoch=0.00912]Epoch 300: Train Loss = 0.008922615088522434\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.00892] Epoch 301: Train Loss = 0.01008511334657669\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.0101] Epoch 302: Train Loss = 0.011416156776249409\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=379, train_loss_step=0.0113, train_loss_epoch=0.0114]Epoch 303: Train Loss = 0.01125062070786953\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.0113]Epoch 304: Train Loss = 0.010596550069749355\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=379, train_loss_step=0.00854, train_loss_epoch=0.0106]Epoch 305: Train Loss = 0.008542344905436039\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, v_num=379, train_loss_step=0.0115, train_loss_epoch=0.00854] Epoch 306: Train Loss = 0.011537156999111176\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=379, train_loss_step=0.00822, train_loss_epoch=0.0115]Epoch 307: Train Loss = 0.008224761113524437\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=379, train_loss_step=0.0109, train_loss_epoch=0.00822] Epoch 308: Train Loss = 0.010861486196517944\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0109] Epoch 309: Train Loss = 0.011181500740349293\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=379, train_loss_step=0.00688, train_loss_epoch=0.0112]Epoch 310: Train Loss = 0.00687679136171937\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=379, train_loss_step=0.00972, train_loss_epoch=0.00688]Epoch 311: Train Loss = 0.009720854461193085\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=379, train_loss_step=0.0094, train_loss_epoch=0.00972] Epoch 312: Train Loss = 0.009400204755365849\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=379, train_loss_step=0.0119, train_loss_epoch=0.0094] Epoch 313: Train Loss = 0.011949163861572742\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0119]Epoch 314: Train Loss = 0.011191087774932384\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=379, train_loss_step=0.0127, train_loss_epoch=0.0112]Epoch 315: Train Loss = 0.012662122957408428\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=379, train_loss_step=0.0128, train_loss_epoch=0.0127]Epoch 316: Train Loss = 0.012781498953700066\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=379, train_loss_step=0.00782, train_loss_epoch=0.0128]Epoch 317: Train Loss = 0.007815642282366753\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=379, train_loss_step=0.00907, train_loss_epoch=0.00782]Epoch 318: Train Loss = 0.009067477658390999\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=379, train_loss_step=0.00991, train_loss_epoch=0.00907]Epoch 319: Train Loss = 0.009910142980515957\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=379, train_loss_step=0.0084, train_loss_epoch=0.00991] Epoch 320: Train Loss = 0.008401519618928432\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=379, train_loss_step=0.011, train_loss_epoch=0.0084]  Epoch 321: Train Loss = 0.01096904557198286\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.011]Epoch 322: Train Loss = 0.010678822174668312\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=379, train_loss_step=0.0113, train_loss_epoch=0.0107]Epoch 323: Train Loss = 0.011344281025230885\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=379, train_loss_step=0.0111, train_loss_epoch=0.0113]Epoch 324: Train Loss = 0.011093891225755215\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.0111]Epoch 325: Train Loss = 0.010178299620747566\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=379, train_loss_step=0.0111, train_loss_epoch=0.0102]Epoch 326: Train Loss = 0.011135770007967949\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=379, train_loss_step=0.011, train_loss_epoch=0.0111] Epoch 327: Train Loss = 0.010982622392475605\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=379, train_loss_step=0.0148, train_loss_epoch=0.011]Epoch 328: Train Loss = 0.014818472787737846\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=379, train_loss_step=0.00806, train_loss_epoch=0.0148]Epoch 329: Train Loss = 0.00806253682821989\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=379, train_loss_step=0.0149, train_loss_epoch=0.00806] Epoch 330: Train Loss = 0.014948257245123386\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=379, train_loss_step=0.010, train_loss_epoch=0.0149]  Epoch 331: Train Loss = 0.01003454439342022\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.010]Epoch 332: Train Loss = 0.01015069056302309\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=379, train_loss_step=0.0115, train_loss_epoch=0.0102]Epoch 333: Train Loss = 0.0114546287804842\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=379, train_loss_step=0.0113, train_loss_epoch=0.0115]Epoch 334: Train Loss = 0.011303327046334743\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=379, train_loss_step=0.00813, train_loss_epoch=0.0113]Epoch 335: Train Loss = 0.008125395514070988\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.00813] Epoch 336: Train Loss = 0.010196142829954624\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 13.91it/s, v_num=379, train_loss_step=0.0134, train_loss_epoch=0.0102] Epoch 337: Train Loss = 0.013419762253761292\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=379, train_loss_step=0.0127, train_loss_epoch=0.0134]Epoch 338: Train Loss = 0.012718386948108673\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 13.05it/s, v_num=379, train_loss_step=0.013, train_loss_epoch=0.0127] Epoch 339: Train Loss = 0.01297051552683115\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=379, train_loss_step=0.00858, train_loss_epoch=0.013]Epoch 340: Train Loss = 0.008583366870880127\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.00858] Epoch 341: Train Loss = 0.010160280391573906\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=379, train_loss_step=0.0109, train_loss_epoch=0.0102] Epoch 342: Train Loss = 0.010863031260669231\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0109]Epoch 343: Train Loss = 0.01124596782028675\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.0112]Epoch 344: Train Loss = 0.010094801895320415\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=379, train_loss_step=0.0115, train_loss_epoch=0.0101]Epoch 345: Train Loss = 0.011467025615274906\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=379, train_loss_step=0.0117, train_loss_epoch=0.0115]Epoch 346: Train Loss = 0.011681812815368176\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=379, train_loss_step=0.0122, train_loss_epoch=0.0117]Epoch 347: Train Loss = 0.012222479097545147\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=379, train_loss_step=0.0134, train_loss_epoch=0.0122]Epoch 348: Train Loss = 0.013439149595797062\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=379, train_loss_step=0.0136, train_loss_epoch=0.0134]Epoch 349: Train Loss = 0.013627818785607815\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=379, train_loss_step=0.0096, train_loss_epoch=0.0136]Epoch 350: Train Loss = 0.009603982791304588\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=379, train_loss_step=0.0134, train_loss_epoch=0.0096]Epoch 351: Train Loss = 0.013445837423205376\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=379, train_loss_step=0.0126, train_loss_epoch=0.0134]Epoch 352: Train Loss = 0.01260805781930685\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=379, train_loss_step=0.00917, train_loss_epoch=0.0126]Epoch 353: Train Loss = 0.009174386039376259\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s, v_num=379, train_loss_step=0.0146, train_loss_epoch=0.00917] Epoch 354: Train Loss = 0.014601700939238071\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=379, train_loss_step=0.0141, train_loss_epoch=0.0146] Epoch 355: Train Loss = 0.014119013212621212\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=379, train_loss_step=0.0147, train_loss_epoch=0.0141]Epoch 356: Train Loss = 0.014687412418425083\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=379, train_loss_step=0.010, train_loss_epoch=0.0147] Epoch 357: Train Loss = 0.010008563287556171\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=379, train_loss_step=0.0113, train_loss_epoch=0.010]Epoch 358: Train Loss = 0.011287814937531948\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=379, train_loss_step=0.00994, train_loss_epoch=0.0113]Epoch 359: Train Loss = 0.009940576739609241\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=379, train_loss_step=0.00977, train_loss_epoch=0.00994]Epoch 360: Train Loss = 0.009768269024789333\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=379, train_loss_step=0.0129, train_loss_epoch=0.00977] Epoch 361: Train Loss = 0.012874537147581577\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=379, train_loss_step=0.0131, train_loss_epoch=0.0129] Epoch 362: Train Loss = 0.013063676655292511\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.0131]Epoch 363: Train Loss = 0.01032886654138565\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=379, train_loss_step=0.0119, train_loss_epoch=0.0103]Epoch 364: Train Loss = 0.011897607706487179\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=379, train_loss_step=0.0147, train_loss_epoch=0.0119]Epoch 365: Train Loss = 0.01468999870121479\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=379, train_loss_step=0.00831, train_loss_epoch=0.0147]Epoch 366: Train Loss = 0.008312024176120758\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=379, train_loss_step=0.00936, train_loss_epoch=0.00831]Epoch 367: Train Loss = 0.009357409551739693\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 13.46it/s, v_num=379, train_loss_step=0.00764, train_loss_epoch=0.00936]Epoch 368: Train Loss = 0.007641555275768042\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=379, train_loss_step=0.00948, train_loss_epoch=0.00764]Epoch 369: Train Loss = 0.009484297595918179\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=379, train_loss_step=0.00928, train_loss_epoch=0.00948]Epoch 370: Train Loss = 0.009282962419092655\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=379, train_loss_step=0.00946, train_loss_epoch=0.00928]Epoch 371: Train Loss = 0.009460440836846828\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=379, train_loss_step=0.0123, train_loss_epoch=0.00946] Epoch 372: Train Loss = 0.012272306717932224\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=379, train_loss_step=0.0122, train_loss_epoch=0.0123] Epoch 373: Train Loss = 0.012248639948666096\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=379, train_loss_step=0.0131, train_loss_epoch=0.0122]Epoch 374: Train Loss = 0.013113362714648247\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=379, train_loss_step=0.0132, train_loss_epoch=0.0131]Epoch 375: Train Loss = 0.013188095763325691\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=379, train_loss_step=0.00921, train_loss_epoch=0.0132]Epoch 376: Train Loss = 0.00921391136944294\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=379, train_loss_step=0.00993, train_loss_epoch=0.00921]Epoch 377: Train Loss = 0.009933793917298317\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=379, train_loss_step=0.00842, train_loss_epoch=0.00993]Epoch 378: Train Loss = 0.008422994054853916\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.00842] Epoch 379: Train Loss = 0.011446507647633553\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=379, train_loss_step=0.00979, train_loss_epoch=0.0114]Epoch 380: Train Loss = 0.00979200191795826\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=379, train_loss_step=0.0135, train_loss_epoch=0.00979] Epoch 381: Train Loss = 0.013548148795962334\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=379, train_loss_step=0.00989, train_loss_epoch=0.0135]Epoch 382: Train Loss = 0.009894797578454018\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=379, train_loss_step=0.00907, train_loss_epoch=0.00989]Epoch 383: Train Loss = 0.009068788029253483\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=379, train_loss_step=0.0121, train_loss_epoch=0.00907] Epoch 384: Train Loss = 0.012077922001481056\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 13.19it/s, v_num=379, train_loss_step=0.00956, train_loss_epoch=0.0121]Epoch 385: Train Loss = 0.00955882202833891\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.00956] Epoch 386: Train Loss = 0.010317615233361721\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.0103] Epoch 387: Train Loss = 0.010384161956608295\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=379, train_loss_step=0.00717, train_loss_epoch=0.0104]Epoch 388: Train Loss = 0.0071737198159098625\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=379, train_loss_step=0.0131, train_loss_epoch=0.00717] Epoch 389: Train Loss = 0.013064195401966572\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.0131] Epoch 390: Train Loss = 0.011406862176954746\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=379, train_loss_step=0.00782, train_loss_epoch=0.0114]Epoch 391: Train Loss = 0.007816897705197334\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=379, train_loss_step=0.0144, train_loss_epoch=0.00782] Epoch 392: Train Loss = 0.01437594834715128\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=379, train_loss_step=0.0108, train_loss_epoch=0.0144] Epoch 393: Train Loss = 0.010773418471217155\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=379, train_loss_step=0.011, train_loss_epoch=0.0108] Epoch 394: Train Loss = 0.011047466658055782\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=379, train_loss_step=0.00899, train_loss_epoch=0.011]Epoch 395: Train Loss = 0.008988491259515285\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.00892, train_loss_epoch=0.00899]Epoch 396: Train Loss = 0.008923595771193504\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=379, train_loss_step=0.00856, train_loss_epoch=0.00892]Epoch 397: Train Loss = 0.00856489222496748\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=379, train_loss_step=0.00821, train_loss_epoch=0.00856]Epoch 398: Train Loss = 0.008206444792449474\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=379, train_loss_step=0.00959, train_loss_epoch=0.00821]Epoch 399: Train Loss = 0.00959482230246067\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=379, train_loss_step=0.00806, train_loss_epoch=0.00959]Epoch 400: Train Loss = 0.008063709363341331\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=379, train_loss_step=0.0076, train_loss_epoch=0.00806] Epoch 401: Train Loss = 0.0076003968715667725\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=379, train_loss_step=0.00786, train_loss_epoch=0.0076]Epoch 402: Train Loss = 0.007856661453843117\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.00786] Epoch 403: Train Loss = 0.010155334137380123\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=379, train_loss_step=0.0114, train_loss_epoch=0.0102] Epoch 404: Train Loss = 0.011405928060412407\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=379, train_loss_step=0.0069, train_loss_epoch=0.0114]Epoch 405: Train Loss = 0.006904118228703737\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=379, train_loss_step=0.0119, train_loss_epoch=0.0069]Epoch 406: Train Loss = 0.011918941512703896\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=379, train_loss_step=0.00862, train_loss_epoch=0.0119]Epoch 407: Train Loss = 0.008621696382761002\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=379, train_loss_step=0.00756, train_loss_epoch=0.00862]Epoch 408: Train Loss = 0.007563539315015078\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=379, train_loss_step=0.0111, train_loss_epoch=0.00756] Epoch 409: Train Loss = 0.01110001653432846\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=379, train_loss_step=0.0109, train_loss_epoch=0.0111] Epoch 410: Train Loss = 0.010921822860836983\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=379, train_loss_step=0.00844, train_loss_epoch=0.0109]Epoch 411: Train Loss = 0.008443493396043777\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=379, train_loss_step=0.00699, train_loss_epoch=0.00844]Epoch 412: Train Loss = 0.006993111688643694\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=379, train_loss_step=0.00908, train_loss_epoch=0.00699]Epoch 413: Train Loss = 0.00907818228006363\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=379, train_loss_step=0.0122, train_loss_epoch=0.00908] Epoch 414: Train Loss = 0.01223936676979065\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=379, train_loss_step=0.0124, train_loss_epoch=0.0122] Epoch 415: Train Loss = 0.01238830666989088\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.00918, train_loss_epoch=0.0124]Epoch 416: Train Loss = 0.009178588166832924\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=379, train_loss_step=0.0126, train_loss_epoch=0.00918] Epoch 417: Train Loss = 0.012573921121656895\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=379, train_loss_step=0.0091, train_loss_epoch=0.0126] Epoch 418: Train Loss = 0.009101290255784988\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=379, train_loss_step=0.0108, train_loss_epoch=0.0091]Epoch 419: Train Loss = 0.010778428986668587\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=379, train_loss_step=0.00832, train_loss_epoch=0.0108]Epoch 420: Train Loss = 0.008321179077029228\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=379, train_loss_step=0.00789, train_loss_epoch=0.00832]Epoch 421: Train Loss = 0.007894848473370075\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, v_num=379, train_loss_step=0.00968, train_loss_epoch=0.00789]Epoch 422: Train Loss = 0.009680621325969696\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=379, train_loss_step=0.00918, train_loss_epoch=0.00968]Epoch 423: Train Loss = 0.009177719242870808\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=379, train_loss_step=0.0108, train_loss_epoch=0.00918] Epoch 424: Train Loss = 0.010799809359014034\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=379, train_loss_step=0.00933, train_loss_epoch=0.0108]Epoch 425: Train Loss = 0.009331749752163887\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, v_num=379, train_loss_step=0.00847, train_loss_epoch=0.00933]Epoch 426: Train Loss = 0.008473214693367481\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=379, train_loss_step=0.0098, train_loss_epoch=0.00847] Epoch 427: Train Loss = 0.009795536287128925\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=379, train_loss_step=0.0124, train_loss_epoch=0.0098] Epoch 428: Train Loss = 0.012435076758265495\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=379, train_loss_step=0.00892, train_loss_epoch=0.0124]Epoch 429: Train Loss = 0.00891569908708334\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=379, train_loss_step=0.0103, train_loss_epoch=0.00892] Epoch 430: Train Loss = 0.01033878792077303\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.0103] Epoch 431: Train Loss = 0.010350437834858894\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=379, train_loss_step=0.0105, train_loss_epoch=0.0104]Epoch 432: Train Loss = 0.010473044589161873\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=379, train_loss_step=0.00812, train_loss_epoch=0.0105]Epoch 433: Train Loss = 0.008115983568131924\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=379, train_loss_step=0.011, train_loss_epoch=0.00812]  Epoch 434: Train Loss = 0.010951857082545757\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=379, train_loss_step=0.0133, train_loss_epoch=0.011] Epoch 435: Train Loss = 0.01327317301183939\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=379, train_loss_step=0.008, train_loss_epoch=0.0133] Epoch 436: Train Loss = 0.007996974512934685\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=379, train_loss_step=0.013, train_loss_epoch=0.008] Epoch 437: Train Loss = 0.01298790518194437\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s, v_num=379, train_loss_step=0.0113, train_loss_epoch=0.013]Epoch 438: Train Loss = 0.011320495046675205\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=379, train_loss_step=0.00963, train_loss_epoch=0.0113]Epoch 439: Train Loss = 0.009632356464862823\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.00963] Epoch 440: Train Loss = 0.010116731747984886\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=379, train_loss_step=0.0116, train_loss_epoch=0.0101] Epoch 441: Train Loss = 0.011611881665885448\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=379, train_loss_step=0.0109, train_loss_epoch=0.0116]Epoch 442: Train Loss = 0.010914924554526806\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=379, train_loss_step=0.00822, train_loss_epoch=0.0109]Epoch 443: Train Loss = 0.008215265348553658\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=379, train_loss_step=0.0138, train_loss_epoch=0.00822] Epoch 444: Train Loss = 0.013796904124319553\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=379, train_loss_step=0.00899, train_loss_epoch=0.0138]Epoch 445: Train Loss = 0.00898868590593338\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.00899] Epoch 446: Train Loss = 0.010410161688923836\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=379, train_loss_step=0.0124, train_loss_epoch=0.0104] Epoch 447: Train Loss = 0.012434365227818489\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.0124]Epoch 448: Train Loss = 0.010646631941199303\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=379, train_loss_step=0.00846, train_loss_epoch=0.0106]Epoch 449: Train Loss = 0.008463476784527302\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 13.08it/s, v_num=379, train_loss_step=0.00808, train_loss_epoch=0.00846]Epoch 450: Train Loss = 0.008075540885329247\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=379, train_loss_step=0.0108, train_loss_epoch=0.00808] Epoch 451: Train Loss = 0.010815130546689034\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=379, train_loss_step=0.0105, train_loss_epoch=0.0108] Epoch 452: Train Loss = 0.010532074607908726\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=379, train_loss_step=0.00772, train_loss_epoch=0.0105]Epoch 453: Train Loss = 0.007719505578279495\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=379, train_loss_step=0.0122, train_loss_epoch=0.00772] Epoch 454: Train Loss = 0.012201930396258831\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=379, train_loss_step=0.00829, train_loss_epoch=0.0122]Epoch 455: Train Loss = 0.008292085491120815\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=379, train_loss_step=0.00852, train_loss_epoch=0.00829]Epoch 456: Train Loss = 0.008520176634192467\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=379, train_loss_step=0.0126, train_loss_epoch=0.00852] Epoch 457: Train Loss = 0.012641501612961292\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.0126] Epoch 458: Train Loss = 0.010144996456801891\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=379, train_loss_step=0.00885, train_loss_epoch=0.0101]Epoch 459: Train Loss = 0.008849047124385834\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.00885] Epoch 460: Train Loss = 0.010200110264122486\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=379, train_loss_step=0.0122, train_loss_epoch=0.0102] Epoch 461: Train Loss = 0.01218328531831503\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=379, train_loss_step=0.0112, train_loss_epoch=0.0122]Epoch 462: Train Loss = 0.011203636415302753\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=379, train_loss_step=0.00822, train_loss_epoch=0.0112]Epoch 463: Train Loss = 0.00822264514863491\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=379, train_loss_step=0.00701, train_loss_epoch=0.00822]Epoch 464: Train Loss = 0.007007008884102106\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.00701] Epoch 465: Train Loss = 0.010391851887106895\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=379, train_loss_step=0.0126, train_loss_epoch=0.0104] Epoch 466: Train Loss = 0.012568189762532711\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=379, train_loss_step=0.00842, train_loss_epoch=0.0126]Epoch 467: Train Loss = 0.00841517187654972\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=379, train_loss_step=0.012, train_loss_epoch=0.00842]  Epoch 468: Train Loss = 0.012037811800837517\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=379, train_loss_step=0.0117, train_loss_epoch=0.012] Epoch 469: Train Loss = 0.011653154157102108\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=379, train_loss_step=0.00858, train_loss_epoch=0.0117]Epoch 470: Train Loss = 0.00857960432767868\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 14.12it/s, v_num=379, train_loss_step=0.0115, train_loss_epoch=0.00858] Epoch 471: Train Loss = 0.011505044996738434\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=379, train_loss_step=0.0107, train_loss_epoch=0.0115] Epoch 472: Train Loss = 0.010672236792743206\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=379, train_loss_step=0.00961, train_loss_epoch=0.0107]Epoch 473: Train Loss = 0.009608529508113861\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=379, train_loss_step=0.00859, train_loss_epoch=0.00961]Epoch 474: Train Loss = 0.008589962497353554\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=379, train_loss_step=0.00994, train_loss_epoch=0.00859]Epoch 475: Train Loss = 0.009943860583007336\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=379, train_loss_step=0.00639, train_loss_epoch=0.00994]Epoch 476: Train Loss = 0.0063906279392540455\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=379, train_loss_step=0.0102, train_loss_epoch=0.00639] Epoch 477: Train Loss = 0.010175970382988453\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=379, train_loss_step=0.00861, train_loss_epoch=0.0102]Epoch 478: Train Loss = 0.008610313758254051\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=379, train_loss_step=0.0145, train_loss_epoch=0.00861] Epoch 479: Train Loss = 0.014460737816989422\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 13.44it/s, v_num=379, train_loss_step=0.00868, train_loss_epoch=0.0145]Epoch 480: Train Loss = 0.00868316926062107\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=379, train_loss_step=0.00986, train_loss_epoch=0.00868]Epoch 481: Train Loss = 0.009861918166279793\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=379, train_loss_step=0.0081, train_loss_epoch=0.00986] Epoch 482: Train Loss = 0.008099280297756195\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=379, train_loss_step=0.00933, train_loss_epoch=0.0081]Epoch 483: Train Loss = 0.009329475462436676\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=379, train_loss_step=0.00918, train_loss_epoch=0.00933]Epoch 484: Train Loss = 0.00918000191450119\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 13.82it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.00918] Epoch 485: Train Loss = 0.010112813673913479\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, v_num=379, train_loss_step=0.00867, train_loss_epoch=0.0101]Epoch 486: Train Loss = 0.00866683665663004\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=379, train_loss_step=0.00823, train_loss_epoch=0.00867]Epoch 487: Train Loss = 0.008231204934418201\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, v_num=379, train_loss_step=0.00958, train_loss_epoch=0.00823]Epoch 488: Train Loss = 0.009579028002917767\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=379, train_loss_step=0.00881, train_loss_epoch=0.00958]Epoch 489: Train Loss = 0.008814879693090916\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=379, train_loss_step=0.00971, train_loss_epoch=0.00881]Epoch 490: Train Loss = 0.009712008759379387\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=379, train_loss_step=0.00716, train_loss_epoch=0.00971]Epoch 491: Train Loss = 0.007155305705964565\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=379, train_loss_step=0.0101, train_loss_epoch=0.00716] Epoch 492: Train Loss = 0.010123864747583866\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=379, train_loss_step=0.00868, train_loss_epoch=0.0101]Epoch 493: Train Loss = 0.00868125632405281\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=379, train_loss_step=0.00925, train_loss_epoch=0.00868]Epoch 494: Train Loss = 0.009248399175703526\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=379, train_loss_step=0.00863, train_loss_epoch=0.00925]Epoch 495: Train Loss = 0.008631325326859951\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=379, train_loss_step=0.00916, train_loss_epoch=0.00863]Epoch 496: Train Loss = 0.00915532372891903\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=379, train_loss_step=0.00604, train_loss_epoch=0.00916]Epoch 497: Train Loss = 0.006035828031599522\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=379, train_loss_step=0.0104, train_loss_epoch=0.00604] Epoch 498: Train Loss = 0.010427877306938171\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.0104] Epoch 499: Train Loss = 0.010615126229822636\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=379, train_loss_step=0.0106, train_loss_epoch=0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the trainer\n",
    "trainer = ModelTrainer(data, scaler_close, save_loss_callback, pl_trainer_kwargs)\n",
    "\n",
    "# Training and prediction loop\n",
    "window_number = 1\n",
    "while True:\n",
    "    train_data = data.loc[:training_end_date]\n",
    "    print(f\"Training window {window_number}: from {train_data.index.min()} to {train_data.index.max()}\")\n",
    "\n",
    "    # Train the model and get predictions\n",
    "    dates, pred_values = trainer.train_model(train_data, window_number)\n",
    "\n",
    "    if len(dates) == 0:\n",
    "        print(\"No future dates were generated. Exiting the loop.\")\n",
    "        break\n",
    "\n",
    "    # Store the predictions\n",
    "    predictions_df = pd.DataFrame({'Date': dates, 'Predicted Value': pred_values.flatten()})\n",
    "    final_predictions.append(predictions_df)\n",
    "\n",
    "    # Update training_end_date for the next window only if dates exist\n",
    "    training_end_date = dates.iloc[-1] if len(dates) > 0 else training_end_date\n",
    "\n",
    "    # Break if we reach the end of the data\n",
    "    if training_end_date >= data.index.max():\n",
    "        break\n",
    "\n",
    "    window_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to prediction_using_window_method_itransformer_model_six_months_nifty_weekly.csv\n",
      "Training Losses: []\n"
     ]
    }
   ],
   "source": [
    "# Combine predictions and save\n",
    "all_predictions_df = pd.concat(final_predictions, ignore_index=True)\n",
    "output_csv_file = 'prediction_using_window_method_itransformer_model_six_months_nifty_weekly.csv'\n",
    "all_predictions_df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_csv_file}\")\n",
    "\n",
    "# Print the logged training losses\n",
    "print(\"Training Losses:\", save_loss_callback.training_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load the actual data from the CSV file\n",
    "#actual_csv_path = '/home/raj/Rajarshi/Term Project/notebook_files/data/SBIN.NS_day_2023.csv'\n",
    "actual_csv_path = csv_file_path\n",
    "actual_df = pd.read_csv(actual_csv_path)\n",
    "\n",
    "# Load the predicted data from the CSV file\n",
    "#predicted_csv_path = '/home/raj/Rajarshi/Term Project/rajarshi_code/itransformer_file/prediction_using_entire_data_itransformer_model.csv'\n",
    "predicted_csv_path = output_csv_file\n",
    "predicted_df = pd.read_csv(predicted_csv_path)\n",
    "\n",
    "# Convert the 'Date' columns to a consistent datetime format for both DataFrames\n",
    "actual_df['Date'] = pd.to_datetime(actual_df['Date'], errors='coerce')\n",
    "predicted_df['Date'] = pd.to_datetime(predicted_df['Date'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates (NaT)\n",
    "actual_df = actual_df.dropna(subset=['Date'])\n",
    "predicted_df = predicted_df.dropna(subset=['Date'])\n",
    "\n",
    "# Merge the DataFrames on the 'Date' column, keeping only the matching dates\n",
    "merged_df = pd.merge(predicted_df, actual_df, on='Date', how='inner')\n",
    "\n",
    "# Print the matched dates for verification\n",
    "# print(\"Matched Dates:\\n\", merged_df['Date'])\n",
    "\n",
    "# Plot the actual and predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(merged_df['Date'], merged_df['Close'], label='Actual Close Value', marker='o')\n",
    "plt.plot(merged_df['Date'], merged_df['Predicted Value'], label='Predicted Value', marker='x')\n",
    "\n",
    "# If 'Window Start' and 'Window End' columns are present, add vertical markers\n",
    "if 'Window Start' in predicted_df.columns and 'Window End' in predicted_df.columns:\n",
    "    for i in range(len(predicted_df)):\n",
    "        plt.axvline(predicted_df['Window Start'].iloc[i], color='green', linestyle='--', label='Window Start' if i == 0 else '')\n",
    "        plt.axvline(predicted_df['Window End'].iloc[i], color='red', linestyle='--', label='Window End' if i == 0 else '')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "title = 'Actual vs prediction_using_entire_data_itransformer_model_weekly'\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)  # Rotate the date labels for better readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Specify the folder where you want to save the plot\n",
    "output_folder = '/home/raj/Rajarshi/Term Project/notebook_files/saved_plots/'\n",
    "\n",
    "# Ensure the folder exists, if not, create it\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Use the plot title for the filename, replacing spaces with underscores and converting to lowercase\n",
    "filename = f'{title.replace(\" \", \"_\").lower()}.png'\n",
    "\n",
    "# Save the plot in the specified folder with the generated filename\n",
    "plt.savefig(os.path.join(output_folder, filename), format='png', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
