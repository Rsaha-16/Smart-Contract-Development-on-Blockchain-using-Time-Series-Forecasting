{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neuralforecast in ./tpvenv/lib/python3.10/site-packages (1.7.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (2.4.1)\n",
      "Requirement already satisfied: pytorch-lightning>=2.0.0 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (2.4.0)\n",
      "Requirement already satisfied: utilsforecast>=0.0.25 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (0.2.5)\n",
      "Requirement already satisfied: optuna in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (1.26.4)\n",
      "Requirement already satisfied: ray[tune]>=2.2.0 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (2.37.0)\n",
      "Requirement already satisfied: pandas>=1.3.5 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (2.2.3)\n",
      "Requirement already satisfied: coreforecast>=0.0.6 in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (0.0.12)\n",
      "Requirement already satisfied: fsspec in ./tpvenv/lib/python3.10/site-packages (from neuralforecast) (2024.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./tpvenv/lib/python3.10/site-packages (from pandas>=1.3.5->neuralforecast) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./tpvenv/lib/python3.10/site-packages (from pandas>=1.3.5->neuralforecast) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./tpvenv/lib/python3.10/site-packages (from pandas>=1.3.5->neuralforecast) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.66.5)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (24.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (0.11.7)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (1.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./tpvenv/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.12.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (5.28.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (1.1.0)\n",
      "Requirement already satisfied: frozenlist in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (1.4.1)\n",
      "Requirement already satisfied: aiosignal in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (1.3.1)\n",
      "Requirement already satisfied: requests in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (2.32.3)\n",
      "Requirement already satisfied: filelock in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (3.16.1)\n",
      "Requirement already satisfied: jsonschema in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (4.23.0)\n",
      "Requirement already satisfied: click>=7.0 in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (8.1.7)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in ./tpvenv/lib/python3.10/site-packages (from ray[tune]>=2.2.0->neuralforecast) (17.0.0)\n",
      "Requirement already satisfied: triton==3.0.0 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (3.0.0)\n",
      "Requirement already satisfied: networkx in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (3.1.4)\n",
      "Requirement already satisfied: sympy in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (1.13.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (2.20.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./tpvenv/lib/python3.10/site-packages (from torch>=2.0.0->neuralforecast) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./tpvenv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->neuralforecast) (12.6.68)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./tpvenv/lib/python3.10/site-packages (from optuna->neuralforecast) (2.0.35)\n",
      "Requirement already satisfied: colorlog in ./tpvenv/lib/python3.10/site-packages (from optuna->neuralforecast) (6.8.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./tpvenv/lib/python3.10/site-packages (from optuna->neuralforecast) (1.13.3)\n",
      "Requirement already satisfied: Mako in ./tpvenv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->neuralforecast) (1.3.5)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./tpvenv/lib/python3.10/site-packages (from fsspec->neuralforecast) (3.10.5)\n",
      "Requirement already satisfied: setuptools in ./tpvenv/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=2.0.0->neuralforecast) (59.6.0)\n",
      "Requirement already satisfied: six>=1.5 in ./tpvenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->neuralforecast) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./tpvenv/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->neuralforecast) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./tpvenv/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->neuralforecast) (2.1.5)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./tpvenv/lib/python3.10/site-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.20.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./tpvenv/lib/python3.10/site-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (24.2.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./tpvenv/lib/python3.10/site-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.35.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./tpvenv/lib/python3.10/site-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (2023.12.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./tpvenv/lib/python3.10/site-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./tpvenv/lib/python3.10/site-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./tpvenv/lib/python3.10/site-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./tpvenv/lib/python3.10/site-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (2.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./tpvenv/lib/python3.10/site-packages (from sympy->torch>=2.0.0->neuralforecast) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./tpvenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (1.12.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./tpvenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (6.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./tpvenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (2.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./tpvenv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (4.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install neuralforecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import iTransformer\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to save training losses at each epoch\n",
    "class SaveTrainingLossCallback(pl.Callback):\n",
    "    def __init__(self, log_file='epoch_loss_log_window_itransformer_model_six_months_nifty.txt'):\n",
    "        self.training_losses = []\n",
    "        self.log_file = log_file\n",
    "        self.window_number = 0\n",
    "        with open(self.log_file, 'w') as f:\n",
    "            f.write('Epoch,Train_Loss,Window\\n')\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # Save the training loss at the end of each epoch\n",
    "        train_loss = trainer.callback_metrics['train_loss'].item()\n",
    "        self.training_losses.append(train_loss)\n",
    "        print(f\"Epoch {trainer.current_epoch}: Train Loss = {train_loss}\")\n",
    "        \n",
    "        # Log the loss to the file\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write(f'{trainer.current_epoch},{train_loss},{self.window_number}\\n')\n",
    "\n",
    "    def set_window_number(self, window_number):\n",
    "        self.window_number = window_number\n",
    "\n",
    "# Initialize callbacks\n",
    "save_loss_callback = SaveTrainingLossCallback()\n",
    "pl_trainer_kwargs = {\"callbacks\": [save_loss_callback], \"accelerator\": \"cpu\", \"devices\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess the data\n",
    "# csv_file_path = '/home/raj/Rajarshi/Term Project/rajarshi_code/rajarshi_code/data/SBIN.NS_day_2022.csv'\n",
    "csv_file_path = '/home/raj/Rajarshi/Term Project/notebook_files/data/^NSEI_day.csv'\n",
    "data = pd.read_csv(csv_file_path, parse_dates=['Date'])\n",
    "data.dropna(inplace=True)\n",
    "data.set_index('Date', inplace=True)\n",
    "data = data.asfreq('B', method='pad')\n",
    "\n",
    "# Create scalers\n",
    "scaler_close = MinMaxScaler()\n",
    "data['Open_Close_Diff'] = data['Open'] - data['Close']\n",
    "data['Close'] = scaler_close.fit_transform(data[['Close']])\n",
    "\n",
    "# Initialize variables\n",
    "training_end_date = data.index.max() - pd.DateOffset(months=6)  # Train using last 1 year of data\n",
    "final_predictions = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window management and model training class\n",
    "class ModelTrainer:\n",
    "    def __init__(self, data, scaler_close, save_loss_callback, pl_trainer_kwargs):\n",
    "        self.data = data\n",
    "        self.scaler_close = scaler_close\n",
    "        self.save_loss_callback = save_loss_callback\n",
    "        self.pl_trainer_kwargs = pl_trainer_kwargs\n",
    "\n",
    "    def train_model(self, train_data, window_number):\n",
    "        # Set the window number for the callback\n",
    "        self.save_loss_callback.set_window_number(window_number)\n",
    "\n",
    "        # Prepare the training data\n",
    "        Y_train_df = train_data.reset_index().rename(columns={'Date': 'ds', 'Close': 'y'})\n",
    "        # Y_train_df['unique_id'] = 'SBIN'\n",
    "        Y_train_df['unique_id'] = 'NSEI'\n",
    "\n",
    "        # Initialize and train the iTransformer model\n",
    "        model = iTransformer(\n",
    "            h=7,  # Output horizon (prediction length)\n",
    "            input_size=60,  # Input window size\n",
    "            n_series=1,  # Number of time series (SBIN in this case)\n",
    "            hidden_size=512,  # Adjusted for iTransformer\n",
    "            n_heads=8,\n",
    "            e_layers=2,\n",
    "            d_layers=1,\n",
    "            d_ff=2048,\n",
    "            factor=1,\n",
    "            dropout=0.1,\n",
    "            use_norm=True,\n",
    "            loss=MAE(),\n",
    "            learning_rate=0.001,\n",
    "            max_steps=500,  # Adjusted as per your code\n",
    "            **{'callbacks': [self.save_loss_callback]}  # Pass the callback directly here\n",
    "        )\n",
    "\n",
    "        # NeuralForecast object to handle model training\n",
    "        nf = NeuralForecast(models=[model], freq='B')\n",
    "        nf.fit(df=Y_train_df)\n",
    "\n",
    "        # Generate future dataframe automatically\n",
    "        futr_df = nf.make_future_dataframe()\n",
    "\n",
    "        # Generate predictions\n",
    "        forecasts = nf.predict(futr_df=futr_df)\n",
    "        \n",
    "        pred_values = self.scaler_close.inverse_transform(forecasts[['iTransformer']].values)\n",
    "        dates = futr_df['ds']\n",
    "\n",
    "        return dates, pred_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training window 1: from 2010-06-30 00:00:00 to 2022-06-30 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s, v_num=295, train_loss_step=0.0246]Epoch 0: Train Loss = 0.02461724914610386\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=295, train_loss_step=0.0474, train_loss_epoch=0.0246]Epoch 1: Train Loss = 0.047354716807603836\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=295, train_loss_step=0.0277, train_loss_epoch=0.0474]Epoch 2: Train Loss = 0.02774818241596222\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=295, train_loss_step=0.0245, train_loss_epoch=0.0277]Epoch 3: Train Loss = 0.024504294618964195\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=295, train_loss_step=0.027, train_loss_epoch=0.0245] Epoch 4: Train Loss = 0.02702927030622959\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=295, train_loss_step=0.0249, train_loss_epoch=0.027]Epoch 5: Train Loss = 0.02490284852683544\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=295, train_loss_step=0.0192, train_loss_epoch=0.0249]Epoch 6: Train Loss = 0.019232941791415215\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s, v_num=295, train_loss_step=0.0169, train_loss_epoch=0.0192]Epoch 7: Train Loss = 0.01688109152019024\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=295, train_loss_step=0.0176, train_loss_epoch=0.0169]Epoch 8: Train Loss = 0.017611192539334297\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=295, train_loss_step=0.0172, train_loss_epoch=0.0176]Epoch 9: Train Loss = 0.01724868454039097\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 13.96it/s, v_num=295, train_loss_step=0.0204, train_loss_epoch=0.0172]Epoch 10: Train Loss = 0.020416056737303734\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=295, train_loss_step=0.0157, train_loss_epoch=0.0204]Epoch 11: Train Loss = 0.01572764851152897\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=295, train_loss_step=0.0136, train_loss_epoch=0.0157]Epoch 12: Train Loss = 0.013644443824887276\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=295, train_loss_step=0.0152, train_loss_epoch=0.0136]Epoch 13: Train Loss = 0.015163183212280273\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.0152]Epoch 14: Train Loss = 0.013466360978782177\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=295, train_loss_step=0.0127, train_loss_epoch=0.0135]Epoch 15: Train Loss = 0.012724610976874828\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=295, train_loss_step=0.00987, train_loss_epoch=0.0127]Epoch 16: Train Loss = 0.009869481436908245\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=295, train_loss_step=0.0151, train_loss_epoch=0.00987] Epoch 17: Train Loss = 0.015128632076084614\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=295, train_loss_step=0.014, train_loss_epoch=0.0151]  Epoch 18: Train Loss = 0.013966729864478111\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=295, train_loss_step=0.0111, train_loss_epoch=0.014]Epoch 19: Train Loss = 0.011087757535278797\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.0111]Epoch 20: Train Loss = 0.013296497985720634\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.0133]Epoch 21: Train Loss = 0.013479948043823242\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 16.89it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0135]Epoch 22: Train Loss = 0.01262478344142437\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=295, train_loss_step=0.0156, train_loss_epoch=0.0126]Epoch 23: Train Loss = 0.015606081113219261\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=295, train_loss_step=0.0147, train_loss_epoch=0.0156]Epoch 24: Train Loss = 0.01468698214739561\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=295, train_loss_step=0.0125, train_loss_epoch=0.0147]Epoch 25: Train Loss = 0.012452737428247929\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=295, train_loss_step=0.0161, train_loss_epoch=0.0125]Epoch 26: Train Loss = 0.016129903495311737\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=295, train_loss_step=0.0119, train_loss_epoch=0.0161]Epoch 27: Train Loss = 0.011857873760163784\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=295, train_loss_step=0.0123, train_loss_epoch=0.0119]Epoch 28: Train Loss = 0.012340064160525799\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 16.92it/s, v_num=295, train_loss_step=0.0147, train_loss_epoch=0.0123]Epoch 29: Train Loss = 0.01473987102508545\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s, v_num=295, train_loss_step=0.012, train_loss_epoch=0.0147] Epoch 30: Train Loss = 0.011998161673545837\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 16.72it/s, v_num=295, train_loss_step=0.0122, train_loss_epoch=0.012]Epoch 31: Train Loss = 0.012205236591398716\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=295, train_loss_step=0.0153, train_loss_epoch=0.0122]Epoch 32: Train Loss = 0.015284344553947449\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 17.75it/s, v_num=295, train_loss_step=0.0108, train_loss_epoch=0.0153]Epoch 33: Train Loss = 0.010838278569281101\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 17.89it/s, v_num=295, train_loss_step=0.0124, train_loss_epoch=0.0108]Epoch 34: Train Loss = 0.012378202751278877\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 16.02it/s, v_num=295, train_loss_step=0.0195, train_loss_epoch=0.0124]Epoch 35: Train Loss = 0.019510900601744652\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=295, train_loss_step=0.0141, train_loss_epoch=0.0195]Epoch 36: Train Loss = 0.014069479890167713\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=295, train_loss_step=0.0143, train_loss_epoch=0.0141]Epoch 37: Train Loss = 0.014280063100159168\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=295, train_loss_step=0.0132, train_loss_epoch=0.0143]Epoch 38: Train Loss = 0.013215258717536926\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=295, train_loss_step=0.0141, train_loss_epoch=0.0132]Epoch 39: Train Loss = 0.01405817735940218\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=295, train_loss_step=0.0155, train_loss_epoch=0.0141]Epoch 40: Train Loss = 0.015546774491667747\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=295, train_loss_step=0.0139, train_loss_epoch=0.0155]Epoch 41: Train Loss = 0.013891125097870827\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.0139]Epoch 42: Train Loss = 0.012144463136792183\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=295, train_loss_step=0.0106, train_loss_epoch=0.0121]Epoch 43: Train Loss = 0.01062235701829195\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=295, train_loss_step=0.0138, train_loss_epoch=0.0106]Epoch 44: Train Loss = 0.01379468385130167\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=295, train_loss_step=0.0194, train_loss_epoch=0.0138]Epoch 45: Train Loss = 0.019395655021071434\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=295, train_loss_step=0.0128, train_loss_epoch=0.0194]Epoch 46: Train Loss = 0.012799330987036228\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 13.19it/s, v_num=295, train_loss_step=0.0181, train_loss_epoch=0.0128]Epoch 47: Train Loss = 0.018145067617297173\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=295, train_loss_step=0.0141, train_loss_epoch=0.0181]Epoch 48: Train Loss = 0.014109504409134388\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=295, train_loss_step=0.0247, train_loss_epoch=0.0141]Epoch 49: Train Loss = 0.02473020739853382\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=295, train_loss_step=0.0194, train_loss_epoch=0.0247]Epoch 50: Train Loss = 0.01935800537467003\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, v_num=295, train_loss_step=0.0167, train_loss_epoch=0.0194]Epoch 51: Train Loss = 0.016719330102205276\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 17.52it/s, v_num=295, train_loss_step=0.0131, train_loss_epoch=0.0167]Epoch 52: Train Loss = 0.013084123842418194\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 16.94it/s, v_num=295, train_loss_step=0.0145, train_loss_epoch=0.0131]Epoch 53: Train Loss = 0.014534682966768742\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s, v_num=295, train_loss_step=0.0215, train_loss_epoch=0.0145]Epoch 54: Train Loss = 0.021515551954507828\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=295, train_loss_step=0.0156, train_loss_epoch=0.0215]Epoch 55: Train Loss = 0.015600299462676048\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=295, train_loss_step=0.0109, train_loss_epoch=0.0156]Epoch 56: Train Loss = 0.010899417102336884\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 16.28it/s, v_num=295, train_loss_step=0.0159, train_loss_epoch=0.0109]Epoch 57: Train Loss = 0.01593243144452572\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, v_num=295, train_loss_step=0.0165, train_loss_epoch=0.0159]Epoch 58: Train Loss = 0.016491921618580818\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 17.09it/s, v_num=295, train_loss_step=0.0197, train_loss_epoch=0.0165]Epoch 59: Train Loss = 0.019747702404856682\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s, v_num=295, train_loss_step=0.0269, train_loss_epoch=0.0197]Epoch 60: Train Loss = 0.0269209872931242\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 15.92it/s, v_num=295, train_loss_step=0.0185, train_loss_epoch=0.0269]Epoch 61: Train Loss = 0.018542161211371422\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=295, train_loss_step=0.0174, train_loss_epoch=0.0185]Epoch 62: Train Loss = 0.017357928678393364\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.0174]Epoch 63: Train Loss = 0.013290268369019032\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=295, train_loss_step=0.015, train_loss_epoch=0.0133] Epoch 64: Train Loss = 0.014989574439823627\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=295, train_loss_step=0.0105, train_loss_epoch=0.015]Epoch 65: Train Loss = 0.010452008806169033\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 16.89it/s, v_num=295, train_loss_step=0.0159, train_loss_epoch=0.0105]Epoch 66: Train Loss = 0.015926694497466087\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=295, train_loss_step=0.0155, train_loss_epoch=0.0159]Epoch 67: Train Loss = 0.015525146387517452\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=295, train_loss_step=0.0149, train_loss_epoch=0.0155]Epoch 68: Train Loss = 0.014912348240613937\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=295, train_loss_step=0.0168, train_loss_epoch=0.0149]Epoch 69: Train Loss = 0.016847549006342888\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=295, train_loss_step=0.0153, train_loss_epoch=0.0168]Epoch 70: Train Loss = 0.015295254066586494\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=295, train_loss_step=0.0148, train_loss_epoch=0.0153]Epoch 71: Train Loss = 0.014753618277609348\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=295, train_loss_step=0.0137, train_loss_epoch=0.0148]Epoch 72: Train Loss = 0.013714948669075966\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=295, train_loss_step=0.0143, train_loss_epoch=0.0137]Epoch 73: Train Loss = 0.014340235851705074\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=295, train_loss_step=0.0131, train_loss_epoch=0.0143]Epoch 74: Train Loss = 0.013130811974406242\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.0131]Epoch 75: Train Loss = 0.01353419665247202\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=295, train_loss_step=0.0141, train_loss_epoch=0.0135]Epoch 76: Train Loss = 0.0141125014051795\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, v_num=295, train_loss_step=0.0139, train_loss_epoch=0.0141]Epoch 77: Train Loss = 0.013903869315981865\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=295, train_loss_step=0.0156, train_loss_epoch=0.0139]Epoch 78: Train Loss = 0.015630777925252914\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s, v_num=295, train_loss_step=0.0181, train_loss_epoch=0.0156]Epoch 79: Train Loss = 0.01808878779411316\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.0181]Epoch 80: Train Loss = 0.010290166363120079\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s, v_num=295, train_loss_step=0.0145, train_loss_epoch=0.0103]Epoch 81: Train Loss = 0.014501484110951424\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 16.55it/s, v_num=295, train_loss_step=0.0128, train_loss_epoch=0.0145]Epoch 82: Train Loss = 0.012788055464625359\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.0128]Epoch 83: Train Loss = 0.013533330522477627\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=295, train_loss_step=0.0132, train_loss_epoch=0.0135]Epoch 84: Train Loss = 0.013190315105021\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=295, train_loss_step=0.0175, train_loss_epoch=0.0132]Epoch 85: Train Loss = 0.017482953146100044\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, v_num=295, train_loss_step=0.0171, train_loss_epoch=0.0175]Epoch 86: Train Loss = 0.01711510308086872\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 17.61it/s, v_num=295, train_loss_step=0.017, train_loss_epoch=0.0171] Epoch 87: Train Loss = 0.017046993598341942\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=295, train_loss_step=0.0134, train_loss_epoch=0.017]Epoch 88: Train Loss = 0.013352411799132824\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 17.11it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.0134]Epoch 89: Train Loss = 0.010272388346493244\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=295, train_loss_step=0.0145, train_loss_epoch=0.0103]Epoch 90: Train Loss = 0.0144698116928339\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=295, train_loss_step=0.0123, train_loss_epoch=0.0145]Epoch 91: Train Loss = 0.012288806959986687\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.0123]Epoch 92: Train Loss = 0.013310559093952179\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.0133] Epoch 93: Train Loss = 0.013049031607806683\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 10.71it/s, v_num=295, train_loss_step=0.00839, train_loss_epoch=0.013]Epoch 94: Train Loss = 0.008393647149205208\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, v_num=295, train_loss_step=0.00907, train_loss_epoch=0.00839]Epoch 95: Train Loss = 0.009074157103896141\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=295, train_loss_step=0.0114, train_loss_epoch=0.00907] Epoch 96: Train Loss = 0.011412869207561016\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=295, train_loss_step=0.0114, train_loss_epoch=0.0114] Epoch 97: Train Loss = 0.011364886537194252\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s, v_num=295, train_loss_step=0.0177, train_loss_epoch=0.0114]Epoch 98: Train Loss = 0.017672352492809296\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=295, train_loss_step=0.0153, train_loss_epoch=0.0177]Epoch 99: Train Loss = 0.015326396562159061\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.0153] Epoch 100: Train Loss = 0.012975207529962063\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=295, train_loss_step=0.0132, train_loss_epoch=0.013]Epoch 101: Train Loss = 0.013174899853765965\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=295, train_loss_step=0.021, train_loss_epoch=0.0132] Epoch 102: Train Loss = 0.02100604958832264\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=295, train_loss_step=0.0116, train_loss_epoch=0.021]Epoch 103: Train Loss = 0.011551265604794025\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=295, train_loss_step=0.0155, train_loss_epoch=0.0116]Epoch 104: Train Loss = 0.015476929023861885\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=295, train_loss_step=0.014, train_loss_epoch=0.0155] Epoch 105: Train Loss = 0.013995633460581303\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=295, train_loss_step=0.0144, train_loss_epoch=0.014]Epoch 106: Train Loss = 0.014409693889319897\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=295, train_loss_step=0.019, train_loss_epoch=0.0144] Epoch 107: Train Loss = 0.019047601148486137\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, v_num=295, train_loss_step=0.0183, train_loss_epoch=0.019]Epoch 108: Train Loss = 0.018293676897883415\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.0183]Epoch 109: Train Loss = 0.013340950012207031\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=295, train_loss_step=0.0158, train_loss_epoch=0.0133]Epoch 110: Train Loss = 0.015843670815229416\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=295, train_loss_step=0.0123, train_loss_epoch=0.0158]Epoch 111: Train Loss = 0.012303886003792286\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s, v_num=295, train_loss_step=0.0127, train_loss_epoch=0.0123]Epoch 112: Train Loss = 0.012725633569061756\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=295, train_loss_step=0.0124, train_loss_epoch=0.0127]Epoch 113: Train Loss = 0.012449763715267181\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=295, train_loss_step=0.0105, train_loss_epoch=0.0124]Epoch 114: Train Loss = 0.010508052073419094\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=295, train_loss_step=0.0147, train_loss_epoch=0.0105]Epoch 115: Train Loss = 0.014740179292857647\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 10.22it/s, v_num=295, train_loss_step=0.0118, train_loss_epoch=0.0147]Epoch 116: Train Loss = 0.011808390729129314\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=295, train_loss_step=0.0102, train_loss_epoch=0.0118]Epoch 117: Train Loss = 0.010238508693873882\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=295, train_loss_step=0.0149, train_loss_epoch=0.0102]Epoch 118: Train Loss = 0.014907649718225002\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=295, train_loss_step=0.0163, train_loss_epoch=0.0149]Epoch 119: Train Loss = 0.01627548784017563\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=295, train_loss_step=0.0115, train_loss_epoch=0.0163]Epoch 120: Train Loss = 0.01146979071199894\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.0115] Epoch 121: Train Loss = 0.013042408041656017\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.013]Epoch 122: Train Loss = 0.01331937126815319\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=295, train_loss_step=0.0125, train_loss_epoch=0.0133]Epoch 123: Train Loss = 0.012454603798687458\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=295, train_loss_step=0.0115, train_loss_epoch=0.0125]Epoch 124: Train Loss = 0.011493409052491188\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=295, train_loss_step=0.0101, train_loss_epoch=0.0115]Epoch 125: Train Loss = 0.010107452981173992\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.0101]Epoch 126: Train Loss = 0.010347363539040089\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=295, train_loss_step=0.0197, train_loss_epoch=0.0103]Epoch 127: Train Loss = 0.01968619041144848\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=295, train_loss_step=0.0145, train_loss_epoch=0.0197]Epoch 128: Train Loss = 0.014495422132313251\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=295, train_loss_step=0.0113, train_loss_epoch=0.0145]Epoch 129: Train Loss = 0.01125760655850172\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=295, train_loss_step=0.0212, train_loss_epoch=0.0113]Epoch 130: Train Loss = 0.021179277449846268\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=295, train_loss_step=0.011, train_loss_epoch=0.0212] Epoch 131: Train Loss = 0.010991567745804787\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=295, train_loss_step=0.017, train_loss_epoch=0.011] Epoch 132: Train Loss = 0.016967996954917908\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=295, train_loss_step=0.0115, train_loss_epoch=0.017]Epoch 133: Train Loss = 0.011454601772129536\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0115]Epoch 134: Train Loss = 0.01258258055895567\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=295, train_loss_step=0.0101, train_loss_epoch=0.0126]Epoch 135: Train Loss = 0.01011924259364605\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=295, train_loss_step=0.0137, train_loss_epoch=0.0101]Epoch 136: Train Loss = 0.013736928813159466\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, v_num=295, train_loss_step=0.0146, train_loss_epoch=0.0137]Epoch 137: Train Loss = 0.014635225757956505\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=295, train_loss_step=0.0131, train_loss_epoch=0.0146]Epoch 138: Train Loss = 0.01307060569524765\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=295, train_loss_step=0.016, train_loss_epoch=0.0131] Epoch 139: Train Loss = 0.01603217050433159\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.016]Epoch 140: Train Loss = 0.012071936391294003\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=295, train_loss_step=0.017, train_loss_epoch=0.0121] Epoch 141: Train Loss = 0.017047544941306114\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s, v_num=295, train_loss_step=0.0173, train_loss_epoch=0.017]Epoch 142: Train Loss = 0.017303813248872757\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=295, train_loss_step=0.0168, train_loss_epoch=0.0173]Epoch 143: Train Loss = 0.016817931085824966\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.0168]Epoch 144: Train Loss = 0.013470137491822243\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=295, train_loss_step=0.0142, train_loss_epoch=0.0135]Epoch 145: Train Loss = 0.014238238334655762\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.0142]Epoch 146: Train Loss = 0.012128357775509357\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.0121] Epoch 147: Train Loss = 0.013007485307753086\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.013] Epoch 148: Train Loss = 0.012956397607922554\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=295, train_loss_step=0.0141, train_loss_epoch=0.013]Epoch 149: Train Loss = 0.014117354527115822\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=295, train_loss_step=0.0191, train_loss_epoch=0.0141]Epoch 150: Train Loss = 0.019093407317996025\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=295, train_loss_step=0.0137, train_loss_epoch=0.0191]Epoch 151: Train Loss = 0.013669378124177456\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=295, train_loss_step=0.011, train_loss_epoch=0.0137] Epoch 152: Train Loss = 0.010973773896694183\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=295, train_loss_step=0.0122, train_loss_epoch=0.011]Epoch 153: Train Loss = 0.012154318392276764\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0122]Epoch 154: Train Loss = 0.012895877473056316\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=295, train_loss_step=0.0104, train_loss_epoch=0.0129]Epoch 155: Train Loss = 0.010395417921245098\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0104]Epoch 156: Train Loss = 0.012937433086335659\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=295, train_loss_step=0.0107, train_loss_epoch=0.0129]Epoch 157: Train Loss = 0.010713557712733746\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.0107]Epoch 158: Train Loss = 0.010340360924601555\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=295, train_loss_step=0.0102, train_loss_epoch=0.0103]Epoch 159: Train Loss = 0.010165964253246784\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0102]Epoch 160: Train Loss = 0.012596704997122288\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s, v_num=295, train_loss_step=0.0137, train_loss_epoch=0.0126]Epoch 161: Train Loss = 0.01367832999676466\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=295, train_loss_step=0.0101, train_loss_epoch=0.0137]Epoch 162: Train Loss = 0.010053334757685661\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.0101]Epoch 163: Train Loss = 0.01213153637945652\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.0121]Epoch 164: Train Loss = 0.012138361111283302\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0121]Epoch 165: Train Loss = 0.012931196950376034\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=295, train_loss_step=0.0099, train_loss_epoch=0.0129]Epoch 166: Train Loss = 0.009901517070829868\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=295, train_loss_step=0.0193, train_loss_epoch=0.0099]Epoch 167: Train Loss = 0.01934911496937275\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=295, train_loss_step=0.014, train_loss_epoch=0.0193] Epoch 168: Train Loss = 0.01404582243412733\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.014]Epoch 169: Train Loss = 0.010276970453560352\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.0103]Epoch 170: Train Loss = 0.01211576908826828\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=295, train_loss_step=0.0114, train_loss_epoch=0.0121]Epoch 171: Train Loss = 0.011371049098670483\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  9.60it/s, v_num=295, train_loss_step=0.0143, train_loss_epoch=0.0114]Epoch 172: Train Loss = 0.014262313954532146\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.0143]Epoch 173: Train Loss = 0.013263598084449768\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0133]Epoch 174: Train Loss = 0.01259655226022005\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=295, train_loss_step=0.0118, train_loss_epoch=0.0126]Epoch 175: Train Loss = 0.011842821724712849\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s, v_num=295, train_loss_step=0.0132, train_loss_epoch=0.0118]Epoch 176: Train Loss = 0.013204718939960003\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 11.26it/s, v_num=295, train_loss_step=0.0148, train_loss_epoch=0.0132]Epoch 177: Train Loss = 0.014849407598376274\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=295, train_loss_step=0.0118, train_loss_epoch=0.0148]Epoch 178: Train Loss = 0.011844987981021404\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=295, train_loss_step=0.0114, train_loss_epoch=0.0118]Epoch 179: Train Loss = 0.011431119404733181\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=295, train_loss_step=0.0161, train_loss_epoch=0.0114]Epoch 180: Train Loss = 0.01613006182014942\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=295, train_loss_step=0.0159, train_loss_epoch=0.0161]Epoch 181: Train Loss = 0.015859518200159073\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0159]Epoch 182: Train Loss = 0.012870634905993938\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=295, train_loss_step=0.0144, train_loss_epoch=0.0129]Epoch 183: Train Loss = 0.014444439671933651\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=295, train_loss_step=0.0118, train_loss_epoch=0.0144]Epoch 184: Train Loss = 0.011799340136349201\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=295, train_loss_step=0.0128, train_loss_epoch=0.0118]Epoch 185: Train Loss = 0.012783239595592022\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 10.18it/s, v_num=295, train_loss_step=0.0162, train_loss_epoch=0.0128]Epoch 186: Train Loss = 0.016170013695955276\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=295, train_loss_step=0.0102, train_loss_epoch=0.0162]Epoch 187: Train Loss = 0.01018444448709488\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=295, train_loss_step=0.0111, train_loss_epoch=0.0102]Epoch 188: Train Loss = 0.011131195351481438\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.0111] Epoch 189: Train Loss = 0.013004949316382408\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=295, train_loss_step=0.0105, train_loss_epoch=0.013]Epoch 190: Train Loss = 0.010514014400541782\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=295, train_loss_step=0.0162, train_loss_epoch=0.0105]Epoch 191: Train Loss = 0.016228822991251945\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s, v_num=295, train_loss_step=0.0162, train_loss_epoch=0.0162]Epoch 192: Train Loss = 0.01619732193648815\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s, v_num=295, train_loss_step=0.0131, train_loss_epoch=0.0162]Epoch 193: Train Loss = 0.013082338497042656\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=295, train_loss_step=0.014, train_loss_epoch=0.0131] Epoch 194: Train Loss = 0.01398486364632845\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=295, train_loss_step=0.0159, train_loss_epoch=0.014]Epoch 195: Train Loss = 0.015912752598524094\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=295, train_loss_step=0.0117, train_loss_epoch=0.0159]Epoch 196: Train Loss = 0.01170969009399414\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=295, train_loss_step=0.0115, train_loss_epoch=0.0117]Epoch 197: Train Loss = 0.011548672802746296\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0115]Epoch 198: Train Loss = 0.012575707398355007\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=295, train_loss_step=0.0136, train_loss_epoch=0.0126]Epoch 199: Train Loss = 0.013553857803344727\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=295, train_loss_step=0.0113, train_loss_epoch=0.0136]Epoch 200: Train Loss = 0.01128722820430994\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=295, train_loss_step=0.0125, train_loss_epoch=0.0113]Epoch 201: Train Loss = 0.01248090248554945\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=295, train_loss_step=0.0109, train_loss_epoch=0.0125]Epoch 202: Train Loss = 0.0108674680814147\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=295, train_loss_step=0.0148, train_loss_epoch=0.0109]Epoch 203: Train Loss = 0.014764553867280483\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=295, train_loss_step=0.0119, train_loss_epoch=0.0148]Epoch 204: Train Loss = 0.011860075406730175\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=295, train_loss_step=0.0176, train_loss_epoch=0.0119]Epoch 205: Train Loss = 0.017614131793379784\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.0176]Epoch 206: Train Loss = 0.012126031331717968\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=295, train_loss_step=0.016, train_loss_epoch=0.0121] Epoch 207: Train Loss = 0.01601579412817955\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=295, train_loss_step=0.0114, train_loss_epoch=0.016]Epoch 208: Train Loss = 0.011379559524357319\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=295, train_loss_step=0.0104, train_loss_epoch=0.0114]Epoch 209: Train Loss = 0.010380817577242851\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=295, train_loss_step=0.0172, train_loss_epoch=0.0104]Epoch 210: Train Loss = 0.017150351777672768\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=295, train_loss_step=0.0178, train_loss_epoch=0.0172]Epoch 211: Train Loss = 0.01783958077430725\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=295, train_loss_step=0.0115, train_loss_epoch=0.0178]Epoch 212: Train Loss = 0.011506101116538048\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s, v_num=295, train_loss_step=0.0128, train_loss_epoch=0.0115]Epoch 213: Train Loss = 0.012778975069522858\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=295, train_loss_step=0.0156, train_loss_epoch=0.0128]Epoch 214: Train Loss = 0.015597255900502205\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=295, train_loss_step=0.0139, train_loss_epoch=0.0156]Epoch 215: Train Loss = 0.013855879195034504\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=295, train_loss_step=0.0188, train_loss_epoch=0.0139]Epoch 216: Train Loss = 0.018772365525364876\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=295, train_loss_step=0.0134, train_loss_epoch=0.0188]Epoch 217: Train Loss = 0.013413788750767708\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=295, train_loss_step=0.0149, train_loss_epoch=0.0134]Epoch 218: Train Loss = 0.014853313565254211\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=295, train_loss_step=0.0111, train_loss_epoch=0.0149]Epoch 219: Train Loss = 0.011081812903285027\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=295, train_loss_step=0.00889, train_loss_epoch=0.0111]Epoch 220: Train Loss = 0.008886897005140781\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.00889] Epoch 221: Train Loss = 0.012074420228600502\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.0121] Epoch 222: Train Loss = 0.013287401758134365\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=295, train_loss_step=0.0101, train_loss_epoch=0.0133]Epoch 223: Train Loss = 0.010050066746771336\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=295, train_loss_step=0.0139, train_loss_epoch=0.0101]Epoch 224: Train Loss = 0.013891947455704212\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=295, train_loss_step=0.0151, train_loss_epoch=0.0139]Epoch 225: Train Loss = 0.015065263025462627\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=295, train_loss_step=0.0134, train_loss_epoch=0.0151]Epoch 226: Train Loss = 0.013448839075863361\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=295, train_loss_step=0.0118, train_loss_epoch=0.0134]Epoch 227: Train Loss = 0.011845315806567669\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=295, train_loss_step=0.011, train_loss_epoch=0.0118] Epoch 228: Train Loss = 0.010988391935825348\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=295, train_loss_step=0.00953, train_loss_epoch=0.011]Epoch 229: Train Loss = 0.00952978152781725\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=295, train_loss_step=0.0123, train_loss_epoch=0.00953] Epoch 230: Train Loss = 0.012264562770724297\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=295, train_loss_step=0.0137, train_loss_epoch=0.0123] Epoch 231: Train Loss = 0.01374803576618433\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=295, train_loss_step=0.017, train_loss_epoch=0.0137] Epoch 232: Train Loss = 0.016995051875710487\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=295, train_loss_step=0.0159, train_loss_epoch=0.017]Epoch 233: Train Loss = 0.01590048149228096\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=295, train_loss_step=0.0134, train_loss_epoch=0.0159]Epoch 234: Train Loss = 0.013395220972597599\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=295, train_loss_step=0.0124, train_loss_epoch=0.0134]Epoch 235: Train Loss = 0.012447063811123371\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=295, train_loss_step=0.0142, train_loss_epoch=0.0124]Epoch 236: Train Loss = 0.014199523255228996\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=295, train_loss_step=0.0261, train_loss_epoch=0.0142]Epoch 237: Train Loss = 0.026057640090584755\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0261]Epoch 238: Train Loss = 0.012942220084369183\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, v_num=295, train_loss_step=0.014, train_loss_epoch=0.0129] Epoch 239: Train Loss = 0.014040589332580566\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=295, train_loss_step=0.0104, train_loss_epoch=0.014]Epoch 240: Train Loss = 0.010449035093188286\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 10.97it/s, v_num=295, train_loss_step=0.0122, train_loss_epoch=0.0104]Epoch 241: Train Loss = 0.01222214661538601\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=295, train_loss_step=0.0119, train_loss_epoch=0.0122]Epoch 242: Train Loss = 0.011859106831252575\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 10.51it/s, v_num=295, train_loss_step=0.0156, train_loss_epoch=0.0119]Epoch 243: Train Loss = 0.015618243254721165\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s, v_num=295, train_loss_step=0.0157, train_loss_epoch=0.0156]Epoch 244: Train Loss = 0.015721697360277176\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s, v_num=295, train_loss_step=0.0123, train_loss_epoch=0.0157]Epoch 245: Train Loss = 0.012318268418312073\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=295, train_loss_step=0.0104, train_loss_epoch=0.0123]Epoch 246: Train Loss = 0.010391094721853733\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0104]Epoch 247: Train Loss = 0.01259190496057272\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0126]Epoch 248: Train Loss = 0.01294990349560976\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0129]Epoch 249: Train Loss = 0.012902090325951576\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=295, train_loss_step=0.00943, train_loss_epoch=0.0129]Epoch 250: Train Loss = 0.009428644552826881\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=295, train_loss_step=0.0108, train_loss_epoch=0.00943] Epoch 251: Train Loss = 0.0107788210734725\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=295, train_loss_step=0.0123, train_loss_epoch=0.0108] Epoch 252: Train Loss = 0.012254362925887108\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=295, train_loss_step=0.0163, train_loss_epoch=0.0123]Epoch 253: Train Loss = 0.016347631812095642\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0163]Epoch 254: Train Loss = 0.012596415355801582\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=295, train_loss_step=0.0158, train_loss_epoch=0.0126]Epoch 255: Train Loss = 0.015766900032758713\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.0158]Epoch 256: Train Loss = 0.010264260694384575\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=295, train_loss_step=0.010, train_loss_epoch=0.0103] Epoch 257: Train Loss = 0.010033565573394299\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=295, train_loss_step=0.0174, train_loss_epoch=0.010]Epoch 258: Train Loss = 0.01735350303351879\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=295, train_loss_step=0.0117, train_loss_epoch=0.0174]Epoch 259: Train Loss = 0.011677303351461887\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=295, train_loss_step=0.0122, train_loss_epoch=0.0117]Epoch 260: Train Loss = 0.01220818143337965\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=295, train_loss_step=0.00974, train_loss_epoch=0.0122]Epoch 261: Train Loss = 0.009735959582030773\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=295, train_loss_step=0.0139, train_loss_epoch=0.00974] Epoch 262: Train Loss = 0.013920755125582218\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=295, train_loss_step=0.015, train_loss_epoch=0.0139]  Epoch 263: Train Loss = 0.014967307448387146\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.015]Epoch 264: Train Loss = 0.01354469545185566\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.0135]Epoch 265: Train Loss = 0.012119488790631294\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=295, train_loss_step=0.012, train_loss_epoch=0.0121] Epoch 266: Train Loss = 0.011985891498625278\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=295, train_loss_step=0.0141, train_loss_epoch=0.012]Epoch 267: Train Loss = 0.014082902111113071\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.0141] Epoch 268: Train Loss = 0.012977475300431252\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s, v_num=295, train_loss_step=0.0137, train_loss_epoch=0.013]Epoch 269: Train Loss = 0.01368860062211752\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=295, train_loss_step=0.0112, train_loss_epoch=0.0137]Epoch 270: Train Loss = 0.011224484071135521\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=295, train_loss_step=0.0144, train_loss_epoch=0.0112]Epoch 271: Train Loss = 0.014415977522730827\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=295, train_loss_step=0.0161, train_loss_epoch=0.0144]Epoch 272: Train Loss = 0.016083652153611183\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=295, train_loss_step=0.0102, train_loss_epoch=0.0161]Epoch 273: Train Loss = 0.010161404497921467\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=295, train_loss_step=0.0173, train_loss_epoch=0.0102]Epoch 274: Train Loss = 0.017342709004878998\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=295, train_loss_step=0.0172, train_loss_epoch=0.0173]Epoch 275: Train Loss = 0.017170535400509834\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0172]Epoch 276: Train Loss = 0.012563982978463173\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.0126]Epoch 277: Train Loss = 0.013534383848309517\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=295, train_loss_step=0.0172, train_loss_epoch=0.0135]Epoch 278: Train Loss = 0.017199868336319923\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=295, train_loss_step=0.0177, train_loss_epoch=0.0172]Epoch 279: Train Loss = 0.01767405867576599\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=295, train_loss_step=0.012, train_loss_epoch=0.0177] Epoch 280: Train Loss = 0.012022783979773521\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=295, train_loss_step=0.0175, train_loss_epoch=0.012]Epoch 281: Train Loss = 0.01748942770063877\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=295, train_loss_step=0.0205, train_loss_epoch=0.0175]Epoch 282: Train Loss = 0.02051551640033722\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=295, train_loss_step=0.0122, train_loss_epoch=0.0205]Epoch 283: Train Loss = 0.012199083343148232\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=295, train_loss_step=0.0165, train_loss_epoch=0.0122]Epoch 284: Train Loss = 0.016503887251019478\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s, v_num=295, train_loss_step=0.0181, train_loss_epoch=0.0165]Epoch 285: Train Loss = 0.01809169538319111\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=295, train_loss_step=0.012, train_loss_epoch=0.0181] Epoch 286: Train Loss = 0.012023798190057278\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=295, train_loss_step=0.017, train_loss_epoch=0.012] Epoch 287: Train Loss = 0.016986439004540443\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=295, train_loss_step=0.0141, train_loss_epoch=0.017]Epoch 288: Train Loss = 0.014058263972401619\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=295, train_loss_step=0.0145, train_loss_epoch=0.0141]Epoch 289: Train Loss = 0.014456755481660366\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=295, train_loss_step=0.0166, train_loss_epoch=0.0145]Epoch 290: Train Loss = 0.016576098278164864\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=295, train_loss_step=0.0153, train_loss_epoch=0.0166]Epoch 291: Train Loss = 0.015309899114072323\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.0153]Epoch 292: Train Loss = 0.013455805368721485\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 13.01it/s, v_num=295, train_loss_step=0.0114, train_loss_epoch=0.0135]Epoch 293: Train Loss = 0.011415348388254642\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=295, train_loss_step=0.0166, train_loss_epoch=0.0114]Epoch 294: Train Loss = 0.01658746600151062\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=295, train_loss_step=0.0243, train_loss_epoch=0.0166]Epoch 295: Train Loss = 0.024313177913427353\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=295, train_loss_step=0.0231, train_loss_epoch=0.0243]Epoch 296: Train Loss = 0.02307734079658985\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=295, train_loss_step=0.0166, train_loss_epoch=0.0231]Epoch 297: Train Loss = 0.01662847213447094\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=295, train_loss_step=0.0156, train_loss_epoch=0.0166]Epoch 298: Train Loss = 0.015597408637404442\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=295, train_loss_step=0.0128, train_loss_epoch=0.0156]Epoch 299: Train Loss = 0.012795777060091496\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=295, train_loss_step=0.0231, train_loss_epoch=0.0128]Epoch 300: Train Loss = 0.023114681243896484\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=295, train_loss_step=0.0152, train_loss_epoch=0.0231]Epoch 301: Train Loss = 0.015196001157164574\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=295, train_loss_step=0.0136, train_loss_epoch=0.0152]Epoch 302: Train Loss = 0.013579552993178368\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=295, train_loss_step=0.0167, train_loss_epoch=0.0136]Epoch 303: Train Loss = 0.01668810099363327\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=295, train_loss_step=0.0208, train_loss_epoch=0.0167]Epoch 304: Train Loss = 0.020770469680428505\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=295, train_loss_step=0.0147, train_loss_epoch=0.0208]Epoch 305: Train Loss = 0.01466303039342165\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=295, train_loss_step=0.0144, train_loss_epoch=0.0147]Epoch 306: Train Loss = 0.014356684871017933\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=295, train_loss_step=0.0142, train_loss_epoch=0.0144]Epoch 307: Train Loss = 0.014247201383113861\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=295, train_loss_step=0.0144, train_loss_epoch=0.0142]Epoch 308: Train Loss = 0.014393803663551807\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=295, train_loss_step=0.0147, train_loss_epoch=0.0144]Epoch 309: Train Loss = 0.014712749049067497\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=295, train_loss_step=0.0149, train_loss_epoch=0.0147]Epoch 310: Train Loss = 0.014860500581562519\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=295, train_loss_step=0.0174, train_loss_epoch=0.0149]Epoch 311: Train Loss = 0.01738705299794674\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0174]Epoch 312: Train Loss = 0.012583647854626179\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=295, train_loss_step=0.0116, train_loss_epoch=0.0126]Epoch 313: Train Loss = 0.011625084094703197\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.0116] Epoch 314: Train Loss = 0.013003649190068245\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=295, train_loss_step=0.0122, train_loss_epoch=0.013]Epoch 315: Train Loss = 0.012161663733422756\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=295, train_loss_step=0.0159, train_loss_epoch=0.0122]Epoch 316: Train Loss = 0.01594601757824421\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0159]Epoch 317: Train Loss = 0.012572511099278927\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=295, train_loss_step=0.011, train_loss_epoch=0.0126] Epoch 318: Train Loss = 0.011038152500987053\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.011]Epoch 319: Train Loss = 0.012583076022565365\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.0126]Epoch 320: Train Loss = 0.013467470183968544\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.0135]Epoch 321: Train Loss = 0.013548805378377438\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=295, train_loss_step=0.0118, train_loss_epoch=0.0135]Epoch 322: Train Loss = 0.011848806403577328\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=295, train_loss_step=0.0123, train_loss_epoch=0.0118]Epoch 323: Train Loss = 0.012269091792404652\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=295, train_loss_step=0.0127, train_loss_epoch=0.0123]Epoch 324: Train Loss = 0.012712948955595493\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s, v_num=295, train_loss_step=0.0187, train_loss_epoch=0.0127]Epoch 325: Train Loss = 0.018688352778553963\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=295, train_loss_step=0.0119, train_loss_epoch=0.0187]Epoch 326: Train Loss = 0.011863182298839092\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=295, train_loss_step=0.0117, train_loss_epoch=0.0119]Epoch 327: Train Loss = 0.01173157524317503\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=295, train_loss_step=0.0138, train_loss_epoch=0.0117]Epoch 328: Train Loss = 0.01380802970379591\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=295, train_loss_step=0.0116, train_loss_epoch=0.0138]Epoch 329: Train Loss = 0.011593461968004704\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=295, train_loss_step=0.0108, train_loss_epoch=0.0116]Epoch 330: Train Loss = 0.010750076733529568\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=295, train_loss_step=0.0109, train_loss_epoch=0.0108]Epoch 331: Train Loss = 0.010931901633739471\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.0109]Epoch 332: Train Loss = 0.012106780894100666\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=295, train_loss_step=0.0188, train_loss_epoch=0.0121]Epoch 333: Train Loss = 0.018788473680615425\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=295, train_loss_step=0.00916, train_loss_epoch=0.0188]Epoch 334: Train Loss = 0.009164564311504364\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=295, train_loss_step=0.0143, train_loss_epoch=0.00916] Epoch 335: Train Loss = 0.014319551177322865\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=295, train_loss_step=0.0116, train_loss_epoch=0.0143] Epoch 336: Train Loss = 0.011556059122085571\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.0116]Epoch 337: Train Loss = 0.013348468579351902\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0133]Epoch 338: Train Loss = 0.012871124781668186\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=295, train_loss_step=0.0127, train_loss_epoch=0.0129]Epoch 339: Train Loss = 0.012663298286497593\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0127]Epoch 340: Train Loss = 0.012856965884566307\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=295, train_loss_step=0.0089, train_loss_epoch=0.0129]Epoch 341: Train Loss = 0.008897373452782631\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=295, train_loss_step=0.0125, train_loss_epoch=0.0089]Epoch 342: Train Loss = 0.012452872470021248\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=295, train_loss_step=0.0164, train_loss_epoch=0.0125]Epoch 343: Train Loss = 0.016392290592193604\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=295, train_loss_step=0.0134, train_loss_epoch=0.0164]Epoch 344: Train Loss = 0.013417872600257397\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 10.63it/s, v_num=295, train_loss_step=0.0108, train_loss_epoch=0.0134]Epoch 345: Train Loss = 0.010842411778867245\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=295, train_loss_step=0.0138, train_loss_epoch=0.0108]Epoch 346: Train Loss = 0.013827330432832241\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=295, train_loss_step=0.0106, train_loss_epoch=0.0138]Epoch 347: Train Loss = 0.010557194240391254\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=295, train_loss_step=0.0145, train_loss_epoch=0.0106]Epoch 348: Train Loss = 0.01445521879941225\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=295, train_loss_step=0.00909, train_loss_epoch=0.0145]Epoch 349: Train Loss = 0.00909064244478941\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s, v_num=295, train_loss_step=0.0106, train_loss_epoch=0.00909] Epoch 350: Train Loss = 0.010626574046909809\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=295, train_loss_step=0.0111, train_loss_epoch=0.0106] Epoch 351: Train Loss = 0.011060602031648159\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=295, train_loss_step=0.0145, train_loss_epoch=0.0111]Epoch 352: Train Loss = 0.014463127590715885\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=295, train_loss_step=0.0113, train_loss_epoch=0.0145]Epoch 353: Train Loss = 0.011315605603158474\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s, v_num=295, train_loss_step=0.0126, train_loss_epoch=0.0113]Epoch 354: Train Loss = 0.012638191692531109\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=295, train_loss_step=0.0114, train_loss_epoch=0.0126]Epoch 355: Train Loss = 0.011385793797671795\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=295, train_loss_step=0.011, train_loss_epoch=0.0114] Epoch 356: Train Loss = 0.010993406176567078\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=295, train_loss_step=0.0132, train_loss_epoch=0.011]Epoch 357: Train Loss = 0.013157477602362633\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=295, train_loss_step=0.0122, train_loss_epoch=0.0132]Epoch 358: Train Loss = 0.012244080193340778\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.0122] Epoch 359: Train Loss = 0.012986375018954277\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=295, train_loss_step=0.0131, train_loss_epoch=0.013]Epoch 360: Train Loss = 0.013098130002617836\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s, v_num=295, train_loss_step=0.0137, train_loss_epoch=0.0131]Epoch 361: Train Loss = 0.01373344473540783\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=295, train_loss_step=0.011, train_loss_epoch=0.0137] Epoch 362: Train Loss = 0.011034038849174976\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=295, train_loss_step=0.0169, train_loss_epoch=0.011]Epoch 363: Train Loss = 0.016885699704289436\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=295, train_loss_step=0.00995, train_loss_epoch=0.0169]Epoch 364: Train Loss = 0.009951276704668999\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=295, train_loss_step=0.0134, train_loss_epoch=0.00995] Epoch 365: Train Loss = 0.013358576223254204\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=295, train_loss_step=0.0114, train_loss_epoch=0.0134] Epoch 366: Train Loss = 0.011371140368282795\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=295, train_loss_step=0.00863, train_loss_epoch=0.0114]Epoch 367: Train Loss = 0.008629271760582924\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=295, train_loss_step=0.0142, train_loss_epoch=0.00863] Epoch 368: Train Loss = 0.014224621467292309\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=295, train_loss_step=0.0164, train_loss_epoch=0.0142] Epoch 369: Train Loss = 0.016407659277319908\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=295, train_loss_step=0.0116, train_loss_epoch=0.0164]Epoch 370: Train Loss = 0.011637910269200802\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=295, train_loss_step=0.0101, train_loss_epoch=0.0116]Epoch 371: Train Loss = 0.010075702331960201\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=295, train_loss_step=0.0132, train_loss_epoch=0.0101]Epoch 372: Train Loss = 0.013176016509532928\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=295, train_loss_step=0.0102, train_loss_epoch=0.0132]Epoch 373: Train Loss = 0.010242846794426441\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=295, train_loss_step=0.0143, train_loss_epoch=0.0102]Epoch 374: Train Loss = 0.014335504733026028\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=295, train_loss_step=0.0163, train_loss_epoch=0.0143]Epoch 375: Train Loss = 0.016279131174087524\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=295, train_loss_step=0.00962, train_loss_epoch=0.0163]Epoch 376: Train Loss = 0.009624884463846684\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=295, train_loss_step=0.0134, train_loss_epoch=0.00962] Epoch 377: Train Loss = 0.013406516052782536\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=295, train_loss_step=0.0105, train_loss_epoch=0.0134] Epoch 378: Train Loss = 0.010459758341312408\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.0105]Epoch 379: Train Loss = 0.01214422658085823\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s, v_num=295, train_loss_step=0.0112, train_loss_epoch=0.0121]Epoch 380: Train Loss = 0.011178053915500641\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=295, train_loss_step=0.0111, train_loss_epoch=0.0112]Epoch 381: Train Loss = 0.011066274717450142\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=295, train_loss_step=0.0141, train_loss_epoch=0.0111]Epoch 382: Train Loss = 0.014087921008467674\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=295, train_loss_step=0.0144, train_loss_epoch=0.0141]Epoch 383: Train Loss = 0.014408028684556484\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=295, train_loss_step=0.0139, train_loss_epoch=0.0144]Epoch 384: Train Loss = 0.013927878811955452\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=295, train_loss_step=0.0173, train_loss_epoch=0.0139]Epoch 385: Train Loss = 0.01729775406420231\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=295, train_loss_step=0.0147, train_loss_epoch=0.0173]Epoch 386: Train Loss = 0.014658598229289055\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=295, train_loss_step=0.0158, train_loss_epoch=0.0147]Epoch 387: Train Loss = 0.015789182856678963\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.0158]Epoch 388: Train Loss = 0.01028558798134327\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=295, train_loss_step=0.012, train_loss_epoch=0.0103] Epoch 389: Train Loss = 0.01201349962502718\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=295, train_loss_step=0.0134, train_loss_epoch=0.012]Epoch 390: Train Loss = 0.013439944013953209\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=295, train_loss_step=0.0113, train_loss_epoch=0.0134]Epoch 391: Train Loss = 0.011305402033030987\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=295, train_loss_step=0.0108, train_loss_epoch=0.0113]Epoch 392: Train Loss = 0.010773895308375359\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=295, train_loss_step=0.0117, train_loss_epoch=0.0108]Epoch 393: Train Loss = 0.011670240201056004\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=295, train_loss_step=0.0132, train_loss_epoch=0.0117]Epoch 394: Train Loss = 0.01324999425560236\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=295, train_loss_step=0.0163, train_loss_epoch=0.0132]Epoch 395: Train Loss = 0.01625673472881317\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=295, train_loss_step=0.0145, train_loss_epoch=0.0163]Epoch 396: Train Loss = 0.01445480901747942\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=295, train_loss_step=0.0125, train_loss_epoch=0.0145]Epoch 397: Train Loss = 0.012460438534617424\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=295, train_loss_step=0.0151, train_loss_epoch=0.0125]Epoch 398: Train Loss = 0.015138152055442333\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=295, train_loss_step=0.0135, train_loss_epoch=0.0151]Epoch 399: Train Loss = 0.013478314504027367\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=295, train_loss_step=0.0123, train_loss_epoch=0.0135]Epoch 400: Train Loss = 0.012306300923228264\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.0123]Epoch 401: Train Loss = 0.010253374464809895\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=295, train_loss_step=0.0107, train_loss_epoch=0.0103]Epoch 402: Train Loss = 0.0107142748311162\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=295, train_loss_step=0.0132, train_loss_epoch=0.0107]Epoch 403: Train Loss = 0.013243808411061764\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=295, train_loss_step=0.00914, train_loss_epoch=0.0132]Epoch 404: Train Loss = 0.009135891683399677\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=295, train_loss_step=0.014, train_loss_epoch=0.00914]  Epoch 405: Train Loss = 0.013998244889080524\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=295, train_loss_step=0.00925, train_loss_epoch=0.014]Epoch 406: Train Loss = 0.009248346090316772\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=295, train_loss_step=0.0125, train_loss_epoch=0.00925] Epoch 407: Train Loss = 0.012468204833567142\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=295, train_loss_step=0.011, train_loss_epoch=0.0125]  Epoch 408: Train Loss = 0.011023678816854954\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.011]Epoch 409: Train Loss = 0.013340643607079983\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=295, train_loss_step=0.0125, train_loss_epoch=0.0133]Epoch 410: Train Loss = 0.012545156292617321\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=295, train_loss_step=0.0106, train_loss_epoch=0.0125]Epoch 411: Train Loss = 0.010594836436212063\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=295, train_loss_step=0.0116, train_loss_epoch=0.0106]Epoch 412: Train Loss = 0.011602993123233318\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=295, train_loss_step=0.0121, train_loss_epoch=0.0116]Epoch 413: Train Loss = 0.012083396315574646\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=295, train_loss_step=0.0105, train_loss_epoch=0.0121]Epoch 414: Train Loss = 0.010528923943638802\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s, v_num=295, train_loss_step=0.0108, train_loss_epoch=0.0105]Epoch 415: Train Loss = 0.010827640071511269\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=295, train_loss_step=0.0158, train_loss_epoch=0.0108]Epoch 416: Train Loss = 0.015769081190228462\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.0158] Epoch 417: Train Loss = 0.013049199245870113\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=295, train_loss_step=0.0106, train_loss_epoch=0.013]Epoch 418: Train Loss = 0.010551219806075096\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=295, train_loss_step=0.0145, train_loss_epoch=0.0106]Epoch 419: Train Loss = 0.014532936736941338\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=295, train_loss_step=0.0122, train_loss_epoch=0.0145]Epoch 420: Train Loss = 0.01217211876064539\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=295, train_loss_step=0.0138, train_loss_epoch=0.0122]Epoch 421: Train Loss = 0.013834432698786259\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=295, train_loss_step=0.0124, train_loss_epoch=0.0138]Epoch 422: Train Loss = 0.012433645315468311\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=295, train_loss_step=0.0112, train_loss_epoch=0.0124]Epoch 423: Train Loss = 0.011156427673995495\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=295, train_loss_step=0.0149, train_loss_epoch=0.0112]Epoch 424: Train Loss = 0.014933251775801182\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=295, train_loss_step=0.00963, train_loss_epoch=0.0149]Epoch 425: Train Loss = 0.009628159925341606\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=295, train_loss_step=0.0142, train_loss_epoch=0.00963] Epoch 426: Train Loss = 0.014237958006560802\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=295, train_loss_step=0.00964, train_loss_epoch=0.0142]Epoch 427: Train Loss = 0.009640218690037727\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=295, train_loss_step=0.00966, train_loss_epoch=0.00964]Epoch 428: Train Loss = 0.00965801440179348\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=295, train_loss_step=0.0101, train_loss_epoch=0.00966] Epoch 429: Train Loss = 0.010144121944904327\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=295, train_loss_step=0.0132, train_loss_epoch=0.0101] Epoch 430: Train Loss = 0.01319480687379837\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.0132]Epoch 431: Train Loss = 0.010252128355205059\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=295, train_loss_step=0.0138, train_loss_epoch=0.0103]Epoch 432: Train Loss = 0.013833875767886639\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.0138]Epoch 433: Train Loss = 0.010301864705979824\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=295, train_loss_step=0.0123, train_loss_epoch=0.0103]Epoch 434: Train Loss = 0.012323230504989624\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=295, train_loss_step=0.0106, train_loss_epoch=0.0123]Epoch 435: Train Loss = 0.010580281727015972\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=295, train_loss_step=0.0162, train_loss_epoch=0.0106]Epoch 436: Train Loss = 0.016215529292821884\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=295, train_loss_step=0.0105, train_loss_epoch=0.0162]Epoch 437: Train Loss = 0.010452000424265862\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=295, train_loss_step=0.0151, train_loss_epoch=0.0105]Epoch 438: Train Loss = 0.015115032903850079\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=295, train_loss_step=0.0139, train_loss_epoch=0.0151]Epoch 439: Train Loss = 0.01386627834290266\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=295, train_loss_step=0.0105, train_loss_epoch=0.0139]Epoch 440: Train Loss = 0.010499900206923485\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=295, train_loss_step=0.0112, train_loss_epoch=0.0105]Epoch 441: Train Loss = 0.011205049231648445\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=295, train_loss_step=0.0101, train_loss_epoch=0.0112]Epoch 442: Train Loss = 0.010125408880412579\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=295, train_loss_step=0.00881, train_loss_epoch=0.0101]Epoch 443: Train Loss = 0.00880837719887495\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.00881] Epoch 444: Train Loss = 0.013282558880746365\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=295, train_loss_step=0.0153, train_loss_epoch=0.0133] Epoch 445: Train Loss = 0.015315954573452473\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0153]Epoch 446: Train Loss = 0.012859814800322056\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=295, train_loss_step=0.00997, train_loss_epoch=0.0129]Epoch 447: Train Loss = 0.009974650107324123\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s, v_num=295, train_loss_step=0.0148, train_loss_epoch=0.00997] Epoch 448: Train Loss = 0.014821241609752178\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=295, train_loss_step=0.00996, train_loss_epoch=0.0148]Epoch 449: Train Loss = 0.009956912137567997\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=295, train_loss_step=0.0108, train_loss_epoch=0.00996] Epoch 450: Train Loss = 0.010763890109956264\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=295, train_loss_step=0.0117, train_loss_epoch=0.0108] Epoch 451: Train Loss = 0.011735894717276096\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=295, train_loss_step=0.0137, train_loss_epoch=0.0117]Epoch 452: Train Loss = 0.01366840023547411\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=295, train_loss_step=0.0101, train_loss_epoch=0.0137]Epoch 453: Train Loss = 0.01014152355492115\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=295, train_loss_step=0.0107, train_loss_epoch=0.0101]Epoch 454: Train Loss = 0.010706047527492046\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=295, train_loss_step=0.011, train_loss_epoch=0.0107] Epoch 455: Train Loss = 0.010998097248375416\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s, v_num=295, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 456: Train Loss = 0.012482292018830776\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=295, train_loss_step=0.0163, train_loss_epoch=0.0125]Epoch 457: Train Loss = 0.016301674768328667\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=295, train_loss_step=0.0163, train_loss_epoch=0.0163]Epoch 458: Train Loss = 0.016278116032481194\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=295, train_loss_step=0.0155, train_loss_epoch=0.0163]Epoch 459: Train Loss = 0.015475010499358177\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=295, train_loss_step=0.0104, train_loss_epoch=0.0155]Epoch 460: Train Loss = 0.010355097241699696\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s, v_num=295, train_loss_step=0.00735, train_loss_epoch=0.0104]Epoch 461: Train Loss = 0.007353152614086866\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=295, train_loss_step=0.0109, train_loss_epoch=0.00735] Epoch 462: Train Loss = 0.010949480347335339\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=295, train_loss_step=0.0118, train_loss_epoch=0.0109] Epoch 463: Train Loss = 0.011846805922687054\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s, v_num=295, train_loss_step=0.0131, train_loss_epoch=0.0118]Epoch 464: Train Loss = 0.013079168274998665\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, v_num=295, train_loss_step=0.0128, train_loss_epoch=0.0131]Epoch 465: Train Loss = 0.012835373170673847\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=295, train_loss_step=0.0129, train_loss_epoch=0.0128]Epoch 466: Train Loss = 0.012941901572048664\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=295, train_loss_step=0.0181, train_loss_epoch=0.0129]Epoch 467: Train Loss = 0.018100986257195473\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=295, train_loss_step=0.0124, train_loss_epoch=0.0181]Epoch 468: Train Loss = 0.012377220205962658\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=295, train_loss_step=0.00993, train_loss_epoch=0.0124]Epoch 469: Train Loss = 0.009926320053637028\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=295, train_loss_step=0.0105, train_loss_epoch=0.00993] Epoch 470: Train Loss = 0.010518653318285942\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=295, train_loss_step=0.0205, train_loss_epoch=0.0105] Epoch 471: Train Loss = 0.020471369847655296\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s, v_num=295, train_loss_step=0.0133, train_loss_epoch=0.0205]Epoch 472: Train Loss = 0.013284014537930489\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=295, train_loss_step=0.0125, train_loss_epoch=0.0133]Epoch 473: Train Loss = 0.012480095028877258\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=295, train_loss_step=0.0134, train_loss_epoch=0.0125]Epoch 474: Train Loss = 0.01342091802507639\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=295, train_loss_step=0.0147, train_loss_epoch=0.0134]Epoch 475: Train Loss = 0.014714695513248444\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=295, train_loss_step=0.0118, train_loss_epoch=0.0147]Epoch 476: Train Loss = 0.011773026548326015\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=295, train_loss_step=0.013, train_loss_epoch=0.0118] Epoch 477: Train Loss = 0.013001857325434685\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=295, train_loss_step=0.0136, train_loss_epoch=0.013]Epoch 478: Train Loss = 0.013591451570391655\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 11.14it/s, v_num=295, train_loss_step=0.0114, train_loss_epoch=0.0136]Epoch 479: Train Loss = 0.011383849196135998\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=295, train_loss_step=0.0171, train_loss_epoch=0.0114]Epoch 480: Train Loss = 0.017126187682151794\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=295, train_loss_step=0.0163, train_loss_epoch=0.0171]Epoch 481: Train Loss = 0.016333257779479027\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=295, train_loss_step=0.0116, train_loss_epoch=0.0163]Epoch 482: Train Loss = 0.011631217785179615\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=295, train_loss_step=0.0106, train_loss_epoch=0.0116]Epoch 483: Train Loss = 0.010592098347842693\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=295, train_loss_step=0.0143, train_loss_epoch=0.0106]Epoch 484: Train Loss = 0.014300157316029072\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=295, train_loss_step=0.0102, train_loss_epoch=0.0143]Epoch 485: Train Loss = 0.010212438181042671\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=295, train_loss_step=0.0183, train_loss_epoch=0.0102]Epoch 486: Train Loss = 0.01829376257956028\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 11.06it/s, v_num=295, train_loss_step=0.0118, train_loss_epoch=0.0183]Epoch 487: Train Loss = 0.01175613235682249\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=295, train_loss_step=0.0168, train_loss_epoch=0.0118]Epoch 488: Train Loss = 0.016827372834086418\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=295, train_loss_step=0.0125, train_loss_epoch=0.0168]Epoch 489: Train Loss = 0.012518494389951229\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=295, train_loss_step=0.0122, train_loss_epoch=0.0125]Epoch 490: Train Loss = 0.012233857996761799\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=295, train_loss_step=0.0109, train_loss_epoch=0.0122]Epoch 491: Train Loss = 0.010933727957308292\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=295, train_loss_step=0.0116, train_loss_epoch=0.0109]Epoch 492: Train Loss = 0.01158443745225668\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=295, train_loss_step=0.0113, train_loss_epoch=0.0116]Epoch 493: Train Loss = 0.01129499264061451\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=295, train_loss_step=0.0103, train_loss_epoch=0.0113]Epoch 494: Train Loss = 0.010277697816491127\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s, v_num=295, train_loss_step=0.0134, train_loss_epoch=0.0103]Epoch 495: Train Loss = 0.01340825017541647\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=295, train_loss_step=0.0117, train_loss_epoch=0.0134]Epoch 496: Train Loss = 0.011700707487761974\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=295, train_loss_step=0.00974, train_loss_epoch=0.0117]Epoch 497: Train Loss = 0.009735679253935814\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=295, train_loss_step=0.014, train_loss_epoch=0.00974]  Epoch 498: Train Loss = 0.013980352319777012\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=295, train_loss_step=0.0158, train_loss_epoch=0.014] Epoch 499: Train Loss = 0.015772422775626183\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=295, train_loss_step=0.0158, train_loss_epoch=0.0158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=295, train_loss_step=0.0158, train_loss_epoch=0.0158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 2: from 2010-06-30 00:00:00 to 2022-07-11 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=298, train_loss_step=0.0259]Epoch 0: Train Loss = 0.025874072685837746\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=298, train_loss_step=0.0372, train_loss_epoch=0.0259]Epoch 1: Train Loss = 0.03724882751703262\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=298, train_loss_step=0.0296, train_loss_epoch=0.0372]Epoch 2: Train Loss = 0.029567137360572815\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=298, train_loss_step=0.0246, train_loss_epoch=0.0296]Epoch 3: Train Loss = 0.0245804525911808\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=298, train_loss_step=0.0171, train_loss_epoch=0.0246]Epoch 4: Train Loss = 0.01708223856985569\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=298, train_loss_step=0.0217, train_loss_epoch=0.0171]Epoch 5: Train Loss = 0.02166786603629589\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=298, train_loss_step=0.0237, train_loss_epoch=0.0217]Epoch 6: Train Loss = 0.023736074566841125\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=298, train_loss_step=0.0147, train_loss_epoch=0.0237]Epoch 7: Train Loss = 0.014717304147779942\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=298, train_loss_step=0.0156, train_loss_epoch=0.0147]Epoch 8: Train Loss = 0.015559700317680836\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=298, train_loss_step=0.0156, train_loss_epoch=0.0156]Epoch 9: Train Loss = 0.015572532080113888\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=298, train_loss_step=0.0155, train_loss_epoch=0.0156]Epoch 10: Train Loss = 0.015505190007388592\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=298, train_loss_step=0.0135, train_loss_epoch=0.0155]Epoch 11: Train Loss = 0.01353523787111044\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=298, train_loss_step=0.0158, train_loss_epoch=0.0135]Epoch 12: Train Loss = 0.015841834247112274\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, v_num=298, train_loss_step=0.0211, train_loss_epoch=0.0158]Epoch 13: Train Loss = 0.021140577271580696\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=298, train_loss_step=0.0153, train_loss_epoch=0.0211]Epoch 14: Train Loss = 0.015256958082318306\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=298, train_loss_step=0.0179, train_loss_epoch=0.0153]Epoch 15: Train Loss = 0.017863841727375984\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=298, train_loss_step=0.0157, train_loss_epoch=0.0179]Epoch 16: Train Loss = 0.015708396211266518\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=298, train_loss_step=0.0182, train_loss_epoch=0.0157]Epoch 17: Train Loss = 0.018199549987912178\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 11.06it/s, v_num=298, train_loss_step=0.024, train_loss_epoch=0.0182] Epoch 18: Train Loss = 0.023961404338479042\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=298, train_loss_step=0.0144, train_loss_epoch=0.024]Epoch 19: Train Loss = 0.01437732856720686\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=298, train_loss_step=0.0166, train_loss_epoch=0.0144]Epoch 20: Train Loss = 0.01655416004359722\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=298, train_loss_step=0.0216, train_loss_epoch=0.0166]Epoch 21: Train Loss = 0.021603435277938843\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=298, train_loss_step=0.0167, train_loss_epoch=0.0216]Epoch 22: Train Loss = 0.016650870442390442\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=298, train_loss_step=0.0214, train_loss_epoch=0.0167]Epoch 23: Train Loss = 0.021413980051875114\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=298, train_loss_step=0.015, train_loss_epoch=0.0214] Epoch 24: Train Loss = 0.014977644197642803\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.015]Epoch 25: Train Loss = 0.011558100581169128\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=298, train_loss_step=0.00993, train_loss_epoch=0.0116]Epoch 26: Train Loss = 0.009927275590598583\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=298, train_loss_step=0.0152, train_loss_epoch=0.00993] Epoch 27: Train Loss = 0.015223083086311817\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, v_num=298, train_loss_step=0.0124, train_loss_epoch=0.0152] Epoch 28: Train Loss = 0.012368768453598022\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s, v_num=298, train_loss_step=0.0111, train_loss_epoch=0.0124]Epoch 29: Train Loss = 0.01112428493797779\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=298, train_loss_step=0.0144, train_loss_epoch=0.0111]Epoch 30: Train Loss = 0.014407818205654621\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=298, train_loss_step=0.0195, train_loss_epoch=0.0144]Epoch 31: Train Loss = 0.019458532333374023\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=298, train_loss_step=0.0171, train_loss_epoch=0.0195]Epoch 32: Train Loss = 0.01711651310324669\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=298, train_loss_step=0.0122, train_loss_epoch=0.0171]Epoch 33: Train Loss = 0.0121730612590909\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0122]Epoch 34: Train Loss = 0.012072599492967129\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 13.77it/s, v_num=298, train_loss_step=0.0101, train_loss_epoch=0.0121]Epoch 35: Train Loss = 0.01012835931032896\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=298, train_loss_step=0.0149, train_loss_epoch=0.0101]Epoch 36: Train Loss = 0.014927463605999947\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=298, train_loss_step=0.0138, train_loss_epoch=0.0149]Epoch 37: Train Loss = 0.013761441223323345\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=298, train_loss_step=0.00862, train_loss_epoch=0.0138]Epoch 38: Train Loss = 0.008617487736046314\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=298, train_loss_step=0.0113, train_loss_epoch=0.00862] Epoch 39: Train Loss = 0.01132721547037363\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=298, train_loss_step=0.0122, train_loss_epoch=0.0113] Epoch 40: Train Loss = 0.012157902121543884\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=298, train_loss_step=0.0149, train_loss_epoch=0.0122]Epoch 41: Train Loss = 0.014915731735527515\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=298, train_loss_step=0.0106, train_loss_epoch=0.0149]Epoch 42: Train Loss = 0.010582090355455875\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=298, train_loss_step=0.0137, train_loss_epoch=0.0106]Epoch 43: Train Loss = 0.013669505715370178\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s, v_num=298, train_loss_step=0.0131, train_loss_epoch=0.0137]Epoch 44: Train Loss = 0.013102291151881218\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=298, train_loss_step=0.0156, train_loss_epoch=0.0131]Epoch 45: Train Loss = 0.015614988282322884\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=298, train_loss_step=0.0111, train_loss_epoch=0.0156]Epoch 46: Train Loss = 0.011084815487265587\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=298, train_loss_step=0.0115, train_loss_epoch=0.0111]Epoch 47: Train Loss = 0.011527723632752895\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=298, train_loss_step=0.0112, train_loss_epoch=0.0115]Epoch 48: Train Loss = 0.01124339085072279\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0112] Epoch 49: Train Loss = 0.01203396450728178\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=298, train_loss_step=0.0176, train_loss_epoch=0.012]Epoch 50: Train Loss = 0.017642825841903687\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s, v_num=298, train_loss_step=0.0127, train_loss_epoch=0.0176]Epoch 51: Train Loss = 0.012686316855251789\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=298, train_loss_step=0.0101, train_loss_epoch=0.0127]Epoch 52: Train Loss = 0.01009809784591198\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=298, train_loss_step=0.0161, train_loss_epoch=0.0101]Epoch 53: Train Loss = 0.016079658642411232\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=298, train_loss_step=0.0164, train_loss_epoch=0.0161]Epoch 54: Train Loss = 0.016389945521950722\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=298, train_loss_step=0.0148, train_loss_epoch=0.0164]Epoch 55: Train Loss = 0.014780848287045956\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=298, train_loss_step=0.0127, train_loss_epoch=0.0148]Epoch 56: Train Loss = 0.012683579698204994\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=298, train_loss_step=0.0102, train_loss_epoch=0.0127]Epoch 57: Train Loss = 0.010209374129772186\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=298, train_loss_step=0.0195, train_loss_epoch=0.0102]Epoch 58: Train Loss = 0.019451918080449104\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 12.53it/s, v_num=298, train_loss_step=0.0147, train_loss_epoch=0.0195]Epoch 59: Train Loss = 0.0146877970546484\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s, v_num=298, train_loss_step=0.0188, train_loss_epoch=0.0147]Epoch 60: Train Loss = 0.018753085285425186\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=298, train_loss_step=0.0139, train_loss_epoch=0.0188]Epoch 61: Train Loss = 0.013898712582886219\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=298, train_loss_step=0.0149, train_loss_epoch=0.0139]Epoch 62: Train Loss = 0.014860115014016628\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=298, train_loss_step=0.0117, train_loss_epoch=0.0149]Epoch 63: Train Loss = 0.011715336702764034\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=298, train_loss_step=0.0187, train_loss_epoch=0.0117]Epoch 64: Train Loss = 0.018714888021349907\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=298, train_loss_step=0.0145, train_loss_epoch=0.0187]Epoch 65: Train Loss = 0.014467135071754456\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s, v_num=298, train_loss_step=0.0126, train_loss_epoch=0.0145]Epoch 66: Train Loss = 0.012646184302866459\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=298, train_loss_step=0.0155, train_loss_epoch=0.0126]Epoch 67: Train Loss = 0.015536674298346043\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=298, train_loss_step=0.0139, train_loss_epoch=0.0155]Epoch 68: Train Loss = 0.013934007845818996\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=298, train_loss_step=0.0158, train_loss_epoch=0.0139]Epoch 69: Train Loss = 0.015805566683411598\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0158] Epoch 70: Train Loss = 0.01198215689510107\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=298, train_loss_step=0.0151, train_loss_epoch=0.012]Epoch 71: Train Loss = 0.015142994932830334\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.0151]Epoch 72: Train Loss = 0.011592395603656769\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=298, train_loss_step=0.0145, train_loss_epoch=0.0116]Epoch 73: Train Loss = 0.01446892973035574\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=298, train_loss_step=0.0199, train_loss_epoch=0.0145]Epoch 74: Train Loss = 0.01994885876774788\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.0199]Epoch 75: Train Loss = 0.011635401286184788\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=298, train_loss_step=0.0219, train_loss_epoch=0.0116]Epoch 76: Train Loss = 0.021886590868234634\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=298, train_loss_step=0.00908, train_loss_epoch=0.0219]Epoch 77: Train Loss = 0.009082111530005932\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=298, train_loss_step=0.0117, train_loss_epoch=0.00908] Epoch 78: Train Loss = 0.011712265200912952\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=298, train_loss_step=0.0117, train_loss_epoch=0.0117] Epoch 79: Train Loss = 0.011676189489662647\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.0117]Epoch 80: Train Loss = 0.012860759161412716\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 11.68it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0129]Epoch 81: Train Loss = 0.012060478329658508\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=298, train_loss_step=0.0112, train_loss_epoch=0.0121]Epoch 82: Train Loss = 0.01123176421970129\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=298, train_loss_step=0.0111, train_loss_epoch=0.0112]Epoch 83: Train Loss = 0.011134198866784573\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 10.63it/s, v_num=298, train_loss_step=0.0138, train_loss_epoch=0.0111]Epoch 84: Train Loss = 0.013779225759208202\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=298, train_loss_step=0.0195, train_loss_epoch=0.0138]Epoch 85: Train Loss = 0.019488181918859482\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=298, train_loss_step=0.0131, train_loss_epoch=0.0195]Epoch 86: Train Loss = 0.013106021098792553\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=298, train_loss_step=0.0108, train_loss_epoch=0.0131]Epoch 87: Train Loss = 0.010785065591335297\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=298, train_loss_step=0.0185, train_loss_epoch=0.0108]Epoch 88: Train Loss = 0.01851476915180683\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s, v_num=298, train_loss_step=0.0152, train_loss_epoch=0.0185]Epoch 89: Train Loss = 0.015155920758843422\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=298, train_loss_step=0.013, train_loss_epoch=0.0152] Epoch 90: Train Loss = 0.013018467463552952\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 11.50it/s, v_num=298, train_loss_step=0.0122, train_loss_epoch=0.013]Epoch 91: Train Loss = 0.012232412584125996\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=298, train_loss_step=0.0128, train_loss_epoch=0.0122]Epoch 92: Train Loss = 0.01282681617885828\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0128] Epoch 93: Train Loss = 0.011986816301941872\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s, v_num=298, train_loss_step=0.0143, train_loss_epoch=0.012]Epoch 94: Train Loss = 0.014336779713630676\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=298, train_loss_step=0.0142, train_loss_epoch=0.0143]Epoch 95: Train Loss = 0.014195255935192108\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=298, train_loss_step=0.0114, train_loss_epoch=0.0142]Epoch 96: Train Loss = 0.011371609754860401\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.0114]Epoch 97: Train Loss = 0.01246807910501957\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=298, train_loss_step=0.0153, train_loss_epoch=0.0125]Epoch 98: Train Loss = 0.015340017154812813\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 13.55it/s, v_num=298, train_loss_step=0.0109, train_loss_epoch=0.0153]Epoch 99: Train Loss = 0.010941678658127785\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 16.02it/s, v_num=298, train_loss_step=0.00967, train_loss_epoch=0.0109]Epoch 100: Train Loss = 0.009674429893493652\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 13.45it/s, v_num=298, train_loss_step=0.0174, train_loss_epoch=0.00967] Epoch 101: Train Loss = 0.017387831583619118\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=298, train_loss_step=0.0126, train_loss_epoch=0.0174] Epoch 102: Train Loss = 0.012640262953937054\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s, v_num=298, train_loss_step=0.00968, train_loss_epoch=0.0126]Epoch 103: Train Loss = 0.009684030897915363\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=298, train_loss_step=0.0134, train_loss_epoch=0.00968] Epoch 104: Train Loss = 0.013442720286548138\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=298, train_loss_step=0.0139, train_loss_epoch=0.0134] Epoch 105: Train Loss = 0.013861305080354214\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0139] Epoch 106: Train Loss = 0.011964915320277214\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.012]Epoch 107: Train Loss = 0.011933663859963417\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=298, train_loss_step=0.0123, train_loss_epoch=0.0119]Epoch 108: Train Loss = 0.012280854396522045\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0123] Epoch 109: Train Loss = 0.012042897753417492\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s, v_num=298, train_loss_step=0.0102, train_loss_epoch=0.012]Epoch 110: Train Loss = 0.010214556939899921\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s, v_num=298, train_loss_step=0.00978, train_loss_epoch=0.0102]Epoch 111: Train Loss = 0.00978016946464777\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=298, train_loss_step=0.0138, train_loss_epoch=0.00978] Epoch 112: Train Loss = 0.013817853294312954\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=298, train_loss_step=0.00992, train_loss_epoch=0.0138]Epoch 113: Train Loss = 0.009923421777784824\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s, v_num=298, train_loss_step=0.0117, train_loss_epoch=0.00992] Epoch 114: Train Loss = 0.011655355803668499\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0117]  Epoch 115: Train Loss = 0.012005790136754513\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=298, train_loss_step=0.0138, train_loss_epoch=0.012]Epoch 116: Train Loss = 0.013775952160358429\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=298, train_loss_step=0.0144, train_loss_epoch=0.0138]Epoch 117: Train Loss = 0.014350076206028461\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=298, train_loss_step=0.0096, train_loss_epoch=0.0144]Epoch 118: Train Loss = 0.009598271921277046\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=298, train_loss_step=0.0151, train_loss_epoch=0.0096]Epoch 119: Train Loss = 0.01506892591714859\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=298, train_loss_step=0.0127, train_loss_epoch=0.0151]Epoch 120: Train Loss = 0.012674429453909397\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=298, train_loss_step=0.0104, train_loss_epoch=0.0127]Epoch 121: Train Loss = 0.010410038754343987\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=298, train_loss_step=0.0149, train_loss_epoch=0.0104]Epoch 122: Train Loss = 0.014907400123775005\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=298, train_loss_step=0.0109, train_loss_epoch=0.0149]Epoch 123: Train Loss = 0.0109182707965374\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=298, train_loss_step=0.0152, train_loss_epoch=0.0109]Epoch 124: Train Loss = 0.015246747992932796\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=298, train_loss_step=0.0117, train_loss_epoch=0.0152]Epoch 125: Train Loss = 0.011732925660908222\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=298, train_loss_step=0.0118, train_loss_epoch=0.0117]Epoch 126: Train Loss = 0.011751445010304451\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0118]Epoch 127: Train Loss = 0.01190599612891674\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=298, train_loss_step=0.0146, train_loss_epoch=0.0119]Epoch 128: Train Loss = 0.01459799986332655\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 11.27it/s, v_num=298, train_loss_step=0.0106, train_loss_epoch=0.0146]Epoch 129: Train Loss = 0.010630227625370026\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s, v_num=298, train_loss_step=0.0128, train_loss_epoch=0.0106]Epoch 130: Train Loss = 0.012819711118936539\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 11.59it/s, v_num=298, train_loss_step=0.0139, train_loss_epoch=0.0128]Epoch 131: Train Loss = 0.013898518867790699\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=298, train_loss_step=0.0147, train_loss_epoch=0.0139]Epoch 132: Train Loss = 0.014745115302503109\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.0147]Epoch 133: Train Loss = 0.01285656075924635\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=298, train_loss_step=0.0152, train_loss_epoch=0.0129]Epoch 134: Train Loss = 0.015163113363087177\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0152]Epoch 135: Train Loss = 0.011881612241268158\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=298, train_loss_step=0.0135, train_loss_epoch=0.0119]Epoch 136: Train Loss = 0.013451107777655125\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=298, train_loss_step=0.0101, train_loss_epoch=0.0135]Epoch 137: Train Loss = 0.010096543468534946\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=298, train_loss_step=0.0164, train_loss_epoch=0.0101]Epoch 138: Train Loss = 0.016407150775194168\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=298, train_loss_step=0.0123, train_loss_epoch=0.0164]Epoch 139: Train Loss = 0.012343931011855602\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=298, train_loss_step=0.0174, train_loss_epoch=0.0123]Epoch 140: Train Loss = 0.017401529476046562\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=298, train_loss_step=0.013, train_loss_epoch=0.0174] Epoch 141: Train Loss = 0.01302641723304987\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=298, train_loss_step=0.0147, train_loss_epoch=0.013]Epoch 142: Train Loss = 0.014742697589099407\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 10.45it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0147]Epoch 143: Train Loss = 0.011874581687152386\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.0119]Epoch 144: Train Loss = 0.01250851433724165\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=298, train_loss_step=0.0142, train_loss_epoch=0.0125]Epoch 145: Train Loss = 0.014168853871524334\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=298, train_loss_step=0.0131, train_loss_epoch=0.0142]Epoch 146: Train Loss = 0.013057662174105644\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=298, train_loss_step=0.0145, train_loss_epoch=0.0131]Epoch 147: Train Loss = 0.014467406086623669\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=298, train_loss_step=0.0114, train_loss_epoch=0.0145]Epoch 148: Train Loss = 0.011403553187847137\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=298, train_loss_step=0.010, train_loss_epoch=0.0114] Epoch 149: Train Loss = 0.010031978599727154\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=298, train_loss_step=0.0146, train_loss_epoch=0.010]Epoch 150: Train Loss = 0.014639198780059814\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=298, train_loss_step=0.0109, train_loss_epoch=0.0146]Epoch 151: Train Loss = 0.010856380686163902\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=298, train_loss_step=0.0109, train_loss_epoch=0.0109]Epoch 152: Train Loss = 0.01092312391847372\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s, v_num=298, train_loss_step=0.0172, train_loss_epoch=0.0109]Epoch 153: Train Loss = 0.01720711961388588\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=298, train_loss_step=0.0108, train_loss_epoch=0.0172]Epoch 154: Train Loss = 0.010847513563930988\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.0108]Epoch 155: Train Loss = 0.012542741373181343\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=298, train_loss_step=0.0113, train_loss_epoch=0.0125]Epoch 156: Train Loss = 0.011346210725605488\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=298, train_loss_step=0.014, train_loss_epoch=0.0113] Epoch 157: Train Loss = 0.013959050178527832\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.014]Epoch 158: Train Loss = 0.011894778348505497\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=298, train_loss_step=0.0115, train_loss_epoch=0.0119]Epoch 159: Train Loss = 0.011543151922523975\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.0115]Epoch 160: Train Loss = 0.011618641205132008\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=298, train_loss_step=0.0134, train_loss_epoch=0.0116]Epoch 161: Train Loss = 0.013388710096478462\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=298, train_loss_step=0.0165, train_loss_epoch=0.0134]Epoch 162: Train Loss = 0.01648089475929737\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=298, train_loss_step=0.00838, train_loss_epoch=0.0165]Epoch 163: Train Loss = 0.008376210927963257\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=298, train_loss_step=0.00909, train_loss_epoch=0.00838]Epoch 164: Train Loss = 0.009094403125345707\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.00909] Epoch 165: Train Loss = 0.013304896652698517\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=298, train_loss_step=0.0112, train_loss_epoch=0.0133] Epoch 166: Train Loss = 0.01121507491916418\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0112]Epoch 167: Train Loss = 0.01212864089757204\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=298, train_loss_step=0.00989, train_loss_epoch=0.0121]Epoch 168: Train Loss = 0.009891086257994175\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s, v_num=298, train_loss_step=0.0147, train_loss_epoch=0.00989] Epoch 169: Train Loss = 0.014748207293450832\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=298, train_loss_step=0.0144, train_loss_epoch=0.0147] Epoch 170: Train Loss = 0.014420418068766594\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=298, train_loss_step=0.0188, train_loss_epoch=0.0144]Epoch 171: Train Loss = 0.018760088831186295\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=298, train_loss_step=0.0141, train_loss_epoch=0.0188]Epoch 172: Train Loss = 0.014073844999074936\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=298, train_loss_step=0.0114, train_loss_epoch=0.0141]Epoch 173: Train Loss = 0.011370648629963398\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.0114]Epoch 174: Train Loss = 0.011646936647593975\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=298, train_loss_step=0.0118, train_loss_epoch=0.0116]Epoch 175: Train Loss = 0.011818923056125641\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=298, train_loss_step=0.0117, train_loss_epoch=0.0118]Epoch 176: Train Loss = 0.011663014069199562\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=298, train_loss_step=0.0165, train_loss_epoch=0.0117]Epoch 177: Train Loss = 0.016542302444577217\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s, v_num=298, train_loss_step=0.0138, train_loss_epoch=0.0165]Epoch 178: Train Loss = 0.013796297833323479\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.0138]Epoch 179: Train Loss = 0.011606627143919468\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=298, train_loss_step=0.0148, train_loss_epoch=0.0116]Epoch 180: Train Loss = 0.014816289767622948\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=298, train_loss_step=0.0128, train_loss_epoch=0.0148]Epoch 181: Train Loss = 0.0127671854570508\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=298, train_loss_step=0.0151, train_loss_epoch=0.0128]Epoch 182: Train Loss = 0.015099947340786457\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.0151]Epoch 183: Train Loss = 0.012871534563601017\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=298, train_loss_step=0.0104, train_loss_epoch=0.0129]Epoch 184: Train Loss = 0.010427949950098991\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0104]Epoch 185: Train Loss = 0.012077809311449528\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0121]Epoch 186: Train Loss = 0.011927642859518528\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.0119]Epoch 187: Train Loss = 0.012882879003882408\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.0129]Epoch 188: Train Loss = 0.01251006219536066\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=298, train_loss_step=0.010, train_loss_epoch=0.0125] Epoch 189: Train Loss = 0.010009943507611752\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=298, train_loss_step=0.00957, train_loss_epoch=0.010]Epoch 190: Train Loss = 0.00957368966192007\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.00957]  Epoch 191: Train Loss = 0.012003570795059204\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.012] Epoch 192: Train Loss = 0.012057187035679817\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=298, train_loss_step=0.0159, train_loss_epoch=0.0121]Epoch 193: Train Loss = 0.015942802652716637\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=298, train_loss_step=0.0115, train_loss_epoch=0.0159]Epoch 194: Train Loss = 0.011500873602926731\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=298, train_loss_step=0.0124, train_loss_epoch=0.0115]Epoch 195: Train Loss = 0.012413937598466873\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=298, train_loss_step=0.0102, train_loss_epoch=0.0124]Epoch 196: Train Loss = 0.01021022628992796\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, v_num=298, train_loss_step=0.0124, train_loss_epoch=0.0102]Epoch 197: Train Loss = 0.012411261908710003\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=298, train_loss_step=0.0205, train_loss_epoch=0.0124]Epoch 198: Train Loss = 0.020522775128483772\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=298, train_loss_step=0.0115, train_loss_epoch=0.0205]Epoch 199: Train Loss = 0.011472276411950588\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=298, train_loss_step=0.0153, train_loss_epoch=0.0115]Epoch 200: Train Loss = 0.015265916474163532\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 11.55it/s, v_num=298, train_loss_step=0.0135, train_loss_epoch=0.0153]Epoch 201: Train Loss = 0.01354298461228609\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=298, train_loss_step=0.0186, train_loss_epoch=0.0135]Epoch 202: Train Loss = 0.0186349805444479\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0186] Epoch 203: Train Loss = 0.011964044533669949\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=298, train_loss_step=0.0118, train_loss_epoch=0.012]Epoch 204: Train Loss = 0.011820528656244278\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.0118]Epoch 205: Train Loss = 0.012489596381783485\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=298, train_loss_step=0.00881, train_loss_epoch=0.0125]Epoch 206: Train Loss = 0.008807176724076271\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=298, train_loss_step=0.0101, train_loss_epoch=0.00881] Epoch 207: Train Loss = 0.010092368349432945\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=298, train_loss_step=0.0106, train_loss_epoch=0.0101] Epoch 208: Train Loss = 0.010556703433394432\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=298, train_loss_step=0.0141, train_loss_epoch=0.0106]Epoch 209: Train Loss = 0.014102841727435589\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=298, train_loss_step=0.0108, train_loss_epoch=0.0141]Epoch 210: Train Loss = 0.010815732181072235\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 11.97it/s, v_num=298, train_loss_step=0.0114, train_loss_epoch=0.0108]Epoch 211: Train Loss = 0.011447058990597725\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s, v_num=298, train_loss_step=0.014, train_loss_epoch=0.0114] Epoch 212: Train Loss = 0.013954118825495243\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=298, train_loss_step=0.0127, train_loss_epoch=0.014]Epoch 213: Train Loss = 0.01268798764795065\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=298, train_loss_step=0.0107, train_loss_epoch=0.0127]Epoch 214: Train Loss = 0.010688567534089088\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s, v_num=298, train_loss_step=0.0103, train_loss_epoch=0.0107]Epoch 215: Train Loss = 0.010331617668271065\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0103] Epoch 216: Train Loss = 0.01202680729329586\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=298, train_loss_step=0.0123, train_loss_epoch=0.012]Epoch 217: Train Loss = 0.012285405769944191\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=298, train_loss_step=0.0137, train_loss_epoch=0.0123]Epoch 218: Train Loss = 0.013664809055626392\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.0137]Epoch 219: Train Loss = 0.013290440663695335\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.0133]Epoch 220: Train Loss = 0.013291917741298676\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=298, train_loss_step=0.0111, train_loss_epoch=0.0133]Epoch 221: Train Loss = 0.011134474538266659\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 12.91it/s, v_num=298, train_loss_step=0.0157, train_loss_epoch=0.0111]Epoch 222: Train Loss = 0.01573776639997959\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s, v_num=298, train_loss_step=0.0143, train_loss_epoch=0.0157]Epoch 223: Train Loss = 0.014290854334831238\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=298, train_loss_step=0.0126, train_loss_epoch=0.0143]Epoch 224: Train Loss = 0.012602153234183788\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=298, train_loss_step=0.0104, train_loss_epoch=0.0126]Epoch 225: Train Loss = 0.010388078168034554\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.0104]Epoch 226: Train Loss = 0.013314880430698395\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=298, train_loss_step=0.0156, train_loss_epoch=0.0133]Epoch 227: Train Loss = 0.015624779276549816\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=298, train_loss_step=0.0111, train_loss_epoch=0.0156]Epoch 228: Train Loss = 0.011072942987084389\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=298, train_loss_step=0.0124, train_loss_epoch=0.0111]Epoch 229: Train Loss = 0.012411640025675297\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=298, train_loss_step=0.0135, train_loss_epoch=0.0124]Epoch 230: Train Loss = 0.01345139741897583\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s, v_num=298, train_loss_step=0.0113, train_loss_epoch=0.0135]Epoch 231: Train Loss = 0.01128946989774704\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=298, train_loss_step=0.0134, train_loss_epoch=0.0113]Epoch 232: Train Loss = 0.01338933128863573\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=298, train_loss_step=0.0139, train_loss_epoch=0.0134]Epoch 233: Train Loss = 0.013912832364439964\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=298, train_loss_step=0.0117, train_loss_epoch=0.0139]Epoch 234: Train Loss = 0.011707873083651066\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 11.10it/s, v_num=298, train_loss_step=0.0128, train_loss_epoch=0.0117]Epoch 235: Train Loss = 0.012831224128603935\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=298, train_loss_step=0.0144, train_loss_epoch=0.0128]Epoch 236: Train Loss = 0.01435412559658289\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=298, train_loss_step=0.0168, train_loss_epoch=0.0144]Epoch 237: Train Loss = 0.01675901748239994\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.0168]Epoch 238: Train Loss = 0.012471453286707401\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=298, train_loss_step=0.0105, train_loss_epoch=0.0125]Epoch 239: Train Loss = 0.010508847422897816\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=298, train_loss_step=0.0123, train_loss_epoch=0.0105]Epoch 240: Train Loss = 0.012250195257365704\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=298, train_loss_step=0.0185, train_loss_epoch=0.0123]Epoch 241: Train Loss = 0.018525289371609688\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=298, train_loss_step=0.0115, train_loss_epoch=0.0185]Epoch 242: Train Loss = 0.011531914584338665\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=298, train_loss_step=0.0136, train_loss_epoch=0.0115]Epoch 243: Train Loss = 0.013580051250755787\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=298, train_loss_step=0.0114, train_loss_epoch=0.0136]Epoch 244: Train Loss = 0.01138988696038723\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=298, train_loss_step=0.0158, train_loss_epoch=0.0114]Epoch 245: Train Loss = 0.0158065278083086\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s, v_num=298, train_loss_step=0.0146, train_loss_epoch=0.0158]Epoch 246: Train Loss = 0.014587251469492912\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0146]Epoch 247: Train Loss = 0.012147177942097187\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s, v_num=298, train_loss_step=0.0106, train_loss_epoch=0.0121]Epoch 248: Train Loss = 0.010589041747152805\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=298, train_loss_step=0.0145, train_loss_epoch=0.0106]Epoch 249: Train Loss = 0.014463215135037899\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=298, train_loss_step=0.015, train_loss_epoch=0.0145] Epoch 250: Train Loss = 0.015002702362835407\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=298, train_loss_step=0.00981, train_loss_epoch=0.015]Epoch 251: Train Loss = 0.009808999486267567\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=298, train_loss_step=0.0136, train_loss_epoch=0.00981] Epoch 252: Train Loss = 0.013593132607638836\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=298, train_loss_step=0.0153, train_loss_epoch=0.0136] Epoch 253: Train Loss = 0.015309912152588367\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.0153]Epoch 254: Train Loss = 0.012481926009058952\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=298, train_loss_step=0.0165, train_loss_epoch=0.0125]Epoch 255: Train Loss = 0.016465822234749794\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=298, train_loss_step=0.0114, train_loss_epoch=0.0165]Epoch 256: Train Loss = 0.011379905976355076\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s, v_num=298, train_loss_step=0.0136, train_loss_epoch=0.0114]Epoch 257: Train Loss = 0.013555319979786873\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=298, train_loss_step=0.0131, train_loss_epoch=0.0136]Epoch 258: Train Loss = 0.013065596111118793\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=298, train_loss_step=0.0142, train_loss_epoch=0.0131]Epoch 259: Train Loss = 0.014230623841285706\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=298, train_loss_step=0.0167, train_loss_epoch=0.0142]Epoch 260: Train Loss = 0.01668195240199566\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=298, train_loss_step=0.0088, train_loss_epoch=0.0167]Epoch 261: Train Loss = 0.008796833455562592\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=298, train_loss_step=0.00941, train_loss_epoch=0.0088]Epoch 262: Train Loss = 0.009411181323230267\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=298, train_loss_step=0.0145, train_loss_epoch=0.00941] Epoch 263: Train Loss = 0.014535916037857533\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=298, train_loss_step=0.0149, train_loss_epoch=0.0145] Epoch 264: Train Loss = 0.014858379028737545\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=298, train_loss_step=0.0106, train_loss_epoch=0.0149]Epoch 265: Train Loss = 0.010573453269898891\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=298, train_loss_step=0.00981, train_loss_epoch=0.0106]Epoch 266: Train Loss = 0.0098051642999053\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=298, train_loss_step=0.0148, train_loss_epoch=0.00981] Epoch 267: Train Loss = 0.014761672355234623\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=298, train_loss_step=0.0112, train_loss_epoch=0.0148] Epoch 268: Train Loss = 0.011167986318469048\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=298, train_loss_step=0.0115, train_loss_epoch=0.0112]Epoch 269: Train Loss = 0.011528554372489452\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=298, train_loss_step=0.016, train_loss_epoch=0.0115] Epoch 270: Train Loss = 0.016004031524062157\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.016]Epoch 271: Train Loss = 0.011619831435382366\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=298, train_loss_step=0.0111, train_loss_epoch=0.0116]Epoch 272: Train Loss = 0.011118887923657894\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=298, train_loss_step=0.0155, train_loss_epoch=0.0111]Epoch 273: Train Loss = 0.015486514195799828\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.0155]Epoch 274: Train Loss = 0.011597038246691227\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0116]Epoch 275: Train Loss = 0.011876814067363739\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=298, train_loss_step=0.0107, train_loss_epoch=0.0119]Epoch 276: Train Loss = 0.010662262327969074\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=298, train_loss_step=0.011, train_loss_epoch=0.0107] Epoch 277: Train Loss = 0.010957839898765087\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=298, train_loss_step=0.0123, train_loss_epoch=0.011]Epoch 278: Train Loss = 0.012284774333238602\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=298, train_loss_step=0.011, train_loss_epoch=0.0123] Epoch 279: Train Loss = 0.011019003577530384\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.011]Epoch 280: Train Loss = 0.012903413735330105\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=298, train_loss_step=0.0155, train_loss_epoch=0.0129]Epoch 281: Train Loss = 0.015460856258869171\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s, v_num=298, train_loss_step=0.0162, train_loss_epoch=0.0155]Epoch 282: Train Loss = 0.016224132850766182\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=298, train_loss_step=0.0183, train_loss_epoch=0.0162]Epoch 283: Train Loss = 0.01831933483481407\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=298, train_loss_step=0.0138, train_loss_epoch=0.0183]Epoch 284: Train Loss = 0.013774947263300419\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=298, train_loss_step=0.0143, train_loss_epoch=0.0138]Epoch 285: Train Loss = 0.014283531345427036\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=298, train_loss_step=0.0106, train_loss_epoch=0.0143]Epoch 286: Train Loss = 0.010583072900772095\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=298, train_loss_step=0.0102, train_loss_epoch=0.0106]Epoch 287: Train Loss = 0.010220484808087349\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.0102]Epoch 288: Train Loss = 0.011566716246306896\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=298, train_loss_step=0.0113, train_loss_epoch=0.0116]Epoch 289: Train Loss = 0.011281703598797321\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=298, train_loss_step=0.00863, train_loss_epoch=0.0113]Epoch 290: Train Loss = 0.00863453559577465\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=298, train_loss_step=0.0109, train_loss_epoch=0.00863] Epoch 291: Train Loss = 0.010885472409427166\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=298, train_loss_step=0.0103, train_loss_epoch=0.0109] Epoch 292: Train Loss = 0.010275949724018574\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=298, train_loss_step=0.014, train_loss_epoch=0.0103] Epoch 293: Train Loss = 0.014008660800755024\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=298, train_loss_step=0.0147, train_loss_epoch=0.014]Epoch 294: Train Loss = 0.014674835838377476\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=298, train_loss_step=0.0118, train_loss_epoch=0.0147]Epoch 295: Train Loss = 0.011784514412283897\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.0118]Epoch 296: Train Loss = 0.013271760195493698\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0133] Epoch 297: Train Loss = 0.011951261200010777\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.012]Epoch 298: Train Loss = 0.012120540253818035\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=298, train_loss_step=0.0141, train_loss_epoch=0.0121]Epoch 299: Train Loss = 0.014113523997366428\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0141]Epoch 300: Train Loss = 0.011894715949892998\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=298, train_loss_step=0.0108, train_loss_epoch=0.0119]Epoch 301: Train Loss = 0.01078890822827816\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=298, train_loss_step=0.014, train_loss_epoch=0.0108] Epoch 302: Train Loss = 0.014033275656402111\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=298, train_loss_step=0.0159, train_loss_epoch=0.014]Epoch 303: Train Loss = 0.01592693291604519\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s, v_num=298, train_loss_step=0.0128, train_loss_epoch=0.0159]Epoch 304: Train Loss = 0.012805329635739326\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s, v_num=298, train_loss_step=0.0181, train_loss_epoch=0.0128]Epoch 305: Train Loss = 0.018112588673830032\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=298, train_loss_step=0.0167, train_loss_epoch=0.0181]Epoch 306: Train Loss = 0.01667085662484169\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.0167]Epoch 307: Train Loss = 0.011632272973656654\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=298, train_loss_step=0.0113, train_loss_epoch=0.0116]Epoch 308: Train Loss = 0.011316503398120403\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=298, train_loss_step=0.0134, train_loss_epoch=0.0113]Epoch 309: Train Loss = 0.01338921021670103\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=298, train_loss_step=0.0132, train_loss_epoch=0.0134]Epoch 310: Train Loss = 0.013159391470253468\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=298, train_loss_step=0.011, train_loss_epoch=0.0132] Epoch 311: Train Loss = 0.011046096682548523\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.011]Epoch 312: Train Loss = 0.01289485301822424\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 10.45it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.0129]Epoch 313: Train Loss = 0.012870974838733673\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=298, train_loss_step=0.0164, train_loss_epoch=0.0129]Epoch 314: Train Loss = 0.01642601564526558\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=298, train_loss_step=0.00995, train_loss_epoch=0.0164]Epoch 315: Train Loss = 0.009950725361704826\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s, v_num=298, train_loss_step=0.015, train_loss_epoch=0.00995]  Epoch 316: Train Loss = 0.015000305138528347\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=298, train_loss_step=0.0146, train_loss_epoch=0.015] Epoch 317: Train Loss = 0.014577229507267475\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s, v_num=298, train_loss_step=0.0107, train_loss_epoch=0.0146]Epoch 318: Train Loss = 0.010728509165346622\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=298, train_loss_step=0.0145, train_loss_epoch=0.0107]Epoch 319: Train Loss = 0.014454190619289875\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=298, train_loss_step=0.0117, train_loss_epoch=0.0145]Epoch 320: Train Loss = 0.01167983002960682\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=298, train_loss_step=0.0108, train_loss_epoch=0.0117]Epoch 321: Train Loss = 0.010790050961077213\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 11.42it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.0108]Epoch 322: Train Loss = 0.01250086072832346\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=298, train_loss_step=0.0112, train_loss_epoch=0.0125]Epoch 323: Train Loss = 0.011215150356292725\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.0112]Epoch 324: Train Loss = 0.012850730679929256\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=298, train_loss_step=0.0162, train_loss_epoch=0.0129]Epoch 325: Train Loss = 0.016248812898993492\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=298, train_loss_step=0.0113, train_loss_epoch=0.0162]Epoch 326: Train Loss = 0.011338615790009499\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=298, train_loss_step=0.0173, train_loss_epoch=0.0113]Epoch 327: Train Loss = 0.017290474846959114\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=298, train_loss_step=0.0124, train_loss_epoch=0.0173]Epoch 328: Train Loss = 0.01240038312971592\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=298, train_loss_step=0.0102, train_loss_epoch=0.0124]Epoch 329: Train Loss = 0.010199506767094135\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=298, train_loss_step=0.0107, train_loss_epoch=0.0102]Epoch 330: Train Loss = 0.010708355344831944\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=298, train_loss_step=0.0131, train_loss_epoch=0.0107]Epoch 331: Train Loss = 0.013113443739712238\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=298, train_loss_step=0.00983, train_loss_epoch=0.0131]Epoch 332: Train Loss = 0.009826065972447395\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=298, train_loss_step=0.0127, train_loss_epoch=0.00983] Epoch 333: Train Loss = 0.012681406922638416\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=298, train_loss_step=0.0118, train_loss_epoch=0.0127] Epoch 334: Train Loss = 0.011838986538350582\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0118]Epoch 335: Train Loss = 0.011907649226486683\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=298, train_loss_step=0.0135, train_loss_epoch=0.0119]Epoch 336: Train Loss = 0.013457664288580418\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0135]Epoch 337: Train Loss = 0.011936730705201626\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=298, train_loss_step=0.011, train_loss_epoch=0.0119] Epoch 338: Train Loss = 0.011033540591597557\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.011]Epoch 339: Train Loss = 0.012899181805551052\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0129]Epoch 340: Train Loss = 0.012101446278393269\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0121]Epoch 341: Train Loss = 0.012124094180762768\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=298, train_loss_step=0.0135, train_loss_epoch=0.0121]Epoch 342: Train Loss = 0.013518095016479492\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=298, train_loss_step=0.0208, train_loss_epoch=0.0135]Epoch 343: Train Loss = 0.020799756050109863\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s, v_num=298, train_loss_step=0.0131, train_loss_epoch=0.0208]Epoch 344: Train Loss = 0.0130907092243433\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=298, train_loss_step=0.0117, train_loss_epoch=0.0131]Epoch 345: Train Loss = 0.011738278903067112\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0117]Epoch 346: Train Loss = 0.011939656920731068\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=298, train_loss_step=0.00928, train_loss_epoch=0.0119]Epoch 347: Train Loss = 0.00927639752626419\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=298, train_loss_step=0.00971, train_loss_epoch=0.00928]Epoch 348: Train Loss = 0.009714796207845211\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=298, train_loss_step=0.0128, train_loss_epoch=0.00971] Epoch 349: Train Loss = 0.01282358169555664\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=298, train_loss_step=0.0111, train_loss_epoch=0.0128] Epoch 350: Train Loss = 0.011149930767714977\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=298, train_loss_step=0.0144, train_loss_epoch=0.0111]Epoch 351: Train Loss = 0.014398671686649323\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=298, train_loss_step=0.0118, train_loss_epoch=0.0144]Epoch 352: Train Loss = 0.011765017174184322\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=298, train_loss_step=0.00932, train_loss_epoch=0.0118]Epoch 353: Train Loss = 0.009322562254965305\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s, v_num=298, train_loss_step=0.0139, train_loss_epoch=0.00932] Epoch 354: Train Loss = 0.013885870575904846\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 11.08it/s, v_num=298, train_loss_step=0.00852, train_loss_epoch=0.0139]Epoch 355: Train Loss = 0.008518973365426064\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=298, train_loss_step=0.0151, train_loss_epoch=0.00852] Epoch 356: Train Loss = 0.01511700451374054\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 10.30it/s, v_num=298, train_loss_step=0.0113, train_loss_epoch=0.0151] Epoch 357: Train Loss = 0.011285258457064629\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s, v_num=298, train_loss_step=0.00906, train_loss_epoch=0.0113]Epoch 358: Train Loss = 0.009055359289050102\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.00906] Epoch 359: Train Loss = 0.013310466893017292\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.0133] Epoch 360: Train Loss = 0.013250146992504597\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=298, train_loss_step=0.0117, train_loss_epoch=0.0133]Epoch 361: Train Loss = 0.011669041588902473\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=298, train_loss_step=0.0115, train_loss_epoch=0.0117]Epoch 362: Train Loss = 0.011530757881700993\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=298, train_loss_step=0.0138, train_loss_epoch=0.0115]Epoch 363: Train Loss = 0.01384882815182209\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=298, train_loss_step=0.0126, train_loss_epoch=0.0138]Epoch 364: Train Loss = 0.012555456720292568\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=298, train_loss_step=0.0141, train_loss_epoch=0.0126]Epoch 365: Train Loss = 0.014129727147519588\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=298, train_loss_step=0.0104, train_loss_epoch=0.0141]Epoch 366: Train Loss = 0.010352447628974915\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 12.72it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.0104]Epoch 367: Train Loss = 0.012515385635197163\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=298, train_loss_step=0.0112, train_loss_epoch=0.0125]Epoch 368: Train Loss = 0.011249413713812828\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=298, train_loss_step=0.014, train_loss_epoch=0.0112] Epoch 369: Train Loss = 0.014028596691787243\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=298, train_loss_step=0.0158, train_loss_epoch=0.014]Epoch 370: Train Loss = 0.0158238522708416\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.0158]Epoch 371: Train Loss = 0.013323107734322548\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=298, train_loss_step=0.0147, train_loss_epoch=0.0133]Epoch 372: Train Loss = 0.014707374386489391\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=298, train_loss_step=0.0136, train_loss_epoch=0.0147]Epoch 373: Train Loss = 0.013600337319076061\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=298, train_loss_step=0.0112, train_loss_epoch=0.0136]Epoch 374: Train Loss = 0.011165332980453968\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=298, train_loss_step=0.0127, train_loss_epoch=0.0112]Epoch 375: Train Loss = 0.012663464061915874\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=298, train_loss_step=0.00922, train_loss_epoch=0.0127]Epoch 376: Train Loss = 0.009223582223057747\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 10.51it/s, v_num=298, train_loss_step=0.0139, train_loss_epoch=0.00922] Epoch 377: Train Loss = 0.013904599472880363\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 11.71it/s, v_num=298, train_loss_step=0.0122, train_loss_epoch=0.0139] Epoch 378: Train Loss = 0.01222884189337492\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=298, train_loss_step=0.0114, train_loss_epoch=0.0122]Epoch 379: Train Loss = 0.011428958736360073\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.0114]Epoch 380: Train Loss = 0.011613653972744942\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=298, train_loss_step=0.0141, train_loss_epoch=0.0116]Epoch 381: Train Loss = 0.014113189652562141\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=298, train_loss_step=0.0111, train_loss_epoch=0.0141]Epoch 382: Train Loss = 0.01108474750071764\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=298, train_loss_step=0.0139, train_loss_epoch=0.0111]Epoch 383: Train Loss = 0.013882441446185112\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=298, train_loss_step=0.0103, train_loss_epoch=0.0139]Epoch 384: Train Loss = 0.010271409526467323\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.0103]Epoch 385: Train Loss = 0.012930444441735744\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0129] Epoch 386: Train Loss = 0.012045137584209442\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=298, train_loss_step=0.0127, train_loss_epoch=0.012]Epoch 387: Train Loss = 0.012731551192700863\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=298, train_loss_step=0.0179, train_loss_epoch=0.0127]Epoch 388: Train Loss = 0.017862210050225258\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=298, train_loss_step=0.0148, train_loss_epoch=0.0179]Epoch 389: Train Loss = 0.014840913936495781\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=298, train_loss_step=0.00924, train_loss_epoch=0.0148]Epoch 390: Train Loss = 0.009243619628250599\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.00924] Epoch 391: Train Loss = 0.012090004980564117\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=298, train_loss_step=0.0112, train_loss_epoch=0.0121] Epoch 392: Train Loss = 0.011226220987737179\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=298, train_loss_step=0.0137, train_loss_epoch=0.0112]Epoch 393: Train Loss = 0.013720293529331684\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=298, train_loss_step=0.0142, train_loss_epoch=0.0137]Epoch 394: Train Loss = 0.014188544824719429\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=298, train_loss_step=0.017, train_loss_epoch=0.0142] Epoch 395: Train Loss = 0.016998404636979103\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.017]Epoch 396: Train Loss = 0.012507406063377857\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=298, train_loss_step=0.00979, train_loss_epoch=0.0125]Epoch 397: Train Loss = 0.009785294532775879\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=298, train_loss_step=0.011, train_loss_epoch=0.00979]  Epoch 398: Train Loss = 0.010967990383505821\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=298, train_loss_step=0.0122, train_loss_epoch=0.011] Epoch 399: Train Loss = 0.01216508261859417\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=298, train_loss_step=0.0102, train_loss_epoch=0.0122]Epoch 400: Train Loss = 0.010191639885306358\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.0102]Epoch 401: Train Loss = 0.01333391573280096\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=298, train_loss_step=0.00973, train_loss_epoch=0.0133]Epoch 402: Train Loss = 0.009725372307002544\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.00973] Epoch 403: Train Loss = 0.011886736378073692\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=298, train_loss_step=0.00987, train_loss_epoch=0.0119]Epoch 404: Train Loss = 0.009873955510556698\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=298, train_loss_step=0.0135, train_loss_epoch=0.00987] Epoch 405: Train Loss = 0.013526876457035542\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=298, train_loss_step=0.0136, train_loss_epoch=0.0135] Epoch 406: Train Loss = 0.013632133603096008\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=298, train_loss_step=0.0122, train_loss_epoch=0.0136]Epoch 407: Train Loss = 0.012247233651578426\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0122]Epoch 408: Train Loss = 0.011878135614097118\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=298, train_loss_step=0.0128, train_loss_epoch=0.0119]Epoch 409: Train Loss = 0.012804321013391018\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=298, train_loss_step=0.00936, train_loss_epoch=0.0128]Epoch 410: Train Loss = 0.009358705021440983\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=298, train_loss_step=0.0138, train_loss_epoch=0.00936] Epoch 411: Train Loss = 0.013760564848780632\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=298, train_loss_step=0.0131, train_loss_epoch=0.0138] Epoch 412: Train Loss = 0.013065574690699577\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=298, train_loss_step=0.0188, train_loss_epoch=0.0131]Epoch 413: Train Loss = 0.018842654302716255\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s, v_num=298, train_loss_step=0.00879, train_loss_epoch=0.0188]Epoch 414: Train Loss = 0.008786896243691444\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.00879] Epoch 415: Train Loss = 0.012867932207882404\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=298, train_loss_step=0.0101, train_loss_epoch=0.0129] Epoch 416: Train Loss = 0.010071425698697567\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.0101]Epoch 417: Train Loss = 0.01158936321735382\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=298, train_loss_step=0.0112, train_loss_epoch=0.0116]Epoch 418: Train Loss = 0.011227035894989967\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s, v_num=298, train_loss_step=0.0143, train_loss_epoch=0.0112]Epoch 419: Train Loss = 0.014346842654049397\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=298, train_loss_step=0.00982, train_loss_epoch=0.0143]Epoch 420: Train Loss = 0.009817481972277164\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=298, train_loss_step=0.0108, train_loss_epoch=0.00982] Epoch 421: Train Loss = 0.010799032635986805\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=298, train_loss_step=0.0115, train_loss_epoch=0.0108] Epoch 422: Train Loss = 0.011496424674987793\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=298, train_loss_step=0.0141, train_loss_epoch=0.0115]Epoch 423: Train Loss = 0.014112591743469238\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0141]Epoch 424: Train Loss = 0.012057721614837646\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=298, train_loss_step=0.0104, train_loss_epoch=0.0121]Epoch 425: Train Loss = 0.01038453821092844\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=298, train_loss_step=0.0126, train_loss_epoch=0.0104]Epoch 426: Train Loss = 0.012602118775248528\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=298, train_loss_step=0.0113, train_loss_epoch=0.0126]Epoch 427: Train Loss = 0.011292892508208752\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=298, train_loss_step=0.0124, train_loss_epoch=0.0113]Epoch 428: Train Loss = 0.01235901564359665\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.0124]Epoch 429: Train Loss = 0.012473388575017452\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=298, train_loss_step=0.0128, train_loss_epoch=0.0125]Epoch 430: Train Loss = 0.012827984057366848\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=298, train_loss_step=0.0108, train_loss_epoch=0.0128]Epoch 431: Train Loss = 0.010849171318113804\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=298, train_loss_step=0.0158, train_loss_epoch=0.0108]Epoch 432: Train Loss = 0.015815017744898796\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=298, train_loss_step=0.0155, train_loss_epoch=0.0158]Epoch 433: Train Loss = 0.015510983765125275\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=298, train_loss_step=0.0126, train_loss_epoch=0.0155]Epoch 434: Train Loss = 0.012649270705878735\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=298, train_loss_step=0.0132, train_loss_epoch=0.0126]Epoch 435: Train Loss = 0.013223277404904366\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=298, train_loss_step=0.0114, train_loss_epoch=0.0132]Epoch 436: Train Loss = 0.011420573107898235\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=298, train_loss_step=0.0156, train_loss_epoch=0.0114]Epoch 437: Train Loss = 0.015598036348819733\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=298, train_loss_step=0.0105, train_loss_epoch=0.0156]Epoch 438: Train Loss = 0.010537682101130486\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=298, train_loss_step=0.00985, train_loss_epoch=0.0105]Epoch 439: Train Loss = 0.009846163913607597\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=298, train_loss_step=0.0154, train_loss_epoch=0.00985] Epoch 440: Train Loss = 0.015443057753145695\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=298, train_loss_step=0.0136, train_loss_epoch=0.0154] Epoch 441: Train Loss = 0.013554106466472149\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=298, train_loss_step=0.0132, train_loss_epoch=0.0136]Epoch 442: Train Loss = 0.01322479359805584\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s, v_num=298, train_loss_step=0.0101, train_loss_epoch=0.0132]Epoch 443: Train Loss = 0.010149078443646431\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, v_num=298, train_loss_step=0.0135, train_loss_epoch=0.0101]Epoch 444: Train Loss = 0.013527348637580872\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.0135]Epoch 445: Train Loss = 0.013259923085570335\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=298, train_loss_step=0.0109, train_loss_epoch=0.0133]Epoch 446: Train Loss = 0.01089479960501194\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=298, train_loss_step=0.0097, train_loss_epoch=0.0109]Epoch 447: Train Loss = 0.009701301343739033\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0097]Epoch 448: Train Loss = 0.012079830281436443\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=298, train_loss_step=0.0106, train_loss_epoch=0.0121]Epoch 449: Train Loss = 0.010559107176959515\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=298, train_loss_step=0.0129, train_loss_epoch=0.0106]Epoch 450: Train Loss = 0.01294502429664135\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=298, train_loss_step=0.0137, train_loss_epoch=0.0129]Epoch 451: Train Loss = 0.013695801608264446\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0137]Epoch 452: Train Loss = 0.012065990827977657\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=298, train_loss_step=0.0104, train_loss_epoch=0.0121]Epoch 453: Train Loss = 0.01035634707659483\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 11.20it/s, v_num=298, train_loss_step=0.0113, train_loss_epoch=0.0104]Epoch 454: Train Loss = 0.011291942559182644\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=298, train_loss_step=0.0123, train_loss_epoch=0.0113]Epoch 455: Train Loss = 0.012325109913945198\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=298, train_loss_step=0.0127, train_loss_epoch=0.0123]Epoch 456: Train Loss = 0.01269912626594305\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s, v_num=298, train_loss_step=0.014, train_loss_epoch=0.0127] Epoch 457: Train Loss = 0.013978885486721992\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=298, train_loss_step=0.0114, train_loss_epoch=0.014]Epoch 458: Train Loss = 0.011396994814276695\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=298, train_loss_step=0.0105, train_loss_epoch=0.0114]Epoch 459: Train Loss = 0.010456823743879795\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0105]Epoch 460: Train Loss = 0.011885978281497955\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s, v_num=298, train_loss_step=0.0106, train_loss_epoch=0.0119]Epoch 461: Train Loss = 0.010586903430521488\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=298, train_loss_step=0.0135, train_loss_epoch=0.0106]Epoch 462: Train Loss = 0.013549054972827435\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=298, train_loss_step=0.0103, train_loss_epoch=0.0135]Epoch 463: Train Loss = 0.010348431766033173\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=298, train_loss_step=0.0109, train_loss_epoch=0.0103]Epoch 464: Train Loss = 0.01089469064027071\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=298, train_loss_step=0.0139, train_loss_epoch=0.0109]Epoch 465: Train Loss = 0.013917350210249424\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=298, train_loss_step=0.0169, train_loss_epoch=0.0139]Epoch 466: Train Loss = 0.016875114291906357\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=298, train_loss_step=0.0164, train_loss_epoch=0.0169]Epoch 467: Train Loss = 0.016355901956558228\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=298, train_loss_step=0.0131, train_loss_epoch=0.0164]Epoch 468: Train Loss = 0.013094043359160423\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=298, train_loss_step=0.015, train_loss_epoch=0.0131] Epoch 469: Train Loss = 0.014961778186261654\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=298, train_loss_step=0.0133, train_loss_epoch=0.015]Epoch 470: Train Loss = 0.013296380639076233\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=298, train_loss_step=0.0153, train_loss_epoch=0.0133]Epoch 471: Train Loss = 0.015301761217415333\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 12.27it/s, v_num=298, train_loss_step=0.0136, train_loss_epoch=0.0153]Epoch 472: Train Loss = 0.013552437536418438\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0136]Epoch 473: Train Loss = 0.011857135221362114\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=298, train_loss_step=0.00954, train_loss_epoch=0.0119]Epoch 474: Train Loss = 0.009541338309645653\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.00954] Epoch 475: Train Loss = 0.01188274659216404\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=298, train_loss_step=0.0108, train_loss_epoch=0.0119] Epoch 476: Train Loss = 0.010816289111971855\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=298, train_loss_step=0.00897, train_loss_epoch=0.0108]Epoch 477: Train Loss = 0.008966512978076935\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, v_num=298, train_loss_step=0.00882, train_loss_epoch=0.00897]Epoch 478: Train Loss = 0.008817498572170734\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=298, train_loss_step=0.0153, train_loss_epoch=0.00882] Epoch 479: Train Loss = 0.015277612023055553\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=298, train_loss_step=0.0119, train_loss_epoch=0.0153] Epoch 480: Train Loss = 0.011911528185009956\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=298, train_loss_step=0.0115, train_loss_epoch=0.0119]Epoch 481: Train Loss = 0.011545307002961636\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=298, train_loss_step=0.0146, train_loss_epoch=0.0115]Epoch 482: Train Loss = 0.014641654677689075\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=298, train_loss_step=0.0106, train_loss_epoch=0.0146]Epoch 483: Train Loss = 0.01057263370603323\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=298, train_loss_step=0.0112, train_loss_epoch=0.0106]Epoch 484: Train Loss = 0.011213607154786587\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=298, train_loss_step=0.00907, train_loss_epoch=0.0112]Epoch 485: Train Loss = 0.009068971499800682\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=298, train_loss_step=0.0116, train_loss_epoch=0.00907] Epoch 486: Train Loss = 0.011596443131566048\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=298, train_loss_step=0.0136, train_loss_epoch=0.0116] Epoch 487: Train Loss = 0.013603760860860348\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=298, train_loss_step=0.0122, train_loss_epoch=0.0136]Epoch 488: Train Loss = 0.012164747342467308\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=298, train_loss_step=0.0113, train_loss_epoch=0.0122]Epoch 489: Train Loss = 0.011278760619461536\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=298, train_loss_step=0.0188, train_loss_epoch=0.0113]Epoch 490: Train Loss = 0.018827110528945923\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=298, train_loss_step=0.0121, train_loss_epoch=0.0188]Epoch 491: Train Loss = 0.012142051942646503\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s, v_num=298, train_loss_step=0.00972, train_loss_epoch=0.0121]Epoch 492: Train Loss = 0.00972157996147871\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=298, train_loss_step=0.0154, train_loss_epoch=0.00972] Epoch 493: Train Loss = 0.015418900176882744\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=298, train_loss_step=0.0145, train_loss_epoch=0.0154] Epoch 494: Train Loss = 0.014483447186648846\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=298, train_loss_step=0.012, train_loss_epoch=0.0145] Epoch 495: Train Loss = 0.012025339528918266\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=298, train_loss_step=0.0125, train_loss_epoch=0.012]Epoch 496: Train Loss = 0.01253389474004507\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=298, train_loss_step=0.0164, train_loss_epoch=0.0125]Epoch 497: Train Loss = 0.01639924757182598\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=298, train_loss_step=0.00886, train_loss_epoch=0.0164]Epoch 498: Train Loss = 0.008864759467542171\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=298, train_loss_step=0.0158, train_loss_epoch=0.00886] Epoch 499: Train Loss = 0.015768155455589294\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=298, train_loss_step=0.0158, train_loss_epoch=0.0158] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=298, train_loss_step=0.0158, train_loss_epoch=0.0158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 3: from 2010-06-30 00:00:00 to 2022-07-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=302, train_loss_step=0.0237]Epoch 0: Train Loss = 0.023686643689870834\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=302, train_loss_step=0.0386, train_loss_epoch=0.0237]Epoch 1: Train Loss = 0.038612183183431625\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=302, train_loss_step=0.0367, train_loss_epoch=0.0386]Epoch 2: Train Loss = 0.036672450602054596\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=302, train_loss_step=0.0215, train_loss_epoch=0.0367]Epoch 3: Train Loss = 0.021455911919474602\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s, v_num=302, train_loss_step=0.0273, train_loss_epoch=0.0215]Epoch 4: Train Loss = 0.027328236028552055\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=302, train_loss_step=0.028, train_loss_epoch=0.0273] Epoch 5: Train Loss = 0.027951259166002274\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=302, train_loss_step=0.0217, train_loss_epoch=0.028]Epoch 6: Train Loss = 0.0217022392898798\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=302, train_loss_step=0.016, train_loss_epoch=0.0217] Epoch 7: Train Loss = 0.01602991111576557\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=302, train_loss_step=0.0164, train_loss_epoch=0.016]Epoch 8: Train Loss = 0.01636761613190174\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=302, train_loss_step=0.0176, train_loss_epoch=0.0164]Epoch 9: Train Loss = 0.01761551760137081\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=302, train_loss_step=0.0158, train_loss_epoch=0.0176]Epoch 10: Train Loss = 0.015825815498828888\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=302, train_loss_step=0.0163, train_loss_epoch=0.0158]Epoch 11: Train Loss = 0.01632481999695301\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=302, train_loss_step=0.0162, train_loss_epoch=0.0163]Epoch 12: Train Loss = 0.016164932399988174\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=302, train_loss_step=0.0133, train_loss_epoch=0.0162]Epoch 13: Train Loss = 0.013331355527043343\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=302, train_loss_step=0.0156, train_loss_epoch=0.0133]Epoch 14: Train Loss = 0.015552337281405926\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.0156]Epoch 15: Train Loss = 0.012786002829670906\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=302, train_loss_step=0.014, train_loss_epoch=0.0128] Epoch 16: Train Loss = 0.013954265043139458\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=302, train_loss_step=0.0136, train_loss_epoch=0.014]Epoch 17: Train Loss = 0.013647169806063175\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=302, train_loss_step=0.0153, train_loss_epoch=0.0136]Epoch 18: Train Loss = 0.015285766683518887\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=302, train_loss_step=0.0102, train_loss_epoch=0.0153]Epoch 19: Train Loss = 0.010167486034333706\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=302, train_loss_step=0.0132, train_loss_epoch=0.0102]Epoch 20: Train Loss = 0.013231707736849785\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=302, train_loss_step=0.0143, train_loss_epoch=0.0132]Epoch 21: Train Loss = 0.014322309754788876\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=302, train_loss_step=0.0147, train_loss_epoch=0.0143]Epoch 22: Train Loss = 0.01472302433103323\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s, v_num=302, train_loss_step=0.0195, train_loss_epoch=0.0147]Epoch 23: Train Loss = 0.019470633938908577\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=302, train_loss_step=0.0114, train_loss_epoch=0.0195]Epoch 24: Train Loss = 0.011398082599043846\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=302, train_loss_step=0.0119, train_loss_epoch=0.0114]Epoch 25: Train Loss = 0.011912738904356956\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s, v_num=302, train_loss_step=0.0108, train_loss_epoch=0.0119]Epoch 26: Train Loss = 0.010780835524201393\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0108]Epoch 27: Train Loss = 0.012392238713800907\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=302, train_loss_step=0.0131, train_loss_epoch=0.0124]Epoch 28: Train Loss = 0.01311729196459055\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=302, train_loss_step=0.0151, train_loss_epoch=0.0131]Epoch 29: Train Loss = 0.015087229199707508\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=302, train_loss_step=0.0133, train_loss_epoch=0.0151]Epoch 30: Train Loss = 0.01329928357154131\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=302, train_loss_step=0.0157, train_loss_epoch=0.0133]Epoch 31: Train Loss = 0.01574433408677578\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s, v_num=302, train_loss_step=0.0149, train_loss_epoch=0.0157]Epoch 32: Train Loss = 0.014863541349768639\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=302, train_loss_step=0.014, train_loss_epoch=0.0149] Epoch 33: Train Loss = 0.014049557968974113\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=302, train_loss_step=0.0154, train_loss_epoch=0.014]Epoch 34: Train Loss = 0.015430330298841\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=302, train_loss_step=0.0162, train_loss_epoch=0.0154]Epoch 35: Train Loss = 0.016156120225787163\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=302, train_loss_step=0.0129, train_loss_epoch=0.0162]Epoch 36: Train Loss = 0.012943891808390617\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=302, train_loss_step=0.0112, train_loss_epoch=0.0129]Epoch 37: Train Loss = 0.011170805431902409\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=302, train_loss_step=0.0134, train_loss_epoch=0.0112]Epoch 38: Train Loss = 0.01335135567933321\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=302, train_loss_step=0.0149, train_loss_epoch=0.0134]Epoch 39: Train Loss = 0.01489140186458826\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=302, train_loss_step=0.0143, train_loss_epoch=0.0149]Epoch 40: Train Loss = 0.014314047060906887\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=302, train_loss_step=0.0109, train_loss_epoch=0.0143]Epoch 41: Train Loss = 0.010902715846896172\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=302, train_loss_step=0.0191, train_loss_epoch=0.0109]Epoch 42: Train Loss = 0.019072193652391434\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=302, train_loss_step=0.0126, train_loss_epoch=0.0191]Epoch 43: Train Loss = 0.012607855722308159\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=302, train_loss_step=0.0129, train_loss_epoch=0.0126]Epoch 44: Train Loss = 0.012853564694523811\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=302, train_loss_step=0.0139, train_loss_epoch=0.0129]Epoch 45: Train Loss = 0.0139232212677598\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s, v_num=302, train_loss_step=0.0226, train_loss_epoch=0.0139]Epoch 46: Train Loss = 0.02261563017964363\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=302, train_loss_step=0.0165, train_loss_epoch=0.0226]Epoch 47: Train Loss = 0.016460595652461052\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=302, train_loss_step=0.0112, train_loss_epoch=0.0165]Epoch 48: Train Loss = 0.01115618646144867\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s, v_num=302, train_loss_step=0.013, train_loss_epoch=0.0112] Epoch 49: Train Loss = 0.012972342781722546\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=302, train_loss_step=0.00901, train_loss_epoch=0.013]Epoch 50: Train Loss = 0.00901296641677618\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=302, train_loss_step=0.013, train_loss_epoch=0.00901]  Epoch 51: Train Loss = 0.013012969866394997\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.013]  Epoch 52: Train Loss = 0.010998298414051533\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=302, train_loss_step=0.0111, train_loss_epoch=0.011]Epoch 53: Train Loss = 0.011095494963228703\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=302, train_loss_step=0.0138, train_loss_epoch=0.0111]Epoch 54: Train Loss = 0.013764473609626293\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=302, train_loss_step=0.0148, train_loss_epoch=0.0138]Epoch 55: Train Loss = 0.014797640964388847\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=302, train_loss_step=0.0177, train_loss_epoch=0.0148]Epoch 56: Train Loss = 0.01774931140244007\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=302, train_loss_step=0.0136, train_loss_epoch=0.0177]Epoch 57: Train Loss = 0.013552160933613777\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=302, train_loss_step=0.0183, train_loss_epoch=0.0136]Epoch 58: Train Loss = 0.018335837870836258\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=302, train_loss_step=0.0167, train_loss_epoch=0.0183]Epoch 59: Train Loss = 0.016747383400797844\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=302, train_loss_step=0.0102, train_loss_epoch=0.0167]Epoch 60: Train Loss = 0.010234353132545948\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s, v_num=302, train_loss_step=0.0125, train_loss_epoch=0.0102]Epoch 61: Train Loss = 0.012490397319197655\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=302, train_loss_step=0.0129, train_loss_epoch=0.0125]Epoch 62: Train Loss = 0.012890816666185856\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=302, train_loss_step=0.0206, train_loss_epoch=0.0129]Epoch 63: Train Loss = 0.020633121952414513\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=302, train_loss_step=0.0129, train_loss_epoch=0.0206]Epoch 64: Train Loss = 0.012882547453045845\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=302, train_loss_step=0.0153, train_loss_epoch=0.0129]Epoch 65: Train Loss = 0.01528903841972351\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=302, train_loss_step=0.0211, train_loss_epoch=0.0153]Epoch 66: Train Loss = 0.021070299670100212\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s, v_num=302, train_loss_step=0.0169, train_loss_epoch=0.0211]Epoch 67: Train Loss = 0.016948675736784935\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.0169] Epoch 68: Train Loss = 0.01096141804009676\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=302, train_loss_step=0.0143, train_loss_epoch=0.011]Epoch 69: Train Loss = 0.014334222301840782\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=302, train_loss_step=0.0198, train_loss_epoch=0.0143]Epoch 70: Train Loss = 0.01976725459098816\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s, v_num=302, train_loss_step=0.0144, train_loss_epoch=0.0198]Epoch 71: Train Loss = 0.014448137953877449\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=302, train_loss_step=0.0133, train_loss_epoch=0.0144]Epoch 72: Train Loss = 0.013273377902805805\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=302, train_loss_step=0.0127, train_loss_epoch=0.0133]Epoch 73: Train Loss = 0.012731856666505337\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=302, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 74: Train Loss = 0.011978375725448132\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=302, train_loss_step=0.0145, train_loss_epoch=0.012]Epoch 75: Train Loss = 0.014500802382826805\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=302, train_loss_step=0.0158, train_loss_epoch=0.0145]Epoch 76: Train Loss = 0.015758642926812172\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=302, train_loss_step=0.0147, train_loss_epoch=0.0158]Epoch 77: Train Loss = 0.014741076156497002\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=302, train_loss_step=0.0122, train_loss_epoch=0.0147]Epoch 78: Train Loss = 0.01219857670366764\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=302, train_loss_step=0.0137, train_loss_epoch=0.0122]Epoch 79: Train Loss = 0.013721595518290997\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=302, train_loss_step=0.0165, train_loss_epoch=0.0137]Epoch 80: Train Loss = 0.016472510993480682\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=302, train_loss_step=0.0165, train_loss_epoch=0.0165]Epoch 81: Train Loss = 0.01650376245379448\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 11.22it/s, v_num=302, train_loss_step=0.0122, train_loss_epoch=0.0165]Epoch 82: Train Loss = 0.01219844352453947\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s, v_num=302, train_loss_step=0.014, train_loss_epoch=0.0122] Epoch 83: Train Loss = 0.014025362208485603\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s, v_num=302, train_loss_step=0.0157, train_loss_epoch=0.014]Epoch 84: Train Loss = 0.0156654454767704\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=302, train_loss_step=0.0145, train_loss_epoch=0.0157]Epoch 85: Train Loss = 0.014506964944303036\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=302, train_loss_step=0.0117, train_loss_epoch=0.0145]Epoch 86: Train Loss = 0.011724269948899746\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=302, train_loss_step=0.0198, train_loss_epoch=0.0117]Epoch 87: Train Loss = 0.01978221721947193\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=302, train_loss_step=0.014, train_loss_epoch=0.0198] Epoch 88: Train Loss = 0.013968980871140957\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=302, train_loss_step=0.017, train_loss_epoch=0.014] Epoch 89: Train Loss = 0.017020555213093758\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 11.55it/s, v_num=302, train_loss_step=0.0171, train_loss_epoch=0.017]Epoch 90: Train Loss = 0.01711113564670086\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.0171]Epoch 91: Train Loss = 0.01175652164965868\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=302, train_loss_step=0.015, train_loss_epoch=0.0118] Epoch 92: Train Loss = 0.0150135587900877\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, v_num=302, train_loss_step=0.0169, train_loss_epoch=0.015]Epoch 93: Train Loss = 0.016911622136831284\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 11.68it/s, v_num=302, train_loss_step=0.0129, train_loss_epoch=0.0169]Epoch 94: Train Loss = 0.012942557223141193\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, v_num=302, train_loss_step=0.0148, train_loss_epoch=0.0129]Epoch 95: Train Loss = 0.01479827705770731\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s, v_num=302, train_loss_step=0.0113, train_loss_epoch=0.0148]Epoch 96: Train Loss = 0.011349712498486042\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=302, train_loss_step=0.0103, train_loss_epoch=0.0113]Epoch 97: Train Loss = 0.010304917581379414\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.0103] Epoch 98: Train Loss = 0.010981475003063679\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=302, train_loss_step=0.0158, train_loss_epoch=0.011]Epoch 99: Train Loss = 0.015811221674084663\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=302, train_loss_step=0.0115, train_loss_epoch=0.0158]Epoch 100: Train Loss = 0.01145434845238924\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s, v_num=302, train_loss_step=0.0183, train_loss_epoch=0.0115]Epoch 101: Train Loss = 0.01831207051873207\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=302, train_loss_step=0.0105, train_loss_epoch=0.0183]Epoch 102: Train Loss = 0.010461317375302315\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=302, train_loss_step=0.0148, train_loss_epoch=0.0105]Epoch 103: Train Loss = 0.01475240383297205\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=302, train_loss_step=0.0167, train_loss_epoch=0.0148]Epoch 104: Train Loss = 0.01673858053982258\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=302, train_loss_step=0.0108, train_loss_epoch=0.0167]Epoch 105: Train Loss = 0.010754721239209175\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=302, train_loss_step=0.0147, train_loss_epoch=0.0108]Epoch 106: Train Loss = 0.014670774340629578\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.0147] Epoch 107: Train Loss = 0.010981572791934013\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=302, train_loss_step=0.0114, train_loss_epoch=0.011]Epoch 108: Train Loss = 0.01139351911842823\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=302, train_loss_step=0.013, train_loss_epoch=0.0114] Epoch 109: Train Loss = 0.012996361590921879\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=302, train_loss_step=0.0106, train_loss_epoch=0.013]Epoch 110: Train Loss = 0.01059070136398077\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.0106]Epoch 111: Train Loss = 0.011829808354377747\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, v_num=302, train_loss_step=0.0138, train_loss_epoch=0.0118]Epoch 112: Train Loss = 0.01375024113804102\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=302, train_loss_step=0.0121, train_loss_epoch=0.0138]Epoch 113: Train Loss = 0.012130639515817165\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=302, train_loss_step=0.0148, train_loss_epoch=0.0121]Epoch 114: Train Loss = 0.014813232235610485\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=302, train_loss_step=0.0175, train_loss_epoch=0.0148]Epoch 115: Train Loss = 0.01754077337682247\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s, v_num=302, train_loss_step=0.0149, train_loss_epoch=0.0175]Epoch 116: Train Loss = 0.014943527057766914\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=302, train_loss_step=0.0142, train_loss_epoch=0.0149]Epoch 117: Train Loss = 0.014173687435686588\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=302, train_loss_step=0.0111, train_loss_epoch=0.0142]Epoch 118: Train Loss = 0.011080100201070309\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.0111] Epoch 119: Train Loss = 0.011006823740899563\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=302, train_loss_step=0.0103, train_loss_epoch=0.011]Epoch 120: Train Loss = 0.01030244491994381\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=302, train_loss_step=0.0145, train_loss_epoch=0.0103]Epoch 121: Train Loss = 0.014495492912828922\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=302, train_loss_step=0.0115, train_loss_epoch=0.0145]Epoch 122: Train Loss = 0.01151574682444334\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=302, train_loss_step=0.0137, train_loss_epoch=0.0115]Epoch 123: Train Loss = 0.013723500072956085\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=302, train_loss_step=0.0142, train_loss_epoch=0.0137]Epoch 124: Train Loss = 0.014155508019030094\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=302, train_loss_step=0.0136, train_loss_epoch=0.0142]Epoch 125: Train Loss = 0.013612277805805206\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=302, train_loss_step=0.0115, train_loss_epoch=0.0136]Epoch 126: Train Loss = 0.01145788375288248\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=302, train_loss_step=0.0155, train_loss_epoch=0.0115]Epoch 127: Train Loss = 0.015547721646726131\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=302, train_loss_step=0.0173, train_loss_epoch=0.0155]Epoch 128: Train Loss = 0.017251621931791306\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=302, train_loss_step=0.0201, train_loss_epoch=0.0173]Epoch 129: Train Loss = 0.02009398490190506\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=302, train_loss_step=0.0157, train_loss_epoch=0.0201]Epoch 130: Train Loss = 0.0157062616199255\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=302, train_loss_step=0.0176, train_loss_epoch=0.0157]Epoch 131: Train Loss = 0.017612874507904053\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=302, train_loss_step=0.0138, train_loss_epoch=0.0176]Epoch 132: Train Loss = 0.013775495812296867\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=302, train_loss_step=0.0162, train_loss_epoch=0.0138]Epoch 133: Train Loss = 0.016193289309740067\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=302, train_loss_step=0.013, train_loss_epoch=0.0162] Epoch 134: Train Loss = 0.013039614073932171\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=302, train_loss_step=0.0141, train_loss_epoch=0.013]Epoch 135: Train Loss = 0.014096589758992195\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=302, train_loss_step=0.0167, train_loss_epoch=0.0141]Epoch 136: Train Loss = 0.016704196110367775\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=302, train_loss_step=0.016, train_loss_epoch=0.0167] Epoch 137: Train Loss = 0.01601211354136467\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=302, train_loss_step=0.0126, train_loss_epoch=0.016]Epoch 138: Train Loss = 0.012618020176887512\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=302, train_loss_step=0.0162, train_loss_epoch=0.0126]Epoch 139: Train Loss = 0.016173193231225014\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s, v_num=302, train_loss_step=0.0134, train_loss_epoch=0.0162]Epoch 140: Train Loss = 0.013406428508460522\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=302, train_loss_step=0.00979, train_loss_epoch=0.0134]Epoch 141: Train Loss = 0.009788437746465206\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=302, train_loss_step=0.0135, train_loss_epoch=0.00979] Epoch 142: Train Loss = 0.013501259498298168\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=302, train_loss_step=0.0113, train_loss_epoch=0.0135] Epoch 143: Train Loss = 0.011345838196575642\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=302, train_loss_step=0.0108, train_loss_epoch=0.0113]Epoch 144: Train Loss = 0.010815707966685295\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=302, train_loss_step=0.0127, train_loss_epoch=0.0108]Epoch 145: Train Loss = 0.012696011923253536\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=302, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 146: Train Loss = 0.012047993019223213\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.012]Epoch 147: Train Loss = 0.01184647623449564\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=302, train_loss_step=0.0109, train_loss_epoch=0.0118]Epoch 148: Train Loss = 0.010868874378502369\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=302, train_loss_step=0.0086, train_loss_epoch=0.0109]Epoch 149: Train Loss = 0.008595621213316917\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=302, train_loss_step=0.0104, train_loss_epoch=0.0086]Epoch 150: Train Loss = 0.01040415745228529\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=302, train_loss_step=0.0133, train_loss_epoch=0.0104]Epoch 151: Train Loss = 0.013266876339912415\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=302, train_loss_step=0.0108, train_loss_epoch=0.0133]Epoch 152: Train Loss = 0.010773925110697746\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=302, train_loss_step=0.0144, train_loss_epoch=0.0108]Epoch 153: Train Loss = 0.014378181658685207\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=302, train_loss_step=0.0131, train_loss_epoch=0.0144]Epoch 154: Train Loss = 0.013100172393023968\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=302, train_loss_step=0.0116, train_loss_epoch=0.0131]Epoch 155: Train Loss = 0.01155269704759121\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=302, train_loss_step=0.0104, train_loss_epoch=0.0116]Epoch 156: Train Loss = 0.010395511984825134\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=302, train_loss_step=0.0143, train_loss_epoch=0.0104]Epoch 157: Train Loss = 0.01426731888204813\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=302, train_loss_step=0.012, train_loss_epoch=0.0143] Epoch 158: Train Loss = 0.011957259848713875\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=302, train_loss_step=0.0125, train_loss_epoch=0.012]Epoch 159: Train Loss = 0.01251200120896101\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=302, train_loss_step=0.0253, train_loss_epoch=0.0125]Epoch 160: Train Loss = 0.025312842801213264\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=302, train_loss_step=0.0179, train_loss_epoch=0.0253]Epoch 161: Train Loss = 0.01792989857494831\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.0179]Epoch 162: Train Loss = 0.012822277843952179\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.0128]Epoch 163: Train Loss = 0.012784074060618877\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=302, train_loss_step=0.0157, train_loss_epoch=0.0128]Epoch 164: Train Loss = 0.015701133757829666\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=302, train_loss_step=0.0132, train_loss_epoch=0.0157]Epoch 165: Train Loss = 0.01320299506187439\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=302, train_loss_step=0.0149, train_loss_epoch=0.0132]Epoch 166: Train Loss = 0.014850945211946964\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s, v_num=302, train_loss_step=0.0123, train_loss_epoch=0.0149]Epoch 167: Train Loss = 0.012316552922129631\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=302, train_loss_step=0.0145, train_loss_epoch=0.0123]Epoch 168: Train Loss = 0.014467635191977024\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=302, train_loss_step=0.0138, train_loss_epoch=0.0145]Epoch 169: Train Loss = 0.013833480887115002\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=302, train_loss_step=0.0122, train_loss_epoch=0.0138]Epoch 170: Train Loss = 0.012151123024523258\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=302, train_loss_step=0.0107, train_loss_epoch=0.0122]Epoch 171: Train Loss = 0.010725411586463451\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=302, train_loss_step=0.00977, train_loss_epoch=0.0107]Epoch 172: Train Loss = 0.009772426448762417\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=302, train_loss_step=0.0167, train_loss_epoch=0.00977] Epoch 173: Train Loss = 0.016659507527947426\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=302, train_loss_step=0.00984, train_loss_epoch=0.0167]Epoch 174: Train Loss = 0.009843535721302032\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=302, train_loss_step=0.0134, train_loss_epoch=0.00984] Epoch 175: Train Loss = 0.013418157584965229\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=302, train_loss_step=0.00819, train_loss_epoch=0.0134]Epoch 176: Train Loss = 0.008190864697098732\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=302, train_loss_step=0.00887, train_loss_epoch=0.00819]Epoch 177: Train Loss = 0.008866031654179096\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=302, train_loss_step=0.0115, train_loss_epoch=0.00887] Epoch 178: Train Loss = 0.011514557525515556\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=302, train_loss_step=0.0109, train_loss_epoch=0.0115] Epoch 179: Train Loss = 0.010934632271528244\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=302, train_loss_step=0.0117, train_loss_epoch=0.0109]Epoch 180: Train Loss = 0.011720218695700169\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=302, train_loss_step=0.0168, train_loss_epoch=0.0117]Epoch 181: Train Loss = 0.01679684966802597\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=302, train_loss_step=0.0101, train_loss_epoch=0.0168]Epoch 182: Train Loss = 0.010076203383505344\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=302, train_loss_step=0.0114, train_loss_epoch=0.0101]Epoch 183: Train Loss = 0.011433825828135014\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=302, train_loss_step=0.0116, train_loss_epoch=0.0114]Epoch 184: Train Loss = 0.011615206487476826\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.0116] Epoch 185: Train Loss = 0.010995583608746529\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=302, train_loss_step=0.0129, train_loss_epoch=0.011]Epoch 186: Train Loss = 0.012870758771896362\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=302, train_loss_step=0.0135, train_loss_epoch=0.0129]Epoch 187: Train Loss = 0.013538815081119537\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=302, train_loss_step=0.0145, train_loss_epoch=0.0135]Epoch 188: Train Loss = 0.014467688277363777\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=302, train_loss_step=0.0116, train_loss_epoch=0.0145]Epoch 189: Train Loss = 0.011560595594346523\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.0116]Epoch 190: Train Loss = 0.011780411005020142\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=302, train_loss_step=0.0122, train_loss_epoch=0.0118]Epoch 191: Train Loss = 0.012181599624454975\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s, v_num=302, train_loss_step=0.0104, train_loss_epoch=0.0122]Epoch 192: Train Loss = 0.01036117784678936\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s, v_num=302, train_loss_step=0.0107, train_loss_epoch=0.0104]Epoch 193: Train Loss = 0.010742509737610817\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=302, train_loss_step=0.0132, train_loss_epoch=0.0107]Epoch 194: Train Loss = 0.013157131150364876\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=302, train_loss_step=0.014, train_loss_epoch=0.0132] Epoch 195: Train Loss = 0.013988135382533073\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=302, train_loss_step=0.00828, train_loss_epoch=0.014]Epoch 196: Train Loss = 0.008280215784907341\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s, v_num=302, train_loss_step=0.0136, train_loss_epoch=0.00828] Epoch 197: Train Loss = 0.013586044311523438\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=302, train_loss_step=0.00823, train_loss_epoch=0.0136]Epoch 198: Train Loss = 0.008231968618929386\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=302, train_loss_step=0.0144, train_loss_epoch=0.00823] Epoch 199: Train Loss = 0.014432170428335667\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=302, train_loss_step=0.0164, train_loss_epoch=0.0144] Epoch 200: Train Loss = 0.01643446274101734\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.0164]Epoch 201: Train Loss = 0.01284888293594122\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=302, train_loss_step=0.012, train_loss_epoch=0.0128] Epoch 202: Train Loss = 0.011986729688942432\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=302, train_loss_step=0.012, train_loss_epoch=0.012] Epoch 203: Train Loss = 0.011975322850048542\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=302, train_loss_step=0.0133, train_loss_epoch=0.012]Epoch 204: Train Loss = 0.013273762539029121\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=302, train_loss_step=0.0142, train_loss_epoch=0.0133]Epoch 205: Train Loss = 0.014243870973587036\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=302, train_loss_step=0.0176, train_loss_epoch=0.0142]Epoch 206: Train Loss = 0.01761331781744957\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=302, train_loss_step=0.0136, train_loss_epoch=0.0176]Epoch 207: Train Loss = 0.013584266416728497\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=302, train_loss_step=0.00905, train_loss_epoch=0.0136]Epoch 208: Train Loss = 0.009052089415490627\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.00905]  Epoch 209: Train Loss = 0.01095926109701395\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=302, train_loss_step=0.0125, train_loss_epoch=0.011] Epoch 210: Train Loss = 0.012480029836297035\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=302, train_loss_step=0.0112, train_loss_epoch=0.0125]Epoch 211: Train Loss = 0.011184538714587688\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=302, train_loss_step=0.0146, train_loss_epoch=0.0112]Epoch 212: Train Loss = 0.01464894600212574\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=302, train_loss_step=0.0115, train_loss_epoch=0.0146]Epoch 213: Train Loss = 0.011548406444489956\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=302, train_loss_step=0.0127, train_loss_epoch=0.0115]Epoch 214: Train Loss = 0.012735036201775074\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=302, train_loss_step=0.0103, train_loss_epoch=0.0127]Epoch 215: Train Loss = 0.010324863716959953\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=302, train_loss_step=0.0113, train_loss_epoch=0.0103]Epoch 216: Train Loss = 0.011330696754157543\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=302, train_loss_step=0.0132, train_loss_epoch=0.0113]Epoch 217: Train Loss = 0.013196575455367565\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.0132]Epoch 218: Train Loss = 0.012823641300201416\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=302, train_loss_step=0.0102, train_loss_epoch=0.0128]Epoch 219: Train Loss = 0.010151942260563374\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=302, train_loss_step=0.0103, train_loss_epoch=0.0102]Epoch 220: Train Loss = 0.010294392704963684\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=302, train_loss_step=0.0115, train_loss_epoch=0.0103]Epoch 221: Train Loss = 0.011505333706736565\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=302, train_loss_step=0.00877, train_loss_epoch=0.0115]Epoch 222: Train Loss = 0.008772483095526695\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=302, train_loss_step=0.0116, train_loss_epoch=0.00877] Epoch 223: Train Loss = 0.011628633365035057\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=302, train_loss_step=0.00905, train_loss_epoch=0.0116]Epoch 224: Train Loss = 0.009047398343682289\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=302, train_loss_step=0.0117, train_loss_epoch=0.00905] Epoch 225: Train Loss = 0.011688532307744026\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=302, train_loss_step=0.0131, train_loss_epoch=0.0117] Epoch 226: Train Loss = 0.013111344538629055\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=302, train_loss_step=0.0126, train_loss_epoch=0.0131]Epoch 227: Train Loss = 0.012629698030650616\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=302, train_loss_step=0.0127, train_loss_epoch=0.0126]Epoch 228: Train Loss = 0.012667296454310417\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=302, train_loss_step=0.0121, train_loss_epoch=0.0127]Epoch 229: Train Loss = 0.012109342031180859\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=302, train_loss_step=0.0139, train_loss_epoch=0.0121]Epoch 230: Train Loss = 0.013850444927811623\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=302, train_loss_step=0.0126, train_loss_epoch=0.0139]Epoch 231: Train Loss = 0.012580983340740204\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 10.72it/s, v_num=302, train_loss_step=0.00915, train_loss_epoch=0.0126]Epoch 232: Train Loss = 0.009152731858193874\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=302, train_loss_step=0.00888, train_loss_epoch=0.00915]Epoch 233: Train Loss = 0.008878279477357864\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=302, train_loss_step=0.013, train_loss_epoch=0.00888]  Epoch 234: Train Loss = 0.012985443696379662\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=302, train_loss_step=0.012, train_loss_epoch=0.013]  Epoch 235: Train Loss = 0.012045087292790413\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=302, train_loss_step=0.0131, train_loss_epoch=0.012]Epoch 236: Train Loss = 0.013101841323077679\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=302, train_loss_step=0.0115, train_loss_epoch=0.0131]Epoch 237: Train Loss = 0.01147706713527441\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=302, train_loss_step=0.0116, train_loss_epoch=0.0115]Epoch 238: Train Loss = 0.011590695008635521\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=302, train_loss_step=0.0139, train_loss_epoch=0.0116]Epoch 239: Train Loss = 0.013869764283299446\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=302, train_loss_step=0.0144, train_loss_epoch=0.0139]Epoch 240: Train Loss = 0.014394368045032024\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=302, train_loss_step=0.0102, train_loss_epoch=0.0144]Epoch 241: Train Loss = 0.010212267749011517\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=302, train_loss_step=0.0135, train_loss_epoch=0.0102]Epoch 242: Train Loss = 0.013455016538500786\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=302, train_loss_step=0.00968, train_loss_epoch=0.0135]Epoch 243: Train Loss = 0.009684608317911625\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=302, train_loss_step=0.0088, train_loss_epoch=0.00968] Epoch 244: Train Loss = 0.008798605762422085\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=302, train_loss_step=0.0119, train_loss_epoch=0.0088] Epoch 245: Train Loss = 0.011855949647724628\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=302, train_loss_step=0.0127, train_loss_epoch=0.0119]Epoch 246: Train Loss = 0.012738038785755634\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=302, train_loss_step=0.00998, train_loss_epoch=0.0127]Epoch 247: Train Loss = 0.009984112344682217\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=302, train_loss_step=0.0101, train_loss_epoch=0.00998] Epoch 248: Train Loss = 0.01008195523172617\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0101] Epoch 249: Train Loss = 0.012412759475409985\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=302, train_loss_step=0.0096, train_loss_epoch=0.0124]Epoch 250: Train Loss = 0.009597950614988804\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=302, train_loss_step=0.0106, train_loss_epoch=0.0096]Epoch 251: Train Loss = 0.010642885230481625\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.0106]Epoch 252: Train Loss = 0.011815131641924381\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=302, train_loss_step=0.0164, train_loss_epoch=0.0118]Epoch 253: Train Loss = 0.016414053738117218\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=302, train_loss_step=0.00866, train_loss_epoch=0.0164]Epoch 254: Train Loss = 0.008662385866045952\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 11.59it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.00866] Epoch 255: Train Loss = 0.012814427725970745\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s, v_num=302, train_loss_step=0.00884, train_loss_epoch=0.0128]Epoch 256: Train Loss = 0.00884238164871931\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.00884] Epoch 257: Train Loss = 0.012357087805867195\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=302, train_loss_step=0.0102, train_loss_epoch=0.0124] Epoch 258: Train Loss = 0.010190045461058617\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=302, train_loss_step=0.0143, train_loss_epoch=0.0102]Epoch 259: Train Loss = 0.014343800023198128\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=302, train_loss_step=0.0151, train_loss_epoch=0.0143]Epoch 260: Train Loss = 0.015118858776986599\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s, v_num=302, train_loss_step=0.0111, train_loss_epoch=0.0151]Epoch 261: Train Loss = 0.011078405193984509\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=302, train_loss_step=0.0114, train_loss_epoch=0.0111]Epoch 262: Train Loss = 0.011390553787350655\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=302, train_loss_step=0.0127, train_loss_epoch=0.0114]Epoch 263: Train Loss = 0.012700708582997322\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 11.12it/s, v_num=302, train_loss_step=0.0137, train_loss_epoch=0.0127]Epoch 264: Train Loss = 0.0136976707726717\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=302, train_loss_step=0.0111, train_loss_epoch=0.0137]Epoch 265: Train Loss = 0.01111338846385479\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=302, train_loss_step=0.00999, train_loss_epoch=0.0111]Epoch 266: Train Loss = 0.00999210961163044\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=302, train_loss_step=0.0154, train_loss_epoch=0.00999] Epoch 267: Train Loss = 0.015419756062328815\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=302, train_loss_step=0.0107, train_loss_epoch=0.0154] Epoch 268: Train Loss = 0.010708874091506004\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=302, train_loss_step=0.012, train_loss_epoch=0.0107] Epoch 269: Train Loss = 0.01198409590870142\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=302, train_loss_step=0.0126, train_loss_epoch=0.012]Epoch 270: Train Loss = 0.012642772868275642\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=302, train_loss_step=0.010, train_loss_epoch=0.0126] Epoch 271: Train Loss = 0.010008437559008598\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=302, train_loss_step=0.00978, train_loss_epoch=0.010]Epoch 272: Train Loss = 0.00977526605129242\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=302, train_loss_step=0.014, train_loss_epoch=0.00978]  Epoch 273: Train Loss = 0.01402932871133089\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=302, train_loss_step=0.0112, train_loss_epoch=0.014] Epoch 274: Train Loss = 0.011233268305659294\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=302, train_loss_step=0.0177, train_loss_epoch=0.0112]Epoch 275: Train Loss = 0.017700571566820145\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=302, train_loss_step=0.0143, train_loss_epoch=0.0177]Epoch 276: Train Loss = 0.01426185853779316\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=302, train_loss_step=0.0135, train_loss_epoch=0.0143]Epoch 277: Train Loss = 0.013495991006493568\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.0135]Epoch 278: Train Loss = 0.012756051495671272\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s, v_num=302, train_loss_step=0.0107, train_loss_epoch=0.0128]Epoch 279: Train Loss = 0.010687850415706635\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=302, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 280: Train Loss = 0.011563236825168133\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=302, train_loss_step=0.0119, train_loss_epoch=0.0116]Epoch 281: Train Loss = 0.011859147809445858\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.0119]Epoch 282: Train Loss = 0.012835042551159859\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=302, train_loss_step=0.0121, train_loss_epoch=0.0128]Epoch 283: Train Loss = 0.012108330614864826\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=302, train_loss_step=0.0119, train_loss_epoch=0.0121]Epoch 284: Train Loss = 0.011933057568967342\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s, v_num=302, train_loss_step=0.0144, train_loss_epoch=0.0119]Epoch 285: Train Loss = 0.014410830102860928\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.0144]Epoch 286: Train Loss = 0.012753878720104694\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=302, train_loss_step=0.0117, train_loss_epoch=0.0128]Epoch 287: Train Loss = 0.011666655540466309\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=302, train_loss_step=0.0112, train_loss_epoch=0.0117]Epoch 288: Train Loss = 0.011178507469594479\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=302, train_loss_step=0.0111, train_loss_epoch=0.0112]Epoch 289: Train Loss = 0.01110928039997816\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=302, train_loss_step=0.0107, train_loss_epoch=0.0111]Epoch 290: Train Loss = 0.010706812143325806\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=302, train_loss_step=0.0153, train_loss_epoch=0.0107]Epoch 291: Train Loss = 0.015347076579928398\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0153]Epoch 292: Train Loss = 0.01241221372038126\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=302, train_loss_step=0.0104, train_loss_epoch=0.0124]Epoch 293: Train Loss = 0.010351723060011864\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=302, train_loss_step=0.0159, train_loss_epoch=0.0104]Epoch 294: Train Loss = 0.015850001946091652\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.0159] Epoch 295: Train Loss = 0.010981046594679356\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=302, train_loss_step=0.0142, train_loss_epoch=0.011]Epoch 296: Train Loss = 0.014219383709132671\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=302, train_loss_step=0.012, train_loss_epoch=0.0142] Epoch 297: Train Loss = 0.011980821378529072\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=302, train_loss_step=0.0102, train_loss_epoch=0.012]Epoch 298: Train Loss = 0.010216020047664642\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=302, train_loss_step=0.0123, train_loss_epoch=0.0102]Epoch 299: Train Loss = 0.012340553104877472\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=302, train_loss_step=0.0114, train_loss_epoch=0.0123]Epoch 300: Train Loss = 0.011374919675290585\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s, v_num=302, train_loss_step=0.0139, train_loss_epoch=0.0114]Epoch 301: Train Loss = 0.013877545483410358\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=302, train_loss_step=0.0113, train_loss_epoch=0.0139]Epoch 302: Train Loss = 0.011282255873084068\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0113]Epoch 303: Train Loss = 0.012355832383036613\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.0124]Epoch 304: Train Loss = 0.011774612590670586\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=302, train_loss_step=0.00956, train_loss_epoch=0.0118]Epoch 305: Train Loss = 0.009561903774738312\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=302, train_loss_step=0.0172, train_loss_epoch=0.00956] Epoch 306: Train Loss = 0.0171698909252882\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.0172]  Epoch 307: Train Loss = 0.010989567264914513\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=302, train_loss_step=0.0103, train_loss_epoch=0.011]Epoch 308: Train Loss = 0.010312200523912907\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=302, train_loss_step=0.0111, train_loss_epoch=0.0103]Epoch 309: Train Loss = 0.011056406423449516\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=302, train_loss_step=0.0142, train_loss_epoch=0.0111]Epoch 310: Train Loss = 0.014210139401257038\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s, v_num=302, train_loss_step=0.0132, train_loss_epoch=0.0142]Epoch 311: Train Loss = 0.013177233748137951\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=302, train_loss_step=0.0108, train_loss_epoch=0.0132]Epoch 312: Train Loss = 0.010848612524569035\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0108]Epoch 313: Train Loss = 0.012432457879185677\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0124]Epoch 314: Train Loss = 0.01235644519329071\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=302, train_loss_step=0.00849, train_loss_epoch=0.0124]Epoch 315: Train Loss = 0.008492388762533665\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=302, train_loss_step=0.0114, train_loss_epoch=0.00849] Epoch 316: Train Loss = 0.01139095425605774\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=302, train_loss_step=0.0121, train_loss_epoch=0.0114] Epoch 317: Train Loss = 0.012053034268319607\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=302, train_loss_step=0.0169, train_loss_epoch=0.0121]Epoch 318: Train Loss = 0.016865793615579605\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=302, train_loss_step=0.0115, train_loss_epoch=0.0169]Epoch 319: Train Loss = 0.0115413349121809\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 10.28it/s, v_num=302, train_loss_step=0.0109, train_loss_epoch=0.0115]Epoch 320: Train Loss = 0.010900097899138927\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=302, train_loss_step=0.0119, train_loss_epoch=0.0109]Epoch 321: Train Loss = 0.01188736129552126\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s, v_num=302, train_loss_step=0.0136, train_loss_epoch=0.0119]Epoch 322: Train Loss = 0.013571850024163723\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=302, train_loss_step=0.0125, train_loss_epoch=0.0136]Epoch 323: Train Loss = 0.012457725591957569\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=302, train_loss_step=0.0105, train_loss_epoch=0.0125]Epoch 324: Train Loss = 0.010503766126930714\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=302, train_loss_step=0.014, train_loss_epoch=0.0105] Epoch 325: Train Loss = 0.014039656147360802\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=302, train_loss_step=0.00938, train_loss_epoch=0.014]Epoch 326: Train Loss = 0.00937535148113966\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=302, train_loss_step=0.0106, train_loss_epoch=0.00938] Epoch 327: Train Loss = 0.010597212240099907\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=302, train_loss_step=0.0101, train_loss_epoch=0.0106] Epoch 328: Train Loss = 0.01013894472271204\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=302, train_loss_step=0.0113, train_loss_epoch=0.0101]Epoch 329: Train Loss = 0.01129115279763937\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=302, train_loss_step=0.0148, train_loss_epoch=0.0113]Epoch 330: Train Loss = 0.014820525422692299\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.0148] Epoch 331: Train Loss = 0.011014495976269245\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=302, train_loss_step=0.0132, train_loss_epoch=0.011]Epoch 332: Train Loss = 0.013153165578842163\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=302, train_loss_step=0.00972, train_loss_epoch=0.0132]Epoch 333: Train Loss = 0.009717004373669624\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=302, train_loss_step=0.0155, train_loss_epoch=0.00972] Epoch 334: Train Loss = 0.015512474812567234\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=302, train_loss_step=0.00765, train_loss_epoch=0.0155]Epoch 335: Train Loss = 0.007650002837181091\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=302, train_loss_step=0.0156, train_loss_epoch=0.00765] Epoch 336: Train Loss = 0.015597207471728325\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=302, train_loss_step=0.00975, train_loss_epoch=0.0156]Epoch 337: Train Loss = 0.009751993231475353\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=302, train_loss_step=0.0105, train_loss_epoch=0.00975] Epoch 338: Train Loss = 0.010460716672241688\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=302, train_loss_step=0.0141, train_loss_epoch=0.0105] Epoch 339: Train Loss = 0.014059842564165592\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.0141]Epoch 340: Train Loss = 0.011815384030342102\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s, v_num=302, train_loss_step=0.0129, train_loss_epoch=0.0118]Epoch 341: Train Loss = 0.01286598015576601\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=302, train_loss_step=0.00987, train_loss_epoch=0.0129]Epoch 342: Train Loss = 0.009872854687273502\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.00987]  Epoch 343: Train Loss = 0.01099844928830862\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=302, train_loss_step=0.0101, train_loss_epoch=0.011] Epoch 344: Train Loss = 0.010105662047863007\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=302, train_loss_step=0.0111, train_loss_epoch=0.0101]Epoch 345: Train Loss = 0.011144584976136684\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=302, train_loss_step=0.0116, train_loss_epoch=0.0111]Epoch 346: Train Loss = 0.011627057567238808\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=302, train_loss_step=0.00995, train_loss_epoch=0.0116]Epoch 347: Train Loss = 0.00994789693504572\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=302, train_loss_step=0.0107, train_loss_epoch=0.00995] Epoch 348: Train Loss = 0.010742025449872017\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=302, train_loss_step=0.0131, train_loss_epoch=0.0107] Epoch 349: Train Loss = 0.013068093918263912\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=302, train_loss_step=0.0106, train_loss_epoch=0.0131]Epoch 350: Train Loss = 0.010635966435074806\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=302, train_loss_step=0.0108, train_loss_epoch=0.0106]Epoch 351: Train Loss = 0.010807962156832218\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=302, train_loss_step=0.0101, train_loss_epoch=0.0108]Epoch 352: Train Loss = 0.010144857689738274\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=302, train_loss_step=0.0121, train_loss_epoch=0.0101]Epoch 353: Train Loss = 0.012121200561523438\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.0121]Epoch 354: Train Loss = 0.011806635186076164\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 10.24it/s, v_num=302, train_loss_step=0.0117, train_loss_epoch=0.0118]Epoch 355: Train Loss = 0.011701433919370174\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=302, train_loss_step=0.0125, train_loss_epoch=0.0117]Epoch 356: Train Loss = 0.012514702044427395\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=302, train_loss_step=0.0101, train_loss_epoch=0.0125]Epoch 357: Train Loss = 0.010051215067505836\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=302, train_loss_step=0.0125, train_loss_epoch=0.0101]Epoch 358: Train Loss = 0.01254072692245245\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=302, train_loss_step=0.0136, train_loss_epoch=0.0125]Epoch 359: Train Loss = 0.013611276634037495\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=302, train_loss_step=0.0129, train_loss_epoch=0.0136]Epoch 360: Train Loss = 0.012906434014439583\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=302, train_loss_step=0.0135, train_loss_epoch=0.0129]Epoch 361: Train Loss = 0.01352973747998476\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=302, train_loss_step=0.0156, train_loss_epoch=0.0135]Epoch 362: Train Loss = 0.01556401513516903\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=302, train_loss_step=0.0168, train_loss_epoch=0.0156]Epoch 363: Train Loss = 0.016753045842051506\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=302, train_loss_step=0.0121, train_loss_epoch=0.0168]Epoch 364: Train Loss = 0.012090570293366909\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0121]Epoch 365: Train Loss = 0.012368917465209961\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=302, train_loss_step=0.010, train_loss_epoch=0.0124] Epoch 366: Train Loss = 0.010027655400335789\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=302, train_loss_step=0.0123, train_loss_epoch=0.010]Epoch 367: Train Loss = 0.012276986613869667\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=302, train_loss_step=0.0133, train_loss_epoch=0.0123]Epoch 368: Train Loss = 0.01325463317334652\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=302, train_loss_step=0.0117, train_loss_epoch=0.0133]Epoch 369: Train Loss = 0.011707750149071217\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=302, train_loss_step=0.018, train_loss_epoch=0.0117] Epoch 370: Train Loss = 0.0179890226572752\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=302, train_loss_step=0.0163, train_loss_epoch=0.018]Epoch 371: Train Loss = 0.016348788514733315\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 11.47it/s, v_num=302, train_loss_step=0.0136, train_loss_epoch=0.0163]Epoch 372: Train Loss = 0.01364580076187849\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=302, train_loss_step=0.00963, train_loss_epoch=0.0136]Epoch 373: Train Loss = 0.009628606028854847\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=302, train_loss_step=0.0096, train_loss_epoch=0.00963] Epoch 374: Train Loss = 0.00959891639649868\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=302, train_loss_step=0.0132, train_loss_epoch=0.0096] Epoch 375: Train Loss = 0.013226242735981941\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=302, train_loss_step=0.0109, train_loss_epoch=0.0132]Epoch 376: Train Loss = 0.010918746702373028\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=302, train_loss_step=0.0125, train_loss_epoch=0.0109]Epoch 377: Train Loss = 0.01251869648694992\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=302, train_loss_step=0.00959, train_loss_epoch=0.0125]Epoch 378: Train Loss = 0.00958891212940216\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, v_num=302, train_loss_step=0.00994, train_loss_epoch=0.00959]Epoch 379: Train Loss = 0.00994470901787281\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=302, train_loss_step=0.0131, train_loss_epoch=0.00994] Epoch 380: Train Loss = 0.013059532269835472\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 12.81it/s, v_num=302, train_loss_step=0.010, train_loss_epoch=0.0131]  Epoch 381: Train Loss = 0.010046930983662605\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=302, train_loss_step=0.0117, train_loss_epoch=0.010]Epoch 382: Train Loss = 0.01173524558544159\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=302, train_loss_step=0.0193, train_loss_epoch=0.0117]Epoch 383: Train Loss = 0.019252438098192215\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=302, train_loss_step=0.0126, train_loss_epoch=0.0193]Epoch 384: Train Loss = 0.012637550942599773\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=302, train_loss_step=0.0112, train_loss_epoch=0.0126]Epoch 385: Train Loss = 0.011202028952538967\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=302, train_loss_step=0.00956, train_loss_epoch=0.0112]Epoch 386: Train Loss = 0.009558198042213917\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=302, train_loss_step=0.0126, train_loss_epoch=0.00956] Epoch 387: Train Loss = 0.01259425189346075\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=302, train_loss_step=0.00873, train_loss_epoch=0.0126]Epoch 388: Train Loss = 0.00873380247503519\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.00873] Epoch 389: Train Loss = 0.011792508885264397\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=302, train_loss_step=0.0179, train_loss_epoch=0.0118] Epoch 390: Train Loss = 0.01786993257701397\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.0179]Epoch 391: Train Loss = 0.012844217009842396\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=302, train_loss_step=0.00957, train_loss_epoch=0.0128]Epoch 392: Train Loss = 0.009571014903485775\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 10.51it/s, v_num=302, train_loss_step=0.0112, train_loss_epoch=0.00957] Epoch 393: Train Loss = 0.011249071918427944\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=302, train_loss_step=0.0111, train_loss_epoch=0.0112] Epoch 394: Train Loss = 0.011072969995439053\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=302, train_loss_step=0.0151, train_loss_epoch=0.0111]Epoch 395: Train Loss = 0.015099985525012016\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=302, train_loss_step=0.0103, train_loss_epoch=0.0151]Epoch 396: Train Loss = 0.010250297375023365\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=302, train_loss_step=0.0113, train_loss_epoch=0.0103]Epoch 397: Train Loss = 0.011323249898850918\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=302, train_loss_step=0.0115, train_loss_epoch=0.0113]Epoch 398: Train Loss = 0.011503258720040321\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=302, train_loss_step=0.0125, train_loss_epoch=0.0115]Epoch 399: Train Loss = 0.012472023256123066\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=302, train_loss_step=0.0147, train_loss_epoch=0.0125]Epoch 400: Train Loss = 0.014683744870126247\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0147]Epoch 401: Train Loss = 0.01242902036756277\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s, v_num=302, train_loss_step=0.0101, train_loss_epoch=0.0124]Epoch 402: Train Loss = 0.01012449897825718\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=302, train_loss_step=0.0115, train_loss_epoch=0.0101]Epoch 403: Train Loss = 0.011475248262286186\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=302, train_loss_step=0.0153, train_loss_epoch=0.0115]Epoch 404: Train Loss = 0.015294765122234821\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=302, train_loss_step=0.0122, train_loss_epoch=0.0153]Epoch 405: Train Loss = 0.012152120471000671\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, v_num=302, train_loss_step=0.0111, train_loss_epoch=0.0122]Epoch 406: Train Loss = 0.011146330274641514\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=302, train_loss_step=0.0137, train_loss_epoch=0.0111]Epoch 407: Train Loss = 0.013699600473046303\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=302, train_loss_step=0.0148, train_loss_epoch=0.0137]Epoch 408: Train Loss = 0.01475604623556137\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=302, train_loss_step=0.0138, train_loss_epoch=0.0148]Epoch 409: Train Loss = 0.013815530575811863\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=302, train_loss_step=0.00952, train_loss_epoch=0.0138]Epoch 410: Train Loss = 0.009523751214146614\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=302, train_loss_step=0.011, train_loss_epoch=0.00952]  Epoch 411: Train Loss = 0.010993769392371178\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=302, train_loss_step=0.0122, train_loss_epoch=0.011] Epoch 412: Train Loss = 0.012165402062237263\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=302, train_loss_step=0.0131, train_loss_epoch=0.0122]Epoch 413: Train Loss = 0.013070312328636646\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s, v_num=302, train_loss_step=0.0111, train_loss_epoch=0.0131]Epoch 414: Train Loss = 0.011108790524303913\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=302, train_loss_step=0.0105, train_loss_epoch=0.0111]Epoch 415: Train Loss = 0.010492099449038506\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=302, train_loss_step=0.0142, train_loss_epoch=0.0105]Epoch 416: Train Loss = 0.014196171425282955\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0142]Epoch 417: Train Loss = 0.012399828992784023\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=302, train_loss_step=0.00866, train_loss_epoch=0.0124]Epoch 418: Train Loss = 0.008656308054924011\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=302, train_loss_step=0.0143, train_loss_epoch=0.00866] Epoch 419: Train Loss = 0.01432033907622099\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=302, train_loss_step=0.00952, train_loss_epoch=0.0143]Epoch 420: Train Loss = 0.009523170068860054\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=302, train_loss_step=0.013, train_loss_epoch=0.00952]  Epoch 421: Train Loss = 0.013004942797124386\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=302, train_loss_step=0.00889, train_loss_epoch=0.013]Epoch 422: Train Loss = 0.008889437653124332\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=302, train_loss_step=0.0102, train_loss_epoch=0.00889] Epoch 423: Train Loss = 0.01019456796348095\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=302, train_loss_step=0.00989, train_loss_epoch=0.0102]Epoch 424: Train Loss = 0.009889872744679451\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=302, train_loss_step=0.0129, train_loss_epoch=0.00989] Epoch 425: Train Loss = 0.012931383214890957\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=302, train_loss_step=0.0116, train_loss_epoch=0.0129] Epoch 426: Train Loss = 0.011590832844376564\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=302, train_loss_step=0.00909, train_loss_epoch=0.0116]Epoch 427: Train Loss = 0.009086303412914276\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=302, train_loss_step=0.0113, train_loss_epoch=0.00909] Epoch 428: Train Loss = 0.011307199485599995\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=302, train_loss_step=0.0119, train_loss_epoch=0.0113] Epoch 429: Train Loss = 0.011942530050873756\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s, v_num=302, train_loss_step=0.0145, train_loss_epoch=0.0119]Epoch 430: Train Loss = 0.014547154307365417\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=302, train_loss_step=0.019, train_loss_epoch=0.0145] Epoch 431: Train Loss = 0.019029568880796432\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=302, train_loss_step=0.0106, train_loss_epoch=0.019]Epoch 432: Train Loss = 0.010614553466439247\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=302, train_loss_step=0.0108, train_loss_epoch=0.0106]Epoch 433: Train Loss = 0.010822438634932041\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=302, train_loss_step=0.0127, train_loss_epoch=0.0108]Epoch 434: Train Loss = 0.012678644619882107\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=302, train_loss_step=0.0114, train_loss_epoch=0.0127]Epoch 435: Train Loss = 0.011357937939465046\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s, v_num=302, train_loss_step=0.00971, train_loss_epoch=0.0114]Epoch 436: Train Loss = 0.009713337756693363\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s, v_num=302, train_loss_step=0.0109, train_loss_epoch=0.00971] Epoch 437: Train Loss = 0.010884643532335758\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=302, train_loss_step=0.00941, train_loss_epoch=0.0109]Epoch 438: Train Loss = 0.009411935694515705\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=302, train_loss_step=0.010, train_loss_epoch=0.00941]  Epoch 439: Train Loss = 0.010041164234280586\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=302, train_loss_step=0.0108, train_loss_epoch=0.010] Epoch 440: Train Loss = 0.010774349793791771\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=302, train_loss_step=0.0163, train_loss_epoch=0.0108]Epoch 441: Train Loss = 0.016268543899059296\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=302, train_loss_step=0.00974, train_loss_epoch=0.0163]Epoch 442: Train Loss = 0.00974466186016798\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=302, train_loss_step=0.0113, train_loss_epoch=0.00974] Epoch 443: Train Loss = 0.01126226969063282\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=302, train_loss_step=0.0121, train_loss_epoch=0.0113] Epoch 444: Train Loss = 0.012093360535800457\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=302, train_loss_step=0.0121, train_loss_epoch=0.0121]Epoch 445: Train Loss = 0.012081357650458813\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=302, train_loss_step=0.0161, train_loss_epoch=0.0121]Epoch 446: Train Loss = 0.016126388683915138\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, v_num=302, train_loss_step=0.0151, train_loss_epoch=0.0161]Epoch 447: Train Loss = 0.015069526620209217\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 11.27it/s, v_num=302, train_loss_step=0.0119, train_loss_epoch=0.0151]Epoch 448: Train Loss = 0.011850997805595398\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=302, train_loss_step=0.0147, train_loss_epoch=0.0119]Epoch 449: Train Loss = 0.014735819771885872\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=302, train_loss_step=0.0116, train_loss_epoch=0.0147]Epoch 450: Train Loss = 0.011591215617954731\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=302, train_loss_step=0.00996, train_loss_epoch=0.0116]Epoch 451: Train Loss = 0.009961781091988087\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=302, train_loss_step=0.0102, train_loss_epoch=0.00996] Epoch 452: Train Loss = 0.010178327560424805\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=302, train_loss_step=0.0107, train_loss_epoch=0.0102] Epoch 453: Train Loss = 0.01065274141728878\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=302, train_loss_step=0.013, train_loss_epoch=0.0107] Epoch 454: Train Loss = 0.013032058253884315\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=302, train_loss_step=0.0128, train_loss_epoch=0.013]Epoch 455: Train Loss = 0.012766159139573574\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=302, train_loss_step=0.0126, train_loss_epoch=0.0128]Epoch 456: Train Loss = 0.012619748711585999\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=302, train_loss_step=0.0135, train_loss_epoch=0.0126]Epoch 457: Train Loss = 0.013533714227378368\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=302, train_loss_step=0.00906, train_loss_epoch=0.0135]Epoch 458: Train Loss = 0.009063854813575745\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=302, train_loss_step=0.0114, train_loss_epoch=0.00906] Epoch 459: Train Loss = 0.011353851296007633\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=302, train_loss_step=0.0142, train_loss_epoch=0.0114] Epoch 460: Train Loss = 0.014234373345971107\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=302, train_loss_step=0.00918, train_loss_epoch=0.0142]Epoch 461: Train Loss = 0.00918134581297636\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.00918] Epoch 462: Train Loss = 0.011836553923785686\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=302, train_loss_step=0.0132, train_loss_epoch=0.0118] Epoch 463: Train Loss = 0.013216943480074406\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, v_num=302, train_loss_step=0.0155, train_loss_epoch=0.0132]Epoch 464: Train Loss = 0.015498296357691288\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=302, train_loss_step=0.0123, train_loss_epoch=0.0155]Epoch 465: Train Loss = 0.012338287197053432\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=302, train_loss_step=0.0118, train_loss_epoch=0.0123]Epoch 466: Train Loss = 0.011821778491139412\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=302, train_loss_step=0.0166, train_loss_epoch=0.0118]Epoch 467: Train Loss = 0.016618097200989723\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s, v_num=302, train_loss_step=0.0102, train_loss_epoch=0.0166]Epoch 468: Train Loss = 0.01017493475228548\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=302, train_loss_step=0.0116, train_loss_epoch=0.0102]Epoch 469: Train Loss = 0.011566194705665112\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=302, train_loss_step=0.00969, train_loss_epoch=0.0116]Epoch 470: Train Loss = 0.009685590863227844\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=302, train_loss_step=0.0101, train_loss_epoch=0.00969] Epoch 471: Train Loss = 0.010062013752758503\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=302, train_loss_step=0.0164, train_loss_epoch=0.0101] Epoch 472: Train Loss = 0.016426246613264084\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=302, train_loss_step=0.00793, train_loss_epoch=0.0164]Epoch 473: Train Loss = 0.007928616367280483\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s, v_num=302, train_loss_step=0.0103, train_loss_epoch=0.00793] Epoch 474: Train Loss = 0.010276230983436108\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=302, train_loss_step=0.0104, train_loss_epoch=0.0103] Epoch 475: Train Loss = 0.010392089374363422\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=302, train_loss_step=0.0108, train_loss_epoch=0.0104]Epoch 476: Train Loss = 0.010836350731551647\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=302, train_loss_step=0.010, train_loss_epoch=0.0108] Epoch 477: Train Loss = 0.010042950510978699\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=302, train_loss_step=0.0119, train_loss_epoch=0.010]Epoch 478: Train Loss = 0.011944293975830078\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=302, train_loss_step=0.0139, train_loss_epoch=0.0119]Epoch 479: Train Loss = 0.013914345763623714\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=302, train_loss_step=0.0146, train_loss_epoch=0.0139]Epoch 480: Train Loss = 0.014575392007827759\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=302, train_loss_step=0.0174, train_loss_epoch=0.0146]Epoch 481: Train Loss = 0.017428947612643242\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=302, train_loss_step=0.0155, train_loss_epoch=0.0174]Epoch 482: Train Loss = 0.015484834089875221\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 11.34it/s, v_num=302, train_loss_step=0.0105, train_loss_epoch=0.0155]Epoch 483: Train Loss = 0.010527217760682106\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 11.20it/s, v_num=302, train_loss_step=0.0123, train_loss_epoch=0.0105]Epoch 484: Train Loss = 0.012254181317985058\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=302, train_loss_step=0.0114, train_loss_epoch=0.0123]Epoch 485: Train Loss = 0.011432292871177197\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=302, train_loss_step=0.0126, train_loss_epoch=0.0114]Epoch 486: Train Loss = 0.012616102583706379\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=302, train_loss_step=0.0122, train_loss_epoch=0.0126]Epoch 487: Train Loss = 0.012161248363554478\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=302, train_loss_step=0.00961, train_loss_epoch=0.0122]Epoch 488: Train Loss = 0.009605576284229755\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=302, train_loss_step=0.0103, train_loss_epoch=0.00961] Epoch 489: Train Loss = 0.010263556614518166\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=302, train_loss_step=0.00998, train_loss_epoch=0.0103]Epoch 490: Train Loss = 0.009980002418160439\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  9.42it/s, v_num=302, train_loss_step=0.0112, train_loss_epoch=0.00998] Epoch 491: Train Loss = 0.011219614185392857\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s, v_num=302, train_loss_step=0.0151, train_loss_epoch=0.0112] Epoch 492: Train Loss = 0.015111343003809452\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=302, train_loss_step=0.012, train_loss_epoch=0.0151] Epoch 493: Train Loss = 0.012037484906613827\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s, v_num=302, train_loss_step=0.00872, train_loss_epoch=0.012]Epoch 494: Train Loss = 0.008718917146325111\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=302, train_loss_step=0.0117, train_loss_epoch=0.00872] Epoch 495: Train Loss = 0.011662701144814491\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=302, train_loss_step=0.0131, train_loss_epoch=0.0117] Epoch 496: Train Loss = 0.013079183176159859\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=302, train_loss_step=0.0146, train_loss_epoch=0.0131]Epoch 497: Train Loss = 0.014596273191273212\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=302, train_loss_step=0.0151, train_loss_epoch=0.0146]Epoch 498: Train Loss = 0.01510119903832674\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0151]Epoch 499: Train Loss = 0.012387269176542759\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0124]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=302, train_loss_step=0.0124, train_loss_epoch=0.0124]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 4: from 2010-06-30 00:00:00 to 2022-07-29 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=306, train_loss_step=0.029]Epoch 0: Train Loss = 0.02901441417634487\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=306, train_loss_step=0.042, train_loss_epoch=0.029]Epoch 1: Train Loss = 0.0420110784471035\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=306, train_loss_step=0.0272, train_loss_epoch=0.042]Epoch 2: Train Loss = 0.02719896100461483\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=306, train_loss_step=0.0219, train_loss_epoch=0.0272]Epoch 3: Train Loss = 0.021869048476219177\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=306, train_loss_step=0.0213, train_loss_epoch=0.0219]Epoch 4: Train Loss = 0.021340226754546165\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=306, train_loss_step=0.0184, train_loss_epoch=0.0213]Epoch 5: Train Loss = 0.0184068251401186\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=306, train_loss_step=0.0142, train_loss_epoch=0.0184]Epoch 6: Train Loss = 0.014247567392885685\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=306, train_loss_step=0.0149, train_loss_epoch=0.0142]Epoch 7: Train Loss = 0.014862005598843098\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=306, train_loss_step=0.0167, train_loss_epoch=0.0149]Epoch 8: Train Loss = 0.016706107184290886\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=306, train_loss_step=0.020, train_loss_epoch=0.0167] Epoch 9: Train Loss = 0.020048197358846664\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.020]Epoch 10: Train Loss = 0.0142965167760849\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0143]Epoch 11: Train Loss = 0.012410965748131275\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=306, train_loss_step=0.0166, train_loss_epoch=0.0124]Epoch 12: Train Loss = 0.01662297360599041\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=306, train_loss_step=0.0165, train_loss_epoch=0.0166]Epoch 13: Train Loss = 0.01648111268877983\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=306, train_loss_step=0.0132, train_loss_epoch=0.0165]Epoch 14: Train Loss = 0.013225325383245945\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.0132]Epoch 15: Train Loss = 0.013130898587405682\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=306, train_loss_step=0.0126, train_loss_epoch=0.0131]Epoch 16: Train Loss = 0.012611047364771366\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=306, train_loss_step=0.0144, train_loss_epoch=0.0126]Epoch 17: Train Loss = 0.014389176853001118\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=306, train_loss_step=0.0167, train_loss_epoch=0.0144]Epoch 18: Train Loss = 0.016671160236001015\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.0167]Epoch 19: Train Loss = 0.01309988833963871\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=306, train_loss_step=0.0133, train_loss_epoch=0.0131]Epoch 20: Train Loss = 0.013310679234564304\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=306, train_loss_step=0.0123, train_loss_epoch=0.0133]Epoch 21: Train Loss = 0.012269596569240093\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 10.30it/s, v_num=306, train_loss_step=0.0139, train_loss_epoch=0.0123]Epoch 22: Train Loss = 0.013940825127065182\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.0139]Epoch 23: Train Loss = 0.012829458341002464\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=306, train_loss_step=0.0132, train_loss_epoch=0.0128]Epoch 24: Train Loss = 0.013198127038776875\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=306, train_loss_step=0.0119, train_loss_epoch=0.0132]Epoch 25: Train Loss = 0.011908294633030891\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, v_num=306, train_loss_step=0.0166, train_loss_epoch=0.0119]Epoch 26: Train Loss = 0.016609763726592064\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=306, train_loss_step=0.0149, train_loss_epoch=0.0166]Epoch 27: Train Loss = 0.014861996285617352\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=306, train_loss_step=0.0142, train_loss_epoch=0.0149]Epoch 28: Train Loss = 0.014215372502803802\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=306, train_loss_step=0.0132, train_loss_epoch=0.0142]Epoch 29: Train Loss = 0.013164231553673744\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=306, train_loss_step=0.0109, train_loss_epoch=0.0132]Epoch 30: Train Loss = 0.010876861400902271\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=306, train_loss_step=0.0157, train_loss_epoch=0.0109]Epoch 31: Train Loss = 0.01565868966281414\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.0157]Epoch 32: Train Loss = 0.012180112302303314\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=306, train_loss_step=0.0139, train_loss_epoch=0.0122]Epoch 33: Train Loss = 0.013914232142269611\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=306, train_loss_step=0.014, train_loss_epoch=0.0139] Epoch 34: Train Loss = 0.013980141840875149\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=306, train_loss_step=0.0171, train_loss_epoch=0.014]Epoch 35: Train Loss = 0.017051050439476967\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=306, train_loss_step=0.0137, train_loss_epoch=0.0171]Epoch 36: Train Loss = 0.013673637993633747\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=306, train_loss_step=0.0165, train_loss_epoch=0.0137]Epoch 37: Train Loss = 0.016498547047376633\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=306, train_loss_step=0.016, train_loss_epoch=0.0165] Epoch 38: Train Loss = 0.016048267483711243\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.016]Epoch 39: Train Loss = 0.012945772148668766\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=306, train_loss_step=0.0142, train_loss_epoch=0.0129]Epoch 40: Train Loss = 0.014183375053107738\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.0142]Epoch 41: Train Loss = 0.012239699251949787\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 11.12it/s, v_num=306, train_loss_step=0.0121, train_loss_epoch=0.0122]Epoch 42: Train Loss = 0.012113711796700954\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=306, train_loss_step=0.0136, train_loss_epoch=0.0121]Epoch 43: Train Loss = 0.013591145165264606\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0136]Epoch 44: Train Loss = 0.012933689169585705\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s, v_num=306, train_loss_step=0.0135, train_loss_epoch=0.0129]Epoch 45: Train Loss = 0.013529889285564423\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.0135]Epoch 46: Train Loss = 0.014264695346355438\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=306, train_loss_step=0.0108, train_loss_epoch=0.0143]Epoch 47: Train Loss = 0.010794836096465588\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=306, train_loss_step=0.0134, train_loss_epoch=0.0108]Epoch 48: Train Loss = 0.013407622464001179\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=306, train_loss_step=0.012, train_loss_epoch=0.0134] Epoch 49: Train Loss = 0.0119853550568223\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=306, train_loss_step=0.0148, train_loss_epoch=0.012]Epoch 50: Train Loss = 0.014831110835075378\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.0148]Epoch 51: Train Loss = 0.014346749521791935\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.0143]Epoch 52: Train Loss = 0.014339504763484001\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=306, train_loss_step=0.0105, train_loss_epoch=0.0143]Epoch 53: Train Loss = 0.010497191920876503\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0105]Epoch 54: Train Loss = 0.012898311950266361\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0129]Epoch 55: Train Loss = 0.012903661467134953\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=306, train_loss_step=0.0127, train_loss_epoch=0.0129]Epoch 56: Train Loss = 0.01266790647059679\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.0127] Epoch 57: Train Loss = 0.010983407497406006\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.011]Epoch 58: Train Loss = 0.011216486804187298\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=306, train_loss_step=0.0137, train_loss_epoch=0.0112]Epoch 59: Train Loss = 0.013733272440731525\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=306, train_loss_step=0.0113, train_loss_epoch=0.0137]Epoch 60: Train Loss = 0.011321811005473137\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=306, train_loss_step=0.0115, train_loss_epoch=0.0113]Epoch 61: Train Loss = 0.011469264514744282\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=306, train_loss_step=0.0106, train_loss_epoch=0.0115]Epoch 62: Train Loss = 0.010583826340734959\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=306, train_loss_step=0.0171, train_loss_epoch=0.0106]Epoch 63: Train Loss = 0.017104152590036392\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=306, train_loss_step=0.0154, train_loss_epoch=0.0171]Epoch 64: Train Loss = 0.015439595095813274\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s, v_num=306, train_loss_step=0.0184, train_loss_epoch=0.0154]Epoch 65: Train Loss = 0.018388496711850166\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=306, train_loss_step=0.0175, train_loss_epoch=0.0184]Epoch 66: Train Loss = 0.01753298006951809\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.0175] Epoch 67: Train Loss = 0.011015413329005241\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=306, train_loss_step=0.0165, train_loss_epoch=0.011]Epoch 68: Train Loss = 0.016451390460133553\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=306, train_loss_step=0.0185, train_loss_epoch=0.0165]Epoch 69: Train Loss = 0.01848236471414566\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=306, train_loss_step=0.019, train_loss_epoch=0.0185] Epoch 70: Train Loss = 0.019003719091415405\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=306, train_loss_step=0.012, train_loss_epoch=0.019] Epoch 71: Train Loss = 0.012026311829686165\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=306, train_loss_step=0.0136, train_loss_epoch=0.012]Epoch 72: Train Loss = 0.013586124405264854\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=306, train_loss_step=0.012, train_loss_epoch=0.0136] Epoch 73: Train Loss = 0.012017041444778442\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=306, train_loss_step=0.0125, train_loss_epoch=0.012]Epoch 74: Train Loss = 0.012523402459919453\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=306, train_loss_step=0.017, train_loss_epoch=0.0125] Epoch 75: Train Loss = 0.017019428312778473\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.017]Epoch 76: Train Loss = 0.011194733902812004\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.0112]Epoch 77: Train Loss = 0.012843758799135685\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0128]Epoch 78: Train Loss = 0.011645653285086155\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=306, train_loss_step=0.0133, train_loss_epoch=0.0116]Epoch 79: Train Loss = 0.013250117190182209\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=306, train_loss_step=0.0118, train_loss_epoch=0.0133]Epoch 80: Train Loss = 0.011849379166960716\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.0118]Epoch 81: Train Loss = 0.013067280873656273\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=306, train_loss_step=0.014, train_loss_epoch=0.0131] Epoch 82: Train Loss = 0.014001772738993168\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.014]Epoch 83: Train Loss = 0.012770059518516064\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.0128]Epoch 84: Train Loss = 0.012206451036036015\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=306, train_loss_step=0.013, train_loss_epoch=0.0122] Epoch 85: Train Loss = 0.012994108721613884\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.013]Epoch 86: Train Loss = 0.013128883205354214\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=306, train_loss_step=0.0141, train_loss_epoch=0.0131]Epoch 87: Train Loss = 0.014065471477806568\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=306, train_loss_step=0.0141, train_loss_epoch=0.0141]Epoch 88: Train Loss = 0.014073577709496021\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=306, train_loss_step=0.0149, train_loss_epoch=0.0141]Epoch 89: Train Loss = 0.014948638156056404\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=306, train_loss_step=0.0138, train_loss_epoch=0.0149]Epoch 90: Train Loss = 0.013765715062618256\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=306, train_loss_step=0.0189, train_loss_epoch=0.0138]Epoch 91: Train Loss = 0.018880721181631088\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=306, train_loss_step=0.0135, train_loss_epoch=0.0189]Epoch 92: Train Loss = 0.013455027714371681\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=306, train_loss_step=0.0199, train_loss_epoch=0.0135]Epoch 93: Train Loss = 0.01993962936103344\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=306, train_loss_step=0.0136, train_loss_epoch=0.0199]Epoch 94: Train Loss = 0.013610409572720528\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.0136]Epoch 95: Train Loss = 0.014286326244473457\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.0143]Epoch 96: Train Loss = 0.010119488462805748\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0101]Epoch 97: Train Loss = 0.011593013070523739\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=306, train_loss_step=0.0152, train_loss_epoch=0.0116]Epoch 98: Train Loss = 0.015202471055090427\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 11.75it/s, v_num=306, train_loss_step=0.0149, train_loss_epoch=0.0152]Epoch 99: Train Loss = 0.014935635961592197\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 13.79it/s, v_num=306, train_loss_step=0.0127, train_loss_epoch=0.0149]Epoch 100: Train Loss = 0.012724320404231548\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=306, train_loss_step=0.0145, train_loss_epoch=0.0127]Epoch 101: Train Loss = 0.01445702649652958\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s, v_num=306, train_loss_step=0.0144, train_loss_epoch=0.0145]Epoch 102: Train Loss = 0.014408379793167114\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s, v_num=306, train_loss_step=0.0145, train_loss_epoch=0.0144]Epoch 103: Train Loss = 0.014530904591083527\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 13.76it/s, v_num=306, train_loss_step=0.0167, train_loss_epoch=0.0145]Epoch 104: Train Loss = 0.016743913292884827\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.0167]Epoch 105: Train Loss = 0.014313110150396824\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=306, train_loss_step=0.0114, train_loss_epoch=0.0143]Epoch 106: Train Loss = 0.011408358812332153\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=306, train_loss_step=0.0175, train_loss_epoch=0.0114]Epoch 107: Train Loss = 0.017493393272161484\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=306, train_loss_step=0.0147, train_loss_epoch=0.0175]Epoch 108: Train Loss = 0.014652684330940247\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=306, train_loss_step=0.012, train_loss_epoch=0.0147] Epoch 109: Train Loss = 0.011968481354415417\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=306, train_loss_step=0.0163, train_loss_epoch=0.012]Epoch 110: Train Loss = 0.016283860430121422\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=306, train_loss_step=0.0169, train_loss_epoch=0.0163]Epoch 111: Train Loss = 0.016878021880984306\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.0169]Epoch 112: Train Loss = 0.014266639947891235\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=306, train_loss_step=0.0164, train_loss_epoch=0.0143]Epoch 113: Train Loss = 0.016426848247647285\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=306, train_loss_step=0.0126, train_loss_epoch=0.0164]Epoch 114: Train Loss = 0.012560493312776089\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=306, train_loss_step=0.0146, train_loss_epoch=0.0126]Epoch 115: Train Loss = 0.014594249427318573\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=306, train_loss_step=0.0136, train_loss_epoch=0.0146]Epoch 116: Train Loss = 0.013591332361102104\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=306, train_loss_step=0.0147, train_loss_epoch=0.0136]Epoch 117: Train Loss = 0.014668083749711514\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=306, train_loss_step=0.0141, train_loss_epoch=0.0147]Epoch 118: Train Loss = 0.014097425155341625\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.0141]Epoch 119: Train Loss = 0.012815878726541996\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0128]Epoch 120: Train Loss = 0.012418932281434536\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.0124]Epoch 121: Train Loss = 0.012822650372982025\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=306, train_loss_step=0.0171, train_loss_epoch=0.0128]Epoch 122: Train Loss = 0.017078761011362076\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=306, train_loss_step=0.0136, train_loss_epoch=0.0171]Epoch 123: Train Loss = 0.013608803041279316\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=306, train_loss_step=0.0147, train_loss_epoch=0.0136]Epoch 124: Train Loss = 0.014665375463664532\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=306, train_loss_step=0.0187, train_loss_epoch=0.0147]Epoch 125: Train Loss = 0.018716759979724884\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=306, train_loss_step=0.0114, train_loss_epoch=0.0187]Epoch 126: Train Loss = 0.011445713229477406\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=306, train_loss_step=0.016, train_loss_epoch=0.0114] Epoch 127: Train Loss = 0.01598232425749302\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.016]Epoch 128: Train Loss = 0.0131294010207057\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=306, train_loss_step=0.0158, train_loss_epoch=0.0131]Epoch 129: Train Loss = 0.015849867835640907\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=306, train_loss_step=0.0151, train_loss_epoch=0.0158]Epoch 130: Train Loss = 0.015142933465540409\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 10.18it/s, v_num=306, train_loss_step=0.0135, train_loss_epoch=0.0151]Epoch 131: Train Loss = 0.013503245078027248\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=306, train_loss_step=0.0158, train_loss_epoch=0.0135]Epoch 132: Train Loss = 0.015843186527490616\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=306, train_loss_step=0.0109, train_loss_epoch=0.0158]Epoch 133: Train Loss = 0.010919253341853619\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=306, train_loss_step=0.0159, train_loss_epoch=0.0109]Epoch 134: Train Loss = 0.01586955413222313\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=306, train_loss_step=0.0102, train_loss_epoch=0.0159]Epoch 135: Train Loss = 0.01017831265926361\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=306, train_loss_step=0.0151, train_loss_epoch=0.0102]Epoch 136: Train Loss = 0.015067393891513348\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=306, train_loss_step=0.0097, train_loss_epoch=0.0151]Epoch 137: Train Loss = 0.009697438217699528\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=306, train_loss_step=0.0136, train_loss_epoch=0.0097]Epoch 138: Train Loss = 0.013583241030573845\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=306, train_loss_step=0.00986, train_loss_epoch=0.0136]Epoch 139: Train Loss = 0.009859819896519184\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s, v_num=306, train_loss_step=0.00886, train_loss_epoch=0.00986]Epoch 140: Train Loss = 0.008861041627824306\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=306, train_loss_step=0.0111, train_loss_epoch=0.00886] Epoch 141: Train Loss = 0.011112207546830177\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s, v_num=306, train_loss_step=0.0109, train_loss_epoch=0.0111] Epoch 142: Train Loss = 0.010873334482312202\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=306, train_loss_step=0.0123, train_loss_epoch=0.0109]Epoch 143: Train Loss = 0.012321743182837963\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=306, train_loss_step=0.0102, train_loss_epoch=0.0123]Epoch 144: Train Loss = 0.010188414715230465\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=306, train_loss_step=0.0114, train_loss_epoch=0.0102]Epoch 145: Train Loss = 0.011360300704836845\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0114]Epoch 146: Train Loss = 0.011599494144320488\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=306, train_loss_step=0.0107, train_loss_epoch=0.0116]Epoch 147: Train Loss = 0.010664389468729496\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=306, train_loss_step=0.0103, train_loss_epoch=0.0107]Epoch 148: Train Loss = 0.010323318652808666\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=306, train_loss_step=0.0113, train_loss_epoch=0.0103]Epoch 149: Train Loss = 0.011319143697619438\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=306, train_loss_step=0.012, train_loss_epoch=0.0113] Epoch 150: Train Loss = 0.011984477750957012\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.012]Epoch 151: Train Loss = 0.012158894911408424\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=306, train_loss_step=0.0152, train_loss_epoch=0.0122]Epoch 152: Train Loss = 0.015151680447161198\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=306, train_loss_step=0.014, train_loss_epoch=0.0152] Epoch 153: Train Loss = 0.013992798514664173\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=306, train_loss_step=0.0115, train_loss_epoch=0.014]Epoch 154: Train Loss = 0.011528215371072292\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=306, train_loss_step=0.0137, train_loss_epoch=0.0115]Epoch 155: Train Loss = 0.013696698471903801\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0137]Epoch 156: Train Loss = 0.011639182455837727\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=306, train_loss_step=0.0126, train_loss_epoch=0.0116]Epoch 157: Train Loss = 0.012639821507036686\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=306, train_loss_step=0.0105, train_loss_epoch=0.0126]Epoch 158: Train Loss = 0.010465564206242561\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=306, train_loss_step=0.0118, train_loss_epoch=0.0105]Epoch 159: Train Loss = 0.01176735945045948\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0118]Epoch 160: Train Loss = 0.012400086037814617\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s, v_num=306, train_loss_step=0.013, train_loss_epoch=0.0124] Epoch 161: Train Loss = 0.012983934953808784\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.013]Epoch 162: Train Loss = 0.012396769598126411\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s, v_num=306, train_loss_step=0.0125, train_loss_epoch=0.0124]Epoch 163: Train Loss = 0.012506814673542976\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.0125]Epoch 164: Train Loss = 0.01006638165563345\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=306, train_loss_step=0.0156, train_loss_epoch=0.0101]Epoch 165: Train Loss = 0.015570981428027153\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.0156]Epoch 166: Train Loss = 0.011237096041440964\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=306, train_loss_step=0.0182, train_loss_epoch=0.0112]Epoch 167: Train Loss = 0.018172945827245712\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.0182] Epoch 168: Train Loss = 0.011005274020135403\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=306, train_loss_step=0.0149, train_loss_epoch=0.011]Epoch 169: Train Loss = 0.0148778622969985\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0149]Epoch 170: Train Loss = 0.012871747836470604\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=306, train_loss_step=0.0153, train_loss_epoch=0.0129]Epoch 171: Train Loss = 0.015265642665326595\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=306, train_loss_step=0.0127, train_loss_epoch=0.0153]Epoch 172: Train Loss = 0.012699040584266186\n",
      "Epoch 173: 100%|██████████| 1/1 [00:01<00:00,  0.99it/s, v_num=306, train_loss_step=0.0164, train_loss_epoch=0.0127]Epoch 173: Train Loss = 0.016409089788794518\n",
      "Epoch 174: 100%|██████████| 1/1 [00:01<00:00,  1.00it/s, v_num=306, train_loss_step=0.0138, train_loss_epoch=0.0164]Epoch 174: Train Loss = 0.013849637471139431\n",
      "Epoch 175: 100%|██████████| 1/1 [00:01<00:00,  0.79it/s, v_num=306, train_loss_step=0.0111, train_loss_epoch=0.0138]Epoch 175: Train Loss = 0.011055815033614635\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s, v_num=306, train_loss_step=0.0121, train_loss_epoch=0.0111]Epoch 176: Train Loss = 0.012129561975598335\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, v_num=306, train_loss_step=0.0118, train_loss_epoch=0.0121]Epoch 177: Train Loss = 0.01179543323814869\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, v_num=306, train_loss_step=0.0123, train_loss_epoch=0.0118]Epoch 178: Train Loss = 0.012332730926573277\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, v_num=306, train_loss_step=0.0105, train_loss_epoch=0.0123]Epoch 179: Train Loss = 0.01052492018789053\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, v_num=306, train_loss_step=0.0138, train_loss_epoch=0.0105]Epoch 180: Train Loss = 0.013774232938885689\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, v_num=306, train_loss_step=0.0127, train_loss_epoch=0.0138]Epoch 181: Train Loss = 0.012669766321778297\n",
      "Epoch 182: 100%|██████████| 1/1 [00:01<00:00,  0.63it/s, v_num=306, train_loss_step=0.0121, train_loss_epoch=0.0127]Epoch 182: Train Loss = 0.012081342749297619\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.0121]Epoch 183: Train Loss = 0.010117401368916035\n",
      "Epoch 184: 100%|██████████| 1/1 [00:01<00:00,  0.83it/s, v_num=306, train_loss_step=0.0126, train_loss_epoch=0.0101]Epoch 184: Train Loss = 0.01261965837329626\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s, v_num=306, train_loss_step=0.0157, train_loss_epoch=0.0126]Epoch 185: Train Loss = 0.01574990712106228\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=306, train_loss_step=0.0156, train_loss_epoch=0.0157]Epoch 186: Train Loss = 0.015571781434118748\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=306, train_loss_step=0.0135, train_loss_epoch=0.0156]Epoch 187: Train Loss = 0.01353710237890482\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s, v_num=306, train_loss_step=0.0147, train_loss_epoch=0.0135]Epoch 188: Train Loss = 0.014663690701127052\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, v_num=306, train_loss_step=0.0145, train_loss_epoch=0.0147]Epoch 189: Train Loss = 0.014536726288497448\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0145]Epoch 190: Train Loss = 0.011605373583734035\n",
      "Epoch 191: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=306, train_loss_step=0.0137, train_loss_epoch=0.0116]Epoch 191: Train Loss = 0.013749903999269009\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, v_num=306, train_loss_step=0.0119, train_loss_epoch=0.0137]Epoch 192: Train Loss = 0.011892260983586311\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, v_num=306, train_loss_step=0.013, train_loss_epoch=0.0119] Epoch 193: Train Loss = 0.013033716939389706\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s, v_num=306, train_loss_step=0.0141, train_loss_epoch=0.013]Epoch 194: Train Loss = 0.014059946872293949\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=306, train_loss_step=0.0134, train_loss_epoch=0.0141]Epoch 195: Train Loss = 0.013412125408649445\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=306, train_loss_step=0.0148, train_loss_epoch=0.0134]Epoch 196: Train Loss = 0.014816336333751678\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=306, train_loss_step=0.0107, train_loss_epoch=0.0148]Epoch 197: Train Loss = 0.010686526075005531\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.0107]Epoch 198: Train Loss = 0.011242685839533806\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=306, train_loss_step=0.0106, train_loss_epoch=0.0112]Epoch 199: Train Loss = 0.010568804107606411\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.0106]Epoch 200: Train Loss = 0.012780977413058281\n",
      "Epoch 201: 100%|██████████| 1/1 [00:01<00:00,  0.85it/s, v_num=306, train_loss_step=0.0125, train_loss_epoch=0.0128]Epoch 201: Train Loss = 0.01251731812953949\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, v_num=306, train_loss_step=0.0148, train_loss_epoch=0.0125]Epoch 202: Train Loss = 0.014762023463845253\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s, v_num=306, train_loss_step=0.0118, train_loss_epoch=0.0148]Epoch 203: Train Loss = 0.011811782605946064\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=306, train_loss_step=0.0113, train_loss_epoch=0.0118]Epoch 204: Train Loss = 0.011286371387541294\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0113]Epoch 205: Train Loss = 0.011609178967773914\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=306, train_loss_step=0.0161, train_loss_epoch=0.0116]Epoch 206: Train Loss = 0.01606486365199089\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=306, train_loss_step=0.0117, train_loss_epoch=0.0161]Epoch 207: Train Loss = 0.011716038919985294\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=306, train_loss_step=0.0141, train_loss_epoch=0.0117]Epoch 208: Train Loss = 0.014088200405240059\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=306, train_loss_step=0.0158, train_loss_epoch=0.0141]Epoch 209: Train Loss = 0.015817755833268166\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.0158]Epoch 210: Train Loss = 0.014320661313831806\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=306, train_loss_step=0.015, train_loss_epoch=0.0143] Epoch 211: Train Loss = 0.014963247813284397\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=306, train_loss_step=0.0127, train_loss_epoch=0.015]Epoch 212: Train Loss = 0.012678960338234901\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=306, train_loss_step=0.0158, train_loss_epoch=0.0127]Epoch 213: Train Loss = 0.015797093510627747\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s, v_num=306, train_loss_step=0.0121, train_loss_epoch=0.0158]Epoch 214: Train Loss = 0.012085163965821266\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s, v_num=306, train_loss_step=0.00974, train_loss_epoch=0.0121]Epoch 215: Train Loss = 0.009744413197040558\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=306, train_loss_step=0.0149, train_loss_epoch=0.00974] Epoch 216: Train Loss = 0.014870190061628819\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, v_num=306, train_loss_step=0.0135, train_loss_epoch=0.0149] Epoch 217: Train Loss = 0.01349956076592207\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, v_num=306, train_loss_step=0.0154, train_loss_epoch=0.0135]Epoch 218: Train Loss = 0.01538370456546545\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, v_num=306, train_loss_step=0.0152, train_loss_epoch=0.0154]Epoch 219: Train Loss = 0.01517645362764597\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=306, train_loss_step=0.00999, train_loss_epoch=0.0152]Epoch 220: Train Loss = 0.009992084465920925\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=306, train_loss_step=0.0123, train_loss_epoch=0.00999] Epoch 221: Train Loss = 0.012327343225479126\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.0123] Epoch 222: Train Loss = 0.012803356163203716\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s, v_num=306, train_loss_step=0.0166, train_loss_epoch=0.0128]Epoch 223: Train Loss = 0.01663648523390293\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0166]Epoch 224: Train Loss = 0.01293937861919403\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=306, train_loss_step=0.0111, train_loss_epoch=0.0129]Epoch 225: Train Loss = 0.01113885547965765\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s, v_num=306, train_loss_step=0.0119, train_loss_epoch=0.0111]Epoch 226: Train Loss = 0.011942108161747456\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s, v_num=306, train_loss_step=0.0132, train_loss_epoch=0.0119]Epoch 227: Train Loss = 0.013168995268642902\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.0132]Epoch 228: Train Loss = 0.01215242687612772\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s, v_num=306, train_loss_step=0.0212, train_loss_epoch=0.0122]Epoch 229: Train Loss = 0.021209316328167915\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, v_num=306, train_loss_step=0.0155, train_loss_epoch=0.0212]Epoch 230: Train Loss = 0.015519634820520878\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.0155]Epoch 231: Train Loss = 0.012838154099881649\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s, v_num=306, train_loss_step=0.0113, train_loss_epoch=0.0128]Epoch 232: Train Loss = 0.011264986358582973\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=306, train_loss_step=0.0148, train_loss_epoch=0.0113]Epoch 233: Train Loss = 0.014811694622039795\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0148]Epoch 234: Train Loss = 0.012908081524074078\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=306, train_loss_step=0.0117, train_loss_epoch=0.0129]Epoch 235: Train Loss = 0.011706371791660786\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, v_num=306, train_loss_step=0.00949, train_loss_epoch=0.0117]Epoch 236: Train Loss = 0.00948730856180191\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.00949] Epoch 237: Train Loss = 0.013133455999195576\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=306, train_loss_step=0.013, train_loss_epoch=0.0131]  Epoch 238: Train Loss = 0.013040455058217049\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s, v_num=306, train_loss_step=0.0126, train_loss_epoch=0.013]Epoch 239: Train Loss = 0.012576252222061157\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s, v_num=306, train_loss_step=0.0111, train_loss_epoch=0.0126]Epoch 240: Train Loss = 0.011142906732857227\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s, v_num=306, train_loss_step=0.0149, train_loss_epoch=0.0111]Epoch 241: Train Loss = 0.014896979555487633\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, v_num=306, train_loss_step=0.00957, train_loss_epoch=0.0149]Epoch 242: Train Loss = 0.009567606262862682\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.00957] Epoch 243: Train Loss = 0.010125363245606422\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s, v_num=306, train_loss_step=0.0135, train_loss_epoch=0.0101] Epoch 244: Train Loss = 0.01346746925264597\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, v_num=306, train_loss_step=0.0123, train_loss_epoch=0.0135]Epoch 245: Train Loss = 0.012326027266681194\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s, v_num=306, train_loss_step=0.0106, train_loss_epoch=0.0123]Epoch 246: Train Loss = 0.010568464174866676\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, v_num=306, train_loss_step=0.013, train_loss_epoch=0.0106] Epoch 247: Train Loss = 0.013029010966420174\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s, v_num=306, train_loss_step=0.0119, train_loss_epoch=0.013]Epoch 248: Train Loss = 0.011851662769913673\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, v_num=306, train_loss_step=0.0184, train_loss_epoch=0.0119]Epoch 249: Train Loss = 0.0184006430208683\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, v_num=306, train_loss_step=0.0117, train_loss_epoch=0.0184]Epoch 250: Train Loss = 0.01168459840118885\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s, v_num=306, train_loss_step=0.0159, train_loss_epoch=0.0117]Epoch 251: Train Loss = 0.01591191440820694\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, v_num=306, train_loss_step=0.0145, train_loss_epoch=0.0159]Epoch 252: Train Loss = 0.014494701288640499\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s, v_num=306, train_loss_step=0.0134, train_loss_epoch=0.0145]Epoch 253: Train Loss = 0.013366272673010826\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, v_num=306, train_loss_step=0.0126, train_loss_epoch=0.0134]Epoch 254: Train Loss = 0.01263913232833147\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0126]Epoch 255: Train Loss = 0.011611459776759148\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s, v_num=306, train_loss_step=0.0138, train_loss_epoch=0.0116]Epoch 256: Train Loss = 0.013820083811879158\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=306, train_loss_step=0.00983, train_loss_epoch=0.0138]Epoch 257: Train Loss = 0.009831834584474564\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.00983]  Epoch 258: Train Loss = 0.011021808721125126\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s, v_num=306, train_loss_step=0.013, train_loss_epoch=0.011]  Epoch 259: Train Loss = 0.013037577271461487\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s, v_num=306, train_loss_step=0.012, train_loss_epoch=0.013]Epoch 260: Train Loss = 0.012002089992165565\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s, v_num=306, train_loss_step=0.0104, train_loss_epoch=0.012]Epoch 261: Train Loss = 0.010363288223743439\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, v_num=306, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 262: Train Loss = 0.011478235945105553\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s, v_num=306, train_loss_step=0.0123, train_loss_epoch=0.0115]Epoch 263: Train Loss = 0.012323076836764812\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.0123]Epoch 264: Train Loss = 0.012237672694027424\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.0122]Epoch 265: Train Loss = 0.013100715354084969\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.0131]Epoch 266: Train Loss = 0.01279942411929369\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, v_num=306, train_loss_step=0.0105, train_loss_epoch=0.0128]Epoch 267: Train Loss = 0.010491682216525078\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, v_num=306, train_loss_step=0.0147, train_loss_epoch=0.0105]Epoch 268: Train Loss = 0.014656132087111473\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s, v_num=306, train_loss_step=0.0139, train_loss_epoch=0.0147]Epoch 269: Train Loss = 0.013893775641918182\n",
      "Epoch 270: 100%|██████████| 1/1 [00:01<00:00,  0.99it/s, v_num=306, train_loss_step=0.0118, train_loss_epoch=0.0139]Epoch 270: Train Loss = 0.01182324718683958\n",
      "Epoch 271: 100%|██████████| 1/1 [00:01<00:00,  0.93it/s, v_num=306, train_loss_step=0.0136, train_loss_epoch=0.0118]Epoch 271: Train Loss = 0.013573193922638893\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s, v_num=306, train_loss_step=0.0146, train_loss_epoch=0.0136]Epoch 272: Train Loss = 0.01458627637475729\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=306, train_loss_step=0.0121, train_loss_epoch=0.0146]Epoch 273: Train Loss = 0.012125080451369286\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, v_num=306, train_loss_step=0.0125, train_loss_epoch=0.0121]Epoch 274: Train Loss = 0.012482858262956142\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s, v_num=306, train_loss_step=0.0166, train_loss_epoch=0.0125]Epoch 275: Train Loss = 0.016595570370554924\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=306, train_loss_step=0.00771, train_loss_epoch=0.0166]Epoch 276: Train Loss = 0.007710454054176807\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.00771] Epoch 277: Train Loss = 0.01293178554624319\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.0129] Epoch 278: Train Loss = 0.013085064478218555\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, v_num=306, train_loss_step=0.0121, train_loss_epoch=0.0131]Epoch 279: Train Loss = 0.012143160216510296\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s, v_num=306, train_loss_step=0.0217, train_loss_epoch=0.0121]Epoch 280: Train Loss = 0.021731363609433174\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.0217]Epoch 281: Train Loss = 0.011226402595639229\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, v_num=306, train_loss_step=0.0107, train_loss_epoch=0.0112]Epoch 282: Train Loss = 0.010696479119360447\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s, v_num=306, train_loss_step=0.0141, train_loss_epoch=0.0107]Epoch 283: Train Loss = 0.014146468602120876\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.0141]Epoch 284: Train Loss = 0.01221691258251667\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s, v_num=306, train_loss_step=0.013, train_loss_epoch=0.0122] Epoch 285: Train Loss = 0.012960417196154594\n",
      "Epoch 286: 100%|██████████| 1/1 [00:01<00:00,  0.99it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.013]Epoch 286: Train Loss = 0.012356625869870186\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, v_num=306, train_loss_step=0.0123, train_loss_epoch=0.0124]Epoch 287: Train Loss = 0.012292551808059216\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0123]Epoch 288: Train Loss = 0.012417403049767017\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, v_num=306, train_loss_step=0.0125, train_loss_epoch=0.0124]Epoch 289: Train Loss = 0.012458868324756622\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s, v_num=306, train_loss_step=0.0121, train_loss_epoch=0.0125]Epoch 290: Train Loss = 0.012075982056558132\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=306, train_loss_step=0.0114, train_loss_epoch=0.0121]Epoch 291: Train Loss = 0.01137504167854786\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s, v_num=306, train_loss_step=0.0137, train_loss_epoch=0.0114]Epoch 292: Train Loss = 0.013716058805584908\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.0137]Epoch 293: Train Loss = 0.014265219680964947\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.0143]Epoch 294: Train Loss = 0.01124486979097128\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.0112] Epoch 295: Train Loss = 0.011009092442691326\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.011]Epoch 296: Train Loss = 0.01117582619190216\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s, v_num=306, train_loss_step=0.0196, train_loss_epoch=0.0112]Epoch 297: Train Loss = 0.019646290689706802\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, v_num=306, train_loss_step=0.0125, train_loss_epoch=0.0196]Epoch 298: Train Loss = 0.012478229589760303\n",
      "Epoch 299: 100%|██████████| 1/1 [00:01<00:00,  0.75it/s, v_num=306, train_loss_step=0.0117, train_loss_epoch=0.0125]Epoch 299: Train Loss = 0.011679056100547314\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s, v_num=306, train_loss_step=0.0119, train_loss_epoch=0.0117]Epoch 300: Train Loss = 0.011907386593520641\n",
      "Epoch 301: 100%|██████████| 1/1 [00:01<00:00,  0.98it/s, v_num=306, train_loss_step=0.0161, train_loss_epoch=0.0119]Epoch 301: Train Loss = 0.016126345843076706\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s, v_num=306, train_loss_step=0.0133, train_loss_epoch=0.0161]Epoch 302: Train Loss = 0.013279059901833534\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, v_num=306, train_loss_step=0.0111, train_loss_epoch=0.0133]Epoch 303: Train Loss = 0.011077038012444973\n",
      "Epoch 304: 100%|██████████| 1/1 [00:01<00:00,  0.81it/s, v_num=306, train_loss_step=0.0155, train_loss_epoch=0.0111]Epoch 304: Train Loss = 0.015526733361184597\n",
      "Epoch 305: 100%|██████████| 1/1 [00:01<00:00,  0.73it/s, v_num=306, train_loss_step=0.0148, train_loss_epoch=0.0155]Epoch 305: Train Loss = 0.014809937216341496\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.0148]Epoch 306: Train Loss = 0.011163781397044659\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, v_num=306, train_loss_step=0.0141, train_loss_epoch=0.0112]Epoch 307: Train Loss = 0.014081721194088459\n",
      "Epoch 308: 100%|██████████| 1/1 [00:01<00:00,  0.91it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.0141]Epoch 308: Train Loss = 0.014308265410363674\n",
      "Epoch 309: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.0143] Epoch 309: Train Loss = 0.011029918678104877\n",
      "Epoch 310: 100%|██████████| 1/1 [00:03<00:00,  0.33it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.011]Epoch 310: Train Loss = 0.012379367835819721\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s, v_num=306, train_loss_step=0.0114, train_loss_epoch=0.0124]Epoch 311: Train Loss = 0.011379363015294075\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s, v_num=306, train_loss_step=0.00949, train_loss_epoch=0.0114]Epoch 312: Train Loss = 0.009489486925303936\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=306, train_loss_step=0.0111, train_loss_epoch=0.00949] Epoch 313: Train Loss = 0.011115088127553463\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=306, train_loss_step=0.0163, train_loss_epoch=0.0111] Epoch 314: Train Loss = 0.016305899247527122\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s, v_num=306, train_loss_step=0.0139, train_loss_epoch=0.0163]Epoch 315: Train Loss = 0.013924113474786282\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=306, train_loss_step=0.0103, train_loss_epoch=0.0139]Epoch 316: Train Loss = 0.010294989682734013\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=306, train_loss_step=0.0155, train_loss_epoch=0.0103]Epoch 317: Train Loss = 0.015484243631362915\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=306, train_loss_step=0.0132, train_loss_epoch=0.0155]Epoch 318: Train Loss = 0.013154969550669193\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0132]Epoch 319: Train Loss = 0.01243802160024643\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=306, train_loss_step=0.0136, train_loss_epoch=0.0124]Epoch 320: Train Loss = 0.013551576994359493\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=306, train_loss_step=0.0108, train_loss_epoch=0.0136]Epoch 321: Train Loss = 0.010757899843156338\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=306, train_loss_step=0.0134, train_loss_epoch=0.0108]Epoch 322: Train Loss = 0.013439400121569633\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0134]Epoch 323: Train Loss = 0.011604727245867252\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, v_num=306, train_loss_step=0.0135, train_loss_epoch=0.0116]Epoch 324: Train Loss = 0.013545827008783817\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=306, train_loss_step=0.012, train_loss_epoch=0.0135] Epoch 325: Train Loss = 0.01196966227144003\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=306, train_loss_step=0.0107, train_loss_epoch=0.012]Epoch 326: Train Loss = 0.010680226609110832\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=306, train_loss_step=0.00947, train_loss_epoch=0.0107]Epoch 327: Train Loss = 0.009465501643717289\n",
      "Epoch 328: 100%|██████████| 1/1 [00:01<00:00,  0.72it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.00947]  Epoch 328: Train Loss = 0.01099736150354147\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=306, train_loss_step=0.0126, train_loss_epoch=0.011] Epoch 329: Train Loss = 0.012638797983527184\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s, v_num=306, train_loss_step=0.0145, train_loss_epoch=0.0126]Epoch 330: Train Loss = 0.014522464014589787\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0145]Epoch 331: Train Loss = 0.012383741326630116\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=306, train_loss_step=0.0162, train_loss_epoch=0.0124]Epoch 332: Train Loss = 0.01616583578288555\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=306, train_loss_step=0.0154, train_loss_epoch=0.0162]Epoch 333: Train Loss = 0.015388713218271732\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0154]Epoch 334: Train Loss = 0.012364518828690052\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0124]Epoch 335: Train Loss = 0.012851707637310028\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=306, train_loss_step=0.0156, train_loss_epoch=0.0129]Epoch 336: Train Loss = 0.015563888475298882\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=306, train_loss_step=0.013, train_loss_epoch=0.0156] Epoch 337: Train Loss = 0.012997559271752834\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=306, train_loss_step=0.0104, train_loss_epoch=0.013]Epoch 338: Train Loss = 0.010435082018375397\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=306, train_loss_step=0.0134, train_loss_epoch=0.0104]Epoch 339: Train Loss = 0.013367010280489922\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=306, train_loss_step=0.0158, train_loss_epoch=0.0134]Epoch 340: Train Loss = 0.015799710527062416\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=306, train_loss_step=0.0163, train_loss_epoch=0.0158]Epoch 341: Train Loss = 0.01632246933877468\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=306, train_loss_step=0.0114, train_loss_epoch=0.0163]Epoch 342: Train Loss = 0.011443582363426685\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s, v_num=306, train_loss_step=0.0158, train_loss_epoch=0.0114]Epoch 343: Train Loss = 0.015799645334482193\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=306, train_loss_step=0.00964, train_loss_epoch=0.0158]Epoch 344: Train Loss = 0.00964065920561552\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=306, train_loss_step=0.0113, train_loss_epoch=0.00964] Epoch 345: Train Loss = 0.011273697949945927\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=306, train_loss_step=0.0143, train_loss_epoch=0.0113] Epoch 346: Train Loss = 0.01430092565715313\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.0143] Epoch 347: Train Loss = 0.010991373099386692\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=306, train_loss_step=0.0148, train_loss_epoch=0.011]Epoch 348: Train Loss = 0.014836256392300129\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=306, train_loss_step=0.0117, train_loss_epoch=0.0148]Epoch 349: Train Loss = 0.011692195199429989\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s, v_num=306, train_loss_step=0.015, train_loss_epoch=0.0117] Epoch 350: Train Loss = 0.015027878805994987\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=306, train_loss_step=0.0118, train_loss_epoch=0.015]Epoch 351: Train Loss = 0.011817030608654022\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s, v_num=306, train_loss_step=0.0154, train_loss_epoch=0.0118]Epoch 352: Train Loss = 0.015399922616779804\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.0154]Epoch 353: Train Loss = 0.010088128969073296\n",
      "Epoch 354: 100%|██████████| 1/1 [00:01<00:00,  0.66it/s, v_num=306, train_loss_step=0.00883, train_loss_epoch=0.0101]Epoch 354: Train Loss = 0.008832777850329876\n",
      "Epoch 355: 100%|██████████| 1/1 [00:02<00:00,  0.39it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.00883]  Epoch 355: Train Loss = 0.010971850715577602\n",
      "Epoch 356: 100%|██████████| 1/1 [00:01<00:00,  0.67it/s, v_num=306, train_loss_step=0.0118, train_loss_epoch=0.011] Epoch 356: Train Loss = 0.011788113042712212\n",
      "Epoch 357: 100%|██████████| 1/1 [00:01<00:00,  0.63it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0118]Epoch 357: Train Loss = 0.01237648818641901\n",
      "Epoch 358: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=306, train_loss_step=0.0159, train_loss_epoch=0.0124]Epoch 358: Train Loss = 0.015867995098233223\n",
      "Epoch 359: 100%|██████████| 1/1 [00:02<00:00,  0.36it/s, v_num=306, train_loss_step=0.0132, train_loss_epoch=0.0159]Epoch 359: Train Loss = 0.01324735302478075\n",
      "Epoch 360: 100%|██████████| 1/1 [00:01<00:00,  0.68it/s, v_num=306, train_loss_step=0.0106, train_loss_epoch=0.0132]Epoch 360: Train Loss = 0.010580509901046753\n",
      "Epoch 361: 100%|██████████| 1/1 [00:01<00:00,  0.62it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.0106]Epoch 361: Train Loss = 0.012781141325831413\n",
      "Epoch 362: 100%|██████████| 1/1 [00:01<00:00,  0.62it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0128]Epoch 362: Train Loss = 0.012873111292719841\n",
      "Epoch 363: 100%|██████████| 1/1 [00:01<00:00,  0.91it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.0129]Epoch 363: Train Loss = 0.010059361346065998\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 11.59it/s, v_num=306, train_loss_step=0.00876, train_loss_epoch=0.0101]Epoch 364: Train Loss = 0.008761346340179443\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=306, train_loss_step=0.0147, train_loss_epoch=0.00876] Epoch 365: Train Loss = 0.01474014949053526\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=306, train_loss_step=0.0133, train_loss_epoch=0.0147] Epoch 366: Train Loss = 0.013340509496629238\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=306, train_loss_step=0.0184, train_loss_epoch=0.0133]Epoch 367: Train Loss = 0.01839551329612732\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.0184]Epoch 368: Train Loss = 0.01011599414050579\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=306, train_loss_step=0.0156, train_loss_epoch=0.0101]Epoch 369: Train Loss = 0.015625478699803352\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=306, train_loss_step=0.00991, train_loss_epoch=0.0156]Epoch 370: Train Loss = 0.009914392605423927\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.00991] Epoch 371: Train Loss = 0.012433046475052834\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=306, train_loss_step=0.0103, train_loss_epoch=0.0124] Epoch 372: Train Loss = 0.010327346622943878\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=306, train_loss_step=0.0133, train_loss_epoch=0.0103]Epoch 373: Train Loss = 0.01332650426775217\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 12.67it/s, v_num=306, train_loss_step=0.0094, train_loss_epoch=0.0133]Epoch 374: Train Loss = 0.00939513836055994\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=306, train_loss_step=0.0161, train_loss_epoch=0.0094]Epoch 375: Train Loss = 0.016137542203068733\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s, v_num=306, train_loss_step=0.0119, train_loss_epoch=0.0161]Epoch 376: Train Loss = 0.011893155984580517\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0119]Epoch 377: Train Loss = 0.012355001643300056\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.0124]Epoch 378: Train Loss = 0.012246604077517986\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=306, train_loss_step=0.0108, train_loss_epoch=0.0122]Epoch 379: Train Loss = 0.010763888247311115\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=306, train_loss_step=0.0115, train_loss_epoch=0.0108]Epoch 380: Train Loss = 0.01146026886999607\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=306, train_loss_step=0.0163, train_loss_epoch=0.0115]Epoch 381: Train Loss = 0.016348088160157204\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=306, train_loss_step=0.0115, train_loss_epoch=0.0163]Epoch 382: Train Loss = 0.011511729098856449\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s, v_num=306, train_loss_step=0.0123, train_loss_epoch=0.0115]Epoch 383: Train Loss = 0.012317872606217861\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 11.55it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0123]Epoch 384: Train Loss = 0.012909377925097942\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0129]Epoch 385: Train Loss = 0.01244842354208231\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=306, train_loss_step=0.0136, train_loss_epoch=0.0124]Epoch 386: Train Loss = 0.013603277504444122\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s, v_num=306, train_loss_step=0.0158, train_loss_epoch=0.0136]Epoch 387: Train Loss = 0.01582503877580166\n",
      "Epoch 388: 100%|██████████| 1/1 [00:01<00:00,  0.67it/s, v_num=306, train_loss_step=0.0111, train_loss_epoch=0.0158]Epoch 388: Train Loss = 0.011054241098463535\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=306, train_loss_step=0.00915, train_loss_epoch=0.0111]Epoch 389: Train Loss = 0.009154142811894417\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=306, train_loss_step=0.0135, train_loss_epoch=0.00915] Epoch 390: Train Loss = 0.013517753221094608\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.0135] Epoch 391: Train Loss = 0.011202082969248295\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s, v_num=306, train_loss_step=0.0097, train_loss_epoch=0.0112]Epoch 392: Train Loss = 0.009699846617877483\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=306, train_loss_step=0.0138, train_loss_epoch=0.0097]Epoch 393: Train Loss = 0.013813311234116554\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s, v_num=306, train_loss_step=0.0105, train_loss_epoch=0.0138]Epoch 394: Train Loss = 0.010489203967154026\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=306, train_loss_step=0.0109, train_loss_epoch=0.0105]Epoch 395: Train Loss = 0.010911566205322742\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=306, train_loss_step=0.00949, train_loss_epoch=0.0109]Epoch 396: Train Loss = 0.00948918517678976\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s, v_num=306, train_loss_step=0.0179, train_loss_epoch=0.00949] Epoch 397: Train Loss = 0.01794680394232273\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.0179] Epoch 398: Train Loss = 0.010079900734126568\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=306, train_loss_step=0.00965, train_loss_epoch=0.0101]Epoch 399: Train Loss = 0.009653449058532715\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=306, train_loss_step=0.0152, train_loss_epoch=0.00965] Epoch 400: Train Loss = 0.01524341106414795\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=306, train_loss_step=0.0115, train_loss_epoch=0.0152] Epoch 401: Train Loss = 0.011509339325129986\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s, v_num=306, train_loss_step=0.0107, train_loss_epoch=0.0115]Epoch 402: Train Loss = 0.010686619207262993\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.0107]Epoch 403: Train Loss = 0.013052425347268581\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0131]Epoch 404: Train Loss = 0.011557403020560741\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, v_num=306, train_loss_step=0.0118, train_loss_epoch=0.0116]Epoch 405: Train Loss = 0.011778316460549831\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, v_num=306, train_loss_step=0.0137, train_loss_epoch=0.0118]Epoch 406: Train Loss = 0.013694973662495613\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.0137]Epoch 407: Train Loss = 0.01014729868620634\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s, v_num=306, train_loss_step=0.0095, train_loss_epoch=0.0101]Epoch 408: Train Loss = 0.009501581080257893\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, v_num=306, train_loss_step=0.0119, train_loss_epoch=0.0095]Epoch 409: Train Loss = 0.011874365620315075\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=306, train_loss_step=0.00923, train_loss_epoch=0.0119]Epoch 410: Train Loss = 0.009227889589965343\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.00923] Epoch 411: Train Loss = 0.013056366704404354\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=306, train_loss_step=0.00947, train_loss_epoch=0.0131]Epoch 412: Train Loss = 0.009468883275985718\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=306, train_loss_step=0.0102, train_loss_epoch=0.00947] Epoch 413: Train Loss = 0.010184168815612793\n",
      "Epoch 414: 100%|██████████| 1/1 [00:01<00:00,  0.88it/s, v_num=306, train_loss_step=0.0102, train_loss_epoch=0.0102] Epoch 414: Train Loss = 0.010165929794311523\n",
      "Epoch 415: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=306, train_loss_step=0.0111, train_loss_epoch=0.0102]Epoch 415: Train Loss = 0.011084290221333504\n",
      "Epoch 416: 100%|██████████| 1/1 [00:02<00:00,  0.37it/s, v_num=306, train_loss_step=0.00999, train_loss_epoch=0.0111]Epoch 416: Train Loss = 0.009986287914216518\n",
      "Epoch 417: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=306, train_loss_step=0.0152, train_loss_epoch=0.00999] Epoch 417: Train Loss = 0.015171139501035213\n",
      "Epoch 418: 100%|██████████| 1/1 [00:01<00:00,  0.71it/s, v_num=306, train_loss_step=0.00738, train_loss_epoch=0.0152]Epoch 418: Train Loss = 0.0073844632133841515\n",
      "Epoch 419: 100%|██████████| 1/1 [00:01<00:00,  0.86it/s, v_num=306, train_loss_step=0.0185, train_loss_epoch=0.00738] Epoch 419: Train Loss = 0.018523182719945908\n",
      "Epoch 420: 100%|██████████| 1/1 [00:03<00:00,  0.33it/s, v_num=306, train_loss_step=0.012, train_loss_epoch=0.0185]  Epoch 420: Train Loss = 0.01198593620210886\n",
      "Epoch 421: 100%|██████████| 1/1 [00:02<00:00,  0.36it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.012]Epoch 421: Train Loss = 0.01012352667748928\n",
      "Epoch 422: 100%|██████████| 1/1 [00:02<00:00,  0.38it/s, v_num=306, train_loss_step=0.0115, train_loss_epoch=0.0101]Epoch 422: Train Loss = 0.01150917261838913\n",
      "Epoch 423: 100%|██████████| 1/1 [00:01<00:00,  0.60it/s, v_num=306, train_loss_step=0.0106, train_loss_epoch=0.0115]Epoch 423: Train Loss = 0.01062026433646679\n",
      "Epoch 424: 100%|██████████| 1/1 [00:01<00:00,  0.78it/s, v_num=306, train_loss_step=0.0121, train_loss_epoch=0.0106]Epoch 424: Train Loss = 0.01206920761615038\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 13.91it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.0121]Epoch 425: Train Loss = 0.013113297522068024\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, v_num=306, train_loss_step=0.0126, train_loss_epoch=0.0131]Epoch 426: Train Loss = 0.012648715637624264\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s, v_num=306, train_loss_step=0.0164, train_loss_epoch=0.0126]Epoch 427: Train Loss = 0.01636507548391819\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.0164]Epoch 428: Train Loss = 0.012211539782583714\n",
      "Epoch 429: 100%|██████████| 1/1 [00:02<00:00,  0.37it/s, v_num=306, train_loss_step=0.0113, train_loss_epoch=0.0122]Epoch 429: Train Loss = 0.011273379437625408\n",
      "Epoch 430: 100%|██████████| 1/1 [00:01<00:00,  0.88it/s, v_num=306, train_loss_step=0.0132, train_loss_epoch=0.0113]Epoch 430: Train Loss = 0.013247660361230373\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, v_num=306, train_loss_step=0.0121, train_loss_epoch=0.0132]Epoch 431: Train Loss = 0.012103980407118797\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=306, train_loss_step=0.0134, train_loss_epoch=0.0121]Epoch 432: Train Loss = 0.013392738997936249\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s, v_num=306, train_loss_step=0.0113, train_loss_epoch=0.0134]Epoch 433: Train Loss = 0.011273330077528954\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.0113] Epoch 434: Train Loss = 0.010995444841682911\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=306, train_loss_step=0.0106, train_loss_epoch=0.011]Epoch 435: Train Loss = 0.010649504140019417\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=306, train_loss_step=0.0124, train_loss_epoch=0.0106]Epoch 436: Train Loss = 0.012396229431033134\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=306, train_loss_step=0.010, train_loss_epoch=0.0124] Epoch 437: Train Loss = 0.010020822286605835\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s, v_num=306, train_loss_step=0.00936, train_loss_epoch=0.010]Epoch 438: Train Loss = 0.00935827475041151\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 17.08it/s, v_num=306, train_loss_step=0.0113, train_loss_epoch=0.00936] Epoch 439: Train Loss = 0.011346316896378994\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 13.59it/s, v_num=306, train_loss_step=0.0102, train_loss_epoch=0.0113] Epoch 440: Train Loss = 0.01023543905466795\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=306, train_loss_step=0.00956, train_loss_epoch=0.0102]Epoch 441: Train Loss = 0.009555844590067863\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 12.77it/s, v_num=306, train_loss_step=0.0114, train_loss_epoch=0.00956] Epoch 442: Train Loss = 0.011376016773283482\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=306, train_loss_step=0.0108, train_loss_epoch=0.0114] Epoch 443: Train Loss = 0.010796817019581795\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, v_num=306, train_loss_step=0.0128, train_loss_epoch=0.0108]Epoch 444: Train Loss = 0.012827552855014801\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  3.46it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0128]Epoch 445: Train Loss = 0.011598452925682068\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=306, train_loss_step=0.0111, train_loss_epoch=0.0116]Epoch 446: Train Loss = 0.011087545193731785\n",
      "Epoch 447: 100%|██████████| 1/1 [00:01<00:00,  0.94it/s, v_num=306, train_loss_step=0.00916, train_loss_epoch=0.0111]Epoch 447: Train Loss = 0.009161323308944702\n",
      "Epoch 448: 100%|██████████| 1/1 [00:01<00:00,  0.87it/s, v_num=306, train_loss_step=0.00852, train_loss_epoch=0.00916]Epoch 448: Train Loss = 0.008518319576978683\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s, v_num=306, train_loss_step=0.0126, train_loss_epoch=0.00852] Epoch 449: Train Loss = 0.012566405348479748\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.0126] Epoch 450: Train Loss = 0.010139684192836285\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.0101]Epoch 451: Train Loss = 0.013056834228336811\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.0131]Epoch 452: Train Loss = 0.011213075369596481\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=306, train_loss_step=0.00912, train_loss_epoch=0.0112]Epoch 453: Train Loss = 0.009119018912315369\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s, v_num=306, train_loss_step=0.015, train_loss_epoch=0.00912]  Epoch 454: Train Loss = 0.014959675259888172\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, v_num=306, train_loss_step=0.0104, train_loss_epoch=0.015] Epoch 455: Train Loss = 0.010430744849145412\n",
      "Epoch 456: 100%|██████████| 1/1 [00:01<00:00,  0.72it/s, v_num=306, train_loss_step=0.0108, train_loss_epoch=0.0104]Epoch 456: Train Loss = 0.01078819204121828\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s, v_num=306, train_loss_step=0.00995, train_loss_epoch=0.0108]Epoch 457: Train Loss = 0.009951164945960045\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, v_num=306, train_loss_step=0.00887, train_loss_epoch=0.00995]Epoch 458: Train Loss = 0.008866680786013603\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s, v_num=306, train_loss_step=0.0101, train_loss_epoch=0.00887] Epoch 459: Train Loss = 0.010062898509204388\n",
      "Epoch 460: 100%|██████████| 1/1 [00:01<00:00,  0.56it/s, v_num=306, train_loss_step=0.0103, train_loss_epoch=0.0101] Epoch 460: Train Loss = 0.010297728702425957\n",
      "Epoch 461: 100%|██████████| 1/1 [00:01<00:00,  0.74it/s, v_num=306, train_loss_step=0.0103, train_loss_epoch=0.0103]Epoch 461: Train Loss = 0.010313555598258972\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=306, train_loss_step=0.0109, train_loss_epoch=0.0103]Epoch 462: Train Loss = 0.010933748446404934\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s, v_num=306, train_loss_step=0.0114, train_loss_epoch=0.0109]Epoch 463: Train Loss = 0.01140519417822361\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, v_num=306, train_loss_step=0.0111, train_loss_epoch=0.0114]Epoch 464: Train Loss = 0.011145421303808689\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=306, train_loss_step=0.0113, train_loss_epoch=0.0111]Epoch 465: Train Loss = 0.011342979036271572\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 12.61it/s, v_num=306, train_loss_step=0.0108, train_loss_epoch=0.0113]Epoch 466: Train Loss = 0.010761207900941372\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.0108]Epoch 467: Train Loss = 0.012239712290465832\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, v_num=306, train_loss_step=0.0142, train_loss_epoch=0.0122]Epoch 468: Train Loss = 0.014213175512850285\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=306, train_loss_step=0.0122, train_loss_epoch=0.0142]Epoch 469: Train Loss = 0.012188665568828583\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, v_num=306, train_loss_step=0.0125, train_loss_epoch=0.0122]Epoch 470: Train Loss = 0.012508460320532322\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=306, train_loss_step=0.00935, train_loss_epoch=0.0125]Epoch 471: Train Loss = 0.009352587163448334\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=306, train_loss_step=0.0169, train_loss_epoch=0.00935] Epoch 472: Train Loss = 0.016899149864912033\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, v_num=306, train_loss_step=0.0109, train_loss_epoch=0.0169] Epoch 473: Train Loss = 0.0108731584623456\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=306, train_loss_step=0.0119, train_loss_epoch=0.0109]Epoch 474: Train Loss = 0.011858516372740269\n",
      "Epoch 475: 100%|██████████| 1/1 [00:01<00:00,  0.64it/s, v_num=306, train_loss_step=0.0115, train_loss_epoch=0.0119]Epoch 475: Train Loss = 0.011472866870462894\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, v_num=306, train_loss_step=0.011, train_loss_epoch=0.0115] Epoch 476: Train Loss = 0.01099917571991682\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=306, train_loss_step=0.0159, train_loss_epoch=0.011]Epoch 477: Train Loss = 0.015907863155007362\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=306, train_loss_step=0.0113, train_loss_epoch=0.0159]Epoch 478: Train Loss = 0.01130378246307373\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=306, train_loss_step=0.0194, train_loss_epoch=0.0113]Epoch 479: Train Loss = 0.019435469061136246\n",
      "Epoch 480: 100%|██████████| 1/1 [00:02<00:00,  0.49it/s, v_num=306, train_loss_step=0.00946, train_loss_epoch=0.0194]Epoch 480: Train Loss = 0.009459003806114197\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.00946] Epoch 481: Train Loss = 0.011561504565179348\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0116] Epoch 482: Train Loss = 0.01293986290693283\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s, v_num=306, train_loss_step=0.0118, train_loss_epoch=0.0129]Epoch 483: Train Loss = 0.011803233996033669\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 13.54it/s, v_num=306, train_loss_step=0.0104, train_loss_epoch=0.0118]Epoch 484: Train Loss = 0.010443218052387238\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 16.60it/s, v_num=306, train_loss_step=0.0112, train_loss_epoch=0.0104]Epoch 485: Train Loss = 0.011227584443986416\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s, v_num=306, train_loss_step=0.0125, train_loss_epoch=0.0112]Epoch 486: Train Loss = 0.012483309023082256\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=306, train_loss_step=0.0103, train_loss_epoch=0.0125]Epoch 487: Train Loss = 0.010298280045390129\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=306, train_loss_step=0.0105, train_loss_epoch=0.0103]Epoch 488: Train Loss = 0.010463421232998371\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0105]Epoch 489: Train Loss = 0.011569793336093426\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=306, train_loss_step=0.0088, train_loss_epoch=0.0116]Epoch 490: Train Loss = 0.008799534291028976\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s, v_num=306, train_loss_step=0.013, train_loss_epoch=0.0088] Epoch 491: Train Loss = 0.013039435259997845\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s, v_num=306, train_loss_step=0.0121, train_loss_epoch=0.013]Epoch 492: Train Loss = 0.012131212279200554\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, v_num=306, train_loss_step=0.0131, train_loss_epoch=0.0121]Epoch 493: Train Loss = 0.013107840903103352\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s, v_num=306, train_loss_step=0.0129, train_loss_epoch=0.0131]Epoch 494: Train Loss = 0.01292991079390049\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s, v_num=306, train_loss_step=0.0123, train_loss_epoch=0.0129]Epoch 495: Train Loss = 0.012254251167178154\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, v_num=306, train_loss_step=0.0102, train_loss_epoch=0.0123]Epoch 496: Train Loss = 0.010161054320633411\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=306, train_loss_step=0.014, train_loss_epoch=0.0102] Epoch 497: Train Loss = 0.01397478487342596\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s, v_num=306, train_loss_step=0.013, train_loss_epoch=0.014] Epoch 498: Train Loss = 0.013032124377787113\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.013]Epoch 499: Train Loss = 0.0115877166390419\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0116]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=306, train_loss_step=0.0116, train_loss_epoch=0.0116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training window 5: from 2010-06-30 00:00:00 to 2022-08-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:01<00:00,  0.67it/s, v_num=312, train_loss_step=0.0287]Epoch 0: Train Loss = 0.028715552762150764\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=312, train_loss_step=0.0398, train_loss_epoch=0.0287]Epoch 1: Train Loss = 0.03981563821434975\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=312, train_loss_step=0.0343, train_loss_epoch=0.0398]Epoch 2: Train Loss = 0.03431626781821251\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s, v_num=312, train_loss_step=0.0209, train_loss_epoch=0.0343]Epoch 3: Train Loss = 0.020942019298672676\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s, v_num=312, train_loss_step=0.0285, train_loss_epoch=0.0209]Epoch 4: Train Loss = 0.02848501317203045\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=312, train_loss_step=0.0226, train_loss_epoch=0.0285]Epoch 5: Train Loss = 0.02261202037334442\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=312, train_loss_step=0.020, train_loss_epoch=0.0226] Epoch 6: Train Loss = 0.01995154283940792\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=312, train_loss_step=0.0172, train_loss_epoch=0.020]Epoch 7: Train Loss = 0.017171313986182213\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s, v_num=312, train_loss_step=0.0206, train_loss_epoch=0.0172]Epoch 8: Train Loss = 0.0206406582146883\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=312, train_loss_step=0.0193, train_loss_epoch=0.0206]Epoch 9: Train Loss = 0.019325798377394676\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=312, train_loss_step=0.0207, train_loss_epoch=0.0193]Epoch 10: Train Loss = 0.020708972588181496\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=312, train_loss_step=0.0157, train_loss_epoch=0.0207]Epoch 11: Train Loss = 0.015691358596086502\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=312, train_loss_step=0.0132, train_loss_epoch=0.0157]Epoch 12: Train Loss = 0.013222389854490757\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=312, train_loss_step=0.0178, train_loss_epoch=0.0132]Epoch 13: Train Loss = 0.017802106216549873\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s, v_num=312, train_loss_step=0.0146, train_loss_epoch=0.0178]Epoch 14: Train Loss = 0.014616241678595543\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=312, train_loss_step=0.0168, train_loss_epoch=0.0146]Epoch 15: Train Loss = 0.016782375052571297\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=312, train_loss_step=0.0172, train_loss_epoch=0.0168]Epoch 16: Train Loss = 0.01717742532491684\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  3.38it/s, v_num=312, train_loss_step=0.0132, train_loss_epoch=0.0172]Epoch 17: Train Loss = 0.013228869996964931\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=312, train_loss_step=0.0115, train_loss_epoch=0.0132]Epoch 18: Train Loss = 0.011461960151791573\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=312, train_loss_step=0.0135, train_loss_epoch=0.0115]Epoch 19: Train Loss = 0.013467137701809406\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.0135] Epoch 20: Train Loss = 0.013971326872706413\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 10.72it/s, v_num=312, train_loss_step=0.0133, train_loss_epoch=0.014]Epoch 21: Train Loss = 0.013298877514898777\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0133]Epoch 22: Train Loss = 0.012490028515458107\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=312, train_loss_step=0.0115, train_loss_epoch=0.0125]Epoch 23: Train Loss = 0.011516186408698559\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s, v_num=312, train_loss_step=0.0183, train_loss_epoch=0.0115]Epoch 24: Train Loss = 0.01832384243607521\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0183]Epoch 25: Train Loss = 0.012496772222220898\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s, v_num=312, train_loss_step=0.0154, train_loss_epoch=0.0125]Epoch 26: Train Loss = 0.01535006519407034\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, v_num=312, train_loss_step=0.00983, train_loss_epoch=0.0154]Epoch 27: Train Loss = 0.009827318601310253\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=312, train_loss_step=0.0178, train_loss_epoch=0.00983] Epoch 28: Train Loss = 0.017767880111932755\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=312, train_loss_step=0.0122, train_loss_epoch=0.0178] Epoch 29: Train Loss = 0.0122222900390625\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=312, train_loss_step=0.0112, train_loss_epoch=0.0122]Epoch 30: Train Loss = 0.011205404996871948\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=312, train_loss_step=0.0148, train_loss_epoch=0.0112]Epoch 31: Train Loss = 0.014785951934754848\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=312, train_loss_step=0.0147, train_loss_epoch=0.0148]Epoch 32: Train Loss = 0.014654942788183689\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=312, train_loss_step=0.0153, train_loss_epoch=0.0147]Epoch 33: Train Loss = 0.01526699960231781\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=312, train_loss_step=0.0163, train_loss_epoch=0.0153]Epoch 34: Train Loss = 0.01628727838397026\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=312, train_loss_step=0.0126, train_loss_epoch=0.0163]Epoch 35: Train Loss = 0.012633507139980793\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=312, train_loss_step=0.0135, train_loss_epoch=0.0126]Epoch 36: Train Loss = 0.013491062447428703\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s, v_num=312, train_loss_step=0.0093, train_loss_epoch=0.0135]Epoch 37: Train Loss = 0.009300408884882927\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0093]Epoch 38: Train Loss = 0.012495824135839939\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.0125]Epoch 39: Train Loss = 0.010619202628731728\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.0106]Epoch 40: Train Loss = 0.012945200316607952\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=312, train_loss_step=0.0136, train_loss_epoch=0.0129]Epoch 41: Train Loss = 0.013617697171866894\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=312, train_loss_step=0.0141, train_loss_epoch=0.0136]Epoch 42: Train Loss = 0.014118723571300507\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, v_num=312, train_loss_step=0.0105, train_loss_epoch=0.0141]Epoch 43: Train Loss = 0.010546342469751835\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=312, train_loss_step=0.0153, train_loss_epoch=0.0105]Epoch 44: Train Loss = 0.01532632578164339\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=312, train_loss_step=0.0142, train_loss_epoch=0.0153]Epoch 45: Train Loss = 0.01417489256709814\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s, v_num=312, train_loss_step=0.0176, train_loss_epoch=0.0142]Epoch 46: Train Loss = 0.0175535399466753\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=312, train_loss_step=0.0138, train_loss_epoch=0.0176]Epoch 47: Train Loss = 0.013792389072477818\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=312, train_loss_step=0.0119, train_loss_epoch=0.0138]Epoch 48: Train Loss = 0.011897402815520763\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=312, train_loss_step=0.00932, train_loss_epoch=0.0119]Epoch 49: Train Loss = 0.009324380196630955\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=312, train_loss_step=0.0117, train_loss_epoch=0.00932] Epoch 50: Train Loss = 0.01173738669604063\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s, v_num=312, train_loss_step=0.0146, train_loss_epoch=0.0117] Epoch 51: Train Loss = 0.014553721062839031\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=312, train_loss_step=0.00954, train_loss_epoch=0.0146]Epoch 52: Train Loss = 0.009539416991174221\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.00954]  Epoch 53: Train Loss = 0.013964156620204449\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=312, train_loss_step=0.0128, train_loss_epoch=0.014] Epoch 54: Train Loss = 0.012763751670718193\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.0128]Epoch 55: Train Loss = 0.010577579960227013\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.0106]Epoch 56: Train Loss = 0.01212277077138424\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  3.46it/s, v_num=312, train_loss_step=0.0107, train_loss_epoch=0.0121]Epoch 57: Train Loss = 0.0106928376480937\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=312, train_loss_step=0.0137, train_loss_epoch=0.0107]Epoch 58: Train Loss = 0.01370792556554079\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=312, train_loss_step=0.0147, train_loss_epoch=0.0137]Epoch 59: Train Loss = 0.014725725166499615\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=312, train_loss_step=0.0175, train_loss_epoch=0.0147]Epoch 60: Train Loss = 0.017539266496896744\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.0175]Epoch 61: Train Loss = 0.012065746821463108\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=312, train_loss_step=0.0101, train_loss_epoch=0.0121]Epoch 62: Train Loss = 0.010082654654979706\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.0101] Epoch 63: Train Loss = 0.014011768624186516\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.014]Epoch 64: Train Loss = 0.012474494986236095\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=312, train_loss_step=0.0123, train_loss_epoch=0.0125]Epoch 65: Train Loss = 0.012347789481282234\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=312, train_loss_step=0.0139, train_loss_epoch=0.0123]Epoch 66: Train Loss = 0.013917207717895508\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=312, train_loss_step=0.0136, train_loss_epoch=0.0139]Epoch 67: Train Loss = 0.013643196783959866\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0136]Epoch 68: Train Loss = 0.012518411502242088\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=312, train_loss_step=0.010, train_loss_epoch=0.0125] Epoch 69: Train Loss = 0.010010262951254845\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s, v_num=312, train_loss_step=0.0127, train_loss_epoch=0.010]Epoch 70: Train Loss = 0.012737804092466831\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=312, train_loss_step=0.0133, train_loss_epoch=0.0127]Epoch 71: Train Loss = 0.013290027156472206\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=312, train_loss_step=0.00973, train_loss_epoch=0.0133]Epoch 72: Train Loss = 0.009730294346809387\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s, v_num=312, train_loss_step=0.0149, train_loss_epoch=0.00973] Epoch 73: Train Loss = 0.014927987940609455\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=312, train_loss_step=0.0109, train_loss_epoch=0.0149] Epoch 74: Train Loss = 0.010886115953326225\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0109]Epoch 75: Train Loss = 0.012462222948670387\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=312, train_loss_step=0.0158, train_loss_epoch=0.0125]Epoch 76: Train Loss = 0.01575380750000477\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=312, train_loss_step=0.0173, train_loss_epoch=0.0158]Epoch 77: Train Loss = 0.01728658378124237\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=312, train_loss_step=0.0132, train_loss_epoch=0.0173]Epoch 78: Train Loss = 0.01322156097739935\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=312, train_loss_step=0.011, train_loss_epoch=0.0132] Epoch 79: Train Loss = 0.010993861593306065\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=312, train_loss_step=0.0118, train_loss_epoch=0.011]Epoch 80: Train Loss = 0.01179229561239481\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=312, train_loss_step=0.0126, train_loss_epoch=0.0118]Epoch 81: Train Loss = 0.012567037716507912\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=312, train_loss_step=0.0135, train_loss_epoch=0.0126]Epoch 82: Train Loss = 0.013470608741044998\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=312, train_loss_step=0.0117, train_loss_epoch=0.0135]Epoch 83: Train Loss = 0.011721623130142689\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=312, train_loss_step=0.0173, train_loss_epoch=0.0117]Epoch 84: Train Loss = 0.01733664982020855\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=312, train_loss_step=0.0147, train_loss_epoch=0.0173]Epoch 85: Train Loss = 0.014678223058581352\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.0147]Epoch 86: Train Loss = 0.01058921031653881\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=312, train_loss_step=0.00974, train_loss_epoch=0.0106]Epoch 87: Train Loss = 0.009743857197463512\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=312, train_loss_step=0.0127, train_loss_epoch=0.00974] Epoch 88: Train Loss = 0.01271149329841137\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=312, train_loss_step=0.0134, train_loss_epoch=0.0127] Epoch 89: Train Loss = 0.01340574026107788\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s, v_num=312, train_loss_step=0.00946, train_loss_epoch=0.0134]Epoch 90: Train Loss = 0.009455906227231026\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=312, train_loss_step=0.00889, train_loss_epoch=0.00946]Epoch 91: Train Loss = 0.008894781582057476\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=312, train_loss_step=0.0122, train_loss_epoch=0.00889] Epoch 92: Train Loss = 0.01217383798211813\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0122] Epoch 93: Train Loss = 0.01252724975347519\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s, v_num=312, train_loss_step=0.00988, train_loss_epoch=0.0125]Epoch 94: Train Loss = 0.009876874275505543\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=312, train_loss_step=0.0098, train_loss_epoch=0.00988] Epoch 95: Train Loss = 0.009804093278944492\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=312, train_loss_step=0.012, train_loss_epoch=0.0098]  Epoch 96: Train Loss = 0.012037196196615696\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=312, train_loss_step=0.0128, train_loss_epoch=0.012]Epoch 97: Train Loss = 0.0128230145201087\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=312, train_loss_step=0.0111, train_loss_epoch=0.0128]Epoch 98: Train Loss = 0.011081824079155922\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=312, train_loss_step=0.0136, train_loss_epoch=0.0111]Epoch 99: Train Loss = 0.013642394915223122\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=312, train_loss_step=0.0105, train_loss_epoch=0.0136]Epoch 100: Train Loss = 0.010473476722836494\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=312, train_loss_step=0.0122, train_loss_epoch=0.0105]Epoch 101: Train Loss = 0.012244566343724728\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 16.36it/s, v_num=312, train_loss_step=0.0154, train_loss_epoch=0.0122]Epoch 102: Train Loss = 0.015436934307217598\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=312, train_loss_step=0.00856, train_loss_epoch=0.0154]Epoch 103: Train Loss = 0.00855732150375843\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.00856] Epoch 104: Train Loss = 0.011331381276249886\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=312, train_loss_step=0.0107, train_loss_epoch=0.0113] Epoch 105: Train Loss = 0.010735486634075642\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0107]Epoch 106: Train Loss = 0.011306081898510456\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=312, train_loss_step=0.0112, train_loss_epoch=0.0113]Epoch 107: Train Loss = 0.011190048418939114\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=312, train_loss_step=0.0103, train_loss_epoch=0.0112]Epoch 108: Train Loss = 0.01025728601962328\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.0103] Epoch 109: Train Loss = 0.014049472287297249\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.014] Epoch 110: Train Loss = 0.013954193331301212\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=312, train_loss_step=0.0139, train_loss_epoch=0.014]Epoch 111: Train Loss = 0.013886776752769947\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=312, train_loss_step=0.00975, train_loss_epoch=0.0139]Epoch 112: Train Loss = 0.00975437369197607\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=312, train_loss_step=0.0102, train_loss_epoch=0.00975] Epoch 113: Train Loss = 0.010203355923295021\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.0102]  Epoch 114: Train Loss = 0.014007248915731907\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.014]Epoch 115: Train Loss = 0.012107006274163723\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=312, train_loss_step=0.0206, train_loss_epoch=0.0121]Epoch 116: Train Loss = 0.02061314508318901\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.0206]Epoch 117: Train Loss = 0.011405186727643013\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s, v_num=312, train_loss_step=0.0142, train_loss_epoch=0.0114]Epoch 118: Train Loss = 0.014185288920998573\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=312, train_loss_step=0.0137, train_loss_epoch=0.0142]Epoch 119: Train Loss = 0.013712072744965553\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0137]Epoch 120: Train Loss = 0.01132724154740572\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=312, train_loss_step=0.011, train_loss_epoch=0.0113] Epoch 121: Train Loss = 0.010985746048390865\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=312, train_loss_step=0.0118, train_loss_epoch=0.011]Epoch 122: Train Loss = 0.011843574233353138\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=312, train_loss_step=0.0147, train_loss_epoch=0.0118]Epoch 123: Train Loss = 0.014699521474540234\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=312, train_loss_step=0.011, train_loss_epoch=0.0147] Epoch 124: Train Loss = 0.011039340868592262\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=312, train_loss_step=0.0139, train_loss_epoch=0.011]Epoch 125: Train Loss = 0.013871421106159687\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=312, train_loss_step=0.0141, train_loss_epoch=0.0139]Epoch 126: Train Loss = 0.0141416871920228\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=312, train_loss_step=0.011, train_loss_epoch=0.0141] Epoch 127: Train Loss = 0.011014715768396854\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=312, train_loss_step=0.0127, train_loss_epoch=0.011]Epoch 128: Train Loss = 0.012719114311039448\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s, v_num=312, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 129: Train Loss = 0.011960769072175026\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=312, train_loss_step=0.00836, train_loss_epoch=0.012]Epoch 130: Train Loss = 0.008363842032849789\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.00836] Epoch 131: Train Loss = 0.012855282984673977\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=312, train_loss_step=0.0163, train_loss_epoch=0.0129] Epoch 132: Train Loss = 0.0162876658141613\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=312, train_loss_step=0.0141, train_loss_epoch=0.0163]Epoch 133: Train Loss = 0.014083461835980415\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 13.21it/s, v_num=312, train_loss_step=0.0109, train_loss_epoch=0.0141]Epoch 134: Train Loss = 0.010865611024200916\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=312, train_loss_step=0.0163, train_loss_epoch=0.0109]Epoch 135: Train Loss = 0.016254231333732605\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=312, train_loss_step=0.013, train_loss_epoch=0.0163] Epoch 136: Train Loss = 0.01296475064009428\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.013]Epoch 137: Train Loss = 0.012058385647833347\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 16.45it/s, v_num=312, train_loss_step=0.0182, train_loss_epoch=0.0121]Epoch 138: Train Loss = 0.01817292906343937\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=312, train_loss_step=0.0188, train_loss_epoch=0.0182]Epoch 139: Train Loss = 0.018763409927487373\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=312, train_loss_step=0.0119, train_loss_epoch=0.0188]Epoch 140: Train Loss = 0.011937995441257954\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 16.54it/s, v_num=312, train_loss_step=0.015, train_loss_epoch=0.0119] Epoch 141: Train Loss = 0.015034851618111134\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=312, train_loss_step=0.00916, train_loss_epoch=0.015]Epoch 142: Train Loss = 0.009157327935099602\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=312, train_loss_step=0.0122, train_loss_epoch=0.00916] Epoch 143: Train Loss = 0.012183055281639099\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=312, train_loss_step=0.0154, train_loss_epoch=0.0122] Epoch 144: Train Loss = 0.015410833060741425\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=312, train_loss_step=0.0124, train_loss_epoch=0.0154]Epoch 145: Train Loss = 0.012417355552315712\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s, v_num=312, train_loss_step=0.0095, train_loss_epoch=0.0124]Epoch 146: Train Loss = 0.00950321089476347\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=312, train_loss_step=0.0138, train_loss_epoch=0.0095]Epoch 147: Train Loss = 0.013781770132482052\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=312, train_loss_step=0.0111, train_loss_epoch=0.0138]Epoch 148: Train Loss = 0.011089806444942951\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=312, train_loss_step=0.0117, train_loss_epoch=0.0111]Epoch 149: Train Loss = 0.01171902846544981\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=312, train_loss_step=0.0144, train_loss_epoch=0.0117]Epoch 150: Train Loss = 0.014420236460864544\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=312, train_loss_step=0.00877, train_loss_epoch=0.0144]Epoch 151: Train Loss = 0.008768213912844658\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=312, train_loss_step=0.0119, train_loss_epoch=0.00877] Epoch 152: Train Loss = 0.011873877607285976\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=312, train_loss_step=0.015, train_loss_epoch=0.0119]  Epoch 153: Train Loss = 0.015021163038909435\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=312, train_loss_step=0.0119, train_loss_epoch=0.015]Epoch 154: Train Loss = 0.011922868900001049\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=312, train_loss_step=0.0178, train_loss_epoch=0.0119]Epoch 155: Train Loss = 0.017843615263700485\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=312, train_loss_step=0.0141, train_loss_epoch=0.0178]Epoch 156: Train Loss = 0.014105362817645073\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.0141] Epoch 157: Train Loss = 0.014037242159247398\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=312, train_loss_step=0.0117, train_loss_epoch=0.014]Epoch 158: Train Loss = 0.011683470569550991\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=312, train_loss_step=0.0101, train_loss_epoch=0.0117]Epoch 159: Train Loss = 0.010094032622873783\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.0101] Epoch 160: Train Loss = 0.013984506949782372\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=312, train_loss_step=0.0112, train_loss_epoch=0.014]Epoch 161: Train Loss = 0.011161847971379757\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=312, train_loss_step=0.0127, train_loss_epoch=0.0112]Epoch 162: Train Loss = 0.012689992785453796\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=312, train_loss_step=0.0141, train_loss_epoch=0.0127]Epoch 163: Train Loss = 0.014114300720393658\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=312, train_loss_step=0.0156, train_loss_epoch=0.0141]Epoch 164: Train Loss = 0.01555363368242979\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 11.82it/s, v_num=312, train_loss_step=0.0128, train_loss_epoch=0.0156]Epoch 165: Train Loss = 0.012849320657551289\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0128]Epoch 166: Train Loss = 0.011285237036645412\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=312, train_loss_step=0.0149, train_loss_epoch=0.0113]Epoch 167: Train Loss = 0.014863588847219944\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0149]Epoch 168: Train Loss = 0.012536248192191124\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=312, train_loss_step=0.0111, train_loss_epoch=0.0125]Epoch 169: Train Loss = 0.01112640555948019\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.0111]Epoch 170: Train Loss = 0.011382602155208588\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=312, train_loss_step=0.0157, train_loss_epoch=0.0114]Epoch 171: Train Loss = 0.01570521667599678\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=312, train_loss_step=0.0147, train_loss_epoch=0.0157]Epoch 172: Train Loss = 0.01473128143697977\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=312, train_loss_step=0.0115, train_loss_epoch=0.0147]Epoch 173: Train Loss = 0.011468647047877312\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s, v_num=312, train_loss_step=0.00903, train_loss_epoch=0.0115]Epoch 174: Train Loss = 0.009034902788698673\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=312, train_loss_step=0.0109, train_loss_epoch=0.00903] Epoch 175: Train Loss = 0.010932092554867268\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=312, train_loss_step=0.0124, train_loss_epoch=0.0109] Epoch 176: Train Loss = 0.012413251213729382\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=312, train_loss_step=0.015, train_loss_epoch=0.0124] Epoch 177: Train Loss = 0.014961091801524162\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=312, train_loss_step=0.0116, train_loss_epoch=0.015]Epoch 178: Train Loss = 0.011647423729300499\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, v_num=312, train_loss_step=0.0119, train_loss_epoch=0.0116]Epoch 179: Train Loss = 0.011898274533450603\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s, v_num=312, train_loss_step=0.0107, train_loss_epoch=0.0119]Epoch 180: Train Loss = 0.010690917260944843\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=312, train_loss_step=0.0104, train_loss_epoch=0.0107]Epoch 181: Train Loss = 0.010436149314045906\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 12.90it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0104]Epoch 182: Train Loss = 0.01125755812972784\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.0113]Epoch 183: Train Loss = 0.012919044122099876\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=312, train_loss_step=0.0142, train_loss_epoch=0.0129]Epoch 184: Train Loss = 0.014236903749406338\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s, v_num=312, train_loss_step=0.0127, train_loss_epoch=0.0142]Epoch 185: Train Loss = 0.012740224599838257\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=312, train_loss_step=0.0117, train_loss_epoch=0.0127]Epoch 186: Train Loss = 0.011718335561454296\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, v_num=312, train_loss_step=0.0126, train_loss_epoch=0.0117]Epoch 187: Train Loss = 0.01261286623775959\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0126]Epoch 188: Train Loss = 0.011301764287054539\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=312, train_loss_step=0.0127, train_loss_epoch=0.0113]Epoch 189: Train Loss = 0.012651394121348858\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s, v_num=312, train_loss_step=0.0167, train_loss_epoch=0.0127]Epoch 190: Train Loss = 0.01665102131664753\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=312, train_loss_step=0.0135, train_loss_epoch=0.0167]Epoch 191: Train Loss = 0.013534483499825\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s, v_num=312, train_loss_step=0.0115, train_loss_epoch=0.0135]Epoch 192: Train Loss = 0.011523163877427578\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=312, train_loss_step=0.0116, train_loss_epoch=0.0115]Epoch 193: Train Loss = 0.011559338308870792\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s, v_num=312, train_loss_step=0.0116, train_loss_epoch=0.0116]Epoch 194: Train Loss = 0.01157183013856411\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=312, train_loss_step=0.0111, train_loss_epoch=0.0116]Epoch 195: Train Loss = 0.011071079410612583\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.0111]Epoch 196: Train Loss = 0.010553069412708282\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=312, train_loss_step=0.010, train_loss_epoch=0.0106] Epoch 197: Train Loss = 0.01003321260213852\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=312, train_loss_step=0.013, train_loss_epoch=0.010] Epoch 198: Train Loss = 0.01298725139349699\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 13.79it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.013]Epoch 199: Train Loss = 0.011417962610721588\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=312, train_loss_step=0.0127, train_loss_epoch=0.0114]Epoch 200: Train Loss = 0.012704604305326939\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=312, train_loss_step=0.0108, train_loss_epoch=0.0127]Epoch 201: Train Loss = 0.01082560420036316\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=312, train_loss_step=0.0116, train_loss_epoch=0.0108]Epoch 202: Train Loss = 0.011647245846688747\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=312, train_loss_step=0.0131, train_loss_epoch=0.0116]Epoch 203: Train Loss = 0.013134753331542015\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=312, train_loss_step=0.0136, train_loss_epoch=0.0131]Epoch 204: Train Loss = 0.01362906489521265\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s, v_num=312, train_loss_step=0.015, train_loss_epoch=0.0136] Epoch 205: Train Loss = 0.015041601844131947\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=312, train_loss_step=0.011, train_loss_epoch=0.015] Epoch 206: Train Loss = 0.01095678098499775\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=312, train_loss_step=0.0144, train_loss_epoch=0.011]Epoch 207: Train Loss = 0.014424743130803108\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=312, train_loss_step=0.0101, train_loss_epoch=0.0144]Epoch 208: Train Loss = 0.010066756047308445\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s, v_num=312, train_loss_step=0.0144, train_loss_epoch=0.0101]Epoch 209: Train Loss = 0.014368763193488121\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s, v_num=312, train_loss_step=0.0144, train_loss_epoch=0.0144]Epoch 210: Train Loss = 0.014388812705874443\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=312, train_loss_step=0.00995, train_loss_epoch=0.0144]Epoch 211: Train Loss = 0.009948919527232647\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=312, train_loss_step=0.0118, train_loss_epoch=0.00995] Epoch 212: Train Loss = 0.011767026968300343\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=312, train_loss_step=0.0161, train_loss_epoch=0.0118] Epoch 213: Train Loss = 0.016134265810251236\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=312, train_loss_step=0.017, train_loss_epoch=0.0161] Epoch 214: Train Loss = 0.017026977613568306\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=312, train_loss_step=0.0154, train_loss_epoch=0.017]Epoch 215: Train Loss = 0.015373392030596733\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=312, train_loss_step=0.0142, train_loss_epoch=0.0154]Epoch 216: Train Loss = 0.014212285168468952\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.0142]Epoch 217: Train Loss = 0.011449252255260944\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 14.13it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0114]Epoch 218: Train Loss = 0.012523780576884747\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=312, train_loss_step=0.0137, train_loss_epoch=0.0125]Epoch 219: Train Loss = 0.013667689636349678\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=312, train_loss_step=0.0186, train_loss_epoch=0.0137]Epoch 220: Train Loss = 0.018556011840701103\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=312, train_loss_step=0.0145, train_loss_epoch=0.0186]Epoch 221: Train Loss = 0.014471381902694702\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=312, train_loss_step=0.0137, train_loss_epoch=0.0145]Epoch 222: Train Loss = 0.013747463002800941\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 12.51it/s, v_num=312, train_loss_step=0.0136, train_loss_epoch=0.0137]Epoch 223: Train Loss = 0.0136067820712924\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.0136] Epoch 224: Train Loss = 0.014007924124598503\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=312, train_loss_step=0.0126, train_loss_epoch=0.014]Epoch 225: Train Loss = 0.012605714611709118\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 12.60it/s, v_num=312, train_loss_step=0.00927, train_loss_epoch=0.0126]Epoch 226: Train Loss = 0.009267706423997879\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.00927] Epoch 227: Train Loss = 0.011340923607349396\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=312, train_loss_step=0.0103, train_loss_epoch=0.0113] Epoch 228: Train Loss = 0.010305218398571014\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.0103]Epoch 229: Train Loss = 0.010648076422512531\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.0106]Epoch 230: Train Loss = 0.012861107476055622\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s, v_num=312, train_loss_step=0.0133, train_loss_epoch=0.0129]Epoch 231: Train Loss = 0.013305740430951118\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=312, train_loss_step=0.0184, train_loss_epoch=0.0133]Epoch 232: Train Loss = 0.018434392288327217\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=312, train_loss_step=0.0169, train_loss_epoch=0.0184]Epoch 233: Train Loss = 0.016866033896803856\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=312, train_loss_step=0.0136, train_loss_epoch=0.0169]Epoch 234: Train Loss = 0.013608337379992008\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0136]Epoch 235: Train Loss = 0.012503749690949917\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=312, train_loss_step=0.0201, train_loss_epoch=0.0125]Epoch 236: Train Loss = 0.020127693191170692\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=312, train_loss_step=0.00857, train_loss_epoch=0.0201]Epoch 237: Train Loss = 0.008567700162529945\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=312, train_loss_step=0.0131, train_loss_epoch=0.00857] Epoch 238: Train Loss = 0.01308094710111618\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=312, train_loss_step=0.0206, train_loss_epoch=0.0131] Epoch 239: Train Loss = 0.020551472902297974\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=312, train_loss_step=0.0138, train_loss_epoch=0.0206]Epoch 240: Train Loss = 0.013835752382874489\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=312, train_loss_step=0.0133, train_loss_epoch=0.0138]Epoch 241: Train Loss = 0.013303943909704685\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=312, train_loss_step=0.0133, train_loss_epoch=0.0133]Epoch 242: Train Loss = 0.013299102894961834\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0133]Epoch 243: Train Loss = 0.011317849159240723\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=312, train_loss_step=0.0128, train_loss_epoch=0.0113]Epoch 244: Train Loss = 0.012830584309995174\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.0128] Epoch 245: Train Loss = 0.013996971771121025\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=312, train_loss_step=0.0128, train_loss_epoch=0.014]Epoch 246: Train Loss = 0.012825807556509972\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 12.54it/s, v_num=312, train_loss_step=0.0139, train_loss_epoch=0.0128]Epoch 247: Train Loss = 0.013856844045221806\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=312, train_loss_step=0.00847, train_loss_epoch=0.0139]Epoch 248: Train Loss = 0.008471637032926083\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=312, train_loss_step=0.0168, train_loss_epoch=0.00847] Epoch 249: Train Loss = 0.01675296388566494\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=312, train_loss_step=0.0119, train_loss_epoch=0.0168] Epoch 250: Train Loss = 0.011911258101463318\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=312, train_loss_step=0.0159, train_loss_epoch=0.0119]Epoch 251: Train Loss = 0.015929626300930977\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=312, train_loss_step=0.0195, train_loss_epoch=0.0159]Epoch 252: Train Loss = 0.01953909918665886\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=312, train_loss_step=0.0225, train_loss_epoch=0.0195]Epoch 253: Train Loss = 0.02254493348300457\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=312, train_loss_step=0.0182, train_loss_epoch=0.0225]Epoch 254: Train Loss = 0.018244890496134758\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=312, train_loss_step=0.0133, train_loss_epoch=0.0182]Epoch 255: Train Loss = 0.01333723682910204\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 13.82it/s, v_num=312, train_loss_step=0.0186, train_loss_epoch=0.0133]Epoch 256: Train Loss = 0.018617382273077965\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0186]Epoch 257: Train Loss = 0.01128541398793459\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.0113]Epoch 258: Train Loss = 0.012914500199258327\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=312, train_loss_step=0.0134, train_loss_epoch=0.0129]Epoch 259: Train Loss = 0.013411076739430428\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=312, train_loss_step=0.0135, train_loss_epoch=0.0134]Epoch 260: Train Loss = 0.013532334007322788\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.0135]Epoch 261: Train Loss = 0.010593988932669163\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s, v_num=312, train_loss_step=0.0179, train_loss_epoch=0.0106]Epoch 262: Train Loss = 0.01790703274309635\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=312, train_loss_step=0.0112, train_loss_epoch=0.0179]Epoch 263: Train Loss = 0.011233503930270672\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, v_num=312, train_loss_step=0.0102, train_loss_epoch=0.0112]Epoch 264: Train Loss = 0.010159678757190704\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=312, train_loss_step=0.0132, train_loss_epoch=0.0102]Epoch 265: Train Loss = 0.0131765091791749\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=312, train_loss_step=0.00994, train_loss_epoch=0.0132]Epoch 266: Train Loss = 0.009944905526936054\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.00994] Epoch 267: Train Loss = 0.012092328630387783\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.0121] Epoch 268: Train Loss = 0.012894128449261189\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=312, train_loss_step=0.0174, train_loss_epoch=0.0129]Epoch 269: Train Loss = 0.017374888062477112\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 11.43it/s, v_num=312, train_loss_step=0.0143, train_loss_epoch=0.0174]Epoch 270: Train Loss = 0.01431227382272482\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s, v_num=312, train_loss_step=0.0134, train_loss_epoch=0.0143]Epoch 271: Train Loss = 0.013426537625491619\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.0134]Epoch 272: Train Loss = 0.011356084607541561\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=312, train_loss_step=0.0156, train_loss_epoch=0.0114]Epoch 273: Train Loss = 0.015623295679688454\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=312, train_loss_step=0.0157, train_loss_epoch=0.0156]Epoch 274: Train Loss = 0.01573668047785759\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s, v_num=312, train_loss_step=0.0123, train_loss_epoch=0.0157]Epoch 275: Train Loss = 0.012319923378527164\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.0123]Epoch 276: Train Loss = 0.01288818009197712\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=312, train_loss_step=0.0175, train_loss_epoch=0.0129]Epoch 277: Train Loss = 0.017547983676195145\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=312, train_loss_step=0.0149, train_loss_epoch=0.0175]Epoch 278: Train Loss = 0.014907092787325382\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=312, train_loss_step=0.0138, train_loss_epoch=0.0149]Epoch 279: Train Loss = 0.013806330040097237\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 13.21it/s, v_num=312, train_loss_step=0.00944, train_loss_epoch=0.0138]Epoch 280: Train Loss = 0.009444428607821465\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=312, train_loss_step=0.0122, train_loss_epoch=0.00944] Epoch 281: Train Loss = 0.0121862031519413\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=312, train_loss_step=0.0136, train_loss_epoch=0.0122] Epoch 282: Train Loss = 0.013579441234469414\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 15.92it/s, v_num=312, train_loss_step=0.011, train_loss_epoch=0.0136] Epoch 283: Train Loss = 0.01101808063685894\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 16.40it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.011]Epoch 284: Train Loss = 0.011344452388584614\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 16.62it/s, v_num=312, train_loss_step=0.0117, train_loss_epoch=0.0113]Epoch 285: Train Loss = 0.011711196042597294\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=312, train_loss_step=0.00951, train_loss_epoch=0.0117]Epoch 286: Train Loss = 0.00950691569596529\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=312, train_loss_step=0.0123, train_loss_epoch=0.00951] Epoch 287: Train Loss = 0.012303980998694897\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 16.07it/s, v_num=312, train_loss_step=0.0109, train_loss_epoch=0.0123] Epoch 288: Train Loss = 0.010941432788968086\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=312, train_loss_step=0.011, train_loss_epoch=0.0109] Epoch 289: Train Loss = 0.011020123027265072\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, v_num=312, train_loss_step=0.0162, train_loss_epoch=0.011]Epoch 290: Train Loss = 0.016216667369008064\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.0162]Epoch 291: Train Loss = 0.011449700221419334\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=312, train_loss_step=0.0174, train_loss_epoch=0.0114]Epoch 292: Train Loss = 0.01735062338411808\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=312, train_loss_step=0.0101, train_loss_epoch=0.0174]Epoch 293: Train Loss = 0.01008724607527256\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0101]Epoch 294: Train Loss = 0.011255763471126556\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.0113]Epoch 295: Train Loss = 0.012066289782524109\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=312, train_loss_step=0.0112, train_loss_epoch=0.0121]Epoch 296: Train Loss = 0.011150732636451721\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=312, train_loss_step=0.0117, train_loss_epoch=0.0112]Epoch 297: Train Loss = 0.011746315285563469\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 13.22it/s, v_num=312, train_loss_step=0.00948, train_loss_epoch=0.0117]Epoch 298: Train Loss = 0.00947760883718729\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, v_num=312, train_loss_step=0.0134, train_loss_epoch=0.00948] Epoch 299: Train Loss = 0.013363161124289036\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.0134] Epoch 300: Train Loss = 0.012876778841018677\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=312, train_loss_step=0.0172, train_loss_epoch=0.0129]Epoch 301: Train Loss = 0.017177434638142586\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=312, train_loss_step=0.0131, train_loss_epoch=0.0172]Epoch 302: Train Loss = 0.013065129518508911\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=312, train_loss_step=0.0124, train_loss_epoch=0.0131]Epoch 303: Train Loss = 0.012427390553057194\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=312, train_loss_step=0.0122, train_loss_epoch=0.0124]Epoch 304: Train Loss = 0.012161694467067719\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 13.08it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0122]Epoch 305: Train Loss = 0.0125206233933568\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=312, train_loss_step=0.0139, train_loss_epoch=0.0125]Epoch 306: Train Loss = 0.013863563537597656\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=312, train_loss_step=0.0103, train_loss_epoch=0.0139]Epoch 307: Train Loss = 0.0103336526080966\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=312, train_loss_step=0.0098, train_loss_epoch=0.0103]Epoch 308: Train Loss = 0.009795797057449818\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 11.22it/s, v_num=312, train_loss_step=0.0116, train_loss_epoch=0.0098]Epoch 309: Train Loss = 0.011596634984016418\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, v_num=312, train_loss_step=0.0103, train_loss_epoch=0.0116]Epoch 310: Train Loss = 0.010291519574820995\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=312, train_loss_step=0.00885, train_loss_epoch=0.0103]Epoch 311: Train Loss = 0.008852474391460419\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=312, train_loss_step=0.0155, train_loss_epoch=0.00885] Epoch 312: Train Loss = 0.015549891628324986\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=312, train_loss_step=0.0164, train_loss_epoch=0.0155] Epoch 313: Train Loss = 0.01637158915400505\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=312, train_loss_step=0.0116, train_loss_epoch=0.0164]Epoch 314: Train Loss = 0.01163164060562849\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.0116]Epoch 315: Train Loss = 0.010558092966675758\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=312, train_loss_step=0.0138, train_loss_epoch=0.0106]Epoch 316: Train Loss = 0.01381636317819357\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=312, train_loss_step=0.0153, train_loss_epoch=0.0138]Epoch 317: Train Loss = 0.015290366485714912\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.0153]Epoch 318: Train Loss = 0.012939644046127796\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=312, train_loss_step=0.0128, train_loss_epoch=0.0129]Epoch 319: Train Loss = 0.012778577394783497\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s, v_num=312, train_loss_step=0.0136, train_loss_epoch=0.0128]Epoch 320: Train Loss = 0.013584651984274387\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=312, train_loss_step=0.0102, train_loss_epoch=0.0136]Epoch 321: Train Loss = 0.010203228332102299\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=312, train_loss_step=0.0138, train_loss_epoch=0.0102]Epoch 322: Train Loss = 0.01378785539418459\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=312, train_loss_step=0.0172, train_loss_epoch=0.0138]Epoch 323: Train Loss = 0.017240386456251144\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=312, train_loss_step=0.0182, train_loss_epoch=0.0172]Epoch 324: Train Loss = 0.018244044855237007\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=312, train_loss_step=0.0141, train_loss_epoch=0.0182]Epoch 325: Train Loss = 0.014074089005589485\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=312, train_loss_step=0.00949, train_loss_epoch=0.0141]Epoch 326: Train Loss = 0.009490196593105793\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=312, train_loss_step=0.0179, train_loss_epoch=0.00949] Epoch 327: Train Loss = 0.017943328246474266\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=312, train_loss_step=0.0128, train_loss_epoch=0.0179] Epoch 328: Train Loss = 0.01278482936322689\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=312, train_loss_step=0.0126, train_loss_epoch=0.0128]Epoch 329: Train Loss = 0.012550381012260914\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=312, train_loss_step=0.0163, train_loss_epoch=0.0126]Epoch 330: Train Loss = 0.016296369954943657\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=312, train_loss_step=0.0154, train_loss_epoch=0.0163]Epoch 331: Train Loss = 0.015379018150269985\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=312, train_loss_step=0.0128, train_loss_epoch=0.0154]Epoch 332: Train Loss = 0.012798485346138477\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=312, train_loss_step=0.0136, train_loss_epoch=0.0128]Epoch 333: Train Loss = 0.013584425672888756\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=312, train_loss_step=0.0182, train_loss_epoch=0.0136]Epoch 334: Train Loss = 0.018226977437734604\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=312, train_loss_step=0.0182, train_loss_epoch=0.0182]Epoch 335: Train Loss = 0.01819774881005287\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=312, train_loss_step=0.015, train_loss_epoch=0.0182] Epoch 336: Train Loss = 0.015007934533059597\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=312, train_loss_step=0.013, train_loss_epoch=0.015] Epoch 337: Train Loss = 0.01302791852504015\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 12.64it/s, v_num=312, train_loss_step=0.0166, train_loss_epoch=0.013]Epoch 338: Train Loss = 0.01664418913424015\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=312, train_loss_step=0.0132, train_loss_epoch=0.0166]Epoch 339: Train Loss = 0.013153797015547752\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=312, train_loss_step=0.0146, train_loss_epoch=0.0132]Epoch 340: Train Loss = 0.014648518525063992\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=312, train_loss_step=0.0148, train_loss_epoch=0.0146]Epoch 341: Train Loss = 0.0147953350096941\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=312, train_loss_step=0.0119, train_loss_epoch=0.0148]Epoch 342: Train Loss = 0.011923639103770256\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 13.29it/s, v_num=312, train_loss_step=0.0138, train_loss_epoch=0.0119]Epoch 343: Train Loss = 0.013756854459643364\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=312, train_loss_step=0.0127, train_loss_epoch=0.0138]Epoch 344: Train Loss = 0.012748142704367638\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=312, train_loss_step=0.0133, train_loss_epoch=0.0127]Epoch 345: Train Loss = 0.01328875869512558\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=312, train_loss_step=0.0141, train_loss_epoch=0.0133]Epoch 346: Train Loss = 0.014146518893539906\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=312, train_loss_step=0.0148, train_loss_epoch=0.0141]Epoch 347: Train Loss = 0.014772060327231884\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=312, train_loss_step=0.0136, train_loss_epoch=0.0148]Epoch 348: Train Loss = 0.013648363761603832\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=312, train_loss_step=0.0204, train_loss_epoch=0.0136]Epoch 349: Train Loss = 0.020357981324195862\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 12.51it/s, v_num=312, train_loss_step=0.0109, train_loss_epoch=0.0204]Epoch 350: Train Loss = 0.010938030667603016\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=312, train_loss_step=0.0139, train_loss_epoch=0.0109]Epoch 351: Train Loss = 0.013864448294043541\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=312, train_loss_step=0.0143, train_loss_epoch=0.0139]Epoch 352: Train Loss = 0.014298499561846256\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=312, train_loss_step=0.012, train_loss_epoch=0.0143] Epoch 353: Train Loss = 0.012002816423773766\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=312, train_loss_step=0.00857, train_loss_epoch=0.012]Epoch 354: Train Loss = 0.008571493439376354\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=312, train_loss_step=0.00922, train_loss_epoch=0.00857]Epoch 355: Train Loss = 0.00921553187072277\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.00922] Epoch 356: Train Loss = 0.012109673582017422\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.0121] Epoch 357: Train Loss = 0.011389710009098053\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, v_num=312, train_loss_step=0.015, train_loss_epoch=0.0114] Epoch 358: Train Loss = 0.014983592554926872\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=312, train_loss_step=0.0101, train_loss_epoch=0.015]Epoch 359: Train Loss = 0.01013006828725338\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=312, train_loss_step=0.0109, train_loss_epoch=0.0101]Epoch 360: Train Loss = 0.010947964154183865\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=312, train_loss_step=0.012, train_loss_epoch=0.0109] Epoch 361: Train Loss = 0.012002472765743732\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.012]Epoch 362: Train Loss = 0.010563795454800129\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=312, train_loss_step=0.0108, train_loss_epoch=0.0106]Epoch 363: Train Loss = 0.010784723795950413\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=312, train_loss_step=0.0101, train_loss_epoch=0.0108]Epoch 364: Train Loss = 0.01007614191621542\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.0101]Epoch 365: Train Loss = 0.012098206207156181\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=312, train_loss_step=0.0112, train_loss_epoch=0.0121]Epoch 366: Train Loss = 0.011177881620824337\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.0112] Epoch 367: Train Loss = 0.014008200727403164\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=312, train_loss_step=0.00966, train_loss_epoch=0.014]Epoch 368: Train Loss = 0.009660384617745876\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=312, train_loss_step=0.0158, train_loss_epoch=0.00966] Epoch 369: Train Loss = 0.015765028074383736\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=312, train_loss_step=0.0112, train_loss_epoch=0.0158] Epoch 370: Train Loss = 0.011211869306862354\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=312, train_loss_step=0.0157, train_loss_epoch=0.0112]Epoch 371: Train Loss = 0.015659663826227188\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=312, train_loss_step=0.0111, train_loss_epoch=0.0157]Epoch 372: Train Loss = 0.011140987277030945\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=312, train_loss_step=0.00983, train_loss_epoch=0.0111]Epoch 373: Train Loss = 0.009828077629208565\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.00983] Epoch 374: Train Loss = 0.01209095399826765\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=312, train_loss_step=0.014, train_loss_epoch=0.0121]  Epoch 375: Train Loss = 0.01400771550834179\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=312, train_loss_step=0.0131, train_loss_epoch=0.014]Epoch 376: Train Loss = 0.013131693005561829\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=312, train_loss_step=0.0133, train_loss_epoch=0.0131]Epoch 377: Train Loss = 0.013293324038386345\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=312, train_loss_step=0.0104, train_loss_epoch=0.0133]Epoch 378: Train Loss = 0.010395360179245472\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=312, train_loss_step=0.0103, train_loss_epoch=0.0104]Epoch 379: Train Loss = 0.010276855900883675\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=312, train_loss_step=0.0135, train_loss_epoch=0.0103]Epoch 380: Train Loss = 0.013495228253304958\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, v_num=312, train_loss_step=0.0122, train_loss_epoch=0.0135]Epoch 381: Train Loss = 0.012212231755256653\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=312, train_loss_step=0.0131, train_loss_epoch=0.0122]Epoch 382: Train Loss = 0.013122530654072762\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.0131]Epoch 383: Train Loss = 0.010597930289804935\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=312, train_loss_step=0.0109, train_loss_epoch=0.0106]Epoch 384: Train Loss = 0.010867893695831299\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s, v_num=312, train_loss_step=0.0195, train_loss_epoch=0.0109]Epoch 385: Train Loss = 0.01948709972202778\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=312, train_loss_step=0.0124, train_loss_epoch=0.0195]Epoch 386: Train Loss = 0.012439621612429619\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.0124]Epoch 387: Train Loss = 0.011400087736546993\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, v_num=312, train_loss_step=0.0116, train_loss_epoch=0.0114]Epoch 388: Train Loss = 0.01155040878802538\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=312, train_loss_step=0.0119, train_loss_epoch=0.0116]Epoch 389: Train Loss = 0.011873392388224602\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0119]Epoch 390: Train Loss = 0.011257183738052845\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=312, train_loss_step=0.0117, train_loss_epoch=0.0113]Epoch 391: Train Loss = 0.011675208806991577\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=312, train_loss_step=0.0127, train_loss_epoch=0.0117]Epoch 392: Train Loss = 0.01267482340335846\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=312, train_loss_step=0.0163, train_loss_epoch=0.0127]Epoch 393: Train Loss = 0.01634134165942669\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=312, train_loss_step=0.00944, train_loss_epoch=0.0163]Epoch 394: Train Loss = 0.009437993168830872\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=312, train_loss_step=0.00949, train_loss_epoch=0.00944]Epoch 395: Train Loss = 0.009494039230048656\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.00949] Epoch 396: Train Loss = 0.012925924733281136\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=312, train_loss_step=0.0097, train_loss_epoch=0.0129] Epoch 397: Train Loss = 0.009697929956018925\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=312, train_loss_step=0.0149, train_loss_epoch=0.0097]Epoch 398: Train Loss = 0.014888981357216835\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 13.50it/s, v_num=312, train_loss_step=0.0112, train_loss_epoch=0.0149]Epoch 399: Train Loss = 0.011231635697185993\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s, v_num=312, train_loss_step=0.00899, train_loss_epoch=0.0112]Epoch 400: Train Loss = 0.008991104550659657\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=312, train_loss_step=0.0111, train_loss_epoch=0.00899] Epoch 401: Train Loss = 0.011109784245491028\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=312, train_loss_step=0.00982, train_loss_epoch=0.0111]Epoch 402: Train Loss = 0.009820583276450634\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=312, train_loss_step=0.0142, train_loss_epoch=0.00982] Epoch 403: Train Loss = 0.014173743315041065\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.0142] Epoch 404: Train Loss = 0.01142887119203806\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=312, train_loss_step=0.0126, train_loss_epoch=0.0114]Epoch 405: Train Loss = 0.012595376931130886\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 11.82it/s, v_num=312, train_loss_step=0.0141, train_loss_epoch=0.0126]Epoch 406: Train Loss = 0.01408252865076065\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.0141]Epoch 407: Train Loss = 0.011402939446270466\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=312, train_loss_step=0.00906, train_loss_epoch=0.0114]Epoch 408: Train Loss = 0.0090595418587327\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=312, train_loss_step=0.00765, train_loss_epoch=0.00906]Epoch 409: Train Loss = 0.007652297616004944\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.00765] Epoch 410: Train Loss = 0.012483066879212856\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.0125] Epoch 411: Train Loss = 0.012129455804824829\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=312, train_loss_step=0.0102, train_loss_epoch=0.0121]Epoch 412: Train Loss = 0.010224977508187294\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s, v_num=312, train_loss_step=0.0181, train_loss_epoch=0.0102]Epoch 413: Train Loss = 0.0180805791169405\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=312, train_loss_step=0.0129, train_loss_epoch=0.0181]Epoch 414: Train Loss = 0.012895512394607067\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=312, train_loss_step=0.0107, train_loss_epoch=0.0129]Epoch 415: Train Loss = 0.010667706839740276\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=312, train_loss_step=0.0162, train_loss_epoch=0.0107]Epoch 416: Train Loss = 0.016207510605454445\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=312, train_loss_step=0.0125, train_loss_epoch=0.0162]Epoch 417: Train Loss = 0.012528893537819386\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 16.55it/s, v_num=312, train_loss_step=0.0123, train_loss_epoch=0.0125]Epoch 418: Train Loss = 0.012261912226676941\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0123]Epoch 419: Train Loss = 0.011337748728692532\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s, v_num=312, train_loss_step=0.010, train_loss_epoch=0.0113] Epoch 420: Train Loss = 0.01002351101487875\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.010]Epoch 421: Train Loss = 0.012076922692358494\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=312, train_loss_step=0.012, train_loss_epoch=0.0121] Epoch 422: Train Loss = 0.011968160979449749\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=312, train_loss_step=0.0165, train_loss_epoch=0.012]Epoch 423: Train Loss = 0.016499653458595276\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0165]Epoch 424: Train Loss = 0.011345013976097107\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 12.97it/s, v_num=312, train_loss_step=0.00943, train_loss_epoch=0.0113]Epoch 425: Train Loss = 0.009434816427528858\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 11.57it/s, v_num=312, train_loss_step=0.00994, train_loss_epoch=0.00943]Epoch 426: Train Loss = 0.009939351119101048\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=312, train_loss_step=0.0165, train_loss_epoch=0.00994] Epoch 427: Train Loss = 0.016546931117773056\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 10.55it/s, v_num=312, train_loss_step=0.00895, train_loss_epoch=0.0165]Epoch 428: Train Loss = 0.008950626477599144\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=312, train_loss_step=0.0103, train_loss_epoch=0.00895] Epoch 429: Train Loss = 0.010289368219673634\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=312, train_loss_step=0.0101, train_loss_epoch=0.0103] Epoch 430: Train Loss = 0.010078475810587406\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=312, train_loss_step=0.0118, train_loss_epoch=0.0101]Epoch 431: Train Loss = 0.011842646636068821\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=312, train_loss_step=0.00846, train_loss_epoch=0.0118]Epoch 432: Train Loss = 0.008464870974421501\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=312, train_loss_step=0.0108, train_loss_epoch=0.00846] Epoch 433: Train Loss = 0.010768530890345573\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=312, train_loss_step=0.0111, train_loss_epoch=0.0108] Epoch 434: Train Loss = 0.011074776761233807\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=312, train_loss_step=0.0131, train_loss_epoch=0.0111]Epoch 435: Train Loss = 0.013125372119247913\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=312, train_loss_step=0.0148, train_loss_epoch=0.0131]Epoch 436: Train Loss = 0.014759136363863945\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=312, train_loss_step=0.0126, train_loss_epoch=0.0148]Epoch 437: Train Loss = 0.01256460789591074\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=312, train_loss_step=0.013, train_loss_epoch=0.0126] Epoch 438: Train Loss = 0.013042830862104893\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, v_num=312, train_loss_step=0.00891, train_loss_epoch=0.013]Epoch 439: Train Loss = 0.008908231742680073\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=312, train_loss_step=0.0117, train_loss_epoch=0.00891] Epoch 440: Train Loss = 0.011729128658771515\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=312, train_loss_step=0.0114, train_loss_epoch=0.0117] Epoch 441: Train Loss = 0.011432436294853687\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=312, train_loss_step=0.0109, train_loss_epoch=0.0114]Epoch 442: Train Loss = 0.010901170782744884\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=312, train_loss_step=0.0123, train_loss_epoch=0.0109]Epoch 443: Train Loss = 0.01233434397727251\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=312, train_loss_step=0.00884, train_loss_epoch=0.0123]Epoch 444: Train Loss = 0.008840447291731834\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=312, train_loss_step=0.00989, train_loss_epoch=0.00884]Epoch 445: Train Loss = 0.009886518120765686\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=312, train_loss_step=0.00935, train_loss_epoch=0.00989]Epoch 446: Train Loss = 0.00934591330587864\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s, v_num=312, train_loss_step=0.0195, train_loss_epoch=0.00935] Epoch 447: Train Loss = 0.0195451769977808\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=312, train_loss_step=0.0117, train_loss_epoch=0.0195] Epoch 448: Train Loss = 0.011654533445835114\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=312, train_loss_step=0.0134, train_loss_epoch=0.0117]Epoch 449: Train Loss = 0.013380484655499458\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=312, train_loss_step=0.0115, train_loss_epoch=0.0134]Epoch 450: Train Loss = 0.011546100489795208\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=312, train_loss_step=0.0141, train_loss_epoch=0.0115]Epoch 451: Train Loss = 0.014072315767407417\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=312, train_loss_step=0.0101, train_loss_epoch=0.0141]Epoch 452: Train Loss = 0.010130762122571468\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s, v_num=312, train_loss_step=0.0111, train_loss_epoch=0.0101]Epoch 453: Train Loss = 0.01114808488637209\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=312, train_loss_step=0.0152, train_loss_epoch=0.0111]Epoch 454: Train Loss = 0.015158893540501595\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=312, train_loss_step=0.0128, train_loss_epoch=0.0152]Epoch 455: Train Loss = 0.01282171718776226\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0128]Epoch 456: Train Loss = 0.011332984082400799\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s, v_num=312, train_loss_step=0.0131, train_loss_epoch=0.0113]Epoch 457: Train Loss = 0.01311606913805008\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=312, train_loss_step=0.0134, train_loss_epoch=0.0131]Epoch 458: Train Loss = 0.013410752639174461\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=312, train_loss_step=0.0185, train_loss_epoch=0.0134]Epoch 459: Train Loss = 0.018522460013628006\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 11.61it/s, v_num=312, train_loss_step=0.0161, train_loss_epoch=0.0185]Epoch 460: Train Loss = 0.016103727743029594\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=312, train_loss_step=0.0156, train_loss_epoch=0.0161]Epoch 461: Train Loss = 0.015629610046744347\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=312, train_loss_step=0.0122, train_loss_epoch=0.0156]Epoch 462: Train Loss = 0.0122127216309309\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=312, train_loss_step=0.0137, train_loss_epoch=0.0122]Epoch 463: Train Loss = 0.013706281781196594\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=312, train_loss_step=0.0118, train_loss_epoch=0.0137]Epoch 464: Train Loss = 0.01176036149263382\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=312, train_loss_step=0.0166, train_loss_epoch=0.0118]Epoch 465: Train Loss = 0.01658247597515583\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=312, train_loss_step=0.0113, train_loss_epoch=0.0166]Epoch 466: Train Loss = 0.011268066242337227\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s, v_num=312, train_loss_step=0.0115, train_loss_epoch=0.0113]Epoch 467: Train Loss = 0.011540311388671398\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s, v_num=312, train_loss_step=0.0139, train_loss_epoch=0.0115]Epoch 468: Train Loss = 0.013911792077124119\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s, v_num=312, train_loss_step=0.0139, train_loss_epoch=0.0139]Epoch 469: Train Loss = 0.013922211714088917\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=312, train_loss_step=0.017, train_loss_epoch=0.0139] Epoch 470: Train Loss = 0.016979629173874855\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=312, train_loss_step=0.0154, train_loss_epoch=0.017]Epoch 471: Train Loss = 0.015370810404419899\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.0154]Epoch 472: Train Loss = 0.01058168150484562\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=312, train_loss_step=0.0115, train_loss_epoch=0.0106]Epoch 473: Train Loss = 0.01146527286618948\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=312, train_loss_step=0.0104, train_loss_epoch=0.0115]Epoch 474: Train Loss = 0.010400059632956982\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=312, train_loss_step=0.0124, train_loss_epoch=0.0104]Epoch 475: Train Loss = 0.012418227270245552\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=312, train_loss_step=0.00966, train_loss_epoch=0.0124]Epoch 476: Train Loss = 0.009656501933932304\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=312, train_loss_step=0.0123, train_loss_epoch=0.00966] Epoch 477: Train Loss = 0.012327334843575954\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=312, train_loss_step=0.0109, train_loss_epoch=0.0123] Epoch 478: Train Loss = 0.01085591409355402\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=312, train_loss_step=0.0115, train_loss_epoch=0.0109]Epoch 479: Train Loss = 0.011533842422068119\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=312, train_loss_step=0.0138, train_loss_epoch=0.0115]Epoch 480: Train Loss = 0.013798409141600132\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=312, train_loss_step=0.011, train_loss_epoch=0.0138] Epoch 481: Train Loss = 0.011018477380275726\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=312, train_loss_step=0.00923, train_loss_epoch=0.011]Epoch 482: Train Loss = 0.009234877303242683\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=312, train_loss_step=0.00886, train_loss_epoch=0.00923]Epoch 483: Train Loss = 0.008858011104166508\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.00886] Epoch 484: Train Loss = 0.01056470163166523\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=312, train_loss_step=0.0119, train_loss_epoch=0.0106] Epoch 485: Train Loss = 0.011915822513401508\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 10.52it/s, v_num=312, train_loss_step=0.0104, train_loss_epoch=0.0119]Epoch 486: Train Loss = 0.010355502367019653\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s, v_num=312, train_loss_step=0.0106, train_loss_epoch=0.0104]Epoch 487: Train Loss = 0.010594780556857586\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 14.17it/s, v_num=312, train_loss_step=0.00889, train_loss_epoch=0.0106]Epoch 488: Train Loss = 0.008889616467058659\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=312, train_loss_step=0.0131, train_loss_epoch=0.00889] Epoch 489: Train Loss = 0.013102846220135689\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 12.77it/s, v_num=312, train_loss_step=0.0124, train_loss_epoch=0.0131] Epoch 490: Train Loss = 0.01242308970540762\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s, v_num=312, train_loss_step=0.0157, train_loss_epoch=0.0124]Epoch 491: Train Loss = 0.01566711999475956\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=312, train_loss_step=0.0121, train_loss_epoch=0.0157]Epoch 492: Train Loss = 0.012078718282282352\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=312, train_loss_step=0.00952, train_loss_epoch=0.0121]Epoch 493: Train Loss = 0.009518916718661785\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=312, train_loss_step=0.0124, train_loss_epoch=0.00952] Epoch 494: Train Loss = 0.012449433095753193\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=312, train_loss_step=0.013, train_loss_epoch=0.0124]  Epoch 495: Train Loss = 0.013042311184108257\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=312, train_loss_step=0.0134, train_loss_epoch=0.013]Epoch 496: Train Loss = 0.013375290669500828\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=312, train_loss_step=0.0196, train_loss_epoch=0.0134]Epoch 497: Train Loss = 0.019568314775824547\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=312, train_loss_step=0.0127, train_loss_epoch=0.0196]Epoch 498: Train Loss = 0.012706468813121319\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=312, train_loss_step=0.0148, train_loss_epoch=0.0127]Epoch 499: Train Loss = 0.014772024936974049\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=312, train_loss_step=0.0148, train_loss_epoch=0.0148]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=312, train_loss_step=0.0148, train_loss_epoch=0.0148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 160.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training window 6: from 2010-06-30 00:00:00 to 2022-08-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=315, train_loss_step=0.0317]Epoch 0: Train Loss = 0.031742747873067856\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=315, train_loss_step=0.0588, train_loss_epoch=0.0317]Epoch 1: Train Loss = 0.05880313739180565\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=315, train_loss_step=0.0243, train_loss_epoch=0.0588]Epoch 2: Train Loss = 0.02426769770681858\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 10.45it/s, v_num=315, train_loss_step=0.0316, train_loss_epoch=0.0243]Epoch 3: Train Loss = 0.0316399410367012\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=315, train_loss_step=0.025, train_loss_epoch=0.0316] Epoch 4: Train Loss = 0.02504180185496807\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s, v_num=315, train_loss_step=0.0158, train_loss_epoch=0.025]Epoch 5: Train Loss = 0.015845194458961487\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 13.21it/s, v_num=315, train_loss_step=0.0196, train_loss_epoch=0.0158]Epoch 6: Train Loss = 0.019574236124753952\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=315, train_loss_step=0.0193, train_loss_epoch=0.0196]Epoch 7: Train Loss = 0.019275913015007973\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=315, train_loss_step=0.0178, train_loss_epoch=0.0193]Epoch 8: Train Loss = 0.01776856742799282\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=315, train_loss_step=0.0153, train_loss_epoch=0.0178]Epoch 9: Train Loss = 0.0152708375826478\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s, v_num=315, train_loss_step=0.0141, train_loss_epoch=0.0153]Epoch 10: Train Loss = 0.014110078103840351\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 12.46it/s, v_num=315, train_loss_step=0.0127, train_loss_epoch=0.0141]Epoch 11: Train Loss = 0.012706990353763103\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=315, train_loss_step=0.0178, train_loss_epoch=0.0127]Epoch 12: Train Loss = 0.01781146042048931\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=315, train_loss_step=0.013, train_loss_epoch=0.0178] Epoch 13: Train Loss = 0.013016567565500736\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=315, train_loss_step=0.0171, train_loss_epoch=0.013]Epoch 14: Train Loss = 0.01706645078957081\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 17.16it/s, v_num=315, train_loss_step=0.0174, train_loss_epoch=0.0171]Epoch 15: Train Loss = 0.017393294721841812\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=315, train_loss_step=0.0215, train_loss_epoch=0.0174]Epoch 16: Train Loss = 0.02153097279369831\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 17.15it/s, v_num=315, train_loss_step=0.0197, train_loss_epoch=0.0215]Epoch 17: Train Loss = 0.019655561074614525\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=315, train_loss_step=0.0134, train_loss_epoch=0.0197]Epoch 18: Train Loss = 0.0133837154135108\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s, v_num=315, train_loss_step=0.0149, train_loss_epoch=0.0134]Epoch 19: Train Loss = 0.014945623464882374\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 16.89it/s, v_num=315, train_loss_step=0.0169, train_loss_epoch=0.0149]Epoch 20: Train Loss = 0.016928276047110558\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 11.43it/s, v_num=315, train_loss_step=0.0132, train_loss_epoch=0.0169]Epoch 21: Train Loss = 0.013160529546439648\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=315, train_loss_step=0.0152, train_loss_epoch=0.0132]Epoch 22: Train Loss = 0.015235411003232002\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=315, train_loss_step=0.0212, train_loss_epoch=0.0152]Epoch 23: Train Loss = 0.021202798932790756\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 16.02it/s, v_num=315, train_loss_step=0.0174, train_loss_epoch=0.0212]Epoch 24: Train Loss = 0.017428379505872726\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, v_num=315, train_loss_step=0.0123, train_loss_epoch=0.0174]Epoch 25: Train Loss = 0.012343385256826878\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=315, train_loss_step=0.0126, train_loss_epoch=0.0123]Epoch 26: Train Loss = 0.012574322521686554\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 13.78it/s, v_num=315, train_loss_step=0.0129, train_loss_epoch=0.0126]Epoch 27: Train Loss = 0.012866338714957237\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 17.50it/s, v_num=315, train_loss_step=0.0129, train_loss_epoch=0.0129]Epoch 28: Train Loss = 0.012898427434265614\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s, v_num=315, train_loss_step=0.0149, train_loss_epoch=0.0129]Epoch 29: Train Loss = 0.014932510443031788\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=315, train_loss_step=0.0127, train_loss_epoch=0.0149]Epoch 30: Train Loss = 0.012686578556895256\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 17.16it/s, v_num=315, train_loss_step=0.0158, train_loss_epoch=0.0127]Epoch 31: Train Loss = 0.015773620456457138\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=315, train_loss_step=0.017, train_loss_epoch=0.0158] Epoch 32: Train Loss = 0.016962101683020592\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=315, train_loss_step=0.0109, train_loss_epoch=0.017]Epoch 33: Train Loss = 0.01085855532437563\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=315, train_loss_step=0.0157, train_loss_epoch=0.0109]Epoch 34: Train Loss = 0.01566736213862896\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=315, train_loss_step=0.0154, train_loss_epoch=0.0157]Epoch 35: Train Loss = 0.015430902130901814\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0154]Epoch 36: Train Loss = 0.011378951370716095\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=315, train_loss_step=0.0133, train_loss_epoch=0.0114]Epoch 37: Train Loss = 0.013331932947039604\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=315, train_loss_step=0.013, train_loss_epoch=0.0133] Epoch 38: Train Loss = 0.013020983897149563\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.013]Epoch 39: Train Loss = 0.01242026686668396\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 13.55it/s, v_num=315, train_loss_step=0.0104, train_loss_epoch=0.0124]Epoch 40: Train Loss = 0.010394839569926262\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=315, train_loss_step=0.0102, train_loss_epoch=0.0104]Epoch 41: Train Loss = 0.010171824134886265\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.0102] Epoch 42: Train Loss = 0.012047099880874157\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.012]Epoch 43: Train Loss = 0.0114596514031291\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.0115]Epoch 44: Train Loss = 0.011260082013905048\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=315, train_loss_step=0.0145, train_loss_epoch=0.0113]Epoch 45: Train Loss = 0.014491655863821507\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=315, train_loss_step=0.0129, train_loss_epoch=0.0145]Epoch 46: Train Loss = 0.012864023447036743\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=315, train_loss_step=0.0241, train_loss_epoch=0.0129]Epoch 47: Train Loss = 0.024059925228357315\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.0241]Epoch 48: Train Loss = 0.01070915162563324\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=315, train_loss_step=0.0144, train_loss_epoch=0.0107]Epoch 49: Train Loss = 0.01443787757307291\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.0144]Epoch 50: Train Loss = 0.012448020279407501\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=315, train_loss_step=0.0141, train_loss_epoch=0.0124]Epoch 51: Train Loss = 0.014135166071355343\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 16.88it/s, v_num=315, train_loss_step=0.0144, train_loss_epoch=0.0141]Epoch 52: Train Loss = 0.014374298974871635\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.0144]Epoch 53: Train Loss = 0.01366578508168459\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=315, train_loss_step=0.0146, train_loss_epoch=0.0137]Epoch 54: Train Loss = 0.014618254266679287\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=315, train_loss_step=0.0106, train_loss_epoch=0.0146]Epoch 55: Train Loss = 0.010629987344145775\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.0106]Epoch 56: Train Loss = 0.012115647085011005\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.0121]Epoch 57: Train Loss = 0.012485243380069733\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, v_num=315, train_loss_step=0.0153, train_loss_epoch=0.0125]Epoch 58: Train Loss = 0.015312698669731617\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=315, train_loss_step=0.00937, train_loss_epoch=0.0153]Epoch 59: Train Loss = 0.00937365647405386\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.00937] Epoch 60: Train Loss = 0.012467787601053715\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, v_num=315, train_loss_step=0.0105, train_loss_epoch=0.0125] Epoch 61: Train Loss = 0.010466284118592739\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 16.72it/s, v_num=315, train_loss_step=0.0163, train_loss_epoch=0.0105]Epoch 62: Train Loss = 0.01630477048456669\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.0163]Epoch 63: Train Loss = 0.012114978395402431\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=315, train_loss_step=0.0138, train_loss_epoch=0.0121]Epoch 64: Train Loss = 0.013836890459060669\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=315, train_loss_step=0.0155, train_loss_epoch=0.0138]Epoch 65: Train Loss = 0.015524919144809246\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=315, train_loss_step=0.0152, train_loss_epoch=0.0155]Epoch 66: Train Loss = 0.015193508006632328\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=315, train_loss_step=0.023, train_loss_epoch=0.0152] Epoch 67: Train Loss = 0.023024607449769974\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 14.12it/s, v_num=315, train_loss_step=0.0112, train_loss_epoch=0.023]Epoch 68: Train Loss = 0.011162885464727879\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 13.32it/s, v_num=315, train_loss_step=0.0133, train_loss_epoch=0.0112]Epoch 69: Train Loss = 0.013300306163728237\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=315, train_loss_step=0.0156, train_loss_epoch=0.0133]Epoch 70: Train Loss = 0.015574770979583263\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s, v_num=315, train_loss_step=0.0166, train_loss_epoch=0.0156]Epoch 71: Train Loss = 0.016555633395910263\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=315, train_loss_step=0.0175, train_loss_epoch=0.0166]Epoch 72: Train Loss = 0.017472539097070694\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=315, train_loss_step=0.0241, train_loss_epoch=0.0175]Epoch 73: Train Loss = 0.02412506379187107\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=315, train_loss_step=0.0166, train_loss_epoch=0.0241]Epoch 74: Train Loss = 0.016617219895124435\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=315, train_loss_step=0.0141, train_loss_epoch=0.0166]Epoch 75: Train Loss = 0.01408986747264862\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 16.22it/s, v_num=315, train_loss_step=0.0138, train_loss_epoch=0.0141]Epoch 76: Train Loss = 0.01375154871493578\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, v_num=315, train_loss_step=0.0132, train_loss_epoch=0.0138]Epoch 77: Train Loss = 0.013197554275393486\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=315, train_loss_step=0.014, train_loss_epoch=0.0132] Epoch 78: Train Loss = 0.013989726081490517\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=315, train_loss_step=0.0117, train_loss_epoch=0.014]Epoch 79: Train Loss = 0.011740936897695065\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=315, train_loss_step=0.0177, train_loss_epoch=0.0117]Epoch 80: Train Loss = 0.017705421894788742\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 16.11it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.0177]Epoch 81: Train Loss = 0.010675947181880474\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s, v_num=315, train_loss_step=0.0136, train_loss_epoch=0.0107]Epoch 82: Train Loss = 0.013606274500489235\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=315, train_loss_step=0.0159, train_loss_epoch=0.0136]Epoch 83: Train Loss = 0.015927838161587715\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s, v_num=315, train_loss_step=0.0159, train_loss_epoch=0.0159]Epoch 84: Train Loss = 0.01590343937277794\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.0159]Epoch 85: Train Loss = 0.013666422106325626\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.0137]Epoch 86: Train Loss = 0.013658552430570126\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=315, train_loss_step=0.0127, train_loss_epoch=0.0137]Epoch 87: Train Loss = 0.01265174150466919\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 16.04it/s, v_num=315, train_loss_step=0.0123, train_loss_epoch=0.0127]Epoch 88: Train Loss = 0.01227243710309267\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=315, train_loss_step=0.0134, train_loss_epoch=0.0123]Epoch 89: Train Loss = 0.013373756781220436\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=315, train_loss_step=0.0132, train_loss_epoch=0.0134]Epoch 90: Train Loss = 0.013170608319342136\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=315, train_loss_step=0.0161, train_loss_epoch=0.0132]Epoch 91: Train Loss = 0.016078094020485878\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s, v_num=315, train_loss_step=0.0194, train_loss_epoch=0.0161]Epoch 92: Train Loss = 0.019357169046998024\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, v_num=315, train_loss_step=0.0109, train_loss_epoch=0.0194]Epoch 93: Train Loss = 0.010867573320865631\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=315, train_loss_step=0.0135, train_loss_epoch=0.0109]Epoch 94: Train Loss = 0.013529368676245213\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=315, train_loss_step=0.0138, train_loss_epoch=0.0135]Epoch 95: Train Loss = 0.013808734714984894\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.0138]Epoch 96: Train Loss = 0.012456009164452553\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 17.14it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0125]Epoch 97: Train Loss = 0.011851382441818714\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=315, train_loss_step=0.0143, train_loss_epoch=0.0119]Epoch 98: Train Loss = 0.014261185191571712\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=315, train_loss_step=0.013, train_loss_epoch=0.0143] Epoch 99: Train Loss = 0.013012922368943691\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, v_num=315, train_loss_step=0.0102, train_loss_epoch=0.013]Epoch 100: Train Loss = 0.010185575112700462\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s, v_num=315, train_loss_step=0.0138, train_loss_epoch=0.0102]Epoch 101: Train Loss = 0.013753822073340416\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=315, train_loss_step=0.011, train_loss_epoch=0.0138] Epoch 102: Train Loss = 0.01100153848528862\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=315, train_loss_step=0.0138, train_loss_epoch=0.011]Epoch 103: Train Loss = 0.013830413110554218\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=315, train_loss_step=0.0135, train_loss_epoch=0.0138]Epoch 104: Train Loss = 0.013458847999572754\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=315, train_loss_step=0.0109, train_loss_epoch=0.0135]Epoch 105: Train Loss = 0.010879595763981342\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=315, train_loss_step=0.0173, train_loss_epoch=0.0109]Epoch 106: Train Loss = 0.017269739881157875\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=315, train_loss_step=0.00981, train_loss_epoch=0.0173]Epoch 107: Train Loss = 0.009809023700654507\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.00981] Epoch 108: Train Loss = 0.01239018328487873\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=315, train_loss_step=0.0128, train_loss_epoch=0.0124] Epoch 109: Train Loss = 0.01275675743818283\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 16.56it/s, v_num=315, train_loss_step=0.0128, train_loss_epoch=0.0128]Epoch 110: Train Loss = 0.012813900597393513\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=315, train_loss_step=0.014, train_loss_epoch=0.0128] Epoch 111: Train Loss = 0.013973618857562542\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=315, train_loss_step=0.0133, train_loss_epoch=0.014]Epoch 112: Train Loss = 0.013279318809509277\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=315, train_loss_step=0.0105, train_loss_epoch=0.0133]Epoch 113: Train Loss = 0.010534057393670082\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=315, train_loss_step=0.0146, train_loss_epoch=0.0105]Epoch 114: Train Loss = 0.014571353793144226\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=315, train_loss_step=0.0162, train_loss_epoch=0.0146]Epoch 115: Train Loss = 0.01623483933508396\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=315, train_loss_step=0.0104, train_loss_epoch=0.0162]Epoch 116: Train Loss = 0.010390904732048512\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.0104]Epoch 117: Train Loss = 0.01307815220206976\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=315, train_loss_step=0.0127, train_loss_epoch=0.0131]Epoch 118: Train Loss = 0.012717234902083874\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.0127]Epoch 119: Train Loss = 0.011528083123266697\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=315, train_loss_step=0.0167, train_loss_epoch=0.0115]Epoch 120: Train Loss = 0.016725407913327217\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=315, train_loss_step=0.0142, train_loss_epoch=0.0167]Epoch 121: Train Loss = 0.01422820333391428\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=315, train_loss_step=0.00992, train_loss_epoch=0.0142]Epoch 122: Train Loss = 0.009921768680214882\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.00992] Epoch 123: Train Loss = 0.012066425755620003\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0121] Epoch 124: Train Loss = 0.011058603413403034\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=315, train_loss_step=0.0127, train_loss_epoch=0.0111]Epoch 125: Train Loss = 0.012718597427010536\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=315, train_loss_step=0.0112, train_loss_epoch=0.0127]Epoch 126: Train Loss = 0.011225239373743534\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=315, train_loss_step=0.0123, train_loss_epoch=0.0112]Epoch 127: Train Loss = 0.012345746159553528\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s, v_num=315, train_loss_step=0.0141, train_loss_epoch=0.0123]Epoch 128: Train Loss = 0.01414599921554327\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0141]Epoch 129: Train Loss = 0.011390835046768188\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.0114] Epoch 130: Train Loss = 0.012044651433825493\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=315, train_loss_step=0.00998, train_loss_epoch=0.012]Epoch 131: Train Loss = 0.009978173300623894\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.00998] Epoch 132: Train Loss = 0.011876552365720272\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=315, train_loss_step=0.0204, train_loss_epoch=0.0119] Epoch 133: Train Loss = 0.020428558811545372\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=315, train_loss_step=0.0171, train_loss_epoch=0.0204]Epoch 134: Train Loss = 0.017087485641241074\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0171]Epoch 135: Train Loss = 0.011131001636385918\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=315, train_loss_step=0.0128, train_loss_epoch=0.0111]Epoch 136: Train Loss = 0.012843392789363861\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.0128]Epoch 137: Train Loss = 0.012501510791480541\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=315, train_loss_step=0.011, train_loss_epoch=0.0125] Epoch 138: Train Loss = 0.011038505472242832\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 139: Train Loss = 0.012494453229010105\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.0125] Epoch 140: Train Loss = 0.012017818167805672\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=315, train_loss_step=0.0116, train_loss_epoch=0.012]Epoch 141: Train Loss = 0.011620021425187588\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=315, train_loss_step=0.0128, train_loss_epoch=0.0116]Epoch 142: Train Loss = 0.012791638262569904\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=315, train_loss_step=0.0139, train_loss_epoch=0.0128]Epoch 143: Train Loss = 0.013905457220971584\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=315, train_loss_step=0.0132, train_loss_epoch=0.0139]Epoch 144: Train Loss = 0.013214128091931343\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0132]Epoch 145: Train Loss = 0.011084134690463543\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.0111]Epoch 146: Train Loss = 0.010652696713805199\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=315, train_loss_step=0.0145, train_loss_epoch=0.0107]Epoch 147: Train Loss = 0.01452887523919344\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.0145]Epoch 148: Train Loss = 0.01129632256925106\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=315, train_loss_step=0.0106, train_loss_epoch=0.0113]Epoch 149: Train Loss = 0.010634475387632847\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=315, train_loss_step=0.0127, train_loss_epoch=0.0106]Epoch 150: Train Loss = 0.012713470496237278\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=315, train_loss_step=0.0136, train_loss_epoch=0.0127]Epoch 151: Train Loss = 0.013600696809589863\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=315, train_loss_step=0.00998, train_loss_epoch=0.0136]Epoch 152: Train Loss = 0.009981781244277954\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.00998]  Epoch 153: Train Loss = 0.011987735517323017\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.012] Epoch 154: Train Loss = 0.012504597194492817\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=315, train_loss_step=0.0128, train_loss_epoch=0.0125]Epoch 155: Train Loss = 0.012765122577548027\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=315, train_loss_step=0.0143, train_loss_epoch=0.0128]Epoch 156: Train Loss = 0.014269017614424229\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0143]Epoch 157: Train Loss = 0.011366084218025208\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.0114]Epoch 158: Train Loss = 0.011538214981555939\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=315, train_loss_step=0.0144, train_loss_epoch=0.0115]Epoch 159: Train Loss = 0.01435460988432169\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 14.13it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.0144]Epoch 160: Train Loss = 0.010714768432080746\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.0107]Epoch 161: Train Loss = 0.012435088865458965\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.0124] Epoch 162: Train Loss = 0.012005501426756382\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.012]Epoch 163: Train Loss = 0.012057610787451267\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.0121] Epoch 164: Train Loss = 0.011994334869086742\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.012]Epoch 165: Train Loss = 0.012476282194256783\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 10.74it/s, v_num=315, train_loss_step=0.0105, train_loss_epoch=0.0125]Epoch 166: Train Loss = 0.010530287399888039\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=315, train_loss_step=0.0158, train_loss_epoch=0.0105]Epoch 167: Train Loss = 0.01583925262093544\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.0158]Epoch 168: Train Loss = 0.012482102029025555\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=315, train_loss_step=0.0136, train_loss_epoch=0.0125]Epoch 169: Train Loss = 0.013584357686340809\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0136]Epoch 170: Train Loss = 0.011382875964045525\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=315, train_loss_step=0.0102, train_loss_epoch=0.0114]Epoch 171: Train Loss = 0.01022061426192522\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=315, train_loss_step=0.0147, train_loss_epoch=0.0102]Epoch 172: Train Loss = 0.014710703864693642\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.0147]Epoch 173: Train Loss = 0.012147986330091953\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=315, train_loss_step=0.0118, train_loss_epoch=0.0121]Epoch 174: Train Loss = 0.011831549927592278\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=315, train_loss_step=0.0155, train_loss_epoch=0.0118]Epoch 175: Train Loss = 0.015524329617619514\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.0155]Epoch 176: Train Loss = 0.010666717775166035\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=315, train_loss_step=0.0118, train_loss_epoch=0.0107]Epoch 177: Train Loss = 0.011777406558394432\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.0118]Epoch 178: Train Loss = 0.01146446168422699\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=315, train_loss_step=0.014, train_loss_epoch=0.0115] Epoch 179: Train Loss = 0.01404835470020771\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.014] Epoch 180: Train Loss = 0.012023971416056156\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=315, train_loss_step=0.0139, train_loss_epoch=0.012]Epoch 181: Train Loss = 0.013893121853470802\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s, v_num=315, train_loss_step=0.0133, train_loss_epoch=0.0139]Epoch 182: Train Loss = 0.013267151080071926\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=315, train_loss_step=0.0109, train_loss_epoch=0.0133]Epoch 183: Train Loss = 0.01085604913532734\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=315, train_loss_step=0.013, train_loss_epoch=0.0109] Epoch 184: Train Loss = 0.012991112656891346\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=315, train_loss_step=0.0136, train_loss_epoch=0.013]Epoch 185: Train Loss = 0.013555788435041904\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=315, train_loss_step=0.0109, train_loss_epoch=0.0136]Epoch 186: Train Loss = 0.010858463123440742\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=315, train_loss_step=0.0136, train_loss_epoch=0.0109]Epoch 187: Train Loss = 0.013612881302833557\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=315, train_loss_step=0.0218, train_loss_epoch=0.0136]Epoch 188: Train Loss = 0.021776719018816948\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0218]Epoch 189: Train Loss = 0.01188290398567915\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 12.32it/s, v_num=315, train_loss_step=0.0195, train_loss_epoch=0.0119]Epoch 190: Train Loss = 0.019528081640601158\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=315, train_loss_step=0.0234, train_loss_epoch=0.0195]Epoch 191: Train Loss = 0.023401500657200813\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=315, train_loss_step=0.0187, train_loss_epoch=0.0234]Epoch 192: Train Loss = 0.018667016178369522\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=315, train_loss_step=0.0169, train_loss_epoch=0.0187]Epoch 193: Train Loss = 0.016904881224036217\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=315, train_loss_step=0.00966, train_loss_epoch=0.0169]Epoch 194: Train Loss = 0.009655402973294258\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.00966] Epoch 195: Train Loss = 0.012096673250198364\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=315, train_loss_step=0.0158, train_loss_epoch=0.0121] Epoch 196: Train Loss = 0.015809189528226852\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=315, train_loss_step=0.016, train_loss_epoch=0.0158] Epoch 197: Train Loss = 0.01599879376590252\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=315, train_loss_step=0.0144, train_loss_epoch=0.016]Epoch 198: Train Loss = 0.014363212510943413\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=315, train_loss_step=0.0133, train_loss_epoch=0.0144]Epoch 199: Train Loss = 0.013277962803840637\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=315, train_loss_step=0.00855, train_loss_epoch=0.0133]Epoch 200: Train Loss = 0.008550755679607391\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=315, train_loss_step=0.0146, train_loss_epoch=0.00855] Epoch 201: Train Loss = 0.014639771543443203\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=315, train_loss_step=0.0132, train_loss_epoch=0.0146] Epoch 202: Train Loss = 0.013246589340269566\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=315, train_loss_step=0.0159, train_loss_epoch=0.0132]Epoch 203: Train Loss = 0.015935081988573074\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=315, train_loss_step=0.013, train_loss_epoch=0.0159] Epoch 204: Train Loss = 0.012979717925190926\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 13.68it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.013]Epoch 205: Train Loss = 0.011322150938212872\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0113]Epoch 206: Train Loss = 0.011411583982408047\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=315, train_loss_step=0.0144, train_loss_epoch=0.0114]Epoch 207: Train Loss = 0.014351077377796173\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=315, train_loss_step=0.0153, train_loss_epoch=0.0144]Epoch 208: Train Loss = 0.015277750790119171\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.0153]Epoch 209: Train Loss = 0.011486556380987167\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s, v_num=315, train_loss_step=0.0151, train_loss_epoch=0.0115]Epoch 210: Train Loss = 0.015056708827614784\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=315, train_loss_step=0.013, train_loss_epoch=0.0151] Epoch 211: Train Loss = 0.01297225896269083\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.013]Epoch 212: Train Loss = 0.01308122556656599\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=315, train_loss_step=0.0132, train_loss_epoch=0.0131]Epoch 213: Train Loss = 0.013239480555057526\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0132]Epoch 214: Train Loss = 0.011119908653199673\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.0111]Epoch 215: Train Loss = 0.011484028771519661\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0115]Epoch 216: Train Loss = 0.011861635372042656\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=315, train_loss_step=0.0108, train_loss_epoch=0.0119]Epoch 217: Train Loss = 0.010751264169812202\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.0108]Epoch 218: Train Loss = 0.012452510185539722\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=315, train_loss_step=0.0163, train_loss_epoch=0.0125]Epoch 219: Train Loss = 0.016325028613209724\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=315, train_loss_step=0.0118, train_loss_epoch=0.0163]Epoch 220: Train Loss = 0.011791097931563854\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s, v_num=315, train_loss_step=0.0139, train_loss_epoch=0.0118]Epoch 221: Train Loss = 0.013930120505392551\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s, v_num=315, train_loss_step=0.0138, train_loss_epoch=0.0139]Epoch 222: Train Loss = 0.013847255147993565\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=315, train_loss_step=0.0153, train_loss_epoch=0.0138]Epoch 223: Train Loss = 0.015338582918047905\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, v_num=315, train_loss_step=0.0154, train_loss_epoch=0.0153]Epoch 224: Train Loss = 0.0153583949431777\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=315, train_loss_step=0.0157, train_loss_epoch=0.0154]Epoch 225: Train Loss = 0.015742694959044456\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=315, train_loss_step=0.0135, train_loss_epoch=0.0157]Epoch 226: Train Loss = 0.01345994882285595\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0135]Epoch 227: Train Loss = 0.011938183568418026\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.0119]Epoch 228: Train Loss = 0.013139878399670124\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=315, train_loss_step=0.0158, train_loss_epoch=0.0131]Epoch 229: Train Loss = 0.015818607062101364\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0158]Epoch 230: Train Loss = 0.011884838342666626\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=315, train_loss_step=0.0159, train_loss_epoch=0.0119]Epoch 231: Train Loss = 0.015854934230446815\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=315, train_loss_step=0.0149, train_loss_epoch=0.0159]Epoch 232: Train Loss = 0.014896540902554989\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.0149]Epoch 233: Train Loss = 0.012379058636724949\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 12.54it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.0124]Epoch 234: Train Loss = 0.012546608224511147\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=315, train_loss_step=0.0116, train_loss_epoch=0.0125]Epoch 235: Train Loss = 0.011621994897723198\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.0116]Epoch 236: Train Loss = 0.011272379197180271\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, v_num=315, train_loss_step=0.0117, train_loss_epoch=0.0113]Epoch 237: Train Loss = 0.011713802814483643\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=315, train_loss_step=0.0181, train_loss_epoch=0.0117]Epoch 238: Train Loss = 0.018149469047784805\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0181]Epoch 239: Train Loss = 0.011422746814787388\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=315, train_loss_step=0.0146, train_loss_epoch=0.0114]Epoch 240: Train Loss = 0.01459705550223589\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.0146]Epoch 241: Train Loss = 0.012470890767872334\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 13.13it/s, v_num=315, train_loss_step=0.0158, train_loss_epoch=0.0125]Epoch 242: Train Loss = 0.01576993800699711\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.0158]Epoch 243: Train Loss = 0.013743534684181213\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 12.33it/s, v_num=315, train_loss_step=0.0153, train_loss_epoch=0.0137]Epoch 244: Train Loss = 0.015300487168133259\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=315, train_loss_step=0.0152, train_loss_epoch=0.0153]Epoch 245: Train Loss = 0.015167387202382088\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=315, train_loss_step=0.0133, train_loss_epoch=0.0152]Epoch 246: Train Loss = 0.01330892276018858\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=315, train_loss_step=0.0208, train_loss_epoch=0.0133]Epoch 247: Train Loss = 0.02077355608344078\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=315, train_loss_step=0.0175, train_loss_epoch=0.0208]Epoch 248: Train Loss = 0.017548050731420517\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, v_num=315, train_loss_step=0.0142, train_loss_epoch=0.0175]Epoch 249: Train Loss = 0.01415756344795227\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=315, train_loss_step=0.015, train_loss_epoch=0.0142] Epoch 250: Train Loss = 0.015017393045127392\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=315, train_loss_step=0.0133, train_loss_epoch=0.015]Epoch 251: Train Loss = 0.013280337676405907\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, v_num=315, train_loss_step=0.0105, train_loss_epoch=0.0133]Epoch 252: Train Loss = 0.010536517016589642\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 13.56it/s, v_num=315, train_loss_step=0.0184, train_loss_epoch=0.0105]Epoch 253: Train Loss = 0.01835152506828308\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 13.91it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.0184] Epoch 254: Train Loss = 0.011983026750385761\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=315, train_loss_step=0.0139, train_loss_epoch=0.012]Epoch 255: Train Loss = 0.01389989722520113\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0139]Epoch 256: Train Loss = 0.011862434446811676\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=315, train_loss_step=0.0103, train_loss_epoch=0.0119]Epoch 257: Train Loss = 0.010302628390491009\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=315, train_loss_step=0.0108, train_loss_epoch=0.0103]Epoch 258: Train Loss = 0.010802419856190681\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0108]Epoch 259: Train Loss = 0.011103854514658451\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.0111]Epoch 260: Train Loss = 0.011253168806433678\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0113]Epoch 261: Train Loss = 0.01189438160508871\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.0119]Epoch 262: Train Loss = 0.013099889270961285\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=315, train_loss_step=0.013, train_loss_epoch=0.0131] Epoch 263: Train Loss = 0.013029501773416996\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.013]Epoch 264: Train Loss = 0.012412847019731998\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 14.12it/s, v_num=315, train_loss_step=0.0143, train_loss_epoch=0.0124]Epoch 265: Train Loss = 0.01429399661719799\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, v_num=315, train_loss_step=0.00924, train_loss_epoch=0.0143]Epoch 266: Train Loss = 0.009242004714906216\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.00924]  Epoch 267: Train Loss = 0.01197365578263998\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.012] Epoch 268: Train Loss = 0.013138426467776299\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=315, train_loss_step=0.0126, train_loss_epoch=0.0131]Epoch 269: Train Loss = 0.012606914155185223\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=315, train_loss_step=0.0102, train_loss_epoch=0.0126]Epoch 270: Train Loss = 0.010190719738602638\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s, v_num=315, train_loss_step=0.0154, train_loss_epoch=0.0102]Epoch 271: Train Loss = 0.015424130484461784\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.0154]Epoch 272: Train Loss = 0.01248475257307291\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=315, train_loss_step=0.0149, train_loss_epoch=0.0125]Epoch 273: Train Loss = 0.01493510790169239\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=315, train_loss_step=0.014, train_loss_epoch=0.0149] Epoch 274: Train Loss = 0.0140285175293684\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.014]Epoch 275: Train Loss = 0.013650030829012394\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s, v_num=315, train_loss_step=0.015, train_loss_epoch=0.0137] Epoch 276: Train Loss = 0.014966924674808979\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.015]Epoch 277: Train Loss = 0.01112436968833208\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 12.86it/s, v_num=315, train_loss_step=0.0118, train_loss_epoch=0.0111]Epoch 278: Train Loss = 0.011804001405835152\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=315, train_loss_step=0.0161, train_loss_epoch=0.0118]Epoch 279: Train Loss = 0.016143659129738808\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=315, train_loss_step=0.0132, train_loss_epoch=0.0161]Epoch 280: Train Loss = 0.013154210522770882\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=315, train_loss_step=0.0144, train_loss_epoch=0.0132]Epoch 281: Train Loss = 0.014430605806410313\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=315, train_loss_step=0.0104, train_loss_epoch=0.0144]Epoch 282: Train Loss = 0.010408478789031506\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=315, train_loss_step=0.0142, train_loss_epoch=0.0104]Epoch 283: Train Loss = 0.014222287572920322\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=315, train_loss_step=0.0141, train_loss_epoch=0.0142]Epoch 284: Train Loss = 0.014067850075662136\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.0141]Epoch 285: Train Loss = 0.013696117326617241\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.0137]Epoch 286: Train Loss = 0.012050746940076351\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 11.53it/s, v_num=315, train_loss_step=0.011, train_loss_epoch=0.0121] Epoch 287: Train Loss = 0.010994271375238895\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, v_num=315, train_loss_step=0.0159, train_loss_epoch=0.011]Epoch 288: Train Loss = 0.015874113887548447\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=315, train_loss_step=0.00963, train_loss_epoch=0.0159]Epoch 289: Train Loss = 0.009627802297472954\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.00963] Epoch 290: Train Loss = 0.012406110763549805\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=315, train_loss_step=0.0123, train_loss_epoch=0.0124] Epoch 291: Train Loss = 0.012254959903657436\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=315, train_loss_step=0.0118, train_loss_epoch=0.0123]Epoch 292: Train Loss = 0.01176037173718214\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0118]Epoch 293: Train Loss = 0.011417836882174015\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=315, train_loss_step=0.0122, train_loss_epoch=0.0114]Epoch 294: Train Loss = 0.01216985285282135\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 13.40it/s, v_num=315, train_loss_step=0.00859, train_loss_epoch=0.0122]Epoch 295: Train Loss = 0.008585036732256413\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.00859] Epoch 296: Train Loss = 0.01305331289768219\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=315, train_loss_step=0.0129, train_loss_epoch=0.0131] Epoch 297: Train Loss = 0.012862135656177998\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=315, train_loss_step=0.0102, train_loss_epoch=0.0129]Epoch 298: Train Loss = 0.010194722563028336\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=315, train_loss_step=0.0148, train_loss_epoch=0.0102]Epoch 299: Train Loss = 0.014825647696852684\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=315, train_loss_step=0.0158, train_loss_epoch=0.0148]Epoch 300: Train Loss = 0.015839288011193275\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.0158]Epoch 301: Train Loss = 0.011277074925601482\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.0113]Epoch 302: Train Loss = 0.012072622776031494\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.0121]Epoch 303: Train Loss = 0.012130730785429478\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=315, train_loss_step=0.0134, train_loss_epoch=0.0121]Epoch 304: Train Loss = 0.013407982885837555\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=315, train_loss_step=0.0172, train_loss_epoch=0.0134]Epoch 305: Train Loss = 0.01717974618077278\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0172]Epoch 306: Train Loss = 0.011862431652843952\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=315, train_loss_step=0.0112, train_loss_epoch=0.0119]Epoch 307: Train Loss = 0.011169095523655415\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=315, train_loss_step=0.0122, train_loss_epoch=0.0112]Epoch 308: Train Loss = 0.01223295833915472\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0122]Epoch 309: Train Loss = 0.011418581008911133\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.0114]Epoch 310: Train Loss = 0.01369654480367899\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=315, train_loss_step=0.0136, train_loss_epoch=0.0137]Epoch 311: Train Loss = 0.013561340980231762\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=315, train_loss_step=0.0098, train_loss_epoch=0.0136]Epoch 312: Train Loss = 0.00980477873235941\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=315, train_loss_step=0.0116, train_loss_epoch=0.0098]Epoch 313: Train Loss = 0.01159755140542984\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=315, train_loss_step=0.0127, train_loss_epoch=0.0116]Epoch 314: Train Loss = 0.012733357958495617\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 13.34it/s, v_num=315, train_loss_step=0.0109, train_loss_epoch=0.0127]Epoch 315: Train Loss = 0.010883421637117863\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 11.97it/s, v_num=315, train_loss_step=0.00938, train_loss_epoch=0.0109]Epoch 316: Train Loss = 0.009375430643558502\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=315, train_loss_step=0.018, train_loss_epoch=0.00938]  Epoch 317: Train Loss = 0.01802704855799675\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=315, train_loss_step=0.0136, train_loss_epoch=0.018] Epoch 318: Train Loss = 0.013608594425022602\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=315, train_loss_step=0.0139, train_loss_epoch=0.0136]Epoch 319: Train Loss = 0.013895981945097446\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s, v_num=315, train_loss_step=0.0108, train_loss_epoch=0.0139]Epoch 320: Train Loss = 0.010762126184999943\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=315, train_loss_step=0.00986, train_loss_epoch=0.0108]Epoch 321: Train Loss = 0.009857887402176857\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 12.32it/s, v_num=315, train_loss_step=0.00961, train_loss_epoch=0.00986]Epoch 322: Train Loss = 0.009614667855203152\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=315, train_loss_step=0.0101, train_loss_epoch=0.00961] Epoch 323: Train Loss = 0.010142544284462929\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 13.76it/s, v_num=315, train_loss_step=0.014, train_loss_epoch=0.0101]  Epoch 324: Train Loss = 0.0140451705083251\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.014] Epoch 325: Train Loss = 0.011984048411250114\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=315, train_loss_step=0.0129, train_loss_epoch=0.012]Epoch 326: Train Loss = 0.012882175855338573\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=315, train_loss_step=0.0197, train_loss_epoch=0.0129]Epoch 327: Train Loss = 0.019716978073120117\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=315, train_loss_step=0.0133, train_loss_epoch=0.0197]Epoch 328: Train Loss = 0.013312214985489845\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=315, train_loss_step=0.0138, train_loss_epoch=0.0133]Epoch 329: Train Loss = 0.013764948584139347\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s, v_num=315, train_loss_step=0.00947, train_loss_epoch=0.0138]Epoch 330: Train Loss = 0.009473356418311596\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=315, train_loss_step=0.0141, train_loss_epoch=0.00947] Epoch 331: Train Loss = 0.01412287075072527\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=315, train_loss_step=0.0118, train_loss_epoch=0.0141] Epoch 332: Train Loss = 0.01183186937123537\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=315, train_loss_step=0.0179, train_loss_epoch=0.0118]Epoch 333: Train Loss = 0.01790325529873371\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=315, train_loss_step=0.013, train_loss_epoch=0.0179] Epoch 334: Train Loss = 0.013003597967326641\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=315, train_loss_step=0.0133, train_loss_epoch=0.013]Epoch 335: Train Loss = 0.013294300995767117\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.0133]Epoch 336: Train Loss = 0.01212717592716217\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=315, train_loss_step=0.0108, train_loss_epoch=0.0121]Epoch 337: Train Loss = 0.010845073498785496\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=315, train_loss_step=0.0162, train_loss_epoch=0.0108]Epoch 338: Train Loss = 0.016176966950297356\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=315, train_loss_step=0.0141, train_loss_epoch=0.0162]Epoch 339: Train Loss = 0.014052154496312141\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=315, train_loss_step=0.00987, train_loss_epoch=0.0141]Epoch 340: Train Loss = 0.0098665039986372\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=315, train_loss_step=0.0102, train_loss_epoch=0.00987] Epoch 341: Train Loss = 0.010243216529488564\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=315, train_loss_step=0.0104, train_loss_epoch=0.0102] Epoch 342: Train Loss = 0.010437682271003723\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s, v_num=315, train_loss_step=0.015, train_loss_epoch=0.0104] Epoch 343: Train Loss = 0.01497725211083889\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=315, train_loss_step=0.0116, train_loss_epoch=0.015]Epoch 344: Train Loss = 0.011593726463615894\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=315, train_loss_step=0.00932, train_loss_epoch=0.0116]Epoch 345: Train Loss = 0.009324518032371998\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=315, train_loss_step=0.0148, train_loss_epoch=0.00932] Epoch 346: Train Loss = 0.014754323288798332\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, v_num=315, train_loss_step=0.0112, train_loss_epoch=0.0148] Epoch 347: Train Loss = 0.011238032951951027\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 13.46it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.0112]Epoch 348: Train Loss = 0.010651400312781334\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s, v_num=315, train_loss_step=0.00987, train_loss_epoch=0.0107]Epoch 349: Train Loss = 0.00986701250076294\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=315, train_loss_step=0.013, train_loss_epoch=0.00987]  Epoch 350: Train Loss = 0.012988300994038582\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s, v_num=315, train_loss_step=0.0118, train_loss_epoch=0.013] Epoch 351: Train Loss = 0.011800626292824745\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=315, train_loss_step=0.0123, train_loss_epoch=0.0118]Epoch 352: Train Loss = 0.012347938492894173\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=315, train_loss_step=0.00996, train_loss_epoch=0.0123]Epoch 353: Train Loss = 0.00996384583413601\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 13.49it/s, v_num=315, train_loss_step=0.0108, train_loss_epoch=0.00996] Epoch 354: Train Loss = 0.01082572154700756\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0108] Epoch 355: Train Loss = 0.011066650040447712\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=315, train_loss_step=0.0126, train_loss_epoch=0.0111]Epoch 356: Train Loss = 0.012633929960429668\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=315, train_loss_step=0.0148, train_loss_epoch=0.0126]Epoch 357: Train Loss = 0.014750565402209759\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=315, train_loss_step=0.00999, train_loss_epoch=0.0148]Epoch 358: Train Loss = 0.009990750811994076\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=315, train_loss_step=0.00961, train_loss_epoch=0.00999]Epoch 359: Train Loss = 0.009608200751245022\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 12.46it/s, v_num=315, train_loss_step=0.0128, train_loss_epoch=0.00961] Epoch 360: Train Loss = 0.01275727991014719\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0128] Epoch 361: Train Loss = 0.011114208027720451\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 11.55it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.0111]Epoch 362: Train Loss = 0.013735230080783367\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 13.49it/s, v_num=315, train_loss_step=0.0122, train_loss_epoch=0.0137]Epoch 363: Train Loss = 0.012207257561385632\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 12.09it/s, v_num=315, train_loss_step=0.0169, train_loss_epoch=0.0122]Epoch 364: Train Loss = 0.016853902488946915\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s, v_num=315, train_loss_step=0.0143, train_loss_epoch=0.0169]Epoch 365: Train Loss = 0.014277578331530094\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s, v_num=315, train_loss_step=0.0129, train_loss_epoch=0.0143]Epoch 366: Train Loss = 0.012871108017861843\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=315, train_loss_step=0.0149, train_loss_epoch=0.0129]Epoch 367: Train Loss = 0.01493403222411871\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=315, train_loss_step=0.0163, train_loss_epoch=0.0149]Epoch 368: Train Loss = 0.016313781961798668\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 11.30it/s, v_num=315, train_loss_step=0.017, train_loss_epoch=0.0163] Epoch 369: Train Loss = 0.016964886337518692\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=315, train_loss_step=0.0147, train_loss_epoch=0.017]Epoch 370: Train Loss = 0.014668806456029415\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=315, train_loss_step=0.0122, train_loss_epoch=0.0147]Epoch 371: Train Loss = 0.01219896413385868\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=315, train_loss_step=0.0112, train_loss_epoch=0.0122]Epoch 372: Train Loss = 0.011176077648997307\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=315, train_loss_step=0.0147, train_loss_epoch=0.0112]Epoch 373: Train Loss = 0.014670620672404766\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 13.80it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.0147]Epoch 374: Train Loss = 0.013725719414651394\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 13.02it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0137]Epoch 375: Train Loss = 0.011436243541538715\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, v_num=315, train_loss_step=0.0125, train_loss_epoch=0.0114]Epoch 376: Train Loss = 0.012479525990784168\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, v_num=315, train_loss_step=0.0135, train_loss_epoch=0.0125]Epoch 377: Train Loss = 0.013521259650588036\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.0135]Epoch 378: Train Loss = 0.012059085071086884\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0121]Epoch 379: Train Loss = 0.011921925470232964\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.0119]Epoch 380: Train Loss = 0.01313985325396061\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=315, train_loss_step=0.0195, train_loss_epoch=0.0131]Epoch 381: Train Loss = 0.019504323601722717\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=315, train_loss_step=0.0148, train_loss_epoch=0.0195]Epoch 382: Train Loss = 0.014833514578640461\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.0148]Epoch 383: Train Loss = 0.01369441393762827\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.0137]Epoch 384: Train Loss = 0.013099203817546368\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0131]Epoch 385: Train Loss = 0.011370479129254818\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=315, train_loss_step=0.0155, train_loss_epoch=0.0114]Epoch 386: Train Loss = 0.015515643171966076\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=315, train_loss_step=0.0137, train_loss_epoch=0.0155]Epoch 387: Train Loss = 0.013703481294214725\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0137]Epoch 388: Train Loss = 0.011445986106991768\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=315, train_loss_step=0.0132, train_loss_epoch=0.0114]Epoch 389: Train Loss = 0.013188786804676056\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=315, train_loss_step=0.0151, train_loss_epoch=0.0132]Epoch 390: Train Loss = 0.015053858049213886\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=315, train_loss_step=0.0148, train_loss_epoch=0.0151]Epoch 391: Train Loss = 0.014791077002882957\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=315, train_loss_step=0.0152, train_loss_epoch=0.0148]Epoch 392: Train Loss = 0.015214248560369015\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 12.91it/s, v_num=315, train_loss_step=0.0146, train_loss_epoch=0.0152]Epoch 393: Train Loss = 0.014582832343876362\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 13.29it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0146]Epoch 394: Train Loss = 0.011944146826863289\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.0119]Epoch 395: Train Loss = 0.010746581479907036\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.0107]Epoch 396: Train Loss = 0.011306731030344963\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=315, train_loss_step=0.0112, train_loss_epoch=0.0113]Epoch 397: Train Loss = 0.011220946907997131\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=315, train_loss_step=0.0109, train_loss_epoch=0.0112]Epoch 398: Train Loss = 0.010944018140435219\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=315, train_loss_step=0.0119, train_loss_epoch=0.0109]Epoch 399: Train Loss = 0.011930041015148163\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=315, train_loss_step=0.0117, train_loss_epoch=0.0119]Epoch 400: Train Loss = 0.011678493581712246\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.0117]Epoch 401: Train Loss = 0.011275983415544033\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=315, train_loss_step=0.0112, train_loss_epoch=0.0113]Epoch 402: Train Loss = 0.011244653724133968\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0112]Epoch 403: Train Loss = 0.011353584937751293\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s, v_num=315, train_loss_step=0.0105, train_loss_epoch=0.0114]Epoch 404: Train Loss = 0.01053526345640421\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=315, train_loss_step=0.0122, train_loss_epoch=0.0105]Epoch 405: Train Loss = 0.012163828127086163\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=315, train_loss_step=0.0132, train_loss_epoch=0.0122]Epoch 406: Train Loss = 0.013174776919186115\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=315, train_loss_step=0.00872, train_loss_epoch=0.0132]Epoch 407: Train Loss = 0.00872225221246481\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.00872] Epoch 408: Train Loss = 0.012363058514893055\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=315, train_loss_step=0.0112, train_loss_epoch=0.0124] Epoch 409: Train Loss = 0.011221337132155895\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=315, train_loss_step=0.00965, train_loss_epoch=0.0112]Epoch 410: Train Loss = 0.009647903963923454\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 13.88it/s, v_num=315, train_loss_step=0.0112, train_loss_epoch=0.00965] Epoch 411: Train Loss = 0.011201717890799046\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=315, train_loss_step=0.0104, train_loss_epoch=0.0112] Epoch 412: Train Loss = 0.01041903905570507\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=315, train_loss_step=0.0127, train_loss_epoch=0.0104]Epoch 413: Train Loss = 0.01272448431700468\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=315, train_loss_step=0.0136, train_loss_epoch=0.0127]Epoch 414: Train Loss = 0.013556890189647675\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s, v_num=315, train_loss_step=0.0151, train_loss_epoch=0.0136]Epoch 415: Train Loss = 0.015134422108530998\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 13.80it/s, v_num=315, train_loss_step=0.0117, train_loss_epoch=0.0151]Epoch 416: Train Loss = 0.01166580244898796\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 13.96it/s, v_num=315, train_loss_step=0.00968, train_loss_epoch=0.0117]Epoch 417: Train Loss = 0.009678552858531475\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=315, train_loss_step=0.0195, train_loss_epoch=0.00968] Epoch 418: Train Loss = 0.019517341628670692\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=315, train_loss_step=0.0122, train_loss_epoch=0.0195] Epoch 419: Train Loss = 0.012221368961036205\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.0122] Epoch 420: Train Loss = 0.01195260975509882\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.012]Epoch 421: Train Loss = 0.010745995678007603\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=315, train_loss_step=0.0172, train_loss_epoch=0.0107]Epoch 422: Train Loss = 0.017228690907359123\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=315, train_loss_step=0.0134, train_loss_epoch=0.0172]Epoch 423: Train Loss = 0.013409844599664211\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=315, train_loss_step=0.012, train_loss_epoch=0.0134] Epoch 424: Train Loss = 0.01203341968357563\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, v_num=315, train_loss_step=0.0109, train_loss_epoch=0.012]Epoch 425: Train Loss = 0.010880936868488789\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.0109]Epoch 426: Train Loss = 0.011465315707027912\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=315, train_loss_step=0.0132, train_loss_epoch=0.0115]Epoch 427: Train Loss = 0.013236016035079956\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=315, train_loss_step=0.0136, train_loss_epoch=0.0132]Epoch 428: Train Loss = 0.013613328337669373\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 13.77it/s, v_num=315, train_loss_step=0.0128, train_loss_epoch=0.0136]Epoch 429: Train Loss = 0.012828187085688114\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=315, train_loss_step=0.0105, train_loss_epoch=0.0128]Epoch 430: Train Loss = 0.010539835318922997\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=315, train_loss_step=0.0104, train_loss_epoch=0.0105]Epoch 431: Train Loss = 0.01039843074977398\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.0104]Epoch 432: Train Loss = 0.011338567361235619\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=315, train_loss_step=0.0109, train_loss_epoch=0.0113]Epoch 433: Train Loss = 0.010933010838925838\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=315, train_loss_step=0.0151, train_loss_epoch=0.0109]Epoch 434: Train Loss = 0.015106846578419209\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=315, train_loss_step=0.0106, train_loss_epoch=0.0151]Epoch 435: Train Loss = 0.010558323934674263\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.0106]Epoch 436: Train Loss = 0.011314858682453632\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=315, train_loss_step=0.0128, train_loss_epoch=0.0113]Epoch 437: Train Loss = 0.012843695469200611\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=315, train_loss_step=0.0138, train_loss_epoch=0.0128]Epoch 438: Train Loss = 0.013762515969574451\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 11.40it/s, v_num=315, train_loss_step=0.0142, train_loss_epoch=0.0138]Epoch 439: Train Loss = 0.014184996485710144\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=315, train_loss_step=0.0117, train_loss_epoch=0.0142]Epoch 440: Train Loss = 0.011709919199347496\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=315, train_loss_step=0.00877, train_loss_epoch=0.0117]Epoch 441: Train Loss = 0.008772090077400208\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=315, train_loss_step=0.0113, train_loss_epoch=0.00877] Epoch 442: Train Loss = 0.011332591064274311\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=315, train_loss_step=0.0152, train_loss_epoch=0.0113] Epoch 443: Train Loss = 0.015183049254119396\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 12.53it/s, v_num=315, train_loss_step=0.013, train_loss_epoch=0.0152] Epoch 444: Train Loss = 0.013031437061727047\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.013]Epoch 445: Train Loss = 0.012421106919646263\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=315, train_loss_step=0.0109, train_loss_epoch=0.0124]Epoch 446: Train Loss = 0.010900864377617836\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s, v_num=315, train_loss_step=0.0108, train_loss_epoch=0.0109]Epoch 447: Train Loss = 0.010812372900545597\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=315, train_loss_step=0.0104, train_loss_epoch=0.0108]Epoch 448: Train Loss = 0.010440388694405556\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 449: Train Loss = 0.011461951769888401\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0115]Epoch 450: Train Loss = 0.011059901677072048\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=315, train_loss_step=0.00992, train_loss_epoch=0.0111]Epoch 451: Train Loss = 0.009916008450090885\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.00992] Epoch 452: Train Loss = 0.010662979446351528\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=315, train_loss_step=0.00889, train_loss_epoch=0.0107]Epoch 453: Train Loss = 0.008886761032044888\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=315, train_loss_step=0.0102, train_loss_epoch=0.00889] Epoch 454: Train Loss = 0.01024288684129715\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=315, train_loss_step=0.0122, train_loss_epoch=0.0102] Epoch 455: Train Loss = 0.012241261079907417\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=315, train_loss_step=0.00918, train_loss_epoch=0.0122]Epoch 456: Train Loss = 0.009177809581160545\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s, v_num=315, train_loss_step=0.0127, train_loss_epoch=0.00918] Epoch 457: Train Loss = 0.012652935460209846\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 12.90it/s, v_num=315, train_loss_step=0.0102, train_loss_epoch=0.0127] Epoch 458: Train Loss = 0.010188409127295017\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=315, train_loss_step=0.00896, train_loss_epoch=0.0102]Epoch 459: Train Loss = 0.008962742984294891\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=315, train_loss_step=0.011, train_loss_epoch=0.00896]  Epoch 460: Train Loss = 0.010951514355838299\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 12.87it/s, v_num=315, train_loss_step=0.0108, train_loss_epoch=0.011] Epoch 461: Train Loss = 0.010785667225718498\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 10.98it/s, v_num=315, train_loss_step=0.0101, train_loss_epoch=0.0108]Epoch 462: Train Loss = 0.010102661326527596\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.0101]Epoch 463: Train Loss = 0.011487424373626709\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 13.29it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.0115]Epoch 464: Train Loss = 0.011533500626683235\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=315, train_loss_step=0.00994, train_loss_epoch=0.0115]Epoch 465: Train Loss = 0.009939702227711678\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=315, train_loss_step=0.0115, train_loss_epoch=0.00994] Epoch 466: Train Loss = 0.01147066056728363\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=315, train_loss_step=0.0105, train_loss_epoch=0.0115] Epoch 467: Train Loss = 0.01050471793860197\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=315, train_loss_step=0.0108, train_loss_epoch=0.0105]Epoch 468: Train Loss = 0.0108001958578825\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=315, train_loss_step=0.00952, train_loss_epoch=0.0108]Epoch 469: Train Loss = 0.009522357024252415\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, v_num=315, train_loss_step=0.011, train_loss_epoch=0.00952]  Epoch 470: Train Loss = 0.010991303250193596\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=315, train_loss_step=0.0096, train_loss_epoch=0.011] Epoch 471: Train Loss = 0.009604135528206825\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.0096]Epoch 472: Train Loss = 0.010718951933085918\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=315, train_loss_step=0.0114, train_loss_epoch=0.0107]Epoch 473: Train Loss = 0.011350457556545734\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=315, train_loss_step=0.0107, train_loss_epoch=0.0114]Epoch 474: Train Loss = 0.010710193775594234\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=315, train_loss_step=0.0178, train_loss_epoch=0.0107]Epoch 475: Train Loss = 0.017846383154392242\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=315, train_loss_step=0.00863, train_loss_epoch=0.0178]Epoch 476: Train Loss = 0.00862960983067751\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 12.27it/s, v_num=315, train_loss_step=0.0138, train_loss_epoch=0.00863] Epoch 477: Train Loss = 0.013818751089274883\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=315, train_loss_step=0.0106, train_loss_epoch=0.0138] Epoch 478: Train Loss = 0.01060845609754324\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 11.34it/s, v_num=315, train_loss_step=0.0146, train_loss_epoch=0.0106]Epoch 479: Train Loss = 0.01463084202259779\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=315, train_loss_step=0.0161, train_loss_epoch=0.0146]Epoch 480: Train Loss = 0.01609927974641323\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.0161]Epoch 481: Train Loss = 0.01242916565388441\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=315, train_loss_step=0.0124, train_loss_epoch=0.0124]Epoch 482: Train Loss = 0.012433426454663277\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0124]Epoch 483: Train Loss = 0.011093162931501865\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=315, train_loss_step=0.0167, train_loss_epoch=0.0111]Epoch 484: Train Loss = 0.01669868640601635\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=315, train_loss_step=0.0136, train_loss_epoch=0.0167]Epoch 485: Train Loss = 0.013610830530524254\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 12.61it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0136]Epoch 486: Train Loss = 0.011055514216423035\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s, v_num=315, train_loss_step=0.0163, train_loss_epoch=0.0111]Epoch 487: Train Loss = 0.016291216015815735\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=315, train_loss_step=0.0135, train_loss_epoch=0.0163]Epoch 488: Train Loss = 0.013512671925127506\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=315, train_loss_step=0.0163, train_loss_epoch=0.0135]Epoch 489: Train Loss = 0.01628391444683075\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s, v_num=315, train_loss_step=0.0092, train_loss_epoch=0.0163]Epoch 490: Train Loss = 0.009200004860758781\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=315, train_loss_step=0.0111, train_loss_epoch=0.0092]Epoch 491: Train Loss = 0.01105248462408781\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s, v_num=315, train_loss_step=0.0129, train_loss_epoch=0.0111]Epoch 492: Train Loss = 0.012948851101100445\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=315, train_loss_step=0.0123, train_loss_epoch=0.0129]Epoch 493: Train Loss = 0.01231651846319437\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=315, train_loss_step=0.0139, train_loss_epoch=0.0123]Epoch 494: Train Loss = 0.013865522108972073\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s, v_num=315, train_loss_step=0.0121, train_loss_epoch=0.0139]Epoch 495: Train Loss = 0.012136309407651424\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.0121]Epoch 496: Train Loss = 0.013126627542078495\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=315, train_loss_step=0.0126, train_loss_epoch=0.0131]Epoch 497: Train Loss = 0.012639340944588184\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=315, train_loss_step=0.0138, train_loss_epoch=0.0126]Epoch 498: Train Loss = 0.0138325747102499\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.0138]Epoch 499: Train Loss = 0.0130801135674119\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.0131]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=315, train_loss_step=0.0131, train_loss_epoch=0.0131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 7: from 2010-06-30 00:00:00 to 2022-08-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=317, train_loss_step=0.0336]Epoch 0: Train Loss = 0.03359169512987137\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=317, train_loss_step=0.0418, train_loss_epoch=0.0336]Epoch 1: Train Loss = 0.041826315224170685\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=317, train_loss_step=0.0345, train_loss_epoch=0.0418]Epoch 2: Train Loss = 0.03446437045931816\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=317, train_loss_step=0.026, train_loss_epoch=0.0345] Epoch 3: Train Loss = 0.025992054492235184\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=317, train_loss_step=0.0286, train_loss_epoch=0.026]Epoch 4: Train Loss = 0.028616664931178093\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=317, train_loss_step=0.0172, train_loss_epoch=0.0286]Epoch 5: Train Loss = 0.01718338206410408\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=317, train_loss_step=0.0239, train_loss_epoch=0.0172]Epoch 6: Train Loss = 0.02386332117021084\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=317, train_loss_step=0.0228, train_loss_epoch=0.0239]Epoch 7: Train Loss = 0.022843968123197556\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=317, train_loss_step=0.0223, train_loss_epoch=0.0228]Epoch 8: Train Loss = 0.022338122129440308\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=317, train_loss_step=0.0161, train_loss_epoch=0.0223]Epoch 9: Train Loss = 0.016100766137242317\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=317, train_loss_step=0.0203, train_loss_epoch=0.0161]Epoch 10: Train Loss = 0.020326243713498116\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=317, train_loss_step=0.0192, train_loss_epoch=0.0203]Epoch 11: Train Loss = 0.019218627363443375\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=317, train_loss_step=0.0179, train_loss_epoch=0.0192]Epoch 12: Train Loss = 0.01787499710917473\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=317, train_loss_step=0.016, train_loss_epoch=0.0179] Epoch 13: Train Loss = 0.01601824350655079\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=317, train_loss_step=0.0173, train_loss_epoch=0.016]Epoch 14: Train Loss = 0.017285658046603203\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, v_num=317, train_loss_step=0.0202, train_loss_epoch=0.0173]Epoch 15: Train Loss = 0.020173009485006332\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=317, train_loss_step=0.0149, train_loss_epoch=0.0202]Epoch 16: Train Loss = 0.014890913851559162\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=317, train_loss_step=0.0184, train_loss_epoch=0.0149]Epoch 17: Train Loss = 0.018435144796967506\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=317, train_loss_step=0.0179, train_loss_epoch=0.0184]Epoch 18: Train Loss = 0.01791440322995186\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.92it/s, v_num=317, train_loss_step=0.016, train_loss_epoch=0.0179] Epoch 19: Train Loss = 0.01595366559922695\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=317, train_loss_step=0.0183, train_loss_epoch=0.016]Epoch 20: Train Loss = 0.018323546275496483\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=317, train_loss_step=0.0231, train_loss_epoch=0.0183]Epoch 21: Train Loss = 0.023085547611117363\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=317, train_loss_step=0.0147, train_loss_epoch=0.0231]Epoch 22: Train Loss = 0.01465229969471693\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=317, train_loss_step=0.019, train_loss_epoch=0.0147] Epoch 23: Train Loss = 0.01901223696768284\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=317, train_loss_step=0.0136, train_loss_epoch=0.019]Epoch 24: Train Loss = 0.013649597764015198\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=317, train_loss_step=0.0182, train_loss_epoch=0.0136]Epoch 25: Train Loss = 0.018159227445721626\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=317, train_loss_step=0.0195, train_loss_epoch=0.0182]Epoch 26: Train Loss = 0.01953180506825447\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=317, train_loss_step=0.0203, train_loss_epoch=0.0195]Epoch 27: Train Loss = 0.020272251218557358\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=317, train_loss_step=0.0161, train_loss_epoch=0.0203]Epoch 28: Train Loss = 0.01612529344856739\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=317, train_loss_step=0.0177, train_loss_epoch=0.0161]Epoch 29: Train Loss = 0.017686229199171066\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=317, train_loss_step=0.0164, train_loss_epoch=0.0177]Epoch 30: Train Loss = 0.016370471566915512\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=317, train_loss_step=0.0122, train_loss_epoch=0.0164]Epoch 31: Train Loss = 0.012189822271466255\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=317, train_loss_step=0.0172, train_loss_epoch=0.0122]Epoch 32: Train Loss = 0.017229581251740456\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=317, train_loss_step=0.0156, train_loss_epoch=0.0172]Epoch 33: Train Loss = 0.015629421919584274\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=317, train_loss_step=0.0145, train_loss_epoch=0.0156]Epoch 34: Train Loss = 0.014486896805465221\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 13.41it/s, v_num=317, train_loss_step=0.0176, train_loss_epoch=0.0145]Epoch 35: Train Loss = 0.01759490743279457\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 12.53it/s, v_num=317, train_loss_step=0.0182, train_loss_epoch=0.0176]Epoch 36: Train Loss = 0.01820226013660431\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 12.53it/s, v_num=317, train_loss_step=0.0155, train_loss_epoch=0.0182]Epoch 37: Train Loss = 0.015525951981544495\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=317, train_loss_step=0.0135, train_loss_epoch=0.0155]Epoch 38: Train Loss = 0.013459180481731892\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=317, train_loss_step=0.0194, train_loss_epoch=0.0135]Epoch 39: Train Loss = 0.019369689747691154\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=317, train_loss_step=0.0122, train_loss_epoch=0.0194]Epoch 40: Train Loss = 0.012246139347553253\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.0122]Epoch 41: Train Loss = 0.013329326175153255\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, v_num=317, train_loss_step=0.0166, train_loss_epoch=0.0133]Epoch 42: Train Loss = 0.01662784069776535\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=317, train_loss_step=0.0207, train_loss_epoch=0.0166]Epoch 43: Train Loss = 0.02071848139166832\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=317, train_loss_step=0.0171, train_loss_epoch=0.0207]Epoch 44: Train Loss = 0.017142279073596\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=317, train_loss_step=0.0151, train_loss_epoch=0.0171]Epoch 45: Train Loss = 0.015084266662597656\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=317, train_loss_step=0.016, train_loss_epoch=0.0151] Epoch 46: Train Loss = 0.015985233709216118\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=317, train_loss_step=0.0141, train_loss_epoch=0.016]Epoch 47: Train Loss = 0.01406092755496502\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=317, train_loss_step=0.0239, train_loss_epoch=0.0141]Epoch 48: Train Loss = 0.023943636566400528\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=317, train_loss_step=0.0192, train_loss_epoch=0.0239]Epoch 49: Train Loss = 0.019196152687072754\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s, v_num=317, train_loss_step=0.0135, train_loss_epoch=0.0192]Epoch 50: Train Loss = 0.013500656001269817\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 10.45it/s, v_num=317, train_loss_step=0.0165, train_loss_epoch=0.0135]Epoch 51: Train Loss = 0.016517769545316696\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=317, train_loss_step=0.0219, train_loss_epoch=0.0165]Epoch 52: Train Loss = 0.021855097264051437\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=317, train_loss_step=0.0216, train_loss_epoch=0.0219]Epoch 53: Train Loss = 0.021558521315455437\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 17.47it/s, v_num=317, train_loss_step=0.0168, train_loss_epoch=0.0216]Epoch 54: Train Loss = 0.016797352582216263\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s, v_num=317, train_loss_step=0.0134, train_loss_epoch=0.0168]Epoch 55: Train Loss = 0.013418384827673435\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=317, train_loss_step=0.0175, train_loss_epoch=0.0134]Epoch 56: Train Loss = 0.017451094463467598\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s, v_num=317, train_loss_step=0.0205, train_loss_epoch=0.0175]Epoch 57: Train Loss = 0.020464729517698288\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 13.44it/s, v_num=317, train_loss_step=0.020, train_loss_epoch=0.0205] Epoch 58: Train Loss = 0.020026346668601036\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=317, train_loss_step=0.0151, train_loss_epoch=0.020]Epoch 59: Train Loss = 0.015080912970006466\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=317, train_loss_step=0.0182, train_loss_epoch=0.0151]Epoch 60: Train Loss = 0.018175985664129257\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=317, train_loss_step=0.0177, train_loss_epoch=0.0182]Epoch 61: Train Loss = 0.01769454963505268\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=317, train_loss_step=0.0179, train_loss_epoch=0.0177]Epoch 62: Train Loss = 0.017865432426333427\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 10.08it/s, v_num=317, train_loss_step=0.0158, train_loss_epoch=0.0179]Epoch 63: Train Loss = 0.015842312946915627\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=317, train_loss_step=0.0193, train_loss_epoch=0.0158]Epoch 64: Train Loss = 0.01928582414984703\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=317, train_loss_step=0.0147, train_loss_epoch=0.0193]Epoch 65: Train Loss = 0.014705436304211617\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=317, train_loss_step=0.0151, train_loss_epoch=0.0147]Epoch 66: Train Loss = 0.01512391958385706\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, v_num=317, train_loss_step=0.0159, train_loss_epoch=0.0151]Epoch 67: Train Loss = 0.01586030423641205\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 16.62it/s, v_num=317, train_loss_step=0.0198, train_loss_epoch=0.0159]Epoch 68: Train Loss = 0.019813956692814827\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s, v_num=317, train_loss_step=0.0145, train_loss_epoch=0.0198]Epoch 69: Train Loss = 0.014534790068864822\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=317, train_loss_step=0.0173, train_loss_epoch=0.0145]Epoch 70: Train Loss = 0.017349282279610634\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 16.45it/s, v_num=317, train_loss_step=0.0185, train_loss_epoch=0.0173]Epoch 71: Train Loss = 0.018511716276407242\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=317, train_loss_step=0.0177, train_loss_epoch=0.0185]Epoch 72: Train Loss = 0.0177434291690588\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=317, train_loss_step=0.0144, train_loss_epoch=0.0177]Epoch 73: Train Loss = 0.01443721167743206\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=317, train_loss_step=0.0154, train_loss_epoch=0.0144]Epoch 74: Train Loss = 0.015445144847035408\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 16.14it/s, v_num=317, train_loss_step=0.0131, train_loss_epoch=0.0154]Epoch 75: Train Loss = 0.01312437653541565\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, v_num=317, train_loss_step=0.0143, train_loss_epoch=0.0131]Epoch 76: Train Loss = 0.014342689886689186\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=317, train_loss_step=0.0149, train_loss_epoch=0.0143]Epoch 77: Train Loss = 0.01493687741458416\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 16.10it/s, v_num=317, train_loss_step=0.0161, train_loss_epoch=0.0149]Epoch 78: Train Loss = 0.01605217717587948\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=317, train_loss_step=0.0158, train_loss_epoch=0.0161]Epoch 79: Train Loss = 0.015769632533192635\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=317, train_loss_step=0.018, train_loss_epoch=0.0158] Epoch 80: Train Loss = 0.017957832664251328\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=317, train_loss_step=0.0191, train_loss_epoch=0.018]Epoch 81: Train Loss = 0.019132550805807114\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=317, train_loss_step=0.0246, train_loss_epoch=0.0191]Epoch 82: Train Loss = 0.024599755182862282\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, v_num=317, train_loss_step=0.0157, train_loss_epoch=0.0246]Epoch 83: Train Loss = 0.015729688107967377\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, v_num=317, train_loss_step=0.0134, train_loss_epoch=0.0157]Epoch 84: Train Loss = 0.013429270125925541\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 16.61it/s, v_num=317, train_loss_step=0.0268, train_loss_epoch=0.0134]Epoch 85: Train Loss = 0.026786169037222862\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=317, train_loss_step=0.0147, train_loss_epoch=0.0268]Epoch 86: Train Loss = 0.014717047102749348\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=317, train_loss_step=0.0164, train_loss_epoch=0.0147]Epoch 87: Train Loss = 0.016419392079114914\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=317, train_loss_step=0.0131, train_loss_epoch=0.0164]Epoch 88: Train Loss = 0.013139135204255581\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=317, train_loss_step=0.022, train_loss_epoch=0.0131] Epoch 89: Train Loss = 0.021993298083543777\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=317, train_loss_step=0.0194, train_loss_epoch=0.022]Epoch 90: Train Loss = 0.01935032568871975\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 13.02it/s, v_num=317, train_loss_step=0.0197, train_loss_epoch=0.0194]Epoch 91: Train Loss = 0.019686471670866013\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=317, train_loss_step=0.0168, train_loss_epoch=0.0197]Epoch 92: Train Loss = 0.016841242089867592\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 16.47it/s, v_num=317, train_loss_step=0.0127, train_loss_epoch=0.0168]Epoch 93: Train Loss = 0.012738173827528954\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=317, train_loss_step=0.0172, train_loss_epoch=0.0127]Epoch 94: Train Loss = 0.017230968922376633\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=317, train_loss_step=0.0202, train_loss_epoch=0.0172]Epoch 95: Train Loss = 0.02018214389681816\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=317, train_loss_step=0.0127, train_loss_epoch=0.0202]Epoch 96: Train Loss = 0.012711440213024616\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=317, train_loss_step=0.0186, train_loss_epoch=0.0127]Epoch 97: Train Loss = 0.018564632162451744\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, v_num=317, train_loss_step=0.0206, train_loss_epoch=0.0186]Epoch 98: Train Loss = 0.020580869168043137\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=317, train_loss_step=0.0162, train_loss_epoch=0.0206]Epoch 99: Train Loss = 0.01622304879128933\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s, v_num=317, train_loss_step=0.0171, train_loss_epoch=0.0162]Epoch 100: Train Loss = 0.017059821635484695\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=317, train_loss_step=0.0143, train_loss_epoch=0.0171]Epoch 101: Train Loss = 0.01428129617124796\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s, v_num=317, train_loss_step=0.0196, train_loss_epoch=0.0143]Epoch 102: Train Loss = 0.01961805857717991\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, v_num=317, train_loss_step=0.0188, train_loss_epoch=0.0196]Epoch 103: Train Loss = 0.01883360557258129\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=317, train_loss_step=0.0168, train_loss_epoch=0.0188]Epoch 104: Train Loss = 0.016837937757372856\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=317, train_loss_step=0.0159, train_loss_epoch=0.0168]Epoch 105: Train Loss = 0.01587287150323391\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=317, train_loss_step=0.0274, train_loss_epoch=0.0159]Epoch 106: Train Loss = 0.02739386074244976\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 16.62it/s, v_num=317, train_loss_step=0.0188, train_loss_epoch=0.0274]Epoch 107: Train Loss = 0.01877128891646862\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s, v_num=317, train_loss_step=0.0201, train_loss_epoch=0.0188]Epoch 108: Train Loss = 0.020124822854995728\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=317, train_loss_step=0.0192, train_loss_epoch=0.0201]Epoch 109: Train Loss = 0.019173255190253258\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=317, train_loss_step=0.0164, train_loss_epoch=0.0192]Epoch 110: Train Loss = 0.01640351675450802\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s, v_num=317, train_loss_step=0.0139, train_loss_epoch=0.0164]Epoch 111: Train Loss = 0.013890613801777363\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=317, train_loss_step=0.0191, train_loss_epoch=0.0139]Epoch 112: Train Loss = 0.019054848700761795\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=317, train_loss_step=0.0202, train_loss_epoch=0.0191]Epoch 113: Train Loss = 0.020152384415268898\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 13.00it/s, v_num=317, train_loss_step=0.0156, train_loss_epoch=0.0202]Epoch 114: Train Loss = 0.015576423145830631\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 16.90it/s, v_num=317, train_loss_step=0.0157, train_loss_epoch=0.0156]Epoch 115: Train Loss = 0.015683351084589958\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 17.11it/s, v_num=317, train_loss_step=0.0234, train_loss_epoch=0.0157]Epoch 116: Train Loss = 0.023374337702989578\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=317, train_loss_step=0.0164, train_loss_epoch=0.0234]Epoch 117: Train Loss = 0.016408057883381844\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=317, train_loss_step=0.0172, train_loss_epoch=0.0164]Epoch 118: Train Loss = 0.01715845614671707\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s, v_num=317, train_loss_step=0.0198, train_loss_epoch=0.0172]Epoch 119: Train Loss = 0.01977263204753399\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, v_num=317, train_loss_step=0.0259, train_loss_epoch=0.0198]Epoch 120: Train Loss = 0.025932466611266136\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=317, train_loss_step=0.015, train_loss_epoch=0.0259] Epoch 121: Train Loss = 0.015042844228446484\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s, v_num=317, train_loss_step=0.0124, train_loss_epoch=0.015]Epoch 122: Train Loss = 0.012387441471219063\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 16.74it/s, v_num=317, train_loss_step=0.0164, train_loss_epoch=0.0124]Epoch 123: Train Loss = 0.01644853688776493\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 16.65it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0164]Epoch 124: Train Loss = 0.01247232686728239\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=317, train_loss_step=0.0181, train_loss_epoch=0.0125]Epoch 125: Train Loss = 0.01809156872332096\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=317, train_loss_step=0.0205, train_loss_epoch=0.0181]Epoch 126: Train Loss = 0.020476488396525383\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 16.04it/s, v_num=317, train_loss_step=0.0161, train_loss_epoch=0.0205]Epoch 127: Train Loss = 0.01611098274588585\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=317, train_loss_step=0.0168, train_loss_epoch=0.0161]Epoch 128: Train Loss = 0.016831248998641968\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=317, train_loss_step=0.0157, train_loss_epoch=0.0168]Epoch 129: Train Loss = 0.015663791447877884\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=317, train_loss_step=0.0173, train_loss_epoch=0.0157]Epoch 130: Train Loss = 0.017277199774980545\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 17.01it/s, v_num=317, train_loss_step=0.0199, train_loss_epoch=0.0173]Epoch 131: Train Loss = 0.019888652488589287\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 16.64it/s, v_num=317, train_loss_step=0.0164, train_loss_epoch=0.0199]Epoch 132: Train Loss = 0.016419360414147377\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.0164]Epoch 133: Train Loss = 0.01334372442215681\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 16.72it/s, v_num=317, train_loss_step=0.0259, train_loss_epoch=0.0133]Epoch 134: Train Loss = 0.025857234373688698\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 16.94it/s, v_num=317, train_loss_step=0.0187, train_loss_epoch=0.0259]Epoch 135: Train Loss = 0.018739739432930946\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 16.90it/s, v_num=317, train_loss_step=0.0131, train_loss_epoch=0.0187]Epoch 136: Train Loss = 0.01305887009948492\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s, v_num=317, train_loss_step=0.0138, train_loss_epoch=0.0131]Epoch 137: Train Loss = 0.013844563625752926\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=317, train_loss_step=0.0152, train_loss_epoch=0.0138]Epoch 138: Train Loss = 0.015158441849052906\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 17.51it/s, v_num=317, train_loss_step=0.0239, train_loss_epoch=0.0152]Epoch 139: Train Loss = 0.023895593360066414\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s, v_num=317, train_loss_step=0.0161, train_loss_epoch=0.0239]Epoch 140: Train Loss = 0.016069600358605385\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s, v_num=317, train_loss_step=0.0168, train_loss_epoch=0.0161]Epoch 141: Train Loss = 0.016836339607834816\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=317, train_loss_step=0.0126, train_loss_epoch=0.0168]Epoch 142: Train Loss = 0.012586338445544243\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, v_num=317, train_loss_step=0.0121, train_loss_epoch=0.0126]Epoch 143: Train Loss = 0.012066337279975414\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s, v_num=317, train_loss_step=0.0178, train_loss_epoch=0.0121]Epoch 144: Train Loss = 0.017774665728211403\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=317, train_loss_step=0.0177, train_loss_epoch=0.0178]Epoch 145: Train Loss = 0.017690394073724747\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 16.74it/s, v_num=317, train_loss_step=0.0168, train_loss_epoch=0.0177]Epoch 146: Train Loss = 0.0167726818472147\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 13.96it/s, v_num=317, train_loss_step=0.022, train_loss_epoch=0.0168] Epoch 147: Train Loss = 0.02203240431845188\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 16.02it/s, v_num=317, train_loss_step=0.0151, train_loss_epoch=0.022]Epoch 148: Train Loss = 0.015077565796673298\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 16.64it/s, v_num=317, train_loss_step=0.0141, train_loss_epoch=0.0151]Epoch 149: Train Loss = 0.014092409051954746\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s, v_num=317, train_loss_step=0.0174, train_loss_epoch=0.0141]Epoch 150: Train Loss = 0.01740492694079876\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 16.82it/s, v_num=317, train_loss_step=0.0141, train_loss_epoch=0.0174]Epoch 151: Train Loss = 0.014102116227149963\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=317, train_loss_step=0.0157, train_loss_epoch=0.0141]Epoch 152: Train Loss = 0.015736481174826622\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 16.72it/s, v_num=317, train_loss_step=0.0173, train_loss_epoch=0.0157]Epoch 153: Train Loss = 0.017271317541599274\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=317, train_loss_step=0.017, train_loss_epoch=0.0173] Epoch 154: Train Loss = 0.016964757815003395\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.017]Epoch 155: Train Loss = 0.0132518345490098\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=317, train_loss_step=0.0214, train_loss_epoch=0.0133]Epoch 156: Train Loss = 0.021394582465291023\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s, v_num=317, train_loss_step=0.0179, train_loss_epoch=0.0214]Epoch 157: Train Loss = 0.017943406477570534\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, v_num=317, train_loss_step=0.0154, train_loss_epoch=0.0179]Epoch 158: Train Loss = 0.015352467074990273\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=317, train_loss_step=0.0159, train_loss_epoch=0.0154]Epoch 159: Train Loss = 0.015931671485304832\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 17.81it/s, v_num=317, train_loss_step=0.0198, train_loss_epoch=0.0159]Epoch 160: Train Loss = 0.01977522112429142\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s, v_num=317, train_loss_step=0.0179, train_loss_epoch=0.0198]Epoch 161: Train Loss = 0.017879387363791466\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s, v_num=317, train_loss_step=0.0176, train_loss_epoch=0.0179]Epoch 162: Train Loss = 0.017568035051226616\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=317, train_loss_step=0.0226, train_loss_epoch=0.0176]Epoch 163: Train Loss = 0.02255867049098015\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=317, train_loss_step=0.0155, train_loss_epoch=0.0226]Epoch 164: Train Loss = 0.015505211427807808\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 16.62it/s, v_num=317, train_loss_step=0.0121, train_loss_epoch=0.0155]Epoch 165: Train Loss = 0.012073497287929058\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s, v_num=317, train_loss_step=0.013, train_loss_epoch=0.0121] Epoch 166: Train Loss = 0.013000785373151302\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 17.70it/s, v_num=317, train_loss_step=0.014, train_loss_epoch=0.013] Epoch 167: Train Loss = 0.01399284042418003\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 17.68it/s, v_num=317, train_loss_step=0.0203, train_loss_epoch=0.014]Epoch 168: Train Loss = 0.020295074209570885\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 17.26it/s, v_num=317, train_loss_step=0.0153, train_loss_epoch=0.0203]Epoch 169: Train Loss = 0.01533512957394123\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=317, train_loss_step=0.0161, train_loss_epoch=0.0153]Epoch 170: Train Loss = 0.016144804656505585\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=317, train_loss_step=0.0172, train_loss_epoch=0.0161]Epoch 171: Train Loss = 0.017160145565867424\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s, v_num=317, train_loss_step=0.0182, train_loss_epoch=0.0172]Epoch 172: Train Loss = 0.018152708187699318\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s, v_num=317, train_loss_step=0.0179, train_loss_epoch=0.0182]Epoch 173: Train Loss = 0.017857210710644722\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=317, train_loss_step=0.0144, train_loss_epoch=0.0179]Epoch 174: Train Loss = 0.014428436756134033\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 17.43it/s, v_num=317, train_loss_step=0.015, train_loss_epoch=0.0144] Epoch 175: Train Loss = 0.015026268549263477\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=317, train_loss_step=0.0188, train_loss_epoch=0.015]Epoch 176: Train Loss = 0.018849769607186317\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=317, train_loss_step=0.0143, train_loss_epoch=0.0188]Epoch 177: Train Loss = 0.014252543449401855\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 13.59it/s, v_num=317, train_loss_step=0.0124, train_loss_epoch=0.0143]Epoch 178: Train Loss = 0.0123967956751585\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=317, train_loss_step=0.0144, train_loss_epoch=0.0124]Epoch 179: Train Loss = 0.014448347501456738\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s, v_num=317, train_loss_step=0.0185, train_loss_epoch=0.0144]Epoch 180: Train Loss = 0.01848514750599861\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=317, train_loss_step=0.0144, train_loss_epoch=0.0185]Epoch 181: Train Loss = 0.014367437921464443\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=317, train_loss_step=0.0181, train_loss_epoch=0.0144]Epoch 182: Train Loss = 0.018063265830278397\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 17.45it/s, v_num=317, train_loss_step=0.0162, train_loss_epoch=0.0181]Epoch 183: Train Loss = 0.016193699091672897\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=317, train_loss_step=0.0209, train_loss_epoch=0.0162]Epoch 184: Train Loss = 0.020904695615172386\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=317, train_loss_step=0.0177, train_loss_epoch=0.0209]Epoch 185: Train Loss = 0.017670664936304092\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0177]Epoch 186: Train Loss = 0.012465503998100758\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=317, train_loss_step=0.0198, train_loss_epoch=0.0125]Epoch 187: Train Loss = 0.019801799207925797\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=317, train_loss_step=0.0162, train_loss_epoch=0.0198]Epoch 188: Train Loss = 0.016172194853425026\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=317, train_loss_step=0.0163, train_loss_epoch=0.0162]Epoch 189: Train Loss = 0.01634480245411396\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=317, train_loss_step=0.00975, train_loss_epoch=0.0163]Epoch 190: Train Loss = 0.009746362455189228\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=317, train_loss_step=0.0144, train_loss_epoch=0.00975] Epoch 191: Train Loss = 0.014365490525960922\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=317, train_loss_step=0.0104, train_loss_epoch=0.0144] Epoch 192: Train Loss = 0.010399477556347847\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 11.55it/s, v_num=317, train_loss_step=0.0144, train_loss_epoch=0.0104]Epoch 193: Train Loss = 0.014426697976887226\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=317, train_loss_step=0.0163, train_loss_epoch=0.0144]Epoch 194: Train Loss = 0.01625528559088707\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=317, train_loss_step=0.0165, train_loss_epoch=0.0163]Epoch 195: Train Loss = 0.016495944932103157\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=317, train_loss_step=0.0136, train_loss_epoch=0.0165]Epoch 196: Train Loss = 0.013636879622936249\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 13.40it/s, v_num=317, train_loss_step=0.015, train_loss_epoch=0.0136] Epoch 197: Train Loss = 0.014955626800656319\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.015]Epoch 198: Train Loss = 0.012468213215470314\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=317, train_loss_step=0.0148, train_loss_epoch=0.0125]Epoch 199: Train Loss = 0.014837482012808323\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, v_num=317, train_loss_step=0.0149, train_loss_epoch=0.0148]Epoch 200: Train Loss = 0.014932320453226566\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=317, train_loss_step=0.0109, train_loss_epoch=0.0149]Epoch 201: Train Loss = 0.010872857645154\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=317, train_loss_step=0.0139, train_loss_epoch=0.0109]Epoch 202: Train Loss = 0.013861632905900478\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 17.22it/s, v_num=317, train_loss_step=0.0136, train_loss_epoch=0.0139]Epoch 203: Train Loss = 0.013557321391999722\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=317, train_loss_step=0.0118, train_loss_epoch=0.0136]Epoch 204: Train Loss = 0.011781467124819756\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=317, train_loss_step=0.0147, train_loss_epoch=0.0118]Epoch 205: Train Loss = 0.014744787476956844\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=317, train_loss_step=0.0195, train_loss_epoch=0.0147]Epoch 206: Train Loss = 0.019484464079141617\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=317, train_loss_step=0.0148, train_loss_epoch=0.0195]Epoch 207: Train Loss = 0.014764310792088509\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=317, train_loss_step=0.0132, train_loss_epoch=0.0148]Epoch 208: Train Loss = 0.01317894458770752\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 17.58it/s, v_num=317, train_loss_step=0.0129, train_loss_epoch=0.0132]Epoch 209: Train Loss = 0.012908252887427807\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, v_num=317, train_loss_step=0.0117, train_loss_epoch=0.0129]Epoch 210: Train Loss = 0.011720948852598667\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=317, train_loss_step=0.013, train_loss_epoch=0.0117] Epoch 211: Train Loss = 0.01295537780970335\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 16.82it/s, v_num=317, train_loss_step=0.0166, train_loss_epoch=0.013]Epoch 212: Train Loss = 0.016600172966718674\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 16.73it/s, v_num=317, train_loss_step=0.0174, train_loss_epoch=0.0166]Epoch 213: Train Loss = 0.017379870638251305\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=317, train_loss_step=0.015, train_loss_epoch=0.0174] Epoch 214: Train Loss = 0.015029093250632286\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=317, train_loss_step=0.0121, train_loss_epoch=0.015]Epoch 215: Train Loss = 0.012116489000618458\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 11.64it/s, v_num=317, train_loss_step=0.0157, train_loss_epoch=0.0121]Epoch 216: Train Loss = 0.015719931572675705\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=317, train_loss_step=0.012, train_loss_epoch=0.0157] Epoch 217: Train Loss = 0.011952036991715431\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.012]Epoch 218: Train Loss = 0.013297474011778831\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=317, train_loss_step=0.0144, train_loss_epoch=0.0133]Epoch 219: Train Loss = 0.014405257068574429\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=317, train_loss_step=0.0135, train_loss_epoch=0.0144]Epoch 220: Train Loss = 0.013491933234035969\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=317, train_loss_step=0.0134, train_loss_epoch=0.0135]Epoch 221: Train Loss = 0.013380544260144234\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, v_num=317, train_loss_step=0.017, train_loss_epoch=0.0134] Epoch 222: Train Loss = 0.016994638368487358\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=317, train_loss_step=0.0183, train_loss_epoch=0.017]Epoch 223: Train Loss = 0.018289241939783096\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=317, train_loss_step=0.0142, train_loss_epoch=0.0183]Epoch 224: Train Loss = 0.014241091907024384\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.0142]Epoch 225: Train Loss = 0.013335945084691048\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=317, train_loss_step=0.0112, train_loss_epoch=0.0133]Epoch 226: Train Loss = 0.011191969737410545\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0112]Epoch 227: Train Loss = 0.01147399004548788\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=317, train_loss_step=0.0124, train_loss_epoch=0.0115]Epoch 228: Train Loss = 0.01235231664031744\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=317, train_loss_step=0.014, train_loss_epoch=0.0124] Epoch 229: Train Loss = 0.013986334204673767\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=317, train_loss_step=0.0128, train_loss_epoch=0.014]Epoch 230: Train Loss = 0.012835103087127209\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=317, train_loss_step=0.0132, train_loss_epoch=0.0128]Epoch 231: Train Loss = 0.01315051969140768\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=317, train_loss_step=0.0139, train_loss_epoch=0.0132]Epoch 232: Train Loss = 0.013938982971012592\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.0139]Epoch 233: Train Loss = 0.013337059877812862\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s, v_num=317, train_loss_step=0.0131, train_loss_epoch=0.0133]Epoch 234: Train Loss = 0.013091749511659145\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=317, train_loss_step=0.0123, train_loss_epoch=0.0131]Epoch 235: Train Loss = 0.012346175499260426\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=317, train_loss_step=0.0128, train_loss_epoch=0.0123]Epoch 236: Train Loss = 0.012803680263459682\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=317, train_loss_step=0.0136, train_loss_epoch=0.0128]Epoch 237: Train Loss = 0.01364194042980671\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=317, train_loss_step=0.0118, train_loss_epoch=0.0136]Epoch 238: Train Loss = 0.011822229251265526\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=317, train_loss_step=0.0187, train_loss_epoch=0.0118]Epoch 239: Train Loss = 0.018654460087418556\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=317, train_loss_step=0.012, train_loss_epoch=0.0187] Epoch 240: Train Loss = 0.012012183666229248\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=317, train_loss_step=0.00995, train_loss_epoch=0.012]Epoch 241: Train Loss = 0.00994805246591568\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=317, train_loss_step=0.0104, train_loss_epoch=0.00995] Epoch 242: Train Loss = 0.010351233184337616\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0104] Epoch 243: Train Loss = 0.012498406693339348\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=317, train_loss_step=0.016, train_loss_epoch=0.0125] Epoch 244: Train Loss = 0.016027579084038734\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=317, train_loss_step=0.0132, train_loss_epoch=0.016]Epoch 245: Train Loss = 0.013180029578506947\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=317, train_loss_step=0.0117, train_loss_epoch=0.0132]Epoch 246: Train Loss = 0.011719921603798866\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=317, train_loss_step=0.0224, train_loss_epoch=0.0117]Epoch 247: Train Loss = 0.022374242544174194\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=317, train_loss_step=0.0173, train_loss_epoch=0.0224]Epoch 248: Train Loss = 0.017294032499194145\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=317, train_loss_step=0.0178, train_loss_epoch=0.0173]Epoch 249: Train Loss = 0.01784646138548851\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0178]Epoch 250: Train Loss = 0.012541703879833221\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=317, train_loss_step=0.0129, train_loss_epoch=0.0125]Epoch 251: Train Loss = 0.012858709320425987\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=317, train_loss_step=0.0141, train_loss_epoch=0.0129]Epoch 252: Train Loss = 0.01409736555069685\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=317, train_loss_step=0.0143, train_loss_epoch=0.0141]Epoch 253: Train Loss = 0.014314679428935051\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=317, train_loss_step=0.0122, train_loss_epoch=0.0143]Epoch 254: Train Loss = 0.012174108065664768\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 16.14it/s, v_num=317, train_loss_step=0.0108, train_loss_epoch=0.0122]Epoch 255: Train Loss = 0.010836818255484104\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=317, train_loss_step=0.0143, train_loss_epoch=0.0108]Epoch 256: Train Loss = 0.014261969365179539\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=317, train_loss_step=0.012, train_loss_epoch=0.0143] Epoch 257: Train Loss = 0.011964226141571999\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 13.61it/s, v_num=317, train_loss_step=0.0109, train_loss_epoch=0.012]Epoch 258: Train Loss = 0.010941335931420326\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0109]Epoch 259: Train Loss = 0.012477261014282703\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 13.20it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0125]Epoch 260: Train Loss = 0.011506015434861183\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=317, train_loss_step=0.0118, train_loss_epoch=0.0115]Epoch 261: Train Loss = 0.01176433078944683\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0118]Epoch 262: Train Loss = 0.012472284026443958\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=317, train_loss_step=0.0119, train_loss_epoch=0.0125]Epoch 263: Train Loss = 0.011869490146636963\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s, v_num=317, train_loss_step=0.0111, train_loss_epoch=0.0119]Epoch 264: Train Loss = 0.011136196553707123\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=317, train_loss_step=0.0138, train_loss_epoch=0.0111]Epoch 265: Train Loss = 0.013751596212387085\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=317, train_loss_step=0.0135, train_loss_epoch=0.0138]Epoch 266: Train Loss = 0.013542522676289082\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=317, train_loss_step=0.0103, train_loss_epoch=0.0135]Epoch 267: Train Loss = 0.010333443060517311\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=317, train_loss_step=0.0116, train_loss_epoch=0.0103]Epoch 268: Train Loss = 0.011633513495326042\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=317, train_loss_step=0.0117, train_loss_epoch=0.0116]Epoch 269: Train Loss = 0.01166793517768383\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.0117]Epoch 270: Train Loss = 0.013254364021122456\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.0133]Epoch 271: Train Loss = 0.013347456231713295\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 11.06it/s, v_num=317, train_loss_step=0.0134, train_loss_epoch=0.0133]Epoch 272: Train Loss = 0.013384782709181309\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=317, train_loss_step=0.0147, train_loss_epoch=0.0134]Epoch 273: Train Loss = 0.014700008556246758\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=317, train_loss_step=0.0105, train_loss_epoch=0.0147]Epoch 274: Train Loss = 0.010462586767971516\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=317, train_loss_step=0.00966, train_loss_epoch=0.0105]Epoch 275: Train Loss = 0.009656136855483055\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 13.77it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.00966] Epoch 276: Train Loss = 0.012476500123739243\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=317, train_loss_step=0.0104, train_loss_epoch=0.0125] Epoch 277: Train Loss = 0.010380378924310207\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=317, train_loss_step=0.0118, train_loss_epoch=0.0104]Epoch 278: Train Loss = 0.011759632267057896\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.0118]Epoch 279: Train Loss = 0.013319476507604122\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=317, train_loss_step=0.0118, train_loss_epoch=0.0133]Epoch 280: Train Loss = 0.011849337257444859\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s, v_num=317, train_loss_step=0.0119, train_loss_epoch=0.0118]Epoch 281: Train Loss = 0.011878018267452717\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0119]Epoch 282: Train Loss = 0.011537066660821438\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, v_num=317, train_loss_step=0.00951, train_loss_epoch=0.0115]Epoch 283: Train Loss = 0.00951172225177288\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=317, train_loss_step=0.014, train_loss_epoch=0.00951]  Epoch 284: Train Loss = 0.014034313149750233\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=317, train_loss_step=0.0113, train_loss_epoch=0.014] Epoch 285: Train Loss = 0.011312312446534634\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=317, train_loss_step=0.014, train_loss_epoch=0.0113] Epoch 286: Train Loss = 0.013972221873700619\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=317, train_loss_step=0.00973, train_loss_epoch=0.014]Epoch 287: Train Loss = 0.009730802848935127\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.00973] Epoch 288: Train Loss = 0.012485268525779247\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=317, train_loss_step=0.0103, train_loss_epoch=0.0125] Epoch 289: Train Loss = 0.010315054096281528\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0103]Epoch 290: Train Loss = 0.011533926241099834\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=317, train_loss_step=0.013, train_loss_epoch=0.0115] Epoch 291: Train Loss = 0.01297178864479065\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=317, train_loss_step=0.0139, train_loss_epoch=0.013]Epoch 292: Train Loss = 0.013901077210903168\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=317, train_loss_step=0.0222, train_loss_epoch=0.0139]Epoch 293: Train Loss = 0.022236792370676994\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 14.17it/s, v_num=317, train_loss_step=0.0139, train_loss_epoch=0.0222]Epoch 294: Train Loss = 0.013883049599826336\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=317, train_loss_step=0.0164, train_loss_epoch=0.0139]Epoch 295: Train Loss = 0.016403283923864365\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=317, train_loss_step=0.010, train_loss_epoch=0.0164] Epoch 296: Train Loss = 0.01004668977111578\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=317, train_loss_step=0.0109, train_loss_epoch=0.010]Epoch 297: Train Loss = 0.010923580266535282\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=317, train_loss_step=0.0142, train_loss_epoch=0.0109]Epoch 298: Train Loss = 0.014243027195334435\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=317, train_loss_step=0.0116, train_loss_epoch=0.0142]Epoch 299: Train Loss = 0.011594452895224094\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s, v_num=317, train_loss_step=0.0164, train_loss_epoch=0.0116]Epoch 300: Train Loss = 0.01642851158976555\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0164]Epoch 301: Train Loss = 0.012479598633944988\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=317, train_loss_step=0.015, train_loss_epoch=0.0125] Epoch 302: Train Loss = 0.015033967792987823\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 14.17it/s, v_num=317, train_loss_step=0.0158, train_loss_epoch=0.015]Epoch 303: Train Loss = 0.015841498970985413\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=317, train_loss_step=0.0129, train_loss_epoch=0.0158]Epoch 304: Train Loss = 0.012925214134156704\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=317, train_loss_step=0.0114, train_loss_epoch=0.0129]Epoch 305: Train Loss = 0.011419795453548431\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 16.04it/s, v_num=317, train_loss_step=0.00932, train_loss_epoch=0.0114]Epoch 306: Train Loss = 0.00932292826473713\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=317, train_loss_step=0.0109, train_loss_epoch=0.00932] Epoch 307: Train Loss = 0.01093348115682602\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, v_num=317, train_loss_step=0.0116, train_loss_epoch=0.0109] Epoch 308: Train Loss = 0.011556259356439114\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, v_num=317, train_loss_step=0.0154, train_loss_epoch=0.0116]Epoch 309: Train Loss = 0.015442258678376675\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=317, train_loss_step=0.0122, train_loss_epoch=0.0154]Epoch 310: Train Loss = 0.012174250558018684\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 13.96it/s, v_num=317, train_loss_step=0.00944, train_loss_epoch=0.0122]Epoch 311: Train Loss = 0.00943546462804079\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=317, train_loss_step=0.0116, train_loss_epoch=0.00944] Epoch 312: Train Loss = 0.011637081392109394\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 14.13it/s, v_num=317, train_loss_step=0.0106, train_loss_epoch=0.0116] Epoch 313: Train Loss = 0.010564479045569897\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0106]Epoch 314: Train Loss = 0.011545978486537933\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=317, train_loss_step=0.011, train_loss_epoch=0.0115] Epoch 315: Train Loss = 0.0109622273594141\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=317, train_loss_step=0.00914, train_loss_epoch=0.011]Epoch 316: Train Loss = 0.00913503859192133\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s, v_num=317, train_loss_step=0.00951, train_loss_epoch=0.00914]Epoch 317: Train Loss = 0.009508498013019562\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=317, train_loss_step=0.0123, train_loss_epoch=0.00951] Epoch 318: Train Loss = 0.012317896820604801\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=317, train_loss_step=0.0109, train_loss_epoch=0.0123] Epoch 319: Train Loss = 0.010905487462878227\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=317, train_loss_step=0.012, train_loss_epoch=0.0109] Epoch 320: Train Loss = 0.01195335853844881\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=317, train_loss_step=0.0116, train_loss_epoch=0.012]Epoch 321: Train Loss = 0.011578737758100033\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=317, train_loss_step=0.0139, train_loss_epoch=0.0116]Epoch 322: Train Loss = 0.013921058736741543\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=317, train_loss_step=0.0145, train_loss_epoch=0.0139]Epoch 323: Train Loss = 0.01451642531901598\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=317, train_loss_step=0.0106, train_loss_epoch=0.0145]Epoch 324: Train Loss = 0.010612336918711662\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=317, train_loss_step=0.0141, train_loss_epoch=0.0106]Epoch 325: Train Loss = 0.014139286242425442\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s, v_num=317, train_loss_step=0.0135, train_loss_epoch=0.0141]Epoch 326: Train Loss = 0.013480848632752895\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=317, train_loss_step=0.0117, train_loss_epoch=0.0135]Epoch 327: Train Loss = 0.011739992536604404\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=317, train_loss_step=0.0101, train_loss_epoch=0.0117]Epoch 328: Train Loss = 0.010062231682240963\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s, v_num=317, train_loss_step=0.012, train_loss_epoch=0.0101] Epoch 329: Train Loss = 0.011987059377133846\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=317, train_loss_step=0.00935, train_loss_epoch=0.012]Epoch 330: Train Loss = 0.00935079250484705\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=317, train_loss_step=0.0139, train_loss_epoch=0.00935] Epoch 331: Train Loss = 0.013853649608790874\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=317, train_loss_step=0.0173, train_loss_epoch=0.0139] Epoch 332: Train Loss = 0.017300570383667946\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=317, train_loss_step=0.0122, train_loss_epoch=0.0173]Epoch 333: Train Loss = 0.012231962755322456\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, v_num=317, train_loss_step=0.0101, train_loss_epoch=0.0122]Epoch 334: Train Loss = 0.01011086069047451\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=317, train_loss_step=0.0158, train_loss_epoch=0.0101]Epoch 335: Train Loss = 0.01579618640244007\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s, v_num=317, train_loss_step=0.0145, train_loss_epoch=0.0158]Epoch 336: Train Loss = 0.01447247713804245\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 13.29it/s, v_num=317, train_loss_step=0.0111, train_loss_epoch=0.0145]Epoch 337: Train Loss = 0.011123210191726685\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 13.08it/s, v_num=317, train_loss_step=0.0126, train_loss_epoch=0.0111]Epoch 338: Train Loss = 0.012629139237105846\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=317, train_loss_step=0.0188, train_loss_epoch=0.0126]Epoch 339: Train Loss = 0.01878911815583706\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=317, train_loss_step=0.0107, train_loss_epoch=0.0188]Epoch 340: Train Loss = 0.01071211975067854\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=317, train_loss_step=0.0114, train_loss_epoch=0.0107]Epoch 341: Train Loss = 0.011404176242649555\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, v_num=317, train_loss_step=0.0118, train_loss_epoch=0.0114]Epoch 342: Train Loss = 0.011839502491056919\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=317, train_loss_step=0.0171, train_loss_epoch=0.0118]Epoch 343: Train Loss = 0.017067385837435722\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=317, train_loss_step=0.017, train_loss_epoch=0.0171] Epoch 344: Train Loss = 0.016991985961794853\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=317, train_loss_step=0.015, train_loss_epoch=0.017] Epoch 345: Train Loss = 0.015041718259453773\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=317, train_loss_step=0.0123, train_loss_epoch=0.015]Epoch 346: Train Loss = 0.01232506986707449\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s, v_num=317, train_loss_step=0.0127, train_loss_epoch=0.0123]Epoch 347: Train Loss = 0.012686793692409992\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=317, train_loss_step=0.0135, train_loss_epoch=0.0127]Epoch 348: Train Loss = 0.013461635448038578\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=317, train_loss_step=0.0108, train_loss_epoch=0.0135]Epoch 349: Train Loss = 0.010758836753666401\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=317, train_loss_step=0.0134, train_loss_epoch=0.0108]Epoch 350: Train Loss = 0.013411776162683964\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, v_num=317, train_loss_step=0.0163, train_loss_epoch=0.0134]Epoch 351: Train Loss = 0.016266759485006332\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=317, train_loss_step=0.0113, train_loss_epoch=0.0163]Epoch 352: Train Loss = 0.011311263777315617\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=317, train_loss_step=0.0116, train_loss_epoch=0.0113]Epoch 353: Train Loss = 0.011637398973107338\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=317, train_loss_step=0.0127, train_loss_epoch=0.0116]Epoch 354: Train Loss = 0.01266986783593893\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.0127]Epoch 355: Train Loss = 0.013325330801308155\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 16.54it/s, v_num=317, train_loss_step=0.0122, train_loss_epoch=0.0133]Epoch 356: Train Loss = 0.012217127718031406\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=317, train_loss_step=0.0153, train_loss_epoch=0.0122]Epoch 357: Train Loss = 0.015306651592254639\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 16.45it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.0153]Epoch 358: Train Loss = 0.013274969533085823\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 16.61it/s, v_num=317, train_loss_step=0.0143, train_loss_epoch=0.0133]Epoch 359: Train Loss = 0.014320326037704945\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, v_num=317, train_loss_step=0.0121, train_loss_epoch=0.0143]Epoch 360: Train Loss = 0.01211798470467329\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, v_num=317, train_loss_step=0.0106, train_loss_epoch=0.0121]Epoch 361: Train Loss = 0.010625741444528103\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=317, train_loss_step=0.00987, train_loss_epoch=0.0106]Epoch 362: Train Loss = 0.009870849549770355\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=317, train_loss_step=0.0127, train_loss_epoch=0.00987] Epoch 363: Train Loss = 0.012737829238176346\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=317, train_loss_step=0.010, train_loss_epoch=0.0127]  Epoch 364: Train Loss = 0.010009991936385632\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.010]Epoch 365: Train Loss = 0.011472337879240513\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 13.30it/s, v_num=317, train_loss_step=0.0126, train_loss_epoch=0.0115]Epoch 366: Train Loss = 0.01257274392992258\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s, v_num=317, train_loss_step=0.0153, train_loss_epoch=0.0126]Epoch 367: Train Loss = 0.015336091630160809\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, v_num=317, train_loss_step=0.012, train_loss_epoch=0.0153] Epoch 368: Train Loss = 0.012046058662235737\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.012]Epoch 369: Train Loss = 0.012541324831545353\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=317, train_loss_step=0.0109, train_loss_epoch=0.0125]Epoch 370: Train Loss = 0.0108699481934309\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=317, train_loss_step=0.0147, train_loss_epoch=0.0109]Epoch 371: Train Loss = 0.014716996811330318\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=317, train_loss_step=0.0162, train_loss_epoch=0.0147]Epoch 372: Train Loss = 0.0162319578230381\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0162]Epoch 373: Train Loss = 0.01250118762254715\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 16.28it/s, v_num=317, train_loss_step=0.017, train_loss_epoch=0.0125] Epoch 374: Train Loss = 0.016996188089251518\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s, v_num=317, train_loss_step=0.012, train_loss_epoch=0.017] Epoch 375: Train Loss = 0.011975002475082874\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=317, train_loss_step=0.0117, train_loss_epoch=0.012]Epoch 376: Train Loss = 0.011675317771732807\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s, v_num=317, train_loss_step=0.0105, train_loss_epoch=0.0117]Epoch 377: Train Loss = 0.010502728633582592\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=317, train_loss_step=0.0147, train_loss_epoch=0.0105]Epoch 378: Train Loss = 0.014677437022328377\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0147]Epoch 379: Train Loss = 0.01148679107427597\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0115]Epoch 380: Train Loss = 0.012458160519599915\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=317, train_loss_step=0.00937, train_loss_epoch=0.0125]Epoch 381: Train Loss = 0.009367267601191998\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=317, train_loss_step=0.0121, train_loss_epoch=0.00937] Epoch 382: Train Loss = 0.01210094802081585\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=317, train_loss_step=0.012, train_loss_epoch=0.0121]  Epoch 383: Train Loss = 0.011963265016674995\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=317, train_loss_step=0.0126, train_loss_epoch=0.012]Epoch 384: Train Loss = 0.0125876534730196\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, v_num=317, train_loss_step=0.0102, train_loss_epoch=0.0126]Epoch 385: Train Loss = 0.010218793526291847\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=317, train_loss_step=0.00972, train_loss_epoch=0.0102]Epoch 386: Train Loss = 0.009720117785036564\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s, v_num=317, train_loss_step=0.0126, train_loss_epoch=0.00972] Epoch 387: Train Loss = 0.01263902522623539\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 16.88it/s, v_num=317, train_loss_step=0.0142, train_loss_epoch=0.0126] Epoch 388: Train Loss = 0.014177091419696808\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s, v_num=317, train_loss_step=0.012, train_loss_epoch=0.0142] Epoch 389: Train Loss = 0.011973542161285877\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s, v_num=317, train_loss_step=0.0122, train_loss_epoch=0.012]Epoch 390: Train Loss = 0.012199210934340954\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s, v_num=317, train_loss_step=0.0161, train_loss_epoch=0.0122]Epoch 391: Train Loss = 0.016095314174890518\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0161]Epoch 392: Train Loss = 0.012483986094594002\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s, v_num=317, train_loss_step=0.0104, train_loss_epoch=0.0125]Epoch 393: Train Loss = 0.01043035089969635\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=317, train_loss_step=0.0128, train_loss_epoch=0.0104]Epoch 394: Train Loss = 0.012822017073631287\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=317, train_loss_step=0.0113, train_loss_epoch=0.0128]Epoch 395: Train Loss = 0.011281592771410942\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=317, train_loss_step=0.014, train_loss_epoch=0.0113] Epoch 396: Train Loss = 0.014043405652046204\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=317, train_loss_step=0.0168, train_loss_epoch=0.014]Epoch 397: Train Loss = 0.01679164543747902\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 17.18it/s, v_num=317, train_loss_step=0.015, train_loss_epoch=0.0168] Epoch 398: Train Loss = 0.014973227865993977\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=317, train_loss_step=0.0141, train_loss_epoch=0.015]Epoch 399: Train Loss = 0.014125673100352287\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 16.74it/s, v_num=317, train_loss_step=0.014, train_loss_epoch=0.0141] Epoch 400: Train Loss = 0.01404210738837719\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, v_num=317, train_loss_step=0.0146, train_loss_epoch=0.014]Epoch 401: Train Loss = 0.014589495025575161\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=317, train_loss_step=0.0142, train_loss_epoch=0.0146]Epoch 402: Train Loss = 0.014161068014800549\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 16.61it/s, v_num=317, train_loss_step=0.012, train_loss_epoch=0.0142] Epoch 403: Train Loss = 0.011971818283200264\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 16.50it/s, v_num=317, train_loss_step=0.0119, train_loss_epoch=0.012]Epoch 404: Train Loss = 0.011856748722493649\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, v_num=317, train_loss_step=0.0126, train_loss_epoch=0.0119]Epoch 405: Train Loss = 0.012565701268613338\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s, v_num=317, train_loss_step=0.0123, train_loss_epoch=0.0126]Epoch 406: Train Loss = 0.01231085229665041\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=317, train_loss_step=0.0117, train_loss_epoch=0.0123]Epoch 407: Train Loss = 0.011683429591357708\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=317, train_loss_step=0.0173, train_loss_epoch=0.0117]Epoch 408: Train Loss = 0.017296267673373222\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=317, train_loss_step=0.0107, train_loss_epoch=0.0173]Epoch 409: Train Loss = 0.01074168924242258\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=317, train_loss_step=0.013, train_loss_epoch=0.0107] Epoch 410: Train Loss = 0.012960033491253853\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=317, train_loss_step=0.0117, train_loss_epoch=0.013]Epoch 411: Train Loss = 0.011714142747223377\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0117]Epoch 412: Train Loss = 0.011467001400887966\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=317, train_loss_step=0.0112, train_loss_epoch=0.0115]Epoch 413: Train Loss = 0.011235890910029411\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=317, train_loss_step=0.0171, train_loss_epoch=0.0112]Epoch 414: Train Loss = 0.01710231974720955\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=317, train_loss_step=0.00895, train_loss_epoch=0.0171]Epoch 415: Train Loss = 0.008953826501965523\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=317, train_loss_step=0.010, train_loss_epoch=0.00895]  Epoch 416: Train Loss = 0.010043402202427387\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=317, train_loss_step=0.0107, train_loss_epoch=0.010] Epoch 417: Train Loss = 0.010674518533051014\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=317, train_loss_step=0.0121, train_loss_epoch=0.0107]Epoch 418: Train Loss = 0.012129639275372028\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=317, train_loss_step=0.0123, train_loss_epoch=0.0121]Epoch 419: Train Loss = 0.012324553914368153\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=317, train_loss_step=0.0119, train_loss_epoch=0.0123]Epoch 420: Train Loss = 0.011919713579118252\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=317, train_loss_step=0.0132, train_loss_epoch=0.0119]Epoch 421: Train Loss = 0.013222711160779\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=317, train_loss_step=0.0105, train_loss_epoch=0.0132]Epoch 422: Train Loss = 0.01048927754163742\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0105]Epoch 423: Train Loss = 0.01150547992438078\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=317, train_loss_step=0.0152, train_loss_epoch=0.0115]Epoch 424: Train Loss = 0.015199226327240467\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, v_num=317, train_loss_step=0.0174, train_loss_epoch=0.0152]Epoch 425: Train Loss = 0.01742621324956417\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 16.61it/s, v_num=317, train_loss_step=0.0133, train_loss_epoch=0.0174]Epoch 426: Train Loss = 0.013256440870463848\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, v_num=317, train_loss_step=0.00935, train_loss_epoch=0.0133]Epoch 427: Train Loss = 0.009348087012767792\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=317, train_loss_step=0.0114, train_loss_epoch=0.00935] Epoch 428: Train Loss = 0.011436715722084045\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=317, train_loss_step=0.0163, train_loss_epoch=0.0114] Epoch 429: Train Loss = 0.016286805272102356\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s, v_num=317, train_loss_step=0.011, train_loss_epoch=0.0163] Epoch 430: Train Loss = 0.010964424349367619\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=317, train_loss_step=0.016, train_loss_epoch=0.011] Epoch 431: Train Loss = 0.015988389030098915\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=317, train_loss_step=0.0113, train_loss_epoch=0.016]Epoch 432: Train Loss = 0.011305590160191059\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=317, train_loss_step=0.010, train_loss_epoch=0.0113] Epoch 433: Train Loss = 0.009995522908866405\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 16.56it/s, v_num=317, train_loss_step=0.0138, train_loss_epoch=0.010]Epoch 434: Train Loss = 0.013763440772891045\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 16.70it/s, v_num=317, train_loss_step=0.0124, train_loss_epoch=0.0138]Epoch 435: Train Loss = 0.012431119568645954\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=317, train_loss_step=0.0129, train_loss_epoch=0.0124]Epoch 436: Train Loss = 0.012946984730660915\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s, v_num=317, train_loss_step=0.0137, train_loss_epoch=0.0129]Epoch 437: Train Loss = 0.01365460641682148\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s, v_num=317, train_loss_step=0.0107, train_loss_epoch=0.0137]Epoch 438: Train Loss = 0.010659066960215569\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=317, train_loss_step=0.014, train_loss_epoch=0.0107] Epoch 439: Train Loss = 0.013984382152557373\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s, v_num=317, train_loss_step=0.0113, train_loss_epoch=0.014]Epoch 440: Train Loss = 0.011296642944216728\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 13.30it/s, v_num=317, train_loss_step=0.0162, train_loss_epoch=0.0113]Epoch 441: Train Loss = 0.016219191253185272\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=317, train_loss_step=0.0113, train_loss_epoch=0.0162]Epoch 442: Train Loss = 0.011283664032816887\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, v_num=317, train_loss_step=0.0151, train_loss_epoch=0.0113]Epoch 443: Train Loss = 0.01505084428936243\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=317, train_loss_step=0.0106, train_loss_epoch=0.0151]Epoch 444: Train Loss = 0.010633249767124653\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=317, train_loss_step=0.0124, train_loss_epoch=0.0106]Epoch 445: Train Loss = 0.012439354322850704\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 12.79it/s, v_num=317, train_loss_step=0.0146, train_loss_epoch=0.0124]Epoch 446: Train Loss = 0.014633242040872574\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=317, train_loss_step=0.0119, train_loss_epoch=0.0146]Epoch 447: Train Loss = 0.011864163912832737\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s, v_num=317, train_loss_step=0.0153, train_loss_epoch=0.0119]Epoch 448: Train Loss = 0.015275244601070881\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 16.76it/s, v_num=317, train_loss_step=0.0137, train_loss_epoch=0.0153]Epoch 449: Train Loss = 0.013682209886610508\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 16.70it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0137]Epoch 450: Train Loss = 0.011518104001879692\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 16.90it/s, v_num=317, train_loss_step=0.0135, train_loss_epoch=0.0115]Epoch 451: Train Loss = 0.013491608202457428\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s, v_num=317, train_loss_step=0.0138, train_loss_epoch=0.0135]Epoch 452: Train Loss = 0.013824916444718838\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=317, train_loss_step=0.0112, train_loss_epoch=0.0138]Epoch 453: Train Loss = 0.011236156336963177\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s, v_num=317, train_loss_step=0.0131, train_loss_epoch=0.0112]Epoch 454: Train Loss = 0.013099723495543003\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s, v_num=317, train_loss_step=0.0118, train_loss_epoch=0.0131]Epoch 455: Train Loss = 0.01178255770355463\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 16.88it/s, v_num=317, train_loss_step=0.0118, train_loss_epoch=0.0118]Epoch 456: Train Loss = 0.01183710154145956\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 16.47it/s, v_num=317, train_loss_step=0.0131, train_loss_epoch=0.0118]Epoch 457: Train Loss = 0.013069534674286842\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=317, train_loss_step=0.0118, train_loss_epoch=0.0131]Epoch 458: Train Loss = 0.01183999516069889\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=317, train_loss_step=0.0112, train_loss_epoch=0.0118]Epoch 459: Train Loss = 0.011198025196790695\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s, v_num=317, train_loss_step=0.0184, train_loss_epoch=0.0112]Epoch 460: Train Loss = 0.018399449065327644\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 16.74it/s, v_num=317, train_loss_step=0.0147, train_loss_epoch=0.0184]Epoch 461: Train Loss = 0.01469088438898325\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=317, train_loss_step=0.0131, train_loss_epoch=0.0147]Epoch 462: Train Loss = 0.013107028789818287\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s, v_num=317, train_loss_step=0.0149, train_loss_epoch=0.0131]Epoch 463: Train Loss = 0.01492277067154646\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=317, train_loss_step=0.0136, train_loss_epoch=0.0149]Epoch 464: Train Loss = 0.013594316318631172\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 17.01it/s, v_num=317, train_loss_step=0.0151, train_loss_epoch=0.0136]Epoch 465: Train Loss = 0.01513316947966814\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 16.90it/s, v_num=317, train_loss_step=0.0119, train_loss_epoch=0.0151]Epoch 466: Train Loss = 0.011868453584611416\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 17.34it/s, v_num=317, train_loss_step=0.0116, train_loss_epoch=0.0119]Epoch 467: Train Loss = 0.011582614853978157\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 13.40it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0116]Epoch 468: Train Loss = 0.011489094235002995\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s, v_num=317, train_loss_step=0.00984, train_loss_epoch=0.0115]Epoch 469: Train Loss = 0.009843590669333935\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, v_num=317, train_loss_step=0.0132, train_loss_epoch=0.00984] Epoch 470: Train Loss = 0.013167585246264935\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 11.57it/s, v_num=317, train_loss_step=0.0094, train_loss_epoch=0.0132] Epoch 471: Train Loss = 0.00939881056547165\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=317, train_loss_step=0.0135, train_loss_epoch=0.0094]Epoch 472: Train Loss = 0.013453868217766285\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=317, train_loss_step=0.0125, train_loss_epoch=0.0135]Epoch 473: Train Loss = 0.01253008283674717\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=317, train_loss_step=0.0148, train_loss_epoch=0.0125]Epoch 474: Train Loss = 0.014762074686586857\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=317, train_loss_step=0.0121, train_loss_epoch=0.0148]Epoch 475: Train Loss = 0.012104817666113377\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=317, train_loss_step=0.0123, train_loss_epoch=0.0121]Epoch 476: Train Loss = 0.012263735756278038\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=317, train_loss_step=0.00883, train_loss_epoch=0.0123]Epoch 477: Train Loss = 0.008829092606902122\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s, v_num=317, train_loss_step=0.0136, train_loss_epoch=0.00883] Epoch 478: Train Loss = 0.013554313220083714\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=317, train_loss_step=0.0164, train_loss_epoch=0.0136] Epoch 479: Train Loss = 0.016383029520511627\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s, v_num=317, train_loss_step=0.0227, train_loss_epoch=0.0164]Epoch 480: Train Loss = 0.02269482985138893\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=317, train_loss_step=0.0147, train_loss_epoch=0.0227]Epoch 481: Train Loss = 0.014746560715138912\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=317, train_loss_step=0.0157, train_loss_epoch=0.0147]Epoch 482: Train Loss = 0.015701720491051674\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=317, train_loss_step=0.0163, train_loss_epoch=0.0157]Epoch 483: Train Loss = 0.016329798847436905\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=317, train_loss_step=0.0115, train_loss_epoch=0.0163]Epoch 484: Train Loss = 0.01152808964252472\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 16.80it/s, v_num=317, train_loss_step=0.0124, train_loss_epoch=0.0115]Epoch 485: Train Loss = 0.012425454333424568\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 16.57it/s, v_num=317, train_loss_step=0.011, train_loss_epoch=0.0124] Epoch 486: Train Loss = 0.010990837588906288\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=317, train_loss_step=0.0151, train_loss_epoch=0.011]Epoch 487: Train Loss = 0.015052304603159428\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 16.47it/s, v_num=317, train_loss_step=0.0162, train_loss_epoch=0.0151]Epoch 488: Train Loss = 0.016205985099077225\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=317, train_loss_step=0.0132, train_loss_epoch=0.0162]Epoch 489: Train Loss = 0.013185788877308369\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, v_num=317, train_loss_step=0.00992, train_loss_epoch=0.0132]Epoch 490: Train Loss = 0.009916136041283607\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=317, train_loss_step=0.016, train_loss_epoch=0.00992]  Epoch 491: Train Loss = 0.015950415283441544\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=317, train_loss_step=0.0136, train_loss_epoch=0.016] Epoch 492: Train Loss = 0.013643871061503887\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, v_num=317, train_loss_step=0.0162, train_loss_epoch=0.0136]Epoch 493: Train Loss = 0.01617305539548397\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, v_num=317, train_loss_step=0.0135, train_loss_epoch=0.0162]Epoch 494: Train Loss = 0.013538852334022522\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s, v_num=317, train_loss_step=0.016, train_loss_epoch=0.0135] Epoch 495: Train Loss = 0.01603197678923607\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 13.44it/s, v_num=317, train_loss_step=0.0137, train_loss_epoch=0.016]Epoch 496: Train Loss = 0.01370332296937704\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=317, train_loss_step=0.0119, train_loss_epoch=0.0137]Epoch 497: Train Loss = 0.011940591968595982\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s, v_num=317, train_loss_step=0.0142, train_loss_epoch=0.0119]Epoch 498: Train Loss = 0.014190763235092163\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=317, train_loss_step=0.0187, train_loss_epoch=0.0142]Epoch 499: Train Loss = 0.018719512969255447\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=317, train_loss_step=0.0187, train_loss_epoch=0.0187]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=317, train_loss_step=0.0187, train_loss_epoch=0.0187]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 8: from 2010-06-30 00:00:00 to 2022-09-07 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=319, train_loss_step=0.0231]Epoch 0: Train Loss = 0.023141922429203987\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=319, train_loss_step=0.0514, train_loss_epoch=0.0231]Epoch 1: Train Loss = 0.05143061652779579\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=319, train_loss_step=0.0257, train_loss_epoch=0.0514]Epoch 2: Train Loss = 0.025692662224173546\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=319, train_loss_step=0.0233, train_loss_epoch=0.0257]Epoch 3: Train Loss = 0.023287776857614517\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=319, train_loss_step=0.0237, train_loss_epoch=0.0233]Epoch 4: Train Loss = 0.02374337799847126\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, v_num=319, train_loss_step=0.0179, train_loss_epoch=0.0237]Epoch 5: Train Loss = 0.01785067282617092\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=319, train_loss_step=0.0189, train_loss_epoch=0.0179]Epoch 6: Train Loss = 0.018934134393930435\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=319, train_loss_step=0.019, train_loss_epoch=0.0189] Epoch 7: Train Loss = 0.01895923912525177\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 16.62it/s, v_num=319, train_loss_step=0.0178, train_loss_epoch=0.019]Epoch 8: Train Loss = 0.01783018745481968\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=319, train_loss_step=0.0186, train_loss_epoch=0.0178]Epoch 9: Train Loss = 0.01855701394379139\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=319, train_loss_step=0.0143, train_loss_epoch=0.0186]Epoch 10: Train Loss = 0.01428880076855421\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=319, train_loss_step=0.0181, train_loss_epoch=0.0143]Epoch 11: Train Loss = 0.01813124679028988\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=319, train_loss_step=0.0187, train_loss_epoch=0.0181]Epoch 12: Train Loss = 0.01873803697526455\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=319, train_loss_step=0.0151, train_loss_epoch=0.0187]Epoch 13: Train Loss = 0.01512250304222107\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=319, train_loss_step=0.0182, train_loss_epoch=0.0151]Epoch 14: Train Loss = 0.018185360357165337\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 17.38it/s, v_num=319, train_loss_step=0.0197, train_loss_epoch=0.0182]Epoch 15: Train Loss = 0.019724223762750626\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 17.02it/s, v_num=319, train_loss_step=0.0198, train_loss_epoch=0.0197]Epoch 16: Train Loss = 0.019784050062298775\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 13.32it/s, v_num=319, train_loss_step=0.0145, train_loss_epoch=0.0198]Epoch 17: Train Loss = 0.014506379142403603\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=319, train_loss_step=0.018, train_loss_epoch=0.0145] Epoch 18: Train Loss = 0.01796145737171173\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=319, train_loss_step=0.0188, train_loss_epoch=0.018]Epoch 19: Train Loss = 0.01877322793006897\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 17.39it/s, v_num=319, train_loss_step=0.0187, train_loss_epoch=0.0188]Epoch 20: Train Loss = 0.01873578317463398\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=319, train_loss_step=0.0159, train_loss_epoch=0.0187]Epoch 21: Train Loss = 0.015927232801914215\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=319, train_loss_step=0.0237, train_loss_epoch=0.0159]Epoch 22: Train Loss = 0.023709846660494804\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=319, train_loss_step=0.0188, train_loss_epoch=0.0237]Epoch 23: Train Loss = 0.01877095364034176\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=319, train_loss_step=0.0175, train_loss_epoch=0.0188]Epoch 24: Train Loss = 0.01746412366628647\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=319, train_loss_step=0.016, train_loss_epoch=0.0175] Epoch 25: Train Loss = 0.016015568748116493\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=319, train_loss_step=0.0185, train_loss_epoch=0.016]Epoch 26: Train Loss = 0.018540844321250916\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, v_num=319, train_loss_step=0.0174, train_loss_epoch=0.0185]Epoch 27: Train Loss = 0.01736292615532875\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=319, train_loss_step=0.019, train_loss_epoch=0.0174] Epoch 28: Train Loss = 0.018957162275910378\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s, v_num=319, train_loss_step=0.0188, train_loss_epoch=0.019]Epoch 29: Train Loss = 0.018846780061721802\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 13.34it/s, v_num=319, train_loss_step=0.018, train_loss_epoch=0.0188] Epoch 30: Train Loss = 0.017979538068175316\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 11.37it/s, v_num=319, train_loss_step=0.0164, train_loss_epoch=0.018]Epoch 31: Train Loss = 0.016374289989471436\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s, v_num=319, train_loss_step=0.0161, train_loss_epoch=0.0164]Epoch 32: Train Loss = 0.016051076352596283\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s, v_num=319, train_loss_step=0.014, train_loss_epoch=0.0161] Epoch 33: Train Loss = 0.014047913253307343\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, v_num=319, train_loss_step=0.0142, train_loss_epoch=0.014]Epoch 34: Train Loss = 0.014186478219926357\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s, v_num=319, train_loss_step=0.0136, train_loss_epoch=0.0142]Epoch 35: Train Loss = 0.013635926879942417\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, v_num=319, train_loss_step=0.0194, train_loss_epoch=0.0136]Epoch 36: Train Loss = 0.019425081089138985\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=319, train_loss_step=0.0126, train_loss_epoch=0.0194]Epoch 37: Train Loss = 0.01264191884547472\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 16.58it/s, v_num=319, train_loss_step=0.014, train_loss_epoch=0.0126] Epoch 38: Train Loss = 0.014020774513483047\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=319, train_loss_step=0.020, train_loss_epoch=0.014] Epoch 39: Train Loss = 0.019952740520238876\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, v_num=319, train_loss_step=0.0136, train_loss_epoch=0.020]Epoch 40: Train Loss = 0.013561790809035301\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=319, train_loss_step=0.015, train_loss_epoch=0.0136] Epoch 41: Train Loss = 0.014979412779211998\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=319, train_loss_step=0.0145, train_loss_epoch=0.015]Epoch 42: Train Loss = 0.014465133659541607\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, v_num=319, train_loss_step=0.0193, train_loss_epoch=0.0145]Epoch 43: Train Loss = 0.019282612949609756\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 13.21it/s, v_num=319, train_loss_step=0.0131, train_loss_epoch=0.0193]Epoch 44: Train Loss = 0.013060127384960651\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 13.21it/s, v_num=319, train_loss_step=0.0163, train_loss_epoch=0.0131]Epoch 45: Train Loss = 0.016305455937981606\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=319, train_loss_step=0.0143, train_loss_epoch=0.0163]Epoch 46: Train Loss = 0.01429195050150156\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 17.02it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.0143] Epoch 47: Train Loss = 0.012959781102836132\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=319, train_loss_step=0.0141, train_loss_epoch=0.013]Epoch 48: Train Loss = 0.014086341485381126\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 17.23it/s, v_num=319, train_loss_step=0.0128, train_loss_epoch=0.0141]Epoch 49: Train Loss = 0.012780996039509773\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 16.82it/s, v_num=319, train_loss_step=0.0188, train_loss_epoch=0.0128]Epoch 50: Train Loss = 0.018750905990600586\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 17.61it/s, v_num=319, train_loss_step=0.0165, train_loss_epoch=0.0188]Epoch 51: Train Loss = 0.016459180042147636\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 17.55it/s, v_num=319, train_loss_step=0.0189, train_loss_epoch=0.0165]Epoch 52: Train Loss = 0.01892593875527382\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 17.59it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0189]Epoch 53: Train Loss = 0.01155017502605915\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 14.11it/s, v_num=319, train_loss_step=0.0124, train_loss_epoch=0.0116]Epoch 54: Train Loss = 0.012430280447006226\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 17.12it/s, v_num=319, train_loss_step=0.0113, train_loss_epoch=0.0124]Epoch 55: Train Loss = 0.01126941479742527\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 17.49it/s, v_num=319, train_loss_step=0.0123, train_loss_epoch=0.0113]Epoch 56: Train Loss = 0.012305433861911297\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 17.34it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0123]Epoch 57: Train Loss = 0.011618444696068764\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 17.27it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0116]Epoch 58: Train Loss = 0.01206065621227026\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 17.71it/s, v_num=319, train_loss_step=0.0108, train_loss_epoch=0.0121]Epoch 59: Train Loss = 0.01079189870506525\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=319, train_loss_step=0.0113, train_loss_epoch=0.0108]Epoch 60: Train Loss = 0.011276009492576122\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 17.61it/s, v_num=319, train_loss_step=0.0124, train_loss_epoch=0.0113]Epoch 61: Train Loss = 0.012434855103492737\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 17.29it/s, v_num=319, train_loss_step=0.0144, train_loss_epoch=0.0124]Epoch 62: Train Loss = 0.014396175742149353\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, v_num=319, train_loss_step=0.00952, train_loss_epoch=0.0144]Epoch 63: Train Loss = 0.009524681605398655\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 16.79it/s, v_num=319, train_loss_step=0.0142, train_loss_epoch=0.00952] Epoch 64: Train Loss = 0.01418509054929018\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=319, train_loss_step=0.0141, train_loss_epoch=0.0142] Epoch 65: Train Loss = 0.014069654047489166\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0141]Epoch 66: Train Loss = 0.011561034247279167\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 17.64it/s, v_num=319, train_loss_step=0.0146, train_loss_epoch=0.0116]Epoch 67: Train Loss = 0.014553375542163849\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 17.01it/s, v_num=319, train_loss_step=0.0122, train_loss_epoch=0.0146]Epoch 68: Train Loss = 0.012221043929457664\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s, v_num=319, train_loss_step=0.0106, train_loss_epoch=0.0122]Epoch 69: Train Loss = 0.010633675381541252\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 16.50it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.0106] Epoch 70: Train Loss = 0.013021989725530148\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, v_num=319, train_loss_step=0.0123, train_loss_epoch=0.013]Epoch 71: Train Loss = 0.012280634604394436\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 17.01it/s, v_num=319, train_loss_step=0.0155, train_loss_epoch=0.0123]Epoch 72: Train Loss = 0.015483730472624302\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=319, train_loss_step=0.0225, train_loss_epoch=0.0155]Epoch 73: Train Loss = 0.022547414526343346\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=319, train_loss_step=0.0114, train_loss_epoch=0.0225]Epoch 74: Train Loss = 0.011353664100170135\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 16.61it/s, v_num=319, train_loss_step=0.0131, train_loss_epoch=0.0114]Epoch 75: Train Loss = 0.013128845952451229\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=319, train_loss_step=0.0147, train_loss_epoch=0.0131]Epoch 76: Train Loss = 0.014663560315966606\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=319, train_loss_step=0.0104, train_loss_epoch=0.0147]Epoch 77: Train Loss = 0.01042125653475523\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 16.06it/s, v_num=319, train_loss_step=0.0131, train_loss_epoch=0.0104]Epoch 78: Train Loss = 0.013098268769681454\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s, v_num=319, train_loss_step=0.0109, train_loss_epoch=0.0131]Epoch 79: Train Loss = 0.010925797745585442\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 16.56it/s, v_num=319, train_loss_step=0.0134, train_loss_epoch=0.0109]Epoch 80: Train Loss = 0.01338338665664196\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 17.01it/s, v_num=319, train_loss_step=0.0125, train_loss_epoch=0.0134]Epoch 81: Train Loss = 0.012542793527245522\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=319, train_loss_step=0.0136, train_loss_epoch=0.0125]Epoch 82: Train Loss = 0.013573751784861088\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 17.10it/s, v_num=319, train_loss_step=0.00994, train_loss_epoch=0.0136]Epoch 83: Train Loss = 0.009943029843270779\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 17.69it/s, v_num=319, train_loss_step=0.0141, train_loss_epoch=0.00994] Epoch 84: Train Loss = 0.014107843860983849\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 17.21it/s, v_num=319, train_loss_step=0.0194, train_loss_epoch=0.0141] Epoch 85: Train Loss = 0.01943344436585903\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 17.08it/s, v_num=319, train_loss_step=0.0127, train_loss_epoch=0.0194]Epoch 86: Train Loss = 0.012727280147373676\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 17.35it/s, v_num=319, train_loss_step=0.0178, train_loss_epoch=0.0127]Epoch 87: Train Loss = 0.017802879214286804\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 16.90it/s, v_num=319, train_loss_step=0.0126, train_loss_epoch=0.0178]Epoch 88: Train Loss = 0.012617026455700397\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=319, train_loss_step=0.0136, train_loss_epoch=0.0126]Epoch 89: Train Loss = 0.0135768698528409\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 16.72it/s, v_num=319, train_loss_step=0.0197, train_loss_epoch=0.0136]Epoch 90: Train Loss = 0.019660551100969315\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=319, train_loss_step=0.0112, train_loss_epoch=0.0197]Epoch 91: Train Loss = 0.011194885708391666\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 16.50it/s, v_num=319, train_loss_step=0.0146, train_loss_epoch=0.0112]Epoch 92: Train Loss = 0.01457016821950674\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=319, train_loss_step=0.0131, train_loss_epoch=0.0146]Epoch 93: Train Loss = 0.01314590871334076\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=319, train_loss_step=0.0162, train_loss_epoch=0.0131]Epoch 94: Train Loss = 0.016155481338500977\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 17.32it/s, v_num=319, train_loss_step=0.0168, train_loss_epoch=0.0162]Epoch 95: Train Loss = 0.01678711734712124\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, v_num=319, train_loss_step=0.0141, train_loss_epoch=0.0168]Epoch 96: Train Loss = 0.0141385393217206\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 16.94it/s, v_num=319, train_loss_step=0.0143, train_loss_epoch=0.0141]Epoch 97: Train Loss = 0.014332511462271214\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=319, train_loss_step=0.0179, train_loss_epoch=0.0143]Epoch 98: Train Loss = 0.017906440421938896\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=319, train_loss_step=0.0143, train_loss_epoch=0.0179]Epoch 99: Train Loss = 0.014288507401943207\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s, v_num=319, train_loss_step=0.0182, train_loss_epoch=0.0143]Epoch 100: Train Loss = 0.018216239288449287\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=319, train_loss_step=0.0152, train_loss_epoch=0.0182]Epoch 101: Train Loss = 0.015210963785648346\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 16.26it/s, v_num=319, train_loss_step=0.0157, train_loss_epoch=0.0152]Epoch 102: Train Loss = 0.015720639377832413\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=319, train_loss_step=0.00955, train_loss_epoch=0.0157]Epoch 103: Train Loss = 0.009552554227411747\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s, v_num=319, train_loss_step=0.0135, train_loss_epoch=0.00955] Epoch 104: Train Loss = 0.01352480798959732\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s, v_num=319, train_loss_step=0.0142, train_loss_epoch=0.0135] Epoch 105: Train Loss = 0.014173099771142006\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s, v_num=319, train_loss_step=0.0122, train_loss_epoch=0.0142]Epoch 106: Train Loss = 0.01215402316302061\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s, v_num=319, train_loss_step=0.0124, train_loss_epoch=0.0122]Epoch 107: Train Loss = 0.012424811720848083\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.0124]Epoch 108: Train Loss = 0.01287889201194048\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s, v_num=319, train_loss_step=0.0115, train_loss_epoch=0.0129]Epoch 109: Train Loss = 0.011473545804619789\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 17.34it/s, v_num=319, train_loss_step=0.0135, train_loss_epoch=0.0115]Epoch 110: Train Loss = 0.013506686314940453\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 17.88it/s, v_num=319, train_loss_step=0.0183, train_loss_epoch=0.0135]Epoch 111: Train Loss = 0.018268266692757607\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 17.33it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0183]Epoch 112: Train Loss = 0.01155475527048111\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.0116] Epoch 113: Train Loss = 0.01302243210375309\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s, v_num=319, train_loss_step=0.0125, train_loss_epoch=0.013]Epoch 114: Train Loss = 0.01250679325312376\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 16.73it/s, v_num=319, train_loss_step=0.0105, train_loss_epoch=0.0125]Epoch 115: Train Loss = 0.010456576943397522\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 17.22it/s, v_num=319, train_loss_step=0.0161, train_loss_epoch=0.0105]Epoch 116: Train Loss = 0.016131678596138954\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 17.64it/s, v_num=319, train_loss_step=0.0142, train_loss_epoch=0.0161]Epoch 117: Train Loss = 0.014196814969182014\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=319, train_loss_step=0.0111, train_loss_epoch=0.0142]Epoch 118: Train Loss = 0.011069201864302158\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 16.88it/s, v_num=319, train_loss_step=0.0148, train_loss_epoch=0.0111]Epoch 119: Train Loss = 0.014823509380221367\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 16.14it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.0148]Epoch 120: Train Loss = 0.010732932016253471\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=319, train_loss_step=0.0132, train_loss_epoch=0.0107]Epoch 121: Train Loss = 0.013249101117253304\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0132]Epoch 122: Train Loss = 0.012071867473423481\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=319, train_loss_step=0.0181, train_loss_epoch=0.0121]Epoch 123: Train Loss = 0.018086254596710205\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=319, train_loss_step=0.0109, train_loss_epoch=0.0181]Epoch 124: Train Loss = 0.010883920826017857\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=319, train_loss_step=0.012, train_loss_epoch=0.0109] Epoch 125: Train Loss = 0.01197377871721983\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.012]Epoch 126: Train Loss = 0.012888706289231777\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=319, train_loss_step=0.0164, train_loss_epoch=0.0129]Epoch 127: Train Loss = 0.01637413538992405\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=319, train_loss_step=0.0117, train_loss_epoch=0.0164]Epoch 128: Train Loss = 0.011719970963895321\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.0117]Epoch 129: Train Loss = 0.012911967001855373\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=319, train_loss_step=0.0104, train_loss_epoch=0.0129]Epoch 130: Train Loss = 0.010370403528213501\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=319, train_loss_step=0.0109, train_loss_epoch=0.0104]Epoch 131: Train Loss = 0.010918759740889072\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 12.27it/s, v_num=319, train_loss_step=0.0134, train_loss_epoch=0.0109]Epoch 132: Train Loss = 0.01340327039361\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=319, train_loss_step=0.00931, train_loss_epoch=0.0134]Epoch 133: Train Loss = 0.009308540262281895\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=319, train_loss_step=0.0192, train_loss_epoch=0.00931] Epoch 134: Train Loss = 0.01921117678284645\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=319, train_loss_step=0.0115, train_loss_epoch=0.0192] Epoch 135: Train Loss = 0.011501176282763481\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=319, train_loss_step=0.0144, train_loss_epoch=0.0115]Epoch 136: Train Loss = 0.014361781068146229\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=319, train_loss_step=0.0173, train_loss_epoch=0.0144]Epoch 137: Train Loss = 0.01729474402964115\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s, v_num=319, train_loss_step=0.0214, train_loss_epoch=0.0173]Epoch 138: Train Loss = 0.021407896652817726\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=319, train_loss_step=0.017, train_loss_epoch=0.0214] Epoch 139: Train Loss = 0.016987236216664314\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.017]Epoch 140: Train Loss = 0.012138811871409416\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=319, train_loss_step=0.0118, train_loss_epoch=0.0121]Epoch 141: Train Loss = 0.0117837218567729\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=319, train_loss_step=0.0124, train_loss_epoch=0.0118]Epoch 142: Train Loss = 0.012391701340675354\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=319, train_loss_step=0.0132, train_loss_epoch=0.0124]Epoch 143: Train Loss = 0.013167272321879864\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=319, train_loss_step=0.0156, train_loss_epoch=0.0132]Epoch 144: Train Loss = 0.015588886104524136\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=319, train_loss_step=0.0105, train_loss_epoch=0.0156]Epoch 145: Train Loss = 0.010516180656850338\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=319, train_loss_step=0.0141, train_loss_epoch=0.0105]Epoch 146: Train Loss = 0.01407176349312067\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=319, train_loss_step=0.0112, train_loss_epoch=0.0141]Epoch 147: Train Loss = 0.01118368562310934\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 12.79it/s, v_num=319, train_loss_step=0.014, train_loss_epoch=0.0112] Epoch 148: Train Loss = 0.013951058499515057\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=319, train_loss_step=0.0125, train_loss_epoch=0.014]Epoch 149: Train Loss = 0.012477755546569824\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=319, train_loss_step=0.0104, train_loss_epoch=0.0125]Epoch 150: Train Loss = 0.01042227540165186\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 12.86it/s, v_num=319, train_loss_step=0.0106, train_loss_epoch=0.0104]Epoch 151: Train Loss = 0.010558315552771091\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.0106]Epoch 152: Train Loss = 0.010662408545613289\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=319, train_loss_step=0.0103, train_loss_epoch=0.0107]Epoch 153: Train Loss = 0.010347804985940456\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=319, train_loss_step=0.0123, train_loss_epoch=0.0103]Epoch 154: Train Loss = 0.01234277430921793\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 16.22it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.0123]Epoch 155: Train Loss = 0.01066220086067915\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 17.02it/s, v_num=319, train_loss_step=0.0147, train_loss_epoch=0.0107]Epoch 156: Train Loss = 0.014724592678248882\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=319, train_loss_step=0.0162, train_loss_epoch=0.0147]Epoch 157: Train Loss = 0.016229091212153435\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=319, train_loss_step=0.0126, train_loss_epoch=0.0162]Epoch 158: Train Loss = 0.012634444050490856\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 16.89it/s, v_num=319, train_loss_step=0.012, train_loss_epoch=0.0126] Epoch 159: Train Loss = 0.01197501365095377\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=319, train_loss_step=0.0149, train_loss_epoch=0.012]Epoch 160: Train Loss = 0.01488927286118269\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 16.57it/s, v_num=319, train_loss_step=0.010, train_loss_epoch=0.0149] Epoch 161: Train Loss = 0.009999136440455914\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 17.26it/s, v_num=319, train_loss_step=0.0133, train_loss_epoch=0.010]Epoch 162: Train Loss = 0.013303772546350956\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=319, train_loss_step=0.0127, train_loss_epoch=0.0133]Epoch 163: Train Loss = 0.012705491855740547\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 16.88it/s, v_num=319, train_loss_step=0.0185, train_loss_epoch=0.0127]Epoch 164: Train Loss = 0.018501728773117065\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=319, train_loss_step=0.0142, train_loss_epoch=0.0185]Epoch 165: Train Loss = 0.014205061830580235\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=319, train_loss_step=0.0145, train_loss_epoch=0.0142]Epoch 166: Train Loss = 0.014534665271639824\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=319, train_loss_step=0.0131, train_loss_epoch=0.0145]Epoch 167: Train Loss = 0.013059399090707302\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=319, train_loss_step=0.00893, train_loss_epoch=0.0131]Epoch 168: Train Loss = 0.008934423327445984\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=319, train_loss_step=0.0126, train_loss_epoch=0.00893] Epoch 169: Train Loss = 0.012607574462890625\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=319, train_loss_step=0.0139, train_loss_epoch=0.0126] Epoch 170: Train Loss = 0.013946590013802052\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=319, train_loss_step=0.0106, train_loss_epoch=0.0139]Epoch 171: Train Loss = 0.010613867081701756\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s, v_num=319, train_loss_step=0.0127, train_loss_epoch=0.0106]Epoch 172: Train Loss = 0.012698422186076641\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 16.61it/s, v_num=319, train_loss_step=0.015, train_loss_epoch=0.0127] Epoch 173: Train Loss = 0.014966372400522232\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s, v_num=319, train_loss_step=0.0102, train_loss_epoch=0.015]Epoch 174: Train Loss = 0.010183960199356079\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=319, train_loss_step=0.0125, train_loss_epoch=0.0102]Epoch 175: Train Loss = 0.012539424002170563\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 16.26it/s, v_num=319, train_loss_step=0.0101, train_loss_epoch=0.0125]Epoch 176: Train Loss = 0.010084290988743305\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, v_num=319, train_loss_step=0.0114, train_loss_epoch=0.0101]Epoch 177: Train Loss = 0.011394810862839222\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, v_num=319, train_loss_step=0.0174, train_loss_epoch=0.0114]Epoch 178: Train Loss = 0.01735869236290455\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 16.94it/s, v_num=319, train_loss_step=0.0106, train_loss_epoch=0.0174]Epoch 179: Train Loss = 0.010649008676409721\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 17.31it/s, v_num=319, train_loss_step=0.0135, train_loss_epoch=0.0106]Epoch 180: Train Loss = 0.013501299545168877\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 17.35it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.0135] Epoch 181: Train Loss = 0.012981047853827477\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.013] Epoch 182: Train Loss = 0.012984092347323895\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, v_num=319, train_loss_step=0.0113, train_loss_epoch=0.013]Epoch 183: Train Loss = 0.011308697983622551\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=319, train_loss_step=0.0122, train_loss_epoch=0.0113]Epoch 184: Train Loss = 0.012247412465512753\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 16.36it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.0122]Epoch 185: Train Loss = 0.012881465256214142\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 16.22it/s, v_num=319, train_loss_step=0.0149, train_loss_epoch=0.0129]Epoch 186: Train Loss = 0.014876827597618103\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, v_num=319, train_loss_step=0.0103, train_loss_epoch=0.0149]Epoch 187: Train Loss = 0.010284428484737873\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=319, train_loss_step=0.0101, train_loss_epoch=0.0103]Epoch 188: Train Loss = 0.010087373666465282\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.0101]Epoch 189: Train Loss = 0.012854891829192638\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=319, train_loss_step=0.0131, train_loss_epoch=0.0129]Epoch 190: Train Loss = 0.01306969579309225\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=319, train_loss_step=0.011, train_loss_epoch=0.0131] Epoch 191: Train Loss = 0.010994276031851768\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=319, train_loss_step=0.0111, train_loss_epoch=0.011]Epoch 192: Train Loss = 0.011131645180284977\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, v_num=319, train_loss_step=0.0123, train_loss_epoch=0.0111]Epoch 193: Train Loss = 0.012318561784923077\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 16.60it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.0123]Epoch 194: Train Loss = 0.01286857295781374\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 16.61it/s, v_num=319, train_loss_step=0.0182, train_loss_epoch=0.0129]Epoch 195: Train Loss = 0.018186429515480995\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=319, train_loss_step=0.00924, train_loss_epoch=0.0182]Epoch 196: Train Loss = 0.009239808656275272\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=319, train_loss_step=0.012, train_loss_epoch=0.00924]  Epoch 197: Train Loss = 0.011990866623818874\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=319, train_loss_step=0.0124, train_loss_epoch=0.012] Epoch 198: Train Loss = 0.01238454133272171\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=319, train_loss_step=0.0115, train_loss_epoch=0.0124]Epoch 199: Train Loss = 0.01153434719890356\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=319, train_loss_step=0.0154, train_loss_epoch=0.0115]Epoch 200: Train Loss = 0.015428432263433933\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=319, train_loss_step=0.0114, train_loss_epoch=0.0154]Epoch 201: Train Loss = 0.011448006145656109\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=319, train_loss_step=0.016, train_loss_epoch=0.0114] Epoch 202: Train Loss = 0.01600765250623226\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=319, train_loss_step=0.0122, train_loss_epoch=0.016]Epoch 203: Train Loss = 0.012178330682218075\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=319, train_loss_step=0.0151, train_loss_epoch=0.0122]Epoch 204: Train Loss = 0.015077458694577217\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=319, train_loss_step=0.0158, train_loss_epoch=0.0151]Epoch 205: Train Loss = 0.01584838517010212\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 16.58it/s, v_num=319, train_loss_step=0.0108, train_loss_epoch=0.0158]Epoch 206: Train Loss = 0.010805602185428143\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 16.72it/s, v_num=319, train_loss_step=0.0143, train_loss_epoch=0.0108]Epoch 207: Train Loss = 0.01432510744780302\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=319, train_loss_step=0.0115, train_loss_epoch=0.0143]Epoch 208: Train Loss = 0.011526256799697876\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 16.92it/s, v_num=319, train_loss_step=0.0139, train_loss_epoch=0.0115]Epoch 209: Train Loss = 0.013853729702532291\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=319, train_loss_step=0.0123, train_loss_epoch=0.0139]Epoch 210: Train Loss = 0.012270569801330566\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=319, train_loss_step=0.0139, train_loss_epoch=0.0123]Epoch 211: Train Loss = 0.013894014060497284\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 16.92it/s, v_num=319, train_loss_step=0.00867, train_loss_epoch=0.0139]Epoch 212: Train Loss = 0.008670511655509472\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=319, train_loss_step=0.0152, train_loss_epoch=0.00867] Epoch 213: Train Loss = 0.015192024409770966\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s, v_num=319, train_loss_step=0.0135, train_loss_epoch=0.0152] Epoch 214: Train Loss = 0.013475144281983376\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 16.64it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.0135]Epoch 215: Train Loss = 0.010703458450734615\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 16.60it/s, v_num=319, train_loss_step=0.0093, train_loss_epoch=0.0107]Epoch 216: Train Loss = 0.00930110551416874\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s, v_num=319, train_loss_step=0.00992, train_loss_epoch=0.0093]Epoch 217: Train Loss = 0.009923180565237999\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, v_num=319, train_loss_step=0.010, train_loss_epoch=0.00992]  Epoch 218: Train Loss = 0.010009720921516418\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 17.44it/s, v_num=319, train_loss_step=0.0115, train_loss_epoch=0.010] Epoch 219: Train Loss = 0.011475017294287682\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 17.49it/s, v_num=319, train_loss_step=0.0123, train_loss_epoch=0.0115]Epoch 220: Train Loss = 0.012270853854715824\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=319, train_loss_step=0.0153, train_loss_epoch=0.0123]Epoch 221: Train Loss = 0.01526972372084856\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 17.58it/s, v_num=319, train_loss_step=0.0137, train_loss_epoch=0.0153]Epoch 222: Train Loss = 0.013742866925895214\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, v_num=319, train_loss_step=0.0122, train_loss_epoch=0.0137]Epoch 223: Train Loss = 0.012200992554426193\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 17.34it/s, v_num=319, train_loss_step=0.00865, train_loss_epoch=0.0122]Epoch 224: Train Loss = 0.008652590215206146\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 17.71it/s, v_num=319, train_loss_step=0.00881, train_loss_epoch=0.00865]Epoch 225: Train Loss = 0.008805030956864357\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s, v_num=319, train_loss_step=0.0104, train_loss_epoch=0.00881] Epoch 226: Train Loss = 0.010446279309689999\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 17.60it/s, v_num=319, train_loss_step=0.0146, train_loss_epoch=0.0104] Epoch 227: Train Loss = 0.014575662091374397\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 17.08it/s, v_num=319, train_loss_step=0.0193, train_loss_epoch=0.0146]Epoch 228: Train Loss = 0.019300151616334915\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 17.58it/s, v_num=319, train_loss_step=0.0132, train_loss_epoch=0.0193]Epoch 229: Train Loss = 0.013235022313892841\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s, v_num=319, train_loss_step=0.0146, train_loss_epoch=0.0132]Epoch 230: Train Loss = 0.014626269228756428\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=319, train_loss_step=0.0122, train_loss_epoch=0.0146]Epoch 231: Train Loss = 0.012195897288620472\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 17.70it/s, v_num=319, train_loss_step=0.0125, train_loss_epoch=0.0122]Epoch 232: Train Loss = 0.012530190870165825\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 17.71it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.0125] Epoch 233: Train Loss = 0.013033594004809856\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 17.48it/s, v_num=319, train_loss_step=0.011, train_loss_epoch=0.013] Epoch 234: Train Loss = 0.011027688160538673\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 17.67it/s, v_num=319, train_loss_step=0.0101, train_loss_epoch=0.011]Epoch 235: Train Loss = 0.010100731626152992\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0101]Epoch 236: Train Loss = 0.012089780531823635\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 17.57it/s, v_num=319, train_loss_step=0.0138, train_loss_epoch=0.0121]Epoch 237: Train Loss = 0.013817423954606056\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 17.26it/s, v_num=319, train_loss_step=0.0194, train_loss_epoch=0.0138]Epoch 238: Train Loss = 0.01936195231974125\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 17.70it/s, v_num=319, train_loss_step=0.0111, train_loss_epoch=0.0194]Epoch 239: Train Loss = 0.011113084852695465\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 17.30it/s, v_num=319, train_loss_step=0.0162, train_loss_epoch=0.0111]Epoch 240: Train Loss = 0.016241583973169327\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=319, train_loss_step=0.0176, train_loss_epoch=0.0162]Epoch 241: Train Loss = 0.01757447049021721\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=319, train_loss_step=0.0183, train_loss_epoch=0.0176]Epoch 242: Train Loss = 0.01833437569439411\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=319, train_loss_step=0.0134, train_loss_epoch=0.0183]Epoch 243: Train Loss = 0.013423346914350986\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s, v_num=319, train_loss_step=0.0156, train_loss_epoch=0.0134]Epoch 244: Train Loss = 0.01556343026459217\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0156]Epoch 245: Train Loss = 0.01157380547374487\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 17.37it/s, v_num=319, train_loss_step=0.0148, train_loss_epoch=0.0116]Epoch 246: Train Loss = 0.014838246628642082\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=319, train_loss_step=0.0189, train_loss_epoch=0.0148]Epoch 247: Train Loss = 0.01887599751353264\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 17.15it/s, v_num=319, train_loss_step=0.0156, train_loss_epoch=0.0189]Epoch 248: Train Loss = 0.015573559328913689\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 16.58it/s, v_num=319, train_loss_step=0.0111, train_loss_epoch=0.0156]Epoch 249: Train Loss = 0.011052103713154793\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=319, train_loss_step=0.0182, train_loss_epoch=0.0111]Epoch 250: Train Loss = 0.018168162554502487\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, v_num=319, train_loss_step=0.0139, train_loss_epoch=0.0182]Epoch 251: Train Loss = 0.013857194222509861\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 16.47it/s, v_num=319, train_loss_step=0.016, train_loss_epoch=0.0139] Epoch 252: Train Loss = 0.015958847478032112\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=319, train_loss_step=0.0157, train_loss_epoch=0.016]Epoch 253: Train Loss = 0.015746397897601128\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 16.58it/s, v_num=319, train_loss_step=0.0125, train_loss_epoch=0.0157]Epoch 254: Train Loss = 0.012543842196464539\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.0125]Epoch 255: Train Loss = 0.010730662383139133\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 12.90it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0107]Epoch 256: Train Loss = 0.012110352516174316\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=319, train_loss_step=0.0135, train_loss_epoch=0.0121]Epoch 257: Train Loss = 0.013467175886034966\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s, v_num=319, train_loss_step=0.0127, train_loss_epoch=0.0135]Epoch 258: Train Loss = 0.012717160396277905\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.0127]Epoch 259: Train Loss = 0.012870586477220058\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=319, train_loss_step=0.0128, train_loss_epoch=0.0129]Epoch 260: Train Loss = 0.012777550145983696\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=319, train_loss_step=0.0131, train_loss_epoch=0.0128]Epoch 261: Train Loss = 0.013131595216691494\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.0131]Epoch 262: Train Loss = 0.010745278559625149\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 16.76it/s, v_num=319, train_loss_step=0.0163, train_loss_epoch=0.0107]Epoch 263: Train Loss = 0.0162874273955822\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=319, train_loss_step=0.0124, train_loss_epoch=0.0163]Epoch 264: Train Loss = 0.01241105142980814\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=319, train_loss_step=0.0158, train_loss_epoch=0.0124]Epoch 265: Train Loss = 0.015832243487238884\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 16.65it/s, v_num=319, train_loss_step=0.0123, train_loss_epoch=0.0158]Epoch 266: Train Loss = 0.012326901778578758\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 17.04it/s, v_num=319, train_loss_step=0.014, train_loss_epoch=0.0123] Epoch 267: Train Loss = 0.014033118262887001\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 16.51it/s, v_num=319, train_loss_step=0.0163, train_loss_epoch=0.014]Epoch 268: Train Loss = 0.01629135198891163\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 16.28it/s, v_num=319, train_loss_step=0.0172, train_loss_epoch=0.0163]Epoch 269: Train Loss = 0.017222480848431587\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=319, train_loss_step=0.0138, train_loss_epoch=0.0172]Epoch 270: Train Loss = 0.013796678744256496\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=319, train_loss_step=0.0201, train_loss_epoch=0.0138]Epoch 271: Train Loss = 0.020107002928853035\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s, v_num=319, train_loss_step=0.0138, train_loss_epoch=0.0201]Epoch 272: Train Loss = 0.01381667796522379\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=319, train_loss_step=0.0154, train_loss_epoch=0.0138]Epoch 273: Train Loss = 0.015368401072919369\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=319, train_loss_step=0.0136, train_loss_epoch=0.0154]Epoch 274: Train Loss = 0.013640825636684895\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 17.29it/s, v_num=319, train_loss_step=0.0143, train_loss_epoch=0.0136]Epoch 275: Train Loss = 0.01429359707981348\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=319, train_loss_step=0.0145, train_loss_epoch=0.0143]Epoch 276: Train Loss = 0.014473959803581238\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=319, train_loss_step=0.0146, train_loss_epoch=0.0145]Epoch 277: Train Loss = 0.01463831216096878\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=319, train_loss_step=0.0117, train_loss_epoch=0.0146]Epoch 278: Train Loss = 0.011667972430586815\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=319, train_loss_step=0.011, train_loss_epoch=0.0117] Epoch 279: Train Loss = 0.011035303585231304\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=319, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 280: Train Loss = 0.012531925924122334\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=319, train_loss_step=0.0154, train_loss_epoch=0.0125]Epoch 281: Train Loss = 0.015444150194525719\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, v_num=319, train_loss_step=0.0141, train_loss_epoch=0.0154]Epoch 282: Train Loss = 0.014125099405646324\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, v_num=319, train_loss_step=0.00907, train_loss_epoch=0.0141]Epoch 283: Train Loss = 0.009069000370800495\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 13.91it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.00907] Epoch 284: Train Loss = 0.012069915421307087\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=319, train_loss_step=0.0152, train_loss_epoch=0.0121] Epoch 285: Train Loss = 0.015170366503298283\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=319, train_loss_step=0.0144, train_loss_epoch=0.0152]Epoch 286: Train Loss = 0.014448734000325203\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, v_num=319, train_loss_step=0.0152, train_loss_epoch=0.0144]Epoch 287: Train Loss = 0.01516221184283495\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=319, train_loss_step=0.0119, train_loss_epoch=0.0152]Epoch 288: Train Loss = 0.011931459419429302\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, v_num=319, train_loss_step=0.0125, train_loss_epoch=0.0119]Epoch 289: Train Loss = 0.012487818486988544\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=319, train_loss_step=0.0113, train_loss_epoch=0.0125]Epoch 290: Train Loss = 0.011312483809888363\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s, v_num=319, train_loss_step=0.0118, train_loss_epoch=0.0113]Epoch 291: Train Loss = 0.011816628277301788\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 16.60it/s, v_num=319, train_loss_step=0.0135, train_loss_epoch=0.0118]Epoch 292: Train Loss = 0.013507932424545288\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=319, train_loss_step=0.011, train_loss_epoch=0.0135] Epoch 293: Train Loss = 0.010977255180478096\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=319, train_loss_step=0.00819, train_loss_epoch=0.011]Epoch 294: Train Loss = 0.008185183629393578\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=319, train_loss_step=0.0139, train_loss_epoch=0.00819] Epoch 295: Train Loss = 0.013943555764853954\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=319, train_loss_step=0.0118, train_loss_epoch=0.0139] Epoch 296: Train Loss = 0.011836575344204903\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 16.22it/s, v_num=319, train_loss_step=0.0198, train_loss_epoch=0.0118]Epoch 297: Train Loss = 0.019754664972424507\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 16.51it/s, v_num=319, train_loss_step=0.0118, train_loss_epoch=0.0198]Epoch 298: Train Loss = 0.011765140108764172\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=319, train_loss_step=0.0106, train_loss_epoch=0.0118]Epoch 299: Train Loss = 0.01063951849937439\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=319, train_loss_step=0.0136, train_loss_epoch=0.0106]Epoch 300: Train Loss = 0.013609972782433033\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=319, train_loss_step=0.0117, train_loss_epoch=0.0136]Epoch 301: Train Loss = 0.011692220345139503\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 16.76it/s, v_num=319, train_loss_step=0.0179, train_loss_epoch=0.0117]Epoch 302: Train Loss = 0.017859460785984993\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=319, train_loss_step=0.0128, train_loss_epoch=0.0179]Epoch 303: Train Loss = 0.012752370908856392\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=319, train_loss_step=0.012, train_loss_epoch=0.0128] Epoch 304: Train Loss = 0.012028701603412628\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s, v_num=319, train_loss_step=0.0136, train_loss_epoch=0.012]Epoch 305: Train Loss = 0.013569734059274197\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=319, train_loss_step=0.0133, train_loss_epoch=0.0136]Epoch 306: Train Loss = 0.013262004591524601\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s, v_num=319, train_loss_step=0.0118, train_loss_epoch=0.0133]Epoch 307: Train Loss = 0.01179098803550005\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=319, train_loss_step=0.0119, train_loss_epoch=0.0118]Epoch 308: Train Loss = 0.011895905248820782\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=319, train_loss_step=0.0137, train_loss_epoch=0.0119]Epoch 309: Train Loss = 0.013701404444873333\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=319, train_loss_step=0.0155, train_loss_epoch=0.0137]Epoch 310: Train Loss = 0.015529257245361805\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.0155]Epoch 311: Train Loss = 0.012943165376782417\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=319, train_loss_step=0.0165, train_loss_epoch=0.0129]Epoch 312: Train Loss = 0.016460636630654335\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=319, train_loss_step=0.0103, train_loss_epoch=0.0165]Epoch 313: Train Loss = 0.010293385945260525\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0103]Epoch 314: Train Loss = 0.011641636490821838\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=319, train_loss_step=0.0145, train_loss_epoch=0.0116]Epoch 315: Train Loss = 0.014456072822213173\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.0145] Epoch 316: Train Loss = 0.012996573932468891\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=319, train_loss_step=0.0136, train_loss_epoch=0.013]Epoch 317: Train Loss = 0.013564604334533215\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=319, train_loss_step=0.0128, train_loss_epoch=0.0136]Epoch 318: Train Loss = 0.012757450342178345\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=319, train_loss_step=0.0117, train_loss_epoch=0.0128]Epoch 319: Train Loss = 0.011668605729937553\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=319, train_loss_step=0.0095, train_loss_epoch=0.0117]Epoch 320: Train Loss = 0.009504609741270542\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0095]Epoch 321: Train Loss = 0.011600037105381489\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.0116] Epoch 322: Train Loss = 0.012967419810593128\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=319, train_loss_step=0.0111, train_loss_epoch=0.013]Epoch 323: Train Loss = 0.011118203401565552\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 12.39it/s, v_num=319, train_loss_step=0.0155, train_loss_epoch=0.0111]Epoch 324: Train Loss = 0.01545395515859127\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, v_num=319, train_loss_step=0.0123, train_loss_epoch=0.0155]Epoch 325: Train Loss = 0.012347412295639515\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=319, train_loss_step=0.0118, train_loss_epoch=0.0123]Epoch 326: Train Loss = 0.011759375222027302\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 13.02it/s, v_num=319, train_loss_step=0.0212, train_loss_epoch=0.0118]Epoch 327: Train Loss = 0.021205803379416466\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 13.00it/s, v_num=319, train_loss_step=0.0105, train_loss_epoch=0.0212]Epoch 328: Train Loss = 0.010519820265471935\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=319, train_loss_step=0.0101, train_loss_epoch=0.0105]Epoch 329: Train Loss = 0.0101232985034585\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=319, train_loss_step=0.0132, train_loss_epoch=0.0101]Epoch 330: Train Loss = 0.013225823640823364\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.0132]Epoch 331: Train Loss = 0.010737900622189045\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=319, train_loss_step=0.0124, train_loss_epoch=0.0107]Epoch 332: Train Loss = 0.012448993511497974\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 17.38it/s, v_num=319, train_loss_step=0.0104, train_loss_epoch=0.0124]Epoch 333: Train Loss = 0.010441349819302559\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 16.58it/s, v_num=319, train_loss_step=0.0118, train_loss_epoch=0.0104]Epoch 334: Train Loss = 0.011827061884105206\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=319, train_loss_step=0.014, train_loss_epoch=0.0118] Epoch 335: Train Loss = 0.014029532670974731\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, v_num=319, train_loss_step=0.0149, train_loss_epoch=0.014]Epoch 336: Train Loss = 0.014905939809978008\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 16.04it/s, v_num=319, train_loss_step=0.0101, train_loss_epoch=0.0149]Epoch 337: Train Loss = 0.010147099383175373\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0101]Epoch 338: Train Loss = 0.01163474377244711\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0116]Epoch 339: Train Loss = 0.011589065194129944\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 16.51it/s, v_num=319, train_loss_step=0.0126, train_loss_epoch=0.0116]Epoch 340: Train Loss = 0.012641973793506622\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=319, train_loss_step=0.0119, train_loss_epoch=0.0126]Epoch 341: Train Loss = 0.011921770870685577\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=319, train_loss_step=0.0141, train_loss_epoch=0.0119]Epoch 342: Train Loss = 0.014061957597732544\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 13.77it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0141]Epoch 343: Train Loss = 0.012067521922290325\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, v_num=319, train_loss_step=0.016, train_loss_epoch=0.0121] Epoch 344: Train Loss = 0.016002226620912552\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=319, train_loss_step=0.0127, train_loss_epoch=0.016]Epoch 345: Train Loss = 0.012684948742389679\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0127]Epoch 346: Train Loss = 0.011617260985076427\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=319, train_loss_step=0.0147, train_loss_epoch=0.0116]Epoch 347: Train Loss = 0.014663340523838997\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=319, train_loss_step=0.0136, train_loss_epoch=0.0147]Epoch 348: Train Loss = 0.013634770177304745\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=319, train_loss_step=0.0201, train_loss_epoch=0.0136]Epoch 349: Train Loss = 0.020139800384640694\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.0201]Epoch 350: Train Loss = 0.012893076054751873\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=319, train_loss_step=0.0127, train_loss_epoch=0.0129]Epoch 351: Train Loss = 0.012744211591780186\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=319, train_loss_step=0.0191, train_loss_epoch=0.0127]Epoch 352: Train Loss = 0.01912294514477253\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=319, train_loss_step=0.0104, train_loss_epoch=0.0191]Epoch 353: Train Loss = 0.010355276055634022\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=319, train_loss_step=0.0132, train_loss_epoch=0.0104]Epoch 354: Train Loss = 0.013160784728825092\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.0132] Epoch 355: Train Loss = 0.012992735020816326\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=319, train_loss_step=0.00943, train_loss_epoch=0.013]Epoch 356: Train Loss = 0.009431545622646809\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=319, train_loss_step=0.00944, train_loss_epoch=0.00943]Epoch 357: Train Loss = 0.009438700042665005\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=319, train_loss_step=0.0133, train_loss_epoch=0.00944] Epoch 358: Train Loss = 0.013339518569409847\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=319, train_loss_step=0.011, train_loss_epoch=0.0133]  Epoch 359: Train Loss = 0.010973985306918621\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=319, train_loss_step=0.0134, train_loss_epoch=0.011]Epoch 360: Train Loss = 0.013357972726225853\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=319, train_loss_step=0.00938, train_loss_epoch=0.0134]Epoch 361: Train Loss = 0.009381667710840702\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=319, train_loss_step=0.0132, train_loss_epoch=0.00938] Epoch 362: Train Loss = 0.013249796815216541\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 16.80it/s, v_num=319, train_loss_step=0.0151, train_loss_epoch=0.0132] Epoch 363: Train Loss = 0.015076443552970886\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 17.15it/s, v_num=319, train_loss_step=0.0126, train_loss_epoch=0.0151]Epoch 364: Train Loss = 0.01261158287525177\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 17.02it/s, v_num=319, train_loss_step=0.00859, train_loss_epoch=0.0126]Epoch 365: Train Loss = 0.008585041388869286\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=319, train_loss_step=0.00964, train_loss_epoch=0.00859]Epoch 366: Train Loss = 0.009636770002543926\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=319, train_loss_step=0.0103, train_loss_epoch=0.00964] Epoch 367: Train Loss = 0.01033709105104208\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=319, train_loss_step=0.0128, train_loss_epoch=0.0103] Epoch 368: Train Loss = 0.012754367664456367\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=319, train_loss_step=0.00932, train_loss_epoch=0.0128]Epoch 369: Train Loss = 0.009317934513092041\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.00932] Epoch 370: Train Loss = 0.01158459484577179\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=319, train_loss_step=0.0144, train_loss_epoch=0.0116] Epoch 371: Train Loss = 0.014350347220897675\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0144]Epoch 372: Train Loss = 0.011606670916080475\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=319, train_loss_step=0.0112, train_loss_epoch=0.0116]Epoch 373: Train Loss = 0.011202052235603333\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 13.46it/s, v_num=319, train_loss_step=0.0108, train_loss_epoch=0.0112]Epoch 374: Train Loss = 0.01077917031943798\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=319, train_loss_step=0.0134, train_loss_epoch=0.0108]Epoch 375: Train Loss = 0.013403543271124363\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=319, train_loss_step=0.0113, train_loss_epoch=0.0134]Epoch 376: Train Loss = 0.011290655471384525\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=319, train_loss_step=0.0128, train_loss_epoch=0.0113]Epoch 377: Train Loss = 0.012810803018510342\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s, v_num=319, train_loss_step=0.0138, train_loss_epoch=0.0128]Epoch 378: Train Loss = 0.013784177601337433\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=319, train_loss_step=0.0104, train_loss_epoch=0.0138]Epoch 379: Train Loss = 0.010430889204144478\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=319, train_loss_step=0.0105, train_loss_epoch=0.0104]Epoch 380: Train Loss = 0.01046911720186472\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=319, train_loss_step=0.0119, train_loss_epoch=0.0105]Epoch 381: Train Loss = 0.011871344409883022\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s, v_num=319, train_loss_step=0.0133, train_loss_epoch=0.0119]Epoch 382: Train Loss = 0.013301110826432705\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=319, train_loss_step=0.0134, train_loss_epoch=0.0133]Epoch 383: Train Loss = 0.013439759612083435\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 12.87it/s, v_num=319, train_loss_step=0.0111, train_loss_epoch=0.0134]Epoch 384: Train Loss = 0.011100870557129383\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=319, train_loss_step=0.0142, train_loss_epoch=0.0111]Epoch 385: Train Loss = 0.014230802655220032\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0142]Epoch 386: Train Loss = 0.01208571344614029\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=319, train_loss_step=0.0141, train_loss_epoch=0.0121]Epoch 387: Train Loss = 0.014093898236751556\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=319, train_loss_step=0.0119, train_loss_epoch=0.0141]Epoch 388: Train Loss = 0.01194870937615633\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=319, train_loss_step=0.0112, train_loss_epoch=0.0119]Epoch 389: Train Loss = 0.011219312436878681\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=319, train_loss_step=0.0125, train_loss_epoch=0.0112]Epoch 390: Train Loss = 0.012496459297835827\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=319, train_loss_step=0.00833, train_loss_epoch=0.0125]Epoch 391: Train Loss = 0.00832814909517765\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s, v_num=319, train_loss_step=0.0093, train_loss_epoch=0.00833] Epoch 392: Train Loss = 0.009296593256294727\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=319, train_loss_step=0.0102, train_loss_epoch=0.0093] Epoch 393: Train Loss = 0.010212748311460018\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=319, train_loss_step=0.0111, train_loss_epoch=0.0102]Epoch 394: Train Loss = 0.011097202077507973\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, v_num=319, train_loss_step=0.0113, train_loss_epoch=0.0111]Epoch 395: Train Loss = 0.011260620318353176\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=319, train_loss_step=0.0108, train_loss_epoch=0.0113]Epoch 396: Train Loss = 0.01084238849580288\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=319, train_loss_step=0.0105, train_loss_epoch=0.0108]Epoch 397: Train Loss = 0.010518915951251984\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=319, train_loss_step=0.016, train_loss_epoch=0.0105] Epoch 398: Train Loss = 0.016028089448809624\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.016] Epoch 399: Train Loss = 0.01295082550495863\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=319, train_loss_step=0.0109, train_loss_epoch=0.013]Epoch 400: Train Loss = 0.01087358221411705\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=319, train_loss_step=0.0133, train_loss_epoch=0.0109]Epoch 401: Train Loss = 0.013345400802791119\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=319, train_loss_step=0.010, train_loss_epoch=0.0133] Epoch 402: Train Loss = 0.010012327693402767\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=319, train_loss_step=0.010, train_loss_epoch=0.010] Epoch 403: Train Loss = 0.010014049708843231\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=319, train_loss_step=0.0126, train_loss_epoch=0.010]Epoch 404: Train Loss = 0.01261491421610117\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=319, train_loss_step=0.0164, train_loss_epoch=0.0126]Epoch 405: Train Loss = 0.016378439962863922\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=319, train_loss_step=0.0132, train_loss_epoch=0.0164]Epoch 406: Train Loss = 0.013185573741793633\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=319, train_loss_step=0.0117, train_loss_epoch=0.0132]Epoch 407: Train Loss = 0.011671426706016064\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 13.01it/s, v_num=319, train_loss_step=0.0161, train_loss_epoch=0.0117]Epoch 408: Train Loss = 0.016100166365504265\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 11.54it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0161]Epoch 409: Train Loss = 0.011608040891587734\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 13.54it/s, v_num=319, train_loss_step=0.0156, train_loss_epoch=0.0116]Epoch 410: Train Loss = 0.015555336140096188\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0156]Epoch 411: Train Loss = 0.012051863595843315\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=319, train_loss_step=0.0123, train_loss_epoch=0.0121]Epoch 412: Train Loss = 0.012326083146035671\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=319, train_loss_step=0.0126, train_loss_epoch=0.0123]Epoch 413: Train Loss = 0.012616164050996304\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.0126]Epoch 414: Train Loss = 0.012893683277070522\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s, v_num=319, train_loss_step=0.0133, train_loss_epoch=0.0129]Epoch 415: Train Loss = 0.013293800875544548\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0133]Epoch 416: Train Loss = 0.012136248871684074\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=319, train_loss_step=0.0112, train_loss_epoch=0.0121]Epoch 417: Train Loss = 0.01123816054314375\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=319, train_loss_step=0.0119, train_loss_epoch=0.0112]Epoch 418: Train Loss = 0.011934137903153896\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=319, train_loss_step=0.0119, train_loss_epoch=0.0119]Epoch 419: Train Loss = 0.01185053400695324\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=319, train_loss_step=0.00902, train_loss_epoch=0.0119]Epoch 420: Train Loss = 0.00902487337589264\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=319, train_loss_step=0.00985, train_loss_epoch=0.00902]Epoch 421: Train Loss = 0.009845455177128315\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=319, train_loss_step=0.0138, train_loss_epoch=0.00985] Epoch 422: Train Loss = 0.013834616169333458\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 13.91it/s, v_num=319, train_loss_step=0.0131, train_loss_epoch=0.0138] Epoch 423: Train Loss = 0.013090236112475395\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=319, train_loss_step=0.0133, train_loss_epoch=0.0131]Epoch 424: Train Loss = 0.013272179290652275\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 11.97it/s, v_num=319, train_loss_step=0.0102, train_loss_epoch=0.0133]Epoch 425: Train Loss = 0.010156990960240364\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.0102]Epoch 426: Train Loss = 0.010737292468547821\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 16.50it/s, v_num=319, train_loss_step=0.0101, train_loss_epoch=0.0107]Epoch 427: Train Loss = 0.010125404223799706\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 16.40it/s, v_num=319, train_loss_step=0.0118, train_loss_epoch=0.0101]Epoch 428: Train Loss = 0.011820556595921516\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0118]Epoch 429: Train Loss = 0.012062511406838894\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=319, train_loss_step=0.011, train_loss_epoch=0.0121] Epoch 430: Train Loss = 0.011037743650376797\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=319, train_loss_step=0.00869, train_loss_epoch=0.011]Epoch 431: Train Loss = 0.008694959804415703\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=319, train_loss_step=0.0123, train_loss_epoch=0.00869] Epoch 432: Train Loss = 0.012269366532564163\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 13.88it/s, v_num=319, train_loss_step=0.0115, train_loss_epoch=0.0123] Epoch 433: Train Loss = 0.011538399383425713\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=319, train_loss_step=0.00967, train_loss_epoch=0.0115]Epoch 434: Train Loss = 0.009667317382991314\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=319, train_loss_step=0.0105, train_loss_epoch=0.00967] Epoch 435: Train Loss = 0.010535777546465397\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=319, train_loss_step=0.0145, train_loss_epoch=0.0105] Epoch 436: Train Loss = 0.014481157064437866\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.0145]Epoch 437: Train Loss = 0.01066957600414753\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=319, train_loss_step=0.0138, train_loss_epoch=0.0107]Epoch 438: Train Loss = 0.013814038597047329\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=319, train_loss_step=0.0113, train_loss_epoch=0.0138]Epoch 439: Train Loss = 0.011267504654824734\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=319, train_loss_step=0.0117, train_loss_epoch=0.0113]Epoch 440: Train Loss = 0.011652871035039425\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 12.45it/s, v_num=319, train_loss_step=0.00933, train_loss_epoch=0.0117]Epoch 441: Train Loss = 0.009328315034508705\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, v_num=319, train_loss_step=0.0133, train_loss_epoch=0.00933] Epoch 442: Train Loss = 0.013257292099297047\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=319, train_loss_step=0.0115, train_loss_epoch=0.0133] Epoch 443: Train Loss = 0.011461928486824036\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 12.39it/s, v_num=319, train_loss_step=0.0127, train_loss_epoch=0.0115]Epoch 444: Train Loss = 0.012660699896514416\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.0127]Epoch 445: Train Loss = 0.01162890437990427\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=319, train_loss_step=0.00707, train_loss_epoch=0.0116]Epoch 446: Train Loss = 0.007066281978040934\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=319, train_loss_step=0.0106, train_loss_epoch=0.00707] Epoch 447: Train Loss = 0.010559484362602234\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 16.57it/s, v_num=319, train_loss_step=0.0147, train_loss_epoch=0.0106] Epoch 448: Train Loss = 0.01474679820239544\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 16.02it/s, v_num=319, train_loss_step=0.0095, train_loss_epoch=0.0147]Epoch 449: Train Loss = 0.009502326138317585\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, v_num=319, train_loss_step=0.0115, train_loss_epoch=0.0095]Epoch 450: Train Loss = 0.011469495482742786\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=319, train_loss_step=0.0175, train_loss_epoch=0.0115]Epoch 451: Train Loss = 0.01753612421452999\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 16.07it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.0175]Epoch 452: Train Loss = 0.010659756138920784\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=319, train_loss_step=0.00841, train_loss_epoch=0.0107]Epoch 453: Train Loss = 0.008405810222029686\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s, v_num=319, train_loss_step=0.00998, train_loss_epoch=0.00841]Epoch 454: Train Loss = 0.009984895586967468\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 17.02it/s, v_num=319, train_loss_step=0.0188, train_loss_epoch=0.00998] Epoch 455: Train Loss = 0.018844621255993843\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0188] Epoch 456: Train Loss = 0.012090972624719143\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, v_num=319, train_loss_step=0.0124, train_loss_epoch=0.0121]Epoch 457: Train Loss = 0.012442897073924541\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=319, train_loss_step=0.014, train_loss_epoch=0.0124] Epoch 458: Train Loss = 0.01396015752106905\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=319, train_loss_step=0.0104, train_loss_epoch=0.014]Epoch 459: Train Loss = 0.010360898450016975\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=319, train_loss_step=0.00989, train_loss_epoch=0.0104]Epoch 460: Train Loss = 0.009892606176435947\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=319, train_loss_step=0.0114, train_loss_epoch=0.00989] Epoch 461: Train Loss = 0.011374637484550476\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=319, train_loss_step=0.00884, train_loss_epoch=0.0114]Epoch 462: Train Loss = 0.00884136650711298\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=319, train_loss_step=0.0162, train_loss_epoch=0.00884] Epoch 463: Train Loss = 0.01621529646217823\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=319, train_loss_step=0.0117, train_loss_epoch=0.0162] Epoch 464: Train Loss = 0.011678594164550304\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=319, train_loss_step=0.013, train_loss_epoch=0.0117] Epoch 465: Train Loss = 0.013041459955275059\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=319, train_loss_step=0.0116, train_loss_epoch=0.013]Epoch 466: Train Loss = 0.011586605571210384\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, v_num=319, train_loss_step=0.0102, train_loss_epoch=0.0116]Epoch 467: Train Loss = 0.01021475251764059\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 13.91it/s, v_num=319, train_loss_step=0.00909, train_loss_epoch=0.0102]Epoch 468: Train Loss = 0.009091466665267944\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=319, train_loss_step=0.0107, train_loss_epoch=0.00909] Epoch 469: Train Loss = 0.010667025111615658\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=319, train_loss_step=0.0132, train_loss_epoch=0.0107] Epoch 470: Train Loss = 0.013209582306444645\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, v_num=319, train_loss_step=0.0191, train_loss_epoch=0.0132]Epoch 471: Train Loss = 0.01905040070414543\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=319, train_loss_step=0.00963, train_loss_epoch=0.0191]Epoch 472: Train Loss = 0.009628921747207642\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=319, train_loss_step=0.00991, train_loss_epoch=0.00963]Epoch 473: Train Loss = 0.009907626546919346\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=319, train_loss_step=0.0127, train_loss_epoch=0.00991] Epoch 474: Train Loss = 0.012710286304354668\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=319, train_loss_step=0.00915, train_loss_epoch=0.0127]Epoch 475: Train Loss = 0.00915229506790638\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=319, train_loss_step=0.0105, train_loss_epoch=0.00915] Epoch 476: Train Loss = 0.010491251945495605\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=319, train_loss_step=0.0153, train_loss_epoch=0.0105] Epoch 477: Train Loss = 0.015278630889952183\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=319, train_loss_step=0.0151, train_loss_epoch=0.0153]Epoch 478: Train Loss = 0.015105076134204865\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=319, train_loss_step=0.0118, train_loss_epoch=0.0151]Epoch 479: Train Loss = 0.011832298710942268\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 13.93it/s, v_num=319, train_loss_step=0.0119, train_loss_epoch=0.0118]Epoch 480: Train Loss = 0.011910572648048401\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=319, train_loss_step=0.0129, train_loss_epoch=0.0119]Epoch 481: Train Loss = 0.012878361158072948\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0129]Epoch 482: Train Loss = 0.012075715698301792\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=319, train_loss_step=0.0209, train_loss_epoch=0.0121]Epoch 483: Train Loss = 0.020861664786934853\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=319, train_loss_step=0.0106, train_loss_epoch=0.0209]Epoch 484: Train Loss = 0.010620047338306904\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=319, train_loss_step=0.0122, train_loss_epoch=0.0106]Epoch 485: Train Loss = 0.012242951430380344\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=319, train_loss_step=0.0125, train_loss_epoch=0.0122]Epoch 486: Train Loss = 0.012528873048722744\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=319, train_loss_step=0.0139, train_loss_epoch=0.0125]Epoch 487: Train Loss = 0.013853969052433968\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=319, train_loss_step=0.0113, train_loss_epoch=0.0139]Epoch 488: Train Loss = 0.011348584666848183\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s, v_num=319, train_loss_step=0.0154, train_loss_epoch=0.0113]Epoch 489: Train Loss = 0.015388366766273975\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 14.13it/s, v_num=319, train_loss_step=0.0153, train_loss_epoch=0.0154]Epoch 490: Train Loss = 0.015292375348508358\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=319, train_loss_step=0.0139, train_loss_epoch=0.0153]Epoch 491: Train Loss = 0.013914183713495731\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=319, train_loss_step=0.0167, train_loss_epoch=0.0139]Epoch 492: Train Loss = 0.016655895859003067\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=319, train_loss_step=0.0119, train_loss_epoch=0.0167]Epoch 493: Train Loss = 0.011924197897315025\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=319, train_loss_step=0.0111, train_loss_epoch=0.0119]Epoch 494: Train Loss = 0.01114196889102459\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=319, train_loss_step=0.0127, train_loss_epoch=0.0111]Epoch 495: Train Loss = 0.012711896561086178\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s, v_num=319, train_loss_step=0.0096, train_loss_epoch=0.0127]Epoch 496: Train Loss = 0.009604058228433132\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s, v_num=319, train_loss_step=0.0126, train_loss_epoch=0.0096]Epoch 497: Train Loss = 0.012576798908412457\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 13.78it/s, v_num=319, train_loss_step=0.0121, train_loss_epoch=0.0126]Epoch 498: Train Loss = 0.012097327038645744\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=319, train_loss_step=0.0109, train_loss_epoch=0.0121]Epoch 499: Train Loss = 0.01094838883727789\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.37it/s, v_num=319, train_loss_step=0.0109, train_loss_epoch=0.0109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=319, train_loss_step=0.0109, train_loss_epoch=0.0109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 9: from 2010-06-30 00:00:00 to 2022-09-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=322, train_loss_step=0.0229]Epoch 0: Train Loss = 0.022880777716636658\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=322, train_loss_step=0.0529, train_loss_epoch=0.0229]Epoch 1: Train Loss = 0.05294661968946457\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=322, train_loss_step=0.0275, train_loss_epoch=0.0529]Epoch 2: Train Loss = 0.027520058676600456\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, v_num=322, train_loss_step=0.0263, train_loss_epoch=0.0275]Epoch 3: Train Loss = 0.026347151026129723\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=322, train_loss_step=0.0183, train_loss_epoch=0.0263]Epoch 4: Train Loss = 0.01828796975314617\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=322, train_loss_step=0.021, train_loss_epoch=0.0183] Epoch 5: Train Loss = 0.021014679223299026\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s, v_num=322, train_loss_step=0.0185, train_loss_epoch=0.021]Epoch 6: Train Loss = 0.01853938214480877\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=322, train_loss_step=0.0238, train_loss_epoch=0.0185]Epoch 7: Train Loss = 0.023780878633260727\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=322, train_loss_step=0.0168, train_loss_epoch=0.0238]Epoch 8: Train Loss = 0.016812991350889206\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=322, train_loss_step=0.0129, train_loss_epoch=0.0168]Epoch 9: Train Loss = 0.01290067471563816\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=322, train_loss_step=0.0162, train_loss_epoch=0.0129]Epoch 10: Train Loss = 0.016192376613616943\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=322, train_loss_step=0.0145, train_loss_epoch=0.0162]Epoch 11: Train Loss = 0.014486799016594887\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=322, train_loss_step=0.0187, train_loss_epoch=0.0145]Epoch 12: Train Loss = 0.018712488934397697\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=322, train_loss_step=0.0169, train_loss_epoch=0.0187]Epoch 13: Train Loss = 0.016885770484805107\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=322, train_loss_step=0.0138, train_loss_epoch=0.0169]Epoch 14: Train Loss = 0.013780317269265652\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=322, train_loss_step=0.0162, train_loss_epoch=0.0138]Epoch 15: Train Loss = 0.016191599890589714\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 16.70it/s, v_num=322, train_loss_step=0.0123, train_loss_epoch=0.0162]Epoch 16: Train Loss = 0.012342274188995361\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=322, train_loss_step=0.0128, train_loss_epoch=0.0123]Epoch 17: Train Loss = 0.01279535423964262\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=322, train_loss_step=0.0129, train_loss_epoch=0.0128]Epoch 18: Train Loss = 0.012871074490249157\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, v_num=322, train_loss_step=0.0131, train_loss_epoch=0.0129]Epoch 19: Train Loss = 0.013105484656989574\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=322, train_loss_step=0.016, train_loss_epoch=0.0131] Epoch 20: Train Loss = 0.01595236174762249\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=322, train_loss_step=0.0141, train_loss_epoch=0.016]Epoch 21: Train Loss = 0.014119080267846584\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=322, train_loss_step=0.0132, train_loss_epoch=0.0141]Epoch 22: Train Loss = 0.013200819492340088\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=322, train_loss_step=0.0164, train_loss_epoch=0.0132]Epoch 23: Train Loss = 0.01635247841477394\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=322, train_loss_step=0.0172, train_loss_epoch=0.0164]Epoch 24: Train Loss = 0.017238430678844452\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=322, train_loss_step=0.0173, train_loss_epoch=0.0172]Epoch 25: Train Loss = 0.017267659306526184\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=322, train_loss_step=0.014, train_loss_epoch=0.0173] Epoch 26: Train Loss = 0.013979898765683174\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=322, train_loss_step=0.0102, train_loss_epoch=0.014]Epoch 27: Train Loss = 0.010161219164729118\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=322, train_loss_step=0.0167, train_loss_epoch=0.0102]Epoch 28: Train Loss = 0.016677886247634888\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=322, train_loss_step=0.0135, train_loss_epoch=0.0167]Epoch 29: Train Loss = 0.01354469545185566\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=322, train_loss_step=0.0151, train_loss_epoch=0.0135]Epoch 30: Train Loss = 0.015086189843714237\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=322, train_loss_step=0.0131, train_loss_epoch=0.0151]Epoch 31: Train Loss = 0.013131360523402691\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=322, train_loss_step=0.0166, train_loss_epoch=0.0131]Epoch 32: Train Loss = 0.016628984361886978\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=322, train_loss_step=0.0122, train_loss_epoch=0.0166]Epoch 33: Train Loss = 0.012187016196548939\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 14.45it/s, v_num=322, train_loss_step=0.0164, train_loss_epoch=0.0122]Epoch 34: Train Loss = 0.016427209600806236\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s, v_num=322, train_loss_step=0.0155, train_loss_epoch=0.0164]Epoch 35: Train Loss = 0.015514761209487915\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=322, train_loss_step=0.0143, train_loss_epoch=0.0155]Epoch 36: Train Loss = 0.014348753727972507\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.0143]Epoch 37: Train Loss = 0.011179379187524319\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.0112] Epoch 38: Train Loss = 0.012028920464217663\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=322, train_loss_step=0.0209, train_loss_epoch=0.012]Epoch 39: Train Loss = 0.02093273028731346\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=322, train_loss_step=0.0208, train_loss_epoch=0.0209]Epoch 40: Train Loss = 0.020808236673474312\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=322, train_loss_step=0.0119, train_loss_epoch=0.0208]Epoch 41: Train Loss = 0.011891094967722893\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=322, train_loss_step=0.0105, train_loss_epoch=0.0119]Epoch 42: Train Loss = 0.010547416284680367\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=322, train_loss_step=0.0127, train_loss_epoch=0.0105]Epoch 43: Train Loss = 0.012739191763103008\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 16.61it/s, v_num=322, train_loss_step=0.0154, train_loss_epoch=0.0127]Epoch 44: Train Loss = 0.015398992225527763\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s, v_num=322, train_loss_step=0.0136, train_loss_epoch=0.0154]Epoch 45: Train Loss = 0.01359542366117239\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=322, train_loss_step=0.0137, train_loss_epoch=0.0136]Epoch 46: Train Loss = 0.013658038340508938\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s, v_num=322, train_loss_step=0.0145, train_loss_epoch=0.0137]Epoch 47: Train Loss = 0.014466864056885242\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=322, train_loss_step=0.0132, train_loss_epoch=0.0145]Epoch 48: Train Loss = 0.013235918246209621\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 17.45it/s, v_num=322, train_loss_step=0.0117, train_loss_epoch=0.0132]Epoch 49: Train Loss = 0.01167324185371399\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s, v_num=322, train_loss_step=0.0132, train_loss_epoch=0.0117]Epoch 50: Train Loss = 0.013219230808317661\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 16.56it/s, v_num=322, train_loss_step=0.0119, train_loss_epoch=0.0132]Epoch 51: Train Loss = 0.011902914382517338\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=322, train_loss_step=0.0151, train_loss_epoch=0.0119]Epoch 52: Train Loss = 0.015092581510543823\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, v_num=322, train_loss_step=0.0139, train_loss_epoch=0.0151]Epoch 53: Train Loss = 0.013910392299294472\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 16.36it/s, v_num=322, train_loss_step=0.0184, train_loss_epoch=0.0139]Epoch 54: Train Loss = 0.01837990991771221\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=322, train_loss_step=0.0157, train_loss_epoch=0.0184]Epoch 55: Train Loss = 0.015739193186163902\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=322, train_loss_step=0.0131, train_loss_epoch=0.0157]Epoch 56: Train Loss = 0.013118299655616283\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 16.56it/s, v_num=322, train_loss_step=0.0158, train_loss_epoch=0.0131]Epoch 57: Train Loss = 0.015790486708283424\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=322, train_loss_step=0.0142, train_loss_epoch=0.0158]Epoch 58: Train Loss = 0.014217549003660679\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 16.62it/s, v_num=322, train_loss_step=0.0168, train_loss_epoch=0.0142]Epoch 59: Train Loss = 0.016817331314086914\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 16.88it/s, v_num=322, train_loss_step=0.0147, train_loss_epoch=0.0168]Epoch 60: Train Loss = 0.014715137891471386\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s, v_num=322, train_loss_step=0.0135, train_loss_epoch=0.0147]Epoch 61: Train Loss = 0.01345326192677021\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=322, train_loss_step=0.0127, train_loss_epoch=0.0135]Epoch 62: Train Loss = 0.012720972299575806\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 16.70it/s, v_num=322, train_loss_step=0.0138, train_loss_epoch=0.0127]Epoch 63: Train Loss = 0.01380955707281828\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 17.15it/s, v_num=322, train_loss_step=0.0151, train_loss_epoch=0.0138]Epoch 64: Train Loss = 0.015131697990000248\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 17.18it/s, v_num=322, train_loss_step=0.0152, train_loss_epoch=0.0151]Epoch 65: Train Loss = 0.015163050033152103\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 17.29it/s, v_num=322, train_loss_step=0.0115, train_loss_epoch=0.0152]Epoch 66: Train Loss = 0.011494372971355915\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=322, train_loss_step=0.019, train_loss_epoch=0.0115] Epoch 67: Train Loss = 0.01897282712161541\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=322, train_loss_step=0.0156, train_loss_epoch=0.019]Epoch 68: Train Loss = 0.015564510598778725\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=322, train_loss_step=0.0142, train_loss_epoch=0.0156]Epoch 69: Train Loss = 0.014234588481485844\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=322, train_loss_step=0.0141, train_loss_epoch=0.0142]Epoch 70: Train Loss = 0.014066798612475395\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 16.57it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.0141]Epoch 71: Train Loss = 0.012405792251229286\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=322, train_loss_step=0.0122, train_loss_epoch=0.0124]Epoch 72: Train Loss = 0.01220343355089426\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=322, train_loss_step=0.013, train_loss_epoch=0.0122] Epoch 73: Train Loss = 0.012999854981899261\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=322, train_loss_step=0.0142, train_loss_epoch=0.013]Epoch 74: Train Loss = 0.014187278226017952\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=322, train_loss_step=0.0178, train_loss_epoch=0.0142]Epoch 75: Train Loss = 0.01779280975461006\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 16.70it/s, v_num=322, train_loss_step=0.0122, train_loss_epoch=0.0178]Epoch 76: Train Loss = 0.012218303047120571\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 17.48it/s, v_num=322, train_loss_step=0.0142, train_loss_epoch=0.0122]Epoch 77: Train Loss = 0.014164878986775875\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=322, train_loss_step=0.017, train_loss_epoch=0.0142] Epoch 78: Train Loss = 0.01696282997727394\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.017]Epoch 79: Train Loss = 0.011284169740974903\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=322, train_loss_step=0.0128, train_loss_epoch=0.0113]Epoch 80: Train Loss = 0.012816891074180603\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 13.64it/s, v_num=322, train_loss_step=0.0196, train_loss_epoch=0.0128]Epoch 81: Train Loss = 0.019579822197556496\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.0196] Epoch 82: Train Loss = 0.012033347971737385\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=322, train_loss_step=0.014, train_loss_epoch=0.012] Epoch 83: Train Loss = 0.013983787968754768\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=322, train_loss_step=0.0116, train_loss_epoch=0.014]Epoch 84: Train Loss = 0.011579151265323162\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=322, train_loss_step=0.0143, train_loss_epoch=0.0116]Epoch 85: Train Loss = 0.014269914478063583\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=322, train_loss_step=0.0185, train_loss_epoch=0.0143]Epoch 86: Train Loss = 0.018506694585084915\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=322, train_loss_step=0.0127, train_loss_epoch=0.0185]Epoch 87: Train Loss = 0.012728103436529636\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=322, train_loss_step=0.0155, train_loss_epoch=0.0127]Epoch 88: Train Loss = 0.0155372628942132\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=322, train_loss_step=0.0169, train_loss_epoch=0.0155]Epoch 89: Train Loss = 0.0169090386480093\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=322, train_loss_step=0.0148, train_loss_epoch=0.0169]Epoch 90: Train Loss = 0.014792963862419128\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 17.14it/s, v_num=322, train_loss_step=0.0108, train_loss_epoch=0.0148]Epoch 91: Train Loss = 0.010783515870571136\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=322, train_loss_step=0.0108, train_loss_epoch=0.0108]Epoch 92: Train Loss = 0.010815201327204704\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=322, train_loss_step=0.0118, train_loss_epoch=0.0108]Epoch 93: Train Loss = 0.01182667724788189\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=322, train_loss_step=0.0167, train_loss_epoch=0.0118]Epoch 94: Train Loss = 0.0167453121393919\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=322, train_loss_step=0.0125, train_loss_epoch=0.0167]Epoch 95: Train Loss = 0.012537680566310883\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=322, train_loss_step=0.0126, train_loss_epoch=0.0125]Epoch 96: Train Loss = 0.012583756819367409\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 17.21it/s, v_num=322, train_loss_step=0.011, train_loss_epoch=0.0126] Epoch 97: Train Loss = 0.010977995581924915\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s, v_num=322, train_loss_step=0.0171, train_loss_epoch=0.011]Epoch 98: Train Loss = 0.017069047316908836\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=322, train_loss_step=0.0135, train_loss_epoch=0.0171]Epoch 99: Train Loss = 0.013539738021790981\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=322, train_loss_step=0.0104, train_loss_epoch=0.0135]Epoch 100: Train Loss = 0.010379315353929996\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=322, train_loss_step=0.0149, train_loss_epoch=0.0104]Epoch 101: Train Loss = 0.014877108857035637\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.0149]Epoch 102: Train Loss = 0.011263866908848286\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=322, train_loss_step=0.0145, train_loss_epoch=0.0113]Epoch 103: Train Loss = 0.014464142732322216\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.0145] Epoch 104: Train Loss = 0.012016273103654385\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, v_num=322, train_loss_step=0.0134, train_loss_epoch=0.012]Epoch 105: Train Loss = 0.013443194329738617\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=322, train_loss_step=0.0114, train_loss_epoch=0.0134]Epoch 106: Train Loss = 0.011414577253162861\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=322, train_loss_step=0.0119, train_loss_epoch=0.0114]Epoch 107: Train Loss = 0.011920264922082424\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=322, train_loss_step=0.0103, train_loss_epoch=0.0119]Epoch 108: Train Loss = 0.010294587351381779\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=322, train_loss_step=0.0101, train_loss_epoch=0.0103]Epoch 109: Train Loss = 0.010117846541106701\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=322, train_loss_step=0.0148, train_loss_epoch=0.0101]Epoch 110: Train Loss = 0.014805733226239681\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=322, train_loss_step=0.0127, train_loss_epoch=0.0148]Epoch 111: Train Loss = 0.012694420292973518\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s, v_num=322, train_loss_step=0.013, train_loss_epoch=0.0127] Epoch 112: Train Loss = 0.013032023794949055\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=322, train_loss_step=0.0131, train_loss_epoch=0.013]Epoch 113: Train Loss = 0.013050486333668232\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=322, train_loss_step=0.00968, train_loss_epoch=0.0131]Epoch 114: Train Loss = 0.009680889546871185\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=322, train_loss_step=0.015, train_loss_epoch=0.00968]  Epoch 115: Train Loss = 0.014967919327318668\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=322, train_loss_step=0.0101, train_loss_epoch=0.015] Epoch 116: Train Loss = 0.010131875984370708\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=322, train_loss_step=0.0158, train_loss_epoch=0.0101]Epoch 117: Train Loss = 0.015811342746019363\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=322, train_loss_step=0.0123, train_loss_epoch=0.0158]Epoch 118: Train Loss = 0.012310607358813286\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.0123]Epoch 119: Train Loss = 0.012384961359202862\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 16.85it/s, v_num=322, train_loss_step=0.0154, train_loss_epoch=0.0124]Epoch 120: Train Loss = 0.015415380708873272\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.0154]Epoch 121: Train Loss = 0.010728283785283566\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=322, train_loss_step=0.013, train_loss_epoch=0.0107] Epoch 122: Train Loss = 0.01300797052681446\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=322, train_loss_step=0.0116, train_loss_epoch=0.013]Epoch 123: Train Loss = 0.011582501232624054\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 16.06it/s, v_num=322, train_loss_step=0.0116, train_loss_epoch=0.0116]Epoch 124: Train Loss = 0.011592714115977287\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=322, train_loss_step=0.0133, train_loss_epoch=0.0116]Epoch 125: Train Loss = 0.013303362764418125\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 16.57it/s, v_num=322, train_loss_step=0.0116, train_loss_epoch=0.0133]Epoch 126: Train Loss = 0.011585958302021027\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=322, train_loss_step=0.0152, train_loss_epoch=0.0116]Epoch 127: Train Loss = 0.015163947828114033\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=322, train_loss_step=0.0138, train_loss_epoch=0.0152]Epoch 128: Train Loss = 0.01375571545213461\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.0138]Epoch 129: Train Loss = 0.011303423903882504\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=322, train_loss_step=0.0164, train_loss_epoch=0.0113]Epoch 130: Train Loss = 0.01643538847565651\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 16.88it/s, v_num=322, train_loss_step=0.0166, train_loss_epoch=0.0164]Epoch 131: Train Loss = 0.016637809574604034\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.0166]Epoch 132: Train Loss = 0.011196090839803219\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=322, train_loss_step=0.0151, train_loss_epoch=0.0112]Epoch 133: Train Loss = 0.015075734816491604\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=322, train_loss_step=0.0111, train_loss_epoch=0.0151]Epoch 134: Train Loss = 0.011097774840891361\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=322, train_loss_step=0.0123, train_loss_epoch=0.0111]Epoch 135: Train Loss = 0.012348688207566738\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=322, train_loss_step=0.0139, train_loss_epoch=0.0123]Epoch 136: Train Loss = 0.013878458179533482\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.0139]Epoch 137: Train Loss = 0.011170804500579834\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=322, train_loss_step=0.00781, train_loss_epoch=0.0112]Epoch 138: Train Loss = 0.00781465508043766\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 11.26it/s, v_num=322, train_loss_step=0.0134, train_loss_epoch=0.00781] Epoch 139: Train Loss = 0.013351493515074253\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=322, train_loss_step=0.0133, train_loss_epoch=0.0134] Epoch 140: Train Loss = 0.01330467127263546\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=322, train_loss_step=0.0103, train_loss_epoch=0.0133]Epoch 141: Train Loss = 0.010315760038793087\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=322, train_loss_step=0.0145, train_loss_epoch=0.0103]Epoch 142: Train Loss = 0.014525329694151878\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=322, train_loss_step=0.0109, train_loss_epoch=0.0145]Epoch 143: Train Loss = 0.01088995672762394\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=322, train_loss_step=0.0149, train_loss_epoch=0.0109]Epoch 144: Train Loss = 0.014939791522920132\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, v_num=322, train_loss_step=0.0147, train_loss_epoch=0.0149]Epoch 145: Train Loss = 0.014699844643473625\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=322, train_loss_step=0.0117, train_loss_epoch=0.0147]Epoch 146: Train Loss = 0.011720702983438969\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s, v_num=322, train_loss_step=0.0156, train_loss_epoch=0.0117]Epoch 147: Train Loss = 0.01564817689359188\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=322, train_loss_step=0.00835, train_loss_epoch=0.0156]Epoch 148: Train Loss = 0.008352345786988735\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=322, train_loss_step=0.013, train_loss_epoch=0.00835]  Epoch 149: Train Loss = 0.013046669773757458\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=322, train_loss_step=0.0108, train_loss_epoch=0.013] Epoch 150: Train Loss = 0.010768929496407509\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, v_num=322, train_loss_step=0.0156, train_loss_epoch=0.0108]Epoch 151: Train Loss = 0.015616288408637047\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=322, train_loss_step=0.0181, train_loss_epoch=0.0156]Epoch 152: Train Loss = 0.018108436837792397\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 13.08it/s, v_num=322, train_loss_step=0.0131, train_loss_epoch=0.0181]Epoch 153: Train Loss = 0.013105650432407856\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=322, train_loss_step=0.0158, train_loss_epoch=0.0131]Epoch 154: Train Loss = 0.015751244500279427\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=322, train_loss_step=0.015, train_loss_epoch=0.0158] Epoch 155: Train Loss = 0.01502236258238554\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 13.60it/s, v_num=322, train_loss_step=0.0102, train_loss_epoch=0.015]Epoch 156: Train Loss = 0.010204792022705078\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s, v_num=322, train_loss_step=0.0196, train_loss_epoch=0.0102]Epoch 157: Train Loss = 0.019631236791610718\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=322, train_loss_step=0.0209, train_loss_epoch=0.0196]Epoch 158: Train Loss = 0.02094670757651329\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=322, train_loss_step=0.0132, train_loss_epoch=0.0209]Epoch 159: Train Loss = 0.013201725669205189\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=322, train_loss_step=0.0133, train_loss_epoch=0.0132]Epoch 160: Train Loss = 0.013308015652000904\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=322, train_loss_step=0.014, train_loss_epoch=0.0133] Epoch 161: Train Loss = 0.013951568864285946\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 13.76it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.014]Epoch 162: Train Loss = 0.012417295016348362\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=322, train_loss_step=0.0165, train_loss_epoch=0.0124]Epoch 163: Train Loss = 0.01647326722741127\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=322, train_loss_step=0.0111, train_loss_epoch=0.0165]Epoch 164: Train Loss = 0.01105706300586462\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=322, train_loss_step=0.0114, train_loss_epoch=0.0111]Epoch 165: Train Loss = 0.011399766430258751\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=322, train_loss_step=0.0148, train_loss_epoch=0.0114]Epoch 166: Train Loss = 0.014783449470996857\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, v_num=322, train_loss_step=0.013, train_loss_epoch=0.0148] Epoch 167: Train Loss = 0.013020326383411884\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=322, train_loss_step=0.0131, train_loss_epoch=0.013]Epoch 168: Train Loss = 0.013087590225040913\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 13.74it/s, v_num=322, train_loss_step=0.0159, train_loss_epoch=0.0131]Epoch 169: Train Loss = 0.015887105837464333\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=322, train_loss_step=0.0148, train_loss_epoch=0.0159]Epoch 170: Train Loss = 0.014759606681764126\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=322, train_loss_step=0.0151, train_loss_epoch=0.0148]Epoch 171: Train Loss = 0.015138009563088417\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, v_num=322, train_loss_step=0.0134, train_loss_epoch=0.0151]Epoch 172: Train Loss = 0.013369396328926086\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=322, train_loss_step=0.011, train_loss_epoch=0.0134] Epoch 173: Train Loss = 0.01102079451084137\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=322, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 174: Train Loss = 0.01248698215931654\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s, v_num=322, train_loss_step=0.0177, train_loss_epoch=0.0125]Epoch 175: Train Loss = 0.017675362527370453\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 13.75it/s, v_num=322, train_loss_step=0.0156, train_loss_epoch=0.0177]Epoch 176: Train Loss = 0.01563413254916668\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, v_num=322, train_loss_step=0.0147, train_loss_epoch=0.0156]Epoch 177: Train Loss = 0.014705793932080269\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=322, train_loss_step=0.0186, train_loss_epoch=0.0147]Epoch 178: Train Loss = 0.018626514822244644\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=322, train_loss_step=0.0139, train_loss_epoch=0.0186]Epoch 179: Train Loss = 0.013930981047451496\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=322, train_loss_step=0.0188, train_loss_epoch=0.0139]Epoch 180: Train Loss = 0.018780652433633804\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=322, train_loss_step=0.0126, train_loss_epoch=0.0188]Epoch 181: Train Loss = 0.012558617629110813\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.0126]Epoch 182: Train Loss = 0.011287079192698002\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=322, train_loss_step=0.011, train_loss_epoch=0.0113] Epoch 183: Train Loss = 0.010958775877952576\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=322, train_loss_step=0.0121, train_loss_epoch=0.011]Epoch 184: Train Loss = 0.012132811360061169\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=322, train_loss_step=0.0151, train_loss_epoch=0.0121]Epoch 185: Train Loss = 0.015134971588850021\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=322, train_loss_step=0.0198, train_loss_epoch=0.0151]Epoch 186: Train Loss = 0.019753189757466316\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=322, train_loss_step=0.0109, train_loss_epoch=0.0198]Epoch 187: Train Loss = 0.0108779426664114\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.0109]Epoch 188: Train Loss = 0.0123829897493124\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.0124] Epoch 189: Train Loss = 0.011956118047237396\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.012]Epoch 190: Train Loss = 0.011152828112244606\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=322, train_loss_step=0.0119, train_loss_epoch=0.0112]Epoch 191: Train Loss = 0.01188462134450674\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=322, train_loss_step=0.0155, train_loss_epoch=0.0119]Epoch 192: Train Loss = 0.015528857707977295\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=322, train_loss_step=0.0152, train_loss_epoch=0.0155]Epoch 193: Train Loss = 0.015217271633446217\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.0152]Epoch 194: Train Loss = 0.01131924707442522\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=322, train_loss_step=0.0135, train_loss_epoch=0.0113]Epoch 195: Train Loss = 0.01346669439226389\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=322, train_loss_step=0.0111, train_loss_epoch=0.0135]Epoch 196: Train Loss = 0.01112079806625843\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=322, train_loss_step=0.0148, train_loss_epoch=0.0111]Epoch 197: Train Loss = 0.014808588661253452\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=322, train_loss_step=0.0117, train_loss_epoch=0.0148]Epoch 198: Train Loss = 0.01168734859675169\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=322, train_loss_step=0.0127, train_loss_epoch=0.0117]Epoch 199: Train Loss = 0.012686332687735558\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=322, train_loss_step=0.0127, train_loss_epoch=0.0127]Epoch 200: Train Loss = 0.012683947570621967\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 201: Train Loss = 0.012009425088763237\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=322, train_loss_step=0.00818, train_loss_epoch=0.012]Epoch 202: Train Loss = 0.008181088604032993\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=322, train_loss_step=0.0141, train_loss_epoch=0.00818] Epoch 203: Train Loss = 0.014126279391348362\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.0141] Epoch 204: Train Loss = 0.012428692542016506\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=322, train_loss_step=0.0185, train_loss_epoch=0.0124]Epoch 205: Train Loss = 0.0184782762080431\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=322, train_loss_step=0.0136, train_loss_epoch=0.0185]Epoch 206: Train Loss = 0.013588184490799904\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=322, train_loss_step=0.0106, train_loss_epoch=0.0136]Epoch 207: Train Loss = 0.010580315254628658\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=322, train_loss_step=0.0144, train_loss_epoch=0.0106]Epoch 208: Train Loss = 0.014399145729839802\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=322, train_loss_step=0.0129, train_loss_epoch=0.0144]Epoch 209: Train Loss = 0.012906546704471111\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=322, train_loss_step=0.0151, train_loss_epoch=0.0129]Epoch 210: Train Loss = 0.015147535130381584\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=322, train_loss_step=0.0188, train_loss_epoch=0.0151]Epoch 211: Train Loss = 0.0187916848808527\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=322, train_loss_step=0.0103, train_loss_epoch=0.0188]Epoch 212: Train Loss = 0.010275918990373611\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=322, train_loss_step=0.0139, train_loss_epoch=0.0103]Epoch 213: Train Loss = 0.013937599025666714\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=322, train_loss_step=0.00925, train_loss_epoch=0.0139]Epoch 214: Train Loss = 0.009248552843928337\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=322, train_loss_step=0.0109, train_loss_epoch=0.00925] Epoch 215: Train Loss = 0.010876218788325787\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=322, train_loss_step=0.0129, train_loss_epoch=0.0109] Epoch 216: Train Loss = 0.012914014980196953\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=322, train_loss_step=0.0148, train_loss_epoch=0.0129]Epoch 217: Train Loss = 0.01484874077141285\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=322, train_loss_step=0.0102, train_loss_epoch=0.0148]Epoch 218: Train Loss = 0.010241529904305935\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=322, train_loss_step=0.0125, train_loss_epoch=0.0102]Epoch 219: Train Loss = 0.012524609453976154\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=322, train_loss_step=0.014, train_loss_epoch=0.0125] Epoch 220: Train Loss = 0.01399643998593092\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=322, train_loss_step=0.0137, train_loss_epoch=0.014]Epoch 221: Train Loss = 0.013671571388840675\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=322, train_loss_step=0.0155, train_loss_epoch=0.0137]Epoch 222: Train Loss = 0.01552627980709076\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=322, train_loss_step=0.0123, train_loss_epoch=0.0155]Epoch 223: Train Loss = 0.01232264656573534\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 13.09it/s, v_num=322, train_loss_step=0.0138, train_loss_epoch=0.0123]Epoch 224: Train Loss = 0.013795789331197739\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=322, train_loss_step=0.0105, train_loss_epoch=0.0138]Epoch 225: Train Loss = 0.0104972617700696\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=322, train_loss_step=0.0184, train_loss_epoch=0.0105]Epoch 226: Train Loss = 0.018422305583953857\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s, v_num=322, train_loss_step=0.0125, train_loss_epoch=0.0184]Epoch 227: Train Loss = 0.012465214356780052\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=322, train_loss_step=0.0127, train_loss_epoch=0.0125]Epoch 228: Train Loss = 0.012691430747509003\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.0127]Epoch 229: Train Loss = 0.010671259835362434\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=322, train_loss_step=0.016, train_loss_epoch=0.0107] Epoch 230: Train Loss = 0.0159766785800457\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=322, train_loss_step=0.0121, train_loss_epoch=0.016]Epoch 231: Train Loss = 0.012094470672309399\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=322, train_loss_step=0.0143, train_loss_epoch=0.0121]Epoch 232: Train Loss = 0.014253559522330761\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=322, train_loss_step=0.0123, train_loss_epoch=0.0143]Epoch 233: Train Loss = 0.0123000992462039\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=322, train_loss_step=0.0119, train_loss_epoch=0.0123]Epoch 234: Train Loss = 0.011947333812713623\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=322, train_loss_step=0.00934, train_loss_epoch=0.0119]Epoch 235: Train Loss = 0.009335505776107311\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=322, train_loss_step=0.015, train_loss_epoch=0.00934]  Epoch 236: Train Loss = 0.014951600693166256\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=322, train_loss_step=0.0136, train_loss_epoch=0.015] Epoch 237: Train Loss = 0.013605132699012756\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=322, train_loss_step=0.0103, train_loss_epoch=0.0136]Epoch 238: Train Loss = 0.010301170870661736\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=322, train_loss_step=0.0114, train_loss_epoch=0.0103]Epoch 239: Train Loss = 0.011384882964193821\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s, v_num=322, train_loss_step=0.0119, train_loss_epoch=0.0114]Epoch 240: Train Loss = 0.011893468908965588\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.0119] Epoch 241: Train Loss = 0.011961913667619228\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=322, train_loss_step=0.0144, train_loss_epoch=0.012]Epoch 242: Train Loss = 0.014427194371819496\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=322, train_loss_step=0.0126, train_loss_epoch=0.0144]Epoch 243: Train Loss = 0.012571415863931179\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=322, train_loss_step=0.0111, train_loss_epoch=0.0126]Epoch 244: Train Loss = 0.011101932264864445\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=322, train_loss_step=0.0108, train_loss_epoch=0.0111]Epoch 245: Train Loss = 0.01076545286923647\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=322, train_loss_step=0.0093, train_loss_epoch=0.0108]Epoch 246: Train Loss = 0.009304161183536053\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=322, train_loss_step=0.0146, train_loss_epoch=0.0093]Epoch 247: Train Loss = 0.014598975889384747\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=322, train_loss_step=0.0152, train_loss_epoch=0.0146]Epoch 248: Train Loss = 0.015172943472862244\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=322, train_loss_step=0.00839, train_loss_epoch=0.0152]Epoch 249: Train Loss = 0.008391505107283592\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=322, train_loss_step=0.00974, train_loss_epoch=0.00839]Epoch 250: Train Loss = 0.009739122353494167\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=322, train_loss_step=0.0116, train_loss_epoch=0.00974] Epoch 251: Train Loss = 0.011572173796594143\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 12.86it/s, v_num=322, train_loss_step=0.016, train_loss_epoch=0.0116]  Epoch 252: Train Loss = 0.016018623486161232\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=322, train_loss_step=0.0134, train_loss_epoch=0.016]Epoch 253: Train Loss = 0.0133733619004488\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=322, train_loss_step=0.0137, train_loss_epoch=0.0134]Epoch 254: Train Loss = 0.013740436173975468\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=322, train_loss_step=0.0165, train_loss_epoch=0.0137]Epoch 255: Train Loss = 0.016497211530804634\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.0165]Epoch 256: Train Loss = 0.012442012317478657\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=322, train_loss_step=0.0108, train_loss_epoch=0.0124]Epoch 257: Train Loss = 0.010767163708806038\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=322, train_loss_step=0.0126, train_loss_epoch=0.0108]Epoch 258: Train Loss = 0.012648137286305428\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.0126]Epoch 259: Train Loss = 0.010669739916920662\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=322, train_loss_step=0.011, train_loss_epoch=0.0107] Epoch 260: Train Loss = 0.011035701259970665\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.011]Epoch 261: Train Loss = 0.012362443841993809\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=322, train_loss_step=0.0104, train_loss_epoch=0.0124]Epoch 262: Train Loss = 0.010439319536089897\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=322, train_loss_step=0.0139, train_loss_epoch=0.0104]Epoch 263: Train Loss = 0.0138736916705966\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=322, train_loss_step=0.0145, train_loss_epoch=0.0139]Epoch 264: Train Loss = 0.014459810219705105\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=322, train_loss_step=0.0135, train_loss_epoch=0.0145]Epoch 265: Train Loss = 0.013476903550326824\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=322, train_loss_step=0.0137, train_loss_epoch=0.0135]Epoch 266: Train Loss = 0.013745003379881382\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=322, train_loss_step=0.014, train_loss_epoch=0.0137] Epoch 267: Train Loss = 0.013956737704575062\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.014]Epoch 268: Train Loss = 0.012356863357126713\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=322, train_loss_step=0.0114, train_loss_epoch=0.0124]Epoch 269: Train Loss = 0.011406208388507366\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.0114]Epoch 270: Train Loss = 0.011183495633304119\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=322, train_loss_step=0.0133, train_loss_epoch=0.0112]Epoch 271: Train Loss = 0.013288150541484356\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=322, train_loss_step=0.00989, train_loss_epoch=0.0133]Epoch 272: Train Loss = 0.009890939109027386\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=322, train_loss_step=0.0125, train_loss_epoch=0.00989] Epoch 273: Train Loss = 0.012461557984352112\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=322, train_loss_step=0.013, train_loss_epoch=0.0125]  Epoch 274: Train Loss = 0.013006321154534817\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=322, train_loss_step=0.00981, train_loss_epoch=0.013]Epoch 275: Train Loss = 0.009806901216506958\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=322, train_loss_step=0.0164, train_loss_epoch=0.00981] Epoch 276: Train Loss = 0.016439421102404594\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.0164] Epoch 277: Train Loss = 0.01067246962338686\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=322, train_loss_step=0.0119, train_loss_epoch=0.0107]Epoch 278: Train Loss = 0.011949262581765652\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 12.67it/s, v_num=322, train_loss_step=0.0137, train_loss_epoch=0.0119]Epoch 279: Train Loss = 0.013727187179028988\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=322, train_loss_step=0.0116, train_loss_epoch=0.0137]Epoch 280: Train Loss = 0.011586049571633339\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=322, train_loss_step=0.0151, train_loss_epoch=0.0116]Epoch 281: Train Loss = 0.015144214034080505\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, v_num=322, train_loss_step=0.0111, train_loss_epoch=0.0151]Epoch 282: Train Loss = 0.011118858121335506\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.0111] Epoch 283: Train Loss = 0.012013465166091919\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=322, train_loss_step=0.0126, train_loss_epoch=0.012]Epoch 284: Train Loss = 0.012565914541482925\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.0126] Epoch 285: Train Loss = 0.012008965946733952\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s, v_num=322, train_loss_step=0.0158, train_loss_epoch=0.012]Epoch 286: Train Loss = 0.0157549437135458\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=322, train_loss_step=0.017, train_loss_epoch=0.0158] Epoch 287: Train Loss = 0.017033744603395462\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=322, train_loss_step=0.011, train_loss_epoch=0.017] Epoch 288: Train Loss = 0.011000566184520721\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 12.91it/s, v_num=322, train_loss_step=0.014, train_loss_epoch=0.011]Epoch 289: Train Loss = 0.013957791030406952\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=322, train_loss_step=0.0106, train_loss_epoch=0.014]Epoch 290: Train Loss = 0.01064280141144991\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=322, train_loss_step=0.0083, train_loss_epoch=0.0106]Epoch 291: Train Loss = 0.008300509303808212\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=322, train_loss_step=0.0129, train_loss_epoch=0.0083]Epoch 292: Train Loss = 0.012880581431090832\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=322, train_loss_step=0.0159, train_loss_epoch=0.0129]Epoch 293: Train Loss = 0.015946922823786736\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=322, train_loss_step=0.0109, train_loss_epoch=0.0159]Epoch 294: Train Loss = 0.010880711488425732\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=322, train_loss_step=0.0143, train_loss_epoch=0.0109]Epoch 295: Train Loss = 0.014255547896027565\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=322, train_loss_step=0.0118, train_loss_epoch=0.0143]Epoch 296: Train Loss = 0.011807980947196484\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=322, train_loss_step=0.0192, train_loss_epoch=0.0118]Epoch 297: Train Loss = 0.019188130274415016\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=322, train_loss_step=0.00913, train_loss_epoch=0.0192]Epoch 298: Train Loss = 0.009126082062721252\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.00913] Epoch 299: Train Loss = 0.010675976984202862\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=322, train_loss_step=0.00967, train_loss_epoch=0.0107]Epoch 300: Train Loss = 0.00966740120202303\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.00967] Epoch 301: Train Loss = 0.011199360713362694\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=322, train_loss_step=0.0152, train_loss_epoch=0.0112] Epoch 302: Train Loss = 0.015154815278947353\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=322, train_loss_step=0.015, train_loss_epoch=0.0152] Epoch 303: Train Loss = 0.014960040338337421\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=322, train_loss_step=0.0109, train_loss_epoch=0.015]Epoch 304: Train Loss = 0.010886992327868938\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.0109]Epoch 305: Train Loss = 0.011204106733202934\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.0112]Epoch 306: Train Loss = 0.010749658569693565\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=322, train_loss_step=0.0147, train_loss_epoch=0.0107]Epoch 307: Train Loss = 0.014736867509782314\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=322, train_loss_step=0.0138, train_loss_epoch=0.0147]Epoch 308: Train Loss = 0.013754264451563358\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=322, train_loss_step=0.0125, train_loss_epoch=0.0138]Epoch 309: Train Loss = 0.012526596896350384\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.0125]Epoch 310: Train Loss = 0.011203302070498466\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=322, train_loss_step=0.0157, train_loss_epoch=0.0112]Epoch 311: Train Loss = 0.01572314463555813\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=322, train_loss_step=0.00801, train_loss_epoch=0.0157]Epoch 312: Train Loss = 0.008013324812054634\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=322, train_loss_step=0.0169, train_loss_epoch=0.00801] Epoch 313: Train Loss = 0.016938956454396248\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=322, train_loss_step=0.0153, train_loss_epoch=0.0169] Epoch 314: Train Loss = 0.015281389467418194\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=322, train_loss_step=0.0105, train_loss_epoch=0.0153]Epoch 315: Train Loss = 0.010525870136916637\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=322, train_loss_step=0.013, train_loss_epoch=0.0105] Epoch 316: Train Loss = 0.013042546808719635\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=322, train_loss_step=0.0139, train_loss_epoch=0.013]Epoch 317: Train Loss = 0.013874730095267296\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=322, train_loss_step=0.0115, train_loss_epoch=0.0139]Epoch 318: Train Loss = 0.01152911689132452\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=322, train_loss_step=0.0165, train_loss_epoch=0.0115]Epoch 319: Train Loss = 0.016505666077136993\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=322, train_loss_step=0.0133, train_loss_epoch=0.0165]Epoch 320: Train Loss = 0.013270950876176357\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=322, train_loss_step=0.0103, train_loss_epoch=0.0133]Epoch 321: Train Loss = 0.010301330126821995\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=322, train_loss_step=0.0111, train_loss_epoch=0.0103]Epoch 322: Train Loss = 0.011108349077403545\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=322, train_loss_step=0.0114, train_loss_epoch=0.0111]Epoch 323: Train Loss = 0.011370123364031315\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=322, train_loss_step=0.0137, train_loss_epoch=0.0114]Epoch 324: Train Loss = 0.013737574219703674\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=322, train_loss_step=0.0121, train_loss_epoch=0.0137]Epoch 325: Train Loss = 0.012114315293729305\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=322, train_loss_step=0.0109, train_loss_epoch=0.0121]Epoch 326: Train Loss = 0.010923989117145538\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=322, train_loss_step=0.0109, train_loss_epoch=0.0109]Epoch 327: Train Loss = 0.010859781876206398\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=322, train_loss_step=0.011, train_loss_epoch=0.0109] Epoch 328: Train Loss = 0.010967935435473919\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=322, train_loss_step=0.0136, train_loss_epoch=0.011]Epoch 329: Train Loss = 0.013562074862420559\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=322, train_loss_step=0.0136, train_loss_epoch=0.0136]Epoch 330: Train Loss = 0.013551993295550346\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=322, train_loss_step=0.0136, train_loss_epoch=0.0136]Epoch 331: Train Loss = 0.013626238331198692\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=322, train_loss_step=0.0141, train_loss_epoch=0.0136]Epoch 332: Train Loss = 0.014102439396083355\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=322, train_loss_step=0.014, train_loss_epoch=0.0141] Epoch 333: Train Loss = 0.013980657793581486\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=322, train_loss_step=0.0108, train_loss_epoch=0.014]Epoch 334: Train Loss = 0.010826281271874905\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=322, train_loss_step=0.0176, train_loss_epoch=0.0108]Epoch 335: Train Loss = 0.01758861169219017\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.0176]Epoch 336: Train Loss = 0.012439688667654991\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.0124]Epoch 337: Train Loss = 0.01134171150624752\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=322, train_loss_step=0.0148, train_loss_epoch=0.0113]Epoch 338: Train Loss = 0.014834352768957615\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=322, train_loss_step=0.010, train_loss_epoch=0.0148] Epoch 339: Train Loss = 0.01002112589776516\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=322, train_loss_step=0.0103, train_loss_epoch=0.010]Epoch 340: Train Loss = 0.010252703912556171\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=322, train_loss_step=0.017, train_loss_epoch=0.0103] Epoch 341: Train Loss = 0.017035866156220436\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.017]Epoch 342: Train Loss = 0.01133063156157732\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.0113] Epoch 343: Train Loss = 0.01202437374740839\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=322, train_loss_step=0.0162, train_loss_epoch=0.012]Epoch 344: Train Loss = 0.016239231452345848\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=322, train_loss_step=0.0152, train_loss_epoch=0.0162]Epoch 345: Train Loss = 0.015165380202233791\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=322, train_loss_step=0.0136, train_loss_epoch=0.0152]Epoch 346: Train Loss = 0.013637865893542767\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=322, train_loss_step=0.0151, train_loss_epoch=0.0136]Epoch 347: Train Loss = 0.015136240981519222\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=322, train_loss_step=0.011, train_loss_epoch=0.0151] Epoch 348: Train Loss = 0.011000027880072594\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=322, train_loss_step=0.0176, train_loss_epoch=0.011]Epoch 349: Train Loss = 0.01763247326016426\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=322, train_loss_step=0.0143, train_loss_epoch=0.0176]Epoch 350: Train Loss = 0.014312108978629112\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.0143]Epoch 351: Train Loss = 0.010661310516297817\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=322, train_loss_step=0.013, train_loss_epoch=0.0107] Epoch 352: Train Loss = 0.012991365976631641\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=322, train_loss_step=0.0173, train_loss_epoch=0.013]Epoch 353: Train Loss = 0.017303461208939552\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=322, train_loss_step=0.0128, train_loss_epoch=0.0173]Epoch 354: Train Loss = 0.012843556702136993\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=322, train_loss_step=0.015, train_loss_epoch=0.0128] Epoch 355: Train Loss = 0.01498888898640871\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.015]Epoch 356: Train Loss = 0.01122727245092392\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=322, train_loss_step=0.011, train_loss_epoch=0.0112] Epoch 357: Train Loss = 0.011028815992176533\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=322, train_loss_step=0.0127, train_loss_epoch=0.011]Epoch 358: Train Loss = 0.012731075286865234\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=322, train_loss_step=0.0105, train_loss_epoch=0.0127]Epoch 359: Train Loss = 0.010517103597521782\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=322, train_loss_step=0.0103, train_loss_epoch=0.0105]Epoch 360: Train Loss = 0.010311109013855457\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=322, train_loss_step=0.0128, train_loss_epoch=0.0103]Epoch 361: Train Loss = 0.01278300117701292\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=322, train_loss_step=0.00984, train_loss_epoch=0.0128]Epoch 362: Train Loss = 0.009838348254561424\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=322, train_loss_step=0.0122, train_loss_epoch=0.00984] Epoch 363: Train Loss = 0.012157835997641087\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=322, train_loss_step=0.0102, train_loss_epoch=0.0122] Epoch 364: Train Loss = 0.010171359404921532\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=322, train_loss_step=0.0106, train_loss_epoch=0.0102]Epoch 365: Train Loss = 0.01055095437914133\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=322, train_loss_step=0.010, train_loss_epoch=0.0106] Epoch 366: Train Loss = 0.010005885735154152\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.010]Epoch 367: Train Loss = 0.01239387784153223\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=322, train_loss_step=0.0132, train_loss_epoch=0.0124]Epoch 368: Train Loss = 0.013215750455856323\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=322, train_loss_step=0.0114, train_loss_epoch=0.0132]Epoch 369: Train Loss = 0.011401238851249218\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=322, train_loss_step=0.0144, train_loss_epoch=0.0114]Epoch 370: Train Loss = 0.014427763409912586\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=322, train_loss_step=0.00946, train_loss_epoch=0.0144]Epoch 371: Train Loss = 0.00946009811013937\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=322, train_loss_step=0.0117, train_loss_epoch=0.00946] Epoch 372: Train Loss = 0.011686659418046474\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=322, train_loss_step=0.0111, train_loss_epoch=0.0117] Epoch 373: Train Loss = 0.011123837903141975\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=322, train_loss_step=0.0129, train_loss_epoch=0.0111]Epoch 374: Train Loss = 0.012879959307610989\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=322, train_loss_step=0.0123, train_loss_epoch=0.0129]Epoch 375: Train Loss = 0.012346561066806316\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=322, train_loss_step=0.0101, train_loss_epoch=0.0123]Epoch 376: Train Loss = 0.01012295950204134\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=322, train_loss_step=0.00953, train_loss_epoch=0.0101]Epoch 377: Train Loss = 0.009526519104838371\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=322, train_loss_step=0.0183, train_loss_epoch=0.00953] Epoch 378: Train Loss = 0.018281886354088783\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.0183]  Epoch 379: Train Loss = 0.012043475173413754\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=322, train_loss_step=0.0136, train_loss_epoch=0.012]Epoch 380: Train Loss = 0.01364167034626007\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=322, train_loss_step=0.0151, train_loss_epoch=0.0136]Epoch 381: Train Loss = 0.015072762966156006\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=322, train_loss_step=0.0103, train_loss_epoch=0.0151]Epoch 382: Train Loss = 0.010300573892891407\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=322, train_loss_step=0.0166, train_loss_epoch=0.0103]Epoch 383: Train Loss = 0.01662895642220974\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=322, train_loss_step=0.0117, train_loss_epoch=0.0166]Epoch 384: Train Loss = 0.011697947047650814\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=322, train_loss_step=0.0101, train_loss_epoch=0.0117]Epoch 385: Train Loss = 0.010129464790225029\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=322, train_loss_step=0.0146, train_loss_epoch=0.0101]Epoch 386: Train Loss = 0.014647146686911583\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=322, train_loss_step=0.0101, train_loss_epoch=0.0146]Epoch 387: Train Loss = 0.010069427080452442\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=322, train_loss_step=0.013, train_loss_epoch=0.0101] Epoch 388: Train Loss = 0.012961923144757748\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=322, train_loss_step=0.0168, train_loss_epoch=0.013]Epoch 389: Train Loss = 0.016783500090241432\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.0168]Epoch 390: Train Loss = 0.011259499005973339\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=322, train_loss_step=0.0119, train_loss_epoch=0.0113]Epoch 391: Train Loss = 0.01187842059880495\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=322, train_loss_step=0.0105, train_loss_epoch=0.0119]Epoch 392: Train Loss = 0.010489562526345253\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 10.30it/s, v_num=322, train_loss_step=0.0148, train_loss_epoch=0.0105]Epoch 393: Train Loss = 0.014763777144253254\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=322, train_loss_step=0.0156, train_loss_epoch=0.0148]Epoch 394: Train Loss = 0.015601256862282753\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.0156]Epoch 395: Train Loss = 0.010686117224395275\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.0107]Epoch 396: Train Loss = 0.011343149468302727\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=322, train_loss_step=0.0171, train_loss_epoch=0.0113]Epoch 397: Train Loss = 0.017104806378483772\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=322, train_loss_step=0.0109, train_loss_epoch=0.0171]Epoch 398: Train Loss = 0.010910450480878353\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=322, train_loss_step=0.0132, train_loss_epoch=0.0109]Epoch 399: Train Loss = 0.013247780501842499\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=322, train_loss_step=0.0141, train_loss_epoch=0.0132]Epoch 400: Train Loss = 0.014123239554464817\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=322, train_loss_step=0.0128, train_loss_epoch=0.0141]Epoch 401: Train Loss = 0.012792820110917091\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=322, train_loss_step=0.0121, train_loss_epoch=0.0128]Epoch 402: Train Loss = 0.012137477286159992\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=322, train_loss_step=0.0105, train_loss_epoch=0.0121]Epoch 403: Train Loss = 0.0104947779327631\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.0105]Epoch 404: Train Loss = 0.011167340911924839\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=322, train_loss_step=0.0136, train_loss_epoch=0.0112]Epoch 405: Train Loss = 0.01359492540359497\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=322, train_loss_step=0.0149, train_loss_epoch=0.0136]Epoch 406: Train Loss = 0.014853800646960735\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=322, train_loss_step=0.015, train_loss_epoch=0.0149] Epoch 407: Train Loss = 0.015022240579128265\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=322, train_loss_step=0.0124, train_loss_epoch=0.015]Epoch 408: Train Loss = 0.012402052991092205\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=322, train_loss_step=0.0164, train_loss_epoch=0.0124]Epoch 409: Train Loss = 0.016445240005850792\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=322, train_loss_step=0.00842, train_loss_epoch=0.0164]Epoch 410: Train Loss = 0.008424170315265656\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=322, train_loss_step=0.0129, train_loss_epoch=0.00842] Epoch 411: Train Loss = 0.012904686853289604\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=322, train_loss_step=0.0115, train_loss_epoch=0.0129] Epoch 412: Train Loss = 0.01151401549577713\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.0115]Epoch 413: Train Loss = 0.011199587024748325\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=322, train_loss_step=0.0168, train_loss_epoch=0.0112]Epoch 414: Train Loss = 0.016756808385252953\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=322, train_loss_step=0.0137, train_loss_epoch=0.0168]Epoch 415: Train Loss = 0.01373523660004139\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s, v_num=322, train_loss_step=0.0145, train_loss_epoch=0.0137]Epoch 416: Train Loss = 0.01451061014086008\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=322, train_loss_step=0.0114, train_loss_epoch=0.0145]Epoch 417: Train Loss = 0.011437884531915188\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=322, train_loss_step=0.0137, train_loss_epoch=0.0114]Epoch 418: Train Loss = 0.01368369348347187\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=322, train_loss_step=0.0112, train_loss_epoch=0.0137]Epoch 419: Train Loss = 0.011190016753971577\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=322, train_loss_step=0.0159, train_loss_epoch=0.0112]Epoch 420: Train Loss = 0.015931962057948112\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=322, train_loss_step=0.0193, train_loss_epoch=0.0159]Epoch 421: Train Loss = 0.019300060346722603\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=322, train_loss_step=0.0135, train_loss_epoch=0.0193]Epoch 422: Train Loss = 0.013544331304728985\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=322, train_loss_step=0.0171, train_loss_epoch=0.0135]Epoch 423: Train Loss = 0.01708834432065487\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=322, train_loss_step=0.0133, train_loss_epoch=0.0171]Epoch 424: Train Loss = 0.013255774974822998\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=322, train_loss_step=0.0121, train_loss_epoch=0.0133]Epoch 425: Train Loss = 0.01205592043697834\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=322, train_loss_step=0.0104, train_loss_epoch=0.0121]Epoch 426: Train Loss = 0.01040799729526043\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=322, train_loss_step=0.0093, train_loss_epoch=0.0104]Epoch 427: Train Loss = 0.009303904138505459\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=322, train_loss_step=0.0136, train_loss_epoch=0.0093]Epoch 428: Train Loss = 0.013617600314319134\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=322, train_loss_step=0.0121, train_loss_epoch=0.0136]Epoch 429: Train Loss = 0.012124232947826385\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=322, train_loss_step=0.0142, train_loss_epoch=0.0121]Epoch 430: Train Loss = 0.01415021251887083\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=322, train_loss_step=0.0106, train_loss_epoch=0.0142]Epoch 431: Train Loss = 0.010571790859103203\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=322, train_loss_step=0.0122, train_loss_epoch=0.0106]Epoch 432: Train Loss = 0.012248897925019264\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.0122]Epoch 433: Train Loss = 0.010720387101173401\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=322, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 434: Train Loss = 0.01160311046987772\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=322, train_loss_step=0.0118, train_loss_epoch=0.0116]Epoch 435: Train Loss = 0.011827943846583366\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=322, train_loss_step=0.0125, train_loss_epoch=0.0118]Epoch 436: Train Loss = 0.012527343817055225\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=322, train_loss_step=0.0148, train_loss_epoch=0.0125]Epoch 437: Train Loss = 0.014791659079492092\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=322, train_loss_step=0.0115, train_loss_epoch=0.0148]Epoch 438: Train Loss = 0.011485463939607143\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.0115]Epoch 439: Train Loss = 0.01072599459439516\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=322, train_loss_step=0.0125, train_loss_epoch=0.0107]Epoch 440: Train Loss = 0.01248482707887888\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=322, train_loss_step=0.010, train_loss_epoch=0.0125] Epoch 441: Train Loss = 0.010014498606324196\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=322, train_loss_step=0.0105, train_loss_epoch=0.010]Epoch 442: Train Loss = 0.01049641240388155\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=322, train_loss_step=0.0121, train_loss_epoch=0.0105]Epoch 443: Train Loss = 0.01214575581252575\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=322, train_loss_step=0.0116, train_loss_epoch=0.0121]Epoch 444: Train Loss = 0.011644599959254265\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=322, train_loss_step=0.0132, train_loss_epoch=0.0116]Epoch 445: Train Loss = 0.013207763433456421\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=322, train_loss_step=0.0146, train_loss_epoch=0.0132]Epoch 446: Train Loss = 0.014628319069743156\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=322, train_loss_step=0.00873, train_loss_epoch=0.0146]Epoch 447: Train Loss = 0.008726341649889946\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.00873] Epoch 448: Train Loss = 0.01131602842360735\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=322, train_loss_step=0.0121, train_loss_epoch=0.0113] Epoch 449: Train Loss = 0.012126832269132137\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=322, train_loss_step=0.0129, train_loss_epoch=0.0121]Epoch 450: Train Loss = 0.012892699800431728\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=322, train_loss_step=0.0111, train_loss_epoch=0.0129]Epoch 451: Train Loss = 0.011100533418357372\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.0111]Epoch 452: Train Loss = 0.011288115754723549\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=322, train_loss_step=0.0134, train_loss_epoch=0.0113]Epoch 453: Train Loss = 0.013352824375033379\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 11.30it/s, v_num=322, train_loss_step=0.0103, train_loss_epoch=0.0134]Epoch 454: Train Loss = 0.010306536220014095\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=322, train_loss_step=0.0125, train_loss_epoch=0.0103]Epoch 455: Train Loss = 0.012542792595922947\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=322, train_loss_step=0.0126, train_loss_epoch=0.0125]Epoch 456: Train Loss = 0.01255884487181902\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=322, train_loss_step=0.010, train_loss_epoch=0.0126] Epoch 457: Train Loss = 0.010001743212342262\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=322, train_loss_step=0.00975, train_loss_epoch=0.010]Epoch 458: Train Loss = 0.009751440025866032\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=322, train_loss_step=0.0105, train_loss_epoch=0.00975] Epoch 459: Train Loss = 0.010464368388056755\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=322, train_loss_step=0.0127, train_loss_epoch=0.0105] Epoch 460: Train Loss = 0.012743508443236351\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=322, train_loss_step=0.018, train_loss_epoch=0.0127] Epoch 461: Train Loss = 0.017953360453248024\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=322, train_loss_step=0.012, train_loss_epoch=0.018] Epoch 462: Train Loss = 0.011957709677517414\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=322, train_loss_step=0.0113, train_loss_epoch=0.012]Epoch 463: Train Loss = 0.011288569308817387\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=322, train_loss_step=0.0088, train_loss_epoch=0.0113]Epoch 464: Train Loss = 0.008803563192486763\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=322, train_loss_step=0.00969, train_loss_epoch=0.0088]Epoch 465: Train Loss = 0.009687659330666065\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=322, train_loss_step=0.0141, train_loss_epoch=0.00969] Epoch 466: Train Loss = 0.014051763340830803\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=322, train_loss_step=0.0153, train_loss_epoch=0.0141] Epoch 467: Train Loss = 0.015324409119784832\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=322, train_loss_step=0.0105, train_loss_epoch=0.0153]Epoch 468: Train Loss = 0.010481131263077259\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=322, train_loss_step=0.0209, train_loss_epoch=0.0105]Epoch 469: Train Loss = 0.020888999104499817\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=322, train_loss_step=0.0125, train_loss_epoch=0.0209]Epoch 470: Train Loss = 0.012464039959013462\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=322, train_loss_step=0.015, train_loss_epoch=0.0125] Epoch 471: Train Loss = 0.014952338300645351\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=322, train_loss_step=0.0127, train_loss_epoch=0.015]Epoch 472: Train Loss = 0.01269717700779438\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=322, train_loss_step=0.0148, train_loss_epoch=0.0127]Epoch 473: Train Loss = 0.014809670858085155\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=322, train_loss_step=0.00991, train_loss_epoch=0.0148]Epoch 474: Train Loss = 0.009913484565913677\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=322, train_loss_step=0.0157, train_loss_epoch=0.00991] Epoch 475: Train Loss = 0.015696244314312935\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=322, train_loss_step=0.0106, train_loss_epoch=0.0157] Epoch 476: Train Loss = 0.01064830832183361\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=322, train_loss_step=0.0131, train_loss_epoch=0.0106]Epoch 477: Train Loss = 0.013058618642389774\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=322, train_loss_step=0.0122, train_loss_epoch=0.0131]Epoch 478: Train Loss = 0.012154408730566502\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=322, train_loss_step=0.00889, train_loss_epoch=0.0122]Epoch 479: Train Loss = 0.008886443451046944\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=322, train_loss_step=0.0111, train_loss_epoch=0.00889] Epoch 480: Train Loss = 0.01106868777424097\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=322, train_loss_step=0.0142, train_loss_epoch=0.0111] Epoch 481: Train Loss = 0.014166394248604774\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=322, train_loss_step=0.00923, train_loss_epoch=0.0142]Epoch 482: Train Loss = 0.009226890280842781\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=322, train_loss_step=0.0152, train_loss_epoch=0.00923] Epoch 483: Train Loss = 0.015234602615237236\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=322, train_loss_step=0.0135, train_loss_epoch=0.0152] Epoch 484: Train Loss = 0.013451317325234413\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=322, train_loss_step=0.00881, train_loss_epoch=0.0135]Epoch 485: Train Loss = 0.008809814229607582\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=322, train_loss_step=0.0133, train_loss_epoch=0.00881] Epoch 486: Train Loss = 0.013310394249856472\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=322, train_loss_step=0.00958, train_loss_epoch=0.0133]Epoch 487: Train Loss = 0.009583628736436367\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.00958] Epoch 488: Train Loss = 0.01069908682256937\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=322, train_loss_step=0.0121, train_loss_epoch=0.0107] Epoch 489: Train Loss = 0.01213863305747509\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=322, train_loss_step=0.0155, train_loss_epoch=0.0121]Epoch 490: Train Loss = 0.015541826374828815\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=322, train_loss_step=0.0107, train_loss_epoch=0.0155]Epoch 491: Train Loss = 0.010680385865271091\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=322, train_loss_step=0.0108, train_loss_epoch=0.0107]Epoch 492: Train Loss = 0.010775883682072163\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=322, train_loss_step=0.00998, train_loss_epoch=0.0108]Epoch 493: Train Loss = 0.00998293049633503\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=322, train_loss_step=0.0138, train_loss_epoch=0.00998] Epoch 494: Train Loss = 0.013818091712892056\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s, v_num=322, train_loss_step=0.010, train_loss_epoch=0.0138]  Epoch 495: Train Loss = 0.01002459041774273\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=322, train_loss_step=0.00995, train_loss_epoch=0.010]Epoch 496: Train Loss = 0.00994755420833826\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=322, train_loss_step=0.0108, train_loss_epoch=0.00995] Epoch 497: Train Loss = 0.010780957527458668\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=322, train_loss_step=0.0119, train_loss_epoch=0.0108] Epoch 498: Train Loss = 0.011947616934776306\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=322, train_loss_step=0.0106, train_loss_epoch=0.0119]Epoch 499: Train Loss = 0.010567739605903625\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=322, train_loss_step=0.0106, train_loss_epoch=0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=322, train_loss_step=0.0106, train_loss_epoch=0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 10: from 2010-06-30 00:00:00 to 2022-09-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=324, train_loss_step=0.0281]Epoch 0: Train Loss = 0.028127068653702736\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=324, train_loss_step=0.0429, train_loss_epoch=0.0281]Epoch 1: Train Loss = 0.04290440306067467\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=324, train_loss_step=0.0294, train_loss_epoch=0.0429]Epoch 2: Train Loss = 0.02937188558280468\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=324, train_loss_step=0.0166, train_loss_epoch=0.0294]Epoch 3: Train Loss = 0.016563482582569122\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s, v_num=324, train_loss_step=0.0175, train_loss_epoch=0.0166]Epoch 4: Train Loss = 0.01745137944817543\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=324, train_loss_step=0.0198, train_loss_epoch=0.0175]Epoch 5: Train Loss = 0.019801491871476173\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=324, train_loss_step=0.0148, train_loss_epoch=0.0198]Epoch 6: Train Loss = 0.014801306650042534\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=324, train_loss_step=0.0137, train_loss_epoch=0.0148]Epoch 7: Train Loss = 0.013708768412470818\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=324, train_loss_step=0.0225, train_loss_epoch=0.0137]Epoch 8: Train Loss = 0.022525900974869728\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=324, train_loss_step=0.0185, train_loss_epoch=0.0225]Epoch 9: Train Loss = 0.01848926767706871\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=324, train_loss_step=0.0143, train_loss_epoch=0.0185]Epoch 10: Train Loss = 0.014293096028268337\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=324, train_loss_step=0.0146, train_loss_epoch=0.0143]Epoch 11: Train Loss = 0.014566555619239807\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=324, train_loss_step=0.0205, train_loss_epoch=0.0146]Epoch 12: Train Loss = 0.0205368809401989\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s, v_num=324, train_loss_step=0.0163, train_loss_epoch=0.0205]Epoch 13: Train Loss = 0.016270514577627182\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=324, train_loss_step=0.0172, train_loss_epoch=0.0163]Epoch 14: Train Loss = 0.017163926735520363\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=324, train_loss_step=0.0157, train_loss_epoch=0.0172]Epoch 15: Train Loss = 0.015718387439846992\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=324, train_loss_step=0.0159, train_loss_epoch=0.0157]Epoch 16: Train Loss = 0.015937168151140213\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=324, train_loss_step=0.0173, train_loss_epoch=0.0159]Epoch 17: Train Loss = 0.01729995384812355\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=324, train_loss_step=0.018, train_loss_epoch=0.0173] Epoch 18: Train Loss = 0.01798251084983349\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=324, train_loss_step=0.0203, train_loss_epoch=0.018]Epoch 19: Train Loss = 0.02027118392288685\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=324, train_loss_step=0.014, train_loss_epoch=0.0203] Epoch 20: Train Loss = 0.01397186703979969\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=324, train_loss_step=0.0155, train_loss_epoch=0.014]Epoch 21: Train Loss = 0.015453280881047249\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=324, train_loss_step=0.0134, train_loss_epoch=0.0155]Epoch 22: Train Loss = 0.013444810174405575\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=324, train_loss_step=0.0238, train_loss_epoch=0.0134]Epoch 23: Train Loss = 0.023842958733439445\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=324, train_loss_step=0.0156, train_loss_epoch=0.0238]Epoch 24: Train Loss = 0.015564807690680027\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=324, train_loss_step=0.0165, train_loss_epoch=0.0156]Epoch 25: Train Loss = 0.01651141420006752\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=324, train_loss_step=0.0109, train_loss_epoch=0.0165]Epoch 26: Train Loss = 0.010906289331614971\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=324, train_loss_step=0.0177, train_loss_epoch=0.0109]Epoch 27: Train Loss = 0.017723441123962402\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=324, train_loss_step=0.0149, train_loss_epoch=0.0177]Epoch 28: Train Loss = 0.014884146861732006\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=324, train_loss_step=0.0152, train_loss_epoch=0.0149]Epoch 29: Train Loss = 0.015170724131166935\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.0152]Epoch 30: Train Loss = 0.012260622344911098\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=324, train_loss_step=0.0165, train_loss_epoch=0.0123]Epoch 31: Train Loss = 0.01651676930487156\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=324, train_loss_step=0.0165, train_loss_epoch=0.0165]Epoch 32: Train Loss = 0.01653730496764183\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=324, train_loss_step=0.0156, train_loss_epoch=0.0165]Epoch 33: Train Loss = 0.015579392202198505\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=324, train_loss_step=0.013, train_loss_epoch=0.0156] Epoch 34: Train Loss = 0.012986630201339722\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=324, train_loss_step=0.0172, train_loss_epoch=0.013]Epoch 35: Train Loss = 0.017192287370562553\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=324, train_loss_step=0.0101, train_loss_epoch=0.0172]Epoch 36: Train Loss = 0.010096495039761066\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=324, train_loss_step=0.0117, train_loss_epoch=0.0101]Epoch 37: Train Loss = 0.011679595336318016\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=324, train_loss_step=0.0101, train_loss_epoch=0.0117]Epoch 38: Train Loss = 0.010118948295712471\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0101]Epoch 39: Train Loss = 0.01164205651730299\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=324, train_loss_step=0.0151, train_loss_epoch=0.0116]Epoch 40: Train Loss = 0.015086127445101738\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=324, train_loss_step=0.0134, train_loss_epoch=0.0151]Epoch 41: Train Loss = 0.013381966389715672\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=324, train_loss_step=0.0149, train_loss_epoch=0.0134]Epoch 42: Train Loss = 0.01493155863136053\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=324, train_loss_step=0.0133, train_loss_epoch=0.0149]Epoch 43: Train Loss = 0.013283721171319485\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0133]Epoch 44: Train Loss = 0.012217278592288494\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=324, train_loss_step=0.0137, train_loss_epoch=0.0122]Epoch 45: Train Loss = 0.013681450858712196\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=324, train_loss_step=0.0124, train_loss_epoch=0.0137]Epoch 46: Train Loss = 0.012372536584734917\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=324, train_loss_step=0.0149, train_loss_epoch=0.0124]Epoch 47: Train Loss = 0.014909796416759491\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=324, train_loss_step=0.0115, train_loss_epoch=0.0149]Epoch 48: Train Loss = 0.011531404219567776\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=324, train_loss_step=0.0142, train_loss_epoch=0.0115]Epoch 49: Train Loss = 0.014171564020216465\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=324, train_loss_step=0.0136, train_loss_epoch=0.0142]Epoch 50: Train Loss = 0.01364940870553255\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=324, train_loss_step=0.0143, train_loss_epoch=0.0136]Epoch 51: Train Loss = 0.014344120398163795\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=324, train_loss_step=0.00981, train_loss_epoch=0.0143]Epoch 52: Train Loss = 0.009807241149246693\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=324, train_loss_step=0.0135, train_loss_epoch=0.00981] Epoch 53: Train Loss = 0.013545620255172253\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=324, train_loss_step=0.0134, train_loss_epoch=0.0135] Epoch 54: Train Loss = 0.013357394374907017\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=324, train_loss_step=0.0132, train_loss_epoch=0.0134]Epoch 55: Train Loss = 0.013150054030120373\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=324, train_loss_step=0.0118, train_loss_epoch=0.0132]Epoch 56: Train Loss = 0.011846421286463737\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=324, train_loss_step=0.0125, train_loss_epoch=0.0118]Epoch 57: Train Loss = 0.01254730112850666\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=324, train_loss_step=0.0179, train_loss_epoch=0.0125]Epoch 58: Train Loss = 0.017947940155863762\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0179]Epoch 59: Train Loss = 0.01139162015169859\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=324, train_loss_step=0.00927, train_loss_epoch=0.0114]Epoch 60: Train Loss = 0.0092726806178689\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.00927] Epoch 61: Train Loss = 0.012343131937086582\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=324, train_loss_step=0.0136, train_loss_epoch=0.0123] Epoch 62: Train Loss = 0.01363898254930973\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=324, train_loss_step=0.0107, train_loss_epoch=0.0136]Epoch 63: Train Loss = 0.010704577900469303\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=324, train_loss_step=0.0151, train_loss_epoch=0.0107]Epoch 64: Train Loss = 0.015107954852283001\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=324, train_loss_step=0.0128, train_loss_epoch=0.0151]Epoch 65: Train Loss = 0.012752639129757881\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=324, train_loss_step=0.0179, train_loss_epoch=0.0128]Epoch 66: Train Loss = 0.017924949526786804\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=324, train_loss_step=0.0163, train_loss_epoch=0.0179]Epoch 67: Train Loss = 0.016286246478557587\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=324, train_loss_step=0.014, train_loss_epoch=0.0163] Epoch 68: Train Loss = 0.014042533934116364\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s, v_num=324, train_loss_step=0.012, train_loss_epoch=0.014] Epoch 69: Train Loss = 0.01196373999118805\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=324, train_loss_step=0.0128, train_loss_epoch=0.012]Epoch 70: Train Loss = 0.012839853763580322\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=324, train_loss_step=0.0128, train_loss_epoch=0.0128]Epoch 71: Train Loss = 0.012819980271160603\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=324, train_loss_step=0.0145, train_loss_epoch=0.0128]Epoch 72: Train Loss = 0.014525865204632282\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=324, train_loss_step=0.0185, train_loss_epoch=0.0145]Epoch 73: Train Loss = 0.01845317706465721\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=324, train_loss_step=0.0137, train_loss_epoch=0.0185]Epoch 74: Train Loss = 0.013674207963049412\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=324, train_loss_step=0.0173, train_loss_epoch=0.0137]Epoch 75: Train Loss = 0.017327524721622467\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=324, train_loss_step=0.0219, train_loss_epoch=0.0173]Epoch 76: Train Loss = 0.02194979228079319\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=324, train_loss_step=0.0135, train_loss_epoch=0.0219]Epoch 77: Train Loss = 0.01348083559423685\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=324, train_loss_step=0.0234, train_loss_epoch=0.0135]Epoch 78: Train Loss = 0.023350268602371216\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=324, train_loss_step=0.0204, train_loss_epoch=0.0234]Epoch 79: Train Loss = 0.020423652604222298\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=324, train_loss_step=0.0162, train_loss_epoch=0.0204]Epoch 80: Train Loss = 0.01616273820400238\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=324, train_loss_step=0.0144, train_loss_epoch=0.0162]Epoch 81: Train Loss = 0.014428971335291862\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=324, train_loss_step=0.0158, train_loss_epoch=0.0144]Epoch 82: Train Loss = 0.01584705151617527\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=324, train_loss_step=0.0146, train_loss_epoch=0.0158]Epoch 83: Train Loss = 0.014636698178946972\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=324, train_loss_step=0.0179, train_loss_epoch=0.0146]Epoch 84: Train Loss = 0.017947938293218613\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=324, train_loss_step=0.0129, train_loss_epoch=0.0179]Epoch 85: Train Loss = 0.012877230532467365\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=324, train_loss_step=0.0148, train_loss_epoch=0.0129]Epoch 86: Train Loss = 0.014767994172871113\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=324, train_loss_step=0.014, train_loss_epoch=0.0148] Epoch 87: Train Loss = 0.014002327807247639\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=324, train_loss_step=0.0229, train_loss_epoch=0.014]Epoch 88: Train Loss = 0.02287914790213108\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=324, train_loss_step=0.0155, train_loss_epoch=0.0229]Epoch 89: Train Loss = 0.015527124516665936\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=324, train_loss_step=0.0241, train_loss_epoch=0.0155]Epoch 90: Train Loss = 0.024065790697932243\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0241]Epoch 91: Train Loss = 0.011607286520302296\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=324, train_loss_step=0.0144, train_loss_epoch=0.0116]Epoch 92: Train Loss = 0.014390054158866405\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=324, train_loss_step=0.0164, train_loss_epoch=0.0144]Epoch 93: Train Loss = 0.016356313601136208\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s, v_num=324, train_loss_step=0.0125, train_loss_epoch=0.0164]Epoch 94: Train Loss = 0.012516235001385212\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0125]Epoch 95: Train Loss = 0.012225712649524212\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=324, train_loss_step=0.0151, train_loss_epoch=0.0122]Epoch 96: Train Loss = 0.015117083676159382\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=324, train_loss_step=0.0188, train_loss_epoch=0.0151]Epoch 97: Train Loss = 0.01878160424530506\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=324, train_loss_step=0.0162, train_loss_epoch=0.0188]Epoch 98: Train Loss = 0.01620480790734291\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=324, train_loss_step=0.0112, train_loss_epoch=0.0162]Epoch 99: Train Loss = 0.011229187250137329\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=324, train_loss_step=0.0296, train_loss_epoch=0.0112]Epoch 100: Train Loss = 0.029558900743722916\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=324, train_loss_step=0.0125, train_loss_epoch=0.0296]Epoch 101: Train Loss = 0.012453699484467506\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=324, train_loss_step=0.0167, train_loss_epoch=0.0125]Epoch 102: Train Loss = 0.016734134405851364\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0167]Epoch 103: Train Loss = 0.011360756121575832\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=324, train_loss_step=0.014, train_loss_epoch=0.0114] Epoch 104: Train Loss = 0.013995334506034851\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=324, train_loss_step=0.0142, train_loss_epoch=0.014]Epoch 105: Train Loss = 0.014176781289279461\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=324, train_loss_step=0.015, train_loss_epoch=0.0142] Epoch 106: Train Loss = 0.014959335327148438\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=324, train_loss_step=0.0143, train_loss_epoch=0.015]Epoch 107: Train Loss = 0.014309071004390717\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=324, train_loss_step=0.0145, train_loss_epoch=0.0143]Epoch 108: Train Loss = 0.01454838179051876\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=324, train_loss_step=0.0135, train_loss_epoch=0.0145]Epoch 109: Train Loss = 0.013493219390511513\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=324, train_loss_step=0.0134, train_loss_epoch=0.0135]Epoch 110: Train Loss = 0.013429543003439903\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=324, train_loss_step=0.0141, train_loss_epoch=0.0134]Epoch 111: Train Loss = 0.014134992845356464\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=324, train_loss_step=0.0155, train_loss_epoch=0.0141]Epoch 112: Train Loss = 0.015513875521719456\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=324, train_loss_step=0.0109, train_loss_epoch=0.0155]Epoch 113: Train Loss = 0.010934506542980671\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=324, train_loss_step=0.0129, train_loss_epoch=0.0109]Epoch 114: Train Loss = 0.012918614782392979\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=324, train_loss_step=0.0149, train_loss_epoch=0.0129]Epoch 115: Train Loss = 0.014907792210578918\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=324, train_loss_step=0.0138, train_loss_epoch=0.0149]Epoch 116: Train Loss = 0.013839802704751492\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=324, train_loss_step=0.0142, train_loss_epoch=0.0138]Epoch 117: Train Loss = 0.014215308241546154\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=324, train_loss_step=0.0119, train_loss_epoch=0.0142]Epoch 118: Train Loss = 0.011854603886604309\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=324, train_loss_step=0.0141, train_loss_epoch=0.0119]Epoch 119: Train Loss = 0.014106256887316704\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=324, train_loss_step=0.0113, train_loss_epoch=0.0141]Epoch 120: Train Loss = 0.01130614709109068\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 11.40it/s, v_num=324, train_loss_step=0.0125, train_loss_epoch=0.0113]Epoch 121: Train Loss = 0.012474983930587769\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=324, train_loss_step=0.0105, train_loss_epoch=0.0125]Epoch 122: Train Loss = 0.010536646470427513\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=324, train_loss_step=0.0152, train_loss_epoch=0.0105]Epoch 123: Train Loss = 0.015162029303610325\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=324, train_loss_step=0.0154, train_loss_epoch=0.0152]Epoch 124: Train Loss = 0.01544241514056921\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0154]Epoch 125: Train Loss = 0.011351619847118855\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=324, train_loss_step=0.0139, train_loss_epoch=0.0114]Epoch 126: Train Loss = 0.013871933333575726\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=324, train_loss_step=0.0145, train_loss_epoch=0.0139]Epoch 127: Train Loss = 0.014467136934399605\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=324, train_loss_step=0.0121, train_loss_epoch=0.0145]Epoch 128: Train Loss = 0.012122871354222298\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=324, train_loss_step=0.0107, train_loss_epoch=0.0121]Epoch 129: Train Loss = 0.010693631134927273\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=324, train_loss_step=0.0155, train_loss_epoch=0.0107]Epoch 130: Train Loss = 0.015529093332588673\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=324, train_loss_step=0.0151, train_loss_epoch=0.0155]Epoch 131: Train Loss = 0.015112962573766708\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=324, train_loss_step=0.0124, train_loss_epoch=0.0151]Epoch 132: Train Loss = 0.012430367060005665\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=324, train_loss_step=0.0159, train_loss_epoch=0.0124]Epoch 133: Train Loss = 0.015933861956000328\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=324, train_loss_step=0.0144, train_loss_epoch=0.0159]Epoch 134: Train Loss = 0.014391742646694183\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0144]Epoch 135: Train Loss = 0.011083269491791725\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=324, train_loss_step=0.013, train_loss_epoch=0.0111] Epoch 136: Train Loss = 0.01298703532665968\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=324, train_loss_step=0.0177, train_loss_epoch=0.013]Epoch 137: Train Loss = 0.017721397802233696\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=324, train_loss_step=0.0146, train_loss_epoch=0.0177]Epoch 138: Train Loss = 0.014556271024048328\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=324, train_loss_step=0.013, train_loss_epoch=0.0146] Epoch 139: Train Loss = 0.013025135733187199\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=324, train_loss_step=0.0144, train_loss_epoch=0.013]Epoch 140: Train Loss = 0.014400833286345005\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=324, train_loss_step=0.0129, train_loss_epoch=0.0144]Epoch 141: Train Loss = 0.01294626947492361\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=324, train_loss_step=0.0124, train_loss_epoch=0.0129]Epoch 142: Train Loss = 0.012368994764983654\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=324, train_loss_step=0.0137, train_loss_epoch=0.0124]Epoch 143: Train Loss = 0.01371043175458908\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.0137]Epoch 144: Train Loss = 0.012255856767296791\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=324, train_loss_step=0.017, train_loss_epoch=0.0123] Epoch 145: Train Loss = 0.016988134011626244\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=324, train_loss_step=0.0119, train_loss_epoch=0.017]Epoch 146: Train Loss = 0.011927196756005287\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=324, train_loss_step=0.0151, train_loss_epoch=0.0119]Epoch 147: Train Loss = 0.01506809238344431\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.0151]Epoch 148: Train Loss = 0.01228400319814682\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=324, train_loss_step=0.0155, train_loss_epoch=0.0123]Epoch 149: Train Loss = 0.015486830845475197\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=324, train_loss_step=0.0127, train_loss_epoch=0.0155]Epoch 150: Train Loss = 0.012718729674816132\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0127]Epoch 151: Train Loss = 0.011618065647780895\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=324, train_loss_step=0.0137, train_loss_epoch=0.0116]Epoch 152: Train Loss = 0.013686132617294788\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0137]Epoch 153: Train Loss = 0.011380444280803204\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=324, train_loss_step=0.0119, train_loss_epoch=0.0114]Epoch 154: Train Loss = 0.011874167248606682\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=324, train_loss_step=0.0126, train_loss_epoch=0.0119]Epoch 155: Train Loss = 0.012647556141018867\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0126]Epoch 156: Train Loss = 0.012201708741486073\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=324, train_loss_step=0.010, train_loss_epoch=0.0122] Epoch 157: Train Loss = 0.010003244504332542\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=324, train_loss_step=0.0128, train_loss_epoch=0.010]Epoch 158: Train Loss = 0.012829768471419811\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.0128]Epoch 159: Train Loss = 0.012281800620257854\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=324, train_loss_step=0.00928, train_loss_epoch=0.0123]Epoch 160: Train Loss = 0.009282777085900307\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=324, train_loss_step=0.0117, train_loss_epoch=0.00928] Epoch 161: Train Loss = 0.011682885698974133\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=324, train_loss_step=0.0168, train_loss_epoch=0.0117] Epoch 162: Train Loss = 0.01682671718299389\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=324, train_loss_step=0.0121, train_loss_epoch=0.0168]Epoch 163: Train Loss = 0.01209333073347807\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=324, train_loss_step=0.0147, train_loss_epoch=0.0121]Epoch 164: Train Loss = 0.01468976866453886\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=324, train_loss_step=0.0119, train_loss_epoch=0.0147]Epoch 165: Train Loss = 0.011920051649212837\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s, v_num=324, train_loss_step=0.0115, train_loss_epoch=0.0119]Epoch 166: Train Loss = 0.011501605622470379\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=324, train_loss_step=0.0148, train_loss_epoch=0.0115]Epoch 167: Train Loss = 0.014810831286013126\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=324, train_loss_step=0.0126, train_loss_epoch=0.0148]Epoch 168: Train Loss = 0.012604956515133381\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=324, train_loss_step=0.0102, train_loss_epoch=0.0126]Epoch 169: Train Loss = 0.01024357695132494\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=324, train_loss_step=0.0109, train_loss_epoch=0.0102]Epoch 170: Train Loss = 0.010855098254978657\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=324, train_loss_step=0.0132, train_loss_epoch=0.0109]Epoch 171: Train Loss = 0.013186277821660042\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 10.17it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.0132]Epoch 172: Train Loss = 0.012294874526560307\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=324, train_loss_step=0.0129, train_loss_epoch=0.0123]Epoch 173: Train Loss = 0.012853743508458138\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=324, train_loss_step=0.0126, train_loss_epoch=0.0129]Epoch 174: Train Loss = 0.012589617632329464\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0126]Epoch 175: Train Loss = 0.011392912827432156\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=324, train_loss_step=0.00939, train_loss_epoch=0.0114]Epoch 176: Train Loss = 0.009389153681695461\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=324, train_loss_step=0.0142, train_loss_epoch=0.00939] Epoch 177: Train Loss = 0.01424866821616888\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=324, train_loss_step=0.013, train_loss_epoch=0.0142]  Epoch 178: Train Loss = 0.013029146008193493\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=324, train_loss_step=0.0102, train_loss_epoch=0.013]Epoch 179: Train Loss = 0.010178987868130207\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0102]Epoch 180: Train Loss = 0.011066260747611523\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0111]Epoch 181: Train Loss = 0.011598331853747368\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0116]Epoch 182: Train Loss = 0.0110631650313735\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=324, train_loss_step=0.0104, train_loss_epoch=0.0111]Epoch 183: Train Loss = 0.01035362295806408\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=324, train_loss_step=0.0148, train_loss_epoch=0.0104]Epoch 184: Train Loss = 0.014813446439802647\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=324, train_loss_step=0.0127, train_loss_epoch=0.0148]Epoch 185: Train Loss = 0.012700689025223255\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=324, train_loss_step=0.0138, train_loss_epoch=0.0127]Epoch 186: Train Loss = 0.013768672943115234\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0138]Epoch 187: Train Loss = 0.01164504699409008\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s, v_num=324, train_loss_step=0.0126, train_loss_epoch=0.0116]Epoch 188: Train Loss = 0.012598802335560322\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 11.28it/s, v_num=324, train_loss_step=0.0167, train_loss_epoch=0.0126]Epoch 189: Train Loss = 0.01667368970811367\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0167]Epoch 190: Train Loss = 0.012167536653578281\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=324, train_loss_step=0.0141, train_loss_epoch=0.0122]Epoch 191: Train Loss = 0.014142653904855251\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=324, train_loss_step=0.011, train_loss_epoch=0.0141] Epoch 192: Train Loss = 0.011018432676792145\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=324, train_loss_step=0.0181, train_loss_epoch=0.011]Epoch 193: Train Loss = 0.01807168312370777\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=324, train_loss_step=0.0124, train_loss_epoch=0.0181]Epoch 194: Train Loss = 0.012415805831551552\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=324, train_loss_step=0.0131, train_loss_epoch=0.0124]Epoch 195: Train Loss = 0.013141801580786705\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=324, train_loss_step=0.00993, train_loss_epoch=0.0131]Epoch 196: Train Loss = 0.009927503764629364\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=324, train_loss_step=0.0161, train_loss_epoch=0.00993] Epoch 197: Train Loss = 0.01606791652739048\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0161] Epoch 198: Train Loss = 0.011560517363250256\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=324, train_loss_step=0.0163, train_loss_epoch=0.0116]Epoch 199: Train Loss = 0.01634453609585762\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=324, train_loss_step=0.014, train_loss_epoch=0.0163] Epoch 200: Train Loss = 0.013959333300590515\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.014]Epoch 201: Train Loss = 0.011592951603233814\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=324, train_loss_step=0.0136, train_loss_epoch=0.0116]Epoch 202: Train Loss = 0.01361791044473648\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0136]Epoch 203: Train Loss = 0.011139261536300182\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=324, train_loss_step=0.0135, train_loss_epoch=0.0111]Epoch 204: Train Loss = 0.013488935306668282\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=324, train_loss_step=0.0106, train_loss_epoch=0.0135]Epoch 205: Train Loss = 0.010586447082459927\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s, v_num=324, train_loss_step=0.0136, train_loss_epoch=0.0106]Epoch 206: Train Loss = 0.013597503304481506\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=324, train_loss_step=0.013, train_loss_epoch=0.0136] Epoch 207: Train Loss = 0.012979967519640923\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=324, train_loss_step=0.0115, train_loss_epoch=0.013]Epoch 208: Train Loss = 0.01152880396693945\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=324, train_loss_step=0.0155, train_loss_epoch=0.0115]Epoch 209: Train Loss = 0.015513762831687927\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=324, train_loss_step=0.0118, train_loss_epoch=0.0155]Epoch 210: Train Loss = 0.011825034394860268\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=324, train_loss_step=0.0072, train_loss_epoch=0.0118]Epoch 211: Train Loss = 0.007200281601399183\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=324, train_loss_step=0.0136, train_loss_epoch=0.0072]Epoch 212: Train Loss = 0.013598761521279812\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=324, train_loss_step=0.0132, train_loss_epoch=0.0136]Epoch 213: Train Loss = 0.013231801800429821\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=324, train_loss_step=0.0115, train_loss_epoch=0.0132]Epoch 214: Train Loss = 0.011549708433449268\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0115]Epoch 215: Train Loss = 0.011356418952345848\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=324, train_loss_step=0.0105, train_loss_epoch=0.0114]Epoch 216: Train Loss = 0.010488398373126984\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0105]Epoch 217: Train Loss = 0.011062024161219597\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=324, train_loss_step=0.0134, train_loss_epoch=0.0111]Epoch 218: Train Loss = 0.013447195291519165\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=324, train_loss_step=0.0102, train_loss_epoch=0.0134]Epoch 219: Train Loss = 0.010151529684662819\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s, v_num=324, train_loss_step=0.0134, train_loss_epoch=0.0102]Epoch 220: Train Loss = 0.01338632870465517\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0134]Epoch 221: Train Loss = 0.011350695975124836\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=324, train_loss_step=0.013, train_loss_epoch=0.0114] Epoch 222: Train Loss = 0.013000903651118279\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=324, train_loss_step=0.0149, train_loss_epoch=0.013]Epoch 223: Train Loss = 0.014928370714187622\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.0149]Epoch 224: Train Loss = 0.012333177961409092\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0123]Epoch 225: Train Loss = 0.011554909870028496\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=324, train_loss_step=0.0126, train_loss_epoch=0.0116]Epoch 226: Train Loss = 0.012606831267476082\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0126]Epoch 227: Train Loss = 0.011059588752686977\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=324, train_loss_step=0.0136, train_loss_epoch=0.0111]Epoch 228: Train Loss = 0.01364863384515047\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=324, train_loss_step=0.0182, train_loss_epoch=0.0136]Epoch 229: Train Loss = 0.01822364330291748\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0182]Epoch 230: Train Loss = 0.011105292476713657\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0111]Epoch 231: Train Loss = 0.012218264862895012\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=324, train_loss_step=0.0137, train_loss_epoch=0.0122]Epoch 232: Train Loss = 0.013713146559894085\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=324, train_loss_step=0.014, train_loss_epoch=0.0137] Epoch 233: Train Loss = 0.013979938812553883\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=324, train_loss_step=0.0112, train_loss_epoch=0.014]Epoch 234: Train Loss = 0.011164932511746883\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=324, train_loss_step=0.0144, train_loss_epoch=0.0112]Epoch 235: Train Loss = 0.014382489025592804\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=324, train_loss_step=0.0164, train_loss_epoch=0.0144]Epoch 236: Train Loss = 0.01641486957669258\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0164]Epoch 237: Train Loss = 0.011353460140526295\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=324, train_loss_step=0.0106, train_loss_epoch=0.0114]Epoch 238: Train Loss = 0.010589043609797955\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=324, train_loss_step=0.00991, train_loss_epoch=0.0106]Epoch 239: Train Loss = 0.009910419583320618\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=324, train_loss_step=0.0127, train_loss_epoch=0.00991] Epoch 240: Train Loss = 0.01269646268337965\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0127] Epoch 241: Train Loss = 0.011099359020590782\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=324, train_loss_step=0.0135, train_loss_epoch=0.0111]Epoch 242: Train Loss = 0.01353235263377428\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=324, train_loss_step=0.0162, train_loss_epoch=0.0135]Epoch 243: Train Loss = 0.016221020370721817\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=324, train_loss_step=0.00912, train_loss_epoch=0.0162]Epoch 244: Train Loss = 0.009116118773818016\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=324, train_loss_step=0.0105, train_loss_epoch=0.00912] Epoch 245: Train Loss = 0.010534566827118397\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0105] Epoch 246: Train Loss = 0.01219760812819004\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 12.52it/s, v_num=324, train_loss_step=0.0109, train_loss_epoch=0.0122]Epoch 247: Train Loss = 0.010871837846934795\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=324, train_loss_step=0.017, train_loss_epoch=0.0109] Epoch 248: Train Loss = 0.017018545418977737\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.017]Epoch 249: Train Loss = 0.01233805064111948\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 10.22it/s, v_num=324, train_loss_step=0.0143, train_loss_epoch=0.0123]Epoch 250: Train Loss = 0.014314527623355389\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=324, train_loss_step=0.011, train_loss_epoch=0.0143] Epoch 251: Train Loss = 0.010955308564007282\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=324, train_loss_step=0.0157, train_loss_epoch=0.011]Epoch 252: Train Loss = 0.015741951763629913\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=324, train_loss_step=0.0147, train_loss_epoch=0.0157]Epoch 253: Train Loss = 0.014735882170498371\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=324, train_loss_step=0.0179, train_loss_epoch=0.0147]Epoch 254: Train Loss = 0.017922747880220413\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=324, train_loss_step=0.0181, train_loss_epoch=0.0179]Epoch 255: Train Loss = 0.018093226477503777\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=324, train_loss_step=0.0106, train_loss_epoch=0.0181]Epoch 256: Train Loss = 0.010637030005455017\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=324, train_loss_step=0.019, train_loss_epoch=0.0106] Epoch 257: Train Loss = 0.019028980284929276\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=324, train_loss_step=0.0137, train_loss_epoch=0.019]Epoch 258: Train Loss = 0.013651114888489246\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=324, train_loss_step=0.0157, train_loss_epoch=0.0137]Epoch 259: Train Loss = 0.01566767506301403\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=324, train_loss_step=0.013, train_loss_epoch=0.0157] Epoch 260: Train Loss = 0.012984362430870533\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=324, train_loss_step=0.0142, train_loss_epoch=0.013]Epoch 261: Train Loss = 0.014151469804346561\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=324, train_loss_step=0.0145, train_loss_epoch=0.0142]Epoch 262: Train Loss = 0.014510735869407654\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=324, train_loss_step=0.0132, train_loss_epoch=0.0145]Epoch 263: Train Loss = 0.013159135356545448\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=324, train_loss_step=0.0133, train_loss_epoch=0.0132]Epoch 264: Train Loss = 0.013259366154670715\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=324, train_loss_step=0.0112, train_loss_epoch=0.0133]Epoch 265: Train Loss = 0.011193783022463322\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=324, train_loss_step=0.0182, train_loss_epoch=0.0112]Epoch 266: Train Loss = 0.018219811841845512\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=324, train_loss_step=0.020, train_loss_epoch=0.0182] Epoch 267: Train Loss = 0.019994039088487625\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=324, train_loss_step=0.0144, train_loss_epoch=0.020]Epoch 268: Train Loss = 0.01440463773906231\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=324, train_loss_step=0.0175, train_loss_epoch=0.0144]Epoch 269: Train Loss = 0.017516179010272026\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=324, train_loss_step=0.0165, train_loss_epoch=0.0175]Epoch 270: Train Loss = 0.016498107463121414\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=324, train_loss_step=0.0135, train_loss_epoch=0.0165]Epoch 271: Train Loss = 0.013462173752486706\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s, v_num=324, train_loss_step=0.016, train_loss_epoch=0.0135] Epoch 272: Train Loss = 0.01602466218173504\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.016]Epoch 273: Train Loss = 0.012201846577227116\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0122]Epoch 274: Train Loss = 0.011082119308412075\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=324, train_loss_step=0.011, train_loss_epoch=0.0111] Epoch 275: Train Loss = 0.011011888273060322\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=324, train_loss_step=0.0133, train_loss_epoch=0.011]Epoch 276: Train Loss = 0.013295300304889679\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, v_num=324, train_loss_step=0.00927, train_loss_epoch=0.0133]Epoch 277: Train Loss = 0.009270332753658295\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=324, train_loss_step=0.0105, train_loss_epoch=0.00927] Epoch 278: Train Loss = 0.010470909997820854\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=324, train_loss_step=0.0152, train_loss_epoch=0.0105] Epoch 279: Train Loss = 0.015195273794233799\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0152]Epoch 280: Train Loss = 0.011567013338208199\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=324, train_loss_step=0.0149, train_loss_epoch=0.0116]Epoch 281: Train Loss = 0.014934963546693325\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=324, train_loss_step=0.0124, train_loss_epoch=0.0149]Epoch 282: Train Loss = 0.012391683645546436\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=324, train_loss_step=0.0127, train_loss_epoch=0.0124]Epoch 283: Train Loss = 0.01274383906275034\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=324, train_loss_step=0.0128, train_loss_epoch=0.0127]Epoch 284: Train Loss = 0.012754072435200214\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0128]Epoch 285: Train Loss = 0.011635270901024342\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=324, train_loss_step=0.0108, train_loss_epoch=0.0116]Epoch 286: Train Loss = 0.01076815091073513\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=324, train_loss_step=0.0106, train_loss_epoch=0.0108]Epoch 287: Train Loss = 0.010580449365079403\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=324, train_loss_step=0.015, train_loss_epoch=0.0106] Epoch 288: Train Loss = 0.014975151978433132\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=324, train_loss_step=0.0126, train_loss_epoch=0.015]Epoch 289: Train Loss = 0.012626560404896736\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=324, train_loss_step=0.0148, train_loss_epoch=0.0126]Epoch 290: Train Loss = 0.014797849580645561\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=324, train_loss_step=0.0171, train_loss_epoch=0.0148]Epoch 291: Train Loss = 0.01711541973054409\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=324, train_loss_step=0.0118, train_loss_epoch=0.0171]Epoch 292: Train Loss = 0.011752724647521973\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=324, train_loss_step=0.0129, train_loss_epoch=0.0118]Epoch 293: Train Loss = 0.012910334393382072\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=324, train_loss_step=0.0124, train_loss_epoch=0.0129]Epoch 294: Train Loss = 0.012367656454443932\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=324, train_loss_step=0.0118, train_loss_epoch=0.0124]Epoch 295: Train Loss = 0.011806377209722996\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=324, train_loss_step=0.0143, train_loss_epoch=0.0118]Epoch 296: Train Loss = 0.014275620691478252\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=324, train_loss_step=0.0126, train_loss_epoch=0.0143]Epoch 297: Train Loss = 0.01262717042118311\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0126]Epoch 298: Train Loss = 0.01141134649515152\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=324, train_loss_step=0.0136, train_loss_epoch=0.0114]Epoch 299: Train Loss = 0.01360951829701662\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=324, train_loss_step=0.0112, train_loss_epoch=0.0136]Epoch 300: Train Loss = 0.011217383667826653\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0112]Epoch 301: Train Loss = 0.011380189098417759\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=324, train_loss_step=0.0102, train_loss_epoch=0.0114]Epoch 302: Train Loss = 0.010214479640126228\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=324, train_loss_step=0.0141, train_loss_epoch=0.0102]Epoch 303: Train Loss = 0.014134956523776054\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=324, train_loss_step=0.0169, train_loss_epoch=0.0141]Epoch 304: Train Loss = 0.016855301335453987\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=324, train_loss_step=0.0103, train_loss_epoch=0.0169]Epoch 305: Train Loss = 0.010270818136632442\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=324, train_loss_step=0.0128, train_loss_epoch=0.0103]Epoch 306: Train Loss = 0.012808360159397125\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=324, train_loss_step=0.0113, train_loss_epoch=0.0128]Epoch 307: Train Loss = 0.011309166438877583\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0113]Epoch 308: Train Loss = 0.011429712176322937\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=324, train_loss_step=0.0117, train_loss_epoch=0.0114]Epoch 309: Train Loss = 0.011720390059053898\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0117]Epoch 310: Train Loss = 0.012188805267214775\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=324, train_loss_step=0.0125, train_loss_epoch=0.0122]Epoch 311: Train Loss = 0.01251455582678318\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=324, train_loss_step=0.0102, train_loss_epoch=0.0125]Epoch 312: Train Loss = 0.01018127053976059\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=324, train_loss_step=0.0168, train_loss_epoch=0.0102]Epoch 313: Train Loss = 0.016750793904066086\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=324, train_loss_step=0.0107, train_loss_epoch=0.0168]Epoch 314: Train Loss = 0.010686630383133888\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 315: Train Loss = 0.011568060144782066\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=324, train_loss_step=0.014, train_loss_epoch=0.0116] Epoch 316: Train Loss = 0.014023907482624054\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=324, train_loss_step=0.0171, train_loss_epoch=0.014]Epoch 317: Train Loss = 0.017141563817858696\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=324, train_loss_step=0.0153, train_loss_epoch=0.0171]Epoch 318: Train Loss = 0.015255621634423733\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 10.79it/s, v_num=324, train_loss_step=0.0125, train_loss_epoch=0.0153]Epoch 319: Train Loss = 0.012453275732696056\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=324, train_loss_step=0.0138, train_loss_epoch=0.0125]Epoch 320: Train Loss = 0.01380377821624279\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=324, train_loss_step=0.0145, train_loss_epoch=0.0138]Epoch 321: Train Loss = 0.014498414471745491\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=324, train_loss_step=0.0133, train_loss_epoch=0.0145]Epoch 322: Train Loss = 0.01328750979155302\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.0133]Epoch 323: Train Loss = 0.012309794314205647\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=324, train_loss_step=0.0131, train_loss_epoch=0.0123]Epoch 324: Train Loss = 0.013067779131233692\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=324, train_loss_step=0.0201, train_loss_epoch=0.0131]Epoch 325: Train Loss = 0.020075052976608276\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=324, train_loss_step=0.0109, train_loss_epoch=0.0201]Epoch 326: Train Loss = 0.010898125357925892\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=324, train_loss_step=0.0127, train_loss_epoch=0.0109]Epoch 327: Train Loss = 0.012748918496072292\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s, v_num=324, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 328: Train Loss = 0.011987906880676746\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=324, train_loss_step=0.0142, train_loss_epoch=0.012]Epoch 329: Train Loss = 0.014196367003023624\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=324, train_loss_step=0.0115, train_loss_epoch=0.0142]Epoch 330: Train Loss = 0.011526643298566341\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=324, train_loss_step=0.0126, train_loss_epoch=0.0115]Epoch 331: Train Loss = 0.012599133886396885\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=324, train_loss_step=0.0102, train_loss_epoch=0.0126]Epoch 332: Train Loss = 0.010203220881521702\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=324, train_loss_step=0.00958, train_loss_epoch=0.0102]Epoch 333: Train Loss = 0.009583435021340847\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.00958] Epoch 334: Train Loss = 0.012210352346301079\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=324, train_loss_step=0.0118, train_loss_epoch=0.0122] Epoch 335: Train Loss = 0.011843194253742695\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=324, train_loss_step=0.015, train_loss_epoch=0.0118] Epoch 336: Train Loss = 0.015005799941718578\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=324, train_loss_step=0.0128, train_loss_epoch=0.015]Epoch 337: Train Loss = 0.012799077667295933\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=324, train_loss_step=0.0127, train_loss_epoch=0.0128]Epoch 338: Train Loss = 0.012708023190498352\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=324, train_loss_step=0.00929, train_loss_epoch=0.0127]Epoch 339: Train Loss = 0.009286822751164436\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, v_num=324, train_loss_step=0.00997, train_loss_epoch=0.00929]Epoch 340: Train Loss = 0.009970097802579403\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=324, train_loss_step=0.00931, train_loss_epoch=0.00997]Epoch 341: Train Loss = 0.009307587519288063\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=324, train_loss_step=0.0178, train_loss_epoch=0.00931] Epoch 342: Train Loss = 0.017779529094696045\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=324, train_loss_step=0.0101, train_loss_epoch=0.0178] Epoch 343: Train Loss = 0.010085999965667725\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=324, train_loss_step=0.0121, train_loss_epoch=0.0101]Epoch 344: Train Loss = 0.01209792960435152\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=324, train_loss_step=0.0125, train_loss_epoch=0.0121]Epoch 345: Train Loss = 0.01254369504749775\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=324, train_loss_step=0.0119, train_loss_epoch=0.0125]Epoch 346: Train Loss = 0.01185232400894165\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=324, train_loss_step=0.012, train_loss_epoch=0.0119] Epoch 347: Train Loss = 0.012010018341243267\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=324, train_loss_step=0.0124, train_loss_epoch=0.012]Epoch 348: Train Loss = 0.012395885773003101\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=324, train_loss_step=0.0156, train_loss_epoch=0.0124]Epoch 349: Train Loss = 0.015565945766866207\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=324, train_loss_step=0.0126, train_loss_epoch=0.0156]Epoch 350: Train Loss = 0.012632916681468487\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=324, train_loss_step=0.0156, train_loss_epoch=0.0126]Epoch 351: Train Loss = 0.015644961968064308\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0156]Epoch 352: Train Loss = 0.0110844811424613\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=324, train_loss_step=0.0141, train_loss_epoch=0.0111]Epoch 353: Train Loss = 0.014056697487831116\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=324, train_loss_step=0.0144, train_loss_epoch=0.0141]Epoch 354: Train Loss = 0.014351291581988335\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.0144]Epoch 355: Train Loss = 0.012334289029240608\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=324, train_loss_step=0.00961, train_loss_epoch=0.0123]Epoch 356: Train Loss = 0.009613746777176857\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=324, train_loss_step=0.0117, train_loss_epoch=0.00961] Epoch 357: Train Loss = 0.011694076471030712\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=324, train_loss_step=0.0119, train_loss_epoch=0.0117] Epoch 358: Train Loss = 0.011917089112102985\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=324, train_loss_step=0.0146, train_loss_epoch=0.0119]Epoch 359: Train Loss = 0.01464406680315733\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=324, train_loss_step=0.0126, train_loss_epoch=0.0146]Epoch 360: Train Loss = 0.012577843852341175\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=324, train_loss_step=0.016, train_loss_epoch=0.0126] Epoch 361: Train Loss = 0.016033288091421127\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=324, train_loss_step=0.0103, train_loss_epoch=0.016]Epoch 362: Train Loss = 0.010277162306010723\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=324, train_loss_step=0.0131, train_loss_epoch=0.0103]Epoch 363: Train Loss = 0.013090967200696468\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=324, train_loss_step=0.00975, train_loss_epoch=0.0131]Epoch 364: Train Loss = 0.009748709388077259\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=324, train_loss_step=0.0113, train_loss_epoch=0.00975] Epoch 365: Train Loss = 0.01126315537840128\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=324, train_loss_step=0.0104, train_loss_epoch=0.0113] Epoch 366: Train Loss = 0.010368590243160725\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=324, train_loss_step=0.0113, train_loss_epoch=0.0104]Epoch 367: Train Loss = 0.011316337622702122\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=324, train_loss_step=0.0128, train_loss_epoch=0.0113]Epoch 368: Train Loss = 0.012809188105165958\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0128]Epoch 369: Train Loss = 0.011398597620427608\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s, v_num=324, train_loss_step=0.00995, train_loss_epoch=0.0114]Epoch 370: Train Loss = 0.009954428300261497\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=324, train_loss_step=0.0163, train_loss_epoch=0.00995] Epoch 371: Train Loss = 0.01631305180490017\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=324, train_loss_step=0.0193, train_loss_epoch=0.0163] Epoch 372: Train Loss = 0.019300427287817\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=324, train_loss_step=0.011, train_loss_epoch=0.0193] Epoch 373: Train Loss = 0.01097081508487463\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=324, train_loss_step=0.0113, train_loss_epoch=0.011]Epoch 374: Train Loss = 0.011268357746303082\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=324, train_loss_step=0.014, train_loss_epoch=0.0113] Epoch 375: Train Loss = 0.013994171284139156\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=324, train_loss_step=0.010, train_loss_epoch=0.014] Epoch 376: Train Loss = 0.010034458711743355\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s, v_num=324, train_loss_step=0.0135, train_loss_epoch=0.010]Epoch 377: Train Loss = 0.013466677628457546\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0135]Epoch 378: Train Loss = 0.01142529584467411\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=324, train_loss_step=0.0135, train_loss_epoch=0.0114]Epoch 379: Train Loss = 0.013531262055039406\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0135]Epoch 380: Train Loss = 0.012245946563780308\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=324, train_loss_step=0.0153, train_loss_epoch=0.0122]Epoch 381: Train Loss = 0.015257750637829304\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0153]Epoch 382: Train Loss = 0.01106591708958149\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=324, train_loss_step=0.0171, train_loss_epoch=0.0111]Epoch 383: Train Loss = 0.017119260504841805\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=324, train_loss_step=0.00897, train_loss_epoch=0.0171]Epoch 384: Train Loss = 0.008972005918622017\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=324, train_loss_step=0.0187, train_loss_epoch=0.00897] Epoch 385: Train Loss = 0.018746810033917427\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=324, train_loss_step=0.0111, train_loss_epoch=0.0187] Epoch 386: Train Loss = 0.011097228154540062\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=324, train_loss_step=0.012, train_loss_epoch=0.0111] Epoch 387: Train Loss = 0.0119823282584548\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=324, train_loss_step=0.0105, train_loss_epoch=0.012]Epoch 388: Train Loss = 0.010455086827278137\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=324, train_loss_step=0.0132, train_loss_epoch=0.0105]Epoch 389: Train Loss = 0.013165180571377277\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=324, train_loss_step=0.00919, train_loss_epoch=0.0132]Epoch 390: Train Loss = 0.009190867654979229\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.00919] Epoch 391: Train Loss = 0.01160798966884613\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=324, train_loss_step=0.0174, train_loss_epoch=0.0116] Epoch 392: Train Loss = 0.017379963770508766\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=324, train_loss_step=0.016, train_loss_epoch=0.0174] Epoch 393: Train Loss = 0.01600521430373192\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=324, train_loss_step=0.0132, train_loss_epoch=0.016]Epoch 394: Train Loss = 0.013156413100659847\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=324, train_loss_step=0.0148, train_loss_epoch=0.0132]Epoch 395: Train Loss = 0.014757181517779827\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=324, train_loss_step=0.00956, train_loss_epoch=0.0148]Epoch 396: Train Loss = 0.009560601785779\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.00956] Epoch 397: Train Loss = 0.0114362183958292\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=324, train_loss_step=0.0162, train_loss_epoch=0.0114] Epoch 398: Train Loss = 0.016187235713005066\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=324, train_loss_step=0.0137, train_loss_epoch=0.0162]Epoch 399: Train Loss = 0.013659297488629818\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=324, train_loss_step=0.0095, train_loss_epoch=0.0137]Epoch 400: Train Loss = 0.009496750310063362\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=324, train_loss_step=0.0109, train_loss_epoch=0.0095]Epoch 401: Train Loss = 0.010945373214781284\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=324, train_loss_step=0.0124, train_loss_epoch=0.0109]Epoch 402: Train Loss = 0.012365556322038174\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=324, train_loss_step=0.0138, train_loss_epoch=0.0124]Epoch 403: Train Loss = 0.013783371075987816\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=324, train_loss_step=0.0132, train_loss_epoch=0.0138]Epoch 404: Train Loss = 0.013177106156945229\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=324, train_loss_step=0.011, train_loss_epoch=0.0132] Epoch 405: Train Loss = 0.01100016850978136\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=324, train_loss_step=0.014, train_loss_epoch=0.011] Epoch 406: Train Loss = 0.01396991778165102\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=324, train_loss_step=0.0142, train_loss_epoch=0.014]Epoch 407: Train Loss = 0.014240476302802563\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=324, train_loss_step=0.0147, train_loss_epoch=0.0142]Epoch 408: Train Loss = 0.014746478758752346\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=324, train_loss_step=0.0129, train_loss_epoch=0.0147]Epoch 409: Train Loss = 0.012872448191046715\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=324, train_loss_step=0.0109, train_loss_epoch=0.0129]Epoch 410: Train Loss = 0.010942922905087471\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0109]Epoch 411: Train Loss = 0.011419196613132954\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=324, train_loss_step=0.0117, train_loss_epoch=0.0114]Epoch 412: Train Loss = 0.011721421964466572\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=324, train_loss_step=0.0127, train_loss_epoch=0.0117]Epoch 413: Train Loss = 0.012706535868346691\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=324, train_loss_step=0.0163, train_loss_epoch=0.0127]Epoch 414: Train Loss = 0.01628047227859497\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=324, train_loss_step=0.0141, train_loss_epoch=0.0163]Epoch 415: Train Loss = 0.014085961505770683\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=324, train_loss_step=0.0134, train_loss_epoch=0.0141]Epoch 416: Train Loss = 0.013352273032069206\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=324, train_loss_step=0.00968, train_loss_epoch=0.0134]Epoch 417: Train Loss = 0.009681443683803082\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=324, train_loss_step=0.0101, train_loss_epoch=0.00968] Epoch 418: Train Loss = 0.010058471001684666\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=324, train_loss_step=0.0115, train_loss_epoch=0.0101] Epoch 419: Train Loss = 0.011548231355845928\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=324, train_loss_step=0.0117, train_loss_epoch=0.0115]Epoch 420: Train Loss = 0.011676485650241375\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s, v_num=324, train_loss_step=0.0145, train_loss_epoch=0.0117]Epoch 421: Train Loss = 0.01451331377029419\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=324, train_loss_step=0.013, train_loss_epoch=0.0145] Epoch 422: Train Loss = 0.013034669682383537\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=324, train_loss_step=0.0127, train_loss_epoch=0.013]Epoch 423: Train Loss = 0.012668808922171593\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=324, train_loss_step=0.00954, train_loss_epoch=0.0127]Epoch 424: Train Loss = 0.009539215825498104\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=324, train_loss_step=0.0134, train_loss_epoch=0.00954] Epoch 425: Train Loss = 0.013391843996942043\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=324, train_loss_step=0.014, train_loss_epoch=0.0134]  Epoch 426: Train Loss = 0.013976042158901691\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=324, train_loss_step=0.0115, train_loss_epoch=0.014]Epoch 427: Train Loss = 0.011476666666567326\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=324, train_loss_step=0.0194, train_loss_epoch=0.0115]Epoch 428: Train Loss = 0.019407909363508224\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=324, train_loss_step=0.0172, train_loss_epoch=0.0194]Epoch 429: Train Loss = 0.017214087769389153\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0172]Epoch 430: Train Loss = 0.011589580215513706\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=324, train_loss_step=0.0118, train_loss_epoch=0.0116]Epoch 431: Train Loss = 0.011816981248557568\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=324, train_loss_step=0.013, train_loss_epoch=0.0118] Epoch 432: Train Loss = 0.013023081235587597\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=324, train_loss_step=0.0127, train_loss_epoch=0.013]Epoch 433: Train Loss = 0.01274378877133131\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=324, train_loss_step=0.00999, train_loss_epoch=0.0127]Epoch 434: Train Loss = 0.009992128238081932\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s, v_num=324, train_loss_step=0.0166, train_loss_epoch=0.00999] Epoch 435: Train Loss = 0.016604945063591003\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=324, train_loss_step=0.0144, train_loss_epoch=0.0166] Epoch 436: Train Loss = 0.014385594986379147\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=324, train_loss_step=0.0115, train_loss_epoch=0.0144]Epoch 437: Train Loss = 0.011536737903952599\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0115]Epoch 438: Train Loss = 0.011434325948357582\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=324, train_loss_step=0.00946, train_loss_epoch=0.0114]Epoch 439: Train Loss = 0.009455406107008457\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=324, train_loss_step=0.0109, train_loss_epoch=0.00946] Epoch 440: Train Loss = 0.010853903368115425\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s, v_num=324, train_loss_step=0.020, train_loss_epoch=0.0109]  Epoch 441: Train Loss = 0.01996530033648014\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=324, train_loss_step=0.0136, train_loss_epoch=0.020]Epoch 442: Train Loss = 0.013624124228954315\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=324, train_loss_step=0.0149, train_loss_epoch=0.0136]Epoch 443: Train Loss = 0.014898557215929031\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=324, train_loss_step=0.0147, train_loss_epoch=0.0149]Epoch 444: Train Loss = 0.014660954475402832\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0147]Epoch 445: Train Loss = 0.012193690054118633\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=324, train_loss_step=0.0112, train_loss_epoch=0.0122]Epoch 446: Train Loss = 0.011174012906849384\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 11.33it/s, v_num=324, train_loss_step=0.0175, train_loss_epoch=0.0112]Epoch 447: Train Loss = 0.01753336563706398\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=324, train_loss_step=0.0175, train_loss_epoch=0.0175]Epoch 448: Train Loss = 0.01745583675801754\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=324, train_loss_step=0.0168, train_loss_epoch=0.0175]Epoch 449: Train Loss = 0.01680537685751915\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=324, train_loss_step=0.0146, train_loss_epoch=0.0168]Epoch 450: Train Loss = 0.014571977779269218\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=324, train_loss_step=0.011, train_loss_epoch=0.0146] Epoch 451: Train Loss = 0.01097142230719328\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.011]Epoch 452: Train Loss = 0.011610999703407288\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0116]Epoch 453: Train Loss = 0.012189001776278019\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=324, train_loss_step=0.0169, train_loss_epoch=0.0122]Epoch 454: Train Loss = 0.0169320460408926\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=324, train_loss_step=0.0147, train_loss_epoch=0.0169]Epoch 455: Train Loss = 0.014702007174491882\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=324, train_loss_step=0.0132, train_loss_epoch=0.0147]Epoch 456: Train Loss = 0.013207721523940563\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=324, train_loss_step=0.00902, train_loss_epoch=0.0132]Epoch 457: Train Loss = 0.00902485754340887\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=324, train_loss_step=0.0109, train_loss_epoch=0.00902] Epoch 458: Train Loss = 0.010877267457544804\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=324, train_loss_step=0.017, train_loss_epoch=0.0109]  Epoch 459: Train Loss = 0.01698966883122921\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=324, train_loss_step=0.0107, train_loss_epoch=0.017]Epoch 460: Train Loss = 0.010687020607292652\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=324, train_loss_step=0.0141, train_loss_epoch=0.0107]Epoch 461: Train Loss = 0.014059232547879219\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=324, train_loss_step=0.0117, train_loss_epoch=0.0141]Epoch 462: Train Loss = 0.011679666116833687\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0117]Epoch 463: Train Loss = 0.011431336402893066\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=324, train_loss_step=0.0138, train_loss_epoch=0.0114]Epoch 464: Train Loss = 0.013760109432041645\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=324, train_loss_step=0.0103, train_loss_epoch=0.0138]Epoch 465: Train Loss = 0.010270262137055397\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0103]Epoch 466: Train Loss = 0.011376584880053997\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=324, train_loss_step=0.00986, train_loss_epoch=0.0114]Epoch 467: Train Loss = 0.00985686480998993\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=324, train_loss_step=0.0182, train_loss_epoch=0.00986] Epoch 468: Train Loss = 0.018225234001874924\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=324, train_loss_step=0.0184, train_loss_epoch=0.0182] Epoch 469: Train Loss = 0.018419668078422546\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0184]Epoch 470: Train Loss = 0.011575303971767426\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=324, train_loss_step=0.00989, train_loss_epoch=0.0116]Epoch 471: Train Loss = 0.009885264560580254\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=324, train_loss_step=0.0109, train_loss_epoch=0.00989] Epoch 472: Train Loss = 0.010939693078398705\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=324, train_loss_step=0.00995, train_loss_epoch=0.0109]Epoch 473: Train Loss = 0.009950007311999798\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=324, train_loss_step=0.00929, train_loss_epoch=0.00995]Epoch 474: Train Loss = 0.009293113835155964\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 11.21it/s, v_num=324, train_loss_step=0.0145, train_loss_epoch=0.00929] Epoch 475: Train Loss = 0.014472872018814087\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=324, train_loss_step=0.0114, train_loss_epoch=0.0145] Epoch 476: Train Loss = 0.01136708166450262\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.0114]Epoch 477: Train Loss = 0.012279297225177288\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=324, train_loss_step=0.0129, train_loss_epoch=0.0123]Epoch 478: Train Loss = 0.012879481539130211\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=324, train_loss_step=0.0113, train_loss_epoch=0.0129]Epoch 479: Train Loss = 0.011296376585960388\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=324, train_loss_step=0.0139, train_loss_epoch=0.0113]Epoch 480: Train Loss = 0.013859846629202366\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=324, train_loss_step=0.0132, train_loss_epoch=0.0139]Epoch 481: Train Loss = 0.013213656842708588\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=324, train_loss_step=0.0123, train_loss_epoch=0.0132]Epoch 482: Train Loss = 0.01226318534463644\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=324, train_loss_step=0.0119, train_loss_epoch=0.0123]Epoch 483: Train Loss = 0.011870399117469788\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=324, train_loss_step=0.0142, train_loss_epoch=0.0119]Epoch 484: Train Loss = 0.01417422853410244\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=324, train_loss_step=0.0166, train_loss_epoch=0.0142]Epoch 485: Train Loss = 0.016602059826254845\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=324, train_loss_step=0.0118, train_loss_epoch=0.0166]Epoch 486: Train Loss = 0.011806600727140903\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=324, train_loss_step=0.0121, train_loss_epoch=0.0118]Epoch 487: Train Loss = 0.012053278274834156\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=324, train_loss_step=0.0122, train_loss_epoch=0.0121]Epoch 488: Train Loss = 0.01224717777222395\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=324, train_loss_step=0.0125, train_loss_epoch=0.0122]Epoch 489: Train Loss = 0.012476637028157711\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=324, train_loss_step=0.00976, train_loss_epoch=0.0125]Epoch 490: Train Loss = 0.009764999151229858\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=324, train_loss_step=0.0134, train_loss_epoch=0.00976] Epoch 491: Train Loss = 0.013376160524785519\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=324, train_loss_step=0.0125, train_loss_epoch=0.0134] Epoch 492: Train Loss = 0.012500499375164509\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=324, train_loss_step=0.0116, train_loss_epoch=0.0125]Epoch 493: Train Loss = 0.01160822156816721\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=324, train_loss_step=0.0172, train_loss_epoch=0.0116]Epoch 494: Train Loss = 0.01724570244550705\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=324, train_loss_step=0.013, train_loss_epoch=0.0172] Epoch 495: Train Loss = 0.012963740155100822\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=324, train_loss_step=0.0153, train_loss_epoch=0.013]Epoch 496: Train Loss = 0.015282965265214443\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=324, train_loss_step=0.0142, train_loss_epoch=0.0153]Epoch 497: Train Loss = 0.01418482419103384\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=324, train_loss_step=0.0104, train_loss_epoch=0.0142]Epoch 498: Train Loss = 0.01039023045450449\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=324, train_loss_step=0.012, train_loss_epoch=0.0104] Epoch 499: Train Loss = 0.01196984015405178\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=324, train_loss_step=0.012, train_loss_epoch=0.012] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=324, train_loss_step=0.012, train_loss_epoch=0.012]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 11: from 2010-06-30 00:00:00 to 2022-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=328, train_loss_step=0.0288]Epoch 0: Train Loss = 0.028817100450396538\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=328, train_loss_step=0.0432, train_loss_epoch=0.0288]Epoch 1: Train Loss = 0.04322457313537598\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=328, train_loss_step=0.0271, train_loss_epoch=0.0432]Epoch 2: Train Loss = 0.027096880599856377\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=328, train_loss_step=0.0305, train_loss_epoch=0.0271]Epoch 3: Train Loss = 0.03046051785349846\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=328, train_loss_step=0.0306, train_loss_epoch=0.0305]Epoch 4: Train Loss = 0.030603576451539993\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=328, train_loss_step=0.019, train_loss_epoch=0.0306] Epoch 5: Train Loss = 0.018952613696455956\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=328, train_loss_step=0.0207, train_loss_epoch=0.019]Epoch 6: Train Loss = 0.020716968923807144\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=328, train_loss_step=0.018, train_loss_epoch=0.0207] Epoch 7: Train Loss = 0.017989376559853554\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=328, train_loss_step=0.0202, train_loss_epoch=0.018]Epoch 8: Train Loss = 0.02017355151474476\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=328, train_loss_step=0.0171, train_loss_epoch=0.0202]Epoch 9: Train Loss = 0.017146410420536995\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=328, train_loss_step=0.0203, train_loss_epoch=0.0171]Epoch 10: Train Loss = 0.020266497507691383\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s, v_num=328, train_loss_step=0.0187, train_loss_epoch=0.0203]Epoch 11: Train Loss = 0.0187244676053524\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s, v_num=328, train_loss_step=0.0163, train_loss_epoch=0.0187]Epoch 12: Train Loss = 0.016260692849755287\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 10.57it/s, v_num=328, train_loss_step=0.021, train_loss_epoch=0.0163] Epoch 13: Train Loss = 0.021029049530625343\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=328, train_loss_step=0.0184, train_loss_epoch=0.021]Epoch 14: Train Loss = 0.01844966784119606\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s, v_num=328, train_loss_step=0.0149, train_loss_epoch=0.0184]Epoch 15: Train Loss = 0.014858254231512547\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=328, train_loss_step=0.0177, train_loss_epoch=0.0149]Epoch 16: Train Loss = 0.017721522599458694\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0177]Epoch 17: Train Loss = 0.013244335539638996\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=328, train_loss_step=0.0146, train_loss_epoch=0.0132]Epoch 18: Train Loss = 0.014563838951289654\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.53it/s, v_num=328, train_loss_step=0.0245, train_loss_epoch=0.0146]Epoch 19: Train Loss = 0.024455565959215164\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=328, train_loss_step=0.0152, train_loss_epoch=0.0245]Epoch 20: Train Loss = 0.015185804106295109\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=328, train_loss_step=0.018, train_loss_epoch=0.0152] Epoch 21: Train Loss = 0.018045902252197266\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=328, train_loss_step=0.0197, train_loss_epoch=0.018]Epoch 22: Train Loss = 0.01970922015607357\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=328, train_loss_step=0.0169, train_loss_epoch=0.0197]Epoch 23: Train Loss = 0.01694326661527157\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=328, train_loss_step=0.0154, train_loss_epoch=0.0169]Epoch 24: Train Loss = 0.015351274982094765\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=328, train_loss_step=0.014, train_loss_epoch=0.0154] Epoch 25: Train Loss = 0.013993941247463226\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=328, train_loss_step=0.0161, train_loss_epoch=0.014]Epoch 26: Train Loss = 0.016136517748236656\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=328, train_loss_step=0.0169, train_loss_epoch=0.0161]Epoch 27: Train Loss = 0.016924643889069557\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=328, train_loss_step=0.0184, train_loss_epoch=0.0169]Epoch 28: Train Loss = 0.018400344997644424\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=328, train_loss_step=0.0164, train_loss_epoch=0.0184]Epoch 29: Train Loss = 0.01644073612987995\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=328, train_loss_step=0.0176, train_loss_epoch=0.0164]Epoch 30: Train Loss = 0.017603572458028793\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=328, train_loss_step=0.0146, train_loss_epoch=0.0176]Epoch 31: Train Loss = 0.01459313090890646\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=328, train_loss_step=0.0169, train_loss_epoch=0.0146]Epoch 32: Train Loss = 0.016872959211468697\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=328, train_loss_step=0.0238, train_loss_epoch=0.0169]Epoch 33: Train Loss = 0.023792119696736336\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.0238]Epoch 34: Train Loss = 0.013390353880822659\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=328, train_loss_step=0.0198, train_loss_epoch=0.0134]Epoch 35: Train Loss = 0.01976054534316063\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=328, train_loss_step=0.0212, train_loss_epoch=0.0198]Epoch 36: Train Loss = 0.021224115043878555\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=328, train_loss_step=0.0186, train_loss_epoch=0.0212]Epoch 37: Train Loss = 0.01857045479118824\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=328, train_loss_step=0.0173, train_loss_epoch=0.0186]Epoch 38: Train Loss = 0.017311185598373413\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=328, train_loss_step=0.0147, train_loss_epoch=0.0173]Epoch 39: Train Loss = 0.014701275154948235\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=328, train_loss_step=0.0137, train_loss_epoch=0.0147]Epoch 40: Train Loss = 0.013730814680457115\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=328, train_loss_step=0.0156, train_loss_epoch=0.0137]Epoch 41: Train Loss = 0.015595308504998684\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=328, train_loss_step=0.0166, train_loss_epoch=0.0156]Epoch 42: Train Loss = 0.016577690839767456\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=328, train_loss_step=0.0135, train_loss_epoch=0.0166]Epoch 43: Train Loss = 0.013529249466955662\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=328, train_loss_step=0.0149, train_loss_epoch=0.0135]Epoch 44: Train Loss = 0.014887526631355286\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s, v_num=328, train_loss_step=0.0152, train_loss_epoch=0.0149]Epoch 45: Train Loss = 0.015157009474933147\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=328, train_loss_step=0.0147, train_loss_epoch=0.0152]Epoch 46: Train Loss = 0.014707637950778008\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=328, train_loss_step=0.0199, train_loss_epoch=0.0147]Epoch 47: Train Loss = 0.019923582673072815\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=328, train_loss_step=0.016, train_loss_epoch=0.0199] Epoch 48: Train Loss = 0.01603926159441471\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=328, train_loss_step=0.0124, train_loss_epoch=0.016]Epoch 49: Train Loss = 0.012400252744555473\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=328, train_loss_step=0.0196, train_loss_epoch=0.0124]Epoch 50: Train Loss = 0.019643526524305344\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=328, train_loss_step=0.0191, train_loss_epoch=0.0196]Epoch 51: Train Loss = 0.019052779302001\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=328, train_loss_step=0.0146, train_loss_epoch=0.0191]Epoch 52: Train Loss = 0.014550448395311832\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=328, train_loss_step=0.0158, train_loss_epoch=0.0146]Epoch 53: Train Loss = 0.015816185623407364\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0158]Epoch 54: Train Loss = 0.013290615752339363\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 10.67it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0133]Epoch 55: Train Loss = 0.013324348255991936\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=328, train_loss_step=0.0122, train_loss_epoch=0.0133]Epoch 56: Train Loss = 0.012160505168139935\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=328, train_loss_step=0.0139, train_loss_epoch=0.0122]Epoch 57: Train Loss = 0.013866382651031017\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0139]Epoch 58: Train Loss = 0.011912068352103233\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0119]Epoch 59: Train Loss = 0.013156785629689693\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=328, train_loss_step=0.0152, train_loss_epoch=0.0132]Epoch 60: Train Loss = 0.015150665305554867\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=328, train_loss_step=0.0166, train_loss_epoch=0.0152]Epoch 61: Train Loss = 0.016572942957282066\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.0166]Epoch 62: Train Loss = 0.013368855230510235\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=328, train_loss_step=0.0183, train_loss_epoch=0.0134]Epoch 63: Train Loss = 0.018261602148413658\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=328, train_loss_step=0.0145, train_loss_epoch=0.0183]Epoch 64: Train Loss = 0.014498292468488216\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=328, train_loss_step=0.0141, train_loss_epoch=0.0145]Epoch 65: Train Loss = 0.014077423140406609\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=328, train_loss_step=0.0131, train_loss_epoch=0.0141]Epoch 66: Train Loss = 0.013119375333189964\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=328, train_loss_step=0.0183, train_loss_epoch=0.0131]Epoch 67: Train Loss = 0.018288837745785713\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0183]Epoch 68: Train Loss = 0.01186137180775404\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=328, train_loss_step=0.0167, train_loss_epoch=0.0119]Epoch 69: Train Loss = 0.01671162061393261\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=328, train_loss_step=0.0107, train_loss_epoch=0.0167]Epoch 70: Train Loss = 0.010689882561564445\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=328, train_loss_step=0.013, train_loss_epoch=0.0107] Epoch 71: Train Loss = 0.012950886972248554\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=328, train_loss_step=0.0142, train_loss_epoch=0.013]Epoch 72: Train Loss = 0.014162459410727024\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=328, train_loss_step=0.0112, train_loss_epoch=0.0142]Epoch 73: Train Loss = 0.011227918788790703\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=328, train_loss_step=0.0123, train_loss_epoch=0.0112]Epoch 74: Train Loss = 0.01234991755336523\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=328, train_loss_step=0.0108, train_loss_epoch=0.0123]Epoch 75: Train Loss = 0.01083330623805523\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=328, train_loss_step=0.0155, train_loss_epoch=0.0108]Epoch 76: Train Loss = 0.01552101131528616\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.0155]Epoch 77: Train Loss = 0.012851172126829624\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=328, train_loss_step=0.0201, train_loss_epoch=0.0129]Epoch 78: Train Loss = 0.020095299929380417\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=328, train_loss_step=0.0151, train_loss_epoch=0.0201]Epoch 79: Train Loss = 0.015051810070872307\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=328, train_loss_step=0.0169, train_loss_epoch=0.0151]Epoch 80: Train Loss = 0.016870714724063873\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=328, train_loss_step=0.0179, train_loss_epoch=0.0169]Epoch 81: Train Loss = 0.017892232164740562\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=328, train_loss_step=0.0139, train_loss_epoch=0.0179]Epoch 82: Train Loss = 0.013922537676990032\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=328, train_loss_step=0.0136, train_loss_epoch=0.0139]Epoch 83: Train Loss = 0.013570002280175686\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=328, train_loss_step=0.0145, train_loss_epoch=0.0136]Epoch 84: Train Loss = 0.014493902213871479\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=328, train_loss_step=0.0169, train_loss_epoch=0.0145]Epoch 85: Train Loss = 0.016912847757339478\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=328, train_loss_step=0.014, train_loss_epoch=0.0169] Epoch 86: Train Loss = 0.013980738818645477\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=328, train_loss_step=0.0173, train_loss_epoch=0.014]Epoch 87: Train Loss = 0.01729007251560688\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0173]Epoch 88: Train Loss = 0.012129931710660458\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=328, train_loss_step=0.0152, train_loss_epoch=0.0121]Epoch 89: Train Loss = 0.015183485113084316\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.0152]Epoch 90: Train Loss = 0.013406624086201191\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.0134]Epoch 91: Train Loss = 0.011090501211583614\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=328, train_loss_step=0.0184, train_loss_epoch=0.0111]Epoch 92: Train Loss = 0.018397821113467216\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=328, train_loss_step=0.0156, train_loss_epoch=0.0184]Epoch 93: Train Loss = 0.015605151653289795\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=328, train_loss_step=0.0191, train_loss_epoch=0.0156]Epoch 94: Train Loss = 0.01905878446996212\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=328, train_loss_step=0.0188, train_loss_epoch=0.0191]Epoch 95: Train Loss = 0.01876569166779518\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=328, train_loss_step=0.0142, train_loss_epoch=0.0188]Epoch 96: Train Loss = 0.014238002710044384\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s, v_num=328, train_loss_step=0.013, train_loss_epoch=0.0142] Epoch 97: Train Loss = 0.0129886819049716\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=328, train_loss_step=0.0156, train_loss_epoch=0.013]Epoch 98: Train Loss = 0.01561754196882248\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s, v_num=328, train_loss_step=0.0122, train_loss_epoch=0.0156]Epoch 99: Train Loss = 0.012229866348206997\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=328, train_loss_step=0.0169, train_loss_epoch=0.0122]Epoch 100: Train Loss = 0.01685480773448944\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=328, train_loss_step=0.0151, train_loss_epoch=0.0169]Epoch 101: Train Loss = 0.015079604461789131\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=328, train_loss_step=0.0138, train_loss_epoch=0.0151]Epoch 102: Train Loss = 0.013833287172019482\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s, v_num=328, train_loss_step=0.013, train_loss_epoch=0.0138] Epoch 103: Train Loss = 0.013041483238339424\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=328, train_loss_step=0.0104, train_loss_epoch=0.013]Epoch 104: Train Loss = 0.010373582132160664\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=328, train_loss_step=0.0171, train_loss_epoch=0.0104]Epoch 105: Train Loss = 0.017069300636649132\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=328, train_loss_step=0.014, train_loss_epoch=0.0171] Epoch 106: Train Loss = 0.013958999887108803\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.014]Epoch 107: Train Loss = 0.012949304655194283\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=328, train_loss_step=0.0168, train_loss_epoch=0.0129]Epoch 108: Train Loss = 0.016836969181895256\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0168]Epoch 109: Train Loss = 0.011860034428536892\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0119]Epoch 110: Train Loss = 0.013301996514201164\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.0133]Epoch 111: Train Loss = 0.012882371433079243\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=328, train_loss_step=0.0138, train_loss_epoch=0.0129]Epoch 112: Train Loss = 0.013832402415573597\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=328, train_loss_step=0.0141, train_loss_epoch=0.0138]Epoch 113: Train Loss = 0.014127634465694427\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=328, train_loss_step=0.0108, train_loss_epoch=0.0141]Epoch 114: Train Loss = 0.010831271298229694\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=328, train_loss_step=0.0159, train_loss_epoch=0.0108]Epoch 115: Train Loss = 0.015914496034383774\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.0159]Epoch 116: Train Loss = 0.013417082838714123\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, v_num=328, train_loss_step=0.0124, train_loss_epoch=0.0134]Epoch 117: Train Loss = 0.012413487769663334\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=328, train_loss_step=0.023, train_loss_epoch=0.0124] Epoch 118: Train Loss = 0.022978736087679863\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=328, train_loss_step=0.017, train_loss_epoch=0.023] Epoch 119: Train Loss = 0.016952285543084145\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=328, train_loss_step=0.0185, train_loss_epoch=0.017]Epoch 120: Train Loss = 0.018527625128626823\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=328, train_loss_step=0.0124, train_loss_epoch=0.0185]Epoch 121: Train Loss = 0.012375674210488796\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=328, train_loss_step=0.0105, train_loss_epoch=0.0124]Epoch 122: Train Loss = 0.010508807376027107\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s, v_num=328, train_loss_step=0.0151, train_loss_epoch=0.0105]Epoch 123: Train Loss = 0.015110904350876808\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.0151]Epoch 124: Train Loss = 0.013359942473471165\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=328, train_loss_step=0.0106, train_loss_epoch=0.0134]Epoch 125: Train Loss = 0.010596596635878086\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=328, train_loss_step=0.0148, train_loss_epoch=0.0106]Epoch 126: Train Loss = 0.014768257737159729\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=328, train_loss_step=0.011, train_loss_epoch=0.0148] Epoch 127: Train Loss = 0.011044887825846672\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=328, train_loss_step=0.0138, train_loss_epoch=0.011]Epoch 128: Train Loss = 0.013817181810736656\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=328, train_loss_step=0.0167, train_loss_epoch=0.0138]Epoch 129: Train Loss = 0.01668822392821312\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=328, train_loss_step=0.0195, train_loss_epoch=0.0167]Epoch 130: Train Loss = 0.01948791928589344\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s, v_num=328, train_loss_step=0.0196, train_loss_epoch=0.0195]Epoch 131: Train Loss = 0.019618486985564232\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=328, train_loss_step=0.0113, train_loss_epoch=0.0196]Epoch 132: Train Loss = 0.011304070241749287\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0113] Epoch 133: Train Loss = 0.012019450776278973\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=328, train_loss_step=0.014, train_loss_epoch=0.012] Epoch 134: Train Loss = 0.014044155366718769\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.014]Epoch 135: Train Loss = 0.011077961884438992\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=328, train_loss_step=0.0148, train_loss_epoch=0.0111]Epoch 136: Train Loss = 0.014775454066693783\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=328, train_loss_step=0.0144, train_loss_epoch=0.0148]Epoch 137: Train Loss = 0.014447406865656376\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 10.63it/s, v_num=328, train_loss_step=0.0178, train_loss_epoch=0.0144]Epoch 138: Train Loss = 0.017812633886933327\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=328, train_loss_step=0.014, train_loss_epoch=0.0178] Epoch 139: Train Loss = 0.0139523446559906\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=328, train_loss_step=0.014, train_loss_epoch=0.014] Epoch 140: Train Loss = 0.014002257026731968\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=328, train_loss_step=0.0146, train_loss_epoch=0.014]Epoch 141: Train Loss = 0.014639563858509064\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=328, train_loss_step=0.0112, train_loss_epoch=0.0146]Epoch 142: Train Loss = 0.01119125634431839\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=328, train_loss_step=0.0139, train_loss_epoch=0.0112]Epoch 143: Train Loss = 0.013926437124609947\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=328, train_loss_step=0.0138, train_loss_epoch=0.0139]Epoch 144: Train Loss = 0.01378577295690775\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=328, train_loss_step=0.0145, train_loss_epoch=0.0138]Epoch 145: Train Loss = 0.014497785829007626\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=328, train_loss_step=0.0139, train_loss_epoch=0.0145]Epoch 146: Train Loss = 0.013912802562117577\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=328, train_loss_step=0.0116, train_loss_epoch=0.0139]Epoch 147: Train Loss = 0.011589770205318928\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=328, train_loss_step=0.0107, train_loss_epoch=0.0116]Epoch 148: Train Loss = 0.010695180855691433\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=328, train_loss_step=0.0144, train_loss_epoch=0.0107]Epoch 149: Train Loss = 0.014414702542126179\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=328, train_loss_step=0.0143, train_loss_epoch=0.0144]Epoch 150: Train Loss = 0.014288966543972492\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=328, train_loss_step=0.0109, train_loss_epoch=0.0143]Epoch 151: Train Loss = 0.010912144556641579\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=328, train_loss_step=0.0125, train_loss_epoch=0.0109]Epoch 152: Train Loss = 0.012472273781895638\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=328, train_loss_step=0.0156, train_loss_epoch=0.0125]Epoch 153: Train Loss = 0.015629678964614868\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.0156]Epoch 154: Train Loss = 0.01286389958113432\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=328, train_loss_step=0.0173, train_loss_epoch=0.0129]Epoch 155: Train Loss = 0.017330553382635117\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=328, train_loss_step=0.0092, train_loss_epoch=0.0173]Epoch 156: Train Loss = 0.009199870750308037\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0092]Epoch 157: Train Loss = 0.011873183771967888\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=328, train_loss_step=0.0147, train_loss_epoch=0.0119]Epoch 158: Train Loss = 0.014661465771496296\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s, v_num=328, train_loss_step=0.0137, train_loss_epoch=0.0147]Epoch 159: Train Loss = 0.013680348172783852\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=328, train_loss_step=0.0152, train_loss_epoch=0.0137]Epoch 160: Train Loss = 0.015157805755734444\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=328, train_loss_step=0.0152, train_loss_epoch=0.0152]Epoch 161: Train Loss = 0.015175728127360344\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0152]Epoch 162: Train Loss = 0.013210250064730644\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=328, train_loss_step=0.0138, train_loss_epoch=0.0132]Epoch 163: Train Loss = 0.013833075761795044\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.0138]Epoch 164: Train Loss = 0.011848150752484798\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=328, train_loss_step=0.0108, train_loss_epoch=0.0118]Epoch 165: Train Loss = 0.010757188312709332\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=328, train_loss_step=0.0122, train_loss_epoch=0.0108]Epoch 166: Train Loss = 0.012227846309542656\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=328, train_loss_step=0.0182, train_loss_epoch=0.0122]Epoch 167: Train Loss = 0.018249988555908203\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=328, train_loss_step=0.0166, train_loss_epoch=0.0182]Epoch 168: Train Loss = 0.016557225957512856\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=328, train_loss_step=0.0105, train_loss_epoch=0.0166]Epoch 169: Train Loss = 0.010502362623810768\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=328, train_loss_step=0.0128, train_loss_epoch=0.0105]Epoch 170: Train Loss = 0.012787253595888615\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=328, train_loss_step=0.0151, train_loss_epoch=0.0128]Epoch 171: Train Loss = 0.015063543803989887\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=328, train_loss_step=0.0117, train_loss_epoch=0.0151]Epoch 172: Train Loss = 0.011731375940144062\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=328, train_loss_step=0.0123, train_loss_epoch=0.0117]Epoch 173: Train Loss = 0.012320386245846748\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0123]Epoch 174: Train Loss = 0.011870724149048328\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0119]Epoch 175: Train Loss = 0.012144158594310284\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0121]Epoch 176: Train Loss = 0.013203895650804043\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0132]Epoch 177: Train Loss = 0.012051261030137539\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=328, train_loss_step=0.0113, train_loss_epoch=0.0121]Epoch 178: Train Loss = 0.011262698099017143\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=328, train_loss_step=0.0161, train_loss_epoch=0.0113]Epoch 179: Train Loss = 0.016096550971269608\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 11.26it/s, v_num=328, train_loss_step=0.0124, train_loss_epoch=0.0161]Epoch 180: Train Loss = 0.01236756145954132\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=328, train_loss_step=0.0159, train_loss_epoch=0.0124]Epoch 181: Train Loss = 0.01594606228172779\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=328, train_loss_step=0.0196, train_loss_epoch=0.0159]Epoch 182: Train Loss = 0.019647061824798584\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=328, train_loss_step=0.0166, train_loss_epoch=0.0196]Epoch 183: Train Loss = 0.01661541685461998\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0166]Epoch 184: Train Loss = 0.013245178386569023\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=328, train_loss_step=0.00945, train_loss_epoch=0.0132]Epoch 185: Train Loss = 0.009445191361010075\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.00945] Epoch 186: Train Loss = 0.012937179766595364\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0129]  Epoch 187: Train Loss = 0.012009839527308941\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=328, train_loss_step=0.0124, train_loss_epoch=0.012]Epoch 188: Train Loss = 0.012355229817330837\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s, v_num=328, train_loss_step=0.0122, train_loss_epoch=0.0124]Epoch 189: Train Loss = 0.01222543977200985\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=328, train_loss_step=0.0112, train_loss_epoch=0.0122]Epoch 190: Train Loss = 0.011233234778046608\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=328, train_loss_step=0.0109, train_loss_epoch=0.0112]Epoch 191: Train Loss = 0.01088380254805088\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 13.21it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.0109]Epoch 192: Train Loss = 0.012935282662510872\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0129]Epoch 193: Train Loss = 0.013242237269878387\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0132]Epoch 194: Train Loss = 0.012061310932040215\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=328, train_loss_step=0.0131, train_loss_epoch=0.0121]Epoch 195: Train Loss = 0.01308646984398365\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=328, train_loss_step=0.0156, train_loss_epoch=0.0131]Epoch 196: Train Loss = 0.015557789243757725\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0156]Epoch 197: Train Loss = 0.013321404345333576\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0133] Epoch 198: Train Loss = 0.012040606699883938\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s, v_num=328, train_loss_step=0.0122, train_loss_epoch=0.012]Epoch 199: Train Loss = 0.012241578660905361\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=328, train_loss_step=0.0127, train_loss_epoch=0.0122]Epoch 200: Train Loss = 0.012749433517456055\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.0127]Epoch 201: Train Loss = 0.013364526443183422\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.0134]Epoch 202: Train Loss = 0.012905052863061428\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s, v_num=328, train_loss_step=0.020, train_loss_epoch=0.0129] Epoch 203: Train Loss = 0.02001981995999813\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=328, train_loss_step=0.0144, train_loss_epoch=0.020]Epoch 204: Train Loss = 0.014350694604218006\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=328, train_loss_step=0.0105, train_loss_epoch=0.0144]Epoch 205: Train Loss = 0.010494434274733067\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=328, train_loss_step=0.0136, train_loss_epoch=0.0105]Epoch 206: Train Loss = 0.01356428675353527\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=328, train_loss_step=0.0137, train_loss_epoch=0.0136]Epoch 207: Train Loss = 0.01370673906058073\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=328, train_loss_step=0.0152, train_loss_epoch=0.0137]Epoch 208: Train Loss = 0.015164874494075775\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=328, train_loss_step=0.0158, train_loss_epoch=0.0152]Epoch 209: Train Loss = 0.015810584649443626\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.0158]Epoch 210: Train Loss = 0.011776642873883247\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=328, train_loss_step=0.0125, train_loss_epoch=0.0118]Epoch 211: Train Loss = 0.012512036599218845\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=328, train_loss_step=0.0112, train_loss_epoch=0.0125]Epoch 212: Train Loss = 0.011186161078512669\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=328, train_loss_step=0.0138, train_loss_epoch=0.0112]Epoch 213: Train Loss = 0.013835450634360313\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=328, train_loss_step=0.0137, train_loss_epoch=0.0138]Epoch 214: Train Loss = 0.013726930133998394\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0137]Epoch 215: Train Loss = 0.011504706926643848\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=328, train_loss_step=0.0146, train_loss_epoch=0.0115]Epoch 216: Train Loss = 0.014639558270573616\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.0146]Epoch 217: Train Loss = 0.012915513478219509\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s, v_num=328, train_loss_step=0.0126, train_loss_epoch=0.0129]Epoch 218: Train Loss = 0.012607193551957607\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=328, train_loss_step=0.0159, train_loss_epoch=0.0126]Epoch 219: Train Loss = 0.01588393561542034\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=328, train_loss_step=0.0139, train_loss_epoch=0.0159]Epoch 220: Train Loss = 0.013909849338233471\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=328, train_loss_step=0.0109, train_loss_epoch=0.0139]Epoch 221: Train Loss = 0.010855907574295998\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=328, train_loss_step=0.0117, train_loss_epoch=0.0109]Epoch 222: Train Loss = 0.011684372089803219\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=328, train_loss_step=0.00898, train_loss_epoch=0.0117]Epoch 223: Train Loss = 0.008980980142951012\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.00898] Epoch 224: Train Loss = 0.011917251162230968\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=328, train_loss_step=0.011, train_loss_epoch=0.0119]  Epoch 225: Train Loss = 0.01100893970578909\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=328, train_loss_step=0.0139, train_loss_epoch=0.011]Epoch 226: Train Loss = 0.013853117823600769\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=328, train_loss_step=0.00926, train_loss_epoch=0.0139]Epoch 227: Train Loss = 0.009259944781661034\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.00926] Epoch 228: Train Loss = 0.01332654058933258\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0133] Epoch 229: Train Loss = 0.01327748503535986\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=328, train_loss_step=0.0161, train_loss_epoch=0.0133]Epoch 230: Train Loss = 0.01606428250670433\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=328, train_loss_step=0.0131, train_loss_epoch=0.0161]Epoch 231: Train Loss = 0.013141290284693241\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0131]Epoch 232: Train Loss = 0.013192588463425636\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0132] Epoch 233: Train Loss = 0.012001527473330498\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=328, train_loss_step=0.0131, train_loss_epoch=0.012]Epoch 234: Train Loss = 0.01305768545717001\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.0131]Epoch 235: Train Loss = 0.011059954762458801\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=328, train_loss_step=0.0145, train_loss_epoch=0.0111]Epoch 236: Train Loss = 0.014464370906352997\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.0145]Epoch 237: Train Loss = 0.013440768234431744\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=328, train_loss_step=0.0145, train_loss_epoch=0.0134]Epoch 238: Train Loss = 0.014496104791760445\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=328, train_loss_step=0.014, train_loss_epoch=0.0145] Epoch 239: Train Loss = 0.014013268984854221\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=328, train_loss_step=0.0117, train_loss_epoch=0.014]Epoch 240: Train Loss = 0.01173832081258297\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=328, train_loss_step=0.0124, train_loss_epoch=0.0117]Epoch 241: Train Loss = 0.012368469499051571\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0124]Epoch 242: Train Loss = 0.013311457820236683\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0133]Epoch 243: Train Loss = 0.012119585648179054\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=328, train_loss_step=0.0127, train_loss_epoch=0.0121]Epoch 244: Train Loss = 0.012683005072176456\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=328, train_loss_step=0.0114, train_loss_epoch=0.0127]Epoch 245: Train Loss = 0.01143820583820343\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=328, train_loss_step=0.0131, train_loss_epoch=0.0114]Epoch 246: Train Loss = 0.013085910119116306\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=328, train_loss_step=0.0136, train_loss_epoch=0.0131]Epoch 247: Train Loss = 0.013649438507854939\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.0136]Epoch 248: Train Loss = 0.011088035069406033\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=328, train_loss_step=0.0117, train_loss_epoch=0.0111]Epoch 249: Train Loss = 0.011651014909148216\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=328, train_loss_step=0.0101, train_loss_epoch=0.0117]Epoch 250: Train Loss = 0.010074686259031296\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=328, train_loss_step=0.0103, train_loss_epoch=0.0101]Epoch 251: Train Loss = 0.01033258717507124\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=328, train_loss_step=0.00961, train_loss_epoch=0.0103]Epoch 252: Train Loss = 0.009614742361009121\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=328, train_loss_step=0.00986, train_loss_epoch=0.00961]Epoch 253: Train Loss = 0.009861530736088753\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.00986] Epoch 254: Train Loss = 0.011828013695776463\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=328, train_loss_step=0.0165, train_loss_epoch=0.0118] Epoch 255: Train Loss = 0.016517871990799904\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=328, train_loss_step=0.0116, train_loss_epoch=0.0165]Epoch 256: Train Loss = 0.01159993838518858\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=328, train_loss_step=0.0123, train_loss_epoch=0.0116]Epoch 257: Train Loss = 0.012271059677004814\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.0123]Epoch 258: Train Loss = 0.01179706770926714\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0118]Epoch 259: Train Loss = 0.011504063382744789\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=328, train_loss_step=0.0131, train_loss_epoch=0.0115]Epoch 260: Train Loss = 0.01309715025126934\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=328, train_loss_step=0.014, train_loss_epoch=0.0131] Epoch 261: Train Loss = 0.014007502235472202\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.014]Epoch 262: Train Loss = 0.01179139781743288\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.0118]Epoch 263: Train Loss = 0.011849842965602875\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=328, train_loss_step=0.0164, train_loss_epoch=0.0118]Epoch 264: Train Loss = 0.01642022840678692\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=328, train_loss_step=0.014, train_loss_epoch=0.0164] Epoch 265: Train Loss = 0.013983963057398796\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=328, train_loss_step=0.0117, train_loss_epoch=0.014]Epoch 266: Train Loss = 0.011656375601887703\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s, v_num=328, train_loss_step=0.00946, train_loss_epoch=0.0117]Epoch 267: Train Loss = 0.009462115354835987\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=328, train_loss_step=0.0127, train_loss_epoch=0.00946] Epoch 268: Train Loss = 0.0127353360876441\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.0127] Epoch 269: Train Loss = 0.011799178086221218\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=328, train_loss_step=0.0151, train_loss_epoch=0.0118]Epoch 270: Train Loss = 0.015083707869052887\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.0151]Epoch 271: Train Loss = 0.013386569917201996\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0134]Epoch 272: Train Loss = 0.011888623237609863\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=328, train_loss_step=0.0128, train_loss_epoch=0.0119]Epoch 273: Train Loss = 0.012752433307468891\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=328, train_loss_step=0.0138, train_loss_epoch=0.0128]Epoch 274: Train Loss = 0.013799949549138546\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0138]Epoch 275: Train Loss = 0.012132398784160614\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=328, train_loss_step=0.0154, train_loss_epoch=0.0121]Epoch 276: Train Loss = 0.015442438423633575\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0154]Epoch 277: Train Loss = 0.011475203558802605\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=328, train_loss_step=0.0126, train_loss_epoch=0.0115]Epoch 278: Train Loss = 0.012596801854670048\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0126]Epoch 279: Train Loss = 0.013323022052645683\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0133]Epoch 280: Train Loss = 0.013184666633605957\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=328, train_loss_step=0.0142, train_loss_epoch=0.0132]Epoch 281: Train Loss = 0.014242231845855713\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=328, train_loss_step=0.013, train_loss_epoch=0.0142] Epoch 282: Train Loss = 0.01296018436551094\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.013] Epoch 283: Train Loss = 0.011952564120292664\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=328, train_loss_step=0.0112, train_loss_epoch=0.012]Epoch 284: Train Loss = 0.01117183268070221\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=328, train_loss_step=0.0114, train_loss_epoch=0.0112]Epoch 285: Train Loss = 0.01140797883272171\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=328, train_loss_step=0.0116, train_loss_epoch=0.0114]Epoch 286: Train Loss = 0.01164668332785368\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=328, train_loss_step=0.0117, train_loss_epoch=0.0116]Epoch 287: Train Loss = 0.011706291697919369\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=328, train_loss_step=0.0113, train_loss_epoch=0.0117]Epoch 288: Train Loss = 0.011343047022819519\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0113]Epoch 289: Train Loss = 0.012120378203690052\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=328, train_loss_step=0.0138, train_loss_epoch=0.0121]Epoch 290: Train Loss = 0.013759230263531208\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0138]Epoch 291: Train Loss = 0.013159893453121185\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=328, train_loss_step=0.0149, train_loss_epoch=0.0132]Epoch 292: Train Loss = 0.014934518374502659\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=328, train_loss_step=0.00994, train_loss_epoch=0.0149]Epoch 293: Train Loss = 0.009939596988260746\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=328, train_loss_step=0.0124, train_loss_epoch=0.00994] Epoch 294: Train Loss = 0.012436429038643837\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0124] Epoch 295: Train Loss = 0.01154207531362772\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=328, train_loss_step=0.011, train_loss_epoch=0.0115] Epoch 296: Train Loss = 0.011024920269846916\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=328, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 297: Train Loss = 0.01250010821968317\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=328, train_loss_step=0.0112, train_loss_epoch=0.0125]Epoch 298: Train Loss = 0.01118527539074421\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=328, train_loss_step=0.0114, train_loss_epoch=0.0112]Epoch 299: Train Loss = 0.011438584886491299\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=328, train_loss_step=0.0105, train_loss_epoch=0.0114]Epoch 300: Train Loss = 0.010472779162228107\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=328, train_loss_step=0.0174, train_loss_epoch=0.0105]Epoch 301: Train Loss = 0.017447371035814285\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0174]Epoch 302: Train Loss = 0.011494538746774197\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=328, train_loss_step=0.00975, train_loss_epoch=0.0115]Epoch 303: Train Loss = 0.00975324772298336\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=328, train_loss_step=0.0171, train_loss_epoch=0.00975] Epoch 304: Train Loss = 0.017103025689721107\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=328, train_loss_step=0.0112, train_loss_epoch=0.0171] Epoch 305: Train Loss = 0.011220612563192844\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=328, train_loss_step=0.0141, train_loss_epoch=0.0112]Epoch 306: Train Loss = 0.014120185747742653\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=328, train_loss_step=0.0114, train_loss_epoch=0.0141]Epoch 307: Train Loss = 0.011427275836467743\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=328, train_loss_step=0.0159, train_loss_epoch=0.0114]Epoch 308: Train Loss = 0.015936996787786484\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=328, train_loss_step=0.0144, train_loss_epoch=0.0159]Epoch 309: Train Loss = 0.01444264780730009\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=328, train_loss_step=0.00936, train_loss_epoch=0.0144]Epoch 310: Train Loss = 0.009361485950648785\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.00936] Epoch 311: Train Loss = 0.01181870512664318\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0118] Epoch 312: Train Loss = 0.011483178474009037\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=328, train_loss_step=0.00939, train_loss_epoch=0.0115]Epoch 313: Train Loss = 0.009388767182826996\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=328, train_loss_step=0.0104, train_loss_epoch=0.00939] Epoch 314: Train Loss = 0.010445023886859417\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=328, train_loss_step=0.0102, train_loss_epoch=0.0104] Epoch 315: Train Loss = 0.010218472220003605\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=328, train_loss_step=0.0123, train_loss_epoch=0.0102]Epoch 316: Train Loss = 0.012294856831431389\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0123] Epoch 317: Train Loss = 0.012042819522321224\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.012]Epoch 318: Train Loss = 0.01343744806945324\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=328, train_loss_step=0.0153, train_loss_epoch=0.0134]Epoch 319: Train Loss = 0.015260257758200169\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0153]Epoch 320: Train Loss = 0.01189328171312809\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=328, train_loss_step=0.011, train_loss_epoch=0.0119] Epoch 321: Train Loss = 0.01101046521216631\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=328, train_loss_step=0.0138, train_loss_epoch=0.011]Epoch 322: Train Loss = 0.013756586238741875\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=328, train_loss_step=0.0194, train_loss_epoch=0.0138]Epoch 323: Train Loss = 0.01943911798298359\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=328, train_loss_step=0.0102, train_loss_epoch=0.0194]Epoch 324: Train Loss = 0.010237491689622402\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=328, train_loss_step=0.0104, train_loss_epoch=0.0102]Epoch 325: Train Loss = 0.010438316501677036\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0104]Epoch 326: Train Loss = 0.013259236700832844\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=328, train_loss_step=0.0113, train_loss_epoch=0.0133]Epoch 327: Train Loss = 0.011337033472955227\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=328, train_loss_step=0.0153, train_loss_epoch=0.0113]Epoch 328: Train Loss = 0.01525983214378357\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=328, train_loss_step=0.0114, train_loss_epoch=0.0153]Epoch 329: Train Loss = 0.011444617994129658\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=328, train_loss_step=0.00977, train_loss_epoch=0.0114]Epoch 330: Train Loss = 0.009769098833203316\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=328, train_loss_step=0.0125, train_loss_epoch=0.00977] Epoch 331: Train Loss = 0.012528321705758572\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=328, train_loss_step=0.0148, train_loss_epoch=0.0125] Epoch 332: Train Loss = 0.014821923337876797\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=328, train_loss_step=0.0112, train_loss_epoch=0.0148]Epoch 333: Train Loss = 0.011217926628887653\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=328, train_loss_step=0.00999, train_loss_epoch=0.0112]Epoch 334: Train Loss = 0.009987333789467812\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=328, train_loss_step=0.0124, train_loss_epoch=0.00999] Epoch 335: Train Loss = 0.012351551093161106\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0124] Epoch 336: Train Loss = 0.011876347474753857\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=328, train_loss_step=0.0125, train_loss_epoch=0.0119]Epoch 337: Train Loss = 0.012514611706137657\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=328, train_loss_step=0.0128, train_loss_epoch=0.0125]Epoch 338: Train Loss = 0.012774045579135418\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=328, train_loss_step=0.0105, train_loss_epoch=0.0128]Epoch 339: Train Loss = 0.010512389242649078\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=328, train_loss_step=0.0135, train_loss_epoch=0.0105]Epoch 340: Train Loss = 0.013454491272568703\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=328, train_loss_step=0.00889, train_loss_epoch=0.0135]Epoch 341: Train Loss = 0.008885180577635765\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=328, train_loss_step=0.0137, train_loss_epoch=0.00889] Epoch 342: Train Loss = 0.013676473870873451\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s, v_num=328, train_loss_step=0.0116, train_loss_epoch=0.0137] Epoch 343: Train Loss = 0.011574341915547848\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=328, train_loss_step=0.0101, train_loss_epoch=0.0116]Epoch 344: Train Loss = 0.010140920989215374\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0101]Epoch 345: Train Loss = 0.011941668577492237\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0119]Epoch 346: Train Loss = 0.01213045697659254\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=328, train_loss_step=0.0158, train_loss_epoch=0.0121]Epoch 347: Train Loss = 0.01579359546303749\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=328, train_loss_step=0.00881, train_loss_epoch=0.0158]Epoch 348: Train Loss = 0.008812381885945797\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.00881] Epoch 349: Train Loss = 0.01191477570682764\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 11.14it/s, v_num=328, train_loss_step=0.010, train_loss_epoch=0.0119]  Epoch 350: Train Loss = 0.010036922059953213\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=328, train_loss_step=0.0125, train_loss_epoch=0.010]Epoch 351: Train Loss = 0.012519566342234612\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0125]Epoch 352: Train Loss = 0.013263218104839325\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=328, train_loss_step=0.0137, train_loss_epoch=0.0133]Epoch 353: Train Loss = 0.013738092966377735\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 11.26it/s, v_num=328, train_loss_step=0.0152, train_loss_epoch=0.0137]Epoch 354: Train Loss = 0.01522899605333805\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.0152]Epoch 355: Train Loss = 0.012905404902994633\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.0129]Epoch 356: Train Loss = 0.011755079962313175\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  3.38it/s, v_num=328, train_loss_step=0.0148, train_loss_epoch=0.0118]Epoch 357: Train Loss = 0.014783995226025581\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=328, train_loss_step=0.0136, train_loss_epoch=0.0148]Epoch 358: Train Loss = 0.013632476329803467\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=328, train_loss_step=0.0199, train_loss_epoch=0.0136]Epoch 359: Train Loss = 0.019886301830410957\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=328, train_loss_step=0.0113, train_loss_epoch=0.0199]Epoch 360: Train Loss = 0.011292592622339725\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=328, train_loss_step=0.0112, train_loss_epoch=0.0113]Epoch 361: Train Loss = 0.011166413314640522\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=328, train_loss_step=0.0127, train_loss_epoch=0.0112]Epoch 362: Train Loss = 0.012685156427323818\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 12.40it/s, v_num=328, train_loss_step=0.0144, train_loss_epoch=0.0127]Epoch 363: Train Loss = 0.014392375946044922\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=328, train_loss_step=0.0199, train_loss_epoch=0.0144]Epoch 364: Train Loss = 0.01989150419831276\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0199] Epoch 365: Train Loss = 0.01198191475123167\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=328, train_loss_step=0.0114, train_loss_epoch=0.012]Epoch 366: Train Loss = 0.011354672722518444\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.0114]Epoch 367: Train Loss = 0.012893930077552795\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=328, train_loss_step=0.0107, train_loss_epoch=0.0129]Epoch 368: Train Loss = 0.01067368034273386\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, v_num=328, train_loss_step=0.013, train_loss_epoch=0.0107] Epoch 369: Train Loss = 0.012951119802892208\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=328, train_loss_step=0.0137, train_loss_epoch=0.013]Epoch 370: Train Loss = 0.013714724220335484\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0137]Epoch 371: Train Loss = 0.012080998159945011\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=328, train_loss_step=0.0122, train_loss_epoch=0.0121]Epoch 372: Train Loss = 0.01220095157623291\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=328, train_loss_step=0.0173, train_loss_epoch=0.0122]Epoch 373: Train Loss = 0.01731201820075512\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=328, train_loss_step=0.011, train_loss_epoch=0.0173] Epoch 374: Train Loss = 0.010954088531434536\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=328, train_loss_step=0.0101, train_loss_epoch=0.011]Epoch 375: Train Loss = 0.010090800933539867\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.0101]Epoch 376: Train Loss = 0.01177708525210619\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=328, train_loss_step=0.0127, train_loss_epoch=0.0118]Epoch 377: Train Loss = 0.012662331573665142\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=328, train_loss_step=0.0135, train_loss_epoch=0.0127]Epoch 378: Train Loss = 0.013509228825569153\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0135]Epoch 379: Train Loss = 0.0133427819237113\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0133]Epoch 380: Train Loss = 0.013177350163459778\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=328, train_loss_step=0.0107, train_loss_epoch=0.0132]Epoch 381: Train Loss = 0.010739126242697239\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=328, train_loss_step=0.0114, train_loss_epoch=0.0107]Epoch 382: Train Loss = 0.011431192047894001\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=328, train_loss_step=0.0127, train_loss_epoch=0.0114]Epoch 383: Train Loss = 0.012688634917140007\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=328, train_loss_step=0.0169, train_loss_epoch=0.0127]Epoch 384: Train Loss = 0.016893988475203514\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=328, train_loss_step=0.0184, train_loss_epoch=0.0169]Epoch 385: Train Loss = 0.018406052142381668\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=328, train_loss_step=0.0139, train_loss_epoch=0.0184]Epoch 386: Train Loss = 0.013894726522266865\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=328, train_loss_step=0.00964, train_loss_epoch=0.0139]Epoch 387: Train Loss = 0.009642085060477257\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=328, train_loss_step=0.0166, train_loss_epoch=0.00964] Epoch 388: Train Loss = 0.016622791066765785\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=328, train_loss_step=0.011, train_loss_epoch=0.0166]  Epoch 389: Train Loss = 0.010985800996422768\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=328, train_loss_step=0.0142, train_loss_epoch=0.011]Epoch 390: Train Loss = 0.014211693778634071\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0142] Epoch 391: Train Loss = 0.011985276825726032\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.012]Epoch 392: Train Loss = 0.011128097772598267\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.0111]Epoch 393: Train Loss = 0.01108615379780531\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0111]Epoch 394: Train Loss = 0.011947804130613804\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=328, train_loss_step=0.0168, train_loss_epoch=0.0119]Epoch 395: Train Loss = 0.0167959276586771\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=328, train_loss_step=0.017, train_loss_epoch=0.0168] Epoch 396: Train Loss = 0.016968602314591408\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=328, train_loss_step=0.0162, train_loss_epoch=0.017]Epoch 397: Train Loss = 0.016200153157114983\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=328, train_loss_step=0.0122, train_loss_epoch=0.0162]Epoch 398: Train Loss = 0.012213647365570068\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=328, train_loss_step=0.011, train_loss_epoch=0.0122] Epoch 399: Train Loss = 0.010981974191963673\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=328, train_loss_step=0.0136, train_loss_epoch=0.011]Epoch 400: Train Loss = 0.013562004081904888\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=328, train_loss_step=0.0123, train_loss_epoch=0.0136]Epoch 401: Train Loss = 0.012265300378203392\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0123] Epoch 402: Train Loss = 0.011991682462394238\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=328, train_loss_step=0.0125, train_loss_epoch=0.012]Epoch 403: Train Loss = 0.012478798627853394\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=328, train_loss_step=0.0179, train_loss_epoch=0.0125]Epoch 404: Train Loss = 0.017862549051642418\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=328, train_loss_step=0.0154, train_loss_epoch=0.0179]Epoch 405: Train Loss = 0.015378512442111969\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=328, train_loss_step=0.0102, train_loss_epoch=0.0154]Epoch 406: Train Loss = 0.010245690122246742\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0102]Epoch 407: Train Loss = 0.012103044427931309\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=328, train_loss_step=0.0155, train_loss_epoch=0.0121]Epoch 408: Train Loss = 0.015474652871489525\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=328, train_loss_step=0.0121, train_loss_epoch=0.0155]Epoch 409: Train Loss = 0.01206300500780344\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=328, train_loss_step=0.0151, train_loss_epoch=0.0121]Epoch 410: Train Loss = 0.015078661032021046\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s, v_num=328, train_loss_step=0.0151, train_loss_epoch=0.0151]Epoch 411: Train Loss = 0.015116612426936626\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s, v_num=328, train_loss_step=0.013, train_loss_epoch=0.0151] Epoch 412: Train Loss = 0.012999272905290127\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.013] Epoch 413: Train Loss = 0.012033993378281593\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=328, train_loss_step=0.0169, train_loss_epoch=0.012]Epoch 414: Train Loss = 0.016903946176171303\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=328, train_loss_step=0.0108, train_loss_epoch=0.0169]Epoch 415: Train Loss = 0.010786657221615314\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=328, train_loss_step=0.0181, train_loss_epoch=0.0108]Epoch 416: Train Loss = 0.01814354583621025\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=328, train_loss_step=0.0124, train_loss_epoch=0.0181]Epoch 417: Train Loss = 0.012431517243385315\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s, v_num=328, train_loss_step=0.0114, train_loss_epoch=0.0124]Epoch 418: Train Loss = 0.01139927003532648\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=328, train_loss_step=0.0104, train_loss_epoch=0.0114]Epoch 419: Train Loss = 0.010437631979584694\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0104]Epoch 420: Train Loss = 0.013334681279957294\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=328, train_loss_step=0.0209, train_loss_epoch=0.0133]Epoch 421: Train Loss = 0.020948220044374466\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=328, train_loss_step=0.0108, train_loss_epoch=0.0209]Epoch 422: Train Loss = 0.010809446685016155\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=328, train_loss_step=0.0105, train_loss_epoch=0.0108]Epoch 423: Train Loss = 0.01049633789807558\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=328, train_loss_step=0.00819, train_loss_epoch=0.0105]Epoch 424: Train Loss = 0.00818787794560194\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=328, train_loss_step=0.0126, train_loss_epoch=0.00819] Epoch 425: Train Loss = 0.01256837509572506\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=328, train_loss_step=0.0104, train_loss_epoch=0.0126] Epoch 426: Train Loss = 0.010438577271997929\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=328, train_loss_step=0.0152, train_loss_epoch=0.0104]Epoch 427: Train Loss = 0.015223766677081585\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0152]Epoch 428: Train Loss = 0.011530159041285515\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=328, train_loss_step=0.0102, train_loss_epoch=0.0115]Epoch 429: Train Loss = 0.010168222710490227\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=328, train_loss_step=0.0101, train_loss_epoch=0.0102]Epoch 430: Train Loss = 0.010071082040667534\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.0101]Epoch 431: Train Loss = 0.011056355200707912\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=328, train_loss_step=0.00918, train_loss_epoch=0.0111]Epoch 432: Train Loss = 0.009183898568153381\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.00918] Epoch 433: Train Loss = 0.011127718724310398\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0111] Epoch 434: Train Loss = 0.011871608905494213\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0119] Epoch 435: Train Loss = 0.01202864944934845\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.012]Epoch 436: Train Loss = 0.013319907709956169\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=328, train_loss_step=0.0106, train_loss_epoch=0.0133]Epoch 437: Train Loss = 0.01056462712585926\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=328, train_loss_step=0.00969, train_loss_epoch=0.0106]Epoch 438: Train Loss = 0.009687510319054127\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=328, train_loss_step=0.0136, train_loss_epoch=0.00969] Epoch 439: Train Loss = 0.013571503572165966\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=328, train_loss_step=0.0107, train_loss_epoch=0.0136] Epoch 440: Train Loss = 0.010655305348336697\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=328, train_loss_step=0.0117, train_loss_epoch=0.0107]Epoch 441: Train Loss = 0.011691704392433167\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=328, train_loss_step=0.0127, train_loss_epoch=0.0117]Epoch 442: Train Loss = 0.012746755965054035\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=328, train_loss_step=0.0099, train_loss_epoch=0.0127]Epoch 443: Train Loss = 0.009898355230689049\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=328, train_loss_step=0.0106, train_loss_epoch=0.0099]Epoch 444: Train Loss = 0.010603280737996101\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.0106]Epoch 445: Train Loss = 0.011764787137508392\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=328, train_loss_step=0.0144, train_loss_epoch=0.0118]Epoch 446: Train Loss = 0.014351949095726013\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=328, train_loss_step=0.00958, train_loss_epoch=0.0144]Epoch 447: Train Loss = 0.009579600766301155\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=328, train_loss_step=0.0103, train_loss_epoch=0.00958] Epoch 448: Train Loss = 0.010304811410605907\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.0103] Epoch 449: Train Loss = 0.013398970477283001\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=328, train_loss_step=0.0109, train_loss_epoch=0.0134]Epoch 450: Train Loss = 0.01086761336773634\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0109]Epoch 451: Train Loss = 0.01334891002625227\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.0133]Epoch 452: Train Loss = 0.011082307435572147\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=328, train_loss_step=0.0125, train_loss_epoch=0.0111]Epoch 453: Train Loss = 0.012501361779868603\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=328, train_loss_step=0.0162, train_loss_epoch=0.0125]Epoch 454: Train Loss = 0.016232021152973175\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=328, train_loss_step=0.0134, train_loss_epoch=0.0162]Epoch 455: Train Loss = 0.013372743502259254\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.0134]Epoch 456: Train Loss = 0.011907992884516716\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, v_num=328, train_loss_step=0.0136, train_loss_epoch=0.0119]Epoch 457: Train Loss = 0.013588658533990383\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=328, train_loss_step=0.011, train_loss_epoch=0.0136] Epoch 458: Train Loss = 0.011003767140209675\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=328, train_loss_step=0.0118, train_loss_epoch=0.011]Epoch 459: Train Loss = 0.011758966371417046\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=328, train_loss_step=0.0109, train_loss_epoch=0.0118]Epoch 460: Train Loss = 0.010924560017883778\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=328, train_loss_step=0.0155, train_loss_epoch=0.0109]Epoch 461: Train Loss = 0.01553274504840374\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=328, train_loss_step=0.0108, train_loss_epoch=0.0155]Epoch 462: Train Loss = 0.01076023280620575\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=328, train_loss_step=0.0107, train_loss_epoch=0.0108]Epoch 463: Train Loss = 0.010701806284487247\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.0107]Epoch 464: Train Loss = 0.011061224155128002\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=328, train_loss_step=0.0125, train_loss_epoch=0.0111]Epoch 465: Train Loss = 0.012526663951575756\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=328, train_loss_step=0.0144, train_loss_epoch=0.0125]Epoch 466: Train Loss = 0.014393390156328678\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0144]Epoch 467: Train Loss = 0.011512036435306072\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=328, train_loss_step=0.0101, train_loss_epoch=0.0115]Epoch 468: Train Loss = 0.010138158686459064\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0101] Epoch 469: Train Loss = 0.011995951645076275\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=328, train_loss_step=0.014, train_loss_epoch=0.012] Epoch 470: Train Loss = 0.013966959901154041\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=328, train_loss_step=0.0119, train_loss_epoch=0.014]Epoch 471: Train Loss = 0.011931424029171467\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=328, train_loss_step=0.00975, train_loss_epoch=0.0119]Epoch 472: Train Loss = 0.009749633260071278\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=328, train_loss_step=0.0117, train_loss_epoch=0.00975] Epoch 473: Train Loss = 0.01168135553598404\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0117] Epoch 474: Train Loss = 0.013285813853144646\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=328, train_loss_step=0.011, train_loss_epoch=0.0133] Epoch 475: Train Loss = 0.011009305715560913\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=328, train_loss_step=0.0123, train_loss_epoch=0.011]Epoch 476: Train Loss = 0.012277582660317421\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=328, train_loss_step=0.0105, train_loss_epoch=0.0123]Epoch 477: Train Loss = 0.010517380200326443\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=328, train_loss_step=0.00981, train_loss_epoch=0.0105]Epoch 478: Train Loss = 0.009812896139919758\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=328, train_loss_step=0.0157, train_loss_epoch=0.00981] Epoch 479: Train Loss = 0.015720220282673836\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=328, train_loss_step=0.0129, train_loss_epoch=0.0157] Epoch 480: Train Loss = 0.012922187335789204\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=328, train_loss_step=0.0147, train_loss_epoch=0.0129]Epoch 481: Train Loss = 0.014731086790561676\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=328, train_loss_step=0.012, train_loss_epoch=0.0147] Epoch 482: Train Loss = 0.011950574815273285\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=328, train_loss_step=0.0102, train_loss_epoch=0.012]Epoch 483: Train Loss = 0.010187949053943157\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=328, train_loss_step=0.0132, train_loss_epoch=0.0102]Epoch 484: Train Loss = 0.013213046826422215\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=328, train_loss_step=0.00962, train_loss_epoch=0.0132]Epoch 485: Train Loss = 0.009623224847018719\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=328, train_loss_step=0.0166, train_loss_epoch=0.00962] Epoch 486: Train Loss = 0.01661197654902935\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=328, train_loss_step=0.0133, train_loss_epoch=0.0166] Epoch 487: Train Loss = 0.013297013938426971\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=328, train_loss_step=0.0105, train_loss_epoch=0.0133]Epoch 488: Train Loss = 0.01053028553724289\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=328, train_loss_step=0.00953, train_loss_epoch=0.0105]Epoch 489: Train Loss = 0.00952898245304823\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=328, train_loss_step=0.0111, train_loss_epoch=0.00953] Epoch 490: Train Loss = 0.011073772795498371\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s, v_num=328, train_loss_step=0.0106, train_loss_epoch=0.0111] Epoch 491: Train Loss = 0.010604445822536945\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=328, train_loss_step=0.0112, train_loss_epoch=0.0106]Epoch 492: Train Loss = 0.011194676160812378\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=328, train_loss_step=0.00941, train_loss_epoch=0.0112]Epoch 493: Train Loss = 0.00941375084221363\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s, v_num=328, train_loss_step=0.00798, train_loss_epoch=0.00941]Epoch 494: Train Loss = 0.007978209294378757\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=328, train_loss_step=0.0123, train_loss_epoch=0.00798] Epoch 495: Train Loss = 0.012304499745368958\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=328, train_loss_step=0.011, train_loss_epoch=0.0123]  Epoch 496: Train Loss = 0.010998612269759178\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=328, train_loss_step=0.00984, train_loss_epoch=0.011]Epoch 497: Train Loss = 0.009838172234594822\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=328, train_loss_step=0.0143, train_loss_epoch=0.00984] Epoch 498: Train Loss = 0.014314559288322926\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0143] Epoch 499: Train Loss = 0.011493035592138767\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=328, train_loss_step=0.0115, train_loss_epoch=0.0115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.87it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 12: from 2010-06-30 00:00:00 to 2022-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=332, train_loss_step=0.029]Epoch 0: Train Loss = 0.029024286195635796\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=332, train_loss_step=0.0356, train_loss_epoch=0.029]Epoch 1: Train Loss = 0.03556472435593605\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=332, train_loss_step=0.0322, train_loss_epoch=0.0356]Epoch 2: Train Loss = 0.032178908586502075\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=332, train_loss_step=0.0242, train_loss_epoch=0.0322]Epoch 3: Train Loss = 0.0241635050624609\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=332, train_loss_step=0.0232, train_loss_epoch=0.0242]Epoch 4: Train Loss = 0.02320779301226139\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=332, train_loss_step=0.0168, train_loss_epoch=0.0232]Epoch 5: Train Loss = 0.016832390800118446\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=332, train_loss_step=0.0157, train_loss_epoch=0.0168]Epoch 6: Train Loss = 0.01573205180466175\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=332, train_loss_step=0.0151, train_loss_epoch=0.0157]Epoch 7: Train Loss = 0.015121153555810452\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=332, train_loss_step=0.0155, train_loss_epoch=0.0151]Epoch 8: Train Loss = 0.015468229539692402\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=332, train_loss_step=0.0203, train_loss_epoch=0.0155]Epoch 9: Train Loss = 0.020297523587942123\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=332, train_loss_step=0.014, train_loss_epoch=0.0203] Epoch 10: Train Loss = 0.014001361094415188\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=332, train_loss_step=0.0217, train_loss_epoch=0.014]Epoch 11: Train Loss = 0.02167615108191967\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0217]Epoch 12: Train Loss = 0.0117860808968544\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=332, train_loss_step=0.0168, train_loss_epoch=0.0118]Epoch 13: Train Loss = 0.016773896291851997\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=332, train_loss_step=0.0157, train_loss_epoch=0.0168]Epoch 14: Train Loss = 0.015675529837608337\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=332, train_loss_step=0.0158, train_loss_epoch=0.0157]Epoch 15: Train Loss = 0.01582789234817028\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=332, train_loss_step=0.014, train_loss_epoch=0.0158] Epoch 16: Train Loss = 0.014037853106856346\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=332, train_loss_step=0.0164, train_loss_epoch=0.014]Epoch 17: Train Loss = 0.01639108918607235\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s, v_num=332, train_loss_step=0.015, train_loss_epoch=0.0164] Epoch 18: Train Loss = 0.015035797841846943\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=332, train_loss_step=0.0123, train_loss_epoch=0.015]Epoch 19: Train Loss = 0.012305534444749355\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=332, train_loss_step=0.0129, train_loss_epoch=0.0123]Epoch 20: Train Loss = 0.012857313267886639\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=332, train_loss_step=0.00974, train_loss_epoch=0.0129]Epoch 21: Train Loss = 0.009737438522279263\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.00974] Epoch 22: Train Loss = 0.01125264447182417\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=332, train_loss_step=0.0105, train_loss_epoch=0.0113] Epoch 23: Train Loss = 0.010456263087689877\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=332, train_loss_step=0.0129, train_loss_epoch=0.0105]Epoch 24: Train Loss = 0.012885771691799164\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0129]Epoch 25: Train Loss = 0.014231863431632519\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=332, train_loss_step=0.0155, train_loss_epoch=0.0142]Epoch 26: Train Loss = 0.015506809577345848\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=332, train_loss_step=0.0114, train_loss_epoch=0.0155]Epoch 27: Train Loss = 0.011439715512096882\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=332, train_loss_step=0.0128, train_loss_epoch=0.0114]Epoch 28: Train Loss = 0.01281136367470026\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=332, train_loss_step=0.0116, train_loss_epoch=0.0128]Epoch 29: Train Loss = 0.01158724632114172\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=332, train_loss_step=0.0108, train_loss_epoch=0.0116]Epoch 30: Train Loss = 0.010822241194546223\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=332, train_loss_step=0.0145, train_loss_epoch=0.0108]Epoch 31: Train Loss = 0.014493430033326149\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=332, train_loss_step=0.0167, train_loss_epoch=0.0145]Epoch 32: Train Loss = 0.01671329326927662\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=332, train_loss_step=0.0169, train_loss_epoch=0.0167]Epoch 33: Train Loss = 0.016942258924245834\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=332, train_loss_step=0.0124, train_loss_epoch=0.0169]Epoch 34: Train Loss = 0.01242061797529459\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=332, train_loss_step=0.0175, train_loss_epoch=0.0124]Epoch 35: Train Loss = 0.017471475526690483\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=332, train_loss_step=0.0136, train_loss_epoch=0.0175]Epoch 36: Train Loss = 0.013614140450954437\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=332, train_loss_step=0.0133, train_loss_epoch=0.0136]Epoch 37: Train Loss = 0.01327220257371664\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=332, train_loss_step=0.014, train_loss_epoch=0.0133] Epoch 38: Train Loss = 0.014041446149349213\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=332, train_loss_step=0.0143, train_loss_epoch=0.014]Epoch 39: Train Loss = 0.014321306720376015\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=332, train_loss_step=0.011, train_loss_epoch=0.0143] Epoch 40: Train Loss = 0.010977625846862793\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=332, train_loss_step=0.0147, train_loss_epoch=0.011]Epoch 41: Train Loss = 0.014673985540866852\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=332, train_loss_step=0.0125, train_loss_epoch=0.0147]Epoch 42: Train Loss = 0.012519030831754208\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0125]Epoch 43: Train Loss = 0.012580770067870617\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.0126]Epoch 44: Train Loss = 0.011309413239359856\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=332, train_loss_step=0.0148, train_loss_epoch=0.0113]Epoch 45: Train Loss = 0.014820271171629429\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=332, train_loss_step=0.0115, train_loss_epoch=0.0148]Epoch 46: Train Loss = 0.011531420983374119\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=332, train_loss_step=0.0171, train_loss_epoch=0.0115]Epoch 47: Train Loss = 0.017074955627322197\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=332, train_loss_step=0.0123, train_loss_epoch=0.0171]Epoch 48: Train Loss = 0.01234020758420229\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=332, train_loss_step=0.0168, train_loss_epoch=0.0123]Epoch 49: Train Loss = 0.01679818704724312\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=332, train_loss_step=0.0129, train_loss_epoch=0.0168]Epoch 50: Train Loss = 0.012924100272357464\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=332, train_loss_step=0.011, train_loss_epoch=0.0129] Epoch 51: Train Loss = 0.011021533980965614\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=332, train_loss_step=0.0135, train_loss_epoch=0.011]Epoch 52: Train Loss = 0.01350208930671215\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=332, train_loss_step=0.013, train_loss_epoch=0.0135] Epoch 53: Train Loss = 0.01303574163466692\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.013]Epoch 54: Train Loss = 0.011269466020166874\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=332, train_loss_step=0.013, train_loss_epoch=0.0113] Epoch 55: Train Loss = 0.01302932109683752\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=332, train_loss_step=0.0134, train_loss_epoch=0.013]Epoch 56: Train Loss = 0.013394023291766644\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=332, train_loss_step=0.0143, train_loss_epoch=0.0134]Epoch 57: Train Loss = 0.014253008179366589\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=332, train_loss_step=0.0186, train_loss_epoch=0.0143]Epoch 58: Train Loss = 0.018582258373498917\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=332, train_loss_step=0.0156, train_loss_epoch=0.0186]Epoch 59: Train Loss = 0.015616034157574177\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=332, train_loss_step=0.0174, train_loss_epoch=0.0156]Epoch 60: Train Loss = 0.0173663217574358\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=332, train_loss_step=0.00989, train_loss_epoch=0.0174]Epoch 61: Train Loss = 0.009892538189888\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=332, train_loss_step=0.0164, train_loss_epoch=0.00989] Epoch 62: Train Loss = 0.016423923894762993\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=332, train_loss_step=0.0141, train_loss_epoch=0.0164] Epoch 63: Train Loss = 0.01412705983966589\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=332, train_loss_step=0.0119, train_loss_epoch=0.0141]Epoch 64: Train Loss = 0.011871956288814545\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=332, train_loss_step=0.0133, train_loss_epoch=0.0119]Epoch 65: Train Loss = 0.013327984139323235\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=332, train_loss_step=0.0145, train_loss_epoch=0.0133]Epoch 66: Train Loss = 0.01454720925539732\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=332, train_loss_step=0.0106, train_loss_epoch=0.0145]Epoch 67: Train Loss = 0.010570329613983631\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=332, train_loss_step=0.0174, train_loss_epoch=0.0106]Epoch 68: Train Loss = 0.01736626774072647\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=332, train_loss_step=0.0132, train_loss_epoch=0.0174]Epoch 69: Train Loss = 0.013236043974757195\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=332, train_loss_step=0.0136, train_loss_epoch=0.0132]Epoch 70: Train Loss = 0.013579025864601135\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 11.08it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.0136]Epoch 71: Train Loss = 0.011313075199723244\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=332, train_loss_step=0.00963, train_loss_epoch=0.0113]Epoch 72: Train Loss = 0.009626917541027069\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.00963] Epoch 73: Train Loss = 0.012115170247852802\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.0121] Epoch 74: Train Loss = 0.012078451924026012\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0121]Epoch 75: Train Loss = 0.01263983454555273\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=332, train_loss_step=0.0134, train_loss_epoch=0.0126]Epoch 76: Train Loss = 0.013444091193377972\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=332, train_loss_step=0.0152, train_loss_epoch=0.0134]Epoch 77: Train Loss = 0.015199998393654823\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=332, train_loss_step=0.0152, train_loss_epoch=0.0152]Epoch 78: Train Loss = 0.015241309069097042\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=332, train_loss_step=0.0109, train_loss_epoch=0.0152]Epoch 79: Train Loss = 0.010858853347599506\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=332, train_loss_step=0.00986, train_loss_epoch=0.0109]Epoch 80: Train Loss = 0.009855945594608784\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=332, train_loss_step=0.0108, train_loss_epoch=0.00986] Epoch 81: Train Loss = 0.010785664431750774\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=332, train_loss_step=0.0174, train_loss_epoch=0.0108] Epoch 82: Train Loss = 0.01744425855576992\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=332, train_loss_step=0.0109, train_loss_epoch=0.0174]Epoch 83: Train Loss = 0.010876248590648174\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=332, train_loss_step=0.0116, train_loss_epoch=0.0109]Epoch 84: Train Loss = 0.01163207832723856\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=332, train_loss_step=0.0107, train_loss_epoch=0.0116]Epoch 85: Train Loss = 0.01066495943814516\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=332, train_loss_step=0.0111, train_loss_epoch=0.0107]Epoch 86: Train Loss = 0.01108340360224247\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=332, train_loss_step=0.0139, train_loss_epoch=0.0111]Epoch 87: Train Loss = 0.01386997103691101\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.0139] Epoch 88: Train Loss = 0.012002391740679741\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=332, train_loss_step=0.0112, train_loss_epoch=0.012]Epoch 89: Train Loss = 0.011249986477196217\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0112]Epoch 90: Train Loss = 0.011663885787129402\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0117]Epoch 91: Train Loss = 0.011828833259642124\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=332, train_loss_step=0.0124, train_loss_epoch=0.0118]Epoch 92: Train Loss = 0.012412408366799355\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=332, train_loss_step=0.014, train_loss_epoch=0.0124] Epoch 93: Train Loss = 0.013999191112816334\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=332, train_loss_step=0.0159, train_loss_epoch=0.014]Epoch 94: Train Loss = 0.0158957801759243\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=332, train_loss_step=0.0107, train_loss_epoch=0.0159]Epoch 95: Train Loss = 0.010733755305409431\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=332, train_loss_step=0.0156, train_loss_epoch=0.0107]Epoch 96: Train Loss = 0.015552165918052197\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=332, train_loss_step=0.0186, train_loss_epoch=0.0156]Epoch 97: Train Loss = 0.018556741997599602\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=332, train_loss_step=0.0154, train_loss_epoch=0.0186]Epoch 98: Train Loss = 0.015384907834231853\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=332, train_loss_step=0.0154, train_loss_epoch=0.0154]Epoch 99: Train Loss = 0.015428366139531136\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=332, train_loss_step=0.0115, train_loss_epoch=0.0154]Epoch 100: Train Loss = 0.011523779481649399\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=332, train_loss_step=0.015, train_loss_epoch=0.0115] Epoch 101: Train Loss = 0.015037545002996922\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=332, train_loss_step=0.0171, train_loss_epoch=0.015]Epoch 102: Train Loss = 0.017077777534723282\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s, v_num=332, train_loss_step=0.0186, train_loss_epoch=0.0171]Epoch 103: Train Loss = 0.018643716350197792\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0186]Epoch 104: Train Loss = 0.011777945794165134\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s, v_num=332, train_loss_step=0.0132, train_loss_epoch=0.0118]Epoch 105: Train Loss = 0.01322113536298275\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=332, train_loss_step=0.0152, train_loss_epoch=0.0132]Epoch 106: Train Loss = 0.015245063230395317\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=332, train_loss_step=0.0181, train_loss_epoch=0.0152]Epoch 107: Train Loss = 0.018120260909199715\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=332, train_loss_step=0.0137, train_loss_epoch=0.0181]Epoch 108: Train Loss = 0.01373784989118576\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0137]Epoch 109: Train Loss = 0.011727492325007915\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=332, train_loss_step=0.0124, train_loss_epoch=0.0117]Epoch 110: Train Loss = 0.012404642067849636\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=332, train_loss_step=0.0101, train_loss_epoch=0.0124]Epoch 111: Train Loss = 0.010068711824715137\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=332, train_loss_step=0.0145, train_loss_epoch=0.0101]Epoch 112: Train Loss = 0.01447531022131443\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=332, train_loss_step=0.0149, train_loss_epoch=0.0145]Epoch 113: Train Loss = 0.01489582471549511\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=332, train_loss_step=0.0149, train_loss_epoch=0.0149]Epoch 114: Train Loss = 0.014929242432117462\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=332, train_loss_step=0.0112, train_loss_epoch=0.0149]Epoch 115: Train Loss = 0.011246093548834324\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=332, train_loss_step=0.0102, train_loss_epoch=0.0112]Epoch 116: Train Loss = 0.01019984669983387\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=332, train_loss_step=0.018, train_loss_epoch=0.0102] Epoch 117: Train Loss = 0.017961690202355385\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=332, train_loss_step=0.0114, train_loss_epoch=0.018]Epoch 118: Train Loss = 0.011405160650610924\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.0114]Epoch 119: Train Loss = 0.012087304145097733\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=332, train_loss_step=0.0133, train_loss_epoch=0.0121]Epoch 120: Train Loss = 0.013300924561917782\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=332, train_loss_step=0.0139, train_loss_epoch=0.0133]Epoch 121: Train Loss = 0.013870795257389545\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=332, train_loss_step=0.0143, train_loss_epoch=0.0139]Epoch 122: Train Loss = 0.014344203285872936\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.0143]Epoch 123: Train Loss = 0.012137825600802898\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=332, train_loss_step=0.0172, train_loss_epoch=0.0121]Epoch 124: Train Loss = 0.01719132997095585\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=332, train_loss_step=0.0131, train_loss_epoch=0.0172]Epoch 125: Train Loss = 0.013093152083456516\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0131]Epoch 126: Train Loss = 0.011736975982785225\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=332, train_loss_step=0.0141, train_loss_epoch=0.0117]Epoch 127: Train Loss = 0.01413796842098236\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=332, train_loss_step=0.0123, train_loss_epoch=0.0141]Epoch 128: Train Loss = 0.012275797314941883\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=332, train_loss_step=0.0153, train_loss_epoch=0.0123]Epoch 129: Train Loss = 0.015300159342586994\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=332, train_loss_step=0.0101, train_loss_epoch=0.0153]Epoch 130: Train Loss = 0.010111440904438496\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=332, train_loss_step=0.0101, train_loss_epoch=0.0101]Epoch 131: Train Loss = 0.01010848581790924\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=332, train_loss_step=0.011, train_loss_epoch=0.0101] Epoch 132: Train Loss = 0.011030416004359722\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.011] Epoch 133: Train Loss = 0.011987465433776379\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.012]Epoch 134: Train Loss = 0.011999376118183136\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.012]Epoch 135: Train Loss = 0.011800287291407585\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=332, train_loss_step=0.0133, train_loss_epoch=0.0118]Epoch 136: Train Loss = 0.01330941915512085\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=332, train_loss_step=0.0125, train_loss_epoch=0.0133]Epoch 137: Train Loss = 0.012519012205302715\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.0125]Epoch 138: Train Loss = 0.012101791799068451\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=332, train_loss_step=0.0107, train_loss_epoch=0.0121]Epoch 139: Train Loss = 0.010667628608644009\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=332, train_loss_step=0.0137, train_loss_epoch=0.0107]Epoch 140: Train Loss = 0.013743780553340912\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=332, train_loss_step=0.0154, train_loss_epoch=0.0137]Epoch 141: Train Loss = 0.015440846793353558\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=332, train_loss_step=0.0167, train_loss_epoch=0.0154]Epoch 142: Train Loss = 0.01674840599298477\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=332, train_loss_step=0.0174, train_loss_epoch=0.0167]Epoch 143: Train Loss = 0.017370566725730896\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.0174]Epoch 144: Train Loss = 0.011339874006807804\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=332, train_loss_step=0.0169, train_loss_epoch=0.0113]Epoch 145: Train Loss = 0.016876336187124252\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.0169]Epoch 146: Train Loss = 0.012095960788428783\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=332, train_loss_step=0.0174, train_loss_epoch=0.0121]Epoch 147: Train Loss = 0.0173747967928648\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=332, train_loss_step=0.0134, train_loss_epoch=0.0174]Epoch 148: Train Loss = 0.013403693214058876\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=332, train_loss_step=0.0115, train_loss_epoch=0.0134]Epoch 149: Train Loss = 0.011470000259578228\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=332, train_loss_step=0.014, train_loss_epoch=0.0115] Epoch 150: Train Loss = 0.013961399905383587\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=332, train_loss_step=0.0122, train_loss_epoch=0.014]Epoch 151: Train Loss = 0.012170412577688694\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=332, train_loss_step=0.0116, train_loss_epoch=0.0122]Epoch 152: Train Loss = 0.011586462147533894\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=332, train_loss_step=0.0107, train_loss_epoch=0.0116]Epoch 153: Train Loss = 0.010743322782218456\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.0107] Epoch 154: Train Loss = 0.011974546127021313\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=332, train_loss_step=0.0163, train_loss_epoch=0.012]Epoch 155: Train Loss = 0.01631956174969673\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=332, train_loss_step=0.0182, train_loss_epoch=0.0163]Epoch 156: Train Loss = 0.018187040463089943\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 10.51it/s, v_num=332, train_loss_step=0.0155, train_loss_epoch=0.0182]Epoch 157: Train Loss = 0.015474800951778889\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=332, train_loss_step=0.0144, train_loss_epoch=0.0155]Epoch 158: Train Loss = 0.01440748292952776\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=332, train_loss_step=0.0186, train_loss_epoch=0.0144]Epoch 159: Train Loss = 0.0185729768127203\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=332, train_loss_step=0.0197, train_loss_epoch=0.0186]Epoch 160: Train Loss = 0.019663915038108826\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=332, train_loss_step=0.0149, train_loss_epoch=0.0197]Epoch 161: Train Loss = 0.0148840406909585\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=332, train_loss_step=0.0132, train_loss_epoch=0.0149]Epoch 162: Train Loss = 0.013188029639422894\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=332, train_loss_step=0.0116, train_loss_epoch=0.0132]Epoch 163: Train Loss = 0.011633764021098614\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=332, train_loss_step=0.0127, train_loss_epoch=0.0116]Epoch 164: Train Loss = 0.012712429277598858\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=332, train_loss_step=0.016, train_loss_epoch=0.0127] Epoch 165: Train Loss = 0.015979429706931114\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=332, train_loss_step=0.0135, train_loss_epoch=0.016]Epoch 166: Train Loss = 0.013532787561416626\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=332, train_loss_step=0.0138, train_loss_epoch=0.0135]Epoch 167: Train Loss = 0.01380448043346405\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=332, train_loss_step=0.0157, train_loss_epoch=0.0138]Epoch 168: Train Loss = 0.015689661726355553\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=332, train_loss_step=0.0161, train_loss_epoch=0.0157]Epoch 169: Train Loss = 0.016050131991505623\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=332, train_loss_step=0.0105, train_loss_epoch=0.0161]Epoch 170: Train Loss = 0.010513270273804665\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=332, train_loss_step=0.0144, train_loss_epoch=0.0105]Epoch 171: Train Loss = 0.01441685389727354\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=332, train_loss_step=0.0155, train_loss_epoch=0.0144]Epoch 172: Train Loss = 0.015489334240555763\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=332, train_loss_step=0.0131, train_loss_epoch=0.0155]Epoch 173: Train Loss = 0.013099116273224354\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=332, train_loss_step=0.0134, train_loss_epoch=0.0131]Epoch 174: Train Loss = 0.01338522881269455\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0134]Epoch 175: Train Loss = 0.014171524904668331\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0142]Epoch 176: Train Loss = 0.012557998299598694\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=332, train_loss_step=0.0132, train_loss_epoch=0.0126]Epoch 177: Train Loss = 0.013187113218009472\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=332, train_loss_step=0.0136, train_loss_epoch=0.0132]Epoch 178: Train Loss = 0.013551146723330021\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s, v_num=332, train_loss_step=0.0149, train_loss_epoch=0.0136]Epoch 179: Train Loss = 0.01486381608992815\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 13.29it/s, v_num=332, train_loss_step=0.0127, train_loss_epoch=0.0149]Epoch 180: Train Loss = 0.012658602558076382\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0127]Epoch 181: Train Loss = 0.011838641948997974\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=332, train_loss_step=0.0114, train_loss_epoch=0.0118]Epoch 182: Train Loss = 0.011375491507351398\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=332, train_loss_step=0.0146, train_loss_epoch=0.0114]Epoch 183: Train Loss = 0.014555036090314388\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=332, train_loss_step=0.0132, train_loss_epoch=0.0146]Epoch 184: Train Loss = 0.013190382160246372\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=332, train_loss_step=0.0154, train_loss_epoch=0.0132]Epoch 185: Train Loss = 0.015373415313661098\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 11.42it/s, v_num=332, train_loss_step=0.0175, train_loss_epoch=0.0154]Epoch 186: Train Loss = 0.017461629584431648\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.0175]Epoch 187: Train Loss = 0.01206301897764206\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=332, train_loss_step=0.0124, train_loss_epoch=0.0121]Epoch 188: Train Loss = 0.012423261068761349\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=332, train_loss_step=0.0156, train_loss_epoch=0.0124]Epoch 189: Train Loss = 0.015575981698930264\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0156]Epoch 190: Train Loss = 0.014191610738635063\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=332, train_loss_step=0.013, train_loss_epoch=0.0142] Epoch 191: Train Loss = 0.012994240038096905\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=332, train_loss_step=0.0144, train_loss_epoch=0.013]Epoch 192: Train Loss = 0.014401300810277462\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=332, train_loss_step=0.0122, train_loss_epoch=0.0144]Epoch 193: Train Loss = 0.012249092571437359\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=332, train_loss_step=0.0166, train_loss_epoch=0.0122]Epoch 194: Train Loss = 0.016566256061196327\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=332, train_loss_step=0.0136, train_loss_epoch=0.0166]Epoch 195: Train Loss = 0.013555091805756092\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=332, train_loss_step=0.0131, train_loss_epoch=0.0136]Epoch 196: Train Loss = 0.013145506381988525\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=332, train_loss_step=0.0133, train_loss_epoch=0.0131]Epoch 197: Train Loss = 0.013297917321324348\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=332, train_loss_step=0.0109, train_loss_epoch=0.0133]Epoch 198: Train Loss = 0.010854950174689293\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=332, train_loss_step=0.0122, train_loss_epoch=0.0109]Epoch 199: Train Loss = 0.012183031067252159\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.0122]Epoch 200: Train Loss = 0.011341732926666737\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=332, train_loss_step=0.018, train_loss_epoch=0.0113] Epoch 201: Train Loss = 0.01802661456167698\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=332, train_loss_step=0.0153, train_loss_epoch=0.018]Epoch 202: Train Loss = 0.015320356003940105\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=332, train_loss_step=0.0156, train_loss_epoch=0.0153]Epoch 203: Train Loss = 0.015553925186395645\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=332, train_loss_step=0.0156, train_loss_epoch=0.0156]Epoch 204: Train Loss = 0.015563486143946648\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=332, train_loss_step=0.014, train_loss_epoch=0.0156] Epoch 205: Train Loss = 0.014015167951583862\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=332, train_loss_step=0.0104, train_loss_epoch=0.014]Epoch 206: Train Loss = 0.010436750017106533\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=332, train_loss_step=0.0136, train_loss_epoch=0.0104]Epoch 207: Train Loss = 0.01358289085328579\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0136]Epoch 208: Train Loss = 0.01178999338299036\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=332, train_loss_step=0.0156, train_loss_epoch=0.0118]Epoch 209: Train Loss = 0.015609701164066792\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=332, train_loss_step=0.0111, train_loss_epoch=0.0156]Epoch 210: Train Loss = 0.011059476062655449\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=332, train_loss_step=0.0162, train_loss_epoch=0.0111]Epoch 211: Train Loss = 0.016189325600862503\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=332, train_loss_step=0.0085, train_loss_epoch=0.0162]Epoch 212: Train Loss = 0.008496296592056751\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=332, train_loss_step=0.0108, train_loss_epoch=0.0085]Epoch 213: Train Loss = 0.010756568983197212\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=332, train_loss_step=0.0119, train_loss_epoch=0.0108]Epoch 214: Train Loss = 0.011938878335058689\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=332, train_loss_step=0.0129, train_loss_epoch=0.0119]Epoch 215: Train Loss = 0.012852097861468792\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=332, train_loss_step=0.0153, train_loss_epoch=0.0129]Epoch 216: Train Loss = 0.015254585072398186\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=332, train_loss_step=0.0141, train_loss_epoch=0.0153]Epoch 217: Train Loss = 0.014057708904147148\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=332, train_loss_step=0.0127, train_loss_epoch=0.0141]Epoch 218: Train Loss = 0.012683943845331669\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=332, train_loss_step=0.0116, train_loss_epoch=0.0127]Epoch 219: Train Loss = 0.01161277573555708\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0116]Epoch 220: Train Loss = 0.011663076467812061\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=332, train_loss_step=0.0106, train_loss_epoch=0.0117]Epoch 221: Train Loss = 0.010611350648105145\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=332, train_loss_step=0.0139, train_loss_epoch=0.0106]Epoch 222: Train Loss = 0.013898791745305061\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=332, train_loss_step=0.010, train_loss_epoch=0.0139] Epoch 223: Train Loss = 0.010017161257565022\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.010] Epoch 224: Train Loss = 0.011973830871284008\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=332, train_loss_step=0.0105, train_loss_epoch=0.012]Epoch 225: Train Loss = 0.010499593801796436\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=332, train_loss_step=0.0141, train_loss_epoch=0.0105]Epoch 226: Train Loss = 0.01410810835659504\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=332, train_loss_step=0.0115, train_loss_epoch=0.0141]Epoch 227: Train Loss = 0.011475050821900368\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=332, train_loss_step=0.0138, train_loss_epoch=0.0115]Epoch 228: Train Loss = 0.013797889463603497\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=332, train_loss_step=0.0155, train_loss_epoch=0.0138]Epoch 229: Train Loss = 0.015548834577202797\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=332, train_loss_step=0.0135, train_loss_epoch=0.0155]Epoch 230: Train Loss = 0.013506046496331692\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=332, train_loss_step=0.0147, train_loss_epoch=0.0135]Epoch 231: Train Loss = 0.014701703563332558\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=332, train_loss_step=0.0125, train_loss_epoch=0.0147]Epoch 232: Train Loss = 0.012490218505263329\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=332, train_loss_step=0.0138, train_loss_epoch=0.0125]Epoch 233: Train Loss = 0.013767127878963947\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=332, train_loss_step=0.0111, train_loss_epoch=0.0138]Epoch 234: Train Loss = 0.011079954914748669\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=332, train_loss_step=0.0236, train_loss_epoch=0.0111]Epoch 235: Train Loss = 0.023628221824765205\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=332, train_loss_step=0.0103, train_loss_epoch=0.0236]Epoch 236: Train Loss = 0.010320601053535938\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=332, train_loss_step=0.013, train_loss_epoch=0.0103] Epoch 237: Train Loss = 0.012988503091037273\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=332, train_loss_step=0.0175, train_loss_epoch=0.013]Epoch 238: Train Loss = 0.01746448688209057\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=332, train_loss_step=0.0128, train_loss_epoch=0.0175]Epoch 239: Train Loss = 0.012807120569050312\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=332, train_loss_step=0.015, train_loss_epoch=0.0128] Epoch 240: Train Loss = 0.01499717403203249\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=332, train_loss_step=0.0156, train_loss_epoch=0.015]Epoch 241: Train Loss = 0.015645284205675125\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=332, train_loss_step=0.0158, train_loss_epoch=0.0156]Epoch 242: Train Loss = 0.015804680064320564\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=332, train_loss_step=0.0119, train_loss_epoch=0.0158]Epoch 243: Train Loss = 0.011882948689162731\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=332, train_loss_step=0.0127, train_loss_epoch=0.0119]Epoch 244: Train Loss = 0.012676221318542957\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0127]Epoch 245: Train Loss = 0.011838257312774658\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=332, train_loss_step=0.0124, train_loss_epoch=0.0118]Epoch 246: Train Loss = 0.012419076636433601\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=332, train_loss_step=0.0139, train_loss_epoch=0.0124]Epoch 247: Train Loss = 0.013874778524041176\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=332, train_loss_step=0.0159, train_loss_epoch=0.0139]Epoch 248: Train Loss = 0.015866370871663094\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=332, train_loss_step=0.0146, train_loss_epoch=0.0159]Epoch 249: Train Loss = 0.014649155549705029\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=332, train_loss_step=0.0164, train_loss_epoch=0.0146]Epoch 250: Train Loss = 0.01642279513180256\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=332, train_loss_step=0.0125, train_loss_epoch=0.0164]Epoch 251: Train Loss = 0.012506111524999142\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=332, train_loss_step=0.0124, train_loss_epoch=0.0125]Epoch 252: Train Loss = 0.012419519945979118\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=332, train_loss_step=0.0107, train_loss_epoch=0.0124]Epoch 253: Train Loss = 0.010743479244410992\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=332, train_loss_step=0.0125, train_loss_epoch=0.0107]Epoch 254: Train Loss = 0.012540541589260101\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=332, train_loss_step=0.014, train_loss_epoch=0.0125] Epoch 255: Train Loss = 0.013986223377287388\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=332, train_loss_step=0.0186, train_loss_epoch=0.014]Epoch 256: Train Loss = 0.018623318523168564\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0186]Epoch 257: Train Loss = 0.014189879409968853\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=332, train_loss_step=0.0114, train_loss_epoch=0.0142]Epoch 258: Train Loss = 0.011373930610716343\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=332, train_loss_step=0.0231, train_loss_epoch=0.0114]Epoch 259: Train Loss = 0.023146307095885277\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0231]Epoch 260: Train Loss = 0.011688762344419956\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=332, train_loss_step=0.0136, train_loss_epoch=0.0117]Epoch 261: Train Loss = 0.013588177971541882\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=332, train_loss_step=0.0129, train_loss_epoch=0.0136]Epoch 262: Train Loss = 0.012876411899924278\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0129]Epoch 263: Train Loss = 0.012647668831050396\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=332, train_loss_step=0.0122, train_loss_epoch=0.0126]Epoch 264: Train Loss = 0.012150612659752369\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=332, train_loss_step=0.0103, train_loss_epoch=0.0122]Epoch 265: Train Loss = 0.010255128145217896\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=332, train_loss_step=0.0106, train_loss_epoch=0.0103]Epoch 266: Train Loss = 0.01055491529405117\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.0106]Epoch 267: Train Loss = 0.011270811781287193\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=332, train_loss_step=0.0109, train_loss_epoch=0.0113]Epoch 268: Train Loss = 0.010874598287045956\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=332, train_loss_step=0.0143, train_loss_epoch=0.0109]Epoch 269: Train Loss = 0.014327673241496086\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=332, train_loss_step=0.0111, train_loss_epoch=0.0143]Epoch 270: Train Loss = 0.011051683686673641\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=332, train_loss_step=0.0129, train_loss_epoch=0.0111]Epoch 271: Train Loss = 0.012902268208563328\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.0129] Epoch 272: Train Loss = 0.012040759436786175\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=332, train_loss_step=0.0124, train_loss_epoch=0.012]Epoch 273: Train Loss = 0.012406165711581707\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0124]Epoch 274: Train Loss = 0.011720401234924793\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s, v_num=332, train_loss_step=0.0206, train_loss_epoch=0.0117]Epoch 275: Train Loss = 0.020621461793780327\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=332, train_loss_step=0.017, train_loss_epoch=0.0206] Epoch 276: Train Loss = 0.017036529257893562\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=332, train_loss_step=0.0186, train_loss_epoch=0.017]Epoch 277: Train Loss = 0.0186478178948164\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0186]Epoch 278: Train Loss = 0.012617925181984901\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=332, train_loss_step=0.0141, train_loss_epoch=0.0126]Epoch 279: Train Loss = 0.014103548601269722\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=332, train_loss_step=0.0116, train_loss_epoch=0.0141]Epoch 280: Train Loss = 0.01156552042812109\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=332, train_loss_step=0.0136, train_loss_epoch=0.0116]Epoch 281: Train Loss = 0.013589881360530853\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=332, train_loss_step=0.0103, train_loss_epoch=0.0136]Epoch 282: Train Loss = 0.01034679263830185\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=332, train_loss_step=0.0143, train_loss_epoch=0.0103]Epoch 283: Train Loss = 0.01429180521517992\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=332, train_loss_step=0.0114, train_loss_epoch=0.0143]Epoch 284: Train Loss = 0.011379341594874859\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=332, train_loss_step=0.0112, train_loss_epoch=0.0114]Epoch 285: Train Loss = 0.011227203533053398\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=332, train_loss_step=0.0143, train_loss_epoch=0.0112]Epoch 286: Train Loss = 0.014338625594973564\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s, v_num=332, train_loss_step=0.0104, train_loss_epoch=0.0143]Epoch 287: Train Loss = 0.01044059544801712\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0104]Epoch 288: Train Loss = 0.01420263946056366\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=332, train_loss_step=0.0124, train_loss_epoch=0.0142]Epoch 289: Train Loss = 0.012434924952685833\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=332, train_loss_step=0.0128, train_loss_epoch=0.0124]Epoch 290: Train Loss = 0.012752723880112171\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=332, train_loss_step=0.00797, train_loss_epoch=0.0128]Epoch 291: Train Loss = 0.007966751232743263\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=332, train_loss_step=0.00982, train_loss_epoch=0.00797]Epoch 292: Train Loss = 0.009816939942538738\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=332, train_loss_step=0.00978, train_loss_epoch=0.00982]Epoch 293: Train Loss = 0.009782725013792515\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=332, train_loss_step=0.0129, train_loss_epoch=0.00978] Epoch 294: Train Loss = 0.012906416319310665\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0129] Epoch 295: Train Loss = 0.011799586936831474\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=332, train_loss_step=0.0109, train_loss_epoch=0.0118]Epoch 296: Train Loss = 0.010925005190074444\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=332, train_loss_step=0.0133, train_loss_epoch=0.0109]Epoch 297: Train Loss = 0.013274343684315681\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=332, train_loss_step=0.0163, train_loss_epoch=0.0133]Epoch 298: Train Loss = 0.016315849497914314\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=332, train_loss_step=0.0123, train_loss_epoch=0.0163]Epoch 299: Train Loss = 0.012317228130996227\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=332, train_loss_step=0.0135, train_loss_epoch=0.0123]Epoch 300: Train Loss = 0.013516283594071865\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=332, train_loss_step=0.0128, train_loss_epoch=0.0135]Epoch 301: Train Loss = 0.012834000401198864\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=332, train_loss_step=0.0123, train_loss_epoch=0.0128]Epoch 302: Train Loss = 0.012303984723985195\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0123]Epoch 303: Train Loss = 0.014172407798469067\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s, v_num=332, train_loss_step=0.0168, train_loss_epoch=0.0142]Epoch 304: Train Loss = 0.01675560511648655\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.0168]Epoch 305: Train Loss = 0.01207785401493311\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.0121]Epoch 306: Train Loss = 0.01125449500977993\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=332, train_loss_step=0.0148, train_loss_epoch=0.0113]Epoch 307: Train Loss = 0.014765167608857155\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=332, train_loss_step=0.0147, train_loss_epoch=0.0148]Epoch 308: Train Loss = 0.014700149185955524\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=332, train_loss_step=0.016, train_loss_epoch=0.0147] Epoch 309: Train Loss = 0.016035838052630424\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=332, train_loss_step=0.0145, train_loss_epoch=0.016]Epoch 310: Train Loss = 0.01445760577917099\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=332, train_loss_step=0.0165, train_loss_epoch=0.0145]Epoch 311: Train Loss = 0.01648484542965889\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=332, train_loss_step=0.015, train_loss_epoch=0.0165] Epoch 312: Train Loss = 0.014990787021815777\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=332, train_loss_step=0.0108, train_loss_epoch=0.015]Epoch 313: Train Loss = 0.01084167417138815\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=332, train_loss_step=0.0149, train_loss_epoch=0.0108]Epoch 314: Train Loss = 0.014915184117853642\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=332, train_loss_step=0.0127, train_loss_epoch=0.0149]Epoch 315: Train Loss = 0.012681915424764156\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=332, train_loss_step=0.0155, train_loss_epoch=0.0127]Epoch 316: Train Loss = 0.015501162968575954\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=332, train_loss_step=0.014, train_loss_epoch=0.0155] Epoch 317: Train Loss = 0.013977204449474812\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.014]Epoch 318: Train Loss = 0.01175581943243742\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=332, train_loss_step=0.0132, train_loss_epoch=0.0118]Epoch 319: Train Loss = 0.013240443542599678\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=332, train_loss_step=0.0131, train_loss_epoch=0.0132]Epoch 320: Train Loss = 0.013128191232681274\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0131]Epoch 321: Train Loss = 0.011728507466614246\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=332, train_loss_step=0.00854, train_loss_epoch=0.0117]Epoch 322: Train Loss = 0.00854167528450489\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=332, train_loss_step=0.0109, train_loss_epoch=0.00854] Epoch 323: Train Loss = 0.010935959406197071\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.0109] Epoch 324: Train Loss = 0.012100562453269958\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=332, train_loss_step=0.0132, train_loss_epoch=0.0121]Epoch 325: Train Loss = 0.013216430321335793\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=332, train_loss_step=0.0182, train_loss_epoch=0.0132]Epoch 326: Train Loss = 0.018193677067756653\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=332, train_loss_step=0.0134, train_loss_epoch=0.0182]Epoch 327: Train Loss = 0.013412688858807087\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0134]Epoch 328: Train Loss = 0.011744318529963493\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=332, train_loss_step=0.0159, train_loss_epoch=0.0117]Epoch 329: Train Loss = 0.01589261181652546\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=332, train_loss_step=0.00939, train_loss_epoch=0.0159]Epoch 330: Train Loss = 0.00938998069614172\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=332, train_loss_step=0.0106, train_loss_epoch=0.00939] Epoch 331: Train Loss = 0.010625594295561314\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=332, train_loss_step=0.0106, train_loss_epoch=0.0106] Epoch 332: Train Loss = 0.010598373599350452\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.0106] Epoch 333: Train Loss = 0.012014351785182953\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=332, train_loss_step=0.0136, train_loss_epoch=0.012]Epoch 334: Train Loss = 0.013558096252381802\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0136]Epoch 335: Train Loss = 0.012608707882463932\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=332, train_loss_step=0.0155, train_loss_epoch=0.0126]Epoch 336: Train Loss = 0.015536787919700146\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=332, train_loss_step=0.0116, train_loss_epoch=0.0155]Epoch 337: Train Loss = 0.011620226316154003\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s, v_num=332, train_loss_step=0.0127, train_loss_epoch=0.0116]Epoch 338: Train Loss = 0.012650586664676666\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s, v_num=332, train_loss_step=0.0147, train_loss_epoch=0.0127]Epoch 339: Train Loss = 0.014670473523437977\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0147]Epoch 340: Train Loss = 0.014226422645151615\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=332, train_loss_step=0.0114, train_loss_epoch=0.0142]Epoch 341: Train Loss = 0.011443709023296833\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=332, train_loss_step=0.0124, train_loss_epoch=0.0114]Epoch 342: Train Loss = 0.01239562127739191\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=332, train_loss_step=0.0106, train_loss_epoch=0.0124]Epoch 343: Train Loss = 0.010612175799906254\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=332, train_loss_step=0.0201, train_loss_epoch=0.0106]Epoch 344: Train Loss = 0.020085405558347702\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=332, train_loss_step=0.0131, train_loss_epoch=0.0201]Epoch 345: Train Loss = 0.013057315722107887\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=332, train_loss_step=0.010, train_loss_epoch=0.0131] Epoch 346: Train Loss = 0.010049399919807911\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=332, train_loss_step=0.0115, train_loss_epoch=0.010]Epoch 347: Train Loss = 0.01151130348443985\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s, v_num=332, train_loss_step=0.0157, train_loss_epoch=0.0115]Epoch 348: Train Loss = 0.015709448605775833\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=332, train_loss_step=0.0131, train_loss_epoch=0.0157]Epoch 349: Train Loss = 0.013139921240508556\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=332, train_loss_step=0.0112, train_loss_epoch=0.0131]Epoch 350: Train Loss = 0.01115038525313139\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=332, train_loss_step=0.00998, train_loss_epoch=0.0112]Epoch 351: Train Loss = 0.00998120941221714\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=332, train_loss_step=0.0112, train_loss_epoch=0.00998] Epoch 352: Train Loss = 0.011165248230099678\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=332, train_loss_step=0.0137, train_loss_epoch=0.0112] Epoch 353: Train Loss = 0.013746152631938457\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=332, train_loss_step=0.0137, train_loss_epoch=0.0137]Epoch 354: Train Loss = 0.013680106960237026\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=332, train_loss_step=0.00972, train_loss_epoch=0.0137]Epoch 355: Train Loss = 0.00972005259245634\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=332, train_loss_step=0.0151, train_loss_epoch=0.00972] Epoch 356: Train Loss = 0.015062175691127777\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0151] Epoch 357: Train Loss = 0.012613201513886452\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=332, train_loss_step=0.0106, train_loss_epoch=0.0126]Epoch 358: Train Loss = 0.01056280080229044\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=332, train_loss_step=0.0156, train_loss_epoch=0.0106]Epoch 359: Train Loss = 0.015633167698979378\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0156]Epoch 360: Train Loss = 0.011706637218594551\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0117]Epoch 361: Train Loss = 0.011831076815724373\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=332, train_loss_step=0.0132, train_loss_epoch=0.0118]Epoch 362: Train Loss = 0.013162444345653057\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=332, train_loss_step=0.0133, train_loss_epoch=0.0132]Epoch 363: Train Loss = 0.013269989751279354\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=332, train_loss_step=0.013, train_loss_epoch=0.0133] Epoch 364: Train Loss = 0.013019030913710594\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=332, train_loss_step=0.0101, train_loss_epoch=0.013]Epoch 365: Train Loss = 0.010078431107103825\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=332, train_loss_step=0.0147, train_loss_epoch=0.0101]Epoch 366: Train Loss = 0.014720113947987556\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=332, train_loss_step=0.0124, train_loss_epoch=0.0147]Epoch 367: Train Loss = 0.012385702691972256\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s, v_num=332, train_loss_step=0.0137, train_loss_epoch=0.0124]Epoch 368: Train Loss = 0.013697098009288311\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.0137]Epoch 369: Train Loss = 0.011316686868667603\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=332, train_loss_step=0.0162, train_loss_epoch=0.0113]Epoch 370: Train Loss = 0.016153091564774513\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=332, train_loss_step=0.011, train_loss_epoch=0.0162] Epoch 371: Train Loss = 0.010961002670228481\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=332, train_loss_step=0.0091, train_loss_epoch=0.011]Epoch 372: Train Loss = 0.009095067158341408\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=332, train_loss_step=0.0144, train_loss_epoch=0.0091]Epoch 373: Train Loss = 0.014362121000885963\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=332, train_loss_step=0.0149, train_loss_epoch=0.0144]Epoch 374: Train Loss = 0.01490902341902256\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s, v_num=332, train_loss_step=0.0164, train_loss_epoch=0.0149]Epoch 375: Train Loss = 0.016374124214053154\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=332, train_loss_step=0.0102, train_loss_epoch=0.0164]Epoch 376: Train Loss = 0.010240589268505573\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=332, train_loss_step=0.0137, train_loss_epoch=0.0102]Epoch 377: Train Loss = 0.013683116063475609\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=332, train_loss_step=0.0112, train_loss_epoch=0.0137]Epoch 378: Train Loss = 0.011174160987138748\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=332, train_loss_step=0.0156, train_loss_epoch=0.0112]Epoch 379: Train Loss = 0.015644503757357597\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=332, train_loss_step=0.0143, train_loss_epoch=0.0156]Epoch 380: Train Loss = 0.014332079328596592\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=332, train_loss_step=0.0128, train_loss_epoch=0.0143]Epoch 381: Train Loss = 0.012819775380194187\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=332, train_loss_step=0.00836, train_loss_epoch=0.0128]Epoch 382: Train Loss = 0.008361011743545532\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=332, train_loss_step=0.0162, train_loss_epoch=0.00836] Epoch 383: Train Loss = 0.01617221161723137\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=332, train_loss_step=0.0116, train_loss_epoch=0.0162] Epoch 384: Train Loss = 0.01163987535983324\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=332, train_loss_step=0.00924, train_loss_epoch=0.0116]Epoch 385: Train Loss = 0.009243624284863472\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=332, train_loss_step=0.0116, train_loss_epoch=0.00924] Epoch 386: Train Loss = 0.01162035297602415\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.0116] Epoch 387: Train Loss = 0.012134729884564877\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0121]Epoch 388: Train Loss = 0.011710280552506447\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.0117] Epoch 389: Train Loss = 0.01202467828989029\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=332, train_loss_step=0.0201, train_loss_epoch=0.012]Epoch 390: Train Loss = 0.020118702203035355\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0201]Epoch 391: Train Loss = 0.014237827621400356\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.0142] Epoch 392: Train Loss = 0.011956274509429932\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=332, train_loss_step=0.0149, train_loss_epoch=0.012]Epoch 393: Train Loss = 0.014871479943394661\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=332, train_loss_step=0.0111, train_loss_epoch=0.0149]Epoch 394: Train Loss = 0.011110617779195309\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=332, train_loss_step=0.0146, train_loss_epoch=0.0111]Epoch 395: Train Loss = 0.01459178514778614\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0146]Epoch 396: Train Loss = 0.011807831935584545\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.0118]Epoch 397: Train Loss = 0.012098640203475952\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=332, train_loss_step=0.0127, train_loss_epoch=0.0121]Epoch 398: Train Loss = 0.012708372436463833\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=332, train_loss_step=0.017, train_loss_epoch=0.0127] Epoch 399: Train Loss = 0.016955411061644554\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=332, train_loss_step=0.0146, train_loss_epoch=0.017]Epoch 400: Train Loss = 0.01462200190871954\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=332, train_loss_step=0.0138, train_loss_epoch=0.0146]Epoch 401: Train Loss = 0.013831647112965584\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s, v_num=332, train_loss_step=0.014, train_loss_epoch=0.0138] Epoch 402: Train Loss = 0.014030901715159416\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=332, train_loss_step=0.0159, train_loss_epoch=0.014]Epoch 403: Train Loss = 0.015940774232149124\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=332, train_loss_step=0.0146, train_loss_epoch=0.0159]Epoch 404: Train Loss = 0.014609845355153084\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=332, train_loss_step=0.0151, train_loss_epoch=0.0146]Epoch 405: Train Loss = 0.015134223736822605\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=332, train_loss_step=0.00986, train_loss_epoch=0.0151]Epoch 406: Train Loss = 0.009864581748843193\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=332, train_loss_step=0.0111, train_loss_epoch=0.00986] Epoch 407: Train Loss = 0.011087806895375252\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0111] Epoch 408: Train Loss = 0.014239232055842876\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0142]Epoch 409: Train Loss = 0.014204837381839752\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=332, train_loss_step=0.0143, train_loss_epoch=0.0142]Epoch 410: Train Loss = 0.014254064299166203\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=332, train_loss_step=0.0155, train_loss_epoch=0.0143]Epoch 411: Train Loss = 0.015515098348259926\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=332, train_loss_step=0.0153, train_loss_epoch=0.0155]Epoch 412: Train Loss = 0.015298193320631981\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=332, train_loss_step=0.0157, train_loss_epoch=0.0153]Epoch 413: Train Loss = 0.01570471003651619\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=332, train_loss_step=0.0125, train_loss_epoch=0.0157]Epoch 414: Train Loss = 0.012496834620833397\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=332, train_loss_step=0.0142, train_loss_epoch=0.0125]Epoch 415: Train Loss = 0.014232379384338856\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=332, train_loss_step=0.0139, train_loss_epoch=0.0142]Epoch 416: Train Loss = 0.013883967883884907\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=332, train_loss_step=0.0177, train_loss_epoch=0.0139]Epoch 417: Train Loss = 0.017724834382534027\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=332, train_loss_step=0.0155, train_loss_epoch=0.0177]Epoch 418: Train Loss = 0.015483483672142029\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=332, train_loss_step=0.0136, train_loss_epoch=0.0155]Epoch 419: Train Loss = 0.013648820109665394\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=332, train_loss_step=0.0131, train_loss_epoch=0.0136]Epoch 420: Train Loss = 0.013063631020486355\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=332, train_loss_step=0.0166, train_loss_epoch=0.0131]Epoch 421: Train Loss = 0.016618555411696434\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=332, train_loss_step=0.0135, train_loss_epoch=0.0166]Epoch 422: Train Loss = 0.013481169939041138\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=332, train_loss_step=0.013, train_loss_epoch=0.0135] Epoch 423: Train Loss = 0.012979780323803425\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.013]Epoch 424: Train Loss = 0.012641197070479393\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=332, train_loss_step=0.0104, train_loss_epoch=0.0126]Epoch 425: Train Loss = 0.010424060747027397\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=332, train_loss_step=0.0122, train_loss_epoch=0.0104]Epoch 426: Train Loss = 0.012180269695818424\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=332, train_loss_step=0.0138, train_loss_epoch=0.0122]Epoch 427: Train Loss = 0.013828457333147526\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=332, train_loss_step=0.0131, train_loss_epoch=0.0138]Epoch 428: Train Loss = 0.013079500757157803\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=332, train_loss_step=0.0151, train_loss_epoch=0.0131]Epoch 429: Train Loss = 0.015055892989039421\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=332, train_loss_step=0.0152, train_loss_epoch=0.0151]Epoch 430: Train Loss = 0.015208705328404903\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0152]Epoch 431: Train Loss = 0.012587795965373516\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=332, train_loss_step=0.0123, train_loss_epoch=0.0126]Epoch 432: Train Loss = 0.012289398349821568\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=332, train_loss_step=0.0102, train_loss_epoch=0.0123]Epoch 433: Train Loss = 0.010182836093008518\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=332, train_loss_step=0.00963, train_loss_epoch=0.0102]Epoch 434: Train Loss = 0.009633580222725868\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=332, train_loss_step=0.0146, train_loss_epoch=0.00963] Epoch 435: Train Loss = 0.014568337239325047\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=332, train_loss_step=0.0107, train_loss_epoch=0.0146] Epoch 436: Train Loss = 0.010678346268832684\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=332, train_loss_step=0.0132, train_loss_epoch=0.0107]Epoch 437: Train Loss = 0.013184425421059132\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=332, train_loss_step=0.00991, train_loss_epoch=0.0132]Epoch 438: Train Loss = 0.009905229322612286\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=332, train_loss_step=0.0102, train_loss_epoch=0.00991] Epoch 439: Train Loss = 0.010175872594118118\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=332, train_loss_step=0.014, train_loss_epoch=0.0102]  Epoch 440: Train Loss = 0.0140066584572196\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=332, train_loss_step=0.0111, train_loss_epoch=0.014]Epoch 441: Train Loss = 0.011050534434616566\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=332, train_loss_step=0.0176, train_loss_epoch=0.0111]Epoch 442: Train Loss = 0.017583947628736496\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=332, train_loss_step=0.0138, train_loss_epoch=0.0176]Epoch 443: Train Loss = 0.01381719671189785\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 10.98it/s, v_num=332, train_loss_step=0.0149, train_loss_epoch=0.0138]Epoch 444: Train Loss = 0.01485398132354021\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=332, train_loss_step=0.0167, train_loss_epoch=0.0149]Epoch 445: Train Loss = 0.016729796305298805\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=332, train_loss_step=0.0107, train_loss_epoch=0.0167]Epoch 446: Train Loss = 0.010687080211937428\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=332, train_loss_step=0.00999, train_loss_epoch=0.0107]Epoch 447: Train Loss = 0.009989743120968342\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=332, train_loss_step=0.0133, train_loss_epoch=0.00999] Epoch 448: Train Loss = 0.013335057534277439\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=332, train_loss_step=0.0109, train_loss_epoch=0.0133] Epoch 449: Train Loss = 0.010850140824913979\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.0109] Epoch 450: Train Loss = 0.012015694752335548\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=332, train_loss_step=0.0109, train_loss_epoch=0.012]Epoch 451: Train Loss = 0.010866662487387657\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=332, train_loss_step=0.0174, train_loss_epoch=0.0109]Epoch 452: Train Loss = 0.017384808510541916\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=332, train_loss_step=0.0106, train_loss_epoch=0.0174]Epoch 453: Train Loss = 0.010554125532507896\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0106]Epoch 454: Train Loss = 0.012593165040016174\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=332, train_loss_step=0.0133, train_loss_epoch=0.0126]Epoch 455: Train Loss = 0.013348870910704136\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=332, train_loss_step=0.0108, train_loss_epoch=0.0133]Epoch 456: Train Loss = 0.010783434845507145\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.0108]Epoch 457: Train Loss = 0.011334736831486225\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=332, train_loss_step=0.0146, train_loss_epoch=0.0113]Epoch 458: Train Loss = 0.01455023605376482\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0146]Epoch 459: Train Loss = 0.011807188391685486\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=332, train_loss_step=0.0139, train_loss_epoch=0.0118]Epoch 460: Train Loss = 0.013902624137699604\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=332, train_loss_step=0.0108, train_loss_epoch=0.0139]Epoch 461: Train Loss = 0.010803778655827045\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=332, train_loss_step=0.0112, train_loss_epoch=0.0108]Epoch 462: Train Loss = 0.01122081745415926\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=332, train_loss_step=0.0114, train_loss_epoch=0.0112]Epoch 463: Train Loss = 0.011444621719419956\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0114]Epoch 464: Train Loss = 0.012590271420776844\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.0126] Epoch 465: Train Loss = 0.012036657892167568\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=332, train_loss_step=0.011, train_loss_epoch=0.012] Epoch 466: Train Loss = 0.01100871991366148\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=332, train_loss_step=0.012, train_loss_epoch=0.011]Epoch 467: Train Loss = 0.012004048563539982\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=332, train_loss_step=0.00914, train_loss_epoch=0.012]Epoch 468: Train Loss = 0.009144221432507038\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s, v_num=332, train_loss_step=0.0189, train_loss_epoch=0.00914] Epoch 469: Train Loss = 0.01886592246592045\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=332, train_loss_step=0.0122, train_loss_epoch=0.0189] Epoch 470: Train Loss = 0.012200036086142063\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0122]Epoch 471: Train Loss = 0.011703334748744965\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=332, train_loss_step=0.0123, train_loss_epoch=0.0117]Epoch 472: Train Loss = 0.012303982861340046\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=332, train_loss_step=0.0094, train_loss_epoch=0.0123]Epoch 473: Train Loss = 0.009396865032613277\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=332, train_loss_step=0.0156, train_loss_epoch=0.0094]Epoch 474: Train Loss = 0.015616035088896751\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=332, train_loss_step=0.0109, train_loss_epoch=0.0156]Epoch 475: Train Loss = 0.010894611477851868\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=332, train_loss_step=0.00917, train_loss_epoch=0.0109]Epoch 476: Train Loss = 0.009174482896924019\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=332, train_loss_step=0.00863, train_loss_epoch=0.00917]Epoch 477: Train Loss = 0.008629056625068188\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=332, train_loss_step=0.0121, train_loss_epoch=0.00863] Epoch 478: Train Loss = 0.01207245048135519\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=332, train_loss_step=0.00975, train_loss_epoch=0.0121]Epoch 479: Train Loss = 0.009748274460434914\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=332, train_loss_step=0.00914, train_loss_epoch=0.00975]Epoch 480: Train Loss = 0.009135373868048191\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=332, train_loss_step=0.0127, train_loss_epoch=0.00914] Epoch 481: Train Loss = 0.012659857980906963\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0127] Epoch 482: Train Loss = 0.012646441347897053\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=332, train_loss_step=0.00996, train_loss_epoch=0.0126]Epoch 483: Train Loss = 0.009959505870938301\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=332, train_loss_step=0.0109, train_loss_epoch=0.00996] Epoch 484: Train Loss = 0.010906045325100422\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=332, train_loss_step=0.0169, train_loss_epoch=0.0109] Epoch 485: Train Loss = 0.016945626586675644\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=332, train_loss_step=0.0147, train_loss_epoch=0.0169]Epoch 486: Train Loss = 0.0147062037140131\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=332, train_loss_step=0.0117, train_loss_epoch=0.0147]Epoch 487: Train Loss = 0.01171081978827715\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=332, train_loss_step=0.0126, train_loss_epoch=0.0117]Epoch 488: Train Loss = 0.012607122771441936\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=332, train_loss_step=0.011, train_loss_epoch=0.0126] Epoch 489: Train Loss = 0.011046799831092358\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=332, train_loss_step=0.011, train_loss_epoch=0.011] Epoch 490: Train Loss = 0.01095609925687313\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s, v_num=332, train_loss_step=0.0102, train_loss_epoch=0.011]Epoch 491: Train Loss = 0.010199976153671741\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=332, train_loss_step=0.0118, train_loss_epoch=0.0102]Epoch 492: Train Loss = 0.011774682439863682\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=332, train_loss_step=0.0114, train_loss_epoch=0.0118]Epoch 493: Train Loss = 0.01139810774475336\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=332, train_loss_step=0.00977, train_loss_epoch=0.0114]Epoch 494: Train Loss = 0.009770411066710949\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=332, train_loss_step=0.0125, train_loss_epoch=0.00977] Epoch 495: Train Loss = 0.012536657974123955\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=332, train_loss_step=0.016, train_loss_epoch=0.0125]  Epoch 496: Train Loss = 0.016023319214582443\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=332, train_loss_step=0.0113, train_loss_epoch=0.016]Epoch 497: Train Loss = 0.011280358768999577\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=332, train_loss_step=0.0125, train_loss_epoch=0.0113]Epoch 498: Train Loss = 0.012517375871539116\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=332, train_loss_step=0.011, train_loss_epoch=0.0125] Epoch 499: Train Loss = 0.010950403288006783\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=332, train_loss_step=0.011, train_loss_epoch=0.011] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=332, train_loss_step=0.011, train_loss_epoch=0.011]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 13: from 2010-06-30 00:00:00 to 2022-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s, v_num=336, train_loss_step=0.028]Epoch 0: Train Loss = 0.02804690971970558\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=336, train_loss_step=0.0399, train_loss_epoch=0.028]Epoch 1: Train Loss = 0.03990353271365166\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=336, train_loss_step=0.0312, train_loss_epoch=0.0399]Epoch 2: Train Loss = 0.031212087720632553\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=336, train_loss_step=0.0251, train_loss_epoch=0.0312]Epoch 3: Train Loss = 0.025085488334298134\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=336, train_loss_step=0.0246, train_loss_epoch=0.0251]Epoch 4: Train Loss = 0.024615172296762466\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=336, train_loss_step=0.0243, train_loss_epoch=0.0246]Epoch 5: Train Loss = 0.024331901222467422\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=336, train_loss_step=0.0248, train_loss_epoch=0.0243]Epoch 6: Train Loss = 0.024764304980635643\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=336, train_loss_step=0.0203, train_loss_epoch=0.0248]Epoch 7: Train Loss = 0.02032383345067501\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=336, train_loss_step=0.0155, train_loss_epoch=0.0203]Epoch 8: Train Loss = 0.015510882250964642\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=336, train_loss_step=0.0171, train_loss_epoch=0.0155]Epoch 9: Train Loss = 0.017111744731664658\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=336, train_loss_step=0.0156, train_loss_epoch=0.0171]Epoch 10: Train Loss = 0.015606343746185303\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s, v_num=336, train_loss_step=0.0237, train_loss_epoch=0.0156]Epoch 11: Train Loss = 0.02370794117450714\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=336, train_loss_step=0.0145, train_loss_epoch=0.0237]Epoch 12: Train Loss = 0.014485876075923443\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=336, train_loss_step=0.0116, train_loss_epoch=0.0145]Epoch 13: Train Loss = 0.011648676358163357\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=336, train_loss_step=0.0192, train_loss_epoch=0.0116]Epoch 14: Train Loss = 0.01920495368540287\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=336, train_loss_step=0.0162, train_loss_epoch=0.0192]Epoch 15: Train Loss = 0.016162265092134476\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=336, train_loss_step=0.0112, train_loss_epoch=0.0162]Epoch 16: Train Loss = 0.011187387630343437\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=336, train_loss_step=0.015, train_loss_epoch=0.0112] Epoch 17: Train Loss = 0.015024763531982899\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=336, train_loss_step=0.0153, train_loss_epoch=0.015]Epoch 18: Train Loss = 0.015251214616000652\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=336, train_loss_step=0.0163, train_loss_epoch=0.0153]Epoch 19: Train Loss = 0.016296738758683205\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=336, train_loss_step=0.0171, train_loss_epoch=0.0163]Epoch 20: Train Loss = 0.01714264415204525\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.0171]Epoch 21: Train Loss = 0.014150322414934635\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=336, train_loss_step=0.0141, train_loss_epoch=0.0142]Epoch 22: Train Loss = 0.014144331216812134\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=336, train_loss_step=0.0211, train_loss_epoch=0.0141]Epoch 23: Train Loss = 0.021094130352139473\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=336, train_loss_step=0.0143, train_loss_epoch=0.0211]Epoch 24: Train Loss = 0.014323561452329159\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0143]Epoch 25: Train Loss = 0.01335927750915289\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=336, train_loss_step=0.0214, train_loss_epoch=0.0134]Epoch 26: Train Loss = 0.021438688039779663\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=336, train_loss_step=0.0207, train_loss_epoch=0.0214]Epoch 27: Train Loss = 0.020702922716736794\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0207]Epoch 28: Train Loss = 0.013456016778945923\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s, v_num=336, train_loss_step=0.0129, train_loss_epoch=0.0135]Epoch 29: Train Loss = 0.012893355451524258\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=336, train_loss_step=0.0137, train_loss_epoch=0.0129]Epoch 30: Train Loss = 0.013728360645473003\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=336, train_loss_step=0.0185, train_loss_epoch=0.0137]Epoch 31: Train Loss = 0.01850857399404049\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=336, train_loss_step=0.0143, train_loss_epoch=0.0185]Epoch 32: Train Loss = 0.014314977452158928\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=336, train_loss_step=0.0199, train_loss_epoch=0.0143]Epoch 33: Train Loss = 0.019879711791872978\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=336, train_loss_step=0.0175, train_loss_epoch=0.0199]Epoch 34: Train Loss = 0.01749172993004322\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=336, train_loss_step=0.0105, train_loss_epoch=0.0175]Epoch 35: Train Loss = 0.010516469366848469\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=336, train_loss_step=0.0129, train_loss_epoch=0.0105]Epoch 36: Train Loss = 0.012941999360918999\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=336, train_loss_step=0.0119, train_loss_epoch=0.0129]Epoch 37: Train Loss = 0.01194232888519764\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=336, train_loss_step=0.0116, train_loss_epoch=0.0119]Epoch 38: Train Loss = 0.011628474108874798\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=336, train_loss_step=0.0133, train_loss_epoch=0.0116]Epoch 39: Train Loss = 0.013255777768790722\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s, v_num=336, train_loss_step=0.0168, train_loss_epoch=0.0133]Epoch 40: Train Loss = 0.016813205555081367\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=336, train_loss_step=0.0144, train_loss_epoch=0.0168]Epoch 41: Train Loss = 0.014448825269937515\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=336, train_loss_step=0.0164, train_loss_epoch=0.0144]Epoch 42: Train Loss = 0.01639942266047001\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=336, train_loss_step=0.0151, train_loss_epoch=0.0164]Epoch 43: Train Loss = 0.015126454643905163\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=336, train_loss_step=0.0124, train_loss_epoch=0.0151]Epoch 44: Train Loss = 0.01240791566669941\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=336, train_loss_step=0.0156, train_loss_epoch=0.0124]Epoch 45: Train Loss = 0.015569566749036312\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0156]Epoch 46: Train Loss = 0.013436638750135899\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=336, train_loss_step=0.0141, train_loss_epoch=0.0134]Epoch 47: Train Loss = 0.014131234958767891\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=336, train_loss_step=0.0117, train_loss_epoch=0.0141]Epoch 48: Train Loss = 0.011687704361975193\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=336, train_loss_step=0.0164, train_loss_epoch=0.0117]Epoch 49: Train Loss = 0.01642720028758049\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=336, train_loss_step=0.0159, train_loss_epoch=0.0164]Epoch 50: Train Loss = 0.01585005782544613\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=336, train_loss_step=0.0144, train_loss_epoch=0.0159]Epoch 51: Train Loss = 0.014384117908775806\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=336, train_loss_step=0.0178, train_loss_epoch=0.0144]Epoch 52: Train Loss = 0.01779976859688759\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=336, train_loss_step=0.0137, train_loss_epoch=0.0178]Epoch 53: Train Loss = 0.013738053850829601\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=336, train_loss_step=0.0117, train_loss_epoch=0.0137]Epoch 54: Train Loss = 0.011690453626215458\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.0117]Epoch 55: Train Loss = 0.014210550114512444\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=336, train_loss_step=0.016, train_loss_epoch=0.0142] Epoch 56: Train Loss = 0.015970861539244652\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=336, train_loss_step=0.011, train_loss_epoch=0.016] Epoch 57: Train Loss = 0.011005070991814137\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=336, train_loss_step=0.0154, train_loss_epoch=0.011]Epoch 58: Train Loss = 0.01536258589476347\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.0154]Epoch 59: Train Loss = 0.014168930239975452\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.0142]Epoch 60: Train Loss = 0.012601236812770367\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0126]Epoch 61: Train Loss = 0.013461553491652012\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.0135] Epoch 62: Train Loss = 0.01200044248253107\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=336, train_loss_step=0.0112, train_loss_epoch=0.012]Epoch 63: Train Loss = 0.011172940023243427\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=336, train_loss_step=0.0124, train_loss_epoch=0.0112]Epoch 64: Train Loss = 0.0124271335080266\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=336, train_loss_step=0.0158, train_loss_epoch=0.0124]Epoch 65: Train Loss = 0.015834925696253777\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.0158]Epoch 66: Train Loss = 0.014225050806999207\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0142]Epoch 67: Train Loss = 0.013549529016017914\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=336, train_loss_step=0.0145, train_loss_epoch=0.0135]Epoch 68: Train Loss = 0.014518569223582745\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.0145]Epoch 69: Train Loss = 0.012636951170861721\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=336, train_loss_step=0.014, train_loss_epoch=0.0126] Epoch 70: Train Loss = 0.014013891108334064\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=336, train_loss_step=0.0198, train_loss_epoch=0.014]Epoch 71: Train Loss = 0.019772229716181755\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=336, train_loss_step=0.0151, train_loss_epoch=0.0198]Epoch 72: Train Loss = 0.015083730220794678\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=336, train_loss_step=0.0131, train_loss_epoch=0.0151]Epoch 73: Train Loss = 0.013103197328746319\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=336, train_loss_step=0.0144, train_loss_epoch=0.0131]Epoch 74: Train Loss = 0.01436598040163517\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=336, train_loss_step=0.0156, train_loss_epoch=0.0144]Epoch 75: Train Loss = 0.015569559298455715\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.0156]Epoch 76: Train Loss = 0.014197339303791523\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=336, train_loss_step=0.0147, train_loss_epoch=0.0142]Epoch 77: Train Loss = 0.014741504564881325\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=336, train_loss_step=0.016, train_loss_epoch=0.0147] Epoch 78: Train Loss = 0.015980016440153122\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=336, train_loss_step=0.015, train_loss_epoch=0.016] Epoch 79: Train Loss = 0.014972574077546597\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=336, train_loss_step=0.0164, train_loss_epoch=0.015]Epoch 80: Train Loss = 0.016431596130132675\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=336, train_loss_step=0.0162, train_loss_epoch=0.0164]Epoch 81: Train Loss = 0.016164425760507584\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=336, train_loss_step=0.0111, train_loss_epoch=0.0162]Epoch 82: Train Loss = 0.01107371412217617\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=336, train_loss_step=0.0113, train_loss_epoch=0.0111]Epoch 83: Train Loss = 0.011296962387859821\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=336, train_loss_step=0.0151, train_loss_epoch=0.0113]Epoch 84: Train Loss = 0.015118919312953949\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=336, train_loss_step=0.014, train_loss_epoch=0.0151] Epoch 85: Train Loss = 0.014032560400664806\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=336, train_loss_step=0.0219, train_loss_epoch=0.014]Epoch 86: Train Loss = 0.021942337974905968\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0219]Epoch 87: Train Loss = 0.013500526547431946\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=336, train_loss_step=0.0154, train_loss_epoch=0.0135]Epoch 88: Train Loss = 0.015433753840625286\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=336, train_loss_step=0.0132, train_loss_epoch=0.0154]Epoch 89: Train Loss = 0.013184942305088043\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=336, train_loss_step=0.0112, train_loss_epoch=0.0132]Epoch 90: Train Loss = 0.01120808906853199\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=336, train_loss_step=0.0166, train_loss_epoch=0.0112]Epoch 91: Train Loss = 0.016590489074587822\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=336, train_loss_step=0.0165, train_loss_epoch=0.0166]Epoch 92: Train Loss = 0.016477996483445168\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=336, train_loss_step=0.0179, train_loss_epoch=0.0165]Epoch 93: Train Loss = 0.01794312335550785\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=336, train_loss_step=0.0204, train_loss_epoch=0.0179]Epoch 94: Train Loss = 0.020447691902518272\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.0204]Epoch 95: Train Loss = 0.0121114831417799\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.0121]Epoch 96: Train Loss = 0.01256310660392046\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=336, train_loss_step=0.013, train_loss_epoch=0.0126] Epoch 97: Train Loss = 0.013045936822891235\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=336, train_loss_step=0.0123, train_loss_epoch=0.013]Epoch 98: Train Loss = 0.01230101939290762\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.0123]Epoch 99: Train Loss = 0.012647596187889576\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=336, train_loss_step=0.0122, train_loss_epoch=0.0126]Epoch 100: Train Loss = 0.01218880619853735\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=336, train_loss_step=0.0129, train_loss_epoch=0.0122]Epoch 101: Train Loss = 0.012853809632360935\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=336, train_loss_step=0.0152, train_loss_epoch=0.0129]Epoch 102: Train Loss = 0.015235903672873974\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=336, train_loss_step=0.010, train_loss_epoch=0.0152] Epoch 103: Train Loss = 0.010035042650997639\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=336, train_loss_step=0.0145, train_loss_epoch=0.010]Epoch 104: Train Loss = 0.014486415311694145\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=336, train_loss_step=0.0163, train_loss_epoch=0.0145]Epoch 105: Train Loss = 0.01633150316774845\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=336, train_loss_step=0.0112, train_loss_epoch=0.0163]Epoch 106: Train Loss = 0.011153295636177063\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0112]Epoch 107: Train Loss = 0.01358382124453783\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0136]Epoch 108: Train Loss = 0.01346707995980978\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0135]Epoch 109: Train Loss = 0.013511164113879204\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=336, train_loss_step=0.013, train_loss_epoch=0.0135] Epoch 110: Train Loss = 0.012955470941960812\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=336, train_loss_step=0.0123, train_loss_epoch=0.013]Epoch 111: Train Loss = 0.012329088523983955\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=336, train_loss_step=0.0179, train_loss_epoch=0.0123]Epoch 112: Train Loss = 0.017906861379742622\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=336, train_loss_step=0.0151, train_loss_epoch=0.0179]Epoch 113: Train Loss = 0.015123412944376469\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=336, train_loss_step=0.0156, train_loss_epoch=0.0151]Epoch 114: Train Loss = 0.0156378336250782\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=336, train_loss_step=0.0148, train_loss_epoch=0.0156]Epoch 115: Train Loss = 0.01483734417706728\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=336, train_loss_step=0.0106, train_loss_epoch=0.0148]Epoch 116: Train Loss = 0.01059558242559433\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=336, train_loss_step=0.0107, train_loss_epoch=0.0106]Epoch 117: Train Loss = 0.010715847834944725\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0107]Epoch 118: Train Loss = 0.013443981297314167\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=336, train_loss_step=0.0144, train_loss_epoch=0.0134]Epoch 119: Train Loss = 0.014369483105838299\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s, v_num=336, train_loss_step=0.0133, train_loss_epoch=0.0144]Epoch 120: Train Loss = 0.013320920057594776\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=336, train_loss_step=0.0139, train_loss_epoch=0.0133]Epoch 121: Train Loss = 0.013924865052103996\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=336, train_loss_step=0.0119, train_loss_epoch=0.0139]Epoch 122: Train Loss = 0.01187174953520298\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0119]Epoch 123: Train Loss = 0.013597319833934307\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=336, train_loss_step=0.0206, train_loss_epoch=0.0136]Epoch 124: Train Loss = 0.02055821381509304\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=336, train_loss_step=0.0132, train_loss_epoch=0.0206]Epoch 125: Train Loss = 0.01319835428148508\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=336, train_loss_step=0.0115, train_loss_epoch=0.0132]Epoch 126: Train Loss = 0.011500284075737\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.0115]Epoch 127: Train Loss = 0.012127979658544064\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=336, train_loss_step=0.0147, train_loss_epoch=0.0121]Epoch 128: Train Loss = 0.01471737865358591\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=336, train_loss_step=0.0122, train_loss_epoch=0.0147]Epoch 129: Train Loss = 0.012226630933582783\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 11.37it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0122]Epoch 130: Train Loss = 0.013443278148770332\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=336, train_loss_step=0.0138, train_loss_epoch=0.0134]Epoch 131: Train Loss = 0.013770364224910736\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=336, train_loss_step=0.0111, train_loss_epoch=0.0138]Epoch 132: Train Loss = 0.011059606447815895\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, v_num=336, train_loss_step=0.0118, train_loss_epoch=0.0111]Epoch 133: Train Loss = 0.011837340891361237\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=336, train_loss_step=0.0139, train_loss_epoch=0.0118]Epoch 134: Train Loss = 0.013850404880940914\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s, v_num=336, train_loss_step=0.0164, train_loss_epoch=0.0139]Epoch 135: Train Loss = 0.016394412145018578\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=336, train_loss_step=0.0127, train_loss_epoch=0.0164]Epoch 136: Train Loss = 0.0127348517999053\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=336, train_loss_step=0.0124, train_loss_epoch=0.0127]Epoch 137: Train Loss = 0.012414270080626011\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0124]Epoch 138: Train Loss = 0.013603891246020794\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0136]Epoch 139: Train Loss = 0.013637542724609375\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=336, train_loss_step=0.0164, train_loss_epoch=0.0136]Epoch 140: Train Loss = 0.01640302874147892\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=336, train_loss_step=0.00992, train_loss_epoch=0.0164]Epoch 141: Train Loss = 0.009916441515088081\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=336, train_loss_step=0.0167, train_loss_epoch=0.00992] Epoch 142: Train Loss = 0.01668003387749195\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=336, train_loss_step=0.0129, train_loss_epoch=0.0167] Epoch 143: Train Loss = 0.012880304828286171\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=336, train_loss_step=0.0155, train_loss_epoch=0.0129]Epoch 144: Train Loss = 0.01553697232156992\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0155]Epoch 145: Train Loss = 0.01339409314095974\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=336, train_loss_step=0.0115, train_loss_epoch=0.0134]Epoch 146: Train Loss = 0.011489330790936947\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=336, train_loss_step=0.0113, train_loss_epoch=0.0115]Epoch 147: Train Loss = 0.011276519857347012\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.0113]Epoch 148: Train Loss = 0.01260031946003437\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=336, train_loss_step=0.011, train_loss_epoch=0.0126] Epoch 149: Train Loss = 0.011007120832800865\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.011] Epoch 150: Train Loss = 0.011985821649432182\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=336, train_loss_step=0.0145, train_loss_epoch=0.012]Epoch 151: Train Loss = 0.014517443254590034\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=336, train_loss_step=0.0116, train_loss_epoch=0.0145]Epoch 152: Train Loss = 0.0116188433021307\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=336, train_loss_step=0.011, train_loss_epoch=0.0116] Epoch 153: Train Loss = 0.010960550047457218\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.011]Epoch 154: Train Loss = 0.01261452492326498\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=336, train_loss_step=0.00907, train_loss_epoch=0.0126]Epoch 155: Train Loss = 0.00907491147518158\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.00907] Epoch 156: Train Loss = 0.013563127256929874\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=336, train_loss_step=0.00928, train_loss_epoch=0.0136]Epoch 157: Train Loss = 0.009279671125113964\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=336, train_loss_step=0.011, train_loss_epoch=0.00928]  Epoch 158: Train Loss = 0.010997184552252293\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 10.52it/s, v_num=336, train_loss_step=0.0118, train_loss_epoch=0.011] Epoch 159: Train Loss = 0.01178746111690998\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=336, train_loss_step=0.0113, train_loss_epoch=0.0118]Epoch 160: Train Loss = 0.01125506404787302\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.0113]Epoch 161: Train Loss = 0.01205358188599348\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 12.33it/s, v_num=336, train_loss_step=0.00939, train_loss_epoch=0.0121]Epoch 162: Train Loss = 0.009387410245835781\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=336, train_loss_step=0.0124, train_loss_epoch=0.00939] Epoch 163: Train Loss = 0.012421319261193275\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.0124] Epoch 164: Train Loss = 0.01264325063675642\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=336, train_loss_step=0.011, train_loss_epoch=0.0126] Epoch 165: Train Loss = 0.011008507572114468\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=336, train_loss_step=0.0193, train_loss_epoch=0.011]Epoch 166: Train Loss = 0.019252050668001175\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=336, train_loss_step=0.0148, train_loss_epoch=0.0193]Epoch 167: Train Loss = 0.01484166644513607\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=336, train_loss_step=0.0123, train_loss_epoch=0.0148]Epoch 168: Train Loss = 0.012332665733993053\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=336, train_loss_step=0.0146, train_loss_epoch=0.0123]Epoch 169: Train Loss = 0.014645987190306187\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=336, train_loss_step=0.0108, train_loss_epoch=0.0146]Epoch 170: Train Loss = 0.010806693695485592\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=336, train_loss_step=0.0153, train_loss_epoch=0.0108]Epoch 171: Train Loss = 0.015260093845427036\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=336, train_loss_step=0.0103, train_loss_epoch=0.0153]Epoch 172: Train Loss = 0.01034051924943924\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=336, train_loss_step=0.0117, train_loss_epoch=0.0103]Epoch 173: Train Loss = 0.011689320206642151\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  9.60it/s, v_num=336, train_loss_step=0.0129, train_loss_epoch=0.0117]Epoch 174: Train Loss = 0.012931476347148418\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 10.63it/s, v_num=336, train_loss_step=0.0166, train_loss_epoch=0.0129]Epoch 175: Train Loss = 0.016608385369181633\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0166]Epoch 176: Train Loss = 0.013421745039522648\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=336, train_loss_step=0.0146, train_loss_epoch=0.0134]Epoch 177: Train Loss = 0.014625735580921173\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=336, train_loss_step=0.0104, train_loss_epoch=0.0146]Epoch 178: Train Loss = 0.010400771163403988\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=336, train_loss_step=0.0107, train_loss_epoch=0.0104]Epoch 179: Train Loss = 0.010735370218753815\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=336, train_loss_step=0.0104, train_loss_epoch=0.0107]Epoch 180: Train Loss = 0.010379232466220856\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=336, train_loss_step=0.0137, train_loss_epoch=0.0104]Epoch 181: Train Loss = 0.01369159109890461\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.0137] Epoch 182: Train Loss = 0.011981283314526081\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.012]Epoch 183: Train Loss = 0.012638399377465248\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=336, train_loss_step=0.0115, train_loss_epoch=0.0126]Epoch 184: Train Loss = 0.011457708664238453\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.0115]Epoch 185: Train Loss = 0.011440680362284184\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=336, train_loss_step=0.0183, train_loss_epoch=0.0114]Epoch 186: Train Loss = 0.018345877528190613\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=336, train_loss_step=0.0122, train_loss_epoch=0.0183]Epoch 187: Train Loss = 0.012238792143762112\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.0122]Epoch 188: Train Loss = 0.012568098492920399\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=336, train_loss_step=0.0104, train_loss_epoch=0.0126]Epoch 189: Train Loss = 0.010440131649374962\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=336, train_loss_step=0.0115, train_loss_epoch=0.0104]Epoch 190: Train Loss = 0.011536057107150555\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=336, train_loss_step=0.0131, train_loss_epoch=0.0115]Epoch 191: Train Loss = 0.013128088787198067\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=336, train_loss_step=0.0116, train_loss_epoch=0.0131]Epoch 192: Train Loss = 0.011645367369055748\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=336, train_loss_step=0.0151, train_loss_epoch=0.0116]Epoch 193: Train Loss = 0.0151212802156806\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=336, train_loss_step=0.0175, train_loss_epoch=0.0151]Epoch 194: Train Loss = 0.01751507632434368\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.0175] Epoch 195: Train Loss = 0.012012258172035217\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=336, train_loss_step=0.0112, train_loss_epoch=0.012]Epoch 196: Train Loss = 0.011152951046824455\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0112]Epoch 197: Train Loss = 0.01358040515333414\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=336, train_loss_step=0.0133, train_loss_epoch=0.0136]Epoch 198: Train Loss = 0.013254010118544102\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=336, train_loss_step=0.014, train_loss_epoch=0.0133] Epoch 199: Train Loss = 0.013966729864478111\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=336, train_loss_step=0.0116, train_loss_epoch=0.014]Epoch 200: Train Loss = 0.01159610040485859\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=336, train_loss_step=0.0102, train_loss_epoch=0.0116]Epoch 201: Train Loss = 0.010198344476521015\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=336, train_loss_step=0.0152, train_loss_epoch=0.0102]Epoch 202: Train Loss = 0.015231160447001457\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.0152]Epoch 203: Train Loss = 0.011367159895598888\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=336, train_loss_step=0.0138, train_loss_epoch=0.0114]Epoch 204: Train Loss = 0.013815654441714287\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=336, train_loss_step=0.0116, train_loss_epoch=0.0138]Epoch 205: Train Loss = 0.01162461843341589\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=336, train_loss_step=0.0185, train_loss_epoch=0.0116]Epoch 206: Train Loss = 0.01849159598350525\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=336, train_loss_step=0.0148, train_loss_epoch=0.0185]Epoch 207: Train Loss = 0.014849415980279446\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=336, train_loss_step=0.0132, train_loss_epoch=0.0148]Epoch 208: Train Loss = 0.013241143897175789\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=336, train_loss_step=0.0144, train_loss_epoch=0.0132]Epoch 209: Train Loss = 0.01443472784012556\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=336, train_loss_step=0.00994, train_loss_epoch=0.0144]Epoch 210: Train Loss = 0.009943506680428982\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=336, train_loss_step=0.0129, train_loss_epoch=0.00994] Epoch 211: Train Loss = 0.012913576327264309\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=336, train_loss_step=0.0117, train_loss_epoch=0.0129] Epoch 212: Train Loss = 0.011679532006382942\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=336, train_loss_step=0.0111, train_loss_epoch=0.0117]Epoch 213: Train Loss = 0.011103504337370396\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=336, train_loss_step=0.0167, train_loss_epoch=0.0111]Epoch 214: Train Loss = 0.016675984486937523\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=336, train_loss_step=0.0106, train_loss_epoch=0.0167]Epoch 215: Train Loss = 0.010602084919810295\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=336, train_loss_step=0.0183, train_loss_epoch=0.0106]Epoch 216: Train Loss = 0.0183002557605505\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=336, train_loss_step=0.0165, train_loss_epoch=0.0183]Epoch 217: Train Loss = 0.016506172716617584\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.0165]Epoch 218: Train Loss = 0.011405052617192268\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=336, train_loss_step=0.0118, train_loss_epoch=0.0114]Epoch 219: Train Loss = 0.011811601929366589\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0118]Epoch 220: Train Loss = 0.013595552183687687\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0136]Epoch 221: Train Loss = 0.013608238659799099\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=336, train_loss_step=0.0108, train_loss_epoch=0.0136]Epoch 222: Train Loss = 0.0107742790132761\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=336, train_loss_step=0.0103, train_loss_epoch=0.0108]Epoch 223: Train Loss = 0.010342171415686607\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0103]Epoch 224: Train Loss = 0.013577749021351337\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.0136]Epoch 225: Train Loss = 0.012147532775998116\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=336, train_loss_step=0.0125, train_loss_epoch=0.0121]Epoch 226: Train Loss = 0.01249547116458416\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=336, train_loss_step=0.0138, train_loss_epoch=0.0125]Epoch 227: Train Loss = 0.013753312639892101\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.0138]Epoch 228: Train Loss = 0.011437040753662586\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=336, train_loss_step=0.0138, train_loss_epoch=0.0114]Epoch 229: Train Loss = 0.013776727952063084\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=336, train_loss_step=0.0145, train_loss_epoch=0.0138]Epoch 230: Train Loss = 0.014484369195997715\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=336, train_loss_step=0.0109, train_loss_epoch=0.0145]Epoch 231: Train Loss = 0.010882833041250706\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=336, train_loss_step=0.0153, train_loss_epoch=0.0109]Epoch 232: Train Loss = 0.015271996147930622\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=336, train_loss_step=0.0162, train_loss_epoch=0.0153]Epoch 233: Train Loss = 0.01623729057610035\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=336, train_loss_step=0.0116, train_loss_epoch=0.0162]Epoch 234: Train Loss = 0.011619120836257935\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=336, train_loss_step=0.0164, train_loss_epoch=0.0116]Epoch 235: Train Loss = 0.01640884391963482\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=336, train_loss_step=0.0106, train_loss_epoch=0.0164]Epoch 236: Train Loss = 0.01056179590523243\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=336, train_loss_step=0.0155, train_loss_epoch=0.0106]Epoch 237: Train Loss = 0.01551129575818777\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.0155]Epoch 238: Train Loss = 0.012115283869206905\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=336, train_loss_step=0.0149, train_loss_epoch=0.0121]Epoch 239: Train Loss = 0.014877734705805779\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=336, train_loss_step=0.0115, train_loss_epoch=0.0149]Epoch 240: Train Loss = 0.011466762982308865\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=336, train_loss_step=0.0147, train_loss_epoch=0.0115]Epoch 241: Train Loss = 0.014733846299350262\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.0147] Epoch 242: Train Loss = 0.011984889395534992\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=336, train_loss_step=0.0161, train_loss_epoch=0.012]Epoch 243: Train Loss = 0.016120197251439095\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=336, train_loss_step=0.0127, train_loss_epoch=0.0161]Epoch 244: Train Loss = 0.012665881775319576\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=336, train_loss_step=0.0151, train_loss_epoch=0.0127]Epoch 245: Train Loss = 0.015130596235394478\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=336, train_loss_step=0.0125, train_loss_epoch=0.0151]Epoch 246: Train Loss = 0.012541649863123894\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.0125]Epoch 247: Train Loss = 0.01424754224717617\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=336, train_loss_step=0.0118, train_loss_epoch=0.0142]Epoch 248: Train Loss = 0.011764245107769966\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s, v_num=336, train_loss_step=0.013, train_loss_epoch=0.0118] Epoch 249: Train Loss = 0.013026753440499306\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=336, train_loss_step=0.0148, train_loss_epoch=0.013]Epoch 250: Train Loss = 0.014848952181637287\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0148]Epoch 251: Train Loss = 0.013623273000121117\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=336, train_loss_step=0.0119, train_loss_epoch=0.0136]Epoch 252: Train Loss = 0.011915785260498524\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 10.18it/s, v_num=336, train_loss_step=0.0137, train_loss_epoch=0.0119]Epoch 253: Train Loss = 0.013721824623644352\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=336, train_loss_step=0.0108, train_loss_epoch=0.0137]Epoch 254: Train Loss = 0.010823625139892101\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=336, train_loss_step=0.0122, train_loss_epoch=0.0108]Epoch 255: Train Loss = 0.012171064503490925\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=336, train_loss_step=0.0124, train_loss_epoch=0.0122]Epoch 256: Train Loss = 0.012402810156345367\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=336, train_loss_step=0.0148, train_loss_epoch=0.0124]Epoch 257: Train Loss = 0.014804775826632977\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=336, train_loss_step=0.0119, train_loss_epoch=0.0148]Epoch 258: Train Loss = 0.011937132105231285\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=336, train_loss_step=0.00859, train_loss_epoch=0.0119]Epoch 259: Train Loss = 0.008585718460381031\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=336, train_loss_step=0.0143, train_loss_epoch=0.00859] Epoch 260: Train Loss = 0.014308844693005085\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=336, train_loss_step=0.0117, train_loss_epoch=0.0143] Epoch 261: Train Loss = 0.011690284125506878\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=336, train_loss_step=0.017, train_loss_epoch=0.0117] Epoch 262: Train Loss = 0.01704530045390129\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=336, train_loss_step=0.013, train_loss_epoch=0.017] Epoch 263: Train Loss = 0.013027733191847801\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=336, train_loss_step=0.014, train_loss_epoch=0.013]Epoch 264: Train Loss = 0.014035187661647797\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 11.33it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.014]Epoch 265: Train Loss = 0.011363108642399311\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=336, train_loss_step=0.0109, train_loss_epoch=0.0114]Epoch 266: Train Loss = 0.010918679647147655\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=336, train_loss_step=0.0118, train_loss_epoch=0.0109]Epoch 267: Train Loss = 0.011810568161308765\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s, v_num=336, train_loss_step=0.0128, train_loss_epoch=0.0118]Epoch 268: Train Loss = 0.012831797823309898\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=336, train_loss_step=0.0123, train_loss_epoch=0.0128]Epoch 269: Train Loss = 0.01229836791753769\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=336, train_loss_step=0.0107, train_loss_epoch=0.0123]Epoch 270: Train Loss = 0.010689176619052887\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0107]Epoch 271: Train Loss = 0.01342239324003458\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=336, train_loss_step=0.0127, train_loss_epoch=0.0134]Epoch 272: Train Loss = 0.012743547558784485\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=336, train_loss_step=0.0103, train_loss_epoch=0.0127]Epoch 273: Train Loss = 0.01033887080848217\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=336, train_loss_step=0.00994, train_loss_epoch=0.0103]Epoch 274: Train Loss = 0.009942195378243923\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=336, train_loss_step=0.0145, train_loss_epoch=0.00994] Epoch 275: Train Loss = 0.014468307606875896\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=336, train_loss_step=0.013, train_loss_epoch=0.0145]  Epoch 276: Train Loss = 0.01299951784312725\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=336, train_loss_step=0.0139, train_loss_epoch=0.013]Epoch 277: Train Loss = 0.013919740915298462\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.0139] Epoch 278: Train Loss = 0.011991032399237156\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=336, train_loss_step=0.0124, train_loss_epoch=0.012]Epoch 279: Train Loss = 0.01239604689180851\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=336, train_loss_step=0.0101, train_loss_epoch=0.0124]Epoch 280: Train Loss = 0.01014429796487093\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0101]Epoch 281: Train Loss = 0.013506685383617878\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=336, train_loss_step=0.0138, train_loss_epoch=0.0135]Epoch 282: Train Loss = 0.013781988993287086\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s, v_num=336, train_loss_step=0.00985, train_loss_epoch=0.0138]Epoch 283: Train Loss = 0.009846778586506844\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=336, train_loss_step=0.00922, train_loss_epoch=0.00985]Epoch 284: Train Loss = 0.009219793602824211\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=336, train_loss_step=0.0184, train_loss_epoch=0.00922] Epoch 285: Train Loss = 0.018360910937190056\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=336, train_loss_step=0.0115, train_loss_epoch=0.0184] Epoch 286: Train Loss = 0.011470095254480839\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=336, train_loss_step=0.011, train_loss_epoch=0.0115] Epoch 287: Train Loss = 0.010985088534653187\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=336, train_loss_step=0.0107, train_loss_epoch=0.011]Epoch 288: Train Loss = 0.010717571713030338\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=336, train_loss_step=0.011, train_loss_epoch=0.0107] Epoch 289: Train Loss = 0.01097892690449953\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=336, train_loss_step=0.014, train_loss_epoch=0.011] Epoch 290: Train Loss = 0.01401880569756031\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=336, train_loss_step=0.0125, train_loss_epoch=0.014]Epoch 291: Train Loss = 0.01247057318687439\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0125]Epoch 292: Train Loss = 0.0135463522747159\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=336, train_loss_step=0.0125, train_loss_epoch=0.0135]Epoch 293: Train Loss = 0.012497355230152607\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.0125]Epoch 294: Train Loss = 0.01209926325827837\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=336, train_loss_step=0.0145, train_loss_epoch=0.0121]Epoch 295: Train Loss = 0.01445724256336689\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=336, train_loss_step=0.00937, train_loss_epoch=0.0145]Epoch 296: Train Loss = 0.009373250417411327\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=336, train_loss_step=0.0131, train_loss_epoch=0.00937] Epoch 297: Train Loss = 0.013139506801962852\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=336, train_loss_step=0.0125, train_loss_epoch=0.0131] Epoch 298: Train Loss = 0.012485623359680176\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, v_num=336, train_loss_step=0.0133, train_loss_epoch=0.0125]Epoch 299: Train Loss = 0.013347122818231583\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=336, train_loss_step=0.0139, train_loss_epoch=0.0133]Epoch 300: Train Loss = 0.013948261737823486\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=336, train_loss_step=0.00906, train_loss_epoch=0.0139]Epoch 301: Train Loss = 0.009063943289220333\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.00906] Epoch 302: Train Loss = 0.012590748257935047\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=336, train_loss_step=0.0108, train_loss_epoch=0.0126] Epoch 303: Train Loss = 0.010809836909174919\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=336, train_loss_step=0.0157, train_loss_epoch=0.0108]Epoch 304: Train Loss = 0.01569303311407566\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=336, train_loss_step=0.0108, train_loss_epoch=0.0157]Epoch 305: Train Loss = 0.01076019648462534\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=336, train_loss_step=0.0106, train_loss_epoch=0.0108]Epoch 306: Train Loss = 0.010593967512249947\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=336, train_loss_step=0.0109, train_loss_epoch=0.0106]Epoch 307: Train Loss = 0.010855404660105705\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.0109]Epoch 308: Train Loss = 0.011422774754464626\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=336, train_loss_step=0.00878, train_loss_epoch=0.0114]Epoch 309: Train Loss = 0.008784177713096142\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=336, train_loss_step=0.0109, train_loss_epoch=0.00878] Epoch 310: Train Loss = 0.010862642899155617\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=336, train_loss_step=0.0107, train_loss_epoch=0.0109] Epoch 311: Train Loss = 0.010687878355383873\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=336, train_loss_step=0.0132, train_loss_epoch=0.0107]Epoch 312: Train Loss = 0.013206998817622662\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, v_num=336, train_loss_step=0.0088, train_loss_epoch=0.0132]Epoch 313: Train Loss = 0.008803722448647022\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0088]Epoch 314: Train Loss = 0.013588025234639645\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=336, train_loss_step=0.0113, train_loss_epoch=0.0136]Epoch 315: Train Loss = 0.011298044584691525\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=336, train_loss_step=0.0113, train_loss_epoch=0.0113]Epoch 316: Train Loss = 0.011336011812090874\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=336, train_loss_step=0.00813, train_loss_epoch=0.0113]Epoch 317: Train Loss = 0.008132864721119404\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.00813] Epoch 318: Train Loss = 0.011423836462199688\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=336, train_loss_step=0.00978, train_loss_epoch=0.0114]Epoch 319: Train Loss = 0.009783418849110603\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 10.74it/s, v_num=336, train_loss_step=0.0123, train_loss_epoch=0.00978] Epoch 320: Train Loss = 0.012332705780863762\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=336, train_loss_step=0.0112, train_loss_epoch=0.0123] Epoch 321: Train Loss = 0.011226377449929714\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=336, train_loss_step=0.0144, train_loss_epoch=0.0112]Epoch 322: Train Loss = 0.014364155940711498\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.0144]Epoch 323: Train Loss = 0.012096120975911617\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=336, train_loss_step=0.0116, train_loss_epoch=0.0121]Epoch 324: Train Loss = 0.0115851741284132\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=336, train_loss_step=0.0118, train_loss_epoch=0.0116]Epoch 325: Train Loss = 0.01181940920650959\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=336, train_loss_step=0.0131, train_loss_epoch=0.0118]Epoch 326: Train Loss = 0.013145089149475098\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=336, train_loss_step=0.0167, train_loss_epoch=0.0131]Epoch 327: Train Loss = 0.016724249348044395\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=336, train_loss_step=0.00884, train_loss_epoch=0.0167]Epoch 328: Train Loss = 0.008842292241752148\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=336, train_loss_step=0.0116, train_loss_epoch=0.00884] Epoch 329: Train Loss = 0.011563017964363098\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=336, train_loss_step=0.0109, train_loss_epoch=0.0116] Epoch 330: Train Loss = 0.01090978179126978\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=336, train_loss_step=0.0132, train_loss_epoch=0.0109]Epoch 331: Train Loss = 0.013165020383894444\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0132]Epoch 332: Train Loss = 0.013567538000643253\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0136]Epoch 333: Train Loss = 0.013534479774534702\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.0135] Epoch 334: Train Loss = 0.012012628838419914\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=336, train_loss_step=0.00939, train_loss_epoch=0.012]Epoch 335: Train Loss = 0.009386902675032616\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=336, train_loss_step=0.0128, train_loss_epoch=0.00939] Epoch 336: Train Loss = 0.012839588336646557\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=336, train_loss_step=0.0105, train_loss_epoch=0.0128] Epoch 337: Train Loss = 0.010498656891286373\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=336, train_loss_step=0.0159, train_loss_epoch=0.0105]Epoch 338: Train Loss = 0.015859022736549377\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=336, train_loss_step=0.0128, train_loss_epoch=0.0159]Epoch 339: Train Loss = 0.012772815302014351\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=336, train_loss_step=0.0104, train_loss_epoch=0.0128]Epoch 340: Train Loss = 0.010402420535683632\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=336, train_loss_step=0.0117, train_loss_epoch=0.0104]Epoch 341: Train Loss = 0.011710201390087605\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=336, train_loss_step=0.0124, train_loss_epoch=0.0117]Epoch 342: Train Loss = 0.012400896288454533\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=336, train_loss_step=0.0167, train_loss_epoch=0.0124]Epoch 343: Train Loss = 0.016705576330423355\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=336, train_loss_step=0.0105, train_loss_epoch=0.0167]Epoch 344: Train Loss = 0.010508930310606956\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=336, train_loss_step=0.0129, train_loss_epoch=0.0105]Epoch 345: Train Loss = 0.01285652257502079\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=336, train_loss_step=0.0153, train_loss_epoch=0.0129]Epoch 346: Train Loss = 0.015333540737628937\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=336, train_loss_step=0.0141, train_loss_epoch=0.0153]Epoch 347: Train Loss = 0.01405287254601717\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=336, train_loss_step=0.00944, train_loss_epoch=0.0141]Epoch 348: Train Loss = 0.009436211548745632\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=336, train_loss_step=0.00912, train_loss_epoch=0.00944]Epoch 349: Train Loss = 0.009119764901697636\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=336, train_loss_step=0.0132, train_loss_epoch=0.00912] Epoch 350: Train Loss = 0.013188495300710201\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=336, train_loss_step=0.0188, train_loss_epoch=0.0132] Epoch 351: Train Loss = 0.018820971250534058\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=336, train_loss_step=0.0129, train_loss_epoch=0.0188]Epoch 352: Train Loss = 0.012883678078651428\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 10.45it/s, v_num=336, train_loss_step=0.0127, train_loss_epoch=0.0129]Epoch 353: Train Loss = 0.012708648107945919\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=336, train_loss_step=0.0138, train_loss_epoch=0.0127]Epoch 354: Train Loss = 0.013780659064650536\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.0138]Epoch 355: Train Loss = 0.011401171796023846\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=336, train_loss_step=0.0102, train_loss_epoch=0.0114]Epoch 356: Train Loss = 0.010213926434516907\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=336, train_loss_step=0.0156, train_loss_epoch=0.0102]Epoch 357: Train Loss = 0.015638520941138268\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=336, train_loss_step=0.0111, train_loss_epoch=0.0156]Epoch 358: Train Loss = 0.011141544207930565\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.0111]Epoch 359: Train Loss = 0.01210050005465746\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=336, train_loss_step=0.0165, train_loss_epoch=0.0121]Epoch 360: Train Loss = 0.016549689695239067\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=336, train_loss_step=0.0119, train_loss_epoch=0.0165]Epoch 361: Train Loss = 0.011853485368192196\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=336, train_loss_step=0.0102, train_loss_epoch=0.0119]Epoch 362: Train Loss = 0.010246215388178825\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=336, train_loss_step=0.00998, train_loss_epoch=0.0102]Epoch 363: Train Loss = 0.009983403608202934\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=336, train_loss_step=0.0157, train_loss_epoch=0.00998] Epoch 364: Train Loss = 0.01568634994328022\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s, v_num=336, train_loss_step=0.0107, train_loss_epoch=0.0157] Epoch 365: Train Loss = 0.010733701288700104\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s, v_num=336, train_loss_step=0.014, train_loss_epoch=0.0107] Epoch 366: Train Loss = 0.013968455605208874\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.014]Epoch 367: Train Loss = 0.011351050809025764\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=336, train_loss_step=0.0115, train_loss_epoch=0.0114]Epoch 368: Train Loss = 0.011461879126727581\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=336, train_loss_step=0.00838, train_loss_epoch=0.0115]Epoch 369: Train Loss = 0.00838066078722477\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.00838] Epoch 370: Train Loss = 0.01210037898272276\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=336, train_loss_step=0.0117, train_loss_epoch=0.0121] Epoch 371: Train Loss = 0.01167088933289051\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=336, train_loss_step=0.00927, train_loss_epoch=0.0117]Epoch 372: Train Loss = 0.009269201196730137\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=336, train_loss_step=0.0105, train_loss_epoch=0.00927] Epoch 373: Train Loss = 0.010477891191840172\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=336, train_loss_step=0.0127, train_loss_epoch=0.0105] Epoch 374: Train Loss = 0.012714228592813015\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=336, train_loss_step=0.0113, train_loss_epoch=0.0127]Epoch 375: Train Loss = 0.01133662648499012\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=336, train_loss_step=0.0103, train_loss_epoch=0.0113]Epoch 376: Train Loss = 0.010272453539073467\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=336, train_loss_step=0.0125, train_loss_epoch=0.0103]Epoch 377: Train Loss = 0.012497643940150738\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=336, train_loss_step=0.0095, train_loss_epoch=0.0125]Epoch 378: Train Loss = 0.009498086757957935\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=336, train_loss_step=0.0101, train_loss_epoch=0.0095]Epoch 379: Train Loss = 0.010131613351404667\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s, v_num=336, train_loss_step=0.0131, train_loss_epoch=0.0101]Epoch 380: Train Loss = 0.013065832667052746\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=336, train_loss_step=0.0124, train_loss_epoch=0.0131]Epoch 381: Train Loss = 0.012368306517601013\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=336, train_loss_step=0.0116, train_loss_epoch=0.0124]Epoch 382: Train Loss = 0.01158297061920166\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=336, train_loss_step=0.0176, train_loss_epoch=0.0116]Epoch 383: Train Loss = 0.01756218634545803\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=336, train_loss_step=0.018, train_loss_epoch=0.0176] Epoch 384: Train Loss = 0.01803063414990902\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=336, train_loss_step=0.0133, train_loss_epoch=0.018]Epoch 385: Train Loss = 0.013257130980491638\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=336, train_loss_step=0.0119, train_loss_epoch=0.0133]Epoch 386: Train Loss = 0.011935758404433727\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=336, train_loss_step=0.014, train_loss_epoch=0.0119] Epoch 387: Train Loss = 0.013989567756652832\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s, v_num=336, train_loss_step=0.0105, train_loss_epoch=0.014]Epoch 388: Train Loss = 0.010475941002368927\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=336, train_loss_step=0.0131, train_loss_epoch=0.0105]Epoch 389: Train Loss = 0.013110206462442875\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=336, train_loss_step=0.0124, train_loss_epoch=0.0131]Epoch 390: Train Loss = 0.012383823283016682\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.0124] Epoch 391: Train Loss = 0.011956713162362576\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.012]Epoch 392: Train Loss = 0.012615897692739964\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=336, train_loss_step=0.0124, train_loss_epoch=0.0126]Epoch 393: Train Loss = 0.012443493120372295\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=336, train_loss_step=0.0127, train_loss_epoch=0.0124]Epoch 394: Train Loss = 0.012653500773012638\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 395: Train Loss = 0.012031015940010548\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.012]Epoch 396: Train Loss = 0.013486512936651707\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=336, train_loss_step=0.0106, train_loss_epoch=0.0135]Epoch 397: Train Loss = 0.01059812307357788\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s, v_num=336, train_loss_step=0.0108, train_loss_epoch=0.0106]Epoch 398: Train Loss = 0.010779664851725101\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=336, train_loss_step=0.0125, train_loss_epoch=0.0108]Epoch 399: Train Loss = 0.012518957257270813\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.0125]Epoch 400: Train Loss = 0.012619921937584877\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=336, train_loss_step=0.0102, train_loss_epoch=0.0126]Epoch 401: Train Loss = 0.010188235901296139\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=336, train_loss_step=0.00931, train_loss_epoch=0.0102]Epoch 402: Train Loss = 0.0093106459826231\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=336, train_loss_step=0.0166, train_loss_epoch=0.00931] Epoch 403: Train Loss = 0.01660117320716381\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.0166] Epoch 404: Train Loss = 0.011430700309574604\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=336, train_loss_step=0.0145, train_loss_epoch=0.0114]Epoch 405: Train Loss = 0.01454903930425644\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=336, train_loss_step=0.0118, train_loss_epoch=0.0145]Epoch 406: Train Loss = 0.011782354675233364\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=336, train_loss_step=0.0133, train_loss_epoch=0.0118]Epoch 407: Train Loss = 0.013266965746879578\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0133]Epoch 408: Train Loss = 0.013357549905776978\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=336, train_loss_step=0.0129, train_loss_epoch=0.0134]Epoch 409: Train Loss = 0.012895660474896431\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=336, train_loss_step=0.00849, train_loss_epoch=0.0129]Epoch 410: Train Loss = 0.008490758948028088\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=336, train_loss_step=0.00975, train_loss_epoch=0.00849]Epoch 411: Train Loss = 0.00975038018077612\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=336, train_loss_step=0.0171, train_loss_epoch=0.00975] Epoch 412: Train Loss = 0.017058981582522392\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0171] Epoch 413: Train Loss = 0.013395780697464943\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=336, train_loss_step=0.013, train_loss_epoch=0.0134] Epoch 414: Train Loss = 0.01303647831082344\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=336, train_loss_step=0.0122, train_loss_epoch=0.013]Epoch 415: Train Loss = 0.012170849367976189\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=336, train_loss_step=0.0131, train_loss_epoch=0.0122]Epoch 416: Train Loss = 0.013073616661131382\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=336, train_loss_step=0.0106, train_loss_epoch=0.0131]Epoch 417: Train Loss = 0.01062698382884264\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=336, train_loss_step=0.0109, train_loss_epoch=0.0106]Epoch 418: Train Loss = 0.010860578157007694\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=336, train_loss_step=0.0184, train_loss_epoch=0.0109]Epoch 419: Train Loss = 0.01843923330307007\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=336, train_loss_step=0.0128, train_loss_epoch=0.0184]Epoch 420: Train Loss = 0.012818226590752602\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=336, train_loss_step=0.0139, train_loss_epoch=0.0128]Epoch 421: Train Loss = 0.013869729824364185\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=336, train_loss_step=0.0105, train_loss_epoch=0.0139]Epoch 422: Train Loss = 0.010543329641222954\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=336, train_loss_step=0.0146, train_loss_epoch=0.0105]Epoch 423: Train Loss = 0.014628730714321136\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.0146]Epoch 424: Train Loss = 0.01259175781160593\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s, v_num=336, train_loss_step=0.0119, train_loss_epoch=0.0126]Epoch 425: Train Loss = 0.011896154843270779\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=336, train_loss_step=0.0149, train_loss_epoch=0.0119]Epoch 426: Train Loss = 0.014938929118216038\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=336, train_loss_step=0.0136, train_loss_epoch=0.0149]Epoch 427: Train Loss = 0.013646906241774559\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=336, train_loss_step=0.0128, train_loss_epoch=0.0136]Epoch 428: Train Loss = 0.012782357633113861\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=336, train_loss_step=0.0115, train_loss_epoch=0.0128]Epoch 429: Train Loss = 0.011483858339488506\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=336, train_loss_step=0.0105, train_loss_epoch=0.0115]Epoch 430: Train Loss = 0.010522931814193726\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=336, train_loss_step=0.0117, train_loss_epoch=0.0105]Epoch 431: Train Loss = 0.011703034862875938\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=336, train_loss_step=0.0139, train_loss_epoch=0.0117]Epoch 432: Train Loss = 0.013942425139248371\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=336, train_loss_step=0.0112, train_loss_epoch=0.0139]Epoch 433: Train Loss = 0.011164932511746883\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=336, train_loss_step=0.0137, train_loss_epoch=0.0112]Epoch 434: Train Loss = 0.013732241466641426\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=336, train_loss_step=0.0111, train_loss_epoch=0.0137]Epoch 435: Train Loss = 0.011085478588938713\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s, v_num=336, train_loss_step=0.0122, train_loss_epoch=0.0111]Epoch 436: Train Loss = 0.012247824110090733\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=336, train_loss_step=0.0146, train_loss_epoch=0.0122]Epoch 437: Train Loss = 0.014607446268200874\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0146]Epoch 438: Train Loss = 0.013458816334605217\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=336, train_loss_step=0.0119, train_loss_epoch=0.0135]Epoch 439: Train Loss = 0.011868844740092754\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=336, train_loss_step=0.0145, train_loss_epoch=0.0119]Epoch 440: Train Loss = 0.014477542601525784\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.0145]Epoch 441: Train Loss = 0.011410095728933811\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.0114]Epoch 442: Train Loss = 0.014166506938636303\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=336, train_loss_step=0.0105, train_loss_epoch=0.0142]Epoch 443: Train Loss = 0.010455348528921604\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=336, train_loss_step=0.0132, train_loss_epoch=0.0105]Epoch 444: Train Loss = 0.013199693523347378\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=336, train_loss_step=0.0126, train_loss_epoch=0.0132]Epoch 445: Train Loss = 0.01261903066188097\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0126]Epoch 446: Train Loss = 0.013386928476393223\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=336, train_loss_step=0.0111, train_loss_epoch=0.0134]Epoch 447: Train Loss = 0.011119949631392956\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=336, train_loss_step=0.0122, train_loss_epoch=0.0111]Epoch 448: Train Loss = 0.012225157581269741\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=336, train_loss_step=0.00895, train_loss_epoch=0.0122]Epoch 449: Train Loss = 0.00895112194120884\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.00895] Epoch 450: Train Loss = 0.014221596531569958\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.0142]  Epoch 451: Train Loss = 0.012001363560557365\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=336, train_loss_step=0.00943, train_loss_epoch=0.012]Epoch 452: Train Loss = 0.009427623823285103\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=336, train_loss_step=0.0101, train_loss_epoch=0.00943] Epoch 453: Train Loss = 0.010130037553608418\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=336, train_loss_step=0.0157, train_loss_epoch=0.0101] Epoch 454: Train Loss = 0.015678809955716133\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=336, train_loss_step=0.011, train_loss_epoch=0.0157] Epoch 455: Train Loss = 0.011016837321221828\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=336, train_loss_step=0.0107, train_loss_epoch=0.011]Epoch 456: Train Loss = 0.010709459893405437\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=336, train_loss_step=0.00893, train_loss_epoch=0.0107]Epoch 457: Train Loss = 0.008932247757911682\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=336, train_loss_step=0.00887, train_loss_epoch=0.00893]Epoch 458: Train Loss = 0.008869856595993042\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=336, train_loss_step=0.0148, train_loss_epoch=0.00887] Epoch 459: Train Loss = 0.014840453863143921\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=336, train_loss_step=0.0151, train_loss_epoch=0.0148] Epoch 460: Train Loss = 0.015098865143954754\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s, v_num=336, train_loss_step=0.00942, train_loss_epoch=0.0151]Epoch 461: Train Loss = 0.009424315765500069\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.00942] Epoch 462: Train Loss = 0.012079328298568726\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=336, train_loss_step=0.0122, train_loss_epoch=0.0121] Epoch 463: Train Loss = 0.012194770388305187\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=336, train_loss_step=0.0151, train_loss_epoch=0.0122]Epoch 464: Train Loss = 0.015059342607855797\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=336, train_loss_step=0.0112, train_loss_epoch=0.0151]Epoch 465: Train Loss = 0.011156619526445866\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0112]Epoch 466: Train Loss = 0.013491198420524597\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=336, train_loss_step=0.0144, train_loss_epoch=0.0135]Epoch 467: Train Loss = 0.014431231655180454\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=336, train_loss_step=0.00906, train_loss_epoch=0.0144]Epoch 468: Train Loss = 0.009063920006155968\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=336, train_loss_step=0.0169, train_loss_epoch=0.00906] Epoch 469: Train Loss = 0.01687868870794773\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=336, train_loss_step=0.0137, train_loss_epoch=0.0169] Epoch 470: Train Loss = 0.013678132556378841\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=336, train_loss_step=0.0151, train_loss_epoch=0.0137]Epoch 471: Train Loss = 0.0150814950466156\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=336, train_loss_step=0.0129, train_loss_epoch=0.0151]Epoch 472: Train Loss = 0.012941260822117329\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=336, train_loss_step=0.0137, train_loss_epoch=0.0129]Epoch 473: Train Loss = 0.01366664282977581\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=336, train_loss_step=0.0141, train_loss_epoch=0.0137]Epoch 474: Train Loss = 0.014058775268495083\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=336, train_loss_step=0.0143, train_loss_epoch=0.0141]Epoch 475: Train Loss = 0.014309617690742016\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=336, train_loss_step=0.0111, train_loss_epoch=0.0143]Epoch 476: Train Loss = 0.01111889909952879\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=336, train_loss_step=0.0107, train_loss_epoch=0.0111]Epoch 477: Train Loss = 0.010734302923083305\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=336, train_loss_step=0.013, train_loss_epoch=0.0107] Epoch 478: Train Loss = 0.01296688336879015\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=336, train_loss_step=0.0121, train_loss_epoch=0.013]Epoch 479: Train Loss = 0.01205582357943058\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=336, train_loss_step=0.0135, train_loss_epoch=0.0121]Epoch 480: Train Loss = 0.013501440174877644\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=336, train_loss_step=0.0119, train_loss_epoch=0.0135]Epoch 481: Train Loss = 0.011877811513841152\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=336, train_loss_step=0.0104, train_loss_epoch=0.0119]Epoch 482: Train Loss = 0.010383342392742634\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=336, train_loss_step=0.00861, train_loss_epoch=0.0104]Epoch 483: Train Loss = 0.008614592254161835\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=336, train_loss_step=0.012, train_loss_epoch=0.00861]  Epoch 484: Train Loss = 0.011971233412623405\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=336, train_loss_step=0.0111, train_loss_epoch=0.012] Epoch 485: Train Loss = 0.011148244142532349\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=336, train_loss_step=0.0153, train_loss_epoch=0.0111]Epoch 486: Train Loss = 0.015348733402788639\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=336, train_loss_step=0.0112, train_loss_epoch=0.0153]Epoch 487: Train Loss = 0.011238912120461464\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=336, train_loss_step=0.0134, train_loss_epoch=0.0112]Epoch 488: Train Loss = 0.013356558047235012\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=336, train_loss_step=0.0158, train_loss_epoch=0.0134]Epoch 489: Train Loss = 0.015769517049193382\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=336, train_loss_step=0.00855, train_loss_epoch=0.0158]Epoch 490: Train Loss = 0.008553450927138329\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.00855] Epoch 491: Train Loss = 0.014160201884806156\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=336, train_loss_step=0.0117, train_loss_epoch=0.0142] Epoch 492: Train Loss = 0.01172138936817646\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=336, train_loss_step=0.0171, train_loss_epoch=0.0117]Epoch 493: Train Loss = 0.017064431682229042\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=336, train_loss_step=0.0114, train_loss_epoch=0.0171]Epoch 494: Train Loss = 0.01136096566915512\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=336, train_loss_step=0.0113, train_loss_epoch=0.0114]Epoch 495: Train Loss = 0.011253871954977512\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=336, train_loss_step=0.00985, train_loss_epoch=0.0113]Epoch 496: Train Loss = 0.00985210482031107\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=336, train_loss_step=0.0125, train_loss_epoch=0.00985] Epoch 497: Train Loss = 0.012465658597648144\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=336, train_loss_step=0.0154, train_loss_epoch=0.0125] Epoch 498: Train Loss = 0.015353335998952389\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.0154]Epoch 499: Train Loss = 0.014153414405882359\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.0142]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=336, train_loss_step=0.0142, train_loss_epoch=0.0142]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 14: from 2010-06-30 00:00:00 to 2022-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=340, train_loss_step=0.0215]Epoch 0: Train Loss = 0.021520376205444336\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=340, train_loss_step=0.0312, train_loss_epoch=0.0215]Epoch 1: Train Loss = 0.031204579398036003\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=340, train_loss_step=0.0413, train_loss_epoch=0.0312]Epoch 2: Train Loss = 0.04126463085412979\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=340, train_loss_step=0.0191, train_loss_epoch=0.0413]Epoch 3: Train Loss = 0.019050683826208115\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=340, train_loss_step=0.027, train_loss_epoch=0.0191] Epoch 4: Train Loss = 0.02700198069214821\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.32it/s, v_num=340, train_loss_step=0.0219, train_loss_epoch=0.027]Epoch 5: Train Loss = 0.02194577269256115\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=340, train_loss_step=0.0224, train_loss_epoch=0.0219]Epoch 6: Train Loss = 0.022363673895597458\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=340, train_loss_step=0.0247, train_loss_epoch=0.0224]Epoch 7: Train Loss = 0.024660969153046608\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.0247] Epoch 8: Train Loss = 0.013953368179500103\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=340, train_loss_step=0.0216, train_loss_epoch=0.014]Epoch 9: Train Loss = 0.021630296483635902\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=340, train_loss_step=0.0199, train_loss_epoch=0.0216]Epoch 10: Train Loss = 0.019857048988342285\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=340, train_loss_step=0.018, train_loss_epoch=0.0199] Epoch 11: Train Loss = 0.017995765432715416\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=340, train_loss_step=0.0114, train_loss_epoch=0.018]Epoch 12: Train Loss = 0.011358399875462055\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=340, train_loss_step=0.0144, train_loss_epoch=0.0114]Epoch 13: Train Loss = 0.01435793749988079\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=340, train_loss_step=0.0152, train_loss_epoch=0.0144]Epoch 14: Train Loss = 0.015233384445309639\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=340, train_loss_step=0.0155, train_loss_epoch=0.0152]Epoch 15: Train Loss = 0.015471315011382103\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  9.60it/s, v_num=340, train_loss_step=0.017, train_loss_epoch=0.0155] Epoch 16: Train Loss = 0.017002256587147713\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=340, train_loss_step=0.0137, train_loss_epoch=0.017]Epoch 17: Train Loss = 0.013713689520955086\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=340, train_loss_step=0.017, train_loss_epoch=0.0137] Epoch 18: Train Loss = 0.016984371468424797\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=340, train_loss_step=0.0143, train_loss_epoch=0.017]Epoch 19: Train Loss = 0.01430595014244318\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=340, train_loss_step=0.015, train_loss_epoch=0.0143] Epoch 20: Train Loss = 0.014998458325862885\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=340, train_loss_step=0.0132, train_loss_epoch=0.015]Epoch 21: Train Loss = 0.013169429264962673\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0132]Epoch 22: Train Loss = 0.01120048202574253\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.0112] Epoch 23: Train Loss = 0.013976164162158966\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=340, train_loss_step=0.0142, train_loss_epoch=0.014]Epoch 24: Train Loss = 0.014156701974570751\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=340, train_loss_step=0.0141, train_loss_epoch=0.0142]Epoch 25: Train Loss = 0.014094923622906208\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=340, train_loss_step=0.0166, train_loss_epoch=0.0141]Epoch 26: Train Loss = 0.016571780666708946\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s, v_num=340, train_loss_step=0.0123, train_loss_epoch=0.0166]Epoch 27: Train Loss = 0.012272394262254238\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=340, train_loss_step=0.0179, train_loss_epoch=0.0123]Epoch 28: Train Loss = 0.017886383458971977\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=340, train_loss_step=0.0187, train_loss_epoch=0.0179]Epoch 29: Train Loss = 0.018749689683318138\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=340, train_loss_step=0.0223, train_loss_epoch=0.0187]Epoch 30: Train Loss = 0.02225777879357338\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=340, train_loss_step=0.0164, train_loss_epoch=0.0223]Epoch 31: Train Loss = 0.016407018527388573\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=340, train_loss_step=0.0169, train_loss_epoch=0.0164]Epoch 32: Train Loss = 0.016850126907229424\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=340, train_loss_step=0.0165, train_loss_epoch=0.0169]Epoch 33: Train Loss = 0.01645827293395996\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=340, train_loss_step=0.0147, train_loss_epoch=0.0165]Epoch 34: Train Loss = 0.01474122516810894\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=340, train_loss_step=0.0211, train_loss_epoch=0.0147]Epoch 35: Train Loss = 0.02112133614718914\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=340, train_loss_step=0.0142, train_loss_epoch=0.0211]Epoch 36: Train Loss = 0.014241473749279976\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=340, train_loss_step=0.016, train_loss_epoch=0.0142] Epoch 37: Train Loss = 0.016013996675610542\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=340, train_loss_step=0.0152, train_loss_epoch=0.016]Epoch 38: Train Loss = 0.015153131447732449\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=340, train_loss_step=0.0228, train_loss_epoch=0.0152]Epoch 39: Train Loss = 0.02275296114385128\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=340, train_loss_step=0.0162, train_loss_epoch=0.0228]Epoch 40: Train Loss = 0.016175391152501106\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=340, train_loss_step=0.0161, train_loss_epoch=0.0162]Epoch 41: Train Loss = 0.016092384234070778\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=340, train_loss_step=0.0118, train_loss_epoch=0.0161]Epoch 42: Train Loss = 0.01179315336048603\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=340, train_loss_step=0.0132, train_loss_epoch=0.0118]Epoch 43: Train Loss = 0.013150321319699287\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=340, train_loss_step=0.0137, train_loss_epoch=0.0132]Epoch 44: Train Loss = 0.013662585988640785\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=340, train_loss_step=0.0132, train_loss_epoch=0.0137]Epoch 45: Train Loss = 0.013169079087674618\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0132]Epoch 46: Train Loss = 0.011880802921950817\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=340, train_loss_step=0.0146, train_loss_epoch=0.0119]Epoch 47: Train Loss = 0.014637225307524204\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=340, train_loss_step=0.018, train_loss_epoch=0.0146] Epoch 48: Train Loss = 0.017969880253076553\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=340, train_loss_step=0.0134, train_loss_epoch=0.018]Epoch 49: Train Loss = 0.013365604914724827\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=340, train_loss_step=0.0144, train_loss_epoch=0.0134]Epoch 50: Train Loss = 0.014431110583245754\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=340, train_loss_step=0.0155, train_loss_epoch=0.0144]Epoch 51: Train Loss = 0.015495987609028816\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=340, train_loss_step=0.0152, train_loss_epoch=0.0155]Epoch 52: Train Loss = 0.015223713591694832\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=340, train_loss_step=0.0115, train_loss_epoch=0.0152]Epoch 53: Train Loss = 0.011475484818220139\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=340, train_loss_step=0.0142, train_loss_epoch=0.0115]Epoch 54: Train Loss = 0.014173882082104683\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=340, train_loss_step=0.0165, train_loss_epoch=0.0142]Epoch 55: Train Loss = 0.016523048281669617\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=340, train_loss_step=0.0123, train_loss_epoch=0.0165]Epoch 56: Train Loss = 0.012321698479354382\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0123]Epoch 57: Train Loss = 0.011943497695028782\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=340, train_loss_step=0.0153, train_loss_epoch=0.0119]Epoch 58: Train Loss = 0.015253609046339989\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=340, train_loss_step=0.0209, train_loss_epoch=0.0153]Epoch 59: Train Loss = 0.02088427171111107\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=340, train_loss_step=0.0153, train_loss_epoch=0.0209]Epoch 60: Train Loss = 0.015281385742127895\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=340, train_loss_step=0.013, train_loss_epoch=0.0153] Epoch 61: Train Loss = 0.012978198938071728\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=340, train_loss_step=0.00972, train_loss_epoch=0.013]Epoch 62: Train Loss = 0.009718435816466808\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=340, train_loss_step=0.0138, train_loss_epoch=0.00972] Epoch 63: Train Loss = 0.013845463283360004\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=340, train_loss_step=0.015, train_loss_epoch=0.0138]  Epoch 64: Train Loss = 0.014995529316365719\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s, v_num=340, train_loss_step=0.0143, train_loss_epoch=0.015]Epoch 65: Train Loss = 0.014333343133330345\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0143]Epoch 66: Train Loss = 0.010897803120315075\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=340, train_loss_step=0.0144, train_loss_epoch=0.0109]Epoch 67: Train Loss = 0.014352171681821346\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=340, train_loss_step=0.0151, train_loss_epoch=0.0144]Epoch 68: Train Loss = 0.015144744887948036\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=340, train_loss_step=0.0152, train_loss_epoch=0.0151]Epoch 69: Train Loss = 0.015196901746094227\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=340, train_loss_step=0.0148, train_loss_epoch=0.0152]Epoch 70: Train Loss = 0.014819732867181301\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=340, train_loss_step=0.015, train_loss_epoch=0.0148] Epoch 71: Train Loss = 0.015034368261694908\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=340, train_loss_step=0.0132, train_loss_epoch=0.015]Epoch 72: Train Loss = 0.013227783143520355\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=340, train_loss_step=0.0191, train_loss_epoch=0.0132]Epoch 73: Train Loss = 0.01910443790256977\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=340, train_loss_step=0.0153, train_loss_epoch=0.0191]Epoch 74: Train Loss = 0.01525045745074749\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=340, train_loss_step=0.0136, train_loss_epoch=0.0153]Epoch 75: Train Loss = 0.013569178059697151\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=340, train_loss_step=0.0148, train_loss_epoch=0.0136]Epoch 76: Train Loss = 0.014827637933194637\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=340, train_loss_step=0.0161, train_loss_epoch=0.0148]Epoch 77: Train Loss = 0.016103746369481087\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=340, train_loss_step=0.0125, train_loss_epoch=0.0161]Epoch 78: Train Loss = 0.012540229596197605\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=340, train_loss_step=0.0209, train_loss_epoch=0.0125]Epoch 79: Train Loss = 0.020891591906547546\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=340, train_loss_step=0.0163, train_loss_epoch=0.0209]Epoch 80: Train Loss = 0.016261262819170952\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0163]Epoch 81: Train Loss = 0.011701692827045918\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=340, train_loss_step=0.013, train_loss_epoch=0.0117] Epoch 82: Train Loss = 0.013044824823737144\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=340, train_loss_step=0.0154, train_loss_epoch=0.013]Epoch 83: Train Loss = 0.015423203818500042\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=340, train_loss_step=0.0156, train_loss_epoch=0.0154]Epoch 84: Train Loss = 0.01557855773717165\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=340, train_loss_step=0.0135, train_loss_epoch=0.0156]Epoch 85: Train Loss = 0.013516618870198727\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=340, train_loss_step=0.0122, train_loss_epoch=0.0135]Epoch 86: Train Loss = 0.012191849760711193\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=340, train_loss_step=0.0163, train_loss_epoch=0.0122]Epoch 87: Train Loss = 0.016330115497112274\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.0163] Epoch 88: Train Loss = 0.014045940712094307\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=340, train_loss_step=0.0202, train_loss_epoch=0.014]Epoch 89: Train Loss = 0.020198604092001915\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.0202]Epoch 90: Train Loss = 0.012794161215424538\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=340, train_loss_step=0.0132, train_loss_epoch=0.0128]Epoch 91: Train Loss = 0.013221864588558674\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=340, train_loss_step=0.0159, train_loss_epoch=0.0132]Epoch 92: Train Loss = 0.015851318836212158\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=340, train_loss_step=0.0149, train_loss_epoch=0.0159]Epoch 93: Train Loss = 0.014941132627427578\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=340, train_loss_step=0.0175, train_loss_epoch=0.0149]Epoch 94: Train Loss = 0.017471767961978912\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.0175] Epoch 95: Train Loss = 0.013978667557239532\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=340, train_loss_step=0.0142, train_loss_epoch=0.014]Epoch 96: Train Loss = 0.014195933006703854\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=340, train_loss_step=0.0157, train_loss_epoch=0.0142]Epoch 97: Train Loss = 0.01572914607822895\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=340, train_loss_step=0.0173, train_loss_epoch=0.0157]Epoch 98: Train Loss = 0.017252188175916672\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=340, train_loss_step=0.0196, train_loss_epoch=0.0173]Epoch 99: Train Loss = 0.019611695781350136\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=340, train_loss_step=0.0145, train_loss_epoch=0.0196]Epoch 100: Train Loss = 0.01451350748538971\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=340, train_loss_step=0.0177, train_loss_epoch=0.0145]Epoch 101: Train Loss = 0.017678817734122276\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=340, train_loss_step=0.0107, train_loss_epoch=0.0177]Epoch 102: Train Loss = 0.010726611129939556\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=340, train_loss_step=0.0147, train_loss_epoch=0.0107]Epoch 103: Train Loss = 0.014713059179484844\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=340, train_loss_step=0.0142, train_loss_epoch=0.0147]Epoch 104: Train Loss = 0.014227773062884808\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.0142]Epoch 105: Train Loss = 0.012667261064052582\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0127]Epoch 106: Train Loss = 0.01116174552589655\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=340, train_loss_step=0.0141, train_loss_epoch=0.0112]Epoch 107: Train Loss = 0.014114625751972198\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s, v_num=340, train_loss_step=0.0168, train_loss_epoch=0.0141]Epoch 108: Train Loss = 0.016829002648591995\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=340, train_loss_step=0.0169, train_loss_epoch=0.0168]Epoch 109: Train Loss = 0.016949813812971115\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=340, train_loss_step=0.0178, train_loss_epoch=0.0169]Epoch 110: Train Loss = 0.01782192662358284\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=340, train_loss_step=0.0137, train_loss_epoch=0.0178]Epoch 111: Train Loss = 0.013701037503778934\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, v_num=340, train_loss_step=0.0171, train_loss_epoch=0.0137]Epoch 112: Train Loss = 0.01708703488111496\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=340, train_loss_step=0.013, train_loss_epoch=0.0171] Epoch 113: Train Loss = 0.01304860133677721\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=340, train_loss_step=0.0123, train_loss_epoch=0.013]Epoch 114: Train Loss = 0.012344432063400745\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=340, train_loss_step=0.0104, train_loss_epoch=0.0123]Epoch 115: Train Loss = 0.010350084863603115\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.0104]Epoch 116: Train Loss = 0.012664277106523514\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.0127]Epoch 117: Train Loss = 0.012842238880693913\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=340, train_loss_step=0.0131, train_loss_epoch=0.0128]Epoch 118: Train Loss = 0.013140072114765644\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=340, train_loss_step=0.00975, train_loss_epoch=0.0131]Epoch 119: Train Loss = 0.00975208729505539\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=340, train_loss_step=0.0157, train_loss_epoch=0.00975] Epoch 120: Train Loss = 0.01569383777678013\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0157] Epoch 121: Train Loss = 0.011749242432415485\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=340, train_loss_step=0.0172, train_loss_epoch=0.0117]Epoch 122: Train Loss = 0.017162945121526718\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=340, train_loss_step=0.0133, train_loss_epoch=0.0172]Epoch 123: Train Loss = 0.01331522036343813\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=340, train_loss_step=0.0121, train_loss_epoch=0.0133]Epoch 124: Train Loss = 0.01211966760456562\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.0121]Epoch 125: Train Loss = 0.012834311462938786\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=340, train_loss_step=0.0123, train_loss_epoch=0.0128]Epoch 126: Train Loss = 0.0123281329870224\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=340, train_loss_step=0.0139, train_loss_epoch=0.0123]Epoch 127: Train Loss = 0.013875516131520271\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=340, train_loss_step=0.0193, train_loss_epoch=0.0139]Epoch 128: Train Loss = 0.01925187185406685\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=340, train_loss_step=0.015, train_loss_epoch=0.0193] Epoch 129: Train Loss = 0.014969834126532078\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=340, train_loss_step=0.0139, train_loss_epoch=0.015]Epoch 130: Train Loss = 0.013864590786397457\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=340, train_loss_step=0.0144, train_loss_epoch=0.0139]Epoch 131: Train Loss = 0.01435949094593525\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.0144]Epoch 132: Train Loss = 0.012820564210414886\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=340, train_loss_step=0.0145, train_loss_epoch=0.0128]Epoch 133: Train Loss = 0.014522843062877655\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=340, train_loss_step=0.0129, train_loss_epoch=0.0145]Epoch 134: Train Loss = 0.012877230532467365\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=340, train_loss_step=0.0135, train_loss_epoch=0.0129]Epoch 135: Train Loss = 0.013507484458386898\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.0135] Epoch 136: Train Loss = 0.014043583534657955\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=340, train_loss_step=0.0115, train_loss_epoch=0.014]Epoch 137: Train Loss = 0.011510723270475864\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=340, train_loss_step=0.0139, train_loss_epoch=0.0115]Epoch 138: Train Loss = 0.01386217214167118\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=340, train_loss_step=0.0124, train_loss_epoch=0.0139]Epoch 139: Train Loss = 0.012362114153802395\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=340, train_loss_step=0.0137, train_loss_epoch=0.0124]Epoch 140: Train Loss = 0.013662018813192844\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.0137] Epoch 141: Train Loss = 0.012011668644845486\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.012] Epoch 142: Train Loss = 0.011953024193644524\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.012]Epoch 143: Train Loss = 0.011972352862358093\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=340, train_loss_step=0.0168, train_loss_epoch=0.012]Epoch 144: Train Loss = 0.01682005450129509\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=340, train_loss_step=0.0121, train_loss_epoch=0.0168]Epoch 145: Train Loss = 0.012119823135435581\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=340, train_loss_step=0.013, train_loss_epoch=0.0121] Epoch 146: Train Loss = 0.013001082465052605\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=340, train_loss_step=0.0124, train_loss_epoch=0.013]Epoch 147: Train Loss = 0.012396697886288166\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=340, train_loss_step=0.0126, train_loss_epoch=0.0124]Epoch 148: Train Loss = 0.012645433656871319\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=340, train_loss_step=0.0104, train_loss_epoch=0.0126]Epoch 149: Train Loss = 0.010427495464682579\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=340, train_loss_step=0.0125, train_loss_epoch=0.0104]Epoch 150: Train Loss = 0.012487352825701237\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=340, train_loss_step=0.0165, train_loss_epoch=0.0125]Epoch 151: Train Loss = 0.01649768464267254\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0165]Epoch 152: Train Loss = 0.010877415537834167\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=340, train_loss_step=0.0106, train_loss_epoch=0.0109]Epoch 153: Train Loss = 0.010630042292177677\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.0106] Epoch 154: Train Loss = 0.014019696973264217\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.014] Epoch 155: Train Loss = 0.014046087861061096\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.014]Epoch 156: Train Loss = 0.012833692133426666\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 11.64it/s, v_num=340, train_loss_step=0.0124, train_loss_epoch=0.0128]Epoch 157: Train Loss = 0.012427208945155144\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=340, train_loss_step=0.0156, train_loss_epoch=0.0124]Epoch 158: Train Loss = 0.015589861199259758\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=340, train_loss_step=0.0163, train_loss_epoch=0.0156]Epoch 159: Train Loss = 0.016331514343619347\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=340, train_loss_step=0.0149, train_loss_epoch=0.0163]Epoch 160: Train Loss = 0.014914115890860558\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=340, train_loss_step=0.0133, train_loss_epoch=0.0149]Epoch 161: Train Loss = 0.01334966067224741\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=340, train_loss_step=0.00994, train_loss_epoch=0.0133]Epoch 162: Train Loss = 0.009940050542354584\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=340, train_loss_step=0.0136, train_loss_epoch=0.00994] Epoch 163: Train Loss = 0.013613425195217133\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0136] Epoch 164: Train Loss = 0.01190528366714716\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=340, train_loss_step=0.0131, train_loss_epoch=0.0119]Epoch 165: Train Loss = 0.013105531223118305\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=340, train_loss_step=0.0124, train_loss_epoch=0.0131]Epoch 166: Train Loss = 0.012417558580636978\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s, v_num=340, train_loss_step=0.00968, train_loss_epoch=0.0124]Epoch 167: Train Loss = 0.009677018038928509\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=340, train_loss_step=0.0139, train_loss_epoch=0.00968] Epoch 168: Train Loss = 0.013942738994956017\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.0139]  Epoch 169: Train Loss = 0.014046577736735344\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=340, train_loss_step=0.0114, train_loss_epoch=0.014]Epoch 170: Train Loss = 0.011417520232498646\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=340, train_loss_step=0.0163, train_loss_epoch=0.0114]Epoch 171: Train Loss = 0.01629391685128212\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=340, train_loss_step=0.0115, train_loss_epoch=0.0163]Epoch 172: Train Loss = 0.011510184966027737\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=340, train_loss_step=0.0101, train_loss_epoch=0.0115]Epoch 173: Train Loss = 0.010139490477740765\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=340, train_loss_step=0.010, train_loss_epoch=0.0101] Epoch 174: Train Loss = 0.010043899528682232\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.010]Epoch 175: Train Loss = 0.012763610109686852\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=340, train_loss_step=0.0159, train_loss_epoch=0.0128]Epoch 176: Train Loss = 0.015914611518383026\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=340, train_loss_step=0.013, train_loss_epoch=0.0159] Epoch 177: Train Loss = 0.012961253523826599\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=340, train_loss_step=0.0163, train_loss_epoch=0.013]Epoch 178: Train Loss = 0.01634633168578148\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=340, train_loss_step=0.0153, train_loss_epoch=0.0163]Epoch 179: Train Loss = 0.015285131521522999\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  9.60it/s, v_num=340, train_loss_step=0.0124, train_loss_epoch=0.0153]Epoch 180: Train Loss = 0.012412650510668755\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=340, train_loss_step=0.0118, train_loss_epoch=0.0124]Epoch 181: Train Loss = 0.011839344166219234\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=340, train_loss_step=0.0135, train_loss_epoch=0.0118]Epoch 182: Train Loss = 0.013535097241401672\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=340, train_loss_step=0.0158, train_loss_epoch=0.0135]Epoch 183: Train Loss = 0.01584179699420929\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=340, train_loss_step=0.0156, train_loss_epoch=0.0158]Epoch 184: Train Loss = 0.015564343892037868\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=340, train_loss_step=0.0126, train_loss_epoch=0.0156]Epoch 185: Train Loss = 0.01260328572243452\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=340, train_loss_step=0.0164, train_loss_epoch=0.0126]Epoch 186: Train Loss = 0.016387369483709335\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=340, train_loss_step=0.0191, train_loss_epoch=0.0164]Epoch 187: Train Loss = 0.019053127616643906\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=340, train_loss_step=0.0131, train_loss_epoch=0.0191]Epoch 188: Train Loss = 0.013148002326488495\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=340, train_loss_step=0.0129, train_loss_epoch=0.0131]Epoch 189: Train Loss = 0.012927276082336903\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=340, train_loss_step=0.0136, train_loss_epoch=0.0129]Epoch 190: Train Loss = 0.01360952015966177\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0136]Epoch 191: Train Loss = 0.010759039781987667\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=340, train_loss_step=0.0149, train_loss_epoch=0.0108]Epoch 192: Train Loss = 0.014896811917424202\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=340, train_loss_step=0.0137, train_loss_epoch=0.0149]Epoch 193: Train Loss = 0.013671888038516045\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=340, train_loss_step=0.0163, train_loss_epoch=0.0137]Epoch 194: Train Loss = 0.016321774572134018\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.0163] Epoch 195: Train Loss = 0.011978165246546268\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.012]Epoch 196: Train Loss = 0.012796706520020962\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.0128]Epoch 197: Train Loss = 0.01277915108948946\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0128]Epoch 198: Train Loss = 0.011159590445458889\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=340, train_loss_step=0.0121, train_loss_epoch=0.0112]Epoch 199: Train Loss = 0.012063354253768921\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0121]Epoch 200: Train Loss = 0.010842458344995975\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=340, train_loss_step=0.0187, train_loss_epoch=0.0108]Epoch 201: Train Loss = 0.018727319315075874\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.0187]Epoch 202: Train Loss = 0.012733672745525837\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=340, train_loss_step=0.0136, train_loss_epoch=0.0127]Epoch 203: Train Loss = 0.013568216003477573\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=340, train_loss_step=0.00989, train_loss_epoch=0.0136]Epoch 204: Train Loss = 0.009890732355415821\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.00989]  Epoch 205: Train Loss = 0.011963470838963985\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=340, train_loss_step=0.0118, train_loss_epoch=0.012] Epoch 206: Train Loss = 0.01183408685028553\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.0118]Epoch 207: Train Loss = 0.012725514359772205\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=340, train_loss_step=0.0223, train_loss_epoch=0.0127]Epoch 208: Train Loss = 0.022313611581921577\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=340, train_loss_step=0.0134, train_loss_epoch=0.0223]Epoch 209: Train Loss = 0.013432299718260765\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.0134]Epoch 210: Train Loss = 0.011264985427260399\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=340, train_loss_step=0.011, train_loss_epoch=0.0113] Epoch 211: Train Loss = 0.01096476148813963\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=340, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 212: Train Loss = 0.012489535845816135\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=340, train_loss_step=0.00966, train_loss_epoch=0.0125]Epoch 213: Train Loss = 0.009656480513513088\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=340, train_loss_step=0.0139, train_loss_epoch=0.00966] Epoch 214: Train Loss = 0.013908334076404572\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=340, train_loss_step=0.0122, train_loss_epoch=0.0139] Epoch 215: Train Loss = 0.012234379537403584\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=340, train_loss_step=0.0167, train_loss_epoch=0.0122]Epoch 216: Train Loss = 0.016736162826418877\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=340, train_loss_step=0.0152, train_loss_epoch=0.0167]Epoch 217: Train Loss = 0.015246296301484108\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=340, train_loss_step=0.00864, train_loss_epoch=0.0152]Epoch 218: Train Loss = 0.008638033643364906\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.00864] Epoch 219: Train Loss = 0.011318136937916279\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=340, train_loss_step=0.0141, train_loss_epoch=0.0113] Epoch 220: Train Loss = 0.014117474667727947\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=340, train_loss_step=0.0115, train_loss_epoch=0.0141]Epoch 221: Train Loss = 0.011504081077873707\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=340, train_loss_step=0.0122, train_loss_epoch=0.0115]Epoch 222: Train Loss = 0.012177643366158009\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0122]Epoch 223: Train Loss = 0.011203457601368427\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.0112]Epoch 224: Train Loss = 0.01270019169896841\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=340, train_loss_step=0.0139, train_loss_epoch=0.0127]Epoch 225: Train Loss = 0.013902089558541775\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=340, train_loss_step=0.0107, train_loss_epoch=0.0139]Epoch 226: Train Loss = 0.010667949914932251\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=340, train_loss_step=0.0118, train_loss_epoch=0.0107]Epoch 227: Train Loss = 0.0118498420342803\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=340, train_loss_step=0.00919, train_loss_epoch=0.0118]Epoch 228: Train Loss = 0.00919150561094284\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=340, train_loss_step=0.0105, train_loss_epoch=0.00919] Epoch 229: Train Loss = 0.010544180870056152\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=340, train_loss_step=0.0147, train_loss_epoch=0.0105] Epoch 230: Train Loss = 0.014716165140271187\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=340, train_loss_step=0.0152, train_loss_epoch=0.0147]Epoch 231: Train Loss = 0.015249122865498066\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=340, train_loss_step=0.0126, train_loss_epoch=0.0152]Epoch 232: Train Loss = 0.012642038986086845\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0126]Epoch 233: Train Loss = 0.01094760000705719\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=340, train_loss_step=0.0124, train_loss_epoch=0.0109]Epoch 234: Train Loss = 0.012416630983352661\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=340, train_loss_step=0.0155, train_loss_epoch=0.0124]Epoch 235: Train Loss = 0.015522866509854794\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=340, train_loss_step=0.0165, train_loss_epoch=0.0155]Epoch 236: Train Loss = 0.01654534600675106\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=340, train_loss_step=0.0143, train_loss_epoch=0.0165]Epoch 237: Train Loss = 0.014338863082230091\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0143]Epoch 238: Train Loss = 0.010808663442730904\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0108]Epoch 239: Train Loss = 0.010935164988040924\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=340, train_loss_step=0.0101, train_loss_epoch=0.0109]Epoch 240: Train Loss = 0.010091935284435749\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.0101]Epoch 241: Train Loss = 0.012819266878068447\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=340, train_loss_step=0.0104, train_loss_epoch=0.0128]Epoch 242: Train Loss = 0.01040951069444418\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=340, train_loss_step=0.0144, train_loss_epoch=0.0104]Epoch 243: Train Loss = 0.014357578940689564\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=340, train_loss_step=0.0145, train_loss_epoch=0.0144]Epoch 244: Train Loss = 0.014504616148769855\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=340, train_loss_step=0.0196, train_loss_epoch=0.0145]Epoch 245: Train Loss = 0.019598867744207382\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0196]Epoch 246: Train Loss = 0.011724330484867096\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=340, train_loss_step=0.0163, train_loss_epoch=0.0117]Epoch 247: Train Loss = 0.016292987391352654\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0163]Epoch 248: Train Loss = 0.01075243391096592\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=340, train_loss_step=0.0131, train_loss_epoch=0.0108]Epoch 249: Train Loss = 0.013125734403729439\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=340, train_loss_step=0.0163, train_loss_epoch=0.0131]Epoch 250: Train Loss = 0.0163144338876009\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s, v_num=340, train_loss_step=0.0147, train_loss_epoch=0.0163]Epoch 251: Train Loss = 0.014676310122013092\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.0147] Epoch 252: Train Loss = 0.01398683525621891\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=340, train_loss_step=0.0115, train_loss_epoch=0.014]Epoch 253: Train Loss = 0.01153224240988493\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=340, train_loss_step=0.0144, train_loss_epoch=0.0115]Epoch 254: Train Loss = 0.01437617838382721\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=340, train_loss_step=0.0123, train_loss_epoch=0.0144]Epoch 255: Train Loss = 0.012251247651875019\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0123]Epoch 256: Train Loss = 0.011717846617102623\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=340, train_loss_step=0.0101, train_loss_epoch=0.0117]Epoch 257: Train Loss = 0.010072852484881878\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=340, train_loss_step=0.0104, train_loss_epoch=0.0101]Epoch 258: Train Loss = 0.010357022285461426\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=340, train_loss_step=0.0124, train_loss_epoch=0.0104]Epoch 259: Train Loss = 0.012437430210411549\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.0124] Epoch 260: Train Loss = 0.011963521130383015\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.012]Epoch 261: Train Loss = 0.011735325679183006\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0117]Epoch 262: Train Loss = 0.01173466444015503\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0117]Epoch 263: Train Loss = 0.01121597085148096\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=340, train_loss_step=0.0129, train_loss_epoch=0.0112]Epoch 264: Train Loss = 0.012880688533186913\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0129]Epoch 265: Train Loss = 0.01168300025165081\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=340, train_loss_step=0.0131, train_loss_epoch=0.0117]Epoch 266: Train Loss = 0.013072697445750237\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=340, train_loss_step=0.0107, train_loss_epoch=0.0131]Epoch 267: Train Loss = 0.01068267971277237\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, v_num=340, train_loss_step=0.0126, train_loss_epoch=0.0107]Epoch 268: Train Loss = 0.012607901357114315\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=340, train_loss_step=0.0162, train_loss_epoch=0.0126]Epoch 269: Train Loss = 0.016198689118027687\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=340, train_loss_step=0.00911, train_loss_epoch=0.0162]Epoch 270: Train Loss = 0.009109596721827984\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=340, train_loss_step=0.0115, train_loss_epoch=0.00911] Epoch 271: Train Loss = 0.011473394930362701\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.0115]  Epoch 272: Train Loss = 0.012025712989270687\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=340, train_loss_step=0.00902, train_loss_epoch=0.012]Epoch 273: Train Loss = 0.009015368297696114\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=340, train_loss_step=0.0123, train_loss_epoch=0.00902] Epoch 274: Train Loss = 0.012267405167222023\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=340, train_loss_step=0.0134, train_loss_epoch=0.0123] Epoch 275: Train Loss = 0.013362917117774487\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 10.97it/s, v_num=340, train_loss_step=0.0123, train_loss_epoch=0.0134]Epoch 276: Train Loss = 0.012272043153643608\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=340, train_loss_step=0.00993, train_loss_epoch=0.0123]Epoch 277: Train Loss = 0.009930556640028954\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.00993] Epoch 278: Train Loss = 0.012691458687186241\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=340, train_loss_step=0.0123, train_loss_epoch=0.0127] Epoch 279: Train Loss = 0.012282432056963444\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=340, train_loss_step=0.00963, train_loss_epoch=0.0123]Epoch 280: Train Loss = 0.009626517072319984\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.00963]  Epoch 281: Train Loss = 0.01395780686289072\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=340, train_loss_step=0.0101, train_loss_epoch=0.014] Epoch 282: Train Loss = 0.010113070718944073\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=340, train_loss_step=0.0135, train_loss_epoch=0.0101]Epoch 283: Train Loss = 0.01353372447192669\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0135]Epoch 284: Train Loss = 0.01079677976667881\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=340, train_loss_step=0.0106, train_loss_epoch=0.0108]Epoch 285: Train Loss = 0.010608847253024578\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=340, train_loss_step=0.0138, train_loss_epoch=0.0106]Epoch 286: Train Loss = 0.01379429455846548\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=340, train_loss_step=0.0124, train_loss_epoch=0.0138]Epoch 287: Train Loss = 0.012364478781819344\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=340, train_loss_step=0.0179, train_loss_epoch=0.0124]Epoch 288: Train Loss = 0.01793775148689747\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=340, train_loss_step=0.0111, train_loss_epoch=0.0179]Epoch 289: Train Loss = 0.011146217584609985\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0111]Epoch 290: Train Loss = 0.011191838420927525\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=340, train_loss_step=0.0104, train_loss_epoch=0.0112]Epoch 291: Train Loss = 0.010360540822148323\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=340, train_loss_step=0.0114, train_loss_epoch=0.0104]Epoch 292: Train Loss = 0.01140070240944624\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=340, train_loss_step=0.0151, train_loss_epoch=0.0114]Epoch 293: Train Loss = 0.015064343810081482\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=340, train_loss_step=0.015, train_loss_epoch=0.0151] Epoch 294: Train Loss = 0.014955274760723114\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.015]Epoch 295: Train Loss = 0.011735114268958569\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0117]Epoch 296: Train Loss = 0.010936787351965904\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.0109]Epoch 297: Train Loss = 0.012708804570138454\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0127]Epoch 298: Train Loss = 0.010801098309457302\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=340, train_loss_step=0.0132, train_loss_epoch=0.0108]Epoch 299: Train Loss = 0.013201597146689892\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=340, train_loss_step=0.0111, train_loss_epoch=0.0132]Epoch 300: Train Loss = 0.011103306896984577\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=340, train_loss_step=0.0102, train_loss_epoch=0.0111]Epoch 301: Train Loss = 0.010164842940866947\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=340, train_loss_step=0.00938, train_loss_epoch=0.0102]Epoch 302: Train Loss = 0.009380964562296867\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=340, train_loss_step=0.0143, train_loss_epoch=0.00938] Epoch 303: Train Loss = 0.01433927845209837\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=340, train_loss_step=0.0136, train_loss_epoch=0.0143] Epoch 304: Train Loss = 0.013590388000011444\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=340, train_loss_step=0.0141, train_loss_epoch=0.0136]Epoch 305: Train Loss = 0.014139547944068909\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=340, train_loss_step=0.0129, train_loss_epoch=0.0141]Epoch 306: Train Loss = 0.01293243933469057\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=340, train_loss_step=0.0126, train_loss_epoch=0.0129]Epoch 307: Train Loss = 0.012590840458869934\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=340, train_loss_step=0.0111, train_loss_epoch=0.0126]Epoch 308: Train Loss = 0.011080020107328892\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=340, train_loss_step=0.0149, train_loss_epoch=0.0111]Epoch 309: Train Loss = 0.014892774634063244\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=340, train_loss_step=0.00933, train_loss_epoch=0.0149]Epoch 310: Train Loss = 0.009325134567916393\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=340, train_loss_step=0.0125, train_loss_epoch=0.00933] Epoch 311: Train Loss = 0.012490938417613506\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=340, train_loss_step=0.0139, train_loss_epoch=0.0125] Epoch 312: Train Loss = 0.013928920961916447\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=340, train_loss_step=0.0144, train_loss_epoch=0.0139]Epoch 313: Train Loss = 0.014364548027515411\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=340, train_loss_step=0.0136, train_loss_epoch=0.0144]Epoch 314: Train Loss = 0.013613791204988956\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=340, train_loss_step=0.017, train_loss_epoch=0.0136] Epoch 315: Train Loss = 0.01700129173696041\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=340, train_loss_step=0.0133, train_loss_epoch=0.017]Epoch 316: Train Loss = 0.013282486237585545\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=340, train_loss_step=0.0099, train_loss_epoch=0.0133]Epoch 317: Train Loss = 0.009900438599288464\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0099]Epoch 318: Train Loss = 0.011933592148125172\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=340, train_loss_step=0.011, train_loss_epoch=0.0119] Epoch 319: Train Loss = 0.010981551371514797\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=340, train_loss_step=0.0152, train_loss_epoch=0.011]Epoch 320: Train Loss = 0.01516822911798954\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.0152]Epoch 321: Train Loss = 0.011306805536150932\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=340, train_loss_step=0.0103, train_loss_epoch=0.0113]Epoch 322: Train Loss = 0.010326199233531952\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=340, train_loss_step=0.013, train_loss_epoch=0.0103] Epoch 323: Train Loss = 0.01301415916532278\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=340, train_loss_step=0.0155, train_loss_epoch=0.013]Epoch 324: Train Loss = 0.015468866564333439\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, v_num=340, train_loss_step=0.0137, train_loss_epoch=0.0155]Epoch 325: Train Loss = 0.013724327087402344\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 10.79it/s, v_num=340, train_loss_step=0.0163, train_loss_epoch=0.0137]Epoch 326: Train Loss = 0.01632809452712536\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.0163]Epoch 327: Train Loss = 0.012796386145055294\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=340, train_loss_step=0.0116, train_loss_epoch=0.0128]Epoch 328: Train Loss = 0.011595308780670166\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0116]Epoch 329: Train Loss = 0.010807054117321968\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 11.33it/s, v_num=340, train_loss_step=0.0129, train_loss_epoch=0.0108]Epoch 330: Train Loss = 0.012923404574394226\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0129]Epoch 331: Train Loss = 0.011928237974643707\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=340, train_loss_step=0.0135, train_loss_epoch=0.0119]Epoch 332: Train Loss = 0.013539784587919712\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0135]Epoch 333: Train Loss = 0.011702614836394787\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=340, train_loss_step=0.00929, train_loss_epoch=0.0117]Epoch 334: Train Loss = 0.009287352673709393\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.00929] Epoch 335: Train Loss = 0.011302528902888298\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=340, train_loss_step=0.0155, train_loss_epoch=0.0113] Epoch 336: Train Loss = 0.015482719987630844\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=340, train_loss_step=0.0146, train_loss_epoch=0.0155]Epoch 337: Train Loss = 0.014611780643463135\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=340, train_loss_step=0.0168, train_loss_epoch=0.0146]Epoch 338: Train Loss = 0.016753900796175003\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=340, train_loss_step=0.017, train_loss_epoch=0.0168] Epoch 339: Train Loss = 0.017031194642186165\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=340, train_loss_step=0.0131, train_loss_epoch=0.017]Epoch 340: Train Loss = 0.013087281957268715\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=340, train_loss_step=0.0125, train_loss_epoch=0.0131]Epoch 341: Train Loss = 0.012541310861706734\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0125]Epoch 342: Train Loss = 0.011224521324038506\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=340, train_loss_step=0.0135, train_loss_epoch=0.0112]Epoch 343: Train Loss = 0.013464977033436298\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=340, train_loss_step=0.0115, train_loss_epoch=0.0135]Epoch 344: Train Loss = 0.011482366360723972\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=340, train_loss_step=0.0133, train_loss_epoch=0.0115]Epoch 345: Train Loss = 0.013287843205034733\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=340, train_loss_step=0.0121, train_loss_epoch=0.0133]Epoch 346: Train Loss = 0.01207960955798626\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=340, train_loss_step=0.0134, train_loss_epoch=0.0121]Epoch 347: Train Loss = 0.013386995531618595\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s, v_num=340, train_loss_step=0.0152, train_loss_epoch=0.0134]Epoch 348: Train Loss = 0.015195195563137531\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s, v_num=340, train_loss_step=0.0162, train_loss_epoch=0.0152]Epoch 349: Train Loss = 0.016214918345212936\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0162]Epoch 350: Train Loss = 0.010903583839535713\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0109]Epoch 351: Train Loss = 0.011942366138100624\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0119]Epoch 352: Train Loss = 0.011935197748243809\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.0119] Epoch 353: Train Loss = 0.011983764357864857\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.012]Epoch 354: Train Loss = 0.011165226809680462\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0112]Epoch 355: Train Loss = 0.01082573365420103\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.0108]Epoch 356: Train Loss = 0.012711980380117893\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0127]Epoch 357: Train Loss = 0.010797335766255856\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=340, train_loss_step=0.0116, train_loss_epoch=0.0108]Epoch 358: Train Loss = 0.011620583944022655\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0116]Epoch 359: Train Loss = 0.010904580354690552\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0109]Epoch 360: Train Loss = 0.010787657462060452\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=340, train_loss_step=0.0102, train_loss_epoch=0.0108]Epoch 361: Train Loss = 0.010222658514976501\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=340, train_loss_step=0.0114, train_loss_epoch=0.0102]Epoch 362: Train Loss = 0.011412562802433968\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=340, train_loss_step=0.0145, train_loss_epoch=0.0114]Epoch 363: Train Loss = 0.014527807012200356\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=340, train_loss_step=0.0106, train_loss_epoch=0.0145]Epoch 364: Train Loss = 0.010609187185764313\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=340, train_loss_step=0.0135, train_loss_epoch=0.0106]Epoch 365: Train Loss = 0.013532564975321293\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0135]Epoch 366: Train Loss = 0.010781851597130299\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0108]Epoch 367: Train Loss = 0.011683791875839233\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=340, train_loss_step=0.0137, train_loss_epoch=0.0117]Epoch 368: Train Loss = 0.013718702830374241\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=340, train_loss_step=0.0126, train_loss_epoch=0.0137]Epoch 369: Train Loss = 0.012554970569908619\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=340, train_loss_step=0.0114, train_loss_epoch=0.0126]Epoch 370: Train Loss = 0.011424754746258259\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0114]Epoch 371: Train Loss = 0.011664514429867268\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0117]Epoch 372: Train Loss = 0.011158464476466179\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=340, train_loss_step=0.0115, train_loss_epoch=0.0112]Epoch 373: Train Loss = 0.011469729244709015\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=340, train_loss_step=0.0101, train_loss_epoch=0.0115]Epoch 374: Train Loss = 0.010149970650672913\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=340, train_loss_step=0.0102, train_loss_epoch=0.0101]Epoch 375: Train Loss = 0.010160097852349281\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=340, train_loss_step=0.0133, train_loss_epoch=0.0102]Epoch 376: Train Loss = 0.01325831189751625\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=340, train_loss_step=0.0172, train_loss_epoch=0.0133]Epoch 377: Train Loss = 0.01716209575533867\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.0172]Epoch 378: Train Loss = 0.011315480805933475\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=340, train_loss_step=0.0126, train_loss_epoch=0.0113]Epoch 379: Train Loss = 0.012608041986823082\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0126]Epoch 380: Train Loss = 0.011865922249853611\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0119]Epoch 381: Train Loss = 0.011684305034577847\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=340, train_loss_step=0.015, train_loss_epoch=0.0117] Epoch 382: Train Loss = 0.014982106164097786\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.015]Epoch 383: Train Loss = 0.011262143962085247\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=340, train_loss_step=0.0139, train_loss_epoch=0.0113]Epoch 384: Train Loss = 0.013921584002673626\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0139]Epoch 385: Train Loss = 0.011866196058690548\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.0119]Epoch 386: Train Loss = 0.012716072611510754\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=340, train_loss_step=0.0147, train_loss_epoch=0.0127]Epoch 387: Train Loss = 0.014737325720489025\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.0147]Epoch 388: Train Loss = 0.01267410907894373\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=340, train_loss_step=0.0121, train_loss_epoch=0.0127]Epoch 389: Train Loss = 0.012140600942075253\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=340, train_loss_step=0.0116, train_loss_epoch=0.0121]Epoch 390: Train Loss = 0.011605008505284786\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=340, train_loss_step=0.0125, train_loss_epoch=0.0116]Epoch 391: Train Loss = 0.0124570457264781\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.0125] Epoch 392: Train Loss = 0.013967303559184074\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.014]Epoch 393: Train Loss = 0.011306575499475002\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=340, train_loss_step=0.0148, train_loss_epoch=0.0113]Epoch 394: Train Loss = 0.01478663645684719\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=340, train_loss_step=0.00979, train_loss_epoch=0.0148]Epoch 395: Train Loss = 0.00979283731430769\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=340, train_loss_step=0.013, train_loss_epoch=0.00979]  Epoch 396: Train Loss = 0.012992453761398792\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.013] Epoch 397: Train Loss = 0.011155019514262676\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=340, train_loss_step=0.00986, train_loss_epoch=0.0112]Epoch 398: Train Loss = 0.009861101396381855\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=340, train_loss_step=0.0129, train_loss_epoch=0.00986] Epoch 399: Train Loss = 0.012914114631712437\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0129] Epoch 400: Train Loss = 0.011947346851229668\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=340, train_loss_step=0.0118, train_loss_epoch=0.0119]Epoch 401: Train Loss = 0.011760374531149864\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=340, train_loss_step=0.0107, train_loss_epoch=0.0118]Epoch 402: Train Loss = 0.010685727931559086\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=340, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 403: Train Loss = 0.011554315686225891\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.0116]Epoch 404: Train Loss = 0.011328665539622307\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=340, train_loss_step=0.0172, train_loss_epoch=0.0113]Epoch 405: Train Loss = 0.017179695889353752\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=340, train_loss_step=0.016, train_loss_epoch=0.0172] Epoch 406: Train Loss = 0.015960244461894035\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=340, train_loss_step=0.0118, train_loss_epoch=0.016]Epoch 407: Train Loss = 0.011808197014033794\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=340, train_loss_step=0.011, train_loss_epoch=0.0118] Epoch 408: Train Loss = 0.011006704531610012\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s, v_num=340, train_loss_step=0.0146, train_loss_epoch=0.011]Epoch 409: Train Loss = 0.014551972970366478\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=340, train_loss_step=0.0126, train_loss_epoch=0.0146]Epoch 410: Train Loss = 0.012637353502213955\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=340, train_loss_step=0.0126, train_loss_epoch=0.0126]Epoch 411: Train Loss = 0.012599052861332893\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=340, train_loss_step=0.0116, train_loss_epoch=0.0126]Epoch 412: Train Loss = 0.011550969444215298\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=340, train_loss_step=0.0147, train_loss_epoch=0.0116]Epoch 413: Train Loss = 0.014710317365825176\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=340, train_loss_step=0.0123, train_loss_epoch=0.0147]Epoch 414: Train Loss = 0.012311646714806557\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=340, train_loss_step=0.0116, train_loss_epoch=0.0123]Epoch 415: Train Loss = 0.011623154394328594\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=340, train_loss_step=0.0129, train_loss_epoch=0.0116]Epoch 416: Train Loss = 0.012937268242239952\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=340, train_loss_step=0.0133, train_loss_epoch=0.0129]Epoch 417: Train Loss = 0.01326859649270773\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.0133]Epoch 418: Train Loss = 0.011316092684864998\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=340, train_loss_step=0.0105, train_loss_epoch=0.0113]Epoch 419: Train Loss = 0.010502577759325504\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.0105]Epoch 420: Train Loss = 0.01129495445638895\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=340, train_loss_step=0.013, train_loss_epoch=0.0113] Epoch 421: Train Loss = 0.012974178418517113\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.013]Epoch 422: Train Loss = 0.011221463792026043\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=340, train_loss_step=0.0115, train_loss_epoch=0.0112]Epoch 423: Train Loss = 0.011500836350023746\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0115]Epoch 424: Train Loss = 0.01080638449639082\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=340, train_loss_step=0.00964, train_loss_epoch=0.0108]Epoch 425: Train Loss = 0.00964201707392931\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=340, train_loss_step=0.0147, train_loss_epoch=0.00964] Epoch 426: Train Loss = 0.014692381955683231\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=340, train_loss_step=0.0111, train_loss_epoch=0.0147] Epoch 427: Train Loss = 0.011100776493549347\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=340, train_loss_step=0.010, train_loss_epoch=0.0111] Epoch 428: Train Loss = 0.010030088014900684\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.010]Epoch 429: Train Loss = 0.012724170461297035\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=340, train_loss_step=0.0122, train_loss_epoch=0.0127]Epoch 430: Train Loss = 0.012175188399851322\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=340, train_loss_step=0.0123, train_loss_epoch=0.0122]Epoch 431: Train Loss = 0.012348382733762264\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=340, train_loss_step=0.0125, train_loss_epoch=0.0123]Epoch 432: Train Loss = 0.012453501112759113\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0125]Epoch 433: Train Loss = 0.01117970235645771\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  9.60it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.0112]Epoch 434: Train Loss = 0.011325606144964695\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=340, train_loss_step=0.0103, train_loss_epoch=0.0113]Epoch 435: Train Loss = 0.010274340398609638\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=340, train_loss_step=0.0134, train_loss_epoch=0.0103]Epoch 436: Train Loss = 0.013441112823784351\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0134]Epoch 437: Train Loss = 0.010919297114014626\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=340, train_loss_step=0.0095, train_loss_epoch=0.0109]Epoch 438: Train Loss = 0.009499900974333286\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=340, train_loss_step=0.0121, train_loss_epoch=0.0095]Epoch 439: Train Loss = 0.012146465480327606\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=340, train_loss_step=0.00935, train_loss_epoch=0.0121]Epoch 440: Train Loss = 0.009352785535156727\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=340, train_loss_step=0.0205, train_loss_epoch=0.00935] Epoch 441: Train Loss = 0.020544851198792458\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0205] Epoch 442: Train Loss = 0.010851887054741383\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=340, train_loss_step=0.0127, train_loss_epoch=0.0109]Epoch 443: Train Loss = 0.01273512002080679\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 444: Train Loss = 0.011980638839304447\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=340, train_loss_step=0.0171, train_loss_epoch=0.012]Epoch 445: Train Loss = 0.01709674671292305\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s, v_num=340, train_loss_step=0.0152, train_loss_epoch=0.0171]Epoch 446: Train Loss = 0.015201563946902752\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=340, train_loss_step=0.0154, train_loss_epoch=0.0152]Epoch 447: Train Loss = 0.01541911717504263\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0154]Epoch 448: Train Loss = 0.011865586042404175\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=340, train_loss_step=0.0125, train_loss_epoch=0.0119]Epoch 449: Train Loss = 0.01254038605839014\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=340, train_loss_step=0.013, train_loss_epoch=0.0125] Epoch 450: Train Loss = 0.012979538179934025\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=340, train_loss_step=0.0118, train_loss_epoch=0.013]Epoch 451: Train Loss = 0.011792117729783058\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.0118] Epoch 452: Train Loss = 0.01196201704442501\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=340, train_loss_step=0.0101, train_loss_epoch=0.012]Epoch 453: Train Loss = 0.010127142071723938\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=340, train_loss_step=0.0137, train_loss_epoch=0.0101]Epoch 454: Train Loss = 0.013698374852538109\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=340, train_loss_step=0.010, train_loss_epoch=0.0137] Epoch 455: Train Loss = 0.01001519151031971\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=340, train_loss_step=0.0121, train_loss_epoch=0.010]Epoch 456: Train Loss = 0.012084982357919216\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=340, train_loss_step=0.0107, train_loss_epoch=0.0121]Epoch 457: Train Loss = 0.010701888240873814\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0107]Epoch 458: Train Loss = 0.011203263886272907\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=340, train_loss_step=0.00907, train_loss_epoch=0.0112]Epoch 459: Train Loss = 0.009074830450117588\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=340, train_loss_step=0.00986, train_loss_epoch=0.00907]Epoch 460: Train Loss = 0.009861854836344719\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=340, train_loss_step=0.0114, train_loss_epoch=0.00986] Epoch 461: Train Loss = 0.01135477889329195\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0114] Epoch 462: Train Loss = 0.01167604885995388\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=340, train_loss_step=0.0153, train_loss_epoch=0.0117]Epoch 463: Train Loss = 0.015345619060099125\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=340, train_loss_step=0.0106, train_loss_epoch=0.0153]Epoch 464: Train Loss = 0.010612004436552525\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=340, train_loss_step=0.0114, train_loss_epoch=0.0106]Epoch 465: Train Loss = 0.011417203582823277\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=340, train_loss_step=0.0117, train_loss_epoch=0.0114]Epoch 466: Train Loss = 0.011728910729289055\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=340, train_loss_step=0.0136, train_loss_epoch=0.0117]Epoch 467: Train Loss = 0.013641628436744213\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 11.12it/s, v_num=340, train_loss_step=0.0103, train_loss_epoch=0.0136]Epoch 468: Train Loss = 0.01033315621316433\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=340, train_loss_step=0.0106, train_loss_epoch=0.0103]Epoch 469: Train Loss = 0.010596437379717827\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=340, train_loss_step=0.0105, train_loss_epoch=0.0106]Epoch 470: Train Loss = 0.010476781986653805\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=340, train_loss_step=0.0102, train_loss_epoch=0.0105]Epoch 471: Train Loss = 0.010216906666755676\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=340, train_loss_step=0.0118, train_loss_epoch=0.0102]Epoch 472: Train Loss = 0.011785405687987804\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=340, train_loss_step=0.0155, train_loss_epoch=0.0118]Epoch 473: Train Loss = 0.015519930981099606\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s, v_num=340, train_loss_step=0.0135, train_loss_epoch=0.0155]Epoch 474: Train Loss = 0.013509145937860012\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=340, train_loss_step=0.0115, train_loss_epoch=0.0135]Epoch 475: Train Loss = 0.011545858345925808\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=340, train_loss_step=0.0105, train_loss_epoch=0.0115]Epoch 476: Train Loss = 0.010509167797863483\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=340, train_loss_step=0.0112, train_loss_epoch=0.0105]Epoch 477: Train Loss = 0.011175530962646008\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=340, train_loss_step=0.0133, train_loss_epoch=0.0112]Epoch 478: Train Loss = 0.013264753855764866\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=340, train_loss_step=0.0122, train_loss_epoch=0.0133]Epoch 479: Train Loss = 0.012193622067570686\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=340, train_loss_step=0.0167, train_loss_epoch=0.0122]Epoch 480: Train Loss = 0.01669161207973957\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0167]Epoch 481: Train Loss = 0.010903350077569485\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=340, train_loss_step=0.0114, train_loss_epoch=0.0109]Epoch 482: Train Loss = 0.01144860778003931\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=340, train_loss_step=0.0132, train_loss_epoch=0.0114]Epoch 483: Train Loss = 0.013176790438592434\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=340, train_loss_step=0.0121, train_loss_epoch=0.0132]Epoch 484: Train Loss = 0.012130252085626125\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=340, train_loss_step=0.014, train_loss_epoch=0.0121] Epoch 485: Train Loss = 0.014001263305544853\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=340, train_loss_step=0.0146, train_loss_epoch=0.014]Epoch 486: Train Loss = 0.014619211666285992\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=340, train_loss_step=0.0111, train_loss_epoch=0.0146]Epoch 487: Train Loss = 0.011099457740783691\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=340, train_loss_step=0.0136, train_loss_epoch=0.0111]Epoch 488: Train Loss = 0.013635958544909954\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=340, train_loss_step=0.0108, train_loss_epoch=0.0136]Epoch 489: Train Loss = 0.010766501538455486\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=340, train_loss_step=0.011, train_loss_epoch=0.0108] Epoch 490: Train Loss = 0.011014727875590324\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=340, train_loss_step=0.0114, train_loss_epoch=0.011]Epoch 491: Train Loss = 0.011442487128078938\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=340, train_loss_step=0.0128, train_loss_epoch=0.0114]Epoch 492: Train Loss = 0.012765035964548588\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=340, train_loss_step=0.0109, train_loss_epoch=0.0128]Epoch 493: Train Loss = 0.01087981928139925\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.0109] Epoch 494: Train Loss = 0.012011880055069923\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=340, train_loss_step=0.0101, train_loss_epoch=0.012]Epoch 495: Train Loss = 0.01011571753770113\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=340, train_loss_step=0.0124, train_loss_epoch=0.0101]Epoch 496: Train Loss = 0.012352707795798779\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=340, train_loss_step=0.012, train_loss_epoch=0.0124] Epoch 497: Train Loss = 0.011966397054493427\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=340, train_loss_step=0.0113, train_loss_epoch=0.012]Epoch 498: Train Loss = 0.011310587637126446\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0113]Epoch 499: Train Loss = 0.011857985518872738\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0119]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=340, train_loss_step=0.0119, train_loss_epoch=0.0119]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 15: from 2010-06-30 00:00:00 to 2022-11-15 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=344, train_loss_step=0.0276]Epoch 0: Train Loss = 0.027626262977719307\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=344, train_loss_step=0.0512, train_loss_epoch=0.0276]Epoch 1: Train Loss = 0.051178332418203354\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=344, train_loss_step=0.0285, train_loss_epoch=0.0512]Epoch 2: Train Loss = 0.028479306027293205\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=344, train_loss_step=0.0234, train_loss_epoch=0.0285]Epoch 3: Train Loss = 0.023408448323607445\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=344, train_loss_step=0.0322, train_loss_epoch=0.0234]Epoch 4: Train Loss = 0.03220774605870247\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=344, train_loss_step=0.0253, train_loss_epoch=0.0322]Epoch 5: Train Loss = 0.025340722873806953\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=344, train_loss_step=0.0193, train_loss_epoch=0.0253]Epoch 6: Train Loss = 0.019260311499238014\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=344, train_loss_step=0.0204, train_loss_epoch=0.0193]Epoch 7: Train Loss = 0.02038124017417431\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=344, train_loss_step=0.0191, train_loss_epoch=0.0204]Epoch 8: Train Loss = 0.019128745421767235\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=344, train_loss_step=0.0193, train_loss_epoch=0.0191]Epoch 9: Train Loss = 0.019272426143288612\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=344, train_loss_step=0.0189, train_loss_epoch=0.0193]Epoch 10: Train Loss = 0.018905920907855034\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=344, train_loss_step=0.020, train_loss_epoch=0.0189] Epoch 11: Train Loss = 0.020033380016684532\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=344, train_loss_step=0.0183, train_loss_epoch=0.020]Epoch 12: Train Loss = 0.018344823271036148\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=344, train_loss_step=0.0189, train_loss_epoch=0.0183]Epoch 13: Train Loss = 0.01890179142355919\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=344, train_loss_step=0.0159, train_loss_epoch=0.0189]Epoch 14: Train Loss = 0.01589846983551979\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=344, train_loss_step=0.0215, train_loss_epoch=0.0159]Epoch 15: Train Loss = 0.021472608670592308\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=344, train_loss_step=0.0167, train_loss_epoch=0.0215]Epoch 16: Train Loss = 0.016720887273550034\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s, v_num=344, train_loss_step=0.0117, train_loss_epoch=0.0167]Epoch 17: Train Loss = 0.011680235154926777\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s, v_num=344, train_loss_step=0.0233, train_loss_epoch=0.0117]Epoch 18: Train Loss = 0.02333967201411724\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=344, train_loss_step=0.0172, train_loss_epoch=0.0233]Epoch 19: Train Loss = 0.017226440832018852\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=344, train_loss_step=0.0143, train_loss_epoch=0.0172]Epoch 20: Train Loss = 0.014338151551783085\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=344, train_loss_step=0.0154, train_loss_epoch=0.0143]Epoch 21: Train Loss = 0.015383722260594368\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=344, train_loss_step=0.0144, train_loss_epoch=0.0154]Epoch 22: Train Loss = 0.014391434378921986\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=344, train_loss_step=0.0208, train_loss_epoch=0.0144]Epoch 23: Train Loss = 0.020755231380462646\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=344, train_loss_step=0.0128, train_loss_epoch=0.0208]Epoch 24: Train Loss = 0.012766663916409016\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 11.28it/s, v_num=344, train_loss_step=0.0181, train_loss_epoch=0.0128]Epoch 25: Train Loss = 0.01814098097383976\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=344, train_loss_step=0.0121, train_loss_epoch=0.0181]Epoch 26: Train Loss = 0.012101498432457447\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=344, train_loss_step=0.0142, train_loss_epoch=0.0121]Epoch 27: Train Loss = 0.014229708351194859\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=344, train_loss_step=0.0223, train_loss_epoch=0.0142]Epoch 28: Train Loss = 0.022283388301730156\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=344, train_loss_step=0.0122, train_loss_epoch=0.0223]Epoch 29: Train Loss = 0.012228906154632568\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=344, train_loss_step=0.0152, train_loss_epoch=0.0122]Epoch 30: Train Loss = 0.015204687602818012\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=344, train_loss_step=0.0151, train_loss_epoch=0.0152]Epoch 31: Train Loss = 0.015080650337040424\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.0151] Epoch 32: Train Loss = 0.012978990562260151\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=344, train_loss_step=0.0137, train_loss_epoch=0.013]Epoch 33: Train Loss = 0.013744867406785488\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=344, train_loss_step=0.0135, train_loss_epoch=0.0137]Epoch 34: Train Loss = 0.013483128510415554\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=344, train_loss_step=0.0164, train_loss_epoch=0.0135]Epoch 35: Train Loss = 0.0163727980107069\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0164]Epoch 36: Train Loss = 0.012441838160157204\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=344, train_loss_step=0.0147, train_loss_epoch=0.0124]Epoch 37: Train Loss = 0.014743941836059093\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0147]Epoch 38: Train Loss = 0.013786797411739826\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=344, train_loss_step=0.0119, train_loss_epoch=0.0138]Epoch 39: Train Loss = 0.011850505135953426\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=344, train_loss_step=0.0153, train_loss_epoch=0.0119]Epoch 40: Train Loss = 0.015294782817363739\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=344, train_loss_step=0.0136, train_loss_epoch=0.0153]Epoch 41: Train Loss = 0.013569483533501625\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0136]Epoch 42: Train Loss = 0.013825115747749805\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=344, train_loss_step=0.0145, train_loss_epoch=0.0138]Epoch 43: Train Loss = 0.014483721926808357\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=344, train_loss_step=0.0175, train_loss_epoch=0.0145]Epoch 44: Train Loss = 0.017460396513342857\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=344, train_loss_step=0.0195, train_loss_epoch=0.0175]Epoch 45: Train Loss = 0.019492199644446373\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=344, train_loss_step=0.0155, train_loss_epoch=0.0195]Epoch 46: Train Loss = 0.015546089969575405\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=344, train_loss_step=0.0113, train_loss_epoch=0.0155]Epoch 47: Train Loss = 0.011284945532679558\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=344, train_loss_step=0.0108, train_loss_epoch=0.0113]Epoch 48: Train Loss = 0.010806150734424591\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=344, train_loss_step=0.012, train_loss_epoch=0.0108] Epoch 49: Train Loss = 0.011953944340348244\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=344, train_loss_step=0.0111, train_loss_epoch=0.012]Epoch 50: Train Loss = 0.01114354282617569\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=344, train_loss_step=0.0146, train_loss_epoch=0.0111]Epoch 51: Train Loss = 0.014636605978012085\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=344, train_loss_step=0.0148, train_loss_epoch=0.0146]Epoch 52: Train Loss = 0.014802008867263794\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0148]Epoch 53: Train Loss = 0.012380173429846764\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=344, train_loss_step=0.0154, train_loss_epoch=0.0124]Epoch 54: Train Loss = 0.015408135019242764\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=344, train_loss_step=0.0131, train_loss_epoch=0.0154]Epoch 55: Train Loss = 0.013132021762430668\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s, v_num=344, train_loss_step=0.0161, train_loss_epoch=0.0131]Epoch 56: Train Loss = 0.01611240766942501\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0161]Epoch 57: Train Loss = 0.0124210175126791\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=344, train_loss_step=0.0143, train_loss_epoch=0.0124]Epoch 58: Train Loss = 0.014348096214234829\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=344, train_loss_step=0.0132, train_loss_epoch=0.0143]Epoch 59: Train Loss = 0.01323558110743761\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=344, train_loss_step=0.0154, train_loss_epoch=0.0132]Epoch 60: Train Loss = 0.015378205105662346\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=344, train_loss_step=0.0133, train_loss_epoch=0.0154]Epoch 61: Train Loss = 0.013292642310261726\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=344, train_loss_step=0.00994, train_loss_epoch=0.0133]Epoch 62: Train Loss = 0.00994200725108385\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=344, train_loss_step=0.0135, train_loss_epoch=0.00994] Epoch 63: Train Loss = 0.013461658731102943\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=344, train_loss_step=0.0172, train_loss_epoch=0.0135] Epoch 64: Train Loss = 0.017186714336276054\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=344, train_loss_step=0.0162, train_loss_epoch=0.0172]Epoch 65: Train Loss = 0.01622755266726017\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=344, train_loss_step=0.00939, train_loss_epoch=0.0162]Epoch 66: Train Loss = 0.009389885701239109\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.00939] Epoch 67: Train Loss = 0.012371839955449104\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=344, train_loss_step=0.0159, train_loss_epoch=0.0124] Epoch 68: Train Loss = 0.015853481367230415\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=344, train_loss_step=0.0143, train_loss_epoch=0.0159]Epoch 69: Train Loss = 0.01431071013212204\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=344, train_loss_step=0.00978, train_loss_epoch=0.0143]Epoch 70: Train Loss = 0.009779355488717556\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=344, train_loss_step=0.0165, train_loss_epoch=0.00978] Epoch 71: Train Loss = 0.016524117439985275\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=344, train_loss_step=0.0115, train_loss_epoch=0.0165] Epoch 72: Train Loss = 0.011474681086838245\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0115]Epoch 73: Train Loss = 0.012711002491414547\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=344, train_loss_step=0.0133, train_loss_epoch=0.0127]Epoch 74: Train Loss = 0.01328162383288145\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=344, train_loss_step=0.0114, train_loss_epoch=0.0133]Epoch 75: Train Loss = 0.011429592035710812\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s, v_num=344, train_loss_step=0.0184, train_loss_epoch=0.0114]Epoch 76: Train Loss = 0.018353084102272987\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.0184] Epoch 77: Train Loss = 0.01097005046904087\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=344, train_loss_step=0.0194, train_loss_epoch=0.011]Epoch 78: Train Loss = 0.019434837624430656\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.0194]Epoch 79: Train Loss = 0.013363897800445557\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=344, train_loss_step=0.0104, train_loss_epoch=0.0134]Epoch 80: Train Loss = 0.010396399535238743\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0104]Epoch 81: Train Loss = 0.012374033220112324\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=344, train_loss_step=0.0119, train_loss_epoch=0.0124]Epoch 82: Train Loss = 0.011930312030017376\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=344, train_loss_step=0.0168, train_loss_epoch=0.0119]Epoch 83: Train Loss = 0.016778675839304924\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=344, train_loss_step=0.0129, train_loss_epoch=0.0168]Epoch 84: Train Loss = 0.012909661047160625\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=344, train_loss_step=0.0103, train_loss_epoch=0.0129]Epoch 85: Train Loss = 0.010314431972801685\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=344, train_loss_step=0.0114, train_loss_epoch=0.0103]Epoch 86: Train Loss = 0.011376338079571724\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=344, train_loss_step=0.0141, train_loss_epoch=0.0114]Epoch 87: Train Loss = 0.014141061343252659\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=344, train_loss_step=0.00978, train_loss_epoch=0.0141]Epoch 88: Train Loss = 0.009781702421605587\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.00978]  Epoch 89: Train Loss = 0.010987886227667332\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.011]  Epoch 90: Train Loss = 0.01299923937767744\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, v_num=344, train_loss_step=0.0155, train_loss_epoch=0.013]Epoch 91: Train Loss = 0.015490224584937096\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=344, train_loss_step=0.0131, train_loss_epoch=0.0155]Epoch 92: Train Loss = 0.013099133037030697\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 10.30it/s, v_num=344, train_loss_step=0.012, train_loss_epoch=0.0131] Epoch 93: Train Loss = 0.012038636021316051\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=344, train_loss_step=0.0123, train_loss_epoch=0.012]Epoch 94: Train Loss = 0.012289771810173988\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0123]Epoch 95: Train Loss = 0.012437671422958374\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=344, train_loss_step=0.0121, train_loss_epoch=0.0124]Epoch 96: Train Loss = 0.012145882472395897\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0121]Epoch 97: Train Loss = 0.013801364228129387\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=344, train_loss_step=0.014, train_loss_epoch=0.0138] Epoch 98: Train Loss = 0.013988650403916836\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=344, train_loss_step=0.0141, train_loss_epoch=0.014]Epoch 99: Train Loss = 0.014125490561127663\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s, v_num=344, train_loss_step=0.0122, train_loss_epoch=0.0141]Epoch 100: Train Loss = 0.012216330505907536\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=344, train_loss_step=0.0144, train_loss_epoch=0.0122]Epoch 101: Train Loss = 0.014413378201425076\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0144]Epoch 102: Train Loss = 0.01156727783381939\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=344, train_loss_step=0.0104, train_loss_epoch=0.0116]Epoch 103: Train Loss = 0.010398226790130138\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.0104]Epoch 104: Train Loss = 0.012643711641430855\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.0126]Epoch 105: Train Loss = 0.012568513862788677\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=344, train_loss_step=0.0163, train_loss_epoch=0.0126]Epoch 106: Train Loss = 0.01625968888401985\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=344, train_loss_step=0.0147, train_loss_epoch=0.0163]Epoch 107: Train Loss = 0.01474228035658598\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=344, train_loss_step=0.0119, train_loss_epoch=0.0147]Epoch 108: Train Loss = 0.011945136822760105\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0119]Epoch 109: Train Loss = 0.012676711194217205\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=344, train_loss_step=0.0148, train_loss_epoch=0.0127]Epoch 110: Train Loss = 0.014803255908191204\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=344, train_loss_step=0.0152, train_loss_epoch=0.0148]Epoch 111: Train Loss = 0.01517955120652914\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=344, train_loss_step=0.0151, train_loss_epoch=0.0152]Epoch 112: Train Loss = 0.015053118579089642\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=344, train_loss_step=0.0109, train_loss_epoch=0.0151]Epoch 113: Train Loss = 0.01087568886578083\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s, v_num=344, train_loss_step=0.014, train_loss_epoch=0.0109] Epoch 114: Train Loss = 0.0140385115519166\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=344, train_loss_step=0.0137, train_loss_epoch=0.014]Epoch 115: Train Loss = 0.0136683639138937\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=344, train_loss_step=0.0129, train_loss_epoch=0.0137]Epoch 116: Train Loss = 0.012875416316092014\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=344, train_loss_step=0.012, train_loss_epoch=0.0129] Epoch 117: Train Loss = 0.012008353136479855\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.012]Epoch 118: Train Loss = 0.013836337253451347\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=344, train_loss_step=0.0206, train_loss_epoch=0.0138]Epoch 119: Train Loss = 0.02059217169880867\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=344, train_loss_step=0.0159, train_loss_epoch=0.0206]Epoch 120: Train Loss = 0.015916986390948296\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=344, train_loss_step=0.0151, train_loss_epoch=0.0159]Epoch 121: Train Loss = 0.015115910209715366\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=344, train_loss_step=0.0115, train_loss_epoch=0.0151]Epoch 122: Train Loss = 0.011473679915070534\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=344, train_loss_step=0.0117, train_loss_epoch=0.0115]Epoch 123: Train Loss = 0.01165205892175436\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=344, train_loss_step=0.0143, train_loss_epoch=0.0117]Epoch 124: Train Loss = 0.014342720620334148\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=344, train_loss_step=0.0144, train_loss_epoch=0.0143]Epoch 125: Train Loss = 0.014353913255035877\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0144]Epoch 126: Train Loss = 0.012416452169418335\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=344, train_loss_step=0.0137, train_loss_epoch=0.0124]Epoch 127: Train Loss = 0.013697492890059948\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.0137]Epoch 128: Train Loss = 0.013447834178805351\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=344, train_loss_step=0.0174, train_loss_epoch=0.0134]Epoch 129: Train Loss = 0.0173835176974535\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=344, train_loss_step=0.0122, train_loss_epoch=0.0174]Epoch 130: Train Loss = 0.012212427332997322\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=344, train_loss_step=0.0135, train_loss_epoch=0.0122]Epoch 131: Train Loss = 0.013544229790568352\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s, v_num=344, train_loss_step=0.0149, train_loss_epoch=0.0135]Epoch 132: Train Loss = 0.014886749908328056\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0149]Epoch 133: Train Loss = 0.012402470223605633\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=344, train_loss_step=0.0184, train_loss_epoch=0.0124]Epoch 134: Train Loss = 0.018366219475865364\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=344, train_loss_step=0.0181, train_loss_epoch=0.0184]Epoch 135: Train Loss = 0.0181388258934021\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0181]Epoch 136: Train Loss = 0.011620990000665188\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=344, train_loss_step=0.0118, train_loss_epoch=0.0116]Epoch 137: Train Loss = 0.011826078407466412\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=344, train_loss_step=0.0173, train_loss_epoch=0.0118]Epoch 138: Train Loss = 0.017312664538621902\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=344, train_loss_step=0.016, train_loss_epoch=0.0173] Epoch 139: Train Loss = 0.016024280339479446\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=344, train_loss_step=0.0117, train_loss_epoch=0.016]Epoch 140: Train Loss = 0.011747254990041256\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=344, train_loss_step=0.0177, train_loss_epoch=0.0117]Epoch 141: Train Loss = 0.017666246742010117\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=344, train_loss_step=0.0131, train_loss_epoch=0.0177]Epoch 142: Train Loss = 0.013125383295118809\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=344, train_loss_step=0.0155, train_loss_epoch=0.0131]Epoch 143: Train Loss = 0.01553143747150898\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=344, train_loss_step=0.0135, train_loss_epoch=0.0155]Epoch 144: Train Loss = 0.013531242497265339\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=344, train_loss_step=0.0113, train_loss_epoch=0.0135]Epoch 145: Train Loss = 0.011280589736998081\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0113]Epoch 146: Train Loss = 0.011585758998990059\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=344, train_loss_step=0.0157, train_loss_epoch=0.0116]Epoch 147: Train Loss = 0.015748918056488037\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0157]Epoch 148: Train Loss = 0.012406821362674236\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=344, train_loss_step=0.0143, train_loss_epoch=0.0124]Epoch 149: Train Loss = 0.014270669780671597\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 12.33it/s, v_num=344, train_loss_step=0.0109, train_loss_epoch=0.0143]Epoch 150: Train Loss = 0.010904288850724697\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 12.39it/s, v_num=344, train_loss_step=0.012, train_loss_epoch=0.0109] Epoch 151: Train Loss = 0.012034227140247822\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=344, train_loss_step=0.0123, train_loss_epoch=0.012]Epoch 152: Train Loss = 0.012349933385848999\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 13.49it/s, v_num=344, train_loss_step=0.0147, train_loss_epoch=0.0123]Epoch 153: Train Loss = 0.014711691997945309\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=344, train_loss_step=0.0109, train_loss_epoch=0.0147]Epoch 154: Train Loss = 0.010937902145087719\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=344, train_loss_step=0.0115, train_loss_epoch=0.0109]Epoch 155: Train Loss = 0.011475006118416786\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.0115]Epoch 156: Train Loss = 0.012630684301257133\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=344, train_loss_step=0.0111, train_loss_epoch=0.0126]Epoch 157: Train Loss = 0.011075294576585293\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=344, train_loss_step=0.0169, train_loss_epoch=0.0111]Epoch 158: Train Loss = 0.016850542277097702\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0169]Epoch 159: Train Loss = 0.013831050135195255\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=344, train_loss_step=0.0119, train_loss_epoch=0.0138]Epoch 160: Train Loss = 0.011880798265337944\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.0119]Epoch 161: Train Loss = 0.013363311067223549\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=344, train_loss_step=0.016, train_loss_epoch=0.0134] Epoch 162: Train Loss = 0.015972858294844627\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=344, train_loss_step=0.0151, train_loss_epoch=0.016]Epoch 163: Train Loss = 0.015131642110645771\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=344, train_loss_step=0.0157, train_loss_epoch=0.0151]Epoch 164: Train Loss = 0.015745120123028755\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=344, train_loss_step=0.0157, train_loss_epoch=0.0157]Epoch 165: Train Loss = 0.015713032335042953\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=344, train_loss_step=0.0179, train_loss_epoch=0.0157]Epoch 166: Train Loss = 0.01794970966875553\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=344, train_loss_step=0.0174, train_loss_epoch=0.0179]Epoch 167: Train Loss = 0.017420800402760506\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0174]Epoch 168: Train Loss = 0.012446129694581032\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=344, train_loss_step=0.0141, train_loss_epoch=0.0124]Epoch 169: Train Loss = 0.014141141436994076\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=344, train_loss_step=0.0115, train_loss_epoch=0.0141]Epoch 170: Train Loss = 0.01148475706577301\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0115]Epoch 171: Train Loss = 0.013780188746750355\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=344, train_loss_step=0.0108, train_loss_epoch=0.0138]Epoch 172: Train Loss = 0.010761338286101818\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=344, train_loss_step=0.0117, train_loss_epoch=0.0108]Epoch 173: Train Loss = 0.011701189912855625\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=344, train_loss_step=0.0152, train_loss_epoch=0.0117]Epoch 174: Train Loss = 0.015244253911077976\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=344, train_loss_step=0.0167, train_loss_epoch=0.0152]Epoch 175: Train Loss = 0.016689468175172806\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=344, train_loss_step=0.0122, train_loss_epoch=0.0167]Epoch 176: Train Loss = 0.012153261341154575\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=344, train_loss_step=0.0136, train_loss_epoch=0.0122]Epoch 177: Train Loss = 0.013564622960984707\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=344, train_loss_step=0.0174, train_loss_epoch=0.0136]Epoch 178: Train Loss = 0.017409218475222588\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=344, train_loss_step=0.0195, train_loss_epoch=0.0174]Epoch 179: Train Loss = 0.019540855661034584\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=344, train_loss_step=0.0173, train_loss_epoch=0.0195]Epoch 180: Train Loss = 0.01725975051522255\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.0173] Epoch 181: Train Loss = 0.013015707954764366\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.013]Epoch 182: Train Loss = 0.01336634811013937\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=344, train_loss_step=0.00952, train_loss_epoch=0.0134]Epoch 183: Train Loss = 0.009523828513920307\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.00952]  Epoch 184: Train Loss = 0.012962393462657928\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=344, train_loss_step=0.023, train_loss_epoch=0.013]  Epoch 185: Train Loss = 0.022970708087086678\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.023]Epoch 186: Train Loss = 0.012446345761418343\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s, v_num=344, train_loss_step=0.0166, train_loss_epoch=0.0124]Epoch 187: Train Loss = 0.016625357791781425\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=344, train_loss_step=0.0114, train_loss_epoch=0.0166]Epoch 188: Train Loss = 0.011392489075660706\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=344, train_loss_step=0.0143, train_loss_epoch=0.0114]Epoch 189: Train Loss = 0.014328675344586372\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=344, train_loss_step=0.0119, train_loss_epoch=0.0143]Epoch 190: Train Loss = 0.01187414862215519\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.0119] Epoch 191: Train Loss = 0.01299750804901123\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.013]Epoch 192: Train Loss = 0.012596706859767437\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=344, train_loss_step=0.021, train_loss_epoch=0.0126] Epoch 193: Train Loss = 0.020958414301276207\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=344, train_loss_step=0.0144, train_loss_epoch=0.021]Epoch 194: Train Loss = 0.014446410350501537\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=344, train_loss_step=0.0121, train_loss_epoch=0.0144]Epoch 195: Train Loss = 0.012063608504831791\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.0121]Epoch 196: Train Loss = 0.013371082954108715\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=344, train_loss_step=0.016, train_loss_epoch=0.0134] Epoch 197: Train Loss = 0.016049515455961227\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=344, train_loss_step=0.0146, train_loss_epoch=0.016]Epoch 198: Train Loss = 0.014594229869544506\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=344, train_loss_step=0.0172, train_loss_epoch=0.0146]Epoch 199: Train Loss = 0.01716349646449089\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=344, train_loss_step=0.0111, train_loss_epoch=0.0172]Epoch 200: Train Loss = 0.011101515963673592\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=344, train_loss_step=0.0121, train_loss_epoch=0.0111]Epoch 201: Train Loss = 0.012096713297069073\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0121]Epoch 202: Train Loss = 0.011583910323679447\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=344, train_loss_step=0.0101, train_loss_epoch=0.0116]Epoch 203: Train Loss = 0.010123341344296932\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=344, train_loss_step=0.0105, train_loss_epoch=0.0101]Epoch 204: Train Loss = 0.010530655272305012\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=344, train_loss_step=0.0123, train_loss_epoch=0.0105]Epoch 205: Train Loss = 0.012326090596616268\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 10.08it/s, v_num=344, train_loss_step=0.0112, train_loss_epoch=0.0123]Epoch 206: Train Loss = 0.011184757575392723\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0112]Epoch 207: Train Loss = 0.012388229370117188\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=344, train_loss_step=0.00835, train_loss_epoch=0.0124]Epoch 208: Train Loss = 0.008350512944161892\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.00835] Epoch 209: Train Loss = 0.012419180944561958\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=344, train_loss_step=0.0143, train_loss_epoch=0.0124] Epoch 210: Train Loss = 0.0142552200704813\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.0143] Epoch 211: Train Loss = 0.013044698163866997\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=344, train_loss_step=0.0179, train_loss_epoch=0.013]Epoch 212: Train Loss = 0.01793833076953888\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=344, train_loss_step=0.012, train_loss_epoch=0.0179] Epoch 213: Train Loss = 0.012045169249176979\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=344, train_loss_step=0.0149, train_loss_epoch=0.012]Epoch 214: Train Loss = 0.014882922172546387\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=344, train_loss_step=0.0168, train_loss_epoch=0.0149]Epoch 215: Train Loss = 0.016845040023326874\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=344, train_loss_step=0.0113, train_loss_epoch=0.0168]Epoch 216: Train Loss = 0.011339954100549221\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.0113] Epoch 217: Train Loss = 0.013035252690315247\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.013]Epoch 218: Train Loss = 0.012669225223362446\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=344, train_loss_step=0.0154, train_loss_epoch=0.0127]Epoch 219: Train Loss = 0.015419035218656063\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0154]Epoch 220: Train Loss = 0.01163752842694521\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.0116] Epoch 221: Train Loss = 0.013047544285655022\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=344, train_loss_step=0.0154, train_loss_epoch=0.013]Epoch 222: Train Loss = 0.01541740633547306\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=344, train_loss_step=0.0183, train_loss_epoch=0.0154]Epoch 223: Train Loss = 0.018303487449884415\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=344, train_loss_step=0.00812, train_loss_epoch=0.0183]Epoch 224: Train Loss = 0.008118768222630024\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=344, train_loss_step=0.0113, train_loss_epoch=0.00812] Epoch 225: Train Loss = 0.011336704716086388\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=344, train_loss_step=0.0146, train_loss_epoch=0.0113] Epoch 226: Train Loss = 0.014631805010139942\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=344, train_loss_step=0.0141, train_loss_epoch=0.0146]Epoch 227: Train Loss = 0.01409092079848051\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0141]Epoch 228: Train Loss = 0.01271064393222332\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=344, train_loss_step=0.0109, train_loss_epoch=0.0127]Epoch 229: Train Loss = 0.010941497050225735\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=344, train_loss_step=0.0148, train_loss_epoch=0.0109]Epoch 230: Train Loss = 0.014849935658276081\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=344, train_loss_step=0.0147, train_loss_epoch=0.0148]Epoch 231: Train Loss = 0.014711981639266014\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=344, train_loss_step=0.00892, train_loss_epoch=0.0147]Epoch 232: Train Loss = 0.008919348940253258\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=344, train_loss_step=0.0125, train_loss_epoch=0.00892] Epoch 233: Train Loss = 0.012456359341740608\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=344, train_loss_step=0.0161, train_loss_epoch=0.0125] Epoch 234: Train Loss = 0.016124393790960312\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=344, train_loss_step=0.0156, train_loss_epoch=0.0161]Epoch 235: Train Loss = 0.015616047196090221\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=344, train_loss_step=0.0167, train_loss_epoch=0.0156]Epoch 236: Train Loss = 0.016650579869747162\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.0167]Epoch 237: Train Loss = 0.012645191513001919\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=344, train_loss_step=0.0129, train_loss_epoch=0.0126]Epoch 238: Train Loss = 0.012947959825396538\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0129]Epoch 239: Train Loss = 0.012716378085315228\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=344, train_loss_step=0.0164, train_loss_epoch=0.0127]Epoch 240: Train Loss = 0.016420913860201836\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=344, train_loss_step=0.0144, train_loss_epoch=0.0164]Epoch 241: Train Loss = 0.014380493201315403\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=344, train_loss_step=0.0123, train_loss_epoch=0.0144]Epoch 242: Train Loss = 0.012308447621762753\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=344, train_loss_step=0.0132, train_loss_epoch=0.0123]Epoch 243: Train Loss = 0.013184085488319397\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=344, train_loss_step=0.0133, train_loss_epoch=0.0132]Epoch 244: Train Loss = 0.01333419419825077\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=344, train_loss_step=0.014, train_loss_epoch=0.0133] Epoch 245: Train Loss = 0.014005155302584171\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.014]Epoch 246: Train Loss = 0.012581969611346722\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=344, train_loss_step=0.0159, train_loss_epoch=0.0126]Epoch 247: Train Loss = 0.015893174335360527\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=344, train_loss_step=0.0133, train_loss_epoch=0.0159]Epoch 248: Train Loss = 0.013332036323845387\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=344, train_loss_step=0.0132, train_loss_epoch=0.0133]Epoch 249: Train Loss = 0.013192552141845226\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=344, train_loss_step=0.0105, train_loss_epoch=0.0132]Epoch 250: Train Loss = 0.010529541410505772\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0105]Epoch 251: Train Loss = 0.01239247526973486\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=344, train_loss_step=0.014, train_loss_epoch=0.0124] Epoch 252: Train Loss = 0.014012848027050495\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=344, train_loss_step=0.0117, train_loss_epoch=0.014]Epoch 253: Train Loss = 0.011717552319169044\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=344, train_loss_step=0.0125, train_loss_epoch=0.0117]Epoch 254: Train Loss = 0.012484452687203884\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=344, train_loss_step=0.0107, train_loss_epoch=0.0125]Epoch 255: Train Loss = 0.010723031125962734\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=344, train_loss_step=0.0152, train_loss_epoch=0.0107]Epoch 256: Train Loss = 0.015209619887173176\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.0152]Epoch 257: Train Loss = 0.012593402527272701\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0126]Epoch 258: Train Loss = 0.01268570777028799\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0127]Epoch 259: Train Loss = 0.013782551512122154\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=344, train_loss_step=0.0133, train_loss_epoch=0.0138]Epoch 260: Train Loss = 0.01331667322665453\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=344, train_loss_step=0.0133, train_loss_epoch=0.0133]Epoch 261: Train Loss = 0.013317420147359371\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0133]Epoch 262: Train Loss = 0.011576339602470398\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=344, train_loss_step=0.0125, train_loss_epoch=0.0116]Epoch 263: Train Loss = 0.012508630752563477\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.0125]Epoch 264: Train Loss = 0.013410060666501522\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=344, train_loss_step=0.0113, train_loss_epoch=0.0134]Epoch 265: Train Loss = 0.011270838789641857\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=344, train_loss_step=0.0245, train_loss_epoch=0.0113]Epoch 266: Train Loss = 0.024528250098228455\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=344, train_loss_step=0.0131, train_loss_epoch=0.0245]Epoch 267: Train Loss = 0.013142918236553669\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=344, train_loss_step=0.0107, train_loss_epoch=0.0131]Epoch 268: Train Loss = 0.010682331398129463\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=344, train_loss_step=0.0118, train_loss_epoch=0.0107]Epoch 269: Train Loss = 0.011817480437457561\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=344, train_loss_step=0.0107, train_loss_epoch=0.0118]Epoch 270: Train Loss = 0.010706785134971142\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 271: Train Loss = 0.011586212553083897\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=344, train_loss_step=0.0168, train_loss_epoch=0.0116]Epoch 272: Train Loss = 0.016836807131767273\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0168]Epoch 273: Train Loss = 0.011574272997677326\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.0116] Epoch 274: Train Loss = 0.013040214776992798\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=344, train_loss_step=0.0145, train_loss_epoch=0.013]Epoch 275: Train Loss = 0.014519661664962769\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=344, train_loss_step=0.0132, train_loss_epoch=0.0145]Epoch 276: Train Loss = 0.0131717873737216\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=344, train_loss_step=0.00984, train_loss_epoch=0.0132]Epoch 277: Train Loss = 0.009840738959610462\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=344, train_loss_step=0.0111, train_loss_epoch=0.00984] Epoch 278: Train Loss = 0.011092351749539375\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=344, train_loss_step=0.0101, train_loss_epoch=0.0111] Epoch 279: Train Loss = 0.010091494768857956\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=344, train_loss_step=0.0117, train_loss_epoch=0.0101]Epoch 280: Train Loss = 0.011666837148368359\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s, v_num=344, train_loss_step=0.0165, train_loss_epoch=0.0117]Epoch 281: Train Loss = 0.01646263897418976\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=344, train_loss_step=0.0153, train_loss_epoch=0.0165]Epoch 282: Train Loss = 0.015310396440327168\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0153]Epoch 283: Train Loss = 0.013848896138370037\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=344, train_loss_step=0.0154, train_loss_epoch=0.0138]Epoch 284: Train Loss = 0.015430407598614693\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=344, train_loss_step=0.0119, train_loss_epoch=0.0154]Epoch 285: Train Loss = 0.011908888816833496\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=344, train_loss_step=0.0136, train_loss_epoch=0.0119]Epoch 286: Train Loss = 0.013562028296291828\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=344, train_loss_step=0.0105, train_loss_epoch=0.0136]Epoch 287: Train Loss = 0.010495168156921864\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=344, train_loss_step=0.0122, train_loss_epoch=0.0105]Epoch 288: Train Loss = 0.012225145474076271\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=344, train_loss_step=0.0117, train_loss_epoch=0.0122]Epoch 289: Train Loss = 0.011686406098306179\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=344, train_loss_step=0.0152, train_loss_epoch=0.0117]Epoch 290: Train Loss = 0.01518002338707447\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=344, train_loss_step=0.0135, train_loss_epoch=0.0152]Epoch 291: Train Loss = 0.013483790680766106\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=344, train_loss_step=0.0132, train_loss_epoch=0.0135]Epoch 292: Train Loss = 0.013184350915253162\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0132]Epoch 293: Train Loss = 0.012674774043262005\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=344, train_loss_step=0.0114, train_loss_epoch=0.0127]Epoch 294: Train Loss = 0.011416074819862843\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=344, train_loss_step=0.0121, train_loss_epoch=0.0114]Epoch 295: Train Loss = 0.012075117789208889\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 11.14it/s, v_num=344, train_loss_step=0.0156, train_loss_epoch=0.0121]Epoch 296: Train Loss = 0.015558281913399696\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=344, train_loss_step=0.00968, train_loss_epoch=0.0156]Epoch 297: Train Loss = 0.009675989858806133\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=344, train_loss_step=0.0114, train_loss_epoch=0.00968] Epoch 298: Train Loss = 0.011364658363163471\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=344, train_loss_step=0.0139, train_loss_epoch=0.0114] Epoch 299: Train Loss = 0.013873154297471046\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=344, train_loss_step=0.0132, train_loss_epoch=0.0139]Epoch 300: Train Loss = 0.013228612951934338\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=344, train_loss_step=0.0129, train_loss_epoch=0.0132]Epoch 301: Train Loss = 0.012874134816229343\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=344, train_loss_step=0.0162, train_loss_epoch=0.0129]Epoch 302: Train Loss = 0.016161641106009483\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=344, train_loss_step=0.0162, train_loss_epoch=0.0162]Epoch 303: Train Loss = 0.01616244576871395\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0162]Epoch 304: Train Loss = 0.012364291585981846\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=344, train_loss_step=0.015, train_loss_epoch=0.0124] Epoch 305: Train Loss = 0.015009180642664433\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=344, train_loss_step=0.0152, train_loss_epoch=0.015]Epoch 306: Train Loss = 0.015207662247121334\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0152]Epoch 307: Train Loss = 0.012388253584504128\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=344, train_loss_step=0.0103, train_loss_epoch=0.0124]Epoch 308: Train Loss = 0.01026428584009409\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=344, train_loss_step=0.016, train_loss_epoch=0.0103] Epoch 309: Train Loss = 0.016026686877012253\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=344, train_loss_step=0.0112, train_loss_epoch=0.016]Epoch 310: Train Loss = 0.011182082816958427\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=344, train_loss_step=0.0187, train_loss_epoch=0.0112]Epoch 311: Train Loss = 0.018737809732556343\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=344, train_loss_step=0.0117, train_loss_epoch=0.0187]Epoch 312: Train Loss = 0.011653746478259563\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.0117] Epoch 313: Train Loss = 0.011031024158000946\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=344, train_loss_step=0.0108, train_loss_epoch=0.011]Epoch 314: Train Loss = 0.010779961943626404\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0108]Epoch 315: Train Loss = 0.012700323946774006\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0127]Epoch 316: Train Loss = 0.011581634171307087\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.0116] Epoch 317: Train Loss = 0.011017383076250553\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=344, train_loss_step=0.012, train_loss_epoch=0.011] Epoch 318: Train Loss = 0.01196474488824606\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s, v_num=344, train_loss_step=0.014, train_loss_epoch=0.012]Epoch 319: Train Loss = 0.01402377337217331\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=344, train_loss_step=0.0105, train_loss_epoch=0.014]Epoch 320: Train Loss = 0.010468317195773125\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.0105]Epoch 321: Train Loss = 0.013415990397334099\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=344, train_loss_step=0.00998, train_loss_epoch=0.0134]Epoch 322: Train Loss = 0.00998013187199831\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=344, train_loss_step=0.0131, train_loss_epoch=0.00998] Epoch 323: Train Loss = 0.01305838581174612\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=344, train_loss_step=0.0136, train_loss_epoch=0.0131] Epoch 324: Train Loss = 0.013564804568886757\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=344, train_loss_step=0.00966, train_loss_epoch=0.0136]Epoch 325: Train Loss = 0.009662232361733913\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=344, train_loss_step=0.0102, train_loss_epoch=0.00966] Epoch 326: Train Loss = 0.010219110175967216\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=344, train_loss_step=0.0155, train_loss_epoch=0.0102] Epoch 327: Train Loss = 0.015538113191723824\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=344, train_loss_step=0.0158, train_loss_epoch=0.0155]Epoch 328: Train Loss = 0.015781652182340622\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=344, train_loss_step=0.0156, train_loss_epoch=0.0158]Epoch 329: Train Loss = 0.015572509728372097\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=344, train_loss_step=0.0122, train_loss_epoch=0.0156]Epoch 330: Train Loss = 0.012200061231851578\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=344, train_loss_step=0.00971, train_loss_epoch=0.0122]Epoch 331: Train Loss = 0.009710162878036499\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=344, train_loss_step=0.0132, train_loss_epoch=0.00971] Epoch 332: Train Loss = 0.013152734376490116\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=344, train_loss_step=0.0112, train_loss_epoch=0.0132] Epoch 333: Train Loss = 0.011193477548658848\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=344, train_loss_step=0.00846, train_loss_epoch=0.0112]Epoch 334: Train Loss = 0.008461679331958294\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.00846] Epoch 335: Train Loss = 0.012575189583003521\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s, v_num=344, train_loss_step=0.0135, train_loss_epoch=0.0126] Epoch 336: Train Loss = 0.013486513867974281\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.0135] Epoch 337: Train Loss = 0.011017956770956516\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.011]Epoch 338: Train Loss = 0.012674265541136265\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=344, train_loss_step=0.0128, train_loss_epoch=0.0127]Epoch 339: Train Loss = 0.012762193568050861\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=344, train_loss_step=0.014, train_loss_epoch=0.0128] Epoch 340: Train Loss = 0.014033698476850986\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.014] Epoch 341: Train Loss = 0.011034567840397358\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=344, train_loss_step=0.0136, train_loss_epoch=0.011]Epoch 342: Train Loss = 0.013645716942846775\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=344, train_loss_step=0.00965, train_loss_epoch=0.0136]Epoch 343: Train Loss = 0.009647613391280174\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=344, train_loss_step=0.0106, train_loss_epoch=0.00965] Epoch 344: Train Loss = 0.010628347285091877\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=344, train_loss_step=0.0103, train_loss_epoch=0.0106] Epoch 345: Train Loss = 0.01032252050936222\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=344, train_loss_step=0.0105, train_loss_epoch=0.0103]Epoch 346: Train Loss = 0.010477249510586262\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=344, train_loss_step=0.0118, train_loss_epoch=0.0105]Epoch 347: Train Loss = 0.011812039650976658\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=344, train_loss_step=0.0123, train_loss_epoch=0.0118]Epoch 348: Train Loss = 0.012293013744056225\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=344, train_loss_step=0.012, train_loss_epoch=0.0123] Epoch 349: Train Loss = 0.01203862763941288\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s, v_num=344, train_loss_step=0.017, train_loss_epoch=0.012] Epoch 350: Train Loss = 0.01696915552020073\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=344, train_loss_step=0.00838, train_loss_epoch=0.017]Epoch 351: Train Loss = 0.00837699230760336\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=344, train_loss_step=0.0122, train_loss_epoch=0.00838] Epoch 352: Train Loss = 0.012163749895989895\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.0122] Epoch 353: Train Loss = 0.013435987755656242\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=344, train_loss_step=0.0114, train_loss_epoch=0.0134]Epoch 354: Train Loss = 0.011414863169193268\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=344, train_loss_step=0.0122, train_loss_epoch=0.0114]Epoch 355: Train Loss = 0.01219186745584011\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0122]Epoch 356: Train Loss = 0.012686003930866718\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.0127] Epoch 357: Train Loss = 0.011034220457077026\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=344, train_loss_step=0.00976, train_loss_epoch=0.011]Epoch 358: Train Loss = 0.009759669192135334\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.00976]  Epoch 359: Train Loss = 0.010987578891217709\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=344, train_loss_step=0.0173, train_loss_epoch=0.011] Epoch 360: Train Loss = 0.017347095534205437\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=344, train_loss_step=0.0148, train_loss_epoch=0.0173]Epoch 361: Train Loss = 0.014796101488173008\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=344, train_loss_step=0.0142, train_loss_epoch=0.0148]Epoch 362: Train Loss = 0.014195723459124565\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=344, train_loss_step=0.00934, train_loss_epoch=0.0142]Epoch 363: Train Loss = 0.009342379868030548\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=344, train_loss_step=0.0106, train_loss_epoch=0.00934] Epoch 364: Train Loss = 0.010642251931130886\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=344, train_loss_step=0.0125, train_loss_epoch=0.0106] Epoch 365: Train Loss = 0.012505843304097652\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.0125] Epoch 366: Train Loss = 0.010969205759465694\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=344, train_loss_step=0.0141, train_loss_epoch=0.011]Epoch 367: Train Loss = 0.014146477915346622\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=344, train_loss_step=0.0131, train_loss_epoch=0.0141]Epoch 368: Train Loss = 0.013087994419038296\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=344, train_loss_step=0.0129, train_loss_epoch=0.0131]Epoch 369: Train Loss = 0.012922081165015697\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0129]Epoch 370: Train Loss = 0.01376225333660841\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=344, train_loss_step=0.00984, train_loss_epoch=0.0138]Epoch 371: Train Loss = 0.00983872264623642\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=344, train_loss_step=0.0128, train_loss_epoch=0.00984] Epoch 372: Train Loss = 0.012830190360546112\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=344, train_loss_step=0.0118, train_loss_epoch=0.0128] Epoch 373: Train Loss = 0.011774731799960136\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=344, train_loss_step=0.00996, train_loss_epoch=0.0118]Epoch 374: Train Loss = 0.009960544295608997\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=344, train_loss_step=0.0111, train_loss_epoch=0.00996] Epoch 375: Train Loss = 0.011068257503211498\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=344, train_loss_step=0.0115, train_loss_epoch=0.0111] Epoch 376: Train Loss = 0.011479715816676617\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=344, train_loss_step=0.0101, train_loss_epoch=0.0115]Epoch 377: Train Loss = 0.010096604004502296\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=344, train_loss_step=0.015, train_loss_epoch=0.0101] Epoch 378: Train Loss = 0.014959237538278103\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=344, train_loss_step=0.0123, train_loss_epoch=0.015]Epoch 379: Train Loss = 0.012317844666540623\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=344, train_loss_step=0.0133, train_loss_epoch=0.0123]Epoch 380: Train Loss = 0.013277530670166016\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=344, train_loss_step=0.0113, train_loss_epoch=0.0133]Epoch 381: Train Loss = 0.01130464393645525\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.0113] Epoch 382: Train Loss = 0.010950503870844841\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=344, train_loss_step=0.0118, train_loss_epoch=0.011]Epoch 383: Train Loss = 0.011847482062876225\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.0118]Epoch 384: Train Loss = 0.013368017040193081\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0134]Epoch 385: Train Loss = 0.013750402256846428\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=344, train_loss_step=0.012, train_loss_epoch=0.0138] Epoch 386: Train Loss = 0.012004048563539982\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=344, train_loss_step=0.0147, train_loss_epoch=0.012]Epoch 387: Train Loss = 0.01474753674119711\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=344, train_loss_step=0.0155, train_loss_epoch=0.0147]Epoch 388: Train Loss = 0.015534626320004463\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=344, train_loss_step=0.0188, train_loss_epoch=0.0155]Epoch 389: Train Loss = 0.018763160333037376\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=344, train_loss_step=0.00953, train_loss_epoch=0.0188]Epoch 390: Train Loss = 0.009527042508125305\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=344, train_loss_step=0.0106, train_loss_epoch=0.00953] Epoch 391: Train Loss = 0.010567791759967804\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=344, train_loss_step=0.014, train_loss_epoch=0.0106]  Epoch 392: Train Loss = 0.013983008451759815\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=344, train_loss_step=0.00984, train_loss_epoch=0.014]Epoch 393: Train Loss = 0.009841470047831535\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=344, train_loss_step=0.00993, train_loss_epoch=0.00984]Epoch 394: Train Loss = 0.00993277132511139\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=344, train_loss_step=0.0158, train_loss_epoch=0.00993] Epoch 395: Train Loss = 0.01582430489361286\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=344, train_loss_step=0.0147, train_loss_epoch=0.0158] Epoch 396: Train Loss = 0.014720723032951355\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.0147] Epoch 397: Train Loss = 0.012977690435945988\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=344, train_loss_step=0.00984, train_loss_epoch=0.013]Epoch 398: Train Loss = 0.009835097007453442\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.00984] Epoch 399: Train Loss = 0.012570984661579132\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=344, train_loss_step=0.0133, train_loss_epoch=0.0126] Epoch 400: Train Loss = 0.013266146183013916\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=344, train_loss_step=0.0131, train_loss_epoch=0.0133]Epoch 401: Train Loss = 0.013093221001327038\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0131]Epoch 402: Train Loss = 0.013792531564831734\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0138]Epoch 403: Train Loss = 0.012681479565799236\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=344, train_loss_step=0.0149, train_loss_epoch=0.0127]Epoch 404: Train Loss = 0.014879073016345501\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=344, train_loss_step=0.0144, train_loss_epoch=0.0149]Epoch 405: Train Loss = 0.014448435045778751\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.0144]Epoch 406: Train Loss = 0.012575605884194374\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=344, train_loss_step=0.0131, train_loss_epoch=0.0126]Epoch 407: Train Loss = 0.013073894195258617\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=344, train_loss_step=0.0101, train_loss_epoch=0.0131]Epoch 408: Train Loss = 0.010127309709787369\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0101]Epoch 409: Train Loss = 0.011595048010349274\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=344, train_loss_step=0.014, train_loss_epoch=0.0116] Epoch 410: Train Loss = 0.014036732725799084\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=344, train_loss_step=0.0183, train_loss_epoch=0.014]Epoch 411: Train Loss = 0.018336137756705284\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=344, train_loss_step=0.0103, train_loss_epoch=0.0183]Epoch 412: Train Loss = 0.010267744772136211\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=344, train_loss_step=0.0135, train_loss_epoch=0.0103]Epoch 413: Train Loss = 0.01347550842911005\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=344, train_loss_step=0.0142, train_loss_epoch=0.0135]Epoch 414: Train Loss = 0.014176958240568638\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=344, train_loss_step=0.014, train_loss_epoch=0.0142] Epoch 415: Train Loss = 0.013981551863253117\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=344, train_loss_step=0.0121, train_loss_epoch=0.014]Epoch 416: Train Loss = 0.01209634356200695\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=344, train_loss_step=0.0131, train_loss_epoch=0.0121]Epoch 417: Train Loss = 0.013129270635545254\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=344, train_loss_step=0.0135, train_loss_epoch=0.0131]Epoch 418: Train Loss = 0.013506554998457432\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=344, train_loss_step=0.0118, train_loss_epoch=0.0135]Epoch 419: Train Loss = 0.011800430715084076\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=344, train_loss_step=0.0156, train_loss_epoch=0.0118]Epoch 420: Train Loss = 0.015600797720253468\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=344, train_loss_step=0.012, train_loss_epoch=0.0156] Epoch 421: Train Loss = 0.011988679878413677\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=344, train_loss_step=0.0139, train_loss_epoch=0.012]Epoch 422: Train Loss = 0.013926699757575989\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=344, train_loss_step=0.0115, train_loss_epoch=0.0139]Epoch 423: Train Loss = 0.011494268663227558\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0115]Epoch 424: Train Loss = 0.012680244632065296\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0127]Epoch 425: Train Loss = 0.011621796526014805\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.0116] Epoch 426: Train Loss = 0.011010155081748962\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=344, train_loss_step=0.0102, train_loss_epoch=0.011]Epoch 427: Train Loss = 0.010246559977531433\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s, v_num=344, train_loss_step=0.0114, train_loss_epoch=0.0102]Epoch 428: Train Loss = 0.011370758526027203\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=344, train_loss_step=0.00966, train_loss_epoch=0.0114]Epoch 429: Train Loss = 0.009659728035330772\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=344, train_loss_step=0.00995, train_loss_epoch=0.00966]Epoch 430: Train Loss = 0.009949837811291218\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=344, train_loss_step=0.0125, train_loss_epoch=0.00995] Epoch 431: Train Loss = 0.012524004094302654\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=344, train_loss_step=0.00933, train_loss_epoch=0.0125]Epoch 432: Train Loss = 0.009325605817139149\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=344, train_loss_step=0.0153, train_loss_epoch=0.00933] Epoch 433: Train Loss = 0.01533037330955267\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.0153] Epoch 434: Train Loss = 0.01262736041098833\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=344, train_loss_step=0.0132, train_loss_epoch=0.0126]Epoch 435: Train Loss = 0.013202975504100323\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=344, train_loss_step=0.0129, train_loss_epoch=0.0132]Epoch 436: Train Loss = 0.01286364533007145\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.0129] Epoch 437: Train Loss = 0.013033413328230381\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=344, train_loss_step=0.0103, train_loss_epoch=0.013]Epoch 438: Train Loss = 0.010292015969753265\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=344, train_loss_step=0.0153, train_loss_epoch=0.0103]Epoch 439: Train Loss = 0.015345425345003605\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.0153]Epoch 440: Train Loss = 0.013375944457948208\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0134]Epoch 441: Train Loss = 0.012377066537737846\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=344, train_loss_step=0.0123, train_loss_epoch=0.0124]Epoch 442: Train Loss = 0.012338665314018726\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=344, train_loss_step=0.0134, train_loss_epoch=0.0123]Epoch 443: Train Loss = 0.013359482400119305\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=344, train_loss_step=0.0123, train_loss_epoch=0.0134]Epoch 444: Train Loss = 0.012293416075408459\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=344, train_loss_step=0.0144, train_loss_epoch=0.0123]Epoch 445: Train Loss = 0.014350985176861286\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=344, train_loss_step=0.0108, train_loss_epoch=0.0144]Epoch 446: Train Loss = 0.010761667974293232\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=344, train_loss_step=0.0117, train_loss_epoch=0.0108]Epoch 447: Train Loss = 0.011742925271391869\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=344, train_loss_step=0.0119, train_loss_epoch=0.0117]Epoch 448: Train Loss = 0.011896742507815361\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=344, train_loss_step=0.0133, train_loss_epoch=0.0119]Epoch 449: Train Loss = 0.013323507271707058\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=344, train_loss_step=0.012, train_loss_epoch=0.0133] Epoch 450: Train Loss = 0.012005249038338661\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=344, train_loss_step=0.0128, train_loss_epoch=0.012]Epoch 451: Train Loss = 0.012755852192640305\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0128]Epoch 452: Train Loss = 0.012383119203150272\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=344, train_loss_step=0.00968, train_loss_epoch=0.0124]Epoch 453: Train Loss = 0.009682309813797474\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=344, train_loss_step=0.00937, train_loss_epoch=0.00968]Epoch 454: Train Loss = 0.009366648271679878\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=344, train_loss_step=0.00972, train_loss_epoch=0.00937]Epoch 455: Train Loss = 0.009715341031551361\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=344, train_loss_step=0.0155, train_loss_epoch=0.00972] Epoch 456: Train Loss = 0.015526064671576023\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=344, train_loss_step=0.0128, train_loss_epoch=0.0155] Epoch 457: Train Loss = 0.012799881398677826\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s, v_num=344, train_loss_step=0.00988, train_loss_epoch=0.0128]Epoch 458: Train Loss = 0.009881298057734966\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=344, train_loss_step=0.0121, train_loss_epoch=0.00988] Epoch 459: Train Loss = 0.012073950842022896\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=344, train_loss_step=0.00954, train_loss_epoch=0.0121]Epoch 460: Train Loss = 0.009541898034512997\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=344, train_loss_step=0.0133, train_loss_epoch=0.00954] Epoch 461: Train Loss = 0.013274205848574638\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=344, train_loss_step=0.0105, train_loss_epoch=0.0133] Epoch 462: Train Loss = 0.010453425347805023\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=344, train_loss_step=0.00887, train_loss_epoch=0.0105]Epoch 463: Train Loss = 0.008868373930454254\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=344, train_loss_step=0.0147, train_loss_epoch=0.00887] Epoch 464: Train Loss = 0.014690025709569454\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.0147]  Epoch 465: Train Loss = 0.01303057186305523\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=344, train_loss_step=0.0139, train_loss_epoch=0.013]Epoch 466: Train Loss = 0.013881823979318142\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=344, train_loss_step=0.019, train_loss_epoch=0.0139] Epoch 467: Train Loss = 0.019015969708561897\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=344, train_loss_step=0.0129, train_loss_epoch=0.019]Epoch 468: Train Loss = 0.01287089567631483\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=344, train_loss_step=0.00863, train_loss_epoch=0.0129]Epoch 469: Train Loss = 0.008626710623502731\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.00863]  Epoch 470: Train Loss = 0.01304115355014801\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.013] Epoch 471: Train Loss = 0.011610313318669796\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.0116]Epoch 472: Train Loss = 0.012580879963934422\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=344, train_loss_step=0.00892, train_loss_epoch=0.0126]Epoch 473: Train Loss = 0.008924966678023338\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=344, train_loss_step=0.0104, train_loss_epoch=0.00892] Epoch 474: Train Loss = 0.010352456010878086\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=344, train_loss_step=0.011, train_loss_epoch=0.0104]  Epoch 475: Train Loss = 0.01103757880628109\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.011]Epoch 476: Train Loss = 0.013767934404313564\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=344, train_loss_step=0.0102, train_loss_epoch=0.0138]Epoch 477: Train Loss = 0.010228059254586697\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=344, train_loss_step=0.0138, train_loss_epoch=0.0102]Epoch 478: Train Loss = 0.01380196399986744\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=344, train_loss_step=0.0128, train_loss_epoch=0.0138]Epoch 479: Train Loss = 0.012830634601414204\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=344, train_loss_step=0.0091, train_loss_epoch=0.0128]Epoch 480: Train Loss = 0.009095989167690277\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=344, train_loss_step=0.0112, train_loss_epoch=0.0091]Epoch 481: Train Loss = 0.01117244828492403\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=344, train_loss_step=0.0143, train_loss_epoch=0.0112]Epoch 482: Train Loss = 0.01428659725934267\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=344, train_loss_step=0.0124, train_loss_epoch=0.0143]Epoch 483: Train Loss = 0.012383011169731617\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=344, train_loss_step=0.0107, train_loss_epoch=0.0124]Epoch 484: Train Loss = 0.010717968456447124\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=344, train_loss_step=0.00878, train_loss_epoch=0.0107]Epoch 485: Train Loss = 0.008776841685175896\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=344, train_loss_step=0.017, train_loss_epoch=0.00878]  Epoch 486: Train Loss = 0.01696046069264412\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=344, train_loss_step=0.0117, train_loss_epoch=0.017] Epoch 487: Train Loss = 0.011704896576702595\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=344, train_loss_step=0.0145, train_loss_epoch=0.0117]Epoch 488: Train Loss = 0.014524700120091438\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=344, train_loss_step=0.0147, train_loss_epoch=0.0145]Epoch 489: Train Loss = 0.01470776367932558\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s, v_num=344, train_loss_step=0.0127, train_loss_epoch=0.0147]Epoch 490: Train Loss = 0.012723852880299091\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.0127]Epoch 491: Train Loss = 0.012554988265037537\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=344, train_loss_step=0.0116, train_loss_epoch=0.0126]Epoch 492: Train Loss = 0.011638193391263485\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=344, train_loss_step=0.00984, train_loss_epoch=0.0116]Epoch 493: Train Loss = 0.009840105660259724\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=344, train_loss_step=0.013, train_loss_epoch=0.00984]  Epoch 494: Train Loss = 0.012961536645889282\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=344, train_loss_step=0.00951, train_loss_epoch=0.013]Epoch 495: Train Loss = 0.009509162977337837\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=344, train_loss_step=0.0126, train_loss_epoch=0.00951] Epoch 496: Train Loss = 0.012629358097910881\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=344, train_loss_step=0.0107, train_loss_epoch=0.0126] Epoch 497: Train Loss = 0.010670577175915241\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=344, train_loss_step=0.0102, train_loss_epoch=0.0107]Epoch 498: Train Loss = 0.010237039066851139\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=344, train_loss_step=0.0104, train_loss_epoch=0.0102]Epoch 499: Train Loss = 0.010409293696284294\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=344, train_loss_step=0.0104, train_loss_epoch=0.0104]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=344, train_loss_step=0.0104, train_loss_epoch=0.0104]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 26.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 16: from 2010-06-30 00:00:00 to 2022-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=348, train_loss_step=0.030]Epoch 0: Train Loss = 0.03003937005996704\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=348, train_loss_step=0.0591, train_loss_epoch=0.030]Epoch 1: Train Loss = 0.05910985916852951\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=348, train_loss_step=0.0377, train_loss_epoch=0.0591]Epoch 2: Train Loss = 0.037709277123212814\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=348, train_loss_step=0.0252, train_loss_epoch=0.0377]Epoch 3: Train Loss = 0.0252093356102705\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=348, train_loss_step=0.0137, train_loss_epoch=0.0252]Epoch 4: Train Loss = 0.013725774362683296\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=348, train_loss_step=0.0227, train_loss_epoch=0.0137]Epoch 5: Train Loss = 0.02266393043100834\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=348, train_loss_step=0.0174, train_loss_epoch=0.0227]Epoch 6: Train Loss = 0.017419125884771347\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=348, train_loss_step=0.0261, train_loss_epoch=0.0174]Epoch 7: Train Loss = 0.026071161031723022\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=348, train_loss_step=0.0153, train_loss_epoch=0.0261]Epoch 8: Train Loss = 0.015318791382014751\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=348, train_loss_step=0.0175, train_loss_epoch=0.0153]Epoch 9: Train Loss = 0.017534369602799416\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=348, train_loss_step=0.0162, train_loss_epoch=0.0175]Epoch 10: Train Loss = 0.016214432194828987\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=348, train_loss_step=0.0172, train_loss_epoch=0.0162]Epoch 11: Train Loss = 0.01719680428504944\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=348, train_loss_step=0.0165, train_loss_epoch=0.0172]Epoch 12: Train Loss = 0.016471518203616142\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=348, train_loss_step=0.0164, train_loss_epoch=0.0165]Epoch 13: Train Loss = 0.016367727890610695\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=348, train_loss_step=0.0194, train_loss_epoch=0.0164]Epoch 14: Train Loss = 0.019385989755392075\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=348, train_loss_step=0.0169, train_loss_epoch=0.0194]Epoch 15: Train Loss = 0.016904480755329132\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=348, train_loss_step=0.0226, train_loss_epoch=0.0169]Epoch 16: Train Loss = 0.022618690505623817\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=348, train_loss_step=0.0114, train_loss_epoch=0.0226]Epoch 17: Train Loss = 0.011370241641998291\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=348, train_loss_step=0.0149, train_loss_epoch=0.0114]Epoch 18: Train Loss = 0.014878069050610065\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=348, train_loss_step=0.0152, train_loss_epoch=0.0149]Epoch 19: Train Loss = 0.015242517925798893\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=348, train_loss_step=0.014, train_loss_epoch=0.0152] Epoch 20: Train Loss = 0.013951847329735756\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=348, train_loss_step=0.0157, train_loss_epoch=0.014]Epoch 21: Train Loss = 0.015690675005316734\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=348, train_loss_step=0.0203, train_loss_epoch=0.0157]Epoch 22: Train Loss = 0.02027486264705658\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=348, train_loss_step=0.0118, train_loss_epoch=0.0203]Epoch 23: Train Loss = 0.01182632427662611\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.0118]Epoch 24: Train Loss = 0.012225070036947727\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=348, train_loss_step=0.0177, train_loss_epoch=0.0122]Epoch 25: Train Loss = 0.017703020945191383\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=348, train_loss_step=0.0157, train_loss_epoch=0.0177]Epoch 26: Train Loss = 0.015737809240818024\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=348, train_loss_step=0.0161, train_loss_epoch=0.0157]Epoch 27: Train Loss = 0.016053443774580956\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=348, train_loss_step=0.0126, train_loss_epoch=0.0161]Epoch 28: Train Loss = 0.012620421126484871\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0126] Epoch 29: Train Loss = 0.010994074866175652\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.011]Epoch 30: Train Loss = 0.013468281365931034\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=348, train_loss_step=0.0148, train_loss_epoch=0.0135]Epoch 31: Train Loss = 0.014750286936759949\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=348, train_loss_step=0.0204, train_loss_epoch=0.0148]Epoch 32: Train Loss = 0.020406454801559448\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.0204]Epoch 33: Train Loss = 0.011210636235773563\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0112] Epoch 34: Train Loss = 0.012950281612575054\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=348, train_loss_step=0.0136, train_loss_epoch=0.013]Epoch 35: Train Loss = 0.013577410951256752\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=348, train_loss_step=0.0149, train_loss_epoch=0.0136]Epoch 36: Train Loss = 0.014905868098139763\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=348, train_loss_step=0.0124, train_loss_epoch=0.0149]Epoch 37: Train Loss = 0.012425246648490429\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.0124]Epoch 38: Train Loss = 0.01345857698470354\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.0135]Epoch 39: Train Loss = 0.011153007857501507\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=348, train_loss_step=0.016, train_loss_epoch=0.0112] Epoch 40: Train Loss = 0.015961891040205956\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=348, train_loss_step=0.0126, train_loss_epoch=0.016]Epoch 41: Train Loss = 0.012620284222066402\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=348, train_loss_step=0.012, train_loss_epoch=0.0126] Epoch 42: Train Loss = 0.012049145065248013\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.012] Epoch 43: Train Loss = 0.010967516340315342\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 44: Train Loss = 0.012489354237914085\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 12.52it/s, v_num=348, train_loss_step=0.0155, train_loss_epoch=0.0125]Epoch 45: Train Loss = 0.015543981455266476\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=348, train_loss_step=0.0165, train_loss_epoch=0.0155]Epoch 46: Train Loss = 0.016514940187335014\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=348, train_loss_step=0.0132, train_loss_epoch=0.0165]Epoch 47: Train Loss = 0.013186605647206306\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.0132]Epoch 48: Train Loss = 0.013516828417778015\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=348, train_loss_step=0.0121, train_loss_epoch=0.0135]Epoch 49: Train Loss = 0.012127196416258812\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=348, train_loss_step=0.017, train_loss_epoch=0.0121] Epoch 50: Train Loss = 0.016989490017294884\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=348, train_loss_step=0.0163, train_loss_epoch=0.017]Epoch 51: Train Loss = 0.01625289022922516\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s, v_num=348, train_loss_step=0.0174, train_loss_epoch=0.0163]Epoch 52: Train Loss = 0.017395608127117157\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=348, train_loss_step=0.0151, train_loss_epoch=0.0174]Epoch 53: Train Loss = 0.01509501039981842\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=348, train_loss_step=0.00956, train_loss_epoch=0.0151]Epoch 54: Train Loss = 0.009556181728839874\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=348, train_loss_step=0.0157, train_loss_epoch=0.00956] Epoch 55: Train Loss = 0.01565251499414444\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=348, train_loss_step=0.0138, train_loss_epoch=0.0157] Epoch 56: Train Loss = 0.013751533813774586\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=348, train_loss_step=0.0101, train_loss_epoch=0.0138]Epoch 57: Train Loss = 0.010130795650184155\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=348, train_loss_step=0.016, train_loss_epoch=0.0101] Epoch 58: Train Loss = 0.016046179458498955\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=348, train_loss_step=0.0147, train_loss_epoch=0.016]Epoch 59: Train Loss = 0.014730117283761501\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=348, train_loss_step=0.0134, train_loss_epoch=0.0147]Epoch 60: Train Loss = 0.013376744464039803\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.0134]Epoch 61: Train Loss = 0.012669481337070465\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=348, train_loss_step=0.0151, train_loss_epoch=0.0127]Epoch 62: Train Loss = 0.015141619369387627\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=348, train_loss_step=0.0155, train_loss_epoch=0.0151]Epoch 63: Train Loss = 0.015505042858421803\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0155] Epoch 64: Train Loss = 0.010971789248287678\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=348, train_loss_step=0.0126, train_loss_epoch=0.011]Epoch 65: Train Loss = 0.012647430412471294\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=348, train_loss_step=0.0149, train_loss_epoch=0.0126]Epoch 66: Train Loss = 0.01493021845817566\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=348, train_loss_step=0.0139, train_loss_epoch=0.0149]Epoch 67: Train Loss = 0.013867177069187164\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=348, train_loss_step=0.0143, train_loss_epoch=0.0139]Epoch 68: Train Loss = 0.014344742521643639\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=348, train_loss_step=0.0156, train_loss_epoch=0.0143]Epoch 69: Train Loss = 0.01562895067036152\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=348, train_loss_step=0.0168, train_loss_epoch=0.0156]Epoch 70: Train Loss = 0.016845647245645523\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=348, train_loss_step=0.0156, train_loss_epoch=0.0168]Epoch 71: Train Loss = 0.015609622932970524\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=348, train_loss_step=0.0101, train_loss_epoch=0.0156]Epoch 72: Train Loss = 0.010141447186470032\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.0101]Epoch 73: Train Loss = 0.012651587836444378\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.0127]Epoch 74: Train Loss = 0.012184344232082367\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=348, train_loss_step=0.0111, train_loss_epoch=0.0122]Epoch 75: Train Loss = 0.01107728574424982\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=348, train_loss_step=0.015, train_loss_epoch=0.0111] Epoch 76: Train Loss = 0.015048622153699398\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.015]Epoch 77: Train Loss = 0.012655908241868019\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.0127]Epoch 78: Train Loss = 0.012159587815403938\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=348, train_loss_step=0.0159, train_loss_epoch=0.0122]Epoch 79: Train Loss = 0.01587107591331005\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=348, train_loss_step=0.0139, train_loss_epoch=0.0159]Epoch 80: Train Loss = 0.013897696509957314\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=348, train_loss_step=0.0119, train_loss_epoch=0.0139]Epoch 81: Train Loss = 0.011864463798701763\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=348, train_loss_step=0.010, train_loss_epoch=0.0119] Epoch 82: Train Loss = 0.010028370656073093\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.010]Epoch 83: Train Loss = 0.012460306286811829\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=348, train_loss_step=0.0131, train_loss_epoch=0.0125]Epoch 84: Train Loss = 0.013133957982063293\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0131]Epoch 85: Train Loss = 0.011587792076170444\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=348, train_loss_step=0.0111, train_loss_epoch=0.0116]Epoch 86: Train Loss = 0.01110009104013443\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=348, train_loss_step=0.0111, train_loss_epoch=0.0111]Epoch 87: Train Loss = 0.011054696515202522\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0111]Epoch 88: Train Loss = 0.012309142388403416\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=348, train_loss_step=0.0149, train_loss_epoch=0.0123]Epoch 89: Train Loss = 0.014886592514812946\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=348, train_loss_step=0.0185, train_loss_epoch=0.0149]Epoch 90: Train Loss = 0.018473295494914055\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0185]Epoch 91: Train Loss = 0.012344295158982277\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=348, train_loss_step=0.0151, train_loss_epoch=0.0123]Epoch 92: Train Loss = 0.015102863311767578\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=348, train_loss_step=0.0126, train_loss_epoch=0.0151]Epoch 93: Train Loss = 0.012565146200358868\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=348, train_loss_step=0.0128, train_loss_epoch=0.0126]Epoch 94: Train Loss = 0.012775393202900887\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s, v_num=348, train_loss_step=0.014, train_loss_epoch=0.0128] Epoch 95: Train Loss = 0.013977570459246635\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=348, train_loss_step=0.0121, train_loss_epoch=0.014]Epoch 96: Train Loss = 0.012058963999152184\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=348, train_loss_step=0.0161, train_loss_epoch=0.0121]Epoch 97: Train Loss = 0.016076253727078438\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=348, train_loss_step=0.0128, train_loss_epoch=0.0161]Epoch 98: Train Loss = 0.012841194868087769\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=348, train_loss_step=0.0128, train_loss_epoch=0.0128]Epoch 99: Train Loss = 0.012792146764695644\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=348, train_loss_step=0.0167, train_loss_epoch=0.0128]Epoch 100: Train Loss = 0.016679221764206886\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=348, train_loss_step=0.0154, train_loss_epoch=0.0167]Epoch 101: Train Loss = 0.015371580608189106\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.0154]Epoch 102: Train Loss = 0.01352801825851202\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.0135]Epoch 103: Train Loss = 0.011209170334041119\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=348, train_loss_step=0.0158, train_loss_epoch=0.0112]Epoch 104: Train Loss = 0.0158227551728487\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=348, train_loss_step=0.012, train_loss_epoch=0.0158] Epoch 105: Train Loss = 0.012021498754620552\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=348, train_loss_step=0.0117, train_loss_epoch=0.012]Epoch 106: Train Loss = 0.011657281778752804\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=348, train_loss_step=0.0106, train_loss_epoch=0.0117]Epoch 107: Train Loss = 0.010556844063103199\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=348, train_loss_step=0.0102, train_loss_epoch=0.0106]Epoch 108: Train Loss = 0.010231100022792816\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=348, train_loss_step=0.0139, train_loss_epoch=0.0102]Epoch 109: Train Loss = 0.013908401131629944\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=348, train_loss_step=0.0211, train_loss_epoch=0.0139]Epoch 110: Train Loss = 0.02107604220509529\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=348, train_loss_step=0.0108, train_loss_epoch=0.0211]Epoch 111: Train Loss = 0.01084734033793211\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=348, train_loss_step=0.0138, train_loss_epoch=0.0108]Epoch 112: Train Loss = 0.013785406947135925\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=348, train_loss_step=0.0146, train_loss_epoch=0.0138]Epoch 113: Train Loss = 0.014615828171372414\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=348, train_loss_step=0.0129, train_loss_epoch=0.0146]Epoch 114: Train Loss = 0.012874697335064411\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=348, train_loss_step=0.0149, train_loss_epoch=0.0129]Epoch 115: Train Loss = 0.014915881678462029\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=348, train_loss_step=0.0109, train_loss_epoch=0.0149]Epoch 116: Train Loss = 0.010937193408608437\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 10.49it/s, v_num=348, train_loss_step=0.0128, train_loss_epoch=0.0109]Epoch 117: Train Loss = 0.012833154760301113\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=348, train_loss_step=0.016, train_loss_epoch=0.0128] Epoch 118: Train Loss = 0.016047563403844833\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=348, train_loss_step=0.0119, train_loss_epoch=0.016]Epoch 119: Train Loss = 0.011901602149009705\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.0119]Epoch 120: Train Loss = 0.01121742557734251\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.0112]Epoch 121: Train Loss = 0.012679633684456348\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=348, train_loss_step=0.015, train_loss_epoch=0.0127] Epoch 122: Train Loss = 0.014976960606873035\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.015]Epoch 123: Train Loss = 0.012674286961555481\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=348, train_loss_step=0.0141, train_loss_epoch=0.0127]Epoch 124: Train Loss = 0.01409719604998827\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0141] Epoch 125: Train Loss = 0.011016188189387321\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=348, train_loss_step=0.0136, train_loss_epoch=0.011]Epoch 126: Train Loss = 0.01361228059977293\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=348, train_loss_step=0.0105, train_loss_epoch=0.0136]Epoch 127: Train Loss = 0.010549341328442097\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=348, train_loss_step=0.0133, train_loss_epoch=0.0105]Epoch 128: Train Loss = 0.013267559930682182\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=348, train_loss_step=0.0113, train_loss_epoch=0.0133]Epoch 129: Train Loss = 0.011293630115687847\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=348, train_loss_step=0.0132, train_loss_epoch=0.0113]Epoch 130: Train Loss = 0.013191865757107735\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=348, train_loss_step=0.0141, train_loss_epoch=0.0132]Epoch 131: Train Loss = 0.014091121032834053\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=348, train_loss_step=0.0144, train_loss_epoch=0.0141]Epoch 132: Train Loss = 0.014448448084294796\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=348, train_loss_step=0.0119, train_loss_epoch=0.0144]Epoch 133: Train Loss = 0.011918148025870323\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=348, train_loss_step=0.0133, train_loss_epoch=0.0119]Epoch 134: Train Loss = 0.01325821690261364\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=348, train_loss_step=0.0145, train_loss_epoch=0.0133]Epoch 135: Train Loss = 0.01453922875225544\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=348, train_loss_step=0.014, train_loss_epoch=0.0145] Epoch 136: Train Loss = 0.01401413045823574\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=348, train_loss_step=0.017, train_loss_epoch=0.014] Epoch 137: Train Loss = 0.01696096733212471\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=348, train_loss_step=0.0186, train_loss_epoch=0.017]Epoch 138: Train Loss = 0.018621031194925308\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0186]Epoch 139: Train Loss = 0.011611764319241047\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=348, train_loss_step=0.023, train_loss_epoch=0.0116] Epoch 140: Train Loss = 0.022995740175247192\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.023]Epoch 141: Train Loss = 0.011173581704497337\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.0112]Epoch 142: Train Loss = 0.011198912747204304\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0112]Epoch 143: Train Loss = 0.011598641984164715\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0116] Epoch 144: Train Loss = 0.013042573817074299\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=348, train_loss_step=0.0119, train_loss_epoch=0.013]Epoch 145: Train Loss = 0.011887581087648869\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=348, train_loss_step=0.0134, train_loss_epoch=0.0119]Epoch 146: Train Loss = 0.013429383747279644\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=348, train_loss_step=0.0146, train_loss_epoch=0.0134]Epoch 147: Train Loss = 0.014554964378476143\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s, v_num=348, train_loss_step=0.0174, train_loss_epoch=0.0146]Epoch 148: Train Loss = 0.017386596649885178\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=348, train_loss_step=0.0124, train_loss_epoch=0.0174]Epoch 149: Train Loss = 0.012363597750663757\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.0124]Epoch 150: Train Loss = 0.013498653657734394\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=348, train_loss_step=0.0109, train_loss_epoch=0.0135]Epoch 151: Train Loss = 0.010870829224586487\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0109]Epoch 152: Train Loss = 0.011560016311705112\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0116]Epoch 153: Train Loss = 0.01161534059792757\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=348, train_loss_step=0.0132, train_loss_epoch=0.0116]Epoch 154: Train Loss = 0.013154515996575356\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=348, train_loss_step=0.0161, train_loss_epoch=0.0132]Epoch 155: Train Loss = 0.01614663191139698\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=348, train_loss_step=0.0113, train_loss_epoch=0.0161]Epoch 156: Train Loss = 0.01131976954638958\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0113]Epoch 157: Train Loss = 0.011551978066563606\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0116]Epoch 158: Train Loss = 0.012335310690104961\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=348, train_loss_step=0.0148, train_loss_epoch=0.0123]Epoch 159: Train Loss = 0.014771954156458378\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=348, train_loss_step=0.0163, train_loss_epoch=0.0148]Epoch 160: Train Loss = 0.0163241196423769\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s, v_num=348, train_loss_step=0.0156, train_loss_epoch=0.0163]Epoch 161: Train Loss = 0.01555789913982153\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=348, train_loss_step=0.0113, train_loss_epoch=0.0156]Epoch 162: Train Loss = 0.01134730875492096\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=348, train_loss_step=0.0152, train_loss_epoch=0.0113]Epoch 163: Train Loss = 0.015198984183371067\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.0152]Epoch 164: Train Loss = 0.012694825418293476\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=348, train_loss_step=0.0109, train_loss_epoch=0.0127]Epoch 165: Train Loss = 0.010926793329417706\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=348, train_loss_step=0.0115, train_loss_epoch=0.0109]Epoch 166: Train Loss = 0.011521496810019016\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=348, train_loss_step=0.0148, train_loss_epoch=0.0115]Epoch 167: Train Loss = 0.014837519265711308\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.0148]Epoch 168: Train Loss = 0.013481096364557743\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.0135]Epoch 169: Train Loss = 0.012151051312685013\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=348, train_loss_step=0.0113, train_loss_epoch=0.0122]Epoch 170: Train Loss = 0.011275785975158215\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=348, train_loss_step=0.0129, train_loss_epoch=0.0113]Epoch 171: Train Loss = 0.012877529487013817\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=348, train_loss_step=0.0105, train_loss_epoch=0.0129]Epoch 172: Train Loss = 0.01045838650316\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=348, train_loss_step=0.0115, train_loss_epoch=0.0105]Epoch 173: Train Loss = 0.011487345211207867\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=348, train_loss_step=0.0133, train_loss_epoch=0.0115]Epoch 174: Train Loss = 0.01330952811986208\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=348, train_loss_step=0.0166, train_loss_epoch=0.0133]Epoch 175: Train Loss = 0.01662808284163475\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=348, train_loss_step=0.0129, train_loss_epoch=0.0166]Epoch 176: Train Loss = 0.012860779650509357\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=348, train_loss_step=0.0131, train_loss_epoch=0.0129]Epoch 177: Train Loss = 0.013141979463398457\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=348, train_loss_step=0.0126, train_loss_epoch=0.0131]Epoch 178: Train Loss = 0.012599174864590168\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=348, train_loss_step=0.0134, train_loss_epoch=0.0126]Epoch 179: Train Loss = 0.013372814282774925\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.0134]Epoch 180: Train Loss = 0.012524915859103203\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=348, train_loss_step=0.0132, train_loss_epoch=0.0125]Epoch 181: Train Loss = 0.013230113312602043\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=348, train_loss_step=0.0166, train_loss_epoch=0.0132]Epoch 182: Train Loss = 0.016565237194299698\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.0166]Epoch 183: Train Loss = 0.012479600496590137\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=348, train_loss_step=0.0109, train_loss_epoch=0.0125]Epoch 184: Train Loss = 0.010884742252528667\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.0109]Epoch 185: Train Loss = 0.012748144567012787\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=348, train_loss_step=0.0104, train_loss_epoch=0.0127]Epoch 186: Train Loss = 0.010377471335232258\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=348, train_loss_step=0.00949, train_loss_epoch=0.0104]Epoch 187: Train Loss = 0.009487325325608253\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=348, train_loss_step=0.0158, train_loss_epoch=0.00949] Epoch 188: Train Loss = 0.01578681543469429\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s, v_num=348, train_loss_step=0.0104, train_loss_epoch=0.0158] Epoch 189: Train Loss = 0.010396228171885014\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=348, train_loss_step=0.0133, train_loss_epoch=0.0104]Epoch 190: Train Loss = 0.013282165862619877\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=348, train_loss_step=0.0199, train_loss_epoch=0.0133]Epoch 191: Train Loss = 0.01989578828215599\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=348, train_loss_step=0.00856, train_loss_epoch=0.0199]Epoch 192: Train Loss = 0.00855632871389389\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.00856] Epoch 193: Train Loss = 0.01253527868539095\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0125]  Epoch 194: Train Loss = 0.010992576368153095\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=348, train_loss_step=0.0105, train_loss_epoch=0.011]Epoch 195: Train Loss = 0.010513385757803917\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=348, train_loss_step=0.0109, train_loss_epoch=0.0105]Epoch 196: Train Loss = 0.010853588581085205\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=348, train_loss_step=0.0111, train_loss_epoch=0.0109]Epoch 197: Train Loss = 0.011080202646553516\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=348, train_loss_step=0.0113, train_loss_epoch=0.0111]Epoch 198: Train Loss = 0.011335944756865501\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=348, train_loss_step=0.00992, train_loss_epoch=0.0113]Epoch 199: Train Loss = 0.009915403090417385\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.00992] Epoch 200: Train Loss = 0.012163679115474224\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.0122] Epoch 201: Train Loss = 0.01253806333988905\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=348, train_loss_step=0.0165, train_loss_epoch=0.0125]Epoch 202: Train Loss = 0.016484713181853294\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=348, train_loss_step=0.0126, train_loss_epoch=0.0165]Epoch 203: Train Loss = 0.012585542164742947\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=348, train_loss_step=0.0161, train_loss_epoch=0.0126]Epoch 204: Train Loss = 0.01611320674419403\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=348, train_loss_step=0.0121, train_loss_epoch=0.0161]Epoch 205: Train Loss = 0.01205974817276001\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=348, train_loss_step=0.0128, train_loss_epoch=0.0121]Epoch 206: Train Loss = 0.012829484418034554\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.0128]Epoch 207: Train Loss = 0.012183562852442265\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=348, train_loss_step=0.0173, train_loss_epoch=0.0122]Epoch 208: Train Loss = 0.01734950952231884\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=348, train_loss_step=0.0121, train_loss_epoch=0.0173]Epoch 209: Train Loss = 0.01208579447120428\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=348, train_loss_step=0.015, train_loss_epoch=0.0121] Epoch 210: Train Loss = 0.01498837023973465\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.015]Epoch 211: Train Loss = 0.013490275479853153\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=348, train_loss_step=0.0141, train_loss_epoch=0.0135]Epoch 212: Train Loss = 0.014122577384114265\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=348, train_loss_step=0.0101, train_loss_epoch=0.0141]Epoch 213: Train Loss = 0.010091395117342472\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=348, train_loss_step=0.0146, train_loss_epoch=0.0101]Epoch 214: Train Loss = 0.014551403000950813\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=348, train_loss_step=0.0138, train_loss_epoch=0.0146]Epoch 215: Train Loss = 0.013829506002366543\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=348, train_loss_step=0.0126, train_loss_epoch=0.0138]Epoch 216: Train Loss = 0.012567711062729359\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=348, train_loss_step=0.0133, train_loss_epoch=0.0126]Epoch 217: Train Loss = 0.013315313495695591\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=348, train_loss_step=0.0149, train_loss_epoch=0.0133]Epoch 218: Train Loss = 0.01492614857852459\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=348, train_loss_step=0.0147, train_loss_epoch=0.0149]Epoch 219: Train Loss = 0.014726533554494381\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=348, train_loss_step=0.0137, train_loss_epoch=0.0147]Epoch 220: Train Loss = 0.013689862564206123\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=348, train_loss_step=0.0133, train_loss_epoch=0.0137]Epoch 221: Train Loss = 0.013316643424332142\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.0133]Epoch 222: Train Loss = 0.012153161689639091\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=348, train_loss_step=0.012, train_loss_epoch=0.0122] Epoch 223: Train Loss = 0.01198993157595396\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=348, train_loss_step=0.0105, train_loss_epoch=0.012]Epoch 224: Train Loss = 0.010538669303059578\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=348, train_loss_step=0.0107, train_loss_epoch=0.0105]Epoch 225: Train Loss = 0.010660049505531788\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=348, train_loss_step=0.0121, train_loss_epoch=0.0107]Epoch 226: Train Loss = 0.012147868983447552\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=348, train_loss_step=0.00942, train_loss_epoch=0.0121]Epoch 227: Train Loss = 0.009418057277798653\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=348, train_loss_step=0.0159, train_loss_epoch=0.00942] Epoch 228: Train Loss = 0.01586252450942993\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=348, train_loss_step=0.0098, train_loss_epoch=0.0159] Epoch 229: Train Loss = 0.009800161235034466\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=348, train_loss_step=0.018, train_loss_epoch=0.0098] Epoch 230: Train Loss = 0.017995666712522507\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.018]Epoch 231: Train Loss = 0.012299956753849983\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0123]Epoch 232: Train Loss = 0.011572449468076229\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=348, train_loss_step=0.0104, train_loss_epoch=0.0116]Epoch 233: Train Loss = 0.01037238072603941\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=348, train_loss_step=0.0124, train_loss_epoch=0.0104]Epoch 234: Train Loss = 0.012416891753673553\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0124] Epoch 235: Train Loss = 0.011008670553565025\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=348, train_loss_step=0.0128, train_loss_epoch=0.011]Epoch 236: Train Loss = 0.012793236412107944\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=348, train_loss_step=0.0175, train_loss_epoch=0.0128]Epoch 237: Train Loss = 0.017465263605117798\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=348, train_loss_step=0.00996, train_loss_epoch=0.0175]Epoch 238: Train Loss = 0.009959614835679531\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=348, train_loss_step=0.0113, train_loss_epoch=0.00996] Epoch 239: Train Loss = 0.011306675150990486\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0113] Epoch 240: Train Loss = 0.012279300019145012\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=348, train_loss_step=0.015, train_loss_epoch=0.0123] Epoch 241: Train Loss = 0.014958543702960014\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.015]Epoch 242: Train Loss = 0.011223201639950275\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=348, train_loss_step=0.0155, train_loss_epoch=0.0112]Epoch 243: Train Loss = 0.015497161075472832\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=348, train_loss_step=0.0139, train_loss_epoch=0.0155]Epoch 244: Train Loss = 0.013899317011237144\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=348, train_loss_step=0.0126, train_loss_epoch=0.0139]Epoch 245: Train Loss = 0.012562857009470463\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0126]Epoch 246: Train Loss = 0.011630252003669739\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=348, train_loss_step=0.0148, train_loss_epoch=0.0116]Epoch 247: Train Loss = 0.014825467951595783\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.0148]Epoch 248: Train Loss = 0.011200668290257454\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=348, train_loss_step=0.0153, train_loss_epoch=0.0112]Epoch 249: Train Loss = 0.015283996239304543\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.0153]Epoch 250: Train Loss = 0.013454101048409939\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=348, train_loss_step=0.0118, train_loss_epoch=0.0135]Epoch 251: Train Loss = 0.011757202446460724\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=348, train_loss_step=0.0115, train_loss_epoch=0.0118]Epoch 252: Train Loss = 0.01147546712309122\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=348, train_loss_step=0.0181, train_loss_epoch=0.0115]Epoch 253: Train Loss = 0.018121177330613136\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=348, train_loss_step=0.0131, train_loss_epoch=0.0181]Epoch 254: Train Loss = 0.013072247616946697\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=348, train_loss_step=0.0114, train_loss_epoch=0.0131]Epoch 255: Train Loss = 0.011419348418712616\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.0114]Epoch 256: Train Loss = 0.012729517184197903\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0127]Epoch 257: Train Loss = 0.012251300737261772\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=348, train_loss_step=0.00973, train_loss_epoch=0.0123]Epoch 258: Train Loss = 0.009730174206197262\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=348, train_loss_step=0.0104, train_loss_epoch=0.00973] Epoch 259: Train Loss = 0.010434048250317574\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=348, train_loss_step=0.0183, train_loss_epoch=0.0104] Epoch 260: Train Loss = 0.01831868104636669\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=348, train_loss_step=0.00785, train_loss_epoch=0.0183]Epoch 261: Train Loss = 0.007845865562558174\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.00785] Epoch 262: Train Loss = 0.013458880595862865\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=348, train_loss_step=0.0118, train_loss_epoch=0.0135] Epoch 263: Train Loss = 0.011847385205328465\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=348, train_loss_step=0.0129, train_loss_epoch=0.0118]Epoch 264: Train Loss = 0.012872842140495777\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=348, train_loss_step=0.0182, train_loss_epoch=0.0129]Epoch 265: Train Loss = 0.01819448731839657\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=348, train_loss_step=0.0133, train_loss_epoch=0.0182]Epoch 266: Train Loss = 0.013279485516250134\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=348, train_loss_step=0.0146, train_loss_epoch=0.0133]Epoch 267: Train Loss = 0.014559755101799965\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=348, train_loss_step=0.00896, train_loss_epoch=0.0146]Epoch 268: Train Loss = 0.008964216336607933\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=348, train_loss_step=0.012, train_loss_epoch=0.00896]  Epoch 269: Train Loss = 0.012036065571010113\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=348, train_loss_step=0.0239, train_loss_epoch=0.012] Epoch 270: Train Loss = 0.023944402113556862\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=348, train_loss_step=0.0114, train_loss_epoch=0.0239]Epoch 271: Train Loss = 0.011408437974750996\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0114] Epoch 272: Train Loss = 0.013038290664553642\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.013]Epoch 273: Train Loss = 0.012310422025620937\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0123] Epoch 274: Train Loss = 0.012964294292032719\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=348, train_loss_step=0.0118, train_loss_epoch=0.013]Epoch 275: Train Loss = 0.01180693693459034\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=348, train_loss_step=0.0124, train_loss_epoch=0.0118]Epoch 276: Train Loss = 0.012357751838862896\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=348, train_loss_step=0.0128, train_loss_epoch=0.0124]Epoch 277: Train Loss = 0.01277091633528471\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=348, train_loss_step=0.0155, train_loss_epoch=0.0128]Epoch 278: Train Loss = 0.015511972829699516\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.0155]Epoch 279: Train Loss = 0.012710361741483212\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=348, train_loss_step=0.0148, train_loss_epoch=0.0127]Epoch 280: Train Loss = 0.014817878603935242\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=348, train_loss_step=0.0138, train_loss_epoch=0.0148]Epoch 281: Train Loss = 0.013782186433672905\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=348, train_loss_step=0.0162, train_loss_epoch=0.0138]Epoch 282: Train Loss = 0.016155404970049858\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=348, train_loss_step=0.0142, train_loss_epoch=0.0162]Epoch 283: Train Loss = 0.014203466475009918\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=348, train_loss_step=0.00888, train_loss_epoch=0.0142]Epoch 284: Train Loss = 0.008881189860403538\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=348, train_loss_step=0.0166, train_loss_epoch=0.00888] Epoch 285: Train Loss = 0.01664903573691845\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=348, train_loss_step=0.016, train_loss_epoch=0.0166]  Epoch 286: Train Loss = 0.015964196994900703\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=348, train_loss_step=0.0137, train_loss_epoch=0.016]Epoch 287: Train Loss = 0.01374143734574318\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=348, train_loss_step=0.0141, train_loss_epoch=0.0137]Epoch 288: Train Loss = 0.01409282349050045\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=348, train_loss_step=0.0129, train_loss_epoch=0.0141]Epoch 289: Train Loss = 0.012898800894618034\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=348, train_loss_step=0.0141, train_loss_epoch=0.0129]Epoch 290: Train Loss = 0.014122913591563702\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=348, train_loss_step=0.0137, train_loss_epoch=0.0141]Epoch 291: Train Loss = 0.013701347634196281\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0137]Epoch 292: Train Loss = 0.012255989015102386\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=348, train_loss_step=0.0134, train_loss_epoch=0.0123]Epoch 293: Train Loss = 0.01341279037296772\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=348, train_loss_step=0.0139, train_loss_epoch=0.0134]Epoch 294: Train Loss = 0.013899529352784157\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=348, train_loss_step=0.0132, train_loss_epoch=0.0139]Epoch 295: Train Loss = 0.013193451799452305\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=348, train_loss_step=0.0178, train_loss_epoch=0.0132]Epoch 296: Train Loss = 0.017801040783524513\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=348, train_loss_step=0.0136, train_loss_epoch=0.0178]Epoch 297: Train Loss = 0.0136429313570261\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=348, train_loss_step=0.0192, train_loss_epoch=0.0136]Epoch 298: Train Loss = 0.019186818972229958\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=348, train_loss_step=0.0105, train_loss_epoch=0.0192]Epoch 299: Train Loss = 0.01049251388758421\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=348, train_loss_step=0.0143, train_loss_epoch=0.0105]Epoch 300: Train Loss = 0.014251010492444038\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=348, train_loss_step=0.0146, train_loss_epoch=0.0143]Epoch 301: Train Loss = 0.014633257873356342\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=348, train_loss_step=0.0183, train_loss_epoch=0.0146]Epoch 302: Train Loss = 0.018292022868990898\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=348, train_loss_step=0.0115, train_loss_epoch=0.0183]Epoch 303: Train Loss = 0.011505265720188618\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=348, train_loss_step=0.0145, train_loss_epoch=0.0115]Epoch 304: Train Loss = 0.01454724371433258\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=348, train_loss_step=0.012, train_loss_epoch=0.0145] Epoch 305: Train Loss = 0.012048294767737389\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.012]Epoch 306: Train Loss = 0.011169277131557465\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=348, train_loss_step=0.0108, train_loss_epoch=0.0112]Epoch 307: Train Loss = 0.010804107412695885\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=348, train_loss_step=0.00928, train_loss_epoch=0.0108]Epoch 308: Train Loss = 0.00927928276360035\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=348, train_loss_step=0.0109, train_loss_epoch=0.00928] Epoch 309: Train Loss = 0.010911739431321621\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=348, train_loss_step=0.0124, train_loss_epoch=0.0109] Epoch 310: Train Loss = 0.012357300147414207\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0124] Epoch 311: Train Loss = 0.013017146848142147\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s, v_num=348, train_loss_step=0.0114, train_loss_epoch=0.013]Epoch 312: Train Loss = 0.011375308968126774\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.0114]Epoch 313: Train Loss = 0.012723688967525959\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s, v_num=348, train_loss_step=0.0107, train_loss_epoch=0.0127]Epoch 314: Train Loss = 0.010712197050452232\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.0107]Epoch 315: Train Loss = 0.012218275107443333\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=348, train_loss_step=0.0132, train_loss_epoch=0.0122]Epoch 316: Train Loss = 0.013221316039562225\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=348, train_loss_step=0.0111, train_loss_epoch=0.0132]Epoch 317: Train Loss = 0.011140374466776848\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=348, train_loss_step=0.00972, train_loss_epoch=0.0111]Epoch 318: Train Loss = 0.00971820019185543\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=348, train_loss_step=0.00993, train_loss_epoch=0.00972]Epoch 319: Train Loss = 0.009927181527018547\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=348, train_loss_step=0.00867, train_loss_epoch=0.00993]Epoch 320: Train Loss = 0.008671225048601627\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=348, train_loss_step=0.0106, train_loss_epoch=0.00867] Epoch 321: Train Loss = 0.010643281042575836\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=348, train_loss_step=0.0127, train_loss_epoch=0.0106] Epoch 322: Train Loss = 0.012663168832659721\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=348, train_loss_step=0.0165, train_loss_epoch=0.0127]Epoch 323: Train Loss = 0.016490744426846504\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=348, train_loss_step=0.0192, train_loss_epoch=0.0165]Epoch 324: Train Loss = 0.019175458699464798\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0192] Epoch 325: Train Loss = 0.011027120053768158\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=348, train_loss_step=0.0131, train_loss_epoch=0.011]Epoch 326: Train Loss = 0.013089919462800026\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=348, train_loss_step=0.0092, train_loss_epoch=0.0131]Epoch 327: Train Loss = 0.009195176884531975\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=348, train_loss_step=0.0134, train_loss_epoch=0.0092]Epoch 328: Train Loss = 0.013365219347178936\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=348, train_loss_step=0.0129, train_loss_epoch=0.0134]Epoch 329: Train Loss = 0.012879661284387112\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=348, train_loss_step=0.0141, train_loss_epoch=0.0129]Epoch 330: Train Loss = 0.014124831184744835\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=348, train_loss_step=0.00967, train_loss_epoch=0.0141]Epoch 331: Train Loss = 0.00966909434646368\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=348, train_loss_step=0.0105, train_loss_epoch=0.00967] Epoch 332: Train Loss = 0.010470275767147541\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=348, train_loss_step=0.0164, train_loss_epoch=0.0105] Epoch 333: Train Loss = 0.016405491158366203\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=348, train_loss_step=0.0136, train_loss_epoch=0.0164]Epoch 334: Train Loss = 0.013625851832330227\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=348, train_loss_step=0.0131, train_loss_epoch=0.0136]Epoch 335: Train Loss = 0.013088054023683071\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=348, train_loss_step=0.0191, train_loss_epoch=0.0131]Epoch 336: Train Loss = 0.019071495160460472\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, v_num=348, train_loss_step=0.0134, train_loss_epoch=0.0191]Epoch 337: Train Loss = 0.013427138328552246\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0134] Epoch 338: Train Loss = 0.012950966134667397\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=348, train_loss_step=0.0166, train_loss_epoch=0.013]Epoch 339: Train Loss = 0.016574755311012268\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=348, train_loss_step=0.0155, train_loss_epoch=0.0166]Epoch 340: Train Loss = 0.015525019727647305\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=348, train_loss_step=0.0111, train_loss_epoch=0.0155]Epoch 341: Train Loss = 0.011119455099105835\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=348, train_loss_step=0.0167, train_loss_epoch=0.0111]Epoch 342: Train Loss = 0.016661718487739563\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.0167]Epoch 343: Train Loss = 0.013490273617208004\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=348, train_loss_step=0.0156, train_loss_epoch=0.0135]Epoch 344: Train Loss = 0.01555411983281374\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0156]Epoch 345: Train Loss = 0.011556131765246391\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=348, train_loss_step=0.00837, train_loss_epoch=0.0116]Epoch 346: Train Loss = 0.008365626446902752\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.00837] Epoch 347: Train Loss = 0.013529771938920021\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=348, train_loss_step=0.0118, train_loss_epoch=0.0135] Epoch 348: Train Loss = 0.011754722334444523\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=348, train_loss_step=0.0106, train_loss_epoch=0.0118]Epoch 349: Train Loss = 0.010635239072144032\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=348, train_loss_step=0.0146, train_loss_epoch=0.0106]Epoch 350: Train Loss = 0.014617969281971455\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0146]Epoch 351: Train Loss = 0.011561485007405281\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=348, train_loss_step=0.0121, train_loss_epoch=0.0116]Epoch 352: Train Loss = 0.012084194459021091\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=348, train_loss_step=0.0156, train_loss_epoch=0.0121]Epoch 353: Train Loss = 0.015596331097185612\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=348, train_loss_step=0.0105, train_loss_epoch=0.0156]Epoch 354: Train Loss = 0.010460949502885342\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=348, train_loss_step=0.0138, train_loss_epoch=0.0105]Epoch 355: Train Loss = 0.013805890455842018\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0138] Epoch 356: Train Loss = 0.013041563332080841\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=348, train_loss_step=0.0177, train_loss_epoch=0.013]Epoch 357: Train Loss = 0.017725814133882523\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=348, train_loss_step=0.0104, train_loss_epoch=0.0177]Epoch 358: Train Loss = 0.01035997737199068\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0104] Epoch 359: Train Loss = 0.013013367541134357\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.013]Epoch 360: Train Loss = 0.01123339869081974\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=348, train_loss_step=0.0157, train_loss_epoch=0.0112]Epoch 361: Train Loss = 0.01569579541683197\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=348, train_loss_step=0.0108, train_loss_epoch=0.0157]Epoch 362: Train Loss = 0.01084649283438921\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0108]Epoch 363: Train Loss = 0.012274243868887424\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=348, train_loss_step=0.0147, train_loss_epoch=0.0123]Epoch 364: Train Loss = 0.014686756767332554\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=348, train_loss_step=0.0109, train_loss_epoch=0.0147]Epoch 365: Train Loss = 0.010878687724471092\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=348, train_loss_step=0.0134, train_loss_epoch=0.0109]Epoch 366: Train Loss = 0.013435928151011467\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=348, train_loss_step=0.0121, train_loss_epoch=0.0134]Epoch 367: Train Loss = 0.012064463458955288\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=348, train_loss_step=0.0118, train_loss_epoch=0.0121]Epoch 368: Train Loss = 0.011818526312708855\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=348, train_loss_step=0.015, train_loss_epoch=0.0118] Epoch 369: Train Loss = 0.014987730421125889\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=348, train_loss_step=0.0106, train_loss_epoch=0.015]Epoch 370: Train Loss = 0.010633601807057858\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=348, train_loss_step=0.0115, train_loss_epoch=0.0106]Epoch 371: Train Loss = 0.011548197828233242\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=348, train_loss_step=0.0136, train_loss_epoch=0.0115]Epoch 372: Train Loss = 0.013613860122859478\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=348, train_loss_step=0.0104, train_loss_epoch=0.0136]Epoch 373: Train Loss = 0.01042295340448618\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0104] Epoch 374: Train Loss = 0.011029842309653759\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 375: Train Loss = 0.012521590106189251\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=348, train_loss_step=0.0113, train_loss_epoch=0.0125]Epoch 376: Train Loss = 0.011262238025665283\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=348, train_loss_step=0.012, train_loss_epoch=0.0113] Epoch 377: Train Loss = 0.011993690393865108\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=348, train_loss_step=0.0124, train_loss_epoch=0.012]Epoch 378: Train Loss = 0.012435903772711754\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=348, train_loss_step=0.0138, train_loss_epoch=0.0124]Epoch 379: Train Loss = 0.013802846893668175\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=348, train_loss_step=0.0113, train_loss_epoch=0.0138]Epoch 380: Train Loss = 0.01133583951741457\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=348, train_loss_step=0.0142, train_loss_epoch=0.0113]Epoch 381: Train Loss = 0.01418499369174242\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0142] Epoch 382: Train Loss = 0.012960626743733883\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.013]Epoch 383: Train Loss = 0.012309527024626732\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0123] Epoch 384: Train Loss = 0.013047573156654835\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=348, train_loss_step=0.0146, train_loss_epoch=0.013]Epoch 385: Train Loss = 0.014551720581948757\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=348, train_loss_step=0.012, train_loss_epoch=0.0146] Epoch 386: Train Loss = 0.012011252343654633\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=348, train_loss_step=0.0141, train_loss_epoch=0.012]Epoch 387: Train Loss = 0.01405950728803873\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0141]Epoch 388: Train Loss = 0.01230255700647831\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0123] Epoch 389: Train Loss = 0.01102376263588667\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=348, train_loss_step=0.0139, train_loss_epoch=0.011]Epoch 390: Train Loss = 0.013883315026760101\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=348, train_loss_step=0.0135, train_loss_epoch=0.0139]Epoch 391: Train Loss = 0.013503998517990112\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=348, train_loss_step=0.0143, train_loss_epoch=0.0135]Epoch 392: Train Loss = 0.014345848932862282\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=348, train_loss_step=0.00876, train_loss_epoch=0.0143]Epoch 393: Train Loss = 0.008764561265707016\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=348, train_loss_step=0.0139, train_loss_epoch=0.00876] Epoch 394: Train Loss = 0.013857364654541016\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=348, train_loss_step=0.0143, train_loss_epoch=0.0139] Epoch 395: Train Loss = 0.014326216652989388\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=348, train_loss_step=0.0124, train_loss_epoch=0.0143]Epoch 396: Train Loss = 0.012363445945084095\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=348, train_loss_step=0.0109, train_loss_epoch=0.0124]Epoch 397: Train Loss = 0.010886198841035366\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=348, train_loss_step=0.0187, train_loss_epoch=0.0109]Epoch 398: Train Loss = 0.018722862005233765\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=348, train_loss_step=0.0169, train_loss_epoch=0.0187]Epoch 399: Train Loss = 0.016859350726008415\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=348, train_loss_step=0.0106, train_loss_epoch=0.0169]Epoch 400: Train Loss = 0.010639024898409843\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=348, train_loss_step=0.0152, train_loss_epoch=0.0106]Epoch 401: Train Loss = 0.01516374945640564\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=348, train_loss_step=0.0161, train_loss_epoch=0.0152]Epoch 402: Train Loss = 0.016107624396681786\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=348, train_loss_step=0.0134, train_loss_epoch=0.0161]Epoch 403: Train Loss = 0.013387685641646385\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=348, train_loss_step=0.0161, train_loss_epoch=0.0134]Epoch 404: Train Loss = 0.016068609431385994\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=348, train_loss_step=0.0148, train_loss_epoch=0.0161]Epoch 405: Train Loss = 0.014758502133190632\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 10.52it/s, v_num=348, train_loss_step=0.0111, train_loss_epoch=0.0148]Epoch 406: Train Loss = 0.01110164262354374\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.0111]Epoch 407: Train Loss = 0.012155110947787762\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=348, train_loss_step=0.0148, train_loss_epoch=0.0122]Epoch 408: Train Loss = 0.014775286428630352\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s, v_num=348, train_loss_step=0.0128, train_loss_epoch=0.0148]Epoch 409: Train Loss = 0.012794638983905315\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0128]Epoch 410: Train Loss = 0.012337018735706806\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=348, train_loss_step=0.0179, train_loss_epoch=0.0123]Epoch 411: Train Loss = 0.01789342425763607\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=348, train_loss_step=0.0147, train_loss_epoch=0.0179]Epoch 412: Train Loss = 0.014665444381535053\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=348, train_loss_step=0.00974, train_loss_epoch=0.0147]Epoch 413: Train Loss = 0.009741946123540401\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=348, train_loss_step=0.0105, train_loss_epoch=0.00974] Epoch 414: Train Loss = 0.010450148023664951\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=348, train_loss_step=0.0191, train_loss_epoch=0.0105] Epoch 415: Train Loss = 0.019094504415988922\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0191]Epoch 416: Train Loss = 0.01232042908668518\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=348, train_loss_step=0.0119, train_loss_epoch=0.0123]Epoch 417: Train Loss = 0.011865123175084591\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0119] Epoch 418: Train Loss = 0.011005474254488945\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=348, train_loss_step=0.0108, train_loss_epoch=0.011]Epoch 419: Train Loss = 0.01080815028399229\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0108] Epoch 420: Train Loss = 0.013017090037465096\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=348, train_loss_step=0.0114, train_loss_epoch=0.013]Epoch 421: Train Loss = 0.011401398107409477\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.0114]Epoch 422: Train Loss = 0.01245384942740202\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=348, train_loss_step=0.0124, train_loss_epoch=0.0125]Epoch 423: Train Loss = 0.01243345532566309\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=348, train_loss_step=0.0119, train_loss_epoch=0.0124]Epoch 424: Train Loss = 0.011939674615859985\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0119] Epoch 425: Train Loss = 0.011024407111108303\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=348, train_loss_step=0.00997, train_loss_epoch=0.011]Epoch 426: Train Loss = 0.00997212529182434\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.00997] Epoch 427: Train Loss = 0.012268438935279846\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=348, train_loss_step=0.0106, train_loss_epoch=0.0123] Epoch 428: Train Loss = 0.010568107478320599\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0106] Epoch 429: Train Loss = 0.01302244421094656\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=348, train_loss_step=0.0117, train_loss_epoch=0.013]Epoch 430: Train Loss = 0.011729436926543713\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=348, train_loss_step=0.0124, train_loss_epoch=0.0117]Epoch 431: Train Loss = 0.012411526404321194\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.0124]Epoch 432: Train Loss = 0.01119131501764059\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=348, train_loss_step=0.0141, train_loss_epoch=0.0112]Epoch 433: Train Loss = 0.01412107516080141\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.0141]Epoch 434: Train Loss = 0.01215915847569704\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=348, train_loss_step=0.0105, train_loss_epoch=0.0122]Epoch 435: Train Loss = 0.010465720668435097\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0105] Epoch 436: Train Loss = 0.013037295080721378\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.013]Epoch 437: Train Loss = 0.012506692670285702\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=348, train_loss_step=0.0137, train_loss_epoch=0.0125]Epoch 438: Train Loss = 0.013731134124100208\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.0137]Epoch 439: Train Loss = 0.01252767350524664\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=348, train_loss_step=0.0107, train_loss_epoch=0.0125]Epoch 440: Train Loss = 0.010712673887610435\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=348, train_loss_step=0.0145, train_loss_epoch=0.0107]Epoch 441: Train Loss = 0.01451779156923294\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=348, train_loss_step=0.0119, train_loss_epoch=0.0145]Epoch 442: Train Loss = 0.011921489611268044\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=348, train_loss_step=0.0195, train_loss_epoch=0.0119]Epoch 443: Train Loss = 0.019491195678710938\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=348, train_loss_step=0.0118, train_loss_epoch=0.0195]Epoch 444: Train Loss = 0.011831414885818958\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=348, train_loss_step=0.0112, train_loss_epoch=0.0118]Epoch 445: Train Loss = 0.011225005611777306\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=348, train_loss_step=0.011, train_loss_epoch=0.0112] Epoch 446: Train Loss = 0.011046021245419979\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=348, train_loss_step=0.00938, train_loss_epoch=0.011]Epoch 447: Train Loss = 0.009383371099829674\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=348, train_loss_step=0.016, train_loss_epoch=0.00938]  Epoch 448: Train Loss = 0.015960166230797768\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=348, train_loss_step=0.0092, train_loss_epoch=0.016] Epoch 449: Train Loss = 0.009202639572322369\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0092] Epoch 450: Train Loss = 0.013040994293987751\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=348, train_loss_step=0.0119, train_loss_epoch=0.013]Epoch 451: Train Loss = 0.011850752867758274\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=348, train_loss_step=0.00878, train_loss_epoch=0.0119]Epoch 452: Train Loss = 0.008776730857789516\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=348, train_loss_step=0.0184, train_loss_epoch=0.00878] Epoch 453: Train Loss = 0.01835690811276436\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=348, train_loss_step=0.0126, train_loss_epoch=0.0184] Epoch 454: Train Loss = 0.01259430218487978\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=348, train_loss_step=0.0134, train_loss_epoch=0.0126]Epoch 455: Train Loss = 0.01335837785154581\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=348, train_loss_step=0.0154, train_loss_epoch=0.0134]Epoch 456: Train Loss = 0.015417469665408134\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=348, train_loss_step=0.0155, train_loss_epoch=0.0154]Epoch 457: Train Loss = 0.0154847651720047\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=348, train_loss_step=0.0114, train_loss_epoch=0.0155]Epoch 458: Train Loss = 0.011403216980397701\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=348, train_loss_step=0.0124, train_loss_epoch=0.0114]Epoch 459: Train Loss = 0.012400718405842781\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=348, train_loss_step=0.0113, train_loss_epoch=0.0124]Epoch 460: Train Loss = 0.011299943551421165\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=348, train_loss_step=0.0101, train_loss_epoch=0.0113]Epoch 461: Train Loss = 0.01011346373707056\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=348, train_loss_step=0.0144, train_loss_epoch=0.0101]Epoch 462: Train Loss = 0.014400155283510685\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=348, train_loss_step=0.00949, train_loss_epoch=0.0144]Epoch 463: Train Loss = 0.009487579576671124\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=348, train_loss_step=0.0113, train_loss_epoch=0.00949] Epoch 464: Train Loss = 0.01134541817009449\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=348, train_loss_step=0.0114, train_loss_epoch=0.0113] Epoch 465: Train Loss = 0.011394357308745384\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=348, train_loss_step=0.0177, train_loss_epoch=0.0114]Epoch 466: Train Loss = 0.01773707941174507\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=348, train_loss_step=0.0133, train_loss_epoch=0.0177]Epoch 467: Train Loss = 0.013257686980068684\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=348, train_loss_step=0.0179, train_loss_epoch=0.0133]Epoch 468: Train Loss = 0.017867540940642357\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=348, train_loss_step=0.0144, train_loss_epoch=0.0179]Epoch 469: Train Loss = 0.014421279542148113\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=348, train_loss_step=0.0123, train_loss_epoch=0.0144]Epoch 470: Train Loss = 0.012315995059907436\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=348, train_loss_step=0.0108, train_loss_epoch=0.0123]Epoch 471: Train Loss = 0.0107562942430377\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=348, train_loss_step=0.0121, train_loss_epoch=0.0108]Epoch 472: Train Loss = 0.012096288613975048\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0121] Epoch 473: Train Loss = 0.012976767495274544\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=348, train_loss_step=0.0155, train_loss_epoch=0.013]Epoch 474: Train Loss = 0.015530364587903023\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=348, train_loss_step=0.0101, train_loss_epoch=0.0155]Epoch 475: Train Loss = 0.010137391276657581\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=348, train_loss_step=0.0154, train_loss_epoch=0.0101]Epoch 476: Train Loss = 0.015421541407704353\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=348, train_loss_step=0.0167, train_loss_epoch=0.0154]Epoch 477: Train Loss = 0.016719812527298927\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=348, train_loss_step=0.0122, train_loss_epoch=0.0167]Epoch 478: Train Loss = 0.012177328579127789\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=348, train_loss_step=0.00992, train_loss_epoch=0.0122]Epoch 479: Train Loss = 0.00992025900632143\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=348, train_loss_step=0.0115, train_loss_epoch=0.00992] Epoch 480: Train Loss = 0.011545917950570583\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=348, train_loss_step=0.013, train_loss_epoch=0.0115]  Epoch 481: Train Loss = 0.0130381491035223\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=348, train_loss_step=0.0139, train_loss_epoch=0.013]Epoch 482: Train Loss = 0.013919693417847157\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  3.38it/s, v_num=348, train_loss_step=0.0117, train_loss_epoch=0.0139]Epoch 483: Train Loss = 0.011720651760697365\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=348, train_loss_step=0.0105, train_loss_epoch=0.0117]Epoch 484: Train Loss = 0.010468847118318081\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=348, train_loss_step=0.0128, train_loss_epoch=0.0105]Epoch 485: Train Loss = 0.012803131714463234\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=348, train_loss_step=0.0132, train_loss_epoch=0.0128]Epoch 486: Train Loss = 0.013154121115803719\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=348, train_loss_step=0.0116, train_loss_epoch=0.0132]Epoch 487: Train Loss = 0.01156467106193304\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=348, train_loss_step=0.0107, train_loss_epoch=0.0116]Epoch 488: Train Loss = 0.01072580087929964\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=348, train_loss_step=0.0126, train_loss_epoch=0.0107]Epoch 489: Train Loss = 0.012571309693157673\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=348, train_loss_step=0.0148, train_loss_epoch=0.0126]Epoch 490: Train Loss = 0.014837835915386677\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=348, train_loss_step=0.00989, train_loss_epoch=0.0148]Epoch 491: Train Loss = 0.009888170287013054\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=348, train_loss_step=0.0134, train_loss_epoch=0.00989] Epoch 492: Train Loss = 0.0133883748203516\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=348, train_loss_step=0.0177, train_loss_epoch=0.0134] Epoch 493: Train Loss = 0.01766788214445114\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=348, train_loss_step=0.0137, train_loss_epoch=0.0177]Epoch 494: Train Loss = 0.0136669110506773\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=348, train_loss_step=0.0096, train_loss_epoch=0.0137]Epoch 495: Train Loss = 0.009601561352610588\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=348, train_loss_step=0.00984, train_loss_epoch=0.0096]Epoch 496: Train Loss = 0.00983996782451868\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=348, train_loss_step=0.0121, train_loss_epoch=0.00984] Epoch 497: Train Loss = 0.01214697677642107\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=348, train_loss_step=0.020, train_loss_epoch=0.0121]  Epoch 498: Train Loss = 0.02000078558921814\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.020]Epoch 499: Train Loss = 0.012457969598472118\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.0125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=348, train_loss_step=0.0125, train_loss_epoch=0.0125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 17: from 2010-06-30 00:00:00 to 2022-12-05 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=352, train_loss_step=0.0286]Epoch 0: Train Loss = 0.02864779718220234\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=352, train_loss_step=0.054, train_loss_epoch=0.0286] Epoch 1: Train Loss = 0.05399401858448982\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=352, train_loss_step=0.0294, train_loss_epoch=0.054]Epoch 2: Train Loss = 0.029385363683104515\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=352, train_loss_step=0.0235, train_loss_epoch=0.0294]Epoch 3: Train Loss = 0.023521024733781815\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=352, train_loss_step=0.0187, train_loss_epoch=0.0235]Epoch 4: Train Loss = 0.018684497103095055\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=352, train_loss_step=0.0134, train_loss_epoch=0.0187]Epoch 5: Train Loss = 0.013380005955696106\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=352, train_loss_step=0.022, train_loss_epoch=0.0134] Epoch 6: Train Loss = 0.022022685036063194\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=352, train_loss_step=0.0185, train_loss_epoch=0.022]Epoch 7: Train Loss = 0.01849912479519844\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=352, train_loss_step=0.0222, train_loss_epoch=0.0185]Epoch 8: Train Loss = 0.022161507979035378\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=352, train_loss_step=0.0204, train_loss_epoch=0.0222]Epoch 9: Train Loss = 0.020369770005345345\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=352, train_loss_step=0.0155, train_loss_epoch=0.0204]Epoch 10: Train Loss = 0.015505197457969189\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s, v_num=352, train_loss_step=0.0147, train_loss_epoch=0.0155]Epoch 11: Train Loss = 0.014651055447757244\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=352, train_loss_step=0.0194, train_loss_epoch=0.0147]Epoch 12: Train Loss = 0.019440745934844017\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=352, train_loss_step=0.0145, train_loss_epoch=0.0194]Epoch 13: Train Loss = 0.01451160479336977\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=352, train_loss_step=0.0177, train_loss_epoch=0.0145]Epoch 14: Train Loss = 0.017697960138320923\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=352, train_loss_step=0.0184, train_loss_epoch=0.0177]Epoch 15: Train Loss = 0.018359782174229622\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=352, train_loss_step=0.0134, train_loss_epoch=0.0184]Epoch 16: Train Loss = 0.013444183394312859\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0134]Epoch 17: Train Loss = 0.01437330525368452\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=352, train_loss_step=0.0155, train_loss_epoch=0.0144]Epoch 18: Train Loss = 0.015505105257034302\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.0155]Epoch 19: Train Loss = 0.011764263734221458\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=352, train_loss_step=0.0176, train_loss_epoch=0.0118]Epoch 20: Train Loss = 0.017636829987168312\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=352, train_loss_step=0.0166, train_loss_epoch=0.0176]Epoch 21: Train Loss = 0.016635872423648834\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=352, train_loss_step=0.0151, train_loss_epoch=0.0166]Epoch 22: Train Loss = 0.015057415701448917\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=352, train_loss_step=0.0142, train_loss_epoch=0.0151]Epoch 23: Train Loss = 0.014215479604899883\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=352, train_loss_step=0.0161, train_loss_epoch=0.0142]Epoch 24: Train Loss = 0.016062550246715546\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0161]Epoch 25: Train Loss = 0.014359098859131336\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=352, train_loss_step=0.0133, train_loss_epoch=0.0144]Epoch 26: Train Loss = 0.013284212909638882\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.0133]Epoch 27: Train Loss = 0.011583425104618073\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=352, train_loss_step=0.0162, train_loss_epoch=0.0116]Epoch 28: Train Loss = 0.016207704320549965\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=352, train_loss_step=0.0145, train_loss_epoch=0.0162]Epoch 29: Train Loss = 0.014451350085437298\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=352, train_loss_step=0.0137, train_loss_epoch=0.0145]Epoch 30: Train Loss = 0.013667678460478783\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=352, train_loss_step=0.0146, train_loss_epoch=0.0137]Epoch 31: Train Loss = 0.01455119252204895\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=352, train_loss_step=0.0198, train_loss_epoch=0.0146]Epoch 32: Train Loss = 0.01983027718961239\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=352, train_loss_step=0.0145, train_loss_epoch=0.0198]Epoch 33: Train Loss = 0.014505341649055481\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s, v_num=352, train_loss_step=0.0222, train_loss_epoch=0.0145]Epoch 34: Train Loss = 0.02220849320292473\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=352, train_loss_step=0.0158, train_loss_epoch=0.0222]Epoch 35: Train Loss = 0.015843059867620468\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=352, train_loss_step=0.0255, train_loss_epoch=0.0158]Epoch 36: Train Loss = 0.025545021519064903\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=352, train_loss_step=0.0155, train_loss_epoch=0.0255]Epoch 37: Train Loss = 0.015546917915344238\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=352, train_loss_step=0.0185, train_loss_epoch=0.0155]Epoch 38: Train Loss = 0.018473485484719276\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=352, train_loss_step=0.0141, train_loss_epoch=0.0185]Epoch 39: Train Loss = 0.014100239612162113\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=352, train_loss_step=0.0173, train_loss_epoch=0.0141]Epoch 40: Train Loss = 0.01732802204787731\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=352, train_loss_step=0.0156, train_loss_epoch=0.0173]Epoch 41: Train Loss = 0.015594201162457466\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=352, train_loss_step=0.0156, train_loss_epoch=0.0156]Epoch 42: Train Loss = 0.015612529590725899\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=352, train_loss_step=0.0126, train_loss_epoch=0.0156]Epoch 43: Train Loss = 0.012616561725735664\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=352, train_loss_step=0.0151, train_loss_epoch=0.0126]Epoch 44: Train Loss = 0.015121613629162312\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=352, train_loss_step=0.0185, train_loss_epoch=0.0151]Epoch 45: Train Loss = 0.018503917381167412\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.0185]Epoch 46: Train Loss = 0.012215313501656055\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=352, train_loss_step=0.0147, train_loss_epoch=0.0122]Epoch 47: Train Loss = 0.014693875797092915\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.0147]Epoch 48: Train Loss = 0.012169511057436466\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=352, train_loss_step=0.0196, train_loss_epoch=0.0122]Epoch 49: Train Loss = 0.01962508074939251\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=352, train_loss_step=0.015, train_loss_epoch=0.0196] Epoch 50: Train Loss = 0.015005245804786682\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=352, train_loss_step=0.0164, train_loss_epoch=0.015]Epoch 51: Train Loss = 0.01641632430255413\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=352, train_loss_step=0.0149, train_loss_epoch=0.0164]Epoch 52: Train Loss = 0.01494213193655014\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=352, train_loss_step=0.0255, train_loss_epoch=0.0149]Epoch 53: Train Loss = 0.025489140301942825\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=352, train_loss_step=0.0132, train_loss_epoch=0.0255]Epoch 54: Train Loss = 0.01320537831634283\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=352, train_loss_step=0.0119, train_loss_epoch=0.0132]Epoch 55: Train Loss = 0.0119331618770957\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=352, train_loss_step=0.0149, train_loss_epoch=0.0119]Epoch 56: Train Loss = 0.014870584942400455\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=352, train_loss_step=0.0185, train_loss_epoch=0.0149]Epoch 57: Train Loss = 0.01851680688560009\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=352, train_loss_step=0.0134, train_loss_epoch=0.0185]Epoch 58: Train Loss = 0.013354884460568428\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=352, train_loss_step=0.0117, train_loss_epoch=0.0134]Epoch 59: Train Loss = 0.011733642779290676\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=352, train_loss_step=0.0165, train_loss_epoch=0.0117]Epoch 60: Train Loss = 0.016507048159837723\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=352, train_loss_step=0.0139, train_loss_epoch=0.0165]Epoch 61: Train Loss = 0.013909602537751198\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=352, train_loss_step=0.0121, train_loss_epoch=0.0139]Epoch 62: Train Loss = 0.012139583937823772\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.0121]Epoch 63: Train Loss = 0.010435506701469421\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=352, train_loss_step=0.0127, train_loss_epoch=0.0104]Epoch 64: Train Loss = 0.012731626629829407\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=352, train_loss_step=0.0135, train_loss_epoch=0.0127]Epoch 65: Train Loss = 0.013481409288942814\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=352, train_loss_step=0.0129, train_loss_epoch=0.0135]Epoch 66: Train Loss = 0.012945390306413174\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=352, train_loss_step=0.0125, train_loss_epoch=0.0129]Epoch 67: Train Loss = 0.012492871843278408\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=352, train_loss_step=0.0126, train_loss_epoch=0.0125]Epoch 68: Train Loss = 0.012625031173229218\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=352, train_loss_step=0.0147, train_loss_epoch=0.0126]Epoch 69: Train Loss = 0.014650859870016575\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=352, train_loss_step=0.0129, train_loss_epoch=0.0147]Epoch 70: Train Loss = 0.012890832498669624\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.0129]Epoch 71: Train Loss = 0.01039810013025999\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0104]Epoch 72: Train Loss = 0.0130881667137146\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=352, train_loss_step=0.0163, train_loss_epoch=0.0131]Epoch 73: Train Loss = 0.01630987785756588\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=352, train_loss_step=0.0168, train_loss_epoch=0.0163]Epoch 74: Train Loss = 0.016767429187893867\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=352, train_loss_step=0.0158, train_loss_epoch=0.0168]Epoch 75: Train Loss = 0.015820825472474098\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=352, train_loss_step=0.0124, train_loss_epoch=0.0158]Epoch 76: Train Loss = 0.012424604967236519\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=352, train_loss_step=0.00961, train_loss_epoch=0.0124]Epoch 77: Train Loss = 0.009607263840734959\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=352, train_loss_step=0.0143, train_loss_epoch=0.00961] Epoch 78: Train Loss = 0.014305944554507732\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  9.42it/s, v_num=352, train_loss_step=0.0128, train_loss_epoch=0.0143] Epoch 79: Train Loss = 0.012802869081497192\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0128]Epoch 80: Train Loss = 0.011136150918900967\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=352, train_loss_step=0.0143, train_loss_epoch=0.0111]Epoch 81: Train Loss = 0.01427896972745657\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=352, train_loss_step=0.00999, train_loss_epoch=0.0143]Epoch 82: Train Loss = 0.009986689314246178\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=352, train_loss_step=0.0147, train_loss_epoch=0.00999] Epoch 83: Train Loss = 0.014746570028364658\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=352, train_loss_step=0.0128, train_loss_epoch=0.0147] Epoch 84: Train Loss = 0.01276908628642559\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=352, train_loss_step=0.0134, train_loss_epoch=0.0128]Epoch 85: Train Loss = 0.013356941752135754\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=352, train_loss_step=0.015, train_loss_epoch=0.0134] Epoch 86: Train Loss = 0.015031279064714909\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=352, train_loss_step=0.00955, train_loss_epoch=0.015]Epoch 87: Train Loss = 0.009554900228977203\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.00955] Epoch 88: Train Loss = 0.013552917167544365\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.0136] Epoch 89: Train Loss = 0.012154614552855492\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=352, train_loss_step=0.00912, train_loss_epoch=0.0122]Epoch 90: Train Loss = 0.009123987518250942\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.00912] Epoch 91: Train Loss = 0.011846217326819897\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=352, train_loss_step=0.0173, train_loss_epoch=0.0118] Epoch 92: Train Loss = 0.0173256266862154\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0173]Epoch 93: Train Loss = 0.014415484853088856\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=352, train_loss_step=0.0145, train_loss_epoch=0.0144]Epoch 94: Train Loss = 0.014508679509162903\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=352, train_loss_step=0.0179, train_loss_epoch=0.0145]Epoch 95: Train Loss = 0.017938818782567978\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=352, train_loss_step=0.00977, train_loss_epoch=0.0179]Epoch 96: Train Loss = 0.009770696051418781\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=352, train_loss_step=0.0181, train_loss_epoch=0.00977] Epoch 97: Train Loss = 0.01811811700463295\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=352, train_loss_step=0.0108, train_loss_epoch=0.0181] Epoch 98: Train Loss = 0.01075261365622282\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.0108]Epoch 99: Train Loss = 0.013606938533484936\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=352, train_loss_step=0.0149, train_loss_epoch=0.0136]Epoch 100: Train Loss = 0.014910095371305943\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=352, train_loss_step=0.012, train_loss_epoch=0.0149] Epoch 101: Train Loss = 0.012016745284199715\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=352, train_loss_step=0.00847, train_loss_epoch=0.012]Epoch 102: Train Loss = 0.008467873558402061\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=352, train_loss_step=0.0109, train_loss_epoch=0.00847] Epoch 103: Train Loss = 0.01088873390108347\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=352, train_loss_step=0.016, train_loss_epoch=0.0109]  Epoch 104: Train Loss = 0.01601753942668438\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=352, train_loss_step=0.0105, train_loss_epoch=0.016]Epoch 105: Train Loss = 0.010487349703907967\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=352, train_loss_step=0.0124, train_loss_epoch=0.0105]Epoch 106: Train Loss = 0.012445456348359585\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=352, train_loss_step=0.0128, train_loss_epoch=0.0124]Epoch 107: Train Loss = 0.01278175413608551\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=352, train_loss_step=0.0117, train_loss_epoch=0.0128]Epoch 108: Train Loss = 0.011728676967322826\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.0117]Epoch 109: Train Loss = 0.010426020249724388\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s, v_num=352, train_loss_step=0.0147, train_loss_epoch=0.0104]Epoch 110: Train Loss = 0.014698914252221584\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=352, train_loss_step=0.0138, train_loss_epoch=0.0147]Epoch 111: Train Loss = 0.013813669793307781\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=352, train_loss_step=0.0148, train_loss_epoch=0.0138]Epoch 112: Train Loss = 0.014755324460566044\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.0148]Epoch 113: Train Loss = 0.013606282882392406\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0136]Epoch 114: Train Loss = 0.013067571446299553\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=352, train_loss_step=0.0127, train_loss_epoch=0.0131]Epoch 115: Train Loss = 0.012674969621002674\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=352, train_loss_step=0.0119, train_loss_epoch=0.0127]Epoch 116: Train Loss = 0.011948679573833942\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=352, train_loss_step=0.0142, train_loss_epoch=0.0119]Epoch 117: Train Loss = 0.014202987775206566\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0142]Epoch 118: Train Loss = 0.014373129233717918\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0144]Epoch 119: Train Loss = 0.014377491548657417\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=352, train_loss_step=0.0171, train_loss_epoch=0.0144]Epoch 120: Train Loss = 0.017128925770521164\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=352, train_loss_step=0.0139, train_loss_epoch=0.0171]Epoch 121: Train Loss = 0.013904372230172157\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=352, train_loss_step=0.0133, train_loss_epoch=0.0139]Epoch 122: Train Loss = 0.013297103345394135\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=352, train_loss_step=0.0117, train_loss_epoch=0.0133]Epoch 123: Train Loss = 0.011657655239105225\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=352, train_loss_step=0.0141, train_loss_epoch=0.0117]Epoch 124: Train Loss = 0.014139210805296898\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=352, train_loss_step=0.0125, train_loss_epoch=0.0141]Epoch 125: Train Loss = 0.012496056035161018\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=352, train_loss_step=0.0142, train_loss_epoch=0.0125]Epoch 126: Train Loss = 0.014235923998057842\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.0142]Epoch 127: Train Loss = 0.01182674802839756\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=352, train_loss_step=0.011, train_loss_epoch=0.0118] Epoch 128: Train Loss = 0.01096859760582447\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=352, train_loss_step=0.0178, train_loss_epoch=0.011]Epoch 129: Train Loss = 0.017849314957857132\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=352, train_loss_step=0.0127, train_loss_epoch=0.0178]Epoch 130: Train Loss = 0.012708989903330803\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=352, train_loss_step=0.0119, train_loss_epoch=0.0127]Epoch 131: Train Loss = 0.011862621642649174\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=352, train_loss_step=0.014, train_loss_epoch=0.0119] Epoch 132: Train Loss = 0.013979941606521606\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.014]Epoch 133: Train Loss = 0.011255452409386635\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=352, train_loss_step=0.0132, train_loss_epoch=0.0113]Epoch 134: Train Loss = 0.01323487889021635\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=352, train_loss_step=0.0109, train_loss_epoch=0.0132]Epoch 135: Train Loss = 0.010897449217736721\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=352, train_loss_step=0.0135, train_loss_epoch=0.0109]Epoch 136: Train Loss = 0.01345816906541586\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.0135]Epoch 137: Train Loss = 0.0121819619089365\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=352, train_loss_step=0.0159, train_loss_epoch=0.0122]Epoch 138: Train Loss = 0.015887077897787094\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 11.53it/s, v_num=352, train_loss_step=0.014, train_loss_epoch=0.0159] Epoch 139: Train Loss = 0.014017588458955288\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=352, train_loss_step=0.0126, train_loss_epoch=0.014]Epoch 140: Train Loss = 0.012568293139338493\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 13.93it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.0126]Epoch 141: Train Loss = 0.011300238780677319\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=352, train_loss_step=0.0149, train_loss_epoch=0.0113]Epoch 142: Train Loss = 0.014906225726008415\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s, v_num=352, train_loss_step=0.0182, train_loss_epoch=0.0149]Epoch 143: Train Loss = 0.018201380968093872\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=352, train_loss_step=0.0159, train_loss_epoch=0.0182]Epoch 144: Train Loss = 0.015867095440626144\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s, v_num=352, train_loss_step=0.0123, train_loss_epoch=0.0159]Epoch 145: Train Loss = 0.012344920076429844\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=352, train_loss_step=0.0162, train_loss_epoch=0.0123]Epoch 146: Train Loss = 0.016234425827860832\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0162]Epoch 147: Train Loss = 0.014379591681063175\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0144]Epoch 148: Train Loss = 0.014373487792909145\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0144]Epoch 149: Train Loss = 0.01313306950032711\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=352, train_loss_step=0.0169, train_loss_epoch=0.0131]Epoch 150: Train Loss = 0.016856089234352112\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=352, train_loss_step=0.0164, train_loss_epoch=0.0169]Epoch 151: Train Loss = 0.016360318288207054\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s, v_num=352, train_loss_step=0.0128, train_loss_epoch=0.0164]Epoch 152: Train Loss = 0.012838667258620262\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=352, train_loss_step=0.0185, train_loss_epoch=0.0128]Epoch 153: Train Loss = 0.01854863576591015\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=352, train_loss_step=0.0155, train_loss_epoch=0.0185]Epoch 154: Train Loss = 0.01553440373390913\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=352, train_loss_step=0.0127, train_loss_epoch=0.0155]Epoch 155: Train Loss = 0.01273330394178629\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=352, train_loss_step=0.0147, train_loss_epoch=0.0127]Epoch 156: Train Loss = 0.014709042385220528\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=352, train_loss_step=0.0149, train_loss_epoch=0.0147]Epoch 157: Train Loss = 0.014851697720587254\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.0149]Epoch 158: Train Loss = 0.011556888930499554\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=352, train_loss_step=0.013, train_loss_epoch=0.0116] Epoch 159: Train Loss = 0.013011818751692772\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=352, train_loss_step=0.00886, train_loss_epoch=0.013]Epoch 160: Train Loss = 0.008863544091582298\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=352, train_loss_step=0.0156, train_loss_epoch=0.00886] Epoch 161: Train Loss = 0.01563899777829647\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=352, train_loss_step=0.013, train_loss_epoch=0.0156]  Epoch 162: Train Loss = 0.013030437752604485\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=352, train_loss_step=0.0133, train_loss_epoch=0.013]Epoch 163: Train Loss = 0.013307097367942333\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=352, train_loss_step=0.0132, train_loss_epoch=0.0133]Epoch 164: Train Loss = 0.013211548328399658\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=352, train_loss_step=0.0152, train_loss_epoch=0.0132]Epoch 165: Train Loss = 0.01516184862703085\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=352, train_loss_step=0.013, train_loss_epoch=0.0152] Epoch 166: Train Loss = 0.013028807938098907\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.013]Epoch 167: Train Loss = 0.013598905876278877\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=352, train_loss_step=0.0137, train_loss_epoch=0.0136]Epoch 168: Train Loss = 0.013716178946197033\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=352, train_loss_step=0.0141, train_loss_epoch=0.0137]Epoch 169: Train Loss = 0.014091871678829193\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0141]Epoch 170: Train Loss = 0.013112187385559082\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.0131]Epoch 171: Train Loss = 0.010357595048844814\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=352, train_loss_step=0.0138, train_loss_epoch=0.0104]Epoch 172: Train Loss = 0.013775230385363102\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=352, train_loss_step=0.0154, train_loss_epoch=0.0138]Epoch 173: Train Loss = 0.015359384939074516\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=352, train_loss_step=0.0239, train_loss_epoch=0.0154]Epoch 174: Train Loss = 0.02387881837785244\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=352, train_loss_step=0.0109, train_loss_epoch=0.0239]Epoch 175: Train Loss = 0.010926013812422752\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0109]Epoch 176: Train Loss = 0.014442810788750648\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0144]Epoch 177: Train Loss = 0.013062745332717896\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=352, train_loss_step=0.0148, train_loss_epoch=0.0131]Epoch 178: Train Loss = 0.014818881638348103\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=352, train_loss_step=0.0135, train_loss_epoch=0.0148]Epoch 179: Train Loss = 0.013453692197799683\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=352, train_loss_step=0.0141, train_loss_epoch=0.0135]Epoch 180: Train Loss = 0.014082921668887138\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0141]Epoch 181: Train Loss = 0.014391747303307056\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 10.76it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0144]Epoch 182: Train Loss = 0.014407658018171787\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=352, train_loss_step=0.0146, train_loss_epoch=0.0144]Epoch 183: Train Loss = 0.01458937581628561\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=352, train_loss_step=0.0123, train_loss_epoch=0.0146]Epoch 184: Train Loss = 0.01234147883951664\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0123]Epoch 185: Train Loss = 0.011076833121478558\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.0111]Epoch 186: Train Loss = 0.013622714206576347\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=352, train_loss_step=0.0149, train_loss_epoch=0.0136]Epoch 187: Train Loss = 0.014928651973605156\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=352, train_loss_step=0.0126, train_loss_epoch=0.0149]Epoch 188: Train Loss = 0.012566217221319675\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0126]Epoch 189: Train Loss = 0.011075756512582302\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=352, train_loss_step=0.014, train_loss_epoch=0.0111] Epoch 190: Train Loss = 0.014032094739377499\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=352, train_loss_step=0.0114, train_loss_epoch=0.014]Epoch 191: Train Loss = 0.011426321230828762\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=352, train_loss_step=0.0099, train_loss_epoch=0.0114]Epoch 192: Train Loss = 0.009899464435875416\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=352, train_loss_step=0.0133, train_loss_epoch=0.0099]Epoch 193: Train Loss = 0.013263705186545849\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=352, train_loss_step=0.0123, train_loss_epoch=0.0133]Epoch 194: Train Loss = 0.012302883900702\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=352, train_loss_step=0.0114, train_loss_epoch=0.0123]Epoch 195: Train Loss = 0.011421282775700092\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0114]Epoch 196: Train Loss = 0.011074238456785679\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.0111]Epoch 197: Train Loss = 0.012180528603494167\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=352, train_loss_step=0.015, train_loss_epoch=0.0122] Epoch 198: Train Loss = 0.015010527335107327\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=352, train_loss_step=0.0124, train_loss_epoch=0.015]Epoch 199: Train Loss = 0.012380714528262615\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=352, train_loss_step=0.0143, train_loss_epoch=0.0124]Epoch 200: Train Loss = 0.014327426441013813\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=352, train_loss_step=0.016, train_loss_epoch=0.0143] Epoch 201: Train Loss = 0.016003254801034927\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=352, train_loss_step=0.0151, train_loss_epoch=0.016]Epoch 202: Train Loss = 0.015113120898604393\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=352, train_loss_step=0.0194, train_loss_epoch=0.0151]Epoch 203: Train Loss = 0.019433896988630295\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=352, train_loss_step=0.0109, train_loss_epoch=0.0194]Epoch 204: Train Loss = 0.010914638638496399\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=352, train_loss_step=0.0102, train_loss_epoch=0.0109]Epoch 205: Train Loss = 0.01018627267330885\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=352, train_loss_step=0.0105, train_loss_epoch=0.0102]Epoch 206: Train Loss = 0.010547660291194916\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.0105]Epoch 207: Train Loss = 0.011603795923292637\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.0116]Epoch 208: Train Loss = 0.010420811362564564\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=352, train_loss_step=0.00915, train_loss_epoch=0.0104]Epoch 209: Train Loss = 0.009147902950644493\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=352, train_loss_step=0.0112, train_loss_epoch=0.00915] Epoch 210: Train Loss = 0.011220342479646206\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.0112] Epoch 211: Train Loss = 0.01364764291793108\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=352, train_loss_step=0.00985, train_loss_epoch=0.0136]Epoch 212: Train Loss = 0.009854820556938648\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=352, train_loss_step=0.0126, train_loss_epoch=0.00985] Epoch 213: Train Loss = 0.012595945037901402\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=352, train_loss_step=0.0127, train_loss_epoch=0.0126] Epoch 214: Train Loss = 0.012682033702731133\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.0127]Epoch 215: Train Loss = 0.011597806587815285\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=352, train_loss_step=0.0121, train_loss_epoch=0.0116]Epoch 216: Train Loss = 0.012072717770934105\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0121]Epoch 217: Train Loss = 0.011066201142966747\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=352, train_loss_step=0.0123, train_loss_epoch=0.0111]Epoch 218: Train Loss = 0.012347252108156681\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=352, train_loss_step=0.0142, train_loss_epoch=0.0123]Epoch 219: Train Loss = 0.014164762571454048\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s, v_num=352, train_loss_step=0.018, train_loss_epoch=0.0142] Epoch 220: Train Loss = 0.01797446608543396\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=352, train_loss_step=0.0177, train_loss_epoch=0.018]Epoch 221: Train Loss = 0.017740478739142418\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=352, train_loss_step=0.0108, train_loss_epoch=0.0177]Epoch 222: Train Loss = 0.010833914391696453\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=352, train_loss_step=0.011, train_loss_epoch=0.0108] Epoch 223: Train Loss = 0.011041496880352497\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=352, train_loss_step=0.0137, train_loss_epoch=0.011]Epoch 224: Train Loss = 0.01368349976837635\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s, v_num=352, train_loss_step=0.011, train_loss_epoch=0.0137] Epoch 225: Train Loss = 0.01102265901863575\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.011]Epoch 226: Train Loss = 0.011808425188064575\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.0118]Epoch 227: Train Loss = 0.013594890013337135\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=352, train_loss_step=0.0128, train_loss_epoch=0.0136]Epoch 228: Train Loss = 0.012760852463543415\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=352, train_loss_step=0.0132, train_loss_epoch=0.0128]Epoch 229: Train Loss = 0.013165101408958435\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.0132]Epoch 230: Train Loss = 0.011791960336267948\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=352, train_loss_step=0.0138, train_loss_epoch=0.0118]Epoch 231: Train Loss = 0.01384909637272358\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=352, train_loss_step=0.0139, train_loss_epoch=0.0138]Epoch 232: Train Loss = 0.013855001889169216\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0139]Epoch 233: Train Loss = 0.013082905672490597\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=352, train_loss_step=0.0165, train_loss_epoch=0.0131]Epoch 234: Train Loss = 0.01645100675523281\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=352, train_loss_step=0.0112, train_loss_epoch=0.0165]Epoch 235: Train Loss = 0.011231133714318275\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=352, train_loss_step=0.0157, train_loss_epoch=0.0112]Epoch 236: Train Loss = 0.015730146318674088\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=352, train_loss_step=0.0154, train_loss_epoch=0.0157]Epoch 237: Train Loss = 0.015442763455212116\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=352, train_loss_step=0.020, train_loss_epoch=0.0154] Epoch 238: Train Loss = 0.020026063546538353\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=352, train_loss_step=0.0095, train_loss_epoch=0.020]Epoch 239: Train Loss = 0.009495059959590435\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=352, train_loss_step=0.0138, train_loss_epoch=0.0095]Epoch 240: Train Loss = 0.013814006000757217\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=352, train_loss_step=0.0195, train_loss_epoch=0.0138]Epoch 241: Train Loss = 0.01951747015118599\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=352, train_loss_step=0.0123, train_loss_epoch=0.0195]Epoch 242: Train Loss = 0.012285511009395123\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=352, train_loss_step=0.0189, train_loss_epoch=0.0123]Epoch 243: Train Loss = 0.018917469307780266\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=352, train_loss_step=0.012, train_loss_epoch=0.0189] Epoch 244: Train Loss = 0.011969603598117828\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=352, train_loss_step=0.019, train_loss_epoch=0.012] Epoch 245: Train Loss = 0.019022228196263313\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=352, train_loss_step=0.0121, train_loss_epoch=0.019]Epoch 246: Train Loss = 0.012134920805692673\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.0121]Epoch 247: Train Loss = 0.011769783683121204\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.0118]Epoch 248: Train Loss = 0.011596202850341797\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=352, train_loss_step=0.0165, train_loss_epoch=0.0116]Epoch 249: Train Loss = 0.0164583008736372\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.0165]Epoch 250: Train Loss = 0.011567601002752781\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=352, train_loss_step=0.0103, train_loss_epoch=0.0116]Epoch 251: Train Loss = 0.010302498936653137\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=352, train_loss_step=0.0125, train_loss_epoch=0.0103]Epoch 252: Train Loss = 0.012497619725763798\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.0125]Epoch 253: Train Loss = 0.011835471726953983\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=352, train_loss_step=0.0206, train_loss_epoch=0.0118]Epoch 254: Train Loss = 0.020578930154442787\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=352, train_loss_step=0.0145, train_loss_epoch=0.0206]Epoch 255: Train Loss = 0.014478293247520924\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=352, train_loss_step=0.0112, train_loss_epoch=0.0145]Epoch 256: Train Loss = 0.011228109709918499\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=352, train_loss_step=0.0112, train_loss_epoch=0.0112]Epoch 257: Train Loss = 0.011165942996740341\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=352, train_loss_step=0.0108, train_loss_epoch=0.0112]Epoch 258: Train Loss = 0.010752350091934204\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=352, train_loss_step=0.0119, train_loss_epoch=0.0108]Epoch 259: Train Loss = 0.011863409541547298\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=352, train_loss_step=0.014, train_loss_epoch=0.0119] Epoch 260: Train Loss = 0.014024883508682251\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=352, train_loss_step=0.0176, train_loss_epoch=0.014]Epoch 261: Train Loss = 0.01760496385395527\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=352, train_loss_step=0.0123, train_loss_epoch=0.0176]Epoch 262: Train Loss = 0.012280525639653206\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=352, train_loss_step=0.0101, train_loss_epoch=0.0123]Epoch 263: Train Loss = 0.010095666162669659\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=352, train_loss_step=0.0114, train_loss_epoch=0.0101]Epoch 264: Train Loss = 0.011356781236827374\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=352, train_loss_step=0.0132, train_loss_epoch=0.0114]Epoch 265: Train Loss = 0.013239502906799316\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0132]Epoch 266: Train Loss = 0.013050316832959652\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=352, train_loss_step=0.0143, train_loss_epoch=0.0131]Epoch 267: Train Loss = 0.014257887378334999\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0143]Epoch 268: Train Loss = 0.011106161400675774\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=352, train_loss_step=0.00966, train_loss_epoch=0.0111]Epoch 269: Train Loss = 0.009657072834670544\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=352, train_loss_step=0.0107, train_loss_epoch=0.00966] Epoch 270: Train Loss = 0.010702642612159252\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=352, train_loss_step=0.013, train_loss_epoch=0.0107]  Epoch 271: Train Loss = 0.012996437028050423\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=352, train_loss_step=0.0123, train_loss_epoch=0.013]Epoch 272: Train Loss = 0.012334912084043026\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=352, train_loss_step=0.0158, train_loss_epoch=0.0123]Epoch 273: Train Loss = 0.015823205932974815\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.0158]Epoch 274: Train Loss = 0.010390272364020348\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=352, train_loss_step=0.0103, train_loss_epoch=0.0104]Epoch 275: Train Loss = 0.010284560732543468\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0103]Epoch 276: Train Loss = 0.0111241415143013\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=352, train_loss_step=0.0139, train_loss_epoch=0.0111]Epoch 277: Train Loss = 0.013919089920818806\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=352, train_loss_step=0.00997, train_loss_epoch=0.0139]Epoch 278: Train Loss = 0.009971005842089653\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=352, train_loss_step=0.0124, train_loss_epoch=0.00997] Epoch 279: Train Loss = 0.012362571433186531\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=352, train_loss_step=0.014, train_loss_epoch=0.0124]  Epoch 280: Train Loss = 0.014002343639731407\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 11.22it/s, v_num=352, train_loss_step=0.0108, train_loss_epoch=0.014]Epoch 281: Train Loss = 0.01080305315554142\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=352, train_loss_step=0.00966, train_loss_epoch=0.0108]Epoch 282: Train Loss = 0.009662585332989693\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=352, train_loss_step=0.0109, train_loss_epoch=0.00966] Epoch 283: Train Loss = 0.010937156155705452\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=352, train_loss_step=0.0109, train_loss_epoch=0.0109] Epoch 284: Train Loss = 0.010857454501092434\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=352, train_loss_step=0.0129, train_loss_epoch=0.0109]Epoch 285: Train Loss = 0.012892450205981731\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=352, train_loss_step=0.0139, train_loss_epoch=0.0129]Epoch 286: Train Loss = 0.013868019916117191\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=352, train_loss_step=0.0156, train_loss_epoch=0.0139]Epoch 287: Train Loss = 0.015649598091840744\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=352, train_loss_step=0.0128, train_loss_epoch=0.0156]Epoch 288: Train Loss = 0.012766693718731403\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=352, train_loss_step=0.017, train_loss_epoch=0.0128] Epoch 289: Train Loss = 0.017049724236130714\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=352, train_loss_step=0.0098, train_loss_epoch=0.017]Epoch 290: Train Loss = 0.00979864876717329\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=352, train_loss_step=0.0108, train_loss_epoch=0.0098]Epoch 291: Train Loss = 0.010814723558723927\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=352, train_loss_step=0.0102, train_loss_epoch=0.0108]Epoch 292: Train Loss = 0.010240942239761353\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=352, train_loss_step=0.0138, train_loss_epoch=0.0102]Epoch 293: Train Loss = 0.013817517086863518\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=352, train_loss_step=0.0115, train_loss_epoch=0.0138]Epoch 294: Train Loss = 0.011530330404639244\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=352, train_loss_step=0.0117, train_loss_epoch=0.0115]Epoch 295: Train Loss = 0.011698571965098381\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=352, train_loss_step=0.0149, train_loss_epoch=0.0117]Epoch 296: Train Loss = 0.014927404001355171\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=352, train_loss_step=0.0108, train_loss_epoch=0.0149]Epoch 297: Train Loss = 0.010813628323376179\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=352, train_loss_step=0.00987, train_loss_epoch=0.0108]Epoch 298: Train Loss = 0.009870261885225773\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.00987] Epoch 299: Train Loss = 0.011323313228785992\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=352, train_loss_step=0.0208, train_loss_epoch=0.0113] Epoch 300: Train Loss = 0.02077423594892025\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=352, train_loss_step=0.013, train_loss_epoch=0.0208] Epoch 301: Train Loss = 0.012953461147844791\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=352, train_loss_step=0.0114, train_loss_epoch=0.013]Epoch 302: Train Loss = 0.011421924456954002\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=352, train_loss_step=0.0137, train_loss_epoch=0.0114]Epoch 303: Train Loss = 0.01368926465511322\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=352, train_loss_step=0.011, train_loss_epoch=0.0137] Epoch 304: Train Loss = 0.011037753894925117\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=352, train_loss_step=0.017, train_loss_epoch=0.011] Epoch 305: Train Loss = 0.0170422475785017\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=352, train_loss_step=0.00964, train_loss_epoch=0.017]Epoch 306: Train Loss = 0.00963676255196333\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=352, train_loss_step=0.0168, train_loss_epoch=0.00964] Epoch 307: Train Loss = 0.016835395246744156\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=352, train_loss_step=0.00963, train_loss_epoch=0.0168]Epoch 308: Train Loss = 0.009627731516957283\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=352, train_loss_step=0.0139, train_loss_epoch=0.00963] Epoch 309: Train Loss = 0.013895810581743717\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=352, train_loss_step=0.0102, train_loss_epoch=0.0139] Epoch 310: Train Loss = 0.010193092748522758\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=352, train_loss_step=0.018, train_loss_epoch=0.0102] Epoch 311: Train Loss = 0.017999321222305298\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.018]Epoch 312: Train Loss = 0.011813637800514698\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=352, train_loss_step=0.0157, train_loss_epoch=0.0118]Epoch 313: Train Loss = 0.01568448916077614\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=352, train_loss_step=0.010, train_loss_epoch=0.0157] Epoch 314: Train Loss = 0.0100125502794981\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.010]Epoch 315: Train Loss = 0.013552471995353699\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.0136]Epoch 316: Train Loss = 0.011646552942693233\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.0116]Epoch 317: Train Loss = 0.011298207566142082\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=352, train_loss_step=0.00931, train_loss_epoch=0.0113]Epoch 318: Train Loss = 0.009305057115852833\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=352, train_loss_step=0.014, train_loss_epoch=0.00931]  Epoch 319: Train Loss = 0.0140305170789361\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=352, train_loss_step=0.0102, train_loss_epoch=0.014] Epoch 320: Train Loss = 0.010229021310806274\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=352, train_loss_step=0.0112, train_loss_epoch=0.0102]Epoch 321: Train Loss = 0.011159705929458141\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=352, train_loss_step=0.0109, train_loss_epoch=0.0112]Epoch 322: Train Loss = 0.010890043340623379\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=352, train_loss_step=0.0127, train_loss_epoch=0.0109]Epoch 323: Train Loss = 0.012660907581448555\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=352, train_loss_step=0.00948, train_loss_epoch=0.0127]Epoch 324: Train Loss = 0.00947932992130518\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=352, train_loss_step=0.012, train_loss_epoch=0.00948]  Epoch 325: Train Loss = 0.011988917365670204\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.012] Epoch 326: Train Loss = 0.012159955687820911\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0122]Epoch 327: Train Loss = 0.011079457588493824\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=352, train_loss_step=0.0114, train_loss_epoch=0.0111]Epoch 328: Train Loss = 0.01141915563493967\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=352, train_loss_step=0.0165, train_loss_epoch=0.0114]Epoch 329: Train Loss = 0.016460629180073738\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.0165]Epoch 330: Train Loss = 0.01159911509603262\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=352, train_loss_step=0.015, train_loss_epoch=0.0116] Epoch 331: Train Loss = 0.015045293606817722\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=352, train_loss_step=0.0137, train_loss_epoch=0.015]Epoch 332: Train Loss = 0.01373299490660429\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=352, train_loss_step=0.0173, train_loss_epoch=0.0137]Epoch 333: Train Loss = 0.017319446429610252\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=352, train_loss_step=0.0107, train_loss_epoch=0.0173]Epoch 334: Train Loss = 0.010719153098762035\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=352, train_loss_step=0.00966, train_loss_epoch=0.0107]Epoch 335: Train Loss = 0.009657739661633968\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=352, train_loss_step=0.0143, train_loss_epoch=0.00966] Epoch 336: Train Loss = 0.014257081784307957\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=352, train_loss_step=0.0157, train_loss_epoch=0.0143] Epoch 337: Train Loss = 0.015732118859887123\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=352, train_loss_step=0.0224, train_loss_epoch=0.0157]Epoch 338: Train Loss = 0.022424424067139626\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=352, train_loss_step=0.0194, train_loss_epoch=0.0224]Epoch 339: Train Loss = 0.01944478414952755\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.0194]Epoch 340: Train Loss = 0.011613087728619576\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=352, train_loss_step=0.014, train_loss_epoch=0.0116] Epoch 341: Train Loss = 0.014021954499185085\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.014]Epoch 342: Train Loss = 0.011294099502265453\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=352, train_loss_step=0.0142, train_loss_epoch=0.0113]Epoch 343: Train Loss = 0.014225920662283897\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=352, train_loss_step=0.0128, train_loss_epoch=0.0142]Epoch 344: Train Loss = 0.012778104282915592\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=352, train_loss_step=0.0154, train_loss_epoch=0.0128]Epoch 345: Train Loss = 0.015422770753502846\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=352, train_loss_step=0.016, train_loss_epoch=0.0154] Epoch 346: Train Loss = 0.016041425988078117\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=352, train_loss_step=0.0108, train_loss_epoch=0.016]Epoch 347: Train Loss = 0.010824703611433506\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.0108]Epoch 348: Train Loss = 0.013625716790556908\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=352, train_loss_step=0.0149, train_loss_epoch=0.0136]Epoch 349: Train Loss = 0.014930720441043377\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0149]Epoch 350: Train Loss = 0.013127864338457584\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=352, train_loss_step=0.0148, train_loss_epoch=0.0131]Epoch 351: Train Loss = 0.014786308631300926\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.0148]Epoch 352: Train Loss = 0.013590109534561634\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=352, train_loss_step=0.0154, train_loss_epoch=0.0136]Epoch 353: Train Loss = 0.015432938002049923\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0154]Epoch 354: Train Loss = 0.011074074544012547\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=352, train_loss_step=0.00889, train_loss_epoch=0.0111]Epoch 355: Train Loss = 0.00888774637132883\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s, v_num=352, train_loss_step=0.0105, train_loss_epoch=0.00889] Epoch 356: Train Loss = 0.01054671872407198\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.0105] Epoch 357: Train Loss = 0.013637205585837364\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=352, train_loss_step=0.013, train_loss_epoch=0.0136] Epoch 358: Train Loss = 0.012976431287825108\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=352, train_loss_step=0.0204, train_loss_epoch=0.013]Epoch 359: Train Loss = 0.020420266315340996\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=352, train_loss_step=0.00996, train_loss_epoch=0.0204]Epoch 360: Train Loss = 0.009961851872503757\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=352, train_loss_step=0.0252, train_loss_epoch=0.00996] Epoch 361: Train Loss = 0.025161460041999817\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0252] Epoch 362: Train Loss = 0.01112762838602066\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=352, train_loss_step=0.0147, train_loss_epoch=0.0111]Epoch 363: Train Loss = 0.014749161899089813\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=352, train_loss_step=0.0138, train_loss_epoch=0.0147]Epoch 364: Train Loss = 0.01380844321101904\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0138]Epoch 365: Train Loss = 0.014438449405133724\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.0144]Epoch 366: Train Loss = 0.012217768467962742\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=352, train_loss_step=0.013, train_loss_epoch=0.0122] Epoch 367: Train Loss = 0.013015644624829292\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=352, train_loss_step=0.0132, train_loss_epoch=0.013]Epoch 368: Train Loss = 0.01324278675019741\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=352, train_loss_step=0.0144, train_loss_epoch=0.0132]Epoch 369: Train Loss = 0.014438806101679802\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=352, train_loss_step=0.0176, train_loss_epoch=0.0144]Epoch 370: Train Loss = 0.017564905807375908\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=352, train_loss_step=0.0151, train_loss_epoch=0.0176]Epoch 371: Train Loss = 0.015066894702613354\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=352, train_loss_step=0.0108, train_loss_epoch=0.0151]Epoch 372: Train Loss = 0.010842404328286648\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=352, train_loss_step=0.0134, train_loss_epoch=0.0108]Epoch 373: Train Loss = 0.013411395251750946\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.0134]Epoch 374: Train Loss = 0.012236908078193665\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=352, train_loss_step=0.0203, train_loss_epoch=0.0122]Epoch 375: Train Loss = 0.020313141867518425\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=352, train_loss_step=0.0114, train_loss_epoch=0.0203]Epoch 376: Train Loss = 0.011448556557297707\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=352, train_loss_step=0.0115, train_loss_epoch=0.0114]Epoch 377: Train Loss = 0.011492994613945484\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=352, train_loss_step=0.0115, train_loss_epoch=0.0115]Epoch 378: Train Loss = 0.011544384993612766\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=352, train_loss_step=0.0155, train_loss_epoch=0.0115]Epoch 379: Train Loss = 0.015549814328551292\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=352, train_loss_step=0.016, train_loss_epoch=0.0155] Epoch 380: Train Loss = 0.016009217128157616\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=352, train_loss_step=0.0156, train_loss_epoch=0.016]Epoch 381: Train Loss = 0.01563396118581295\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.0156]Epoch 382: Train Loss = 0.012222273275256157\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.0122]Epoch 383: Train Loss = 0.012184813618659973\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=352, train_loss_step=0.015, train_loss_epoch=0.0122] Epoch 384: Train Loss = 0.015000561252236366\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s, v_num=352, train_loss_step=0.0103, train_loss_epoch=0.015]Epoch 385: Train Loss = 0.01027020625770092\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0103]Epoch 386: Train Loss = 0.013094372116029263\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=352, train_loss_step=0.017, train_loss_epoch=0.0131] Epoch 387: Train Loss = 0.016952550038695335\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=352, train_loss_step=0.0137, train_loss_epoch=0.017]Epoch 388: Train Loss = 0.013724250718951225\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=352, train_loss_step=0.0115, train_loss_epoch=0.0137]Epoch 389: Train Loss = 0.011505073867738247\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=352, train_loss_step=0.0106, train_loss_epoch=0.0115]Epoch 390: Train Loss = 0.010616282932460308\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=352, train_loss_step=0.0119, train_loss_epoch=0.0106]Epoch 391: Train Loss = 0.011883229948580265\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 11.22it/s, v_num=352, train_loss_step=0.014, train_loss_epoch=0.0119] Epoch 392: Train Loss = 0.014042426832020283\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=352, train_loss_step=0.011, train_loss_epoch=0.014] Epoch 393: Train Loss = 0.011044630780816078\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=352, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 394: Train Loss = 0.012474216520786285\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=352, train_loss_step=0.0107, train_loss_epoch=0.0125]Epoch 395: Train Loss = 0.01065791491419077\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=352, train_loss_step=0.0154, train_loss_epoch=0.0107]Epoch 396: Train Loss = 0.015446471981704235\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=352, train_loss_step=0.0106, train_loss_epoch=0.0154]Epoch 397: Train Loss = 0.010582302697002888\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=352, train_loss_step=0.0107, train_loss_epoch=0.0106]Epoch 398: Train Loss = 0.010657555423676968\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=352, train_loss_step=0.0121, train_loss_epoch=0.0107]Epoch 399: Train Loss = 0.012080741114914417\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=352, train_loss_step=0.00985, train_loss_epoch=0.0121]Epoch 400: Train Loss = 0.009849847294390202\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=352, train_loss_step=0.0121, train_loss_epoch=0.00985] Epoch 401: Train Loss = 0.01212347112596035\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=352, train_loss_step=0.00879, train_loss_epoch=0.0121]Epoch 402: Train Loss = 0.008794178254902363\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=352, train_loss_step=0.00789, train_loss_epoch=0.00879]Epoch 403: Train Loss = 0.007892129942774773\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.00789] Epoch 404: Train Loss = 0.011564143933355808\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=352, train_loss_step=0.0107, train_loss_epoch=0.0116] Epoch 405: Train Loss = 0.010714774951338768\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=352, train_loss_step=0.0133, train_loss_epoch=0.0107]Epoch 406: Train Loss = 0.013255951926112175\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.0133]Epoch 407: Train Loss = 0.011769150383770466\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=352, train_loss_step=0.0132, train_loss_epoch=0.0118]Epoch 408: Train Loss = 0.013224451802670956\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=352, train_loss_step=0.0105, train_loss_epoch=0.0132]Epoch 409: Train Loss = 0.01048723328858614\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.0105]Epoch 410: Train Loss = 0.010436207056045532\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=352, train_loss_step=0.00996, train_loss_epoch=0.0104]Epoch 411: Train Loss = 0.009957464411854744\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=352, train_loss_step=0.00998, train_loss_epoch=0.00996]Epoch 412: Train Loss = 0.009981733746826649\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=352, train_loss_step=0.0183, train_loss_epoch=0.00998] Epoch 413: Train Loss = 0.01833631470799446\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=352, train_loss_step=0.0124, train_loss_epoch=0.0183] Epoch 414: Train Loss = 0.012449423782527447\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=352, train_loss_step=0.0127, train_loss_epoch=0.0124]Epoch 415: Train Loss = 0.012729079462587833\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0127]Epoch 416: Train Loss = 0.013135789893567562\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=352, train_loss_step=0.0128, train_loss_epoch=0.0131]Epoch 417: Train Loss = 0.012798963114619255\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=352, train_loss_step=0.0115, train_loss_epoch=0.0128]Epoch 418: Train Loss = 0.011452381499111652\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.0115]Epoch 419: Train Loss = 0.010443637147545815\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.0104]Epoch 420: Train Loss = 0.0112727927044034\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.0113]Epoch 421: Train Loss = 0.011288600042462349\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=352, train_loss_step=0.0121, train_loss_epoch=0.0113]Epoch 422: Train Loss = 0.012051423080265522\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=352, train_loss_step=0.00851, train_loss_epoch=0.0121]Epoch 423: Train Loss = 0.008514241315424442\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=352, train_loss_step=0.0126, train_loss_epoch=0.00851] Epoch 424: Train Loss = 0.012565822340548038\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=352, train_loss_step=0.0139, train_loss_epoch=0.0126] Epoch 425: Train Loss = 0.013887690380215645\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=352, train_loss_step=0.0112, train_loss_epoch=0.0139]Epoch 426: Train Loss = 0.011247728951275349\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=352, train_loss_step=0.0115, train_loss_epoch=0.0112]Epoch 427: Train Loss = 0.011543167755007744\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=352, train_loss_step=0.012, train_loss_epoch=0.0115] Epoch 428: Train Loss = 0.011952576227486134\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=352, train_loss_step=0.0117, train_loss_epoch=0.012]Epoch 429: Train Loss = 0.011730092577636242\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0117]Epoch 430: Train Loss = 0.011083320714533329\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=352, train_loss_step=0.0134, train_loss_epoch=0.0111]Epoch 431: Train Loss = 0.013428093865513802\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 10.08it/s, v_num=352, train_loss_step=0.00996, train_loss_epoch=0.0134]Epoch 432: Train Loss = 0.009955435991287231\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=352, train_loss_step=0.00989, train_loss_epoch=0.00996]Epoch 433: Train Loss = 0.00988748949021101\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=352, train_loss_step=0.0105, train_loss_epoch=0.00989] Epoch 434: Train Loss = 0.010508645325899124\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=352, train_loss_step=0.0111, train_loss_epoch=0.0105] Epoch 435: Train Loss = 0.011082828976213932\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=352, train_loss_step=0.0135, train_loss_epoch=0.0111]Epoch 436: Train Loss = 0.013545019552111626\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=352, train_loss_step=0.0119, train_loss_epoch=0.0135]Epoch 437: Train Loss = 0.011857266537845135\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=352, train_loss_step=0.00944, train_loss_epoch=0.0119]Epoch 438: Train Loss = 0.009437535889446735\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s, v_num=352, train_loss_step=0.00918, train_loss_epoch=0.00944]Epoch 439: Train Loss = 0.009179441258311272\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=352, train_loss_step=0.0116, train_loss_epoch=0.00918] Epoch 440: Train Loss = 0.011596141383051872\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=352, train_loss_step=0.00898, train_loss_epoch=0.0116]Epoch 441: Train Loss = 0.008984887972474098\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=352, train_loss_step=0.0114, train_loss_epoch=0.00898] Epoch 442: Train Loss = 0.011372262611985207\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.0114] Epoch 443: Train Loss = 0.0104116415604949\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=352, train_loss_step=0.0156, train_loss_epoch=0.0104]Epoch 444: Train Loss = 0.015588345937430859\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=352, train_loss_step=0.00997, train_loss_epoch=0.0156]Epoch 445: Train Loss = 0.009974286891520023\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=352, train_loss_step=0.0181, train_loss_epoch=0.00997] Epoch 446: Train Loss = 0.018068816512823105\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=352, train_loss_step=0.00985, train_loss_epoch=0.0181]Epoch 447: Train Loss = 0.009849880822002888\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.00985] Epoch 448: Train Loss = 0.0104100676253438\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=352, train_loss_step=0.0106, train_loss_epoch=0.0104] Epoch 449: Train Loss = 0.010553142055869102\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=352, train_loss_step=0.0107, train_loss_epoch=0.0106]Epoch 450: Train Loss = 0.010677127167582512\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s, v_num=352, train_loss_step=0.0109, train_loss_epoch=0.0107]Epoch 451: Train Loss = 0.010902127251029015\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=352, train_loss_step=0.00977, train_loss_epoch=0.0109]Epoch 452: Train Loss = 0.009771601296961308\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.00977] Epoch 453: Train Loss = 0.011267454363405704\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.0113] Epoch 454: Train Loss = 0.011321314610540867\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=352, train_loss_step=0.0186, train_loss_epoch=0.0113]Epoch 455: Train Loss = 0.018571054562926292\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=352, train_loss_step=0.00944, train_loss_epoch=0.0186]Epoch 456: Train Loss = 0.009441486559808254\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.00944] Epoch 457: Train Loss = 0.011338208802044392\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=352, train_loss_step=0.0142, train_loss_epoch=0.0113] Epoch 458: Train Loss = 0.014212146401405334\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  9.42it/s, v_num=352, train_loss_step=0.0115, train_loss_epoch=0.0142]Epoch 459: Train Loss = 0.011450898833572865\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=352, train_loss_step=0.00988, train_loss_epoch=0.0115]Epoch 460: Train Loss = 0.009879651479423046\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=352, train_loss_step=0.011, train_loss_epoch=0.00988]  Epoch 461: Train Loss = 0.010970483534038067\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=352, train_loss_step=0.0108, train_loss_epoch=0.011] Epoch 462: Train Loss = 0.010784887708723545\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=352, train_loss_step=0.0112, train_loss_epoch=0.0108]Epoch 463: Train Loss = 0.011179213412106037\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=352, train_loss_step=0.0137, train_loss_epoch=0.0112]Epoch 464: Train Loss = 0.013682845048606396\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=352, train_loss_step=0.0103, train_loss_epoch=0.0137]Epoch 465: Train Loss = 0.010264553129673004\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=352, train_loss_step=0.0121, train_loss_epoch=0.0103]Epoch 466: Train Loss = 0.012128480710089207\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=352, train_loss_step=0.0142, train_loss_epoch=0.0121]Epoch 467: Train Loss = 0.014227292500436306\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=352, train_loss_step=0.0117, train_loss_epoch=0.0142]Epoch 468: Train Loss = 0.011672204360365868\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=352, train_loss_step=0.00948, train_loss_epoch=0.0117]Epoch 469: Train Loss = 0.009481959044933319\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.00948] Epoch 470: Train Loss = 0.0112539604306221\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=352, train_loss_step=0.0142, train_loss_epoch=0.0113] Epoch 471: Train Loss = 0.01420100498944521\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=352, train_loss_step=0.0163, train_loss_epoch=0.0142]Epoch 472: Train Loss = 0.016290873289108276\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=352, train_loss_step=0.0149, train_loss_epoch=0.0163]Epoch 473: Train Loss = 0.014948219060897827\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.0149]Epoch 474: Train Loss = 0.011816286481916904\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=352, train_loss_step=0.0138, train_loss_epoch=0.0118]Epoch 475: Train Loss = 0.013827667571604252\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=352, train_loss_step=0.0122, train_loss_epoch=0.0138]Epoch 476: Train Loss = 0.012184469029307365\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=352, train_loss_step=0.0135, train_loss_epoch=0.0122]Epoch 477: Train Loss = 0.01348169893026352\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=352, train_loss_step=0.0121, train_loss_epoch=0.0135]Epoch 478: Train Loss = 0.012068488635122776\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=352, train_loss_step=0.0113, train_loss_epoch=0.0121]Epoch 479: Train Loss = 0.011282703839242458\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=352, train_loss_step=0.0118, train_loss_epoch=0.0113]Epoch 480: Train Loss = 0.011835113167762756\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=352, train_loss_step=0.0132, train_loss_epoch=0.0118]Epoch 481: Train Loss = 0.013153684325516224\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=352, train_loss_step=0.0153, train_loss_epoch=0.0132]Epoch 482: Train Loss = 0.015314505435526371\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=352, train_loss_step=0.0106, train_loss_epoch=0.0153]Epoch 483: Train Loss = 0.010562635026872158\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=352, train_loss_step=0.0104, train_loss_epoch=0.0106]Epoch 484: Train Loss = 0.010384933091700077\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=352, train_loss_step=0.0103, train_loss_epoch=0.0104]Epoch 485: Train Loss = 0.010293685831129551\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=352, train_loss_step=0.0126, train_loss_epoch=0.0103]Epoch 486: Train Loss = 0.012594157829880714\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=352, train_loss_step=0.00952, train_loss_epoch=0.0126]Epoch 487: Train Loss = 0.009521749801933765\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=352, train_loss_step=0.0112, train_loss_epoch=0.00952] Epoch 488: Train Loss = 0.01117604412138462\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=352, train_loss_step=0.0134, train_loss_epoch=0.0112] Epoch 489: Train Loss = 0.013370229862630367\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=352, train_loss_step=0.0146, train_loss_epoch=0.0134]Epoch 490: Train Loss = 0.014560608193278313\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=352, train_loss_step=0.0159, train_loss_epoch=0.0146]Epoch 491: Train Loss = 0.015932584181427956\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s, v_num=352, train_loss_step=0.0131, train_loss_epoch=0.0159]Epoch 492: Train Loss = 0.013113109394907951\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 11.68it/s, v_num=352, train_loss_step=0.011, train_loss_epoch=0.0131] Epoch 493: Train Loss = 0.01103472150862217\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=352, train_loss_step=0.0099, train_loss_epoch=0.011]Epoch 494: Train Loss = 0.00989861786365509\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=352, train_loss_step=0.0153, train_loss_epoch=0.0099]Epoch 495: Train Loss = 0.01526289526373148\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=352, train_loss_step=0.0119, train_loss_epoch=0.0153]Epoch 496: Train Loss = 0.011940333060920238\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s, v_num=352, train_loss_step=0.0136, train_loss_epoch=0.0119]Epoch 497: Train Loss = 0.013596632517874241\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=352, train_loss_step=0.0124, train_loss_epoch=0.0136]Epoch 498: Train Loss = 0.01236841268837452\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=352, train_loss_step=0.0106, train_loss_epoch=0.0124]Epoch 499: Train Loss = 0.010571968741714954\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=352, train_loss_step=0.0106, train_loss_epoch=0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=352, train_loss_step=0.0106, train_loss_epoch=0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 18: from 2010-06-30 00:00:00 to 2022-12-14 00:00:00\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=356, train_loss_step=0.0308]Epoch 0: Train Loss = 0.030831605195999146\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=356, train_loss_step=0.0493, train_loss_epoch=0.0308]Epoch 1: Train Loss = 0.04929235577583313\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=356, train_loss_step=0.0276, train_loss_epoch=0.0493]Epoch 2: Train Loss = 0.027613705024123192\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=356, train_loss_step=0.0222, train_loss_epoch=0.0276]Epoch 3: Train Loss = 0.022190703079104424\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=356, train_loss_step=0.0209, train_loss_epoch=0.0222]Epoch 4: Train Loss = 0.020878123119473457\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=356, train_loss_step=0.0216, train_loss_epoch=0.0209]Epoch 5: Train Loss = 0.021641304716467857\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=356, train_loss_step=0.0208, train_loss_epoch=0.0216]Epoch 6: Train Loss = 0.020837480202317238\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=356, train_loss_step=0.0161, train_loss_epoch=0.0208]Epoch 7: Train Loss = 0.01610768772661686\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=356, train_loss_step=0.0149, train_loss_epoch=0.0161]Epoch 8: Train Loss = 0.014862850308418274\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=356, train_loss_step=0.0185, train_loss_epoch=0.0149]Epoch 9: Train Loss = 0.018456770107150078\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=356, train_loss_step=0.0161, train_loss_epoch=0.0185]Epoch 10: Train Loss = 0.016088077798485756\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=356, train_loss_step=0.0177, train_loss_epoch=0.0161]Epoch 11: Train Loss = 0.017704512923955917\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=356, train_loss_step=0.0145, train_loss_epoch=0.0177]Epoch 12: Train Loss = 0.014541451819241047\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=356, train_loss_step=0.0227, train_loss_epoch=0.0145]Epoch 13: Train Loss = 0.02267608977854252\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0227]Epoch 14: Train Loss = 0.012851851060986519\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=356, train_loss_step=0.0115, train_loss_epoch=0.0129]Epoch 15: Train Loss = 0.01149712037295103\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=356, train_loss_step=0.0138, train_loss_epoch=0.0115]Epoch 16: Train Loss = 0.013767155818641186\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0138]Epoch 17: Train Loss = 0.014240317977964878\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=356, train_loss_step=0.0199, train_loss_epoch=0.0142]Epoch 18: Train Loss = 0.01987353526055813\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=356, train_loss_step=0.0131, train_loss_epoch=0.0199]Epoch 19: Train Loss = 0.01309984177350998\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=356, train_loss_step=0.0148, train_loss_epoch=0.0131]Epoch 20: Train Loss = 0.014849744737148285\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=356, train_loss_step=0.0179, train_loss_epoch=0.0148]Epoch 21: Train Loss = 0.017922384664416313\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=356, train_loss_step=0.0125, train_loss_epoch=0.0179]Epoch 22: Train Loss = 0.01247279904782772\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.0125]Epoch 23: Train Loss = 0.012744189240038395\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=356, train_loss_step=0.0167, train_loss_epoch=0.0127]Epoch 24: Train Loss = 0.016689812764525414\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=356, train_loss_step=0.0229, train_loss_epoch=0.0167]Epoch 25: Train Loss = 0.022894933819770813\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=356, train_loss_step=0.0149, train_loss_epoch=0.0229]Epoch 26: Train Loss = 0.01490073837339878\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0149]Epoch 27: Train Loss = 0.01423648651689291\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=356, train_loss_step=0.0138, train_loss_epoch=0.0142]Epoch 28: Train Loss = 0.013831236399710178\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=356, train_loss_step=0.0177, train_loss_epoch=0.0138]Epoch 29: Train Loss = 0.017678184434771538\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=356, train_loss_step=0.0137, train_loss_epoch=0.0177]Epoch 30: Train Loss = 0.013694529421627522\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0137]Epoch 31: Train Loss = 0.012356767430901527\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=356, train_loss_step=0.0141, train_loss_epoch=0.0124]Epoch 32: Train Loss = 0.014066637493669987\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=356, train_loss_step=0.0141, train_loss_epoch=0.0141]Epoch 33: Train Loss = 0.014068533666431904\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=356, train_loss_step=0.0135, train_loss_epoch=0.0141]Epoch 34: Train Loss = 0.01350960973650217\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=356, train_loss_step=0.0144, train_loss_epoch=0.0135]Epoch 35: Train Loss = 0.01441134698688984\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=356, train_loss_step=0.0185, train_loss_epoch=0.0144]Epoch 36: Train Loss = 0.01852363534271717\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=356, train_loss_step=0.0176, train_loss_epoch=0.0185]Epoch 37: Train Loss = 0.017633041366934776\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=356, train_loss_step=0.0143, train_loss_epoch=0.0176]Epoch 38: Train Loss = 0.014265143312513828\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=356, train_loss_step=0.016, train_loss_epoch=0.0143] Epoch 39: Train Loss = 0.016046786680817604\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=356, train_loss_step=0.0123, train_loss_epoch=0.016]Epoch 40: Train Loss = 0.01231906283646822\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=356, train_loss_step=0.0169, train_loss_epoch=0.0123]Epoch 41: Train Loss = 0.01694287173449993\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.0169]Epoch 42: Train Loss = 0.012725003995001316\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0127]Epoch 43: Train Loss = 0.012384963221848011\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=356, train_loss_step=0.0136, train_loss_epoch=0.0124]Epoch 44: Train Loss = 0.01355838868767023\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=356, train_loss_step=0.0121, train_loss_epoch=0.0136]Epoch 45: Train Loss = 0.012094304896891117\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=356, train_loss_step=0.0166, train_loss_epoch=0.0121]Epoch 46: Train Loss = 0.016591042280197144\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=356, train_loss_step=0.0117, train_loss_epoch=0.0166]Epoch 47: Train Loss = 0.011726854369044304\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0117]Epoch 48: Train Loss = 0.01421565655618906\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=356, train_loss_step=0.0168, train_loss_epoch=0.0142]Epoch 49: Train Loss = 0.016778219491243362\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  9.60it/s, v_num=356, train_loss_step=0.0109, train_loss_epoch=0.0168]Epoch 50: Train Loss = 0.010939253494143486\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=356, train_loss_step=0.0146, train_loss_epoch=0.0109]Epoch 51: Train Loss = 0.014585505239665508\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=356, train_loss_step=0.0161, train_loss_epoch=0.0146]Epoch 52: Train Loss = 0.016067028045654297\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=356, train_loss_step=0.0179, train_loss_epoch=0.0161]Epoch 53: Train Loss = 0.017893200740218163\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=356, train_loss_step=0.013, train_loss_epoch=0.0179] Epoch 54: Train Loss = 0.012987450696527958\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=356, train_loss_step=0.0098, train_loss_epoch=0.013]Epoch 55: Train Loss = 0.00979641079902649\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=356, train_loss_step=0.0154, train_loss_epoch=0.0098]Epoch 56: Train Loss = 0.015399576164782047\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  3.46it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.0154]Epoch 57: Train Loss = 0.010553115978837013\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=356, train_loss_step=0.0143, train_loss_epoch=0.0106]Epoch 58: Train Loss = 0.01430326234549284\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=356, train_loss_step=0.0139, train_loss_epoch=0.0143]Epoch 59: Train Loss = 0.013872944749891758\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=356, train_loss_step=0.0176, train_loss_epoch=0.0139]Epoch 60: Train Loss = 0.017624707892537117\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=356, train_loss_step=0.0139, train_loss_epoch=0.0176]Epoch 61: Train Loss = 0.013872762210667133\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=356, train_loss_step=0.0114, train_loss_epoch=0.0139]Epoch 62: Train Loss = 0.011425341479480267\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=356, train_loss_step=0.0134, train_loss_epoch=0.0114]Epoch 63: Train Loss = 0.01343872956931591\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=356, train_loss_step=0.0141, train_loss_epoch=0.0134]Epoch 64: Train Loss = 0.014088870026171207\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=356, train_loss_step=0.0118, train_loss_epoch=0.0141]Epoch 65: Train Loss = 0.011787241324782372\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=356, train_loss_step=0.0113, train_loss_epoch=0.0118]Epoch 66: Train Loss = 0.011328296735882759\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=356, train_loss_step=0.0139, train_loss_epoch=0.0113]Epoch 67: Train Loss = 0.013868369162082672\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=356, train_loss_step=0.0104, train_loss_epoch=0.0139]Epoch 68: Train Loss = 0.010390530340373516\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0104]Epoch 69: Train Loss = 0.012922468595206738\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0129]Epoch 70: Train Loss = 0.014196211472153664\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=356, train_loss_step=0.0162, train_loss_epoch=0.0142]Epoch 71: Train Loss = 0.016161946579813957\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=356, train_loss_step=0.0139, train_loss_epoch=0.0162]Epoch 72: Train Loss = 0.013856478035449982\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=356, train_loss_step=0.0128, train_loss_epoch=0.0139]Epoch 73: Train Loss = 0.012822123244404793\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=356, train_loss_step=0.0148, train_loss_epoch=0.0128]Epoch 74: Train Loss = 0.014802125282585621\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=356, train_loss_step=0.013, train_loss_epoch=0.0148] Epoch 75: Train Loss = 0.012971381656825542\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=356, train_loss_step=0.0125, train_loss_epoch=0.013]Epoch 76: Train Loss = 0.012486343272030354\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=356, train_loss_step=0.0132, train_loss_epoch=0.0125]Epoch 77: Train Loss = 0.013190791010856628\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=356, train_loss_step=0.0122, train_loss_epoch=0.0132]Epoch 78: Train Loss = 0.012233170680701733\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=356, train_loss_step=0.0132, train_loss_epoch=0.0122]Epoch 79: Train Loss = 0.013217945583164692\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=356, train_loss_step=0.0186, train_loss_epoch=0.0132]Epoch 80: Train Loss = 0.018574487417936325\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=356, train_loss_step=0.0115, train_loss_epoch=0.0186]Epoch 81: Train Loss = 0.011538272723555565\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=356, train_loss_step=0.0135, train_loss_epoch=0.0115]Epoch 82: Train Loss = 0.013515042141079903\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=356, train_loss_step=0.0172, train_loss_epoch=0.0135]Epoch 83: Train Loss = 0.017180534079670906\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=356, train_loss_step=0.0134, train_loss_epoch=0.0172]Epoch 84: Train Loss = 0.013434021733701229\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=356, train_loss_step=0.0137, train_loss_epoch=0.0134]Epoch 85: Train Loss = 0.013732150197029114\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=356, train_loss_step=0.0137, train_loss_epoch=0.0137]Epoch 86: Train Loss = 0.013658511452376842\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=356, train_loss_step=0.014, train_loss_epoch=0.0137] Epoch 87: Train Loss = 0.013966173864901066\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 12.32it/s, v_num=356, train_loss_step=0.0104, train_loss_epoch=0.014]Epoch 88: Train Loss = 0.010441693477332592\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=356, train_loss_step=0.0165, train_loss_epoch=0.0104]Epoch 89: Train Loss = 0.016506191343069077\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=356, train_loss_step=0.0154, train_loss_epoch=0.0165]Epoch 90: Train Loss = 0.015434210188686848\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 11.27it/s, v_num=356, train_loss_step=0.0135, train_loss_epoch=0.0154]Epoch 91: Train Loss = 0.013539649546146393\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=356, train_loss_step=0.0131, train_loss_epoch=0.0135]Epoch 92: Train Loss = 0.013113937340676785\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=356, train_loss_step=0.0167, train_loss_epoch=0.0131]Epoch 93: Train Loss = 0.016682516783475876\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=356, train_loss_step=0.00918, train_loss_epoch=0.0167]Epoch 94: Train Loss = 0.009179011918604374\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.00918] Epoch 95: Train Loss = 0.010640113614499569\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=356, train_loss_step=0.0125, train_loss_epoch=0.0106] Epoch 96: Train Loss = 0.01248479075729847\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=356, train_loss_step=0.0118, train_loss_epoch=0.0125]Epoch 97: Train Loss = 0.011755796149373055\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.0118]Epoch 98: Train Loss = 0.01271593663841486\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0127]Epoch 99: Train Loss = 0.014221484772861004\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0142]Epoch 100: Train Loss = 0.013347452506422997\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=356, train_loss_step=0.0125, train_loss_epoch=0.0133]Epoch 101: Train Loss = 0.012476526200771332\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=356, train_loss_step=0.0151, train_loss_epoch=0.0125]Epoch 102: Train Loss = 0.015121287666261196\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=356, train_loss_step=0.0126, train_loss_epoch=0.0151]Epoch 103: Train Loss = 0.01256216038018465\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=356, train_loss_step=0.0159, train_loss_epoch=0.0126]Epoch 104: Train Loss = 0.015919502824544907\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.0159]Epoch 105: Train Loss = 0.012672552838921547\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=356, train_loss_step=0.0122, train_loss_epoch=0.0127]Epoch 106: Train Loss = 0.012189428322017193\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=356, train_loss_step=0.0109, train_loss_epoch=0.0122]Epoch 107: Train Loss = 0.010874432511627674\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=356, train_loss_step=0.0083, train_loss_epoch=0.0109]Epoch 108: Train Loss = 0.00829743780195713\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=356, train_loss_step=0.0108, train_loss_epoch=0.0083]Epoch 109: Train Loss = 0.0107990438118577\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=356, train_loss_step=0.0144, train_loss_epoch=0.0108]Epoch 110: Train Loss = 0.01444639265537262\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.0144]Epoch 111: Train Loss = 0.010637578554451466\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=356, train_loss_step=0.0119, train_loss_epoch=0.0106]Epoch 112: Train Loss = 0.011899258010089397\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=356, train_loss_step=0.0116, train_loss_epoch=0.0119]Epoch 113: Train Loss = 0.011592855677008629\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=356, train_loss_step=0.0097, train_loss_epoch=0.0116]Epoch 114: Train Loss = 0.009700433351099491\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=356, train_loss_step=0.0116, train_loss_epoch=0.0097]Epoch 115: Train Loss = 0.01155902910977602\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=356, train_loss_step=0.0147, train_loss_epoch=0.0116]Epoch 116: Train Loss = 0.014665588736534119\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=356, train_loss_step=0.0125, train_loss_epoch=0.0147]Epoch 117: Train Loss = 0.012496904470026493\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=356, train_loss_step=0.0157, train_loss_epoch=0.0125]Epoch 118: Train Loss = 0.015664229169487953\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=356, train_loss_step=0.0115, train_loss_epoch=0.0157]Epoch 119: Train Loss = 0.011544954963028431\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=356, train_loss_step=0.0128, train_loss_epoch=0.0115]Epoch 120: Train Loss = 0.012774108909070492\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=356, train_loss_step=0.0117, train_loss_epoch=0.0128]Epoch 121: Train Loss = 0.011748050339519978\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=356, train_loss_step=0.014, train_loss_epoch=0.0117] Epoch 122: Train Loss = 0.014039154164493084\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=356, train_loss_step=0.0149, train_loss_epoch=0.014]Epoch 123: Train Loss = 0.01487895380705595\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.0149]Epoch 124: Train Loss = 0.010559790767729282\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=356, train_loss_step=0.0157, train_loss_epoch=0.0106]Epoch 125: Train Loss = 0.01573336310684681\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=356, train_loss_step=0.0174, train_loss_epoch=0.0157]Epoch 126: Train Loss = 0.01742730475962162\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s, v_num=356, train_loss_step=0.0136, train_loss_epoch=0.0174]Epoch 127: Train Loss = 0.013636966235935688\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=356, train_loss_step=0.0141, train_loss_epoch=0.0136]Epoch 128: Train Loss = 0.014119172468781471\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=356, train_loss_step=0.0118, train_loss_epoch=0.0141]Epoch 129: Train Loss = 0.01181926392018795\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=356, train_loss_step=0.0148, train_loss_epoch=0.0118]Epoch 130: Train Loss = 0.01481608860194683\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0148]Epoch 131: Train Loss = 0.012432646937668324\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=356, train_loss_step=0.0097, train_loss_epoch=0.0124]Epoch 132: Train Loss = 0.009703715331852436\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=356, train_loss_step=0.0118, train_loss_epoch=0.0097]Epoch 133: Train Loss = 0.011801193468272686\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.0118]Epoch 134: Train Loss = 0.012748569250106812\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=356, train_loss_step=0.0223, train_loss_epoch=0.0127]Epoch 135: Train Loss = 0.02225947380065918\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s, v_num=356, train_loss_step=0.0146, train_loss_epoch=0.0223]Epoch 136: Train Loss = 0.014579757116734982\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=356, train_loss_step=0.0149, train_loss_epoch=0.0146]Epoch 137: Train Loss = 0.01494560670107603\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=356, train_loss_step=0.0198, train_loss_epoch=0.0149]Epoch 138: Train Loss = 0.01979142799973488\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=356, train_loss_step=0.0178, train_loss_epoch=0.0198]Epoch 139: Train Loss = 0.017841925844550133\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=356, train_loss_step=0.0118, train_loss_epoch=0.0178]Epoch 140: Train Loss = 0.01184565294533968\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=356, train_loss_step=0.0147, train_loss_epoch=0.0118]Epoch 141: Train Loss = 0.014686997048556805\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=356, train_loss_step=0.0121, train_loss_epoch=0.0147]Epoch 142: Train Loss = 0.01206776313483715\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0121]Epoch 143: Train Loss = 0.012887273915112019\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=356, train_loss_step=0.0161, train_loss_epoch=0.0129]Epoch 144: Train Loss = 0.016092892736196518\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=356, train_loss_step=0.0139, train_loss_epoch=0.0161]Epoch 145: Train Loss = 0.013942965306341648\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0139]Epoch 146: Train Loss = 0.012915666215121746\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=356, train_loss_step=0.0141, train_loss_epoch=0.0129]Epoch 147: Train Loss = 0.014125811867415905\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0141]Epoch 148: Train Loss = 0.013339417986571789\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=356, train_loss_step=0.0112, train_loss_epoch=0.0133]Epoch 149: Train Loss = 0.011156899854540825\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, v_num=356, train_loss_step=0.0104, train_loss_epoch=0.0112]Epoch 150: Train Loss = 0.010366597212851048\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0104]Epoch 151: Train Loss = 0.012419686652719975\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=356, train_loss_step=0.0112, train_loss_epoch=0.0124]Epoch 152: Train Loss = 0.011169813573360443\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=356, train_loss_step=0.0158, train_loss_epoch=0.0112]Epoch 153: Train Loss = 0.015786807984113693\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=356, train_loss_step=0.013, train_loss_epoch=0.0158] Epoch 154: Train Loss = 0.013016334734857082\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=356, train_loss_step=0.0112, train_loss_epoch=0.013]Epoch 155: Train Loss = 0.011165169067680836\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=356, train_loss_step=0.0141, train_loss_epoch=0.0112]Epoch 156: Train Loss = 0.014116877689957619\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0141]Epoch 157: Train Loss = 0.012411156669259071\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=356, train_loss_step=0.0122, train_loss_epoch=0.0124]Epoch 158: Train Loss = 0.012184656225144863\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=356, train_loss_step=0.0138, train_loss_epoch=0.0122]Epoch 159: Train Loss = 0.013761475682258606\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 13.64it/s, v_num=356, train_loss_step=0.0101, train_loss_epoch=0.0138]Epoch 160: Train Loss = 0.010128958150744438\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.0101]Epoch 161: Train Loss = 0.012742994353175163\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=356, train_loss_step=0.0092, train_loss_epoch=0.0127]Epoch 162: Train Loss = 0.009197956882417202\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0092]Epoch 163: Train Loss = 0.013280603103339672\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=356, train_loss_step=0.0145, train_loss_epoch=0.0133]Epoch 164: Train Loss = 0.014528137631714344\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=356, train_loss_step=0.0146, train_loss_epoch=0.0145]Epoch 165: Train Loss = 0.014562247321009636\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=356, train_loss_step=0.0204, train_loss_epoch=0.0146]Epoch 166: Train Loss = 0.020356416702270508\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=356, train_loss_step=0.0134, train_loss_epoch=0.0204]Epoch 167: Train Loss = 0.013423869386315346\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 10.94it/s, v_num=356, train_loss_step=0.0102, train_loss_epoch=0.0134]Epoch 168: Train Loss = 0.010227590799331665\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=356, train_loss_step=0.0179, train_loss_epoch=0.0102]Epoch 169: Train Loss = 0.01790454611182213\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=356, train_loss_step=0.0112, train_loss_epoch=0.0179]Epoch 170: Train Loss = 0.011179143562912941\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=356, train_loss_step=0.0147, train_loss_epoch=0.0112]Epoch 171: Train Loss = 0.01467992179095745\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0147]Epoch 172: Train Loss = 0.01325803343206644\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=356, train_loss_step=0.0113, train_loss_epoch=0.0133]Epoch 173: Train Loss = 0.011272020637989044\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=356, train_loss_step=0.012, train_loss_epoch=0.0113] Epoch 174: Train Loss = 0.011993318796157837\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=356, train_loss_step=0.0197, train_loss_epoch=0.012]Epoch 175: Train Loss = 0.01974574849009514\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=356, train_loss_step=0.011, train_loss_epoch=0.0197] Epoch 176: Train Loss = 0.010974697768688202\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=356, train_loss_step=0.0157, train_loss_epoch=0.011]Epoch 177: Train Loss = 0.015713825821876526\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=356, train_loss_step=0.0131, train_loss_epoch=0.0157]Epoch 178: Train Loss = 0.013079528696835041\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=356, train_loss_step=0.016, train_loss_epoch=0.0131] Epoch 179: Train Loss = 0.016022246330976486\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=356, train_loss_step=0.0139, train_loss_epoch=0.016]Epoch 180: Train Loss = 0.013878241181373596\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=356, train_loss_step=0.0138, train_loss_epoch=0.0139]Epoch 181: Train Loss = 0.01375057827681303\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=356, train_loss_step=0.0163, train_loss_epoch=0.0138]Epoch 182: Train Loss = 0.016277527436614037\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0163]Epoch 183: Train Loss = 0.014195251278579235\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=356, train_loss_step=0.0111, train_loss_epoch=0.0142]Epoch 184: Train Loss = 0.011050811968743801\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0111]Epoch 185: Train Loss = 0.013327427208423615\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0133]Epoch 186: Train Loss = 0.014181087724864483\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=356, train_loss_step=0.00921, train_loss_epoch=0.0142]Epoch 187: Train Loss = 0.009208922274410725\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=356, train_loss_step=0.014, train_loss_epoch=0.00921]  Epoch 188: Train Loss = 0.013972350396215916\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=356, train_loss_step=0.0102, train_loss_epoch=0.014] Epoch 189: Train Loss = 0.010165376588702202\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=356, train_loss_step=0.0115, train_loss_epoch=0.0102]Epoch 190: Train Loss = 0.01145892683416605\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=356, train_loss_step=0.0138, train_loss_epoch=0.0115]Epoch 191: Train Loss = 0.013839111663401127\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=356, train_loss_step=0.013, train_loss_epoch=0.0138] Epoch 192: Train Loss = 0.012993148528039455\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=356, train_loss_step=0.0137, train_loss_epoch=0.013]Epoch 193: Train Loss = 0.01369448471814394\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0137]Epoch 194: Train Loss = 0.013280444778501987\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=356, train_loss_step=0.012, train_loss_epoch=0.0133] Epoch 195: Train Loss = 0.011984684504568577\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=356, train_loss_step=0.0144, train_loss_epoch=0.012]Epoch 196: Train Loss = 0.014379234984517097\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=356, train_loss_step=0.0126, train_loss_epoch=0.0144]Epoch 197: Train Loss = 0.012637312524020672\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=356, train_loss_step=0.0154, train_loss_epoch=0.0126]Epoch 198: Train Loss = 0.015385786071419716\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=356, train_loss_step=0.0152, train_loss_epoch=0.0154]Epoch 199: Train Loss = 0.015213116072118282\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=356, train_loss_step=0.00945, train_loss_epoch=0.0152]Epoch 200: Train Loss = 0.009448586963117123\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.00945] Epoch 201: Train Loss = 0.01265629567205906\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=356, train_loss_step=0.0204, train_loss_epoch=0.0127] Epoch 202: Train Loss = 0.020409448072314262\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0204]Epoch 203: Train Loss = 0.013268105685710907\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=356, train_loss_step=0.0122, train_loss_epoch=0.0133]Epoch 204: Train Loss = 0.012185524217784405\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=356, train_loss_step=0.0136, train_loss_epoch=0.0122]Epoch 205: Train Loss = 0.013565375469624996\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0136]Epoch 206: Train Loss = 0.014204606413841248\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=356, train_loss_step=0.0141, train_loss_epoch=0.0142]Epoch 207: Train Loss = 0.014128901064395905\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=356, train_loss_step=0.0125, train_loss_epoch=0.0141]Epoch 208: Train Loss = 0.012475545518100262\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=356, train_loss_step=0.0195, train_loss_epoch=0.0125]Epoch 209: Train Loss = 0.019531985744833946\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=356, train_loss_step=0.0171, train_loss_epoch=0.0195]Epoch 210: Train Loss = 0.017074164003133774\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=356, train_loss_step=0.013, train_loss_epoch=0.0171] Epoch 211: Train Loss = 0.012977324426174164\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=356, train_loss_step=0.0123, train_loss_epoch=0.013]Epoch 212: Train Loss = 0.012307331897318363\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=356, train_loss_step=0.013, train_loss_epoch=0.0123] Epoch 213: Train Loss = 0.01300682220607996\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=356, train_loss_step=0.0115, train_loss_epoch=0.013]Epoch 214: Train Loss = 0.011525549925863743\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=356, train_loss_step=0.0126, train_loss_epoch=0.0115]Epoch 215: Train Loss = 0.012562842108309269\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.0126]Epoch 216: Train Loss = 0.010611829347908497\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=356, train_loss_step=0.0183, train_loss_epoch=0.0106]Epoch 217: Train Loss = 0.018328072503209114\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=356, train_loss_step=0.017, train_loss_epoch=0.0183] Epoch 218: Train Loss = 0.017032233998179436\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=356, train_loss_step=0.0138, train_loss_epoch=0.017]Epoch 219: Train Loss = 0.01377067156136036\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0138]Epoch 220: Train Loss = 0.012854664586484432\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.0129]Epoch 221: Train Loss = 0.012715322896838188\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=356, train_loss_step=0.00927, train_loss_epoch=0.0127]Epoch 222: Train Loss = 0.009274041280150414\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.00927] Epoch 223: Train Loss = 0.012749156914651394\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=356, train_loss_step=0.00988, train_loss_epoch=0.0127]Epoch 224: Train Loss = 0.009882993996143341\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=356, train_loss_step=0.0121, train_loss_epoch=0.00988] Epoch 225: Train Loss = 0.012142597697675228\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=356, train_loss_step=0.0151, train_loss_epoch=0.0121] Epoch 226: Train Loss = 0.015098458155989647\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=356, train_loss_step=0.0145, train_loss_epoch=0.0151]Epoch 227: Train Loss = 0.014512176625430584\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=356, train_loss_step=0.0158, train_loss_epoch=0.0145]Epoch 228: Train Loss = 0.01578715816140175\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0158]Epoch 229: Train Loss = 0.012354000471532345\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=356, train_loss_step=0.0119, train_loss_epoch=0.0124]Epoch 230: Train Loss = 0.011919112876057625\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=356, train_loss_step=0.011, train_loss_epoch=0.0119] Epoch 231: Train Loss = 0.011036989279091358\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=356, train_loss_step=0.015, train_loss_epoch=0.011] Epoch 232: Train Loss = 0.01495891623198986\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=356, train_loss_step=0.0153, train_loss_epoch=0.015]Epoch 233: Train Loss = 0.015299917198717594\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=356, train_loss_step=0.0108, train_loss_epoch=0.0153]Epoch 234: Train Loss = 0.01075421180576086\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=356, train_loss_step=0.0125, train_loss_epoch=0.0108]Epoch 235: Train Loss = 0.012478960677981377\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=356, train_loss_step=0.0121, train_loss_epoch=0.0125]Epoch 236: Train Loss = 0.012148912064731121\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0121]Epoch 237: Train Loss = 0.012390532530844212\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=356, train_loss_step=0.0126, train_loss_epoch=0.0124]Epoch 238: Train Loss = 0.012634790502488613\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=356, train_loss_step=0.017, train_loss_epoch=0.0126] Epoch 239: Train Loss = 0.016956260427832603\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=356, train_loss_step=0.0152, train_loss_epoch=0.017]Epoch 240: Train Loss = 0.015205582603812218\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=356, train_loss_step=0.0227, train_loss_epoch=0.0152]Epoch 241: Train Loss = 0.022651461884379387\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0227]Epoch 242: Train Loss = 0.01334458775818348\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=356, train_loss_step=0.0178, train_loss_epoch=0.0133]Epoch 243: Train Loss = 0.017816973850131035\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=356, train_loss_step=0.0143, train_loss_epoch=0.0178]Epoch 244: Train Loss = 0.014259793795645237\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s, v_num=356, train_loss_step=0.0105, train_loss_epoch=0.0143]Epoch 245: Train Loss = 0.0104984687641263\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=356, train_loss_step=0.0163, train_loss_epoch=0.0105]Epoch 246: Train Loss = 0.016302525997161865\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=356, train_loss_step=0.0112, train_loss_epoch=0.0163]Epoch 247: Train Loss = 0.011196864768862724\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=356, train_loss_step=0.0132, train_loss_epoch=0.0112]Epoch 248: Train Loss = 0.013217153027653694\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=356, train_loss_step=0.0125, train_loss_epoch=0.0132]Epoch 249: Train Loss = 0.012535945512354374\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=356, train_loss_step=0.0145, train_loss_epoch=0.0125]Epoch 250: Train Loss = 0.014477302320301533\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=356, train_loss_step=0.0126, train_loss_epoch=0.0145]Epoch 251: Train Loss = 0.012567938305437565\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=356, train_loss_step=0.0151, train_loss_epoch=0.0126]Epoch 252: Train Loss = 0.015072875656187534\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.0151]Epoch 253: Train Loss = 0.010642877779901028\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=356, train_loss_step=0.0105, train_loss_epoch=0.0106]Epoch 254: Train Loss = 0.010539106093347073\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=356, train_loss_step=0.0123, train_loss_epoch=0.0105]Epoch 255: Train Loss = 0.012297664768993855\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=356, train_loss_step=0.0105, train_loss_epoch=0.0123]Epoch 256: Train Loss = 0.010529113933444023\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.0105]Epoch 257: Train Loss = 0.012655915692448616\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=356, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 258: Train Loss = 0.012034651823341846\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=356, train_loss_step=0.0122, train_loss_epoch=0.012]Epoch 259: Train Loss = 0.012210275046527386\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=356, train_loss_step=0.0111, train_loss_epoch=0.0122]Epoch 260: Train Loss = 0.011104091070592403\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=356, train_loss_step=0.0115, train_loss_epoch=0.0111]Epoch 261: Train Loss = 0.011537895537912846\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=356, train_loss_step=0.0113, train_loss_epoch=0.0115]Epoch 262: Train Loss = 0.011333822272717953\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=356, train_loss_step=0.0116, train_loss_epoch=0.0113]Epoch 263: Train Loss = 0.011599543504416943\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=356, train_loss_step=0.0162, train_loss_epoch=0.0116]Epoch 264: Train Loss = 0.0162359606474638\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0162]Epoch 265: Train Loss = 0.012352880090475082\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=356, train_loss_step=0.00942, train_loss_epoch=0.0124]Epoch 266: Train Loss = 0.009418929927051067\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=356, train_loss_step=0.0155, train_loss_epoch=0.00942] Epoch 267: Train Loss = 0.015456795692443848\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=356, train_loss_step=0.0119, train_loss_epoch=0.0155] Epoch 268: Train Loss = 0.011887616477906704\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=356, train_loss_step=0.0145, train_loss_epoch=0.0119]Epoch 269: Train Loss = 0.014528384432196617\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=356, train_loss_step=0.0132, train_loss_epoch=0.0145]Epoch 270: Train Loss = 0.013168576173484325\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=356, train_loss_step=0.0153, train_loss_epoch=0.0132]Epoch 271: Train Loss = 0.015332506969571114\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=356, train_loss_step=0.0166, train_loss_epoch=0.0153]Epoch 272: Train Loss = 0.016550865024328232\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=356, train_loss_step=0.00993, train_loss_epoch=0.0166]Epoch 273: Train Loss = 0.00993222463876009\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=356, train_loss_step=0.0183, train_loss_epoch=0.00993] Epoch 274: Train Loss = 0.018277067691087723\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s, v_num=356, train_loss_step=0.0179, train_loss_epoch=0.0183] Epoch 275: Train Loss = 0.017940187826752663\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0179]Epoch 276: Train Loss = 0.014172779396176338\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=356, train_loss_step=0.0115, train_loss_epoch=0.0142]Epoch 277: Train Loss = 0.011501112952828407\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=356, train_loss_step=0.00926, train_loss_epoch=0.0115]Epoch 278: Train Loss = 0.009256589226424694\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=356, train_loss_step=0.00999, train_loss_epoch=0.00926]Epoch 279: Train Loss = 0.009987528435885906\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=356, train_loss_step=0.0117, train_loss_epoch=0.00999] Epoch 280: Train Loss = 0.011718657799065113\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=356, train_loss_step=0.0101, train_loss_epoch=0.0117] Epoch 281: Train Loss = 0.010064938105642796\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=356, train_loss_step=0.0111, train_loss_epoch=0.0101]Epoch 282: Train Loss = 0.011061890982091427\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=356, train_loss_step=0.0132, train_loss_epoch=0.0111]Epoch 283: Train Loss = 0.013180642388761044\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=356, train_loss_step=0.0138, train_loss_epoch=0.0132]Epoch 284: Train Loss = 0.01379495020955801\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=356, train_loss_step=0.0177, train_loss_epoch=0.0138]Epoch 285: Train Loss = 0.017717931419610977\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=356, train_loss_step=0.0147, train_loss_epoch=0.0177]Epoch 286: Train Loss = 0.01470032799988985\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=356, train_loss_step=0.0135, train_loss_epoch=0.0147]Epoch 287: Train Loss = 0.013532496057450771\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0135]Epoch 288: Train Loss = 0.012909943237900734\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0129]Epoch 289: Train Loss = 0.012924921698868275\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=356, train_loss_step=0.00949, train_loss_epoch=0.0129]Epoch 290: Train Loss = 0.009486262686550617\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=356, train_loss_step=0.0116, train_loss_epoch=0.00949] Epoch 291: Train Loss = 0.011588851921260357\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=356, train_loss_step=0.00981, train_loss_epoch=0.0116]Epoch 292: Train Loss = 0.00981476716697216\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 10.28it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.00981] Epoch 293: Train Loss = 0.010572021827101707\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=356, train_loss_step=0.0136, train_loss_epoch=0.0106] Epoch 294: Train Loss = 0.013640915043652058\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=356, train_loss_step=0.0128, train_loss_epoch=0.0136]Epoch 295: Train Loss = 0.01279197633266449\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=356, train_loss_step=0.0153, train_loss_epoch=0.0128]Epoch 296: Train Loss = 0.015346537344157696\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=356, train_loss_step=0.0101, train_loss_epoch=0.0153]Epoch 297: Train Loss = 0.010064064525067806\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=356, train_loss_step=0.0116, train_loss_epoch=0.0101]Epoch 298: Train Loss = 0.011618555523455143\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=356, train_loss_step=0.0105, train_loss_epoch=0.0116]Epoch 299: Train Loss = 0.010488064959645271\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=356, train_loss_step=0.017, train_loss_epoch=0.0105] Epoch 300: Train Loss = 0.0169886015355587\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=356, train_loss_step=0.013, train_loss_epoch=0.017] Epoch 301: Train Loss = 0.013007866218686104\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=356, train_loss_step=0.0205, train_loss_epoch=0.013]Epoch 302: Train Loss = 0.02050406113266945\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=356, train_loss_step=0.0119, train_loss_epoch=0.0205]Epoch 303: Train Loss = 0.011929883621633053\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=356, train_loss_step=0.0104, train_loss_epoch=0.0119]Epoch 304: Train Loss = 0.010397565551102161\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=356, train_loss_step=0.0104, train_loss_epoch=0.0104]Epoch 305: Train Loss = 0.01043825875967741\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=356, train_loss_step=0.0112, train_loss_epoch=0.0104]Epoch 306: Train Loss = 0.011194826103746891\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=356, train_loss_step=0.0126, train_loss_epoch=0.0112]Epoch 307: Train Loss = 0.012621158733963966\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0126]Epoch 308: Train Loss = 0.012361264787614346\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s, v_num=356, train_loss_step=0.0102, train_loss_epoch=0.0124]Epoch 309: Train Loss = 0.010210545733571053\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=356, train_loss_step=0.0122, train_loss_epoch=0.0102]Epoch 310: Train Loss = 0.012151564471423626\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s, v_num=356, train_loss_step=0.0132, train_loss_epoch=0.0122]Epoch 311: Train Loss = 0.013227545656263828\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=356, train_loss_step=0.0108, train_loss_epoch=0.0132]Epoch 312: Train Loss = 0.01079561561346054\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=356, train_loss_step=0.0104, train_loss_epoch=0.0108]Epoch 313: Train Loss = 0.010408884845674038\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=356, train_loss_step=0.0101, train_loss_epoch=0.0104]Epoch 314: Train Loss = 0.010104887187480927\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=356, train_loss_step=0.0101, train_loss_epoch=0.0101]Epoch 315: Train Loss = 0.010056192986667156\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=356, train_loss_step=0.011, train_loss_epoch=0.0101] Epoch 316: Train Loss = 0.011047239415347576\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=356, train_loss_step=0.0109, train_loss_epoch=0.011]Epoch 317: Train Loss = 0.010902969166636467\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=356, train_loss_step=0.0118, train_loss_epoch=0.0109]Epoch 318: Train Loss = 0.011771291494369507\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=356, train_loss_step=0.00945, train_loss_epoch=0.0118]Epoch 319: Train Loss = 0.009451255202293396\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.00945] Epoch 320: Train Loss = 0.013327250257134438\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=356, train_loss_step=0.0136, train_loss_epoch=0.0133] Epoch 321: Train Loss = 0.01355747040361166\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=356, train_loss_step=0.0147, train_loss_epoch=0.0136]Epoch 322: Train Loss = 0.014726825058460236\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=356, train_loss_step=0.0182, train_loss_epoch=0.0147]Epoch 323: Train Loss = 0.018180636689066887\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=356, train_loss_step=0.0103, train_loss_epoch=0.0182]Epoch 324: Train Loss = 0.010267895646393299\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=356, train_loss_step=0.0113, train_loss_epoch=0.0103]Epoch 325: Train Loss = 0.011272797361016273\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=356, train_loss_step=0.013, train_loss_epoch=0.0113] Epoch 326: Train Loss = 0.012972735799849033\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.013]Epoch 327: Train Loss = 0.012939835898578167\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 11.50it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.0129]Epoch 328: Train Loss = 0.01055888645350933\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=356, train_loss_step=0.0113, train_loss_epoch=0.0106]Epoch 329: Train Loss = 0.011283492669463158\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s, v_num=356, train_loss_step=0.0104, train_loss_epoch=0.0113]Epoch 330: Train Loss = 0.010409467853605747\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=356, train_loss_step=0.0144, train_loss_epoch=0.0104]Epoch 331: Train Loss = 0.014413065277040005\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=356, train_loss_step=0.0115, train_loss_epoch=0.0144]Epoch 332: Train Loss = 0.011452214792370796\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=356, train_loss_step=0.00989, train_loss_epoch=0.0115]Epoch 333: Train Loss = 0.009892658330500126\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=356, train_loss_step=0.0122, train_loss_epoch=0.00989] Epoch 334: Train Loss = 0.012154188938438892\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, v_num=356, train_loss_step=0.0119, train_loss_epoch=0.0122] Epoch 335: Train Loss = 0.01188218779861927\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=356, train_loss_step=0.0114, train_loss_epoch=0.0119]Epoch 336: Train Loss = 0.011396192014217377\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=356, train_loss_step=0.0107, train_loss_epoch=0.0114]Epoch 337: Train Loss = 0.010713529773056507\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=356, train_loss_step=0.0116, train_loss_epoch=0.0107]Epoch 338: Train Loss = 0.01158792246133089\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=356, train_loss_step=0.0138, train_loss_epoch=0.0116]Epoch 339: Train Loss = 0.013784474693238735\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=356, train_loss_step=0.0118, train_loss_epoch=0.0138]Epoch 340: Train Loss = 0.011761183850467205\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=356, train_loss_step=0.014, train_loss_epoch=0.0118] Epoch 341: Train Loss = 0.013992001302540302\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=356, train_loss_step=0.00942, train_loss_epoch=0.014]Epoch 342: Train Loss = 0.009420515969395638\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=356, train_loss_step=0.00873, train_loss_epoch=0.00942]Epoch 343: Train Loss = 0.008732072077691555\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=356, train_loss_step=0.00984, train_loss_epoch=0.00873]Epoch 344: Train Loss = 0.009838744066655636\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=356, train_loss_step=0.0107, train_loss_epoch=0.00984] Epoch 345: Train Loss = 0.010657740756869316\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=356, train_loss_step=0.00968, train_loss_epoch=0.0107]Epoch 346: Train Loss = 0.009675479494035244\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=356, train_loss_step=0.0108, train_loss_epoch=0.00968] Epoch 347: Train Loss = 0.010831487365067005\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=356, train_loss_step=0.0143, train_loss_epoch=0.0108] Epoch 348: Train Loss = 0.014268656261265278\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=356, train_loss_step=0.0111, train_loss_epoch=0.0143]Epoch 349: Train Loss = 0.011050069704651833\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=356, train_loss_step=0.0116, train_loss_epoch=0.0111]Epoch 350: Train Loss = 0.01158811990171671\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=356, train_loss_step=0.0122, train_loss_epoch=0.0116]Epoch 351: Train Loss = 0.012184461578726768\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0122]Epoch 352: Train Loss = 0.014176982454955578\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0142]Epoch 353: Train Loss = 0.01289329119026661\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=356, train_loss_step=0.0162, train_loss_epoch=0.0129]Epoch 354: Train Loss = 0.016198959201574326\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=356, train_loss_step=0.0135, train_loss_epoch=0.0162]Epoch 355: Train Loss = 0.013464043848216534\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=356, train_loss_step=0.0107, train_loss_epoch=0.0135]Epoch 356: Train Loss = 0.010747130028903484\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.0107]Epoch 357: Train Loss = 0.010614690370857716\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=356, train_loss_step=0.0117, train_loss_epoch=0.0106]Epoch 358: Train Loss = 0.01167982630431652\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=356, train_loss_step=0.00993, train_loss_epoch=0.0117]Epoch 359: Train Loss = 0.009928569197654724\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=356, train_loss_step=0.0147, train_loss_epoch=0.00993] Epoch 360: Train Loss = 0.014697079546749592\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=356, train_loss_step=0.0111, train_loss_epoch=0.0147] Epoch 361: Train Loss = 0.01108328253030777\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=356, train_loss_step=0.0128, train_loss_epoch=0.0111]Epoch 362: Train Loss = 0.012823020108044147\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=356, train_loss_step=0.00939, train_loss_epoch=0.0128]Epoch 363: Train Loss = 0.009387766011059284\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=356, train_loss_step=0.0123, train_loss_epoch=0.00939] Epoch 364: Train Loss = 0.012256711721420288\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=356, train_loss_step=0.0109, train_loss_epoch=0.0123] Epoch 365: Train Loss = 0.010927711613476276\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0109]Epoch 366: Train Loss = 0.013267620466649532\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=356, train_loss_step=0.013, train_loss_epoch=0.0133] Epoch 367: Train Loss = 0.013009251095354557\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=356, train_loss_step=0.0108, train_loss_epoch=0.013]Epoch 368: Train Loss = 0.010801088996231556\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0108]Epoch 369: Train Loss = 0.01290007121860981\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=356, train_loss_step=0.0155, train_loss_epoch=0.0129]Epoch 370: Train Loss = 0.015488113276660442\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=356, train_loss_step=0.0105, train_loss_epoch=0.0155]Epoch 371: Train Loss = 0.010450335219502449\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=356, train_loss_step=0.0114, train_loss_epoch=0.0105]Epoch 372: Train Loss = 0.011437901295721531\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=356, train_loss_step=0.0121, train_loss_epoch=0.0114]Epoch 373: Train Loss = 0.012110312469303608\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0121]Epoch 374: Train Loss = 0.013319158926606178\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=356, train_loss_step=0.0118, train_loss_epoch=0.0133]Epoch 375: Train Loss = 0.011754469014704227\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=356, train_loss_step=0.00979, train_loss_epoch=0.0118]Epoch 376: Train Loss = 0.009786712005734444\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=356, train_loss_step=0.0128, train_loss_epoch=0.00979] Epoch 377: Train Loss = 0.012782628647983074\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=356, train_loss_step=0.0139, train_loss_epoch=0.0128] Epoch 378: Train Loss = 0.013881884515285492\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s, v_num=356, train_loss_step=0.012, train_loss_epoch=0.0139] Epoch 379: Train Loss = 0.011970797553658485\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=356, train_loss_step=0.0103, train_loss_epoch=0.012]Epoch 380: Train Loss = 0.010268447920680046\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=356, train_loss_step=0.0123, train_loss_epoch=0.0103]Epoch 381: Train Loss = 0.012336693704128265\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=356, train_loss_step=0.0105, train_loss_epoch=0.0123]Epoch 382: Train Loss = 0.010480218566954136\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=356, train_loss_step=0.0113, train_loss_epoch=0.0105]Epoch 383: Train Loss = 0.011257003992795944\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=356, train_loss_step=0.0114, train_loss_epoch=0.0113]Epoch 384: Train Loss = 0.011428222060203552\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.0114]Epoch 385: Train Loss = 0.010621265508234501\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=356, train_loss_step=0.0136, train_loss_epoch=0.0106]Epoch 386: Train Loss = 0.013604114763438702\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=356, train_loss_step=0.0108, train_loss_epoch=0.0136]Epoch 387: Train Loss = 0.010782009921967983\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=356, train_loss_step=0.0146, train_loss_epoch=0.0108]Epoch 388: Train Loss = 0.014598376117646694\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=356, train_loss_step=0.0116, train_loss_epoch=0.0146]Epoch 389: Train Loss = 0.011611857451498508\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=356, train_loss_step=0.0107, train_loss_epoch=0.0116]Epoch 390: Train Loss = 0.010736484080553055\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=356, train_loss_step=0.0114, train_loss_epoch=0.0107]Epoch 391: Train Loss = 0.011406236328184605\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=356, train_loss_step=0.0186, train_loss_epoch=0.0114]Epoch 392: Train Loss = 0.018602047115564346\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=356, train_loss_step=0.0146, train_loss_epoch=0.0186]Epoch 393: Train Loss = 0.014647608622908592\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=356, train_loss_step=0.0157, train_loss_epoch=0.0146]Epoch 394: Train Loss = 0.015712477266788483\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=356, train_loss_step=0.0101, train_loss_epoch=0.0157]Epoch 395: Train Loss = 0.01011752150952816\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=356, train_loss_step=0.00958, train_loss_epoch=0.0101]Epoch 396: Train Loss = 0.009582137688994408\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=356, train_loss_step=0.0134, train_loss_epoch=0.00958] Epoch 397: Train Loss = 0.013351441361010075\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=356, train_loss_step=0.012, train_loss_epoch=0.0134]  Epoch 398: Train Loss = 0.011994659900665283\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=356, train_loss_step=0.0131, train_loss_epoch=0.012]Epoch 399: Train Loss = 0.013147330842912197\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=356, train_loss_step=0.00975, train_loss_epoch=0.0131]Epoch 400: Train Loss = 0.009753867983818054\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=356, train_loss_step=0.0131, train_loss_epoch=0.00975] Epoch 401: Train Loss = 0.013058326207101345\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0131] Epoch 402: Train Loss = 0.012882895767688751\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=356, train_loss_step=0.0151, train_loss_epoch=0.0129]Epoch 403: Train Loss = 0.015113107860088348\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=356, train_loss_step=0.0149, train_loss_epoch=0.0151]Epoch 404: Train Loss = 0.014907879754900932\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=356, train_loss_step=0.0125, train_loss_epoch=0.0149]Epoch 405: Train Loss = 0.012529230676591396\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=356, train_loss_step=0.0149, train_loss_epoch=0.0125]Epoch 406: Train Loss = 0.014949740841984749\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=356, train_loss_step=0.0141, train_loss_epoch=0.0149]Epoch 407: Train Loss = 0.014118621125817299\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=356, train_loss_step=0.0133, train_loss_epoch=0.0141]Epoch 408: Train Loss = 0.01329762488603592\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=356, train_loss_step=0.0164, train_loss_epoch=0.0133]Epoch 409: Train Loss = 0.01642809994518757\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=356, train_loss_step=0.0143, train_loss_epoch=0.0164]Epoch 410: Train Loss = 0.01430235244333744\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=356, train_loss_step=0.014, train_loss_epoch=0.0143] Epoch 411: Train Loss = 0.01399567723274231\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=356, train_loss_step=0.0109, train_loss_epoch=0.014]Epoch 412: Train Loss = 0.01090250164270401\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=356, train_loss_step=0.015, train_loss_epoch=0.0109] Epoch 413: Train Loss = 0.015027320943772793\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 10.36it/s, v_num=356, train_loss_step=0.0162, train_loss_epoch=0.015]Epoch 414: Train Loss = 0.01617971621453762\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=356, train_loss_step=0.016, train_loss_epoch=0.0162] Epoch 415: Train Loss = 0.01598632149398327\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.016]Epoch 416: Train Loss = 0.012689289636909962\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=356, train_loss_step=0.0114, train_loss_epoch=0.0127]Epoch 417: Train Loss = 0.01141794677823782\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=356, train_loss_step=0.0134, train_loss_epoch=0.0114]Epoch 418: Train Loss = 0.013377976603806019\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=356, train_loss_step=0.0176, train_loss_epoch=0.0134]Epoch 419: Train Loss = 0.017559843137860298\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=356, train_loss_step=0.016, train_loss_epoch=0.0176] Epoch 420: Train Loss = 0.01602218858897686\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=356, train_loss_step=0.0162, train_loss_epoch=0.016]Epoch 421: Train Loss = 0.01618960313498974\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s, v_num=356, train_loss_step=0.0134, train_loss_epoch=0.0162]Epoch 422: Train Loss = 0.013415873982012272\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=356, train_loss_step=0.015, train_loss_epoch=0.0134] Epoch 423: Train Loss = 0.014987834729254246\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=356, train_loss_step=0.0121, train_loss_epoch=0.015]Epoch 424: Train Loss = 0.01214685756713152\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=356, train_loss_step=0.0181, train_loss_epoch=0.0121]Epoch 425: Train Loss = 0.018100744113326073\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=356, train_loss_step=0.00965, train_loss_epoch=0.0181]Epoch 426: Train Loss = 0.009649836458265781\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=356, train_loss_step=0.014, train_loss_epoch=0.00965]  Epoch 427: Train Loss = 0.014018066227436066\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=356, train_loss_step=0.0173, train_loss_epoch=0.014] Epoch 428: Train Loss = 0.017276635393500328\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=356, train_loss_step=0.0146, train_loss_epoch=0.0173]Epoch 429: Train Loss = 0.014605831354856491\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=356, train_loss_step=0.0135, train_loss_epoch=0.0146]Epoch 430: Train Loss = 0.013469979166984558\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0135]Epoch 431: Train Loss = 0.012927472591400146\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=356, train_loss_step=0.0113, train_loss_epoch=0.0129]Epoch 432: Train Loss = 0.01134452037513256\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=356, train_loss_step=0.0149, train_loss_epoch=0.0113]Epoch 433: Train Loss = 0.014876137487590313\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=356, train_loss_step=0.0127, train_loss_epoch=0.0149]Epoch 434: Train Loss = 0.012715931050479412\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=356, train_loss_step=0.0105, train_loss_epoch=0.0127]Epoch 435: Train Loss = 0.010516638867557049\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=356, train_loss_step=0.0147, train_loss_epoch=0.0105]Epoch 436: Train Loss = 0.014685568399727345\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=356, train_loss_step=0.0113, train_loss_epoch=0.0147]Epoch 437: Train Loss = 0.01132762897759676\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=356, train_loss_step=0.0134, train_loss_epoch=0.0113]Epoch 438: Train Loss = 0.013436561450362206\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s, v_num=356, train_loss_step=0.00904, train_loss_epoch=0.0134]Epoch 439: Train Loss = 0.00904012005776167\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 11.61it/s, v_num=356, train_loss_step=0.0128, train_loss_epoch=0.00904] Epoch 440: Train Loss = 0.012806911952793598\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=356, train_loss_step=0.0101, train_loss_epoch=0.0128] Epoch 441: Train Loss = 0.010107249021530151\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, v_num=356, train_loss_step=0.0114, train_loss_epoch=0.0101]Epoch 442: Train Loss = 0.011411692015826702\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=356, train_loss_step=0.0111, train_loss_epoch=0.0114]Epoch 443: Train Loss = 0.011138142086565495\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=356, train_loss_step=0.0123, train_loss_epoch=0.0111]Epoch 444: Train Loss = 0.012314577586948872\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=356, train_loss_step=0.0118, train_loss_epoch=0.0123]Epoch 445: Train Loss = 0.011777556501328945\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=356, train_loss_step=0.0159, train_loss_epoch=0.0118]Epoch 446: Train Loss = 0.01586725004017353\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=356, train_loss_step=0.0138, train_loss_epoch=0.0159]Epoch 447: Train Loss = 0.013818860054016113\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=356, train_loss_step=0.0115, train_loss_epoch=0.0138]Epoch 448: Train Loss = 0.011499720625579357\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=356, train_loss_step=0.0136, train_loss_epoch=0.0115]Epoch 449: Train Loss = 0.013623401522636414\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=356, train_loss_step=0.0125, train_loss_epoch=0.0136]Epoch 450: Train Loss = 0.012489971704781055\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=356, train_loss_step=0.0103, train_loss_epoch=0.0125]Epoch 451: Train Loss = 0.010334561578929424\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=356, train_loss_step=0.011, train_loss_epoch=0.0103] Epoch 452: Train Loss = 0.010968923568725586\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=356, train_loss_step=0.0106, train_loss_epoch=0.011]Epoch 453: Train Loss = 0.010646621696650982\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0106]Epoch 454: Train Loss = 0.012425503693521023\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=356, train_loss_step=0.0174, train_loss_epoch=0.0124]Epoch 455: Train Loss = 0.0174472164362669\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=356, train_loss_step=0.0109, train_loss_epoch=0.0174]Epoch 456: Train Loss = 0.010892433114349842\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=356, train_loss_step=0.014, train_loss_epoch=0.0109] Epoch 457: Train Loss = 0.014025526121258736\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=356, train_loss_step=0.0131, train_loss_epoch=0.014]Epoch 458: Train Loss = 0.01311415433883667\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=356, train_loss_step=0.0124, train_loss_epoch=0.0131]Epoch 459: Train Loss = 0.012428832240402699\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=356, train_loss_step=0.0118, train_loss_epoch=0.0124]Epoch 460: Train Loss = 0.01180820632725954\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=356, train_loss_step=0.00991, train_loss_epoch=0.0118]Epoch 461: Train Loss = 0.009909647516906261\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=356, train_loss_step=0.00961, train_loss_epoch=0.00991]Epoch 462: Train Loss = 0.009607295505702496\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=356, train_loss_step=0.00953, train_loss_epoch=0.00961]Epoch 463: Train Loss = 0.009527534246444702\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=356, train_loss_step=0.0135, train_loss_epoch=0.00953] Epoch 464: Train Loss = 0.01347332913428545\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s, v_num=356, train_loss_step=0.011, train_loss_epoch=0.0135]  Epoch 465: Train Loss = 0.010980443097651005\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=356, train_loss_step=0.0115, train_loss_epoch=0.011]Epoch 466: Train Loss = 0.011507351882755756\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s, v_num=356, train_loss_step=0.0107, train_loss_epoch=0.0115]Epoch 467: Train Loss = 0.010748831555247307\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=356, train_loss_step=0.0142, train_loss_epoch=0.0107]Epoch 468: Train Loss = 0.014202907681465149\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=356, train_loss_step=0.0144, train_loss_epoch=0.0142]Epoch 469: Train Loss = 0.014418015256524086\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=356, train_loss_step=0.0117, train_loss_epoch=0.0144]Epoch 470: Train Loss = 0.011701441369950771\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0117]Epoch 471: Train Loss = 0.012946141883730888\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=356, train_loss_step=0.013, train_loss_epoch=0.0129] Epoch 472: Train Loss = 0.012979812920093536\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=356, train_loss_step=0.0141, train_loss_epoch=0.013]Epoch 473: Train Loss = 0.014086795039474964\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=356, train_loss_step=0.00904, train_loss_epoch=0.0141]Epoch 474: Train Loss = 0.009036819450557232\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=356, train_loss_step=0.0111, train_loss_epoch=0.00904] Epoch 475: Train Loss = 0.011098066344857216\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=356, train_loss_step=0.00965, train_loss_epoch=0.0111]Epoch 476: Train Loss = 0.009654438123106956\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=356, train_loss_step=0.00844, train_loss_epoch=0.00965]Epoch 477: Train Loss = 0.008440281264483929\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=356, train_loss_step=0.0121, train_loss_epoch=0.00844] Epoch 478: Train Loss = 0.012139608152210712\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=356, train_loss_step=0.0139, train_loss_epoch=0.0121] Epoch 479: Train Loss = 0.013913283124566078\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s, v_num=356, train_loss_step=0.0148, train_loss_epoch=0.0139]Epoch 480: Train Loss = 0.01478905975818634\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0148]Epoch 481: Train Loss = 0.012880498543381691\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=356, train_loss_step=0.0141, train_loss_epoch=0.0129]Epoch 482: Train Loss = 0.014102010056376457\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=356, train_loss_step=0.0123, train_loss_epoch=0.0141]Epoch 483: Train Loss = 0.01232545729726553\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=356, train_loss_step=0.0162, train_loss_epoch=0.0123]Epoch 484: Train Loss = 0.01623002626001835\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=356, train_loss_step=0.0117, train_loss_epoch=0.0162]Epoch 485: Train Loss = 0.011682822369039059\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=356, train_loss_step=0.00879, train_loss_epoch=0.0117]Epoch 486: Train Loss = 0.00878915749490261\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=356, train_loss_step=0.0188, train_loss_epoch=0.00879] Epoch 487: Train Loss = 0.018832847476005554\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=356, train_loss_step=0.0104, train_loss_epoch=0.0188] Epoch 488: Train Loss = 0.010413174517452717\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=356, train_loss_step=0.0177, train_loss_epoch=0.0104]Epoch 489: Train Loss = 0.017720399424433708\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=356, train_loss_step=0.0148, train_loss_epoch=0.0177]Epoch 490: Train Loss = 0.01481736171990633\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=356, train_loss_step=0.0114, train_loss_epoch=0.0148]Epoch 491: Train Loss = 0.01136824768036604\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=356, train_loss_step=0.0114, train_loss_epoch=0.0114]Epoch 492: Train Loss = 0.01144180167466402\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=356, train_loss_step=0.0139, train_loss_epoch=0.0114]Epoch 493: Train Loss = 0.013881335034966469\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=356, train_loss_step=0.0131, train_loss_epoch=0.0139]Epoch 494: Train Loss = 0.013127918355166912\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=356, train_loss_step=0.0129, train_loss_epoch=0.0131]Epoch 495: Train Loss = 0.012858890928328037\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s, v_num=356, train_loss_step=0.0136, train_loss_epoch=0.0129]Epoch 496: Train Loss = 0.01355890091508627\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=356, train_loss_step=0.0108, train_loss_epoch=0.0136]Epoch 497: Train Loss = 0.01082193199545145\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=356, train_loss_step=0.0166, train_loss_epoch=0.0108]Epoch 498: Train Loss = 0.016600215807557106\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=356, train_loss_step=0.0105, train_loss_epoch=0.0166]Epoch 499: Train Loss = 0.010489379055798054\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=356, train_loss_step=0.0105, train_loss_epoch=0.0105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=356, train_loss_step=0.0105, train_loss_epoch=0.0105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window 19: from 2010-06-30 00:00:00 to 2022-12-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0      | train\n",
      "1 | padder        | ConstantPad1d          | 0      | train\n",
      "2 | scaler        | TemporalNorm           | 0      | train\n",
      "3 | enc_embedding | DataEmbedding_inverted | 31.2 K | train\n",
      "4 | encoder       | TransEncoder           | 6.3 M  | train\n",
      "5 | projector     | Linear                 | 3.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.362    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=360, train_loss_step=0.0298]Epoch 0: Train Loss = 0.02980097569525242\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=360, train_loss_step=0.0405, train_loss_epoch=0.0298]Epoch 1: Train Loss = 0.04053184390068054\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s, v_num=360, train_loss_step=0.024, train_loss_epoch=0.0405] Epoch 2: Train Loss = 0.024000361561775208\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=360, train_loss_step=0.0213, train_loss_epoch=0.024]Epoch 3: Train Loss = 0.021340344101190567\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=360, train_loss_step=0.0178, train_loss_epoch=0.0213]Epoch 4: Train Loss = 0.017776193097233772\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=360, train_loss_step=0.0207, train_loss_epoch=0.0178]Epoch 5: Train Loss = 0.02070079743862152\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=360, train_loss_step=0.0127, train_loss_epoch=0.0207]Epoch 6: Train Loss = 0.012658855877816677\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=360, train_loss_step=0.0267, train_loss_epoch=0.0127]Epoch 7: Train Loss = 0.026671765372157097\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s, v_num=360, train_loss_step=0.0163, train_loss_epoch=0.0267]Epoch 8: Train Loss = 0.016345886513590813\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=360, train_loss_step=0.0287, train_loss_epoch=0.0163]Epoch 9: Train Loss = 0.02869473583996296\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=360, train_loss_step=0.022, train_loss_epoch=0.0287] Epoch 10: Train Loss = 0.02199713885784149\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=360, train_loss_step=0.0174, train_loss_epoch=0.022]Epoch 11: Train Loss = 0.017431650310754776\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=360, train_loss_step=0.0131, train_loss_epoch=0.0174]Epoch 12: Train Loss = 0.013107099570333958\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=360, train_loss_step=0.0188, train_loss_epoch=0.0131]Epoch 13: Train Loss = 0.018790248781442642\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=360, train_loss_step=0.0245, train_loss_epoch=0.0188]Epoch 14: Train Loss = 0.02453380823135376\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=360, train_loss_step=0.0186, train_loss_epoch=0.0245]Epoch 15: Train Loss = 0.018581071868538857\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=360, train_loss_step=0.0186, train_loss_epoch=0.0186]Epoch 16: Train Loss = 0.018552720546722412\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=360, train_loss_step=0.0159, train_loss_epoch=0.0186]Epoch 17: Train Loss = 0.01591789349913597\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=360, train_loss_step=0.0167, train_loss_epoch=0.0159]Epoch 18: Train Loss = 0.01674315147101879\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=360, train_loss_step=0.0173, train_loss_epoch=0.0167]Epoch 19: Train Loss = 0.017303071916103363\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=360, train_loss_step=0.0172, train_loss_epoch=0.0173]Epoch 20: Train Loss = 0.01719275675714016\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=360, train_loss_step=0.0173, train_loss_epoch=0.0172]Epoch 21: Train Loss = 0.01734052412211895\n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=360, train_loss_step=0.0175, train_loss_epoch=0.0173]Epoch 22: Train Loss = 0.017501231282949448\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=360, train_loss_step=0.0173, train_loss_epoch=0.0175]Epoch 23: Train Loss = 0.01725033111870289\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s, v_num=360, train_loss_step=0.0137, train_loss_epoch=0.0173]Epoch 24: Train Loss = 0.013701305724680424\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=360, train_loss_step=0.0117, train_loss_epoch=0.0137]Epoch 25: Train Loss = 0.01174481213092804\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=360, train_loss_step=0.0161, train_loss_epoch=0.0117]Epoch 26: Train Loss = 0.016112705692648888\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=360, train_loss_step=0.0176, train_loss_epoch=0.0161]Epoch 27: Train Loss = 0.017578113824129105\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=360, train_loss_step=0.0155, train_loss_epoch=0.0176]Epoch 28: Train Loss = 0.015495792962610722\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=360, train_loss_step=0.0144, train_loss_epoch=0.0155]Epoch 29: Train Loss = 0.014397731050848961\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=360, train_loss_step=0.0139, train_loss_epoch=0.0144]Epoch 30: Train Loss = 0.013886085711419582\n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=360, train_loss_step=0.0108, train_loss_epoch=0.0139]Epoch 31: Train Loss = 0.010751982219517231\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.0108]Epoch 32: Train Loss = 0.012366166338324547\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=360, train_loss_step=0.0146, train_loss_epoch=0.0124]Epoch 33: Train Loss = 0.014598658308386803\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=360, train_loss_step=0.0158, train_loss_epoch=0.0146]Epoch 34: Train Loss = 0.015838012099266052\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=360, train_loss_step=0.0145, train_loss_epoch=0.0158]Epoch 35: Train Loss = 0.014488394372165203\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.0145]Epoch 36: Train Loss = 0.011294945143163204\n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=360, train_loss_step=0.0127, train_loss_epoch=0.0113]Epoch 37: Train Loss = 0.012712224386632442\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=360, train_loss_step=0.012, train_loss_epoch=0.0127] Epoch 38: Train Loss = 0.01202152855694294\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.012] Epoch 39: Train Loss = 0.012951210141181946\n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=360, train_loss_step=0.0176, train_loss_epoch=0.013]Epoch 40: Train Loss = 0.017555300146341324\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=360, train_loss_step=0.0116, train_loss_epoch=0.0176]Epoch 41: Train Loss = 0.011636905372142792\n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=360, train_loss_step=0.0109, train_loss_epoch=0.0116]Epoch 42: Train Loss = 0.010868408717215061\n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.0109]Epoch 43: Train Loss = 0.013561352156102657\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=360, train_loss_step=0.0127, train_loss_epoch=0.0136]Epoch 44: Train Loss = 0.012651779688894749\n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.0127] Epoch 45: Train Loss = 0.012981065548956394\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=360, train_loss_step=0.0134, train_loss_epoch=0.013]Epoch 46: Train Loss = 0.013409541919827461\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=360, train_loss_step=0.014, train_loss_epoch=0.0134] Epoch 47: Train Loss = 0.013960831798613071\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=360, train_loss_step=0.0149, train_loss_epoch=0.014]Epoch 48: Train Loss = 0.014933362603187561\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=360, train_loss_step=0.0132, train_loss_epoch=0.0149]Epoch 49: Train Loss = 0.013194155879318714\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=360, train_loss_step=0.014, train_loss_epoch=0.0132] Epoch 50: Train Loss = 0.01401028037071228\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=360, train_loss_step=0.018, train_loss_epoch=0.014] Epoch 51: Train Loss = 0.018016895279288292\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.018]Epoch 52: Train Loss = 0.013590906746685505\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=360, train_loss_step=0.0203, train_loss_epoch=0.0136]Epoch 53: Train Loss = 0.02029806189239025\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=360, train_loss_step=0.0131, train_loss_epoch=0.0203]Epoch 54: Train Loss = 0.013120189309120178\n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=360, train_loss_step=0.00849, train_loss_epoch=0.0131]Epoch 55: Train Loss = 0.008489388041198254\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=360, train_loss_step=0.0119, train_loss_epoch=0.00849] Epoch 56: Train Loss = 0.011909643188118935\n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=360, train_loss_step=0.0163, train_loss_epoch=0.0119] Epoch 57: Train Loss = 0.016283702105283737\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=360, train_loss_step=0.0156, train_loss_epoch=0.0163]Epoch 58: Train Loss = 0.015626726672053337\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=360, train_loss_step=0.0152, train_loss_epoch=0.0156]Epoch 59: Train Loss = 0.015239241532981396\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=360, train_loss_step=0.012, train_loss_epoch=0.0152] Epoch 60: Train Loss = 0.012003692798316479\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=360, train_loss_step=0.0103, train_loss_epoch=0.012]Epoch 61: Train Loss = 0.010309150442481041\n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=360, train_loss_step=0.0151, train_loss_epoch=0.0103]Epoch 62: Train Loss = 0.0151486461982131\n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=360, train_loss_step=0.0138, train_loss_epoch=0.0151]Epoch 63: Train Loss = 0.0137800183147192\n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=360, train_loss_step=0.0169, train_loss_epoch=0.0138]Epoch 64: Train Loss = 0.016931405290961266\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=360, train_loss_step=0.0165, train_loss_epoch=0.0169]Epoch 65: Train Loss = 0.016544779762625694\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, v_num=360, train_loss_step=0.0109, train_loss_epoch=0.0165]Epoch 66: Train Loss = 0.010926240123808384\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=360, train_loss_step=0.0169, train_loss_epoch=0.0109]Epoch 67: Train Loss = 0.016937782987952232\n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=360, train_loss_step=0.0143, train_loss_epoch=0.0169]Epoch 68: Train Loss = 0.014318973757326603\n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.0143]Epoch 69: Train Loss = 0.011515302583575249\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=360, train_loss_step=0.0142, train_loss_epoch=0.0115]Epoch 70: Train Loss = 0.014226572588086128\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s, v_num=360, train_loss_step=0.012, train_loss_epoch=0.0142] Epoch 71: Train Loss = 0.012031619437038898\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=360, train_loss_step=0.0133, train_loss_epoch=0.012]Epoch 72: Train Loss = 0.013338154181838036\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, v_num=360, train_loss_step=0.015, train_loss_epoch=0.0133] Epoch 73: Train Loss = 0.014998904429376125\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=360, train_loss_step=0.0144, train_loss_epoch=0.015]Epoch 74: Train Loss = 0.014439755119383335\n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=360, train_loss_step=0.0153, train_loss_epoch=0.0144]Epoch 75: Train Loss = 0.015330709517002106\n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.0153] Epoch 76: Train Loss = 0.01297769881784916\n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.013]Epoch 77: Train Loss = 0.01214687991887331\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=360, train_loss_step=0.0127, train_loss_epoch=0.0121]Epoch 78: Train Loss = 0.012724438682198524\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=360, train_loss_step=0.0117, train_loss_epoch=0.0127]Epoch 79: Train Loss = 0.011691190302371979\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=360, train_loss_step=0.0151, train_loss_epoch=0.0117]Epoch 80: Train Loss = 0.015111875720322132\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=360, train_loss_step=0.0159, train_loss_epoch=0.0151]Epoch 81: Train Loss = 0.015859369188547134\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=360, train_loss_step=0.0104, train_loss_epoch=0.0159]Epoch 82: Train Loss = 0.010399815626442432\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.0104]Epoch 83: Train Loss = 0.01361092645674944\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=360, train_loss_step=0.00881, train_loss_epoch=0.0136]Epoch 84: Train Loss = 0.008805830031633377\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.00881] Epoch 85: Train Loss = 0.014144872315227985\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=360, train_loss_step=0.0128, train_loss_epoch=0.0141] Epoch 86: Train Loss = 0.012786343693733215\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=360, train_loss_step=0.0135, train_loss_epoch=0.0128]Epoch 87: Train Loss = 0.01351174060255289\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0135]Epoch 88: Train Loss = 0.01207210123538971\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=360, train_loss_step=0.0109, train_loss_epoch=0.0121]Epoch 89: Train Loss = 0.01087227463722229\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=360, train_loss_step=0.0133, train_loss_epoch=0.0109]Epoch 90: Train Loss = 0.013325602747499943\n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.0133]Epoch 91: Train Loss = 0.01154401246458292\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=360, train_loss_step=0.0131, train_loss_epoch=0.0115]Epoch 92: Train Loss = 0.013072356581687927\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=360, train_loss_step=0.0129, train_loss_epoch=0.0131]Epoch 93: Train Loss = 0.012941241264343262\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=360, train_loss_step=0.0205, train_loss_epoch=0.0129]Epoch 94: Train Loss = 0.020473405718803406\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=360, train_loss_step=0.00936, train_loss_epoch=0.0205]Epoch 95: Train Loss = 0.009359374642372131\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=360, train_loss_step=0.0143, train_loss_epoch=0.00936] Epoch 96: Train Loss = 0.014299268834292889\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.0143]  Epoch 97: Train Loss = 0.012959875166416168\n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=360, train_loss_step=0.0135, train_loss_epoch=0.013]Epoch 98: Train Loss = 0.013454451225697994\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.0135]Epoch 99: Train Loss = 0.014058636501431465\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=360, train_loss_step=0.0106, train_loss_epoch=0.0141]Epoch 100: Train Loss = 0.010613085702061653\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=360, train_loss_step=0.0147, train_loss_epoch=0.0106]Epoch 101: Train Loss = 0.014749363996088505\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.0147]Epoch 102: Train Loss = 0.011541277170181274\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=360, train_loss_step=0.0132, train_loss_epoch=0.0115]Epoch 103: Train Loss = 0.01322566531598568\n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=360, train_loss_step=0.0111, train_loss_epoch=0.0132]Epoch 104: Train Loss = 0.011055457405745983\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.0111]Epoch 105: Train Loss = 0.01235074270516634\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=360, train_loss_step=0.0156, train_loss_epoch=0.0124]Epoch 106: Train Loss = 0.015635451301932335\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=360, train_loss_step=0.0165, train_loss_epoch=0.0156]Epoch 107: Train Loss = 0.016488367691636086\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=360, train_loss_step=0.0174, train_loss_epoch=0.0165]Epoch 108: Train Loss = 0.01739925518631935\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=360, train_loss_step=0.0118, train_loss_epoch=0.0174]Epoch 109: Train Loss = 0.01182409469038248\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=360, train_loss_step=0.0169, train_loss_epoch=0.0118]Epoch 110: Train Loss = 0.016865311190485954\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=360, train_loss_step=0.0148, train_loss_epoch=0.0169]Epoch 111: Train Loss = 0.014781584963202477\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=360, train_loss_step=0.012, train_loss_epoch=0.0148] Epoch 112: Train Loss = 0.011953995563089848\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s, v_num=360, train_loss_step=0.0116, train_loss_epoch=0.012]Epoch 113: Train Loss = 0.011629834771156311\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=360, train_loss_step=0.0123, train_loss_epoch=0.0116]Epoch 114: Train Loss = 0.01229896117001772\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=360, train_loss_step=0.012, train_loss_epoch=0.0123] Epoch 115: Train Loss = 0.012022482231259346\n",
      "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.012]Epoch 116: Train Loss = 0.01358114741742611\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s, v_num=360, train_loss_step=0.0111, train_loss_epoch=0.0136]Epoch 117: Train Loss = 0.011082162149250507\n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=360, train_loss_step=0.0171, train_loss_epoch=0.0111]Epoch 118: Train Loss = 0.017130179330706596\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.0171]Epoch 119: Train Loss = 0.014065854251384735\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s, v_num=360, train_loss_step=0.00952, train_loss_epoch=0.0141]Epoch 120: Train Loss = 0.009524157270789146\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=360, train_loss_step=0.0155, train_loss_epoch=0.00952] Epoch 121: Train Loss = 0.015480617061257362\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=360, train_loss_step=0.0116, train_loss_epoch=0.0155] Epoch 122: Train Loss = 0.011616086587309837\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, v_num=360, train_loss_step=0.00951, train_loss_epoch=0.0116]Epoch 123: Train Loss = 0.009511111304163933\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.00951] Epoch 124: Train Loss = 0.012052305974066257\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=360, train_loss_step=0.00984, train_loss_epoch=0.0121]Epoch 125: Train Loss = 0.00983645860105753\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=360, train_loss_step=0.0155, train_loss_epoch=0.00984] Epoch 126: Train Loss = 0.015540244057774544\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=360, train_loss_step=0.016, train_loss_epoch=0.0155]  Epoch 127: Train Loss = 0.016008678823709488\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.016]Epoch 128: Train Loss = 0.014068479649722576\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.0141]Epoch 129: Train Loss = 0.013579248450696468\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.0136]Epoch 130: Train Loss = 0.011471006087958813\n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.0115]Epoch 131: Train Loss = 0.013576489873230457\n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s, v_num=360, train_loss_step=0.0106, train_loss_epoch=0.0136]Epoch 132: Train Loss = 0.010628066025674343\n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=360, train_loss_step=0.014, train_loss_epoch=0.0106] Epoch 133: Train Loss = 0.01401633583009243\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s, v_num=360, train_loss_step=0.014, train_loss_epoch=0.014] Epoch 134: Train Loss = 0.014017450623214245\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.014]Epoch 135: Train Loss = 0.011341741308569908\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=360, train_loss_step=0.0109, train_loss_epoch=0.0113]Epoch 136: Train Loss = 0.010938148014247417\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.0109]Epoch 137: Train Loss = 0.011265711858868599\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, v_num=360, train_loss_step=0.0123, train_loss_epoch=0.0113]Epoch 138: Train Loss = 0.012307950295507908\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=360, train_loss_step=0.0104, train_loss_epoch=0.0123]Epoch 139: Train Loss = 0.010366874746978283\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=360, train_loss_step=0.0118, train_loss_epoch=0.0104]Epoch 140: Train Loss = 0.011827146634459496\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=360, train_loss_step=0.0105, train_loss_epoch=0.0118]Epoch 141: Train Loss = 0.010493309237062931\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0105]Epoch 142: Train Loss = 0.012221680954098701\n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=360, train_loss_step=0.0118, train_loss_epoch=0.0122]Epoch 143: Train Loss = 0.011800708249211311\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=360, train_loss_step=0.011, train_loss_epoch=0.0118] Epoch 144: Train Loss = 0.011036669835448265\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=360, train_loss_step=0.0137, train_loss_epoch=0.011]Epoch 145: Train Loss = 0.01365853101015091\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=360, train_loss_step=0.0131, train_loss_epoch=0.0137]Epoch 146: Train Loss = 0.01305783074349165\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=360, train_loss_step=0.018, train_loss_epoch=0.0131] Epoch 147: Train Loss = 0.01803341507911682\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=360, train_loss_step=0.0145, train_loss_epoch=0.018]Epoch 148: Train Loss = 0.014456328935921192\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.0145] Epoch 149: Train Loss = 0.013035573065280914\n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=360, train_loss_step=0.0106, train_loss_epoch=0.013]Epoch 150: Train Loss = 0.01059760618954897\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.0106]Epoch 151: Train Loss = 0.013552355580031872\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=360, train_loss_step=0.0161, train_loss_epoch=0.0136]Epoch 152: Train Loss = 0.016073400154709816\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=360, train_loss_step=0.0108, train_loss_epoch=0.0161]Epoch 153: Train Loss = 0.01076540444046259\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=360, train_loss_step=0.0123, train_loss_epoch=0.0108]Epoch 154: Train Loss = 0.012348877266049385\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s, v_num=360, train_loss_step=0.0155, train_loss_epoch=0.0123]Epoch 155: Train Loss = 0.015543249435722828\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=360, train_loss_step=0.0128, train_loss_epoch=0.0155]Epoch 156: Train Loss = 0.012785914354026318\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=360, train_loss_step=0.0103, train_loss_epoch=0.0128]Epoch 157: Train Loss = 0.01027160044759512\n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=360, train_loss_step=0.0114, train_loss_epoch=0.0103]Epoch 158: Train Loss = 0.011411570943892002\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.0114]Epoch 159: Train Loss = 0.012436570599675179\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=360, train_loss_step=0.0102, train_loss_epoch=0.0124]Epoch 160: Train Loss = 0.010224658064544201\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=360, train_loss_step=0.0133, train_loss_epoch=0.0102]Epoch 161: Train Loss = 0.013349534012377262\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.0133]Epoch 162: Train Loss = 0.011314393021166325\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=360, train_loss_step=0.011, train_loss_epoch=0.0113] Epoch 163: Train Loss = 0.011034558527171612\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.011]Epoch 164: Train Loss = 0.011533359996974468\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s, v_num=360, train_loss_step=0.0108, train_loss_epoch=0.0115]Epoch 165: Train Loss = 0.01076269056648016\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=360, train_loss_step=0.0132, train_loss_epoch=0.0108]Epoch 166: Train Loss = 0.013153749518096447\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s, v_num=360, train_loss_step=0.0128, train_loss_epoch=0.0132]Epoch 167: Train Loss = 0.01281717699021101\n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, v_num=360, train_loss_step=0.0126, train_loss_epoch=0.0128]Epoch 168: Train Loss = 0.012608708813786507\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 12.37it/s, v_num=360, train_loss_step=0.0134, train_loss_epoch=0.0126]Epoch 169: Train Loss = 0.013425127603113651\n",
      "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.0134]Epoch 170: Train Loss = 0.011280599050223827\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=360, train_loss_step=0.0125, train_loss_epoch=0.0113]Epoch 171: Train Loss = 0.01246671937406063\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0125]Epoch 172: Train Loss = 0.012082304805517197\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=360, train_loss_step=0.0194, train_loss_epoch=0.0121]Epoch 173: Train Loss = 0.019408464431762695\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=360, train_loss_step=0.0129, train_loss_epoch=0.0194]Epoch 174: Train Loss = 0.012870758771896362\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, v_num=360, train_loss_step=0.0116, train_loss_epoch=0.0129]Epoch 175: Train Loss = 0.011639805510640144\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0116]Epoch 176: Train Loss = 0.012210461311042309\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=360, train_loss_step=0.0176, train_loss_epoch=0.0122]Epoch 177: Train Loss = 0.01762341894209385\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.0176]Epoch 178: Train Loss = 0.01242899615317583\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=360, train_loss_step=0.0144, train_loss_epoch=0.0124]Epoch 179: Train Loss = 0.014429797418415546\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=360, train_loss_step=0.0175, train_loss_epoch=0.0144]Epoch 180: Train Loss = 0.01754666492342949\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=360, train_loss_step=0.0135, train_loss_epoch=0.0175]Epoch 181: Train Loss = 0.013487903401255608\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=360, train_loss_step=0.0138, train_loss_epoch=0.0135]Epoch 182: Train Loss = 0.013842030428349972\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=360, train_loss_step=0.0156, train_loss_epoch=0.0138]Epoch 183: Train Loss = 0.015583544969558716\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=360, train_loss_step=0.0119, train_loss_epoch=0.0156]Epoch 184: Train Loss = 0.01193892303854227\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=360, train_loss_step=0.0128, train_loss_epoch=0.0119]Epoch 185: Train Loss = 0.012829716317355633\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=360, train_loss_step=0.0185, train_loss_epoch=0.0128]Epoch 186: Train Loss = 0.018457965925335884\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=360, train_loss_step=0.00979, train_loss_epoch=0.0185]Epoch 187: Train Loss = 0.00978651363402605\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, v_num=360, train_loss_step=0.0184, train_loss_epoch=0.00979] Epoch 188: Train Loss = 0.01842888817191124\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=360, train_loss_step=0.0126, train_loss_epoch=0.0184] Epoch 189: Train Loss = 0.012648930773139\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=360, train_loss_step=0.0137, train_loss_epoch=0.0126]Epoch 190: Train Loss = 0.01368516031652689\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=360, train_loss_step=0.0101, train_loss_epoch=0.0137]Epoch 191: Train Loss = 0.010121463797986507\n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.0101]Epoch 192: Train Loss = 0.01355221401900053\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s, v_num=360, train_loss_step=0.0112, train_loss_epoch=0.0136]Epoch 193: Train Loss = 0.011175830848515034\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.0112]Epoch 194: Train Loss = 0.012405349873006344\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=360, train_loss_step=0.0146, train_loss_epoch=0.0124]Epoch 195: Train Loss = 0.014635705389082432\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=360, train_loss_step=0.0133, train_loss_epoch=0.0146]Epoch 196: Train Loss = 0.013332679867744446\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=360, train_loss_step=0.0139, train_loss_epoch=0.0133]Epoch 197: Train Loss = 0.013941165991127491\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=360, train_loss_step=0.0153, train_loss_epoch=0.0139]Epoch 198: Train Loss = 0.01534811407327652\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=360, train_loss_step=0.0111, train_loss_epoch=0.0153]Epoch 199: Train Loss = 0.011068986728787422\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s, v_num=360, train_loss_step=0.0101, train_loss_epoch=0.0111]Epoch 200: Train Loss = 0.010078607127070427\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=360, train_loss_step=0.0126, train_loss_epoch=0.0101]Epoch 201: Train Loss = 0.012643053196370602\n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s, v_num=360, train_loss_step=0.0128, train_loss_epoch=0.0126]Epoch 202: Train Loss = 0.012817434035241604\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=360, train_loss_step=0.0139, train_loss_epoch=0.0128]Epoch 203: Train Loss = 0.013937384821474552\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=360, train_loss_step=0.0178, train_loss_epoch=0.0139]Epoch 204: Train Loss = 0.017762165516614914\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=360, train_loss_step=0.0158, train_loss_epoch=0.0178]Epoch 205: Train Loss = 0.015792082995176315\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=360, train_loss_step=0.0175, train_loss_epoch=0.0158]Epoch 206: Train Loss = 0.017468871548771858\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s, v_num=360, train_loss_step=0.0162, train_loss_epoch=0.0175]Epoch 207: Train Loss = 0.01620188169181347\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=360, train_loss_step=0.0117, train_loss_epoch=0.0162]Epoch 208: Train Loss = 0.011748227290809155\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=360, train_loss_step=0.0126, train_loss_epoch=0.0117]Epoch 209: Train Loss = 0.01263794768601656\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=360, train_loss_step=0.0129, train_loss_epoch=0.0126]Epoch 210: Train Loss = 0.012860363349318504\n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=360, train_loss_step=0.00864, train_loss_epoch=0.0129]Epoch 211: Train Loss = 0.008637191727757454\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=360, train_loss_step=0.0165, train_loss_epoch=0.00864] Epoch 212: Train Loss = 0.016490085050463676\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=360, train_loss_step=0.0183, train_loss_epoch=0.0165] Epoch 213: Train Loss = 0.018332619220018387\n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=360, train_loss_step=0.0161, train_loss_epoch=0.0183]Epoch 214: Train Loss = 0.01605839654803276\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.0161]Epoch 215: Train Loss = 0.01237475872039795\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.0124]Epoch 216: Train Loss = 0.013645552098751068\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0136]Epoch 217: Train Loss = 0.012148761190474033\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 10.68it/s, v_num=360, train_loss_step=0.0134, train_loss_epoch=0.0121]Epoch 218: Train Loss = 0.013395781628787518\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=360, train_loss_step=0.0177, train_loss_epoch=0.0134]Epoch 219: Train Loss = 0.017693227156996727\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=360, train_loss_step=0.0109, train_loss_epoch=0.0177]Epoch 220: Train Loss = 0.010925382375717163\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=360, train_loss_step=0.00909, train_loss_epoch=0.0109]Epoch 221: Train Loss = 0.00908983126282692\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=360, train_loss_step=0.0158, train_loss_epoch=0.00909] Epoch 222: Train Loss = 0.015764715149998665\n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=360, train_loss_step=0.0149, train_loss_epoch=0.0158] Epoch 223: Train Loss = 0.014936921186745167\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=360, train_loss_step=0.0155, train_loss_epoch=0.0149]Epoch 224: Train Loss = 0.015468987636268139\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=360, train_loss_step=0.0139, train_loss_epoch=0.0155]Epoch 225: Train Loss = 0.013930803164839745\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=360, train_loss_step=0.0197, train_loss_epoch=0.0139]Epoch 226: Train Loss = 0.019730644300580025\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=360, train_loss_step=0.0108, train_loss_epoch=0.0197]Epoch 227: Train Loss = 0.010782303288578987\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=360, train_loss_step=0.011, train_loss_epoch=0.0108] Epoch 228: Train Loss = 0.011018171906471252\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=360, train_loss_step=0.0111, train_loss_epoch=0.011]Epoch 229: Train Loss = 0.011095973663032055\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0111]Epoch 230: Train Loss = 0.012169033288955688\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=360, train_loss_step=0.0144, train_loss_epoch=0.0122]Epoch 231: Train Loss = 0.014436359517276287\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.0144]Epoch 232: Train Loss = 0.0112635912373662\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=360, train_loss_step=0.0117, train_loss_epoch=0.0113]Epoch 233: Train Loss = 0.011665740981698036\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=360, train_loss_step=0.0119, train_loss_epoch=0.0117]Epoch 234: Train Loss = 0.011923253536224365\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=360, train_loss_step=0.0131, train_loss_epoch=0.0119]Epoch 235: Train Loss = 0.013107205741107464\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=360, train_loss_step=0.0103, train_loss_epoch=0.0131]Epoch 236: Train Loss = 0.010304519906640053\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=360, train_loss_step=0.0126, train_loss_epoch=0.0103]Epoch 237: Train Loss = 0.01260146964341402\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=360, train_loss_step=0.0176, train_loss_epoch=0.0126]Epoch 238: Train Loss = 0.01763099431991577\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=360, train_loss_step=0.0118, train_loss_epoch=0.0176]Epoch 239: Train Loss = 0.011836415156722069\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0118]Epoch 240: Train Loss = 0.012214760296046734\n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0122]Epoch 241: Train Loss = 0.012182424776256084\n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=360, train_loss_step=0.0132, train_loss_epoch=0.0122]Epoch 242: Train Loss = 0.013233036734163761\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=360, train_loss_step=0.00959, train_loss_epoch=0.0132]Epoch 243: Train Loss = 0.009589090943336487\n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.00959] Epoch 244: Train Loss = 0.011483706533908844\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=360, train_loss_step=0.00903, train_loss_epoch=0.0115]Epoch 245: Train Loss = 0.00902580562978983\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s, v_num=360, train_loss_step=0.0118, train_loss_epoch=0.00903] Epoch 246: Train Loss = 0.011761472560465336\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=360, train_loss_step=0.017, train_loss_epoch=0.0118]  Epoch 247: Train Loss = 0.016960343345999718\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=360, train_loss_step=0.012, train_loss_epoch=0.017] Epoch 248: Train Loss = 0.011965597979724407\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=360, train_loss_step=0.0184, train_loss_epoch=0.012]Epoch 249: Train Loss = 0.01837795414030552\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=360, train_loss_step=0.0165, train_loss_epoch=0.0184]Epoch 250: Train Loss = 0.016514355316758156\n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=360, train_loss_step=0.0156, train_loss_epoch=0.0165]Epoch 251: Train Loss = 0.015564755536615849\n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=360, train_loss_step=0.0119, train_loss_epoch=0.0156]Epoch 252: Train Loss = 0.011924812570214272\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=360, train_loss_step=0.0111, train_loss_epoch=0.0119]Epoch 253: Train Loss = 0.011136353947222233\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=360, train_loss_step=0.0112, train_loss_epoch=0.0111]Epoch 254: Train Loss = 0.011213268153369427\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0112]Epoch 255: Train Loss = 0.012215946801006794\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0122]Epoch 256: Train Loss = 0.012214353308081627\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.0122]Epoch 257: Train Loss = 0.013555447570979595\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=360, train_loss_step=0.0123, train_loss_epoch=0.0136]Epoch 258: Train Loss = 0.012307162396609783\n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 11.42it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0123]Epoch 259: Train Loss = 0.012243157252669334\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=360, train_loss_step=0.0106, train_loss_epoch=0.0122]Epoch 260: Train Loss = 0.010580800473690033\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.0106] Epoch 261: Train Loss = 0.012969513423740864\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=360, train_loss_step=0.0126, train_loss_epoch=0.013]Epoch 262: Train Loss = 0.01261148601770401\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=360, train_loss_step=0.014, train_loss_epoch=0.0126] Epoch 263: Train Loss = 0.013976305723190308\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=360, train_loss_step=0.0118, train_loss_epoch=0.014]Epoch 264: Train Loss = 0.011834276840090752\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=360, train_loss_step=0.0116, train_loss_epoch=0.0118]Epoch 265: Train Loss = 0.01163434237241745\n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.0116]Epoch 266: Train Loss = 0.011483153328299522\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=360, train_loss_step=0.016, train_loss_epoch=0.0115] Epoch 267: Train Loss = 0.016018494963645935\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.016]Epoch 268: Train Loss = 0.011278829537332058\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, v_num=360, train_loss_step=0.0147, train_loss_epoch=0.0113]Epoch 269: Train Loss = 0.014682923443615437\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0147]Epoch 270: Train Loss = 0.012140589766204357\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=360, train_loss_step=0.0102, train_loss_epoch=0.0121]Epoch 271: Train Loss = 0.010175319388508797\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=360, train_loss_step=0.0104, train_loss_epoch=0.0102]Epoch 272: Train Loss = 0.01041148416697979\n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=360, train_loss_step=0.0101, train_loss_epoch=0.0104]Epoch 273: Train Loss = 0.010091814212501049\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=360, train_loss_step=0.0188, train_loss_epoch=0.0101]Epoch 274: Train Loss = 0.018837975338101387\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.0188]Epoch 275: Train Loss = 0.012411068193614483\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=360, train_loss_step=0.0107, train_loss_epoch=0.0124]Epoch 276: Train Loss = 0.01072807889431715\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=360, train_loss_step=0.0163, train_loss_epoch=0.0107]Epoch 277: Train Loss = 0.016307903453707695\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=360, train_loss_step=0.0104, train_loss_epoch=0.0163]Epoch 278: Train Loss = 0.010364032350480556\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=360, train_loss_step=0.0147, train_loss_epoch=0.0104]Epoch 279: Train Loss = 0.014668838120996952\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=360, train_loss_step=0.0143, train_loss_epoch=0.0147]Epoch 280: Train Loss = 0.014300018548965454\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0143]Epoch 281: Train Loss = 0.01207055989652872\n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s, v_num=360, train_loss_step=0.00959, train_loss_epoch=0.0121]Epoch 282: Train Loss = 0.009585083462297916\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=360, train_loss_step=0.0118, train_loss_epoch=0.00959] Epoch 283: Train Loss = 0.011788113974034786\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s, v_num=360, train_loss_step=0.0137, train_loss_epoch=0.0118] Epoch 284: Train Loss = 0.013733038678765297\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=360, train_loss_step=0.0159, train_loss_epoch=0.0137]Epoch 285: Train Loss = 0.015855329111218452\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.0159]Epoch 286: Train Loss = 0.011518478393554688\n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=360, train_loss_step=0.0146, train_loss_epoch=0.0115]Epoch 287: Train Loss = 0.014568381011486053\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=360, train_loss_step=0.0116, train_loss_epoch=0.0146]Epoch 288: Train Loss = 0.011575241573154926\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=360, train_loss_step=0.0106, train_loss_epoch=0.0116]Epoch 289: Train Loss = 0.01055693719536066\n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=360, train_loss_step=0.00829, train_loss_epoch=0.0106]Epoch 290: Train Loss = 0.008293388411402702\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=360, train_loss_step=0.00973, train_loss_epoch=0.00829]Epoch 291: Train Loss = 0.009728699922561646\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=360, train_loss_step=0.0129, train_loss_epoch=0.00973] Epoch 292: Train Loss = 0.012874341569840908\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0129] Epoch 293: Train Loss = 0.01210072822868824\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s, v_num=360, train_loss_step=0.0148, train_loss_epoch=0.0121]Epoch 294: Train Loss = 0.014827847480773926\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=360, train_loss_step=0.0215, train_loss_epoch=0.0148]Epoch 295: Train Loss = 0.021467555314302444\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s, v_num=360, train_loss_step=0.014, train_loss_epoch=0.0215] Epoch 296: Train Loss = 0.013985934667289257\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=360, train_loss_step=0.0156, train_loss_epoch=0.014]Epoch 297: Train Loss = 0.015572236850857735\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0156]Epoch 298: Train Loss = 0.01210521999746561\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=360, train_loss_step=0.0107, train_loss_epoch=0.0121]Epoch 299: Train Loss = 0.010734823532402515\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=360, train_loss_step=0.014, train_loss_epoch=0.0107] Epoch 300: Train Loss = 0.01396945770829916\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=360, train_loss_step=0.015, train_loss_epoch=0.014] Epoch 301: Train Loss = 0.014967979863286018\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=360, train_loss_step=0.0123, train_loss_epoch=0.015]Epoch 302: Train Loss = 0.012294582091271877\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=360, train_loss_step=0.0101, train_loss_epoch=0.0123]Epoch 303: Train Loss = 0.010128072462975979\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=360, train_loss_step=0.0105, train_loss_epoch=0.0101]Epoch 304: Train Loss = 0.010499199852347374\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=360, train_loss_step=0.0137, train_loss_epoch=0.0105]Epoch 305: Train Loss = 0.013703413307666779\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=360, train_loss_step=0.0135, train_loss_epoch=0.0137]Epoch 306: Train Loss = 0.013484147377312183\n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.0135]Epoch 307: Train Loss = 0.0141151649877429\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.0141]Epoch 308: Train Loss = 0.01414983719587326\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=360, train_loss_step=0.0127, train_loss_epoch=0.0141]Epoch 309: Train Loss = 0.012659045867621899\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=360, train_loss_step=0.016, train_loss_epoch=0.0127] Epoch 310: Train Loss = 0.015953246504068375\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=360, train_loss_step=0.0117, train_loss_epoch=0.016]Epoch 311: Train Loss = 0.011700144968926907\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=360, train_loss_step=0.0137, train_loss_epoch=0.0117]Epoch 312: Train Loss = 0.013712397776544094\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=360, train_loss_step=0.00912, train_loss_epoch=0.0137]Epoch 313: Train Loss = 0.009119746275246143\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=360, train_loss_step=0.0145, train_loss_epoch=0.00912] Epoch 314: Train Loss = 0.014493185095489025\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=360, train_loss_step=0.011, train_loss_epoch=0.0145]  Epoch 315: Train Loss = 0.010961736552417278\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=360, train_loss_step=0.0125, train_loss_epoch=0.011]Epoch 316: Train Loss = 0.01254711952060461\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=360, train_loss_step=0.012, train_loss_epoch=0.0125] Epoch 317: Train Loss = 0.011972508393228054\n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.012] Epoch 318: Train Loss = 0.013033530674874783\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=360, train_loss_step=0.0123, train_loss_epoch=0.013]Epoch 319: Train Loss = 0.01233841571956873\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=360, train_loss_step=0.0102, train_loss_epoch=0.0123]Epoch 320: Train Loss = 0.01015550084412098\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0102]Epoch 321: Train Loss = 0.012187488377094269\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.0122] Epoch 322: Train Loss = 0.013048074208199978\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.013]Epoch 323: Train Loss = 0.01238792110234499\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=360, train_loss_step=0.0138, train_loss_epoch=0.0124]Epoch 324: Train Loss = 0.013786607421934605\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=360, train_loss_step=0.010, train_loss_epoch=0.0138] Epoch 325: Train Loss = 0.010042952373623848\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=360, train_loss_step=0.0125, train_loss_epoch=0.010]Epoch 326: Train Loss = 0.012511028908193111\n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=360, train_loss_step=0.0126, train_loss_epoch=0.0125]Epoch 327: Train Loss = 0.012633725069463253\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0126]Epoch 328: Train Loss = 0.012135905213654041\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0121]Epoch 329: Train Loss = 0.012122533284127712\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=360, train_loss_step=0.00936, train_loss_epoch=0.0121]Epoch 330: Train Loss = 0.009362933225929737\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=360, train_loss_step=0.0127, train_loss_epoch=0.00936] Epoch 331: Train Loss = 0.01266959123313427\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=360, train_loss_step=0.0119, train_loss_epoch=0.0127] Epoch 332: Train Loss = 0.011865386739373207\n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=360, train_loss_step=0.0116, train_loss_epoch=0.0119]Epoch 333: Train Loss = 0.011609142646193504\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=360, train_loss_step=0.0112, train_loss_epoch=0.0116]Epoch 334: Train Loss = 0.011200531385838985\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=360, train_loss_step=0.0144, train_loss_epoch=0.0112]Epoch 335: Train Loss = 0.014429232105612755\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=360, train_loss_step=0.0174, train_loss_epoch=0.0144]Epoch 336: Train Loss = 0.017409423366189003\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=360, train_loss_step=0.0132, train_loss_epoch=0.0174]Epoch 337: Train Loss = 0.013209333643317223\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=360, train_loss_step=0.0106, train_loss_epoch=0.0132]Epoch 338: Train Loss = 0.010615663602948189\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=360, train_loss_step=0.0103, train_loss_epoch=0.0106]Epoch 339: Train Loss = 0.010278197936713696\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=360, train_loss_step=0.0149, train_loss_epoch=0.0103]Epoch 340: Train Loss = 0.01491136010736227\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=360, train_loss_step=0.0137, train_loss_epoch=0.0149]Epoch 341: Train Loss = 0.013674668036401272\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=360, train_loss_step=0.0126, train_loss_epoch=0.0137]Epoch 342: Train Loss = 0.012560015544295311\n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=360, train_loss_step=0.0136, train_loss_epoch=0.0126]Epoch 343: Train Loss = 0.013577570207417011\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.0136]Epoch 344: Train Loss = 0.012431616894900799\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=360, train_loss_step=0.0101, train_loss_epoch=0.0124]Epoch 345: Train Loss = 0.010061673820018768\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 11.33it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.0101]Epoch 346: Train Loss = 0.011324663646519184\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=360, train_loss_step=0.0133, train_loss_epoch=0.0113]Epoch 347: Train Loss = 0.013317270204424858\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=360, train_loss_step=0.0146, train_loss_epoch=0.0133]Epoch 348: Train Loss = 0.014565304853022099\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.0146]Epoch 349: Train Loss = 0.011516674421727657\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=360, train_loss_step=0.0138, train_loss_epoch=0.0115]Epoch 350: Train Loss = 0.013773108832538128\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0138]Epoch 351: Train Loss = 0.012074272148311138\n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=360, train_loss_step=0.0144, train_loss_epoch=0.0121]Epoch 352: Train Loss = 0.014401412568986416\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=360, train_loss_step=0.0143, train_loss_epoch=0.0144]Epoch 353: Train Loss = 0.014330269768834114\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=360, train_loss_step=0.00995, train_loss_epoch=0.0143]Epoch 354: Train Loss = 0.009952929802238941\n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=360, train_loss_step=0.0108, train_loss_epoch=0.00995] Epoch 355: Train Loss = 0.010810570791363716\n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=360, train_loss_step=0.011, train_loss_epoch=0.0108]  Epoch 356: Train Loss = 0.010966053232550621\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=360, train_loss_step=0.0145, train_loss_epoch=0.011]Epoch 357: Train Loss = 0.014542284421622753\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.0145]Epoch 358: Train Loss = 0.011265695095062256\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=360, train_loss_step=0.0106, train_loss_epoch=0.0113]Epoch 359: Train Loss = 0.010629178956151009\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=360, train_loss_step=0.0145, train_loss_epoch=0.0106]Epoch 360: Train Loss = 0.01453698705881834\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=360, train_loss_step=0.012, train_loss_epoch=0.0145] Epoch 361: Train Loss = 0.011970068328082561\n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=360, train_loss_step=0.0134, train_loss_epoch=0.012]Epoch 362: Train Loss = 0.013362528756260872\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=360, train_loss_step=0.0155, train_loss_epoch=0.0134]Epoch 363: Train Loss = 0.015458247624337673\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=360, train_loss_step=0.0105, train_loss_epoch=0.0155]Epoch 364: Train Loss = 0.010543343611061573\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=360, train_loss_step=0.0151, train_loss_epoch=0.0105]Epoch 365: Train Loss = 0.015111886896193027\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=360, train_loss_step=0.0154, train_loss_epoch=0.0151]Epoch 366: Train Loss = 0.015415400266647339\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s, v_num=360, train_loss_step=0.0125, train_loss_epoch=0.0154]Epoch 367: Train Loss = 0.012513612397015095\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=360, train_loss_step=0.0134, train_loss_epoch=0.0125]Epoch 368: Train Loss = 0.013389302417635918\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=360, train_loss_step=0.0103, train_loss_epoch=0.0134]Epoch 369: Train Loss = 0.01028068270534277\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0103]Epoch 370: Train Loss = 0.012248796410858631\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0122]Epoch 371: Train Loss = 0.012177464552223682\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=360, train_loss_step=0.0137, train_loss_epoch=0.0122]Epoch 372: Train Loss = 0.013652736321091652\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=360, train_loss_step=0.0125, train_loss_epoch=0.0137]Epoch 373: Train Loss = 0.012528732419013977\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=360, train_loss_step=0.0086, train_loss_epoch=0.0125]Epoch 374: Train Loss = 0.00859812181442976\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=360, train_loss_step=0.0134, train_loss_epoch=0.0086]Epoch 375: Train Loss = 0.013375848531723022\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s, v_num=360, train_loss_step=0.00957, train_loss_epoch=0.0134]Epoch 376: Train Loss = 0.00956819299608469\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=360, train_loss_step=0.00891, train_loss_epoch=0.00957]Epoch 377: Train Loss = 0.008905509486794472\n",
      "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=360, train_loss_step=0.0103, train_loss_epoch=0.00891] Epoch 378: Train Loss = 0.010254894383251667\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.0103] Epoch 379: Train Loss = 0.014065907336771488\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=360, train_loss_step=0.0172, train_loss_epoch=0.0141]Epoch 380: Train Loss = 0.017241017892956734\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=360, train_loss_step=0.0127, train_loss_epoch=0.0172]Epoch 381: Train Loss = 0.012685132212936878\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 11.40it/s, v_num=360, train_loss_step=0.0166, train_loss_epoch=0.0127]Epoch 382: Train Loss = 0.016587033867836\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=360, train_loss_step=0.0142, train_loss_epoch=0.0166]Epoch 383: Train Loss = 0.014165082946419716\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=360, train_loss_step=0.0132, train_loss_epoch=0.0142]Epoch 384: Train Loss = 0.013150055892765522\n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=360, train_loss_step=0.0131, train_loss_epoch=0.0132]Epoch 385: Train Loss = 0.013078871183097363\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=360, train_loss_step=0.0119, train_loss_epoch=0.0131]Epoch 386: Train Loss = 0.01194840669631958\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=360, train_loss_step=0.0161, train_loss_epoch=0.0119]Epoch 387: Train Loss = 0.016142455860972404\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=360, train_loss_step=0.0188, train_loss_epoch=0.0161]Epoch 388: Train Loss = 0.01877703331410885\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=360, train_loss_step=0.0101, train_loss_epoch=0.0188]Epoch 389: Train Loss = 0.01014687865972519\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=360, train_loss_step=0.0114, train_loss_epoch=0.0101]Epoch 390: Train Loss = 0.011356485076248646\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=360, train_loss_step=0.0154, train_loss_epoch=0.0114]Epoch 391: Train Loss = 0.01538906805217266\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.0154]Epoch 392: Train Loss = 0.01149672083556652\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=360, train_loss_step=0.014, train_loss_epoch=0.0115] Epoch 393: Train Loss = 0.013992984779179096\n",
      "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s, v_num=360, train_loss_step=0.0133, train_loss_epoch=0.014]Epoch 394: Train Loss = 0.013300362043082714\n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=360, train_loss_step=0.0137, train_loss_epoch=0.0133]Epoch 395: Train Loss = 0.0137223731726408\n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=360, train_loss_step=0.00935, train_loss_epoch=0.0137]Epoch 396: Train Loss = 0.009348147548735142\n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=360, train_loss_step=0.0134, train_loss_epoch=0.00935] Epoch 397: Train Loss = 0.013400848023593426\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=360, train_loss_step=0.0174, train_loss_epoch=0.0134] Epoch 398: Train Loss = 0.01744900457561016\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=360, train_loss_step=0.0165, train_loss_epoch=0.0174]Epoch 399: Train Loss = 0.01649162918329239\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=360, train_loss_step=0.012, train_loss_epoch=0.0165] Epoch 400: Train Loss = 0.012002373114228249\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=360, train_loss_step=0.0116, train_loss_epoch=0.012]Epoch 401: Train Loss = 0.011645258404314518\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=360, train_loss_step=0.0103, train_loss_epoch=0.0116]Epoch 402: Train Loss = 0.010258872993290424\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=360, train_loss_step=0.0138, train_loss_epoch=0.0103]Epoch 403: Train Loss = 0.013781784102320671\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0138]Epoch 404: Train Loss = 0.012078369036316872\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=360, train_loss_step=0.0153, train_loss_epoch=0.0121]Epoch 405: Train Loss = 0.015344856306910515\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=360, train_loss_step=0.0114, train_loss_epoch=0.0153]Epoch 406: Train Loss = 0.011385264806449413\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=360, train_loss_step=0.0233, train_loss_epoch=0.0114]Epoch 407: Train Loss = 0.02328840270638466\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=360, train_loss_step=0.0129, train_loss_epoch=0.0233]Epoch 408: Train Loss = 0.012875671498477459\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=360, train_loss_step=0.00979, train_loss_epoch=0.0129]Epoch 409: Train Loss = 0.009785185568034649\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=360, train_loss_step=0.0109, train_loss_epoch=0.00979] Epoch 410: Train Loss = 0.010886487551033497\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=360, train_loss_step=0.0118, train_loss_epoch=0.0109] Epoch 411: Train Loss = 0.011752995662391186\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=360, train_loss_step=0.0147, train_loss_epoch=0.0118]Epoch 412: Train Loss = 0.014725425280630589\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=360, train_loss_step=0.0157, train_loss_epoch=0.0147]Epoch 413: Train Loss = 0.015681276097893715\n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=360, train_loss_step=0.00971, train_loss_epoch=0.0157]Epoch 414: Train Loss = 0.009709103032946587\n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=360, train_loss_step=0.0107, train_loss_epoch=0.00971] Epoch 415: Train Loss = 0.010723322629928589\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=360, train_loss_step=0.0152, train_loss_epoch=0.0107] Epoch 416: Train Loss = 0.015151513740420341\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=360, train_loss_step=0.012, train_loss_epoch=0.0152] Epoch 417: Train Loss = 0.011964508332312107\n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.012] Epoch 418: Train Loss = 0.013016416691243649\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=360, train_loss_step=0.00945, train_loss_epoch=0.013]Epoch 419: Train Loss = 0.009448151104152203\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.00945] Epoch 420: Train Loss = 0.012081949040293694\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.0121]  Epoch 421: Train Loss = 0.012984433211386204\n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=360, train_loss_step=0.0158, train_loss_epoch=0.013]Epoch 422: Train Loss = 0.015786314383149147\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=360, train_loss_step=0.015, train_loss_epoch=0.0158] Epoch 423: Train Loss = 0.014993789605796337\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=360, train_loss_step=0.00998, train_loss_epoch=0.015]Epoch 424: Train Loss = 0.009980064816772938\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.00998] Epoch 425: Train Loss = 0.012084158137440681\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=360, train_loss_step=0.0172, train_loss_epoch=0.0121] Epoch 426: Train Loss = 0.01722737029194832\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=360, train_loss_step=0.0146, train_loss_epoch=0.0172]Epoch 427: Train Loss = 0.01461443305015564\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=360, train_loss_step=0.0117, train_loss_epoch=0.0146]Epoch 428: Train Loss = 0.011651654727756977\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=360, train_loss_step=0.0109, train_loss_epoch=0.0117]Epoch 429: Train Loss = 0.01088106632232666\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 11.08it/s, v_num=360, train_loss_step=0.0181, train_loss_epoch=0.0109]Epoch 430: Train Loss = 0.018098393455147743\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.0181]Epoch 431: Train Loss = 0.01405451912432909\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=360, train_loss_step=0.00957, train_loss_epoch=0.0141]Epoch 432: Train Loss = 0.009565828368067741\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.00957] Epoch 433: Train Loss = 0.012220081873238087\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0122] Epoch 434: Train Loss = 0.01218286994844675\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=360, train_loss_step=0.0099, train_loss_epoch=0.0122]Epoch 435: Train Loss = 0.009895244613289833\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=360, train_loss_step=0.00996, train_loss_epoch=0.0099]Epoch 436: Train Loss = 0.009956794790923595\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=360, train_loss_step=0.00814, train_loss_epoch=0.00996]Epoch 437: Train Loss = 0.008136982098221779\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s, v_num=360, train_loss_step=0.011, train_loss_epoch=0.00814]  Epoch 438: Train Loss = 0.011042104102671146\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=360, train_loss_step=0.0151, train_loss_epoch=0.011] Epoch 439: Train Loss = 0.015113144181668758\n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, v_num=360, train_loss_step=0.0151, train_loss_epoch=0.0151]Epoch 440: Train Loss = 0.015114737674593925\n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.0151]Epoch 441: Train Loss = 0.01130480132997036\n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=360, train_loss_step=0.0101, train_loss_epoch=0.0113]Epoch 442: Train Loss = 0.010054285638034344\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=360, train_loss_step=0.0117, train_loss_epoch=0.0101]Epoch 443: Train Loss = 0.011729377321898937\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=360, train_loss_step=0.0132, train_loss_epoch=0.0117]Epoch 444: Train Loss = 0.01318853534758091\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=360, train_loss_step=0.00976, train_loss_epoch=0.0132]Epoch 445: Train Loss = 0.009755308739840984\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=360, train_loss_step=0.0111, train_loss_epoch=0.00976] Epoch 446: Train Loss = 0.011077232658863068\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0111] Epoch 447: Train Loss = 0.012180058285593987\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=360, train_loss_step=0.014, train_loss_epoch=0.0122] Epoch 448: Train Loss = 0.014031109400093555\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 12.67it/s, v_num=360, train_loss_step=0.0134, train_loss_epoch=0.014]Epoch 449: Train Loss = 0.013358987867832184\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=360, train_loss_step=0.0143, train_loss_epoch=0.0134]Epoch 450: Train Loss = 0.01428992860019207\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=360, train_loss_step=0.0104, train_loss_epoch=0.0143]Epoch 451: Train Loss = 0.010408306494355202\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=360, train_loss_step=0.0118, train_loss_epoch=0.0104]Epoch 452: Train Loss = 0.011753584258258343\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.0118]Epoch 453: Train Loss = 0.012401439249515533\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=360, train_loss_step=0.0114, train_loss_epoch=0.0124]Epoch 454: Train Loss = 0.011431119404733181\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=360, train_loss_step=0.0125, train_loss_epoch=0.0114]Epoch 455: Train Loss = 0.012545594945549965\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s, v_num=360, train_loss_step=0.0156, train_loss_epoch=0.0125]Epoch 456: Train Loss = 0.015647774562239647\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=360, train_loss_step=0.0111, train_loss_epoch=0.0156]Epoch 457: Train Loss = 0.011052235029637814\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=360, train_loss_step=0.0103, train_loss_epoch=0.0111]Epoch 458: Train Loss = 0.010341678746044636\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=360, train_loss_step=0.0107, train_loss_epoch=0.0103]Epoch 459: Train Loss = 0.010690444149076939\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=360, train_loss_step=0.0129, train_loss_epoch=0.0107]Epoch 460: Train Loss = 0.01288131345063448\n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=360, train_loss_step=0.0111, train_loss_epoch=0.0129]Epoch 461: Train Loss = 0.011055013164877892\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=360, train_loss_step=0.0142, train_loss_epoch=0.0111]Epoch 462: Train Loss = 0.014208758249878883\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=360, train_loss_step=0.0101, train_loss_epoch=0.0142]Epoch 463: Train Loss = 0.010056027211248875\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=360, train_loss_step=0.0114, train_loss_epoch=0.0101]Epoch 464: Train Loss = 0.011390432715415955\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=360, train_loss_step=0.0135, train_loss_epoch=0.0114]Epoch 465: Train Loss = 0.013515445403754711\n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=360, train_loss_step=0.020, train_loss_epoch=0.0135] Epoch 466: Train Loss = 0.020034214481711388\n",
      "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=360, train_loss_step=0.00848, train_loss_epoch=0.020]Epoch 467: Train Loss = 0.00847763754427433\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=360, train_loss_step=0.0106, train_loss_epoch=0.00848] Epoch 468: Train Loss = 0.010573267005383968\n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=360, train_loss_step=0.0105, train_loss_epoch=0.0106] Epoch 469: Train Loss = 0.010458281263709068\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=360, train_loss_step=0.0142, train_loss_epoch=0.0105]Epoch 470: Train Loss = 0.014237834140658379\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s, v_num=360, train_loss_step=0.013, train_loss_epoch=0.0142] Epoch 471: Train Loss = 0.012960761785507202\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 12.26it/s, v_num=360, train_loss_step=0.0101, train_loss_epoch=0.013]Epoch 472: Train Loss = 0.010128363966941833\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=360, train_loss_step=0.0119, train_loss_epoch=0.0101]Epoch 473: Train Loss = 0.011910006403923035\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=360, train_loss_step=0.0131, train_loss_epoch=0.0119]Epoch 474: Train Loss = 0.01310888770967722\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=360, train_loss_step=0.0124, train_loss_epoch=0.0131]Epoch 475: Train Loss = 0.01242678053677082\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=360, train_loss_step=0.0105, train_loss_epoch=0.0124]Epoch 476: Train Loss = 0.01048334501683712\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=360, train_loss_step=0.0106, train_loss_epoch=0.0105]Epoch 477: Train Loss = 0.010627313517034054\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=360, train_loss_step=0.0112, train_loss_epoch=0.0106]Epoch 478: Train Loss = 0.011232738383114338\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=360, train_loss_step=0.0132, train_loss_epoch=0.0112]Epoch 479: Train Loss = 0.013244086876511574\n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=360, train_loss_step=0.0109, train_loss_epoch=0.0132]Epoch 480: Train Loss = 0.01092470996081829\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=360, train_loss_step=0.0109, train_loss_epoch=0.0109]Epoch 481: Train Loss = 0.010893058963119984\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=360, train_loss_step=0.00969, train_loss_epoch=0.0109]Epoch 482: Train Loss = 0.009691900573670864\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=360, train_loss_step=0.0115, train_loss_epoch=0.00969] Epoch 483: Train Loss = 0.01153813861310482\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=360, train_loss_step=0.0098, train_loss_epoch=0.0115] Epoch 484: Train Loss = 0.009804883040487766\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s, v_num=360, train_loss_step=0.0108, train_loss_epoch=0.0098]Epoch 485: Train Loss = 0.010767492465674877\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=360, train_loss_step=0.011, train_loss_epoch=0.0108] Epoch 486: Train Loss = 0.010990886949002743\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=360, train_loss_step=0.00982, train_loss_epoch=0.011]Epoch 487: Train Loss = 0.009822373278439045\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 10.24it/s, v_num=360, train_loss_step=0.0133, train_loss_epoch=0.00982] Epoch 488: Train Loss = 0.013324908912181854\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=360, train_loss_step=0.0126, train_loss_epoch=0.0133] Epoch 489: Train Loss = 0.012557050213217735\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=360, train_loss_step=0.0143, train_loss_epoch=0.0126]Epoch 490: Train Loss = 0.014257162809371948\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=360, train_loss_step=0.0121, train_loss_epoch=0.0143]Epoch 491: Train Loss = 0.012113925069570541\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=360, train_loss_step=0.0127, train_loss_epoch=0.0121]Epoch 492: Train Loss = 0.012734703719615936\n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=360, train_loss_step=0.010, train_loss_epoch=0.0127] Epoch 493: Train Loss = 0.010043160989880562\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.010]Epoch 494: Train Loss = 0.014084410853683949\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=360, train_loss_step=0.0113, train_loss_epoch=0.0141]Epoch 495: Train Loss = 0.01130693219602108\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=360, train_loss_step=0.011, train_loss_epoch=0.0113] Epoch 496: Train Loss = 0.011004118248820305\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=360, train_loss_step=0.0139, train_loss_epoch=0.011]Epoch 497: Train Loss = 0.013946793973445892\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=360, train_loss_step=0.0122, train_loss_epoch=0.0139]Epoch 498: Train Loss = 0.012196903117001057\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.0122]Epoch 499: Train Loss = 0.014129781164228916\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.0141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=360, train_loss_step=0.0141, train_loss_epoch=0.0141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Rajarshi/Term Project/notebook_files/tpvenv/lib/python3.10/site-packages/neuralforecast/core.py:210: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the trainer\n",
    "trainer = ModelTrainer(data, scaler_close, save_loss_callback, pl_trainer_kwargs)\n",
    "\n",
    "# Training and prediction loop\n",
    "window_number = 1\n",
    "while True:\n",
    "    train_data = data.loc[:training_end_date]\n",
    "    print(f\"Training window {window_number}: from {train_data.index.min()} to {train_data.index.max()}\")\n",
    "\n",
    "    # Train the model and get predictions\n",
    "    dates, pred_values = trainer.train_model(train_data, window_number)\n",
    "\n",
    "    if len(dates) == 0:\n",
    "        print(\"No future dates were generated. Exiting the loop.\")\n",
    "        break\n",
    "\n",
    "    # Store the predictions\n",
    "    predictions_df = pd.DataFrame({'Date': dates, 'Predicted Value': pred_values.flatten()})\n",
    "    final_predictions.append(predictions_df)\n",
    "\n",
    "    # Update training_end_date for the next window only if dates exist\n",
    "    training_end_date = dates.iloc[-1] if len(dates) > 0 else training_end_date\n",
    "\n",
    "    # Break if we reach the end of the data\n",
    "    if training_end_date >= data.index.max():\n",
    "        break\n",
    "\n",
    "    window_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to prediction_using_window_method_itransformer_model_one_year.csv\n",
      "Training Losses: []\n"
     ]
    }
   ],
   "source": [
    "# Combine predictions and save\n",
    "all_predictions_df = pd.concat(final_predictions, ignore_index=True)\n",
    "output_csv_file = 'prediction_using_window_method_itransformer_model_one_year.csv'\n",
    "all_predictions_df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_csv_file}\")\n",
    "\n",
    "# Print the logged training losses\n",
    "print(\"Training Losses:\", save_loss_callback.training_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load the actual data from the CSV file\n",
    "#actual_csv_path = '/home/raj/Rajarshi/Term Project/notebook_files/data/SBIN.NS_day_2023.csv'\n",
    "actual_csv_path = csv_file_path\n",
    "actual_df = pd.read_csv(actual_csv_path)\n",
    "\n",
    "# Load the predicted data from the CSV file\n",
    "#predicted_csv_path = '/home/raj/Rajarshi/Term Project/rajarshi_code/itransformer_file/prediction_using_entire_data_itransformer_model.csv'\n",
    "predicted_csv_path = output_csv_file\n",
    "predicted_df = pd.read_csv(predicted_csv_path)\n",
    "\n",
    "# Convert the 'Date' columns to a consistent datetime format for both DataFrames\n",
    "actual_df['Date'] = pd.to_datetime(actual_df['Date'], errors='coerce')\n",
    "predicted_df['Date'] = pd.to_datetime(predicted_df['Date'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates (NaT)\n",
    "actual_df = actual_df.dropna(subset=['Date'])\n",
    "predicted_df = predicted_df.dropna(subset=['Date'])\n",
    "\n",
    "# Merge the DataFrames on the 'Date' column, keeping only the matching dates\n",
    "merged_df = pd.merge(predicted_df, actual_df, on='Date', how='inner')\n",
    "\n",
    "# Print the matched dates for verification\n",
    "# print(\"Matched Dates:\\n\", merged_df['Date'])\n",
    "\n",
    "# Plot the actual and predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(merged_df['Date'], merged_df['Close'], label='Actual Close Value', marker='o')\n",
    "plt.plot(merged_df['Date'], merged_df['Predicted Value'], label='Predicted Value', marker='x')\n",
    "\n",
    "# If 'Window Start' and 'Window End' columns are present, add vertical markers\n",
    "if 'Window Start' in predicted_df.columns and 'Window End' in predicted_df.columns:\n",
    "    for i in range(len(predicted_df)):\n",
    "        plt.axvline(predicted_df['Window Start'].iloc[i], color='green', linestyle='--', label='Window Start' if i == 0 else '')\n",
    "        plt.axvline(predicted_df['Window End'].iloc[i], color='red', linestyle='--', label='Window End' if i == 0 else '')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "title = 'Actual vs prediction_using_entire_data_itransformer_model'\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)  # Rotate the date labels for better readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Specify the folder where you want to save the plot\n",
    "output_folder = '/home/raj/Rajarshi/Term Project/notebook_files/saved_plots/'\n",
    "\n",
    "# Ensure the folder exists, if not, create it\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Use the plot title for the filename, replacing spaces with underscores and converting to lowercase\n",
    "filename = f'{title.replace(\" \", \"_\").lower()}.png'\n",
    "\n",
    "# Save the plot in the specified folder with the generated filename\n",
    "plt.savefig(os.path.join(output_folder, filename), format='png', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
